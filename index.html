 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-22">2021-06-22</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Augment for Data-Scarce Domain BERT Knowledge Distillation. (arXiv:2101.08106v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lingyun Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1">Minghui Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Ying Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08106">
                                    <div class="article-summary-box-inner">
                                        <span>Despite pre-trained language models such as BERT have achieved appealing
performance in a wide range of natural language processing tasks, they are
computationally expensive to be deployed in real-time applications. A typical
method is to adopt knowledge distillation to compress these large pre-trained
models (teacher models) to small student models. However, for a target domain
with scarce training data, the teacher can hardly pass useful knowledge to the
student, which yields performance degradation for the student models. To tackle
this problem, we propose a method to learn to augment for data-scarce domain
BERT knowledge distillation, by learning a cross-domain manipulation scheme
that automatically augments the target with the help of resource-rich source
domains. Specifically, the proposed method generates samples acquired from a
stationary distribution near the target data and adopts a reinforced selector
to automatically refine the augmentation strategy according to the performance
of the student. Extensive experiments demonstrate that the proposed method
significantly outperforms state-of-the-art baselines on four different tasks,
and for the data-scarce domains, the compressed student models even perform
better than the original large teacher model, with much fewer parameters (only
${\sim}13.3\%$) when only a few labeled examples available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1">David Gaddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01933">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an improved model for voicing silent speech, where
audio is synthesized from facial electromyography (EMG) signals. To give our
model greater flexibility to learn its own input features, we directly use EMG
signals as input in the place of hand-designed features used by prior work. Our
model uses convolutional layers to extract features from the signals and
Transformer layers to propagate information across longer distances. To provide
better signal for learning, we also introduce an auxiliary task of predicting
phoneme labels in addition to predicting speech audio features. On an open
vocabulary intelligibility evaluation, our model improves the state of the art
for this task by an absolute 25.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese Grammatical Error Correction. (arXiv:2106.01609v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Piji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01609">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem of Chinese Grammatical Error Correction (CGEC) and
present a new framework named Tail-to-Tail (\textbf{TtT}) non-autoregressive
sequence prediction to address the deep issues hidden in CGEC. Considering that
most tokens are correct and can be conveyed directly from source to target, and
the error positions can be estimated and corrected based on the bidirectional
context information, thus we employ a BERT-initialized Transformer Encoder as
the backbone model to conduct information modeling and conveying. Considering
that only relying on the same position substitution cannot handle the
variable-length correction cases, various operations such substitution,
deletion, insertion, and local paraphrasing are required jointly. Therefore, a
Conditional Random Fields (CRF) layer is stacked on the up tail to conduct
non-autoregressive sequence prediction by modeling the token dependencies.
Since most tokens are correct and easily to be predicted/conveyed to the
target, then the models may suffer from a severe class imbalance issue. To
alleviate this problem, focal loss penalty strategies are integrated into the
loss functions. Moreover, besides the typical fix-length error correction
datasets, we also construct a variable-length corpus to conduct experiments.
Experimental results on standard datasets, especially on the variable-length
datasets, demonstrate the effectiveness of TtT in terms of sentence-level
Accuracy, Precision, Recall, and F1-Measure on tasks of error Detection and
Correction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Sequence-to-Set Network for Nested Named Entity Recognition. (arXiv:2105.08901v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zeqi Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yongliang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Weiming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yueting Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08901">
                                    <div class="article-summary-box-inner">
                                        <span>Named entity recognition (NER) is a widely studied task in natural language
processing. Recently, a growing number of studies have focused on the nested
NER. The span-based methods, considering the entity recognition as a span
classification task, can deal with nested entities naturally. But they suffer
from the huge search space and the lack of interactions between entities. To
address these issues, we propose a novel sequence-to-set neural network for
nested NER. Instead of specifying candidate spans in advance, we provide a
fixed set of learnable vectors to learn the patterns of the valuable spans. We
utilize a non-autoregressive decoder to predict the final set of entities in
one pass, in which we are able to capture dependencies between entities.
Compared with the sequence-to-sequence method, our model is more suitable for
such unordered recognition task as it is insensitive to the label order. In
addition, we utilize the loss function based on bipartite matching to compute
the overall training loss. Experimental results show that our proposed model
achieves state-of-the-art on three nested NER corpora: ACE 2004, ACE 2005 and
KBP 2017. The code is available at
https://github.com/zqtan1024/sequence-to-set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure-Grounded Pretraining for Text-to-SQL. (arXiv:2010.12773v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Meek_C/0/1/0/all/0/1">Christopher Meek</a>, <a href="http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1">Oleksandr Polozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Richardson_M/0/1/0/all/0/1">Matthew Richardson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12773">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to capture text-table alignment is essential for tasks like
text-to-SQL. A model needs to correctly recognize natural language references
to columns and values and to ground them in the given database schema. In this
paper, we present a novel weakly supervised Structure-Grounded pretraining
framework (StruG) for text-to-SQL that can effectively learn to capture
text-table alignment based on a parallel text-table corpus. We identify a set
of novel prediction tasks: column grounding, value grounding and column-value
mapping, and leverage them to pretrain a text-table encoder. Additionally, to
evaluate different methods under more realistic text-table alignment settings,
we create a new evaluation set Spider-Realistic based on Spider dev set with
explicit mentions of column names removed, and adopt eight existing text-to-SQL
datasets for cross-database evaluation. STRUG brings significant improvement
over BERT-LARGE in all settings. Compared with existing pretraining methods
such as GRAPPA, STRUG achieves similar performance on Spider, and outperforms
all baselines on more realistic sets. All the code and data used in this work
is public available at https://aka.ms/strug.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FNet: Mixing Tokens with Fourier Transforms. (arXiv:2105.03824v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1">James Lee-Thorp</a>, <a href="http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1">Joshua Ainslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_I/0/1/0/all/0/1">Ilya Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Ontanon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03824">
                                    <div class="article-summary-box-inner">
                                        <span>We show that Transformer encoder architectures can be massively sped up, with
limited accuracy costs, by replacing the self-attention sublayers with simple
linear transformations that &quot;mix&quot; input tokens. These linear transformations,
along with standard nonlinearities in feed-forward layers, prove competent at
modeling semantic relationships in several text classification tasks. Most
surprisingly, we find that replacing the self-attention sublayer in a
Transformer encoder with a standard, unparameterized Fourier Transform achieves
92-97% of the accuracy of BERT counterparts on the GLUE benchmark, but trains
nearly seven times faster on GPUs and twice as fast on TPUs. The resulting
model, FNet, also scales very efficiently to long inputs. Specifically, when
compared to the &quot;efficient&quot; Transformers on the Long Range Arena benchmark,
FNet matches the accuracy of the most accurate models, but is faster than the
fastest models across all sequence lengths on GPUs (and across relatively
shorter lengths on TPUs). Finally, FNet has a light memory footprint and is
particularly efficient at smaller model sizes: for a fixed speed and accuracy
budget, small FNet models outperform Transformer counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robustness of Text-to-SQL Models against Synonym Substitution. (arXiv:2106.01065v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yujian Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiuping Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1">Matthew Purver</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodward_J/0/1/0/all/0/1">John R. Woodward</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jinxia Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Pengsheng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01065">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been significant progress in studying neural networks to
translate text descriptions into SQL queries. Despite achieving good
performance on some public benchmarks, existing text-to-SQL models typically
rely on the lexical matching between words in natural language (NL) questions
and tokens in table schemas, which may render the models vulnerable to attacks
that break the schema linking mechanism. In this work, we investigate the
robustness of text-to-SQL models to synonym substitution. In particular, we
introduce Spider-Syn, a human-curated dataset based on the Spider benchmark for
text-to-SQL translation. NL questions in Spider-Syn are modified from Spider,
by replacing their schema-related words with manually selected synonyms that
reflect real-world question paraphrases. We observe that the accuracy
dramatically drops by eliminating such explicit correspondence between NL
questions and table schemas, even if the synonyms are not adversarially
selected to conduct worst-case adversarial attacks. Finally, we present two
categories of approaches to improve the model robustness. The first category of
approaches utilizes additional synonym annotations for table schemas by
modifying the model input, while the second category is based on adversarial
training. We demonstrate that both categories of approaches significantly
outperform their counterparts without the defense, and the first category of
approaches are more effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-NERD: A Few-Shot Named Entity Recognition Dataset. (arXiv:2105.07464v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guangwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yulin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaobin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengjun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07464">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, considerable literature has grown up around the theme of few-shot
named entity recognition (NER), but little published benchmark data
specifically focused on the practical and challenging task. Current approaches
collect existing supervised NER datasets and re-organize them to the few-shot
setting for empirical study. These strategies conventionally aim to recognize
coarse-grained entity types with few examples, while in practice, most unseen
entity types are fine-grained. In this paper, we present Few-NERD, a
large-scale human-annotated few-shot NER dataset with a hierarchy of 8
coarse-grained and 66 fine-grained entity types. Few-NERD consists of 188,238
sentences from Wikipedia, 4,601,160 words are included and each is annotated as
context or a part of a two-level entity type. To the best of our knowledge,
this is the first few-shot NER dataset and the largest human-crafted NER
dataset. We construct benchmark tasks with different emphases to
comprehensively assess the generalization capability of models. Extensive
empirical results and analysis show that Few-NERD is challenging and the
problem requires further research. We make Few-NERD public at
https://ningding97.github.io/fewnerd/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of Disentangled Speech Content and Style Representation. (arXiv:2010.12973v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1">Andros Tjandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Ruoming Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karita_S/0/1/0/all/0/1">Shigeki Karita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12973">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for unsupervised learning of speech representation
disentangling contents and styles. Our model consists of: (1) a local encoder
that captures per-frame information; (2) a global encoder that captures
per-utterance information; and (3) a conditional decoder that reconstructs
speech given local and global latent variables. Our experiments show that (1)
the local latent variables encode speech contents, as reconstructed speech can
be recognized by ASR with low word error rates (WER), even with a different
global encoding; (2) the global latent variables encode speaker style, as
reconstructed speech shares speaker identity with the source utterance of the
global encoding. Additionally, we demonstrate an useful application from our
pre-trained model, where we can train a speaker recognition model from the
global latent variables and achieve high accuracy by fine-tuning with as few
data as one label per speaker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out of Context: A New Clue for Context Modeling of Aspect-based Sentiment Analysis. (arXiv:2106.10816v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1">Bowen Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1">Ivor W. Tsang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10816">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect-based sentiment analysis (ABSA) aims to predict the sentiment
expressed in a review with respect to a given aspect. The core of ABSA is to
model the interaction between the context and given aspect to extract the
aspect-related information. In prior work, attention mechanisms and dependency
graph networks are commonly adopted to capture the relations between the
context and given aspect. And the weighted sum of context hidden states is used
as the final representation fed to the classifier. However, the information
related to the given aspect may be already discarded and adverse information
may be retained in the context modeling processes of existing models. This
problem cannot be solved by subsequent modules and there are two reasons:
first, their operations are conducted on the encoder-generated context hidden
states, whose value cannot change after the encoder; second, existing encoders
only consider the context while not the given aspect. To address this problem,
we argue the given aspect should be considered as a new clue out of context in
the context modeling process. As for solutions, we design several aspect-aware
context encoders based on different backbones: an aspect-aware LSTM and three
aspect-aware BERTs. They are dedicated to generate aspect-aware hidden states
which are tailored for ABSA task. In these aspect-aware context encoders, the
semantics of the given aspect is used to regulate the information flow.
Consequently, the aspect-related information can be retained and
aspect-irrelevant information can be excluded in the generated hidden states.
We conduct extensive experiments on several benchmark datasets with empirical
analysis, demonstrating the efficacies and advantages of our proposed
aspect-aware context encoders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Disentangled Adversarial Neural Topic Model for Separating Opinions from Plots in User Reviews. (arXiv:2010.11384v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1">Gabriele Pergola</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1">Lin Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yulan He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11384">
                                    <div class="article-summary-box-inner">
                                        <span>The flexibility of the inference process in Variational Autoencoders (VAEs)
has recently led to revising traditional probabilistic topic models giving rise
to Neural Topic Models (NTMs). Although these approaches have achieved
significant results, surprisingly very little work has been done on how to
disentangle the latent topics. Existing topic models when applied to reviews
may extract topics associated with writers&#x27; subjective opinions mixed with
those related to factual descriptions such as plot summaries in movie and book
reviews. It is thus desirable to automatically separate opinion topics from
plot/neutral ones enabling a better interpretability. In this paper, we propose
a neural topic model combined with adversarial training to disentangle opinion
topics from plot and neutral ones. We conduct an extensive experimental
assessment introducing a new collection of movie and book reviews paired with
their plots, namely MOBO dataset, showing an improved coherence and variety of
topics, a consistent disentanglement rate, and sentiment classification
performance superior to other supervised topic models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1">Ignacio Tampe Palma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1">Marcelo Mendoza</a>, <a href="http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1">Evangelos Milios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03953">
                                    <div class="article-summary-box-inner">
                                        <span>Summarization has usually relied on gold standard summaries to train
extractive or abstractive models. Social media brings a hurdle to summarization
techniques since it requires addressing a multi-document multi-author approach.
We address this challenging task by introducing a novel method that generates
abstractive summaries of online news discussions. Our method extends a
BERT-based architecture, including an attention encoding that fed comments&#x27;
likes during the training stage. To train our model, we define a task which
consists of reconstructing high impact comments based on popularity (likes).
Accordingly, our model learns to summarize online discussions based on their
most relevant comments. Our novel approach provides a summary that represents
the most relevant aspects of a news item that users comment on, incorporating
the social context as a source of information to summarize texts in online
social networks. Our model is evaluated using ROUGE scores between the
generated summary and each comment on the thread. Our model, including the
social attention encoding, significantly outperforms both extractive and
abstractive summarization methods based on such evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing is Knowing! Fact-based Visual Question Answering using Knowledge Graph Embeddings. (arXiv:2012.15484v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramnath_K/0/1/0/all/0/1">Kiran Ramnath</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1">Mark Hasegawa-Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15484">
                                    <div class="article-summary-box-inner">
                                        <span>Fact-based Visual Question Answering (FVQA), a challenging variant of VQA,
requires a QA-system to include facts from a diverse knowledge graph (KG) in
its reasoning process to produce an answer. Large KGs, especially common-sense
KGs, are known to be incomplete, i.e., not all non-existent facts are always
incorrect. Therefore, being able to reason over incomplete KGs for QA is a
critical requirement in real-world applications that has not been addressed
extensively in the literature. We develop a novel QA architecture that allows
us to reason over incomplete KGs, something current FVQA state-of-the-art
(SOTA) approaches lack due to their critical reliance on fact retrieval. We use
KG Embeddings, a technique widely used for KG completion, for the downstream
task of FVQA. We also employ a new image representation technique we call
&#x27;Image-as-Knowledge&#x27; to enable this capability, alongside a simple one-step
CoAttention mechanism to attend to text and image during QA. Our FVQA
architecture is faster during inference time, being O(m), as opposed to
existing FVQA SOTA methods which are O(N log N), where m &#x3D; number of vertices,
N &#x3D; number of edges &#x3D; O(m^2). KG embeddings are shown to hold complementary
information to word embeddings: a combination of both metrics permits
performance comparable to SOTA methods in the standard answer retrieval task,
and significantly better (26% absolute) in the proposed missing-edge reasoning
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Speaker Diarization: Recent Advances with Deep Learning. (arXiv:2101.09624v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Park_T/0/1/0/all/0/1">Tae Jin Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1">Naoyuki Kanda</a>, <a href="http://arxiv.org/find/eess/1/au:+Dimitriadis_D/0/1/0/all/0/1">Dimitrios Dimitriadis</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_K/0/1/0/all/0/1">Kyu J. Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/eess/1/au:+Narayanan_S/0/1/0/all/0/1">Shrikanth Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09624">
                                    <div class="article-summary-box-inner">
                                        <span>Speaker diarization is a task to label audio or video recordings with classes
that correspond to speaker identity, or in short, a task to identify &quot;who spoke
when&quot;. In the early years, speaker diarization algorithms were developed for
speech recognition on multispeaker audio recordings to enable speaker adaptive
processing. These algorithms also gained their own value as a standalone
application over time to provide speaker-specific metainformation for
downstream tasks such as audio retrieval. More recently, with the emergence of
deep learning technology, which has driven revolutionary changes in research
and practices across speech application domains, rapid advancements have been
made for speaker diarization. In this paper, we review not only the historical
development of speaker diarization technology but also the recent advancements
in neural speaker diarization approaches. Furthermore, we discuss how speaker
diarization systems have been integrated with speech recognition applications
and how the recent surge of deep learning is leading the way of jointly
modeling these two components to be complementary to each other. By considering
such exciting technical trends, we believe that this paper is a valuable
contribution to the community to provide a survey work by consolidating the
recent developments with neural methods and thus facilitating further progress
toward a more efficient speaker diarization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training. (arXiv:2106.10835v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haochen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1">Jian Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhigang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yueting Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10835">
                                    <div class="article-summary-box-inner">
                                        <span>With recent advances in distantly supervised (DS) relation extraction (RE),
considerable attention is attracted to leverage multi-instance learning (MIL)
to distill high-quality supervision from the noisy DS. Here, we go beyond label
noise and identify the key bottleneck of DS-MIL to be its low data utilization:
as high-quality supervision being refined by MIL, MIL abandons a large amount
of training instances, which leads to a low data utilization and hinders model
training from having abundant supervision. In this paper, we propose
collaborative adversarial training to improve the data utilization, which
coordinates virtual adversarial training (VAT) and adversarial training (AT) at
different levels. Specifically, since VAT is label-free, we employ the
instance-level VAT to recycle instances abandoned by MIL. Besides, we deploy AT
at the bag-level to unleash the full potential of the high-quality supervision
got by MIL. Our proposed method brings consistent improvements (~ 5 absolute
AUC score) to the previous state of the art, which verifies the importance of
the data utilization issue and the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-grained Fact Verification with Kernel Graph Attention Network. (arXiv:1910.09796v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chenyan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.09796">
                                    <div class="article-summary-box-inner">
                                        <span>Fact Verification requires fine-grained natural language inference capability
that finds subtle clues to identify the syntactical and semantically correct
but not well-supported claims. This paper presents Kernel Graph Attention
Network (KGAT), which conducts more fine-grained fact verification with
kernel-based attentions. Given a claim and a set of potential evidence
sentences that form an evidence graph, KGAT introduces node kernels, which
better measure the importance of the evidence node, and edge kernels, which
conduct fine-grained evidence propagation in the graph, into Graph Attention
Networks for more accurate fact verification. KGAT achieves a 70.38% FEVER
score and significantly outperforms existing fact verification models on FEVER,
a large-scale benchmark for fact verification. Our analyses illustrate that,
compared to dot-product attentions, the kernel-based attention concentrates
more on relevant evidence sentences and meaningful clues in the evidence graph,
which is the main source of KGAT&#x27;s effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related Domains. (arXiv:2106.02792v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yudong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1">Smaranda Muresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02792">
                                    <div class="article-summary-box-inner">
                                        <span>Social media has become a valuable resource for the study of suicidal
ideation and the assessment of suicide risk. Among social media platforms,
Reddit has emerged as the most promising one due to its anonymity and its focus
on topic-based communities (subreddits) that can be indicative of someone&#x27;s
state of mind or interest regarding mental health disorders such as
r/SuicideWatch, r/Anxiety, r/depression. A challenge for previous work on
suicide risk assessment has been the small amount of labeled data. We propose
an empirical investigation into several classes of weakly-supervised
approaches, and show that using pseudo-labeling based on related issues around
mental health (e.g., anxiety, depression) helps improve model performance for
suicide risk assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Institutional Grammar 2.0 Codebook. (arXiv:2008.08937v3 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frantz_C/0/1/0/all/0/1">Christopher K. Frantz</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddiki_S/0/1/0/all/0/1">Saba N. Siddiki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08937">
                                    <div class="article-summary-box-inner">
                                        <span>The Grammar of Institutions, or Institutional Grammar, is an established
approach to encode policy information in terms of institutional statements
based on a set of pre-defined syntactic components. This codebook provides
coding guidelines for a revised version of the Institutional Grammar, the
Institutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at
facilitating the encoding of policy to meet varying analytical objectives. To
this end, it revises the grammar with respect to comprehensiveness,
flexibility, and specificity by offering multiple levels of expressiveness (IG
Core, IG Extended, IG Logico). In addition to the encoding of regulative
statements, it further introduces the encoding of constitutive institutional
statements, as well as statements that exhibit both constitutive and regulative
characteristics. Introducing those aspects, the codebook initially covers
fundamental concepts of IG 2.0, before providing an overview of pre-coding
steps relevant for document preparation. Detailed coding guidelines are
provided for both regulative and constitutive statements across all levels of
expressiveness, along with the encoding guidelines for statements of mixed form
-- hybrid and polymorphic institutional statements. The document further
provides an overview of taxonomies used in the encoding process and referred to
throughout the codebook. The codebook concludes with a summary and discussion
of relevant considerations to facilitate the coding process. An initial
Reader&#x27;s Guide helps the reader tailor the content to her interest.

Note that this codebook specifically focuses on operational aspects of IG 2.0
in the context of policy coding. Links to additional resources such as the
underlying scientific literature (that offers a comprehensive treatment of the
underlying theoretical concepts) are referred to in the concluding section of
the codebook.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inducing Language-Agnostic Multilingual Representations. (arXiv:2008.09112v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>, <a href="http://arxiv.org/find/cs/1/au:+Bjerva_J/0/1/0/all/0/1">Johannes Bjerva</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09112">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-lingual representations have the potential to make NLP techniques
available to the vast majority of languages in the world. However, they
currently require large pretraining corpora or access to typologically similar
languages. In this work, we address these obstacles by removing language
identity signals from multilingual embeddings. We examine three approaches for
this: (i) re-aligning the vector spaces of target languages (all together) to a
pivot source language; (ii) removing language-specific means and variances,
which yields better discriminativeness of embeddings as a by-product; and (iii)
increasing input similarity across languages by removing morphological
contractions and sentence reordering. We evaluate on XNLI and reference-free MT
across 19 typologically diverse languages. Our findings expose the limitations
of these approaches -- unlike vector normalization, vector space re-alignment
and text normalization do not achieve consistent gains across encoders and
languages. Due to the approaches&#x27; additive effects, their combination decreases
the cross-lingual transfer gap by 8.9 points (m-BERT) and 18.2 points (XLM-R)
on average across all tasks and languages, however. Our code and models are
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Visual Layout Structures for Scientific Text Classification. (arXiv:2106.00676v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zejiang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lucy Lu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1">Bailey Kuehl</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel S. Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1">Doug Downey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00676">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying the core textual components of a scientific paper-title, author,
body text, etc.-is a critical first step in automated scientific document
understanding. Previous work has shown how using elementary layout information,
i.e., each token&#x27;s 2D position on the page, leads to more accurate
classification. We introduce new methods for incorporating VIsual LAyout (VILA)
structures, e.g., the grouping of page texts into text lines or text blocks,
into language models to further improve performance. We show that the I-VILA
approach, which simply adds special tokens denoting the boundaries of layout
structures into model inputs, can lead to 1.9% Macro F1 improvements for token
classification. Moreover, we design a hierarchical model, H-VILA, that encodes
the text based on layout structures and record an up-to 47% inference time
reduction with less than 1.5% Macro F1 loss for the text classification models.
Experiments are conducted on a newly curated evaluation suite, S2-VLUE, with a
novel metric measuring classification uniformity within visual groups and a new
dataset of gold annotations covering papers from 19 scientific disciplines.
Pre-trained weights, benchmark datasets, and source code will be available at
https://github.com/allenai/VILA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of MRR and NDCG models for Visual Dialog. (arXiv:2104.07511v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1">Idan Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07511">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing an AI agent that can converse in human language and understand
visual content is challenging. Generation metrics, such as BLEU scores favor
correct syntax over semantics. Hence a discriminative approach is often used,
where an agent ranks a set of candidate options. The mean reciprocal rank (MRR)
metric evaluates the model performance by taking into account the rank of a
single human-derived answer. This approach, however, raises a new challenge:
the ambiguity and synonymy of answers, for instance, semantic equivalence
(e.g., &#x60;yeah&#x27; and &#x60;yes&#x27;). To address this, the normalized discounted cumulative
gain (NDCG) metric has been used to capture the relevance of all the correct
answers via dense annotations. However, the NDCG metric favors the usually
applicable uncertain answers such as &#x60;I don&#x27;t know. Crafting a model that
excels on both MRR and NDCG metrics is challenging. Ideally, an AI agent should
answer a human-like reply and validate the correctness of any answer. To
address this issue, we describe a two-step non-parametric ranking approach that
can merge strong MRR and NDCG models. Using our approach, we manage to keep
most MRR state-of-the-art performance (70.41% vs. 71.24%) and the NDCG
state-of-the-art performance (72.16% vs. 75.35%). Moreover, our approach won
the recent Visual Dialog 2020 challenge. Source code is available at
https://github.com/idansc/mrr-ndcg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Brief Study on the Effects of Training Generative Dialogue Models with a Semantic loss. (arXiv:2106.10619v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelsalam_M/0/1/0/all/0/1">Mohamed Abdelsalam</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10619">
                                    <div class="article-summary-box-inner">
                                        <span>Neural models trained for next utterance generation in dialogue task learn to
mimic the n-gram sequences in the training set with training objectives like
negative log-likelihood (NLL) or cross-entropy. Such commonly used training
objectives do not foster generating alternate responses to a context. But, the
effects of minimizing an alternate training objective that fosters a model to
generate alternate response and score it on semantic similarity has not been
well studied. We hypothesize that a language generation model can improve on
its diversity by learning to generate alternate text during training and
minimizing a semantic loss as an auxiliary objective. We explore this idea on
two different sized data sets on the task of next utterance generation in goal
oriented dialogues. We make two observations (1) minimizing a semantic
objective improved diversity in responses in the smaller data set (Frames) but
only as-good-as minimizing the NLL in the larger data set (MultiWoZ) (2) large
language model embeddings can be more useful as a semantic loss objective than
as initialization for token embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUPERB: Speech processing Universal PERformance Benchmark. (arXiv:2105.01051v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shu-wen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_P/0/1/0/all/0/1">Po-Han Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Sung Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Cheng-I Jeff Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1">Kushal Lakhotia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yist Y. Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andy T. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiatong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xuankai Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guan-Ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tzu-Hsien Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_W/0/1/0/all/0/1">Wei-Cheng Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Ko-tik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Da-Rong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zili Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shuyan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shang-Wen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Abdelrahman Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01051">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning (SSL) has proven vital for advancing research in
natural language processing (NLP) and computer vision (CV). The paradigm
pretrains a shared model on large volumes of unlabeled data and achieves
state-of-the-art (SOTA) for various tasks with minimal adaptation. However, the
speech processing community lacks a similar setup to systematically explore the
paradigm. To bridge this gap, we introduce Speech processing Universal
PERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the
performance of a shared model across a wide range of speech processing tasks
with minimal architecture changes and labeled data. Among multiple usages of
the shared model, we especially focus on extracting the representation learned
from SSL due to its preferable re-usability. We present a simple framework to
solve SUPERB tasks by learning task-specialized lightweight prediction heads on
top of the frozen shared model. Our results demonstrate that the framework is
promising as SSL representations show competitive generalizability and
accessibility across SUPERB tasks. We release SUPERB as a challenge with a
leaderboard and a benchmark toolkit to fuel the research in representation
learning and general speech processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Urdu Caption Generation using Attention based LSTM. (arXiv:2008.01663v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilahi_I/0/1/0/all/0/1">Inaam Ilahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zia_H/0/1/0/all/0/1">Hafiz Muhammad Abdullah Zia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahsan_M/0/1/0/all/0/1">Muhammad Ahtazaz Ahsan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabassam_R/0/1/0/all/0/1">Rauf Tabassam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Armaghan Ahmed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01663">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep learning have created many opportunities to solve
real-world problems that remained unsolved for more than a decade. Automatic
caption generation is a major research field, and the research community has
done a lot of work on it in most common languages like English. Urdu is the
national language of Pakistan and also much spoken and understood in the
sub-continent region of Pakistan-India, and yet no work has been done for Urdu
language caption generation. Our research aims to fill this gap by developing
an attention-based deep learning model using techniques of sequence modeling
specialized for the Urdu language. We have prepared a dataset in the Urdu
language by translating a subset of the &quot;Flickr8k&quot; dataset containing 700 &#x27;man&#x27;
images. We evaluate our proposed technique on this dataset and show that it can
achieve a BLEU score of 0.83 in the Urdu language. We improve on the previous
state-of-the-art by using better CNN architectures and optimization techniques.
Furthermore, we provide a discussion on how the generated captions can be made
correct grammar-wise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech2Phone: A Novel and Efficient Method for Training Speaker Recognition Models. (arXiv:2002.11213v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Casanova_E/0/1/0/all/0/1">Edresson Casanova</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1">Arnaldo Candido Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Shulby_C/0/1/0/all/0/1">Christopher Shulby</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1">Frederico Santos de Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Gris_L/0/1/0/all/0/1">Lucas Rafael Stefanel Gris</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1">Hamilton Pereira da Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Aluisio_S/0/1/0/all/0/1">Sandra Maria Aluisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1">Moacir Antonelli Ponti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11213">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present an efficient method for training models for speaker
recognition using small or under-resourced datasets. This method requires less
data than other SOTA (State-Of-The-Art) methods, e.g. the Angular Prototypical
and GE2E loss functions, while achieving similar results to those methods. This
is done using the knowledge of the reconstruction of a phoneme in the speaker&#x27;s
voice. For this purpose, a new dataset was built, composed of 40 male speakers,
who read sentences in Portuguese, totaling approximately 3h. We compare the
three best architectures trained using our method to select the best one, which
is the one with a shallow architecture. Then, we compared this model with the
SOTA method for the speaker recognition task: the Fast ResNet-34 trained with
approximately 2,000 hours, using the loss functions Angular Prototypical and
GE2E. Three experiments were carried out with datasets in different languages.
Among these three experiments, our model achieved the second best result in two
experiments and the best result in one of them. This highlights the importance
of our method, which proved to be a great competitor to SOTA speaker
recognition models, with 500x less data and a simpler approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Subverting the Jewtocracy&quot;: Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v3 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1">Mohit Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Pailla_D/0/1/0/all/0/1">Dheeraj Pailla</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1">Himanshu Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchawala_A/0/1/0/all/0/1">Aadilmehdi Sanchawala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Manish Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1">Manish Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1">Ponnurangam Kumaraguru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05947">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential rise of online social media has enabled the creation,
distribution, and consumption of information at an unprecedented rate. However,
it has also led to the burgeoning of various forms of online abuse. Increasing
cases of online antisemitism have become one of the major concerns because of
its socio-political consequences. Unlike other major forms of online abuse like
racism, sexism, etc., online antisemitism has not been studied much from a
machine learning perspective. To the best of our knowledge, we present the
first work in the direction of automated multimodal detection of online
antisemitism. The task poses multiple challenges that include extracting
signals across multiple modalities, contextual references, and handling
multiple aspects of antisemitism. Unfortunately, there does not exist any
publicly available benchmark corpus for this critical task. Hence, we collect
and label two datasets with 3,102 and 3,509 social media posts from Twitter and
Gab respectively. Further, we present a multimodal deep learning system that
detects the presence of antisemitic content and its specific antisemitism
category using text and images from posts. We perform an extensive set of
experiments on the two datasets to evaluate the efficacy of the proposed
system. Finally, we also present a qualitative analysis of our study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Robustness Improve Fairness? Approaching Fairness with Word Substitution Robustness Methods for Text Classification. (arXiv:2106.10826v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1">Yada Pruksachatkun</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1">Satyapriya Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamala_J/0/1/0/all/0/1">Jwala Dhamala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Rahul Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10826">
                                    <div class="article-summary-box-inner">
                                        <span>Existing bias mitigation methods to reduce disparities in model outcomes
across cohorts have focused on data augmentation, debiasing model embeddings,
or adding fairness-based optimization objectives during training. Separately,
certified word substitution robustness methods have been developed to decrease
the impact of spurious features and synonym substitutions on model predictions.
While their end goals are different, they both aim to encourage models to make
the same prediction for certain changes in the input. In this paper, we
investigate the utility of certified word substitution robustness methods to
improve equality of odds and equality of opportunity on multiple text
classification tasks. We observe that certified robustness methods improve
fairness, and using both robustness and bias mitigation methods in training
results in an improvement in both fronts</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Dialog Systems for Negotiation with Personality Modeling. (arXiv:2010.09954v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Runzhe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1">Karthik Narasimhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09954">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the ability to model and infer personality types of
opponents, predict their responses, and use this information to adapt a dialog
agent&#x27;s high-level strategy in negotiation tasks. Inspired by the idea of
incorporating a theory of mind (ToM) into machines, we introduce a
probabilistic formulation to encapsulate the opponent&#x27;s personality type during
both learning and inference. We test our approach on the CraigslistBargain
dataset and show that our method using ToM inference achieves a 20% higher
dialog agreement rate compared to baselines on a mixed population of opponents.
We also find that our model displays diverse negotiation behavior with
different types of opponents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialogue Relation Extraction with Document-level Heterogeneous Graph Attention Networks. (arXiv:2009.05092v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1">Pengfei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05092">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue relation extraction (DRE) aims to detect the relation between two
entities mentioned in a multi-party dialogue. It plays an important role in
constructing knowledge graphs from conversational data increasingly abundant on
the internet and facilitating intelligent dialogue system development. The
prior methods of DRE do not meaningfully leverage speaker information-they just
prepend the utterances with the respective speaker names. Thus, they fail to
model the crucial inter-speaker relations that may give additional context to
relevant argument entities through pronouns and triggers. We, however, present
a graph attention network-based method for DRE where a graph, that contains
meaningfully connected speaker, entity, entity-type, and utterance nodes, is
constructed. This graph is fed to a graph attention network for context
propagation among relevant nodes, which effectively captures the dialogue
context. We empirically show that this graph-based approach quite effectively
captures the relations between different entity pairs in a dialogue as it
outperforms the state-of-the-art approaches by a significant margin on the
benchmark dataset DialogRE. Our code is released at:
https://github.com/declare-lab/dialog-HGAT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jacqueline Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1">Adam Vagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09507">
                                    <div class="article-summary-box-inner">
                                        <span>Text classifiers are at the core of many NLP applications and use a variety
of algorithmic approaches and software. This paper introduces infrastructure
and methodologies for text classifiers based on large-scale regular
expressions. In particular, we describe how Facebook determines if a given
piece of text - anything from a hashtag to a post - belongs to a narrow topic
such as COVID-19. To fully define a topic and evaluate classifier performance
we employ human-guided iterations of keyword discovery, but do not require
labeled data. For COVID-19, we build two sets of regular expressions: (1) for
66 languages, with 99% precision and recall &gt;50%, (2) for the 11 most common
languages, with precision &gt;90% and recall &gt;90%. Regular expressions enable
low-latency queries from multiple platforms. Response to challenges like
COVID-19 is fast and so are revisions. Comparisons to a DNN classifier show
explainable results, higher precision and recall, and less overfitting. Our
learnings can be applied to other narrow-topic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and Affective Labels. (arXiv:2007.04626v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbado_A/0/1/0/all/0/1">Alberto Barbado</a>, <a href="http://arxiv.org/find/cs/1/au:+Fresno_V/0/1/0/all/0/1">V&#xed;ctor Fresno</a>, <a href="http://arxiv.org/find/cs/1/au:+Riesco_A/0/1/0/all/0/1">&#xc1;ngeles Manjarr&#xe9;s Riesco</a>, <a href="http://arxiv.org/find/cs/1/au:+Ros_S/0/1/0/all/0/1">Salvador Ros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04626">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, there are many applications of text mining over corpora from
different languages. However, most of them are based on texts in prose, lacking
applications that work with poetry texts. An example of an application of text
mining in poetry is the usage of features derived from their individual words
in order to capture the lexical, sublexical and interlexical meaning, and infer
the General Affective Meaning (GAM) of the text. However, even though this
proposal has been proved as useful for poetry in some languages, there is a
lack of studies for both Spanish poetry and for highly-structured poetic
compositions such as sonnets. This article presents a study over an annotated
corpus of Spanish sonnets, in order to analyse if it is possible to build
features from their individual words for predicting their GAM. The purpose of
this is to model sonnets at an affective level. The article also analyses the
relationship between the GAM of the sonnets and the content itself. For this,
we consider the content from a psychological perspective, identifying with tags
when a sonnet is related to a specific term. Then, we study how GAM changes
according to each of those psychological terms.

The corpus used contains 274 Spanish sonnets from authors of different
centuries, from 15th to 19th. This corpus was annotated by different domain
experts. The experts annotated the poems with affective and lexico-semantic
features, as well as with domain concepts that belong to psychology. Thanks to
this, the corpus of sonnets can be used in different applications, such as
poetry recommender systems, personality text mining studies of the authors, or
the usage of poetry for therapeutic purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoreGen: Contextualized Code Representation Learning for Commit Message Generation. (arXiv:2007.06934v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Lun Yiu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Cuiyun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhicong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1">Wai Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06934">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic generation of high-quality commit messages for code commits can
substantially facilitate software developers&#x27; works and coordination. However,
the semantic gap between source code and natural language poses a major
challenge for the task. Several studies have been proposed to alleviate the
challenge but none explicitly involves code contextual information during
commit message generation. Specifically, existing research adopts static
embedding for code tokens, which maps a token to the same vector regardless of
its context. In this paper, we propose a novel Contextualized code
representation learning strategy for commit message Generation (CoreGen).
CoreGen first learns contextualized code representations which exploit the
contextual information behind code commit sequences. The learned
representations of code commits built upon Transformer are then fine-tuned for
downstream commit message generation. Experiments on the benchmark dataset
demonstrate the superior effectiveness of our model over the baseline models
with at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also
highlight the future opportunities in training contextualized code
representations on larger code corpus as a solution to low-resource tasks and
adapting the contextualized code representation framework to other code-to-text
generation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformers for Headline Selection for Russian News Clusters. (arXiv:2106.10487v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voropaev_P/0/1/0/all/0/1">Pavel Voropaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sopilnyak_O/0/1/0/all/0/1">Olga Sopilnyak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10487">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore various multilingual and Russian pre-trained
transformer-based models for the Dialogue Evaluation 2021 shared task on
headline selection. Our experiments show that the combined approach is superior
to individual multilingual and monolingual models. We present an analysis of a
number of ways to obtain sentence embeddings and learn a ranking model on top
of them. We achieve the result of 87.28% and 86.60% accuracy for the public and
private test sets respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calliar: An Online Handwritten Dataset for Arabic Calligraphy. (arXiv:2106.10745v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alyafeai_Z/0/1/0/all/0/1">Zaid Alyafeai</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_shaibani_M/0/1/0/all/0/1">Maged S. Al-shaibani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaleb_M/0/1/0/all/0/1">Mustafa Ghaleb</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Wajih_Y/0/1/0/all/0/1">Yousif Ahmed Al-Wajih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10745">
                                    <div class="article-summary-box-inner">
                                        <span>Calligraphy is an essential part of the Arabic heritage and culture. It has
been used in the past for the decoration of houses and mosques. Usually, such
calligraphy is designed manually by experts with aesthetic insights. In the
past few years, there has been a considerable effort to digitize such type of
art by either taking a photo of decorated buildings or drawing them using
digital devices. The latter is considered an online form where the drawing is
tracked by recording the apparatus movement, an electronic pen for instance, on
a screen. In the literature, there are many offline datasets collected with a
diversity of Arabic styles for calligraphy. However, there is no available
online dataset for Arabic calligraphy. In this paper, we illustrate our
approach for the collection and annotation of an online dataset for Arabic
calligraphy called Calliar that consists of 2,500 sentences. Calliar is
annotated for stroke, character, word and sentence level prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROPE: Reading Order Equivariant Positional Encoding for Graph-based Document Information Extraction. (arXiv:2106.10786v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chun-Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Renshen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1">Yasuhisa Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1">Siyang Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Popat_A/0/1/0/all/0/1">Ashok Popat</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1">Tomas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10786">
                                    <div class="article-summary-box-inner">
                                        <span>Natural reading orders of words are crucial for information extraction from
form-like documents. Despite recent advances in Graph Convolutional Networks
(GCNs) on modeling spatial layout patterns of documents, they have limited
ability to capture reading orders of given word-level node representations in a
graph. We propose Reading Order Equivariant Positional Encoding (ROPE), a new
positional encoding technique designed to apprehend the sequential presentation
of words in documents. ROPE generates unique reading order codes for
neighboring words relative to the target word given a word-level graph
connectivity. We study two fundamental document entity extraction tasks
including word labeling and word grouping on the public FUNSD dataset and a
large-scale payment dataset. We show that ROPE consistently improves existing
GCNs with a margin up to 8.4% F1-score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CPM-2: Large-scale Cost-effective Pre-trained Language Models. (arXiv:2106.10715v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuxian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shengqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaojun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhenbo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Fanchao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1">Jian Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_P/0/1/0/all/0/1">Pei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yanzheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1">Guoyang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhixing Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wentao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoyan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10715">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the size of pre-trained language models (PLMs) has grown by
leaps and bounds. However, efficiency issues of these large-scale PLMs limit
their utilization in real-world scenarios. We present a suite of cost-effective
techniques for the use of PLMs to deal with the efficiency issues of
pre-training, fine-tuning, and inference. (1) We introduce knowledge
inheritance to accelerate the pre-training process by exploiting existing PLMs
instead of training models from scratch. (2) We explore the best practice of
prompt tuning with large-scale PLMs. Compared with conventional fine-tuning,
prompt tuning significantly reduces the number of task-specific parameters. (3)
We implement a new inference toolkit, namely InfMoE, for using large-scale PLMs
with limited computational resources. Based on our cost-effective pipeline, we
pre-train two models: an encoder-decoder bilingual model with 11 billion
parameters (CPM-2) and its corresponding MoE version with 198 billion
parameters. In our experiments, we compare CPM-2 with mT5 on downstream tasks.
Experimental results show that CPM-2 has excellent general language
intelligence. Moreover, we validate the efficiency of InfMoE when conducting
inference of large-scale models having tens of billions of parameters on a
single GPU. All source code and model parameters are available at
https://github.com/TsinghuaAI/CPM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges in Translation of Emotions in Multilingual User-Generated Content: Twitter as a Case Study. (arXiv:2106.10719v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saadany_H/0/1/0/all/0/1">Hadeel Saadany</a>, <a href="http://arxiv.org/find/cs/1/au:+Orasan_C/0/1/0/all/0/1">Constantin Orasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Quintana_R/0/1/0/all/0/1">Rocio Caro Quintana</a>, <a href="http://arxiv.org/find/cs/1/au:+Carmo_F/0/1/0/all/0/1">Felix do Carmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zilio_L/0/1/0/all/0/1">Leonardo Zilio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10719">
                                    <div class="article-summary-box-inner">
                                        <span>Although emotions are universal concepts, transferring the different shades
of emotion from one language to another may not always be straightforward for
human translators, let alone for machine translation systems. Moreover, the
cognitive states are established by verbal explanations of experience which is
shaped by both the verbal and cultural contexts. There are a number of verbal
contexts where expression of emotions constitutes the pivotal component of the
message. This is particularly true for User-Generated Content (UGC) which can
be in the form of a review of a product or a service, a tweet, or a social
media post. Recently, it has become common practice for multilingual websites
such as Twitter to provide an automatic translation of UGC to reach out to
their linguistically diverse users. In such scenarios, the process of
translating the user&#x27;s emotion is entirely automatic with no human
intervention, neither for post-editing nor for accuracy checking. In this
research, we assess whether automatic translation tools can be a successful
real-life utility in transferring emotion in user-generated multilingual data
such as tweets. We show that there are linguistic phenomena specific of Twitter
data that pose a challenge in translation of emotions in different languages.
We summarise these challenges in a list of linguistic features and show how
frequent these features are in different language pairs. We also assess the
capacity of commonly used methods for evaluating the performance of an MT
system with respect to the preservation of emotion in the source text.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Aware Legal Citation Recommendation using Deep Learning. (arXiv:2106.10776v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zihan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_C/0/1/0/all/0/1">Charles Low</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_M/0/1/0/all/0/1">Mengqiu Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Krass_M/0/1/0/all/0/1">Mark S. Krass</a>, <a href="http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1">Matthias Grabmair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10776">
                                    <div class="article-summary-box-inner">
                                        <span>Lawyers and judges spend a large amount of time researching the proper legal
authority to cite while drafting decisions. In this paper, we develop a
citation recommendation tool that can help improve efficiency in the process of
opinion drafting. We train four types of machine learning models, including a
citation-list based method (collaborative filtering) and three context-based
methods (text similarity, BiLSTM and RoBERTa classifiers). Our experiments show
that leveraging local textual context improves recommendation, and that deep
neural models achieve decent performance. We show that non-deep text-based
methods benefit from access to structured case metadata, but deep models only
benefit from such access when predicting from context of insufficient length.
We also find that, even after extensive training, RoBERTa does not outperform a
recurrent neural model, despite its benefits of pretraining. Our behavior
analysis of the RoBERTa model further shows that predictive performance is
stable across time and citation classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid approach to detecting symptoms of depression in social media entries. (arXiv:2106.10485v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolk_A/0/1/0/all/0/1">Agnieszka Wo&#x142;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Chlasta_K/0/1/0/all/0/1">Karol Chlasta</a>, <a href="http://arxiv.org/find/cs/1/au:+Holas_P/0/1/0/all/0/1">Pawe&#x142; Holas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10485">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment and lexical analyses are widely used to detect depression or
anxiety disorders. It has been documented that there are significant
differences in the language used by a person with emotional disorders in
comparison to a healthy individual. Still, the effectiveness of these lexical
approaches could be improved further because the current analysis focuses on
what the social media entries are about, and not how they are written. In this
study, we focus on aspects in which these short texts are similar to each
other, and how they were created. We present an innovative approach to the
depression screening problem by applying Collgram analysis, which is a known
effective method of obtaining linguistic information from texts. We compare
these results with sentiment analysis based on the BERT architecture. Finally,
we create a hybrid model achieving a diagnostic accuracy of 71%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Condense-then-Select Strategy for Text Summarization. (arXiv:2106.10468v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1">Hou Pong Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10468">
                                    <div class="article-summary-box-inner">
                                        <span>Select-then-compress is a popular hybrid, framework for text summarization
due to its high efficiency. This framework first selects salient sentences and
then independently condenses each of the selected sentences into a concise
version. However, compressing sentences separately ignores the context
information of the document, and is therefore prone to delete salient
information. To address this limitation, we propose a novel
condense-then-select framework for text summarization. Our framework first
concurrently condenses each document sentence. Original document sentences and
their compressed versions then become the candidates for extraction. Finally,
an extractor utilizes the context information of the document to select
candidates and assembles them into a summary. If salient information is deleted
during condensing, the extractor can select an original sentence to retain the
information. Thus, our framework helps to avoid the loss of salient
information, while preserving the high efficiency of sentence-level
compression. Experiment results on the CNN/DailyMail, DUC-2002, and Pubmed
datasets demonstrate that our framework outperforms the select-then-compress
framework and other strong baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JointGT: Graph-Text Joint Representation Learning for Text Generation from Knowledge Graphs. (arXiv:2106.10502v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_P/0/1/0/all/0/1">Pei Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Haozhe Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Ran_Y/0/1/0/all/0/1">Yu Ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1">Xin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Linfeng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoyan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10502">
                                    <div class="article-summary-box-inner">
                                        <span>Existing pre-trained models for knowledge-graph-to-text (KG-to-text)
generation simply fine-tune text-to-text pre-trained models such as BART or T5
on KG-to-text datasets, which largely ignore the graph structure during
encoding and lack elaborate pre-training tasks to explicitly model graph-text
alignments. To tackle these problems, we propose a graph-text joint
representation learning model called JointGT. During encoding, we devise a
structure-aware semantic aggregation module which is plugged into each
Transformer layer to preserve the graph structure. Furthermore, we propose
three new pre-training tasks to explicitly enhance the graph-text alignment
including respective text / graph reconstruction, and graph-text alignment in
the embedding space via Optimal Transport. Experiments show that JointGT
obtains new state-of-the-art performance on various KG-to-text datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TweeNLP: A Twitter Exploration Portal for Natural Language Processing. (arXiv:2106.10512v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1">Viraj Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shruti Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10512">
                                    <div class="article-summary-box-inner">
                                        <span>We present TweeNLP, a one-stop portal that organizes Twitter&#x27;s natural
language processing (NLP) data and builds a visualization and exploration
platform. It curates 19,395 tweets (as of April 2021) from various NLP
conferences and general NLP discussions. It supports multiple features such as
TweetExplorer to explore tweets by topics, visualize insights from Twitter
activity throughout the organization cycle of conferences, discover popular
research papers and researchers. It also builds a timeline of conference and
workshop submission deadlines. We envision TweeNLP to function as a collective
memory unit for the NLP community by integrating the tweets pertaining to
research papers with the NLPExplorer scientific literature search engine. The
current system is hosted at this http URL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Compositional Generalization in Classification Tasks via Structure Annotations. (arXiv:2106.10434v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1">Joshua Ainslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10434">
                                    <div class="article-summary-box-inner">
                                        <span>Compositional generalization is the ability to generalize systematically to a
new data distribution by combining known components. Although humans seem to
have a great ability to generalize compositionally, state-of-the-art neural
models struggle to do so. In this work, we study compositional generalization
in classification tasks and present two main contributions. First, we study
ways to convert a natural language sequence-to-sequence dataset to a
classification dataset that also requires compositional generalization. Second,
we show that providing structural hints (specifically, providing parse trees
and entity links as attention masks for a Transformer model) helps
compositional generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Question Generation with Commonsense Knowledge. (arXiv:2106.10454v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xin Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dawei Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yunfang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10454">
                                    <div class="article-summary-box-inner">
                                        <span>Question generation (QG) is to generate natural and grammatical questions
that can be answered by a specific answer for a given context. Previous
sequence-to-sequence models suffer from a problem that asking high-quality
questions requires commonsense knowledge as backgrounds, which in most cases
can not be learned directly from training data, resulting in unsatisfactory
questions deprived of knowledge. In this paper, we propose a multi-task
learning framework to introduce commonsense knowledge into question generation
process. We first retrieve relevant commonsense knowledge triples from mature
databases and select triples with the conversion information from source
context to question. Based on these informative knowledge triples, we design
two auxiliary tasks to incorporate commonsense knowledge into the main QG
model, where one task is Concept Relation Classification and the other is Tail
Concept Generation. Experimental results on SQuAD show that our proposed
methods are able to noticeably improve the QG performance on both automatic and
human evaluation metrics, demonstrating that incorporating external commonsense
knowledge with multi-task learning can help the model generate human-like and
high-quality questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets. (arXiv:2106.10328v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Solaiman_I/0/1/0/all/0/1">Irene Solaiman</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Dennison_C/0/1/0/all/0/1">Christy Dennison</a> (1) ((1) OpenAI)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10328">
                                    <div class="article-summary-box-inner">
                                        <span>Language models can generate harmful and biased outputs and exhibit
undesirable behavior. We propose a Process for Adapting Language Models to
Society (PALMS) with Values-Targeted Datasets, an iterative process to
significantly change model behavior by crafting and fine-tuning on a dataset
that reflects a predetermined set of target values. We evaluate our process
using three metrics: quantitative metrics with human evaluations that score
output adherence to a target value, and toxicity scoring on outputs; and
qualitative metrics analyzing the most common word associated with a given
social category. Through each iteration, we add additional training dataset
examples based on observed shortcomings from evaluations. PALMS performs
significantly better on all metrics compared to baseline and control models for
a broad range of GPT-3 language model sizes without compromising capability
integrity. We find that the effectiveness of PALMS increases with model size.
We show that significantly adjusting language model behavior is feasible with a
small, hand-curated dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Pair Text Style Transfer on Unbalanced Data. (arXiv:2106.10608v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lundin_J/0/1/0/all/0/1">Jessica Lundin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10608">
                                    <div class="article-summary-box-inner">
                                        <span>Text-style transfer aims to convert text given in one domain into another by
paraphrasing the sentence or substituting the keywords without altering the
content. By necessity, state-of-the-art methods have evolved to accommodate
nonparallel training data, as it is frequently the case there are multiple data
sources of unequal size, with a mixture of labeled and unlabeled sentences.
Moreover, the inherent style defined within each source might be distinct. A
generic bidirectional (e.g., formal $\Leftrightarrow$ informal) style transfer
regardless of different groups may not generalize well to different
applications. In this work, we developed a task adaptive meta-learning
framework that can simultaneously perform a multi-pair text-style transfer
using a single model. The proposed method can adaptively balance the difference
of meta-knowledge across multiple tasks. Results show that our method leads to
better quantitative performance as well as coherent style variations. Common
challenges of unbalanced data and mismatched domains are handled well by this
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pay Better Attention to Attention: Head Selection in Multilingual and Multi-Domain Sequence Modeling. (arXiv:2106.10840v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1">Hongyu Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yun Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1">Juan Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xian Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10840">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-head attention has each of the attention heads collect salient
information from different parts of an input sequence, making it a powerful
mechanism for sequence modeling. Multilingual and multi-domain learning are
common scenarios for sequence modeling, where the key challenge is to maximize
positive transfer and mitigate negative transfer across languages and domains.
In this paper, we find that non-selective attention sharing is sub-optimal for
achieving good generalization across all languages and domains. We further
propose attention sharing strategies to facilitate parameter sharing and
specialization in multilingual and multi-domain sequence modeling. Our approach
automatically learns shared and specialized attention heads for different
languages and domains to mitigate their interference. Evaluated in various
tasks including speech recognition, text-to-text and speech-to-text
translation, the proposed attention sharing strategies consistently bring gains
to sequence models built upon multi-head attention. For speech-to-text
translation, our approach yields an average of $+2.0$ BLEU over $13$ language
directions in multilingual setting and $+2.0$ BLEU over $3$ domains in
multi-domain setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Encoder Representations of Generative Dialogue Models Encode Sufficient Information about the Task ?. (arXiv:2106.10622v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10622">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the next utterance in dialogue is contingent on encoding of users&#x27;
input text to generate appropriate and relevant response in data-driven
approaches. Although the semantic and syntactic quality of the language
generated is evaluated, more often than not, the encoded representation of
input is not evaluated. As the representation of the encoder is essential for
predicting the appropriate response, evaluation of encoder representation is a
challenging yet important problem. In this work, we showcase evaluating the
text generated through human or automatic metrics is not sufficient to
appropriately evaluate soundness of the language understanding of dialogue
models and, to that end, propose a set of probe tasks to evaluate encoder
representation of different language encoders commonly used in dialogue models.
From experiments, we observe that some of the probe tasks are easier and some
are harder for even sophisticated model architectures to learn. And, through
experiments we observe that RNN based architectures have lower performance on
automatic metrics on text generation than transformer model but perform better
than the transformer model on the probe tasks indicating that RNNs might
preserve task information better than the Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Visual Layout Structures for Scientific Text Classification. (arXiv:2106.00676v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zejiang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lucy Lu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1">Bailey Kuehl</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel S. Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1">Doug Downey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00676">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying the core textual components of a scientific paper-title, author,
body text, etc.-is a critical first step in automated scientific document
understanding. Previous work has shown how using elementary layout information,
i.e., each token&#x27;s 2D position on the page, leads to more accurate
classification. We introduce new methods for incorporating VIsual LAyout (VILA)
structures, e.g., the grouping of page texts into text lines or text blocks,
into language models to further improve performance. We show that the I-VILA
approach, which simply adds special tokens denoting the boundaries of layout
structures into model inputs, can lead to 1.9% Macro F1 improvements for token
classification. Moreover, we design a hierarchical model, H-VILA, that encodes
the text based on layout structures and record an up-to 47% inference time
reduction with less than 1.5% Macro F1 loss for the text classification models.
Experiments are conducted on a newly curated evaluation suite, S2-VLUE, with a
novel metric measuring classification uniformity within visual groups and a new
dataset of gold annotations covering papers from 19 scientific disciplines.
Pre-trained weights, benchmark datasets, and source code will be available at
https://github.com/allenai/VILA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of MRR and NDCG models for Visual Dialog. (arXiv:2104.07511v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1">Idan Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07511">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing an AI agent that can converse in human language and understand
visual content is challenging. Generation metrics, such as BLEU scores favor
correct syntax over semantics. Hence a discriminative approach is often used,
where an agent ranks a set of candidate options. The mean reciprocal rank (MRR)
metric evaluates the model performance by taking into account the rank of a
single human-derived answer. This approach, however, raises a new challenge:
the ambiguity and synonymy of answers, for instance, semantic equivalence
(e.g., &#x60;yeah&#x27; and &#x60;yes&#x27;). To address this, the normalized discounted cumulative
gain (NDCG) metric has been used to capture the relevance of all the correct
answers via dense annotations. However, the NDCG metric favors the usually
applicable uncertain answers such as &#x60;I don&#x27;t know. Crafting a model that
excels on both MRR and NDCG metrics is challenging. Ideally, an AI agent should
answer a human-like reply and validate the correctness of any answer. To
address this issue, we describe a two-step non-parametric ranking approach that
can merge strong MRR and NDCG models. Using our approach, we manage to keep
most MRR state-of-the-art performance (70.41% vs. 71.24%) and the NDCG
state-of-the-art performance (72.16% vs. 75.35%). Moreover, our approach won
the recent Visual Dialog 2020 challenge. Source code is available at
https://github.com/idansc/mrr-ndcg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis. (arXiv:2106.07524v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kollias_D/0/1/0/all/0/1">Dimitrios Kollias</a>, <a href="http://arxiv.org/find/eess/1/au:+Arsenos_A/0/1/0/all/0/1">Anastasios Arsenos</a>, <a href="http://arxiv.org/find/eess/1/au:+Soukissian_L/0/1/0/all/0/1">Levon Soukissian</a>, <a href="http://arxiv.org/find/eess/1/au:+Kollias_S/0/1/0/all/0/1">Stefanos Kollias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07524">
                                    <div class="article-summary-box-inner">
                                        <span>Early and reliable COVID-19 diagnosis based on chest 3-D CT scans can assist
medical specialists in vital circumstances. Deep learning methodologies
constitute a main approach for chest CT scan analysis and disease prediction.
However, large annotated databases are necessary for developing deep learning
models that are able to provide COVID-19 diagnosis across various medical
environments in different countries. Due to privacy issues, publicly available
COVID-19 CT datasets are highly difficult to obtain, which hinders the research
and development of AI-enabled diagnosis methods of COVID-19 based on CT scans.
In this paper we present the COV19-CT-DB database which is annotated for
COVID-19, consisting of about 5,000 3-D CT scans, We have split the database in
training, validation and test datasets. The former two datasets can be used for
training and validation of machine learning models, while the latter will be
used for evaluation of the developed models. We also present a deep learning
approach, based on a CNN-RNN network and report its performance on the
COVID19-CT-DB database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization. (arXiv:2103.14862v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1">Fang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xingjia Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhiliang Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhenjun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14862">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised object localization (WSOL) is a challenging problem when
given image category labels but requires to learn object localization models.
Optimizing a convolutional neural network (CNN) for classification tends to
activate local discriminative regions while ignoring complete object extent,
causing the partial activation issue. In this paper, we argue that partial
activation is caused by the intrinsic characteristics of CNN, where the
convolution operations produce local receptive fields and experience difficulty
to capture long-range feature dependency among pixels. We introduce the token
semantic coupled attention map (TS-CAM) to take full advantage of the
self-attention mechanism in visual transformer for long-range dependency
extraction. TS-CAM first splits an image into a sequence of patch tokens for
spatial embedding, which produce attention maps of long-range visual dependency
to avoid partial activation. TS-CAM then re-allocates category-related
semantics for patch tokens, enabling each of them to be aware of object
categories. TS-CAM finally couples the patch tokens with the semantic-agnostic
attention map to achieve semantic-aware localization. Experiments on the
ILSVRC/CUB-200-2011 datasets show that TS-CAM outperforms its CNN-CAM
counterparts by 7.1%/27.1% for WSOL, achieving state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Which Parts Determine the Impression of the Font?. (arXiv:2103.14216v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masaya Ueda</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1">Akisato Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14216">
                                    <div class="article-summary-box-inner">
                                        <span>Various fonts give different impressions, such as legible, rough, and
comic-text.This paper aims to analyze the correlation between the local shapes,
or parts, and the impression of fonts. By focusing on local shapes instead of
the whole letter shape, we can realize letter-shape independent and more
general analysis. The analysis is performed by newly combining SIFT and
DeepSets, to extract an arbitrary number of essential parts from a particular
font and aggregate them to infer the font impressions by nonlinear regression.
Our qualitative and quantitative analyses prove that (1)fonts with similar
parts have similar impressions, (2)many impressions, such as legible and rough,
largely depend on specific parts, (3)several impressions are very irrelevant to
parts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unconstrained Facial Action Unit Detection via Latent Feature Domain. (arXiv:1903.10143v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiwen Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cham_T/0/1/0/all/0/1">Tat-Jen Cham</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.10143">
                                    <div class="article-summary-box-inner">
                                        <span>Facial action unit (AU) detection in the wild is a challenging problem, due
to the unconstrained variability in facial appearances and the lack of accurate
annotations. Most existing methods depend on either impractical labor-intensive
labeling or inaccurate pseudo labels. In this paper, we propose an end-to-end
unconstrained facial AU detection framework based on domain adaptation, which
transfers accurate AU labels from a constrained source domain to an
unconstrained target domain by exploiting labels of AU-related facial
landmarks. Specifically, we map a source image with label and a target image
without label into a latent feature domain by combining source landmark-related
feature with target landmark-free feature. Due to the combination of source
AU-related information and target AU-free information, the latent feature
domain with transferred source label can be learned by maximizing the
target-domain AU detection performance. Moreover, we introduce a novel landmark
adversarial loss to disentangle the landmark-free feature from the
landmark-related feature by treating the adversarial learning as a multi-player
minimax game. Our framework can also be naturally extended for use with
target-domain pseudo AU labels. Extensive experiments show that our method
soundly outperforms lower-bounds and upper-bounds of the basic model, as well
as state-of-the-art approaches on the challenging in-the-wild benchmarks. The
code is available at https://github.com/ZhiwenShao/ADLD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trainable Class Prototypes for Few-Shot Learning. (arXiv:2106.10846v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guizhong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10846">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning is a widely used method for few shot learning in which the
quality of prototypes plays a key role in the algorithm. In this paper we
propose the trainable prototypes for distance measure instead of the artificial
ones within the meta-training and task-training framework. Also to avoid the
disadvantages that the episodic meta-training brought, we adopt non-episodic
meta-training based on self-supervised learning. Overall we solve the few-shot
tasks in two phases: meta-training a transferable feature extractor via
self-supervised learning and training the prototypes for metric classification.
In addition, the simple attention mechanism is used in both meta-training and
task-training. Our method achieves state-of-the-art performance in a variety of
established few-shot tasks on the standard few-shot visual classification
dataset, with about 20% increase compared to the available unsupervised
few-shot learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Piano Skills Assessment. (arXiv:2101.04884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parmar_P/0/1/0/all/0/1">Paritosh Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_J/0/1/0/all/0/1">Jaiden Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04884">
                                    <div class="article-summary-box-inner">
                                        <span>Can a computer determine a piano player&#x27;s skill level? Is it preferable to
base this assessment on visual analysis of the player&#x27;s performance or should
we trust our ears over our eyes? Since current CNNs have difficulty processing
long video videos, how can shorter clips be sampled to best reflect the players
skill level? In this work, we collect and release a first-of-its-kind dataset
for multimodal skill assessment focusing on assessing piano player&#x27;s skill
level, answer the asked questions, initiate work in automated evaluation of
piano playing skills and provide baselines for future work. Dataset is
available from: https://github.com/ParitoshParmar/Piano-Skills-Assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed-Privacy Forgetting in Deep Networks. (arXiv:2012.13431v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golatkar_A/0/1/0/all/0/1">Aditya Golatkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1">Alessandro Achille</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1">Avinash Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Polito_M/0/1/0/all/0/1">Marzia Polito</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13431">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the influence of a subset of the training samples can be removed
-- or &quot;forgotten&quot; -- from the weights of a network trained on large-scale image
classification tasks, and we provide strong computable bounds on the amount of
remaining information after forgetting. Inspired by real-world applications of
forgetting techniques, we introduce a novel notion of forgetting in
mixed-privacy setting, where we know that a &quot;core&quot; subset of the training
samples does not need to be forgotten. While this variation of the problem is
conceptually simple, we show that working in this setting significantly
improves the accuracy and guarantees of forgetting methods applied to vision
classification tasks. Moreover, our method allows efficient removal of all
information contained in non-core data by simply setting to zero a subset of
the weights with minimal loss in performance. We achieve these results by
replacing a standard deep network with a suitable linear approximation. With
opportune changes to the network architecture and training procedure, we show
that such linear approximation achieves comparable performance to the original
network and that the forgetting problem becomes quadratic and can be solved
efficiently even for large models. Unlike previous forgetting methods on deep
networks, ours can achieve close to the state-of-the-art accuracy on large
scale vision tasks. In particular, we show that our method allows forgetting
without having to trade off the model accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a Supervised Method without supervision for foreground segmentation. (arXiv:2011.07954v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kassel_L/0/1/0/all/0/1">Levi Kassel</a>, <a href="http://arxiv.org/find/cs/1/au:+Werman_M/0/1/0/all/0/1">Michael Werman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07954">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are a powerful framework for foreground segmentation in video
acquired by static cameras, segmenting moving objects from the background in a
robust way in various challenging scenarios. The premier methods are those
based on supervision requiring a final training stage on a database of tens to
hundreds of manually segmented images from the specific static camera. In this
work, we propose a method to automatically create an &quot;artificial&quot; database that
is sufficient for training the supervised methods so that it performs better
than current unsupervised methods. It is based on combining a weak foreground
segmenter, compared to the supervised method, to extract suitable objects from
the training images and randomly inserting these objects back into a background
image. Test results are shown on the test sequences in CDnet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nuclei Grading of Clear Cell Renal Cell Carcinoma in Histopathological Image by Composite High-Resolution Network. (arXiv:2106.10641v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gao_Z/0/1/0/all/0/1">Zeyu Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1">Jiangbo Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xianli Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Haichuan Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1">Jialun Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chunbao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10641">
                                    <div class="article-summary-box-inner">
                                        <span>The grade of clear cell renal cell carcinoma (ccRCC) is a critical prognostic
factor, making ccRCC nuclei grading a crucial task in RCC pathology analysis.
Computer-aided nuclei grading aims to improve pathologists&#x27; work efficiency
while reducing their misdiagnosis rate by automatically identifying the grades
of tumor nuclei within histopathological images. Such a task requires precisely
segment and accurately classify the nuclei. However, most of the existing
nuclei segmentation and classification methods can not handle the inter-class
similarity property of nuclei grading, thus can not be directly applied to the
ccRCC grading task. In this paper, we propose a Composite High-Resolution
Network for ccRCC nuclei grading. Specifically, we propose a segmentation
network called W-Net that can separate the clustered nuclei. Then, we recast
the fine-grained classification of nuclei to two cross-category classification
tasks, based on two high-resolution feature extractors (HRFEs) which are
proposed for learning these two tasks. The two HRFEs share the same backbone
encoder with W-Net by a composite connection so that meaningful features for
the segmentation task can be inherited for the classification task. Last, a
head-fusion block is applied to generate the predicted label of each nucleus.
Furthermore, we introduce a dataset for ccRCC nuclei grading, containing 1000
image patches with 70945 annotated nuclei. We demonstrate that our proposed
method achieves state-of-the-art performance compared to existing methods on
this large ccRCC grading dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attack to Fool and Explain Deep Networks. (arXiv:2106.10606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalwana_M/0/1/0/all/0/1">Muhammad A. A. K. Jalwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep visual models are susceptible to adversarial perturbations to inputs.
Although these signals are carefully crafted, they still appear noise-like
patterns to humans. This observation has led to the argument that deep visual
representation is misaligned with human perception. We counter-argue by
providing evidence of human-meaningful patterns in adversarial perturbations.
We first propose an attack that fools a network to confuse a whole category of
objects (source class) with a target label. Our attack also limits the
unintended fooling by samples from non-sources classes, thereby circumscribing
human-defined semantic notions for network fooling. We show that the proposed
attack not only leads to the emergence of regular geometric patterns in the
perturbations, but also reveals insightful information about the decision
boundaries of deep models. Exploring this phenomenon further, we alter the
&#x60;adversarial&#x27; objective of our attack to use it as a tool to &#x60;explain&#x27; deep
visual representation. We show that by careful channeling and projection of the
perturbations computed by our method, we can visualize a model&#x27;s understanding
of human-defined semantic notions. Finally, we exploit the explanability
properties of our perturbations to perform image generation, inpainting and
interactive image manipulation by attacking adversarialy robust
&#x60;classifiers&#x27;.In all, our major contribution is a novel pragmatic adversarial
attack that is subsequently transformed into a tool to interpret the visual
models. The article also makes secondary contributions in terms of establishing
the utility of our attack beyond the adversarial objective with multiple
interesting applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Faster R-CNN: Towards Accurate Few-Shot Object Detection with Attentive Feature Alignment. (arXiv:2104.07719v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1">Guangxing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shiyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiawei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yicheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07719">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot object detection (FSOD) aims to detect objects using only few
examples. It&#x27;s critically needed for many practical applications but so far
remains challenging. We propose a meta-learning based few-shot object detection
method by transferring meta-knowledge learned from data-abundant base classes
to data-scarce novel classes. Our method incorporates a coarse-to-fine approach
into the proposal based object detection framework and integrates prototype
based classifiers into both the proposal generation and classification stages.
To improve proposal generation for few-shot novel classes, we propose to learn
a lightweight matching network to measure the similarity between each spatial
position in the query image feature map and spatially-pooled class features,
instead of the traditional object/nonobject classifier, thus generating
category-specific proposals and improving proposal recall for novel classes. To
address the spatial misalignment between generated proposals and few-shot class
examples, we propose a novel attentive feature alignment method, thus improving
the performance of few-shot object detection. Meanwhile we jointly learn a
Faster R-CNN detection head for base classes. Extensive experiments conducted
on multiple FSOD benchmarks show our proposed approach achieves state of the
art results under (incremental) few-shot learning settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge. (arXiv:2012.11696v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dognin_P/0/1/0/all/0/1">Pierre Dognin</a>, <a href="http://arxiv.org/find/cs/1/au:+Melnyk_I/0/1/0/all/0/1">Igor Melnyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1">Inkit Padhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigotti_M/0/1/0/all/0/1">Mattia Rigotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1">Jarret Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/cs/1/au:+Young_R/0/1/0/all/0/1">Richard A. Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Belgodere_B/0/1/0/all/0/1">Brian Belgodere</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11696">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning has recently demonstrated impressive progress largely owing
to the introduction of neural network algorithms trained on curated dataset
like MS-COCO. Often work in this field is motivated by the promise of
deployment of captioning systems in practical applications. However, the
scarcity of data and contexts in many competition datasets renders the utility
of systems trained on these datasets limited as an assistive technology in
real-world settings, such as helping visually impaired people navigate and
accomplish everyday tasks. This gap motivated the introduction of the novel
VizWiz dataset, which consists of images taken by the visually impaired and
captions that have useful, task-oriented information. In an attempt to help the
machine learning computer vision field realize its promise of producing
technologies that have positive social impact, the curators of the VizWiz
dataset host several competitions, including one for image captioning. This
work details the theory and engineering from our winning submission to the 2020
captioning competition. Our work provides a step towards improved assistive
image captioning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Input Gradients Highlight Discriminative Features?. (arXiv:2102.12781v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1">Harshay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1">Praneeth Netrapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12781">
                                    <div class="article-summary-box-inner">
                                        <span>Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,
Smilkov et al., 2017] that provide instance-specific explanations of model
predictions are often based on assumption (A): magnitude of input gradients --
gradients of logits with respect to input -- noisily highlight discriminative
task-relevant features. In this work, we test the validity of assumption (A)
using a three-pronged approach. First, we develop an evaluation framework,
DiffROAR, to test assumption (A) on four image classification benchmarks. Our
results suggest that (i) input gradients of standard models (i.e., trained on
original data) may grossly violate (A), whereas (ii) input gradients of
adversarially robust models satisfy (A). Second, we then introduce BlockMNIST,
an MNIST-based semi-real dataset, that by design encodes a priori knowledge of
discriminative features. Our analysis on BlockMNIST leverages this information
to validate as well as characterize differences between input gradient
attributions of standard and robust models. Finally, we theoretically prove
that our empirical findings hold on a simplified version of the BlockMNIST
dataset. Specifically, we prove that input gradients of standard
one-hidden-layer MLPs trained on this dataset do not highlight
instance-specific signal coordinates, thus grossly violating assumption (A).
Our findings motivate the need to formalize and test common assumptions in
interpretability in a falsifiable manner [Leavitt and Morcos, 2020].
Additionally, we believe that the DiffROAR evaluation framework and
BlockMNIST-based datasets can serve as sanity checks to audit instance-specific
interpretability methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Contrastive Learning for Few-Shot Classification. (arXiv:2012.13831v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouali_Y/0/1/0/all/0/1">Yassine Ouali</a>, <a href="http://arxiv.org/find/cs/1/au:+Hudelot_C/0/1/0/all/0/1">C&#xe9;line Hudelot</a>, <a href="http://arxiv.org/find/cs/1/au:+Tami_M/0/1/0/all/0/1">Myriam Tami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13831">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore contrastive learning for few-shot classification,
in which we propose to use it as an additional auxiliary training objective
acting as a data-dependent regularizer to promote more general and transferable
features. In particular, we present a novel attention-based spatial contrastive
objective to learn locally discriminative and class-agnostic features. As a
result, our approach overcomes some of the limitations of the cross-entropy
loss, such as its excessive discrimination towards seen classes, which reduces
the transferability of features to unseen classes. With extensive experiments,
we show that the proposed method outperforms state-of-the-art approaches,
confirming the importance of learning good and transferable embeddings for
few-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FloorPP-Net: Reconstructing Floor Plans using Point Pillars for Scan-to-BIM. (arXiv:2106.10635v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yijie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Fan Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10635">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a deep learning-based point cloud processing method named
FloorPP-Net for the task of Scan-to-BIM (building information model).
FloorPP-Net first converts the input point cloud of a building story into point
pillars (PP), then predicts the corners and edges to output the floor plan.
Altogether, FloorPP-Net establishes an end-to-end supervised learning framework
for the Scan-to-Floor-Plan (Scan2FP) task. In the 1st International Scan-to-BIM
Challenge held in conjunction with CVPR 2021, FloorPP-Net was ranked the second
runner-up in the floor plan reconstruction track. Future work includes general
edge proposals, 2D plan regularization, and 3D BIM reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Evaluation Metric: Learning to Evaluate Simulated Radar Point Clouds for Virtual Testing of Autonomous Driving. (arXiv:2104.06772v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_A/0/1/0/all/0/1">Anthony Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Max Paul Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Resch_M/0/1/0/all/0/1">Michael Resch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06772">
                                    <div class="article-summary-box-inner">
                                        <span>The usage of environment sensor models for virtual testing is a promising
approach to reduce the testing effort of autonomous driving. However, in order
to deduce any statements regarding the performance of an autonomous driving
function based on simulation, the sensor model has to be validated to determine
the discrepancy between the synthetic and real sensor data. Since a certain
degree of divergence can be assumed to exist, the sufficient level of fidelity
must be determined, which poses a major challenge. In particular, a method for
quantifying the fidelity of a sensor model does not exist and the problem of
defining an appropriate metric remains. In this work, we train a neural network
to distinguish real and simulated radar sensor data with the purpose of
learning the latent features of real radar point clouds. Furthermore, we
propose the classifier&#x27;s confidence score for the &#x60;real radar point cloud&#x27;
class as a metric to determine the degree of fidelity of synthetically
generated radar data. The presented approach is evaluated and it can be
demonstrated that the proposed deep evaluation metric outperforms conventional
metrics in terms of its capability to identify characteristic differences
between real and simulated radar data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighborhood Contrastive Learning for Novel Class Discovery. (arXiv:2106.10731v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fini_E/0/1/0/all/0/1">Enrico Fini</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhankar Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhiming Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1">Elisa Ricci</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10731">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address Novel Class Discovery (NCD), the task of unveiling
new classes in a set of unlabeled samples given a labeled dataset with known
classes. We exploit the peculiarities of NCD to build a new framework, named
Neighborhood Contrastive Learning (NCL), to learn discriminative
representations that are important to clustering performance. Our contribution
is twofold. First, we find that a feature extractor trained on the labeled set
generates representations in which a generic query sample and its neighbors are
likely to share the same class. We exploit this observation to retrieve and
aggregate pseudo-positive pairs with contrastive learning, thus encouraging the
model to learn more discriminative representations. Second, we notice that most
of the instances are easily discriminated by the network, contributing less to
the contrastive loss. To overcome this issue, we propose to generate hard
negatives by mixing labeled and unlabeled samples in the feature space. We
experimentally demonstrate that these two ingredients significantly contribute
to clustering performance and lead our model to outperform state-of-the-art
methods by a large margin (e.g., clustering accuracy +13% on CIFAR-100 and +8%
on ImageNet).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SiamSNN: Siamese Spiking Neural Networks for Energy-Efficient Object Tracking. (arXiv:2003.07584v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yihao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Caihong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianjiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1">Qi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.07584">
                                    <div class="article-summary-box-inner">
                                        <span>Recently spiking neural networks (SNNs), the third-generation of neural
networks has shown remarkable capabilities of energy-efficient computing, which
is a promising alternative for deep neural networks (DNNs) with high energy
consumption. SNNs have reached competitive results compared to DNNs in
relatively simple tasks and small datasets such as image classification and
MNIST/CIFAR, while few studies on more challenging vision tasks on complex
datasets. In this paper, we focus on extending deep SNNs to object tracking, a
more advanced vision task with embedded applications and energy-saving
requirements, and present a spike-based Siamese network called SiamSNN.
Specifically, we propose an optimized hybrid similarity estimation method to
exploit temporal information in the SNNs, and introduce a novel two-status
coding scheme to optimize the temporal distribution of output spike trains for
further improvements. SiamSNN is the first deep SNN tracker that achieves short
latency and low precision loss on the visual object tracking benchmarks
OTB2013/2015, VOT2016/2018, and GOT-10k. Moreover, SiamSNN achieves notably low
energy consumption and real-time on Neuromorphic chip TrueNorth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Libraries: A Deep Learning Framework Designed from Engineers&#x27; Perspectives. (arXiv:2102.06725v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narihira_T/0/1/0/all/0/1">Takuya Narihira</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonsogarcia_J/0/1/0/all/0/1">Javier Alonsogarcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardinaux_F/0/1/0/all/0/1">Fabien Cardinaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayakawa_A/0/1/0/all/0/1">Akio Hayakawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1">Masato Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwaki_K/0/1/0/all/0/1">Kazunori Iwaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemp_T/0/1/0/all/0/1">Thomas Kemp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yoshiyuki Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mauch_L/0/1/0/all/0/1">Lukas Mauch</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakamura_A/0/1/0/all/0/1">Akira Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Obuchi_Y/0/1/0/all/0/1">Yukio Obuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_A/0/1/0/all/0/1">Andrew Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_K/0/1/0/all/0/1">Kenji Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiedmann_S/0/1/0/all/0/1">Stephen Tiedmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Uhlich_S/0/1/0/all/0/1">Stefan Uhlich</a>, <a href="http://arxiv.org/find/cs/1/au:+Yashima_T/0/1/0/all/0/1">Takuya Yashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshiyama_K/0/1/0/all/0/1">Kazuki Yoshiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06725">
                                    <div class="article-summary-box-inner">
                                        <span>While there exist a plethora of deep learning tools and frameworks, the
fast-growing complexity of the field brings new demands and challenges, such as
more flexible network design, speedy computation on distributed setting, and
compatibility between different tools. In this paper, we introduce Neural
Network Libraries (https://nnabla.org), a deep learning framework designed from
engineer&#x27;s perspective, with emphasis on usability and compatibility as its
core design principles. We elaborate on each of our design principles and its
merits, and validate our attempts via experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plant Disease Detection Using Image Processing and Machine Learning. (arXiv:2106.10698v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1">Pranesh Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Karwande_A/0/1/0/all/0/1">Atharva Karwande</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolhe_T/0/1/0/all/0/1">Tejas Kolhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamble_S/0/1/0/all/0/1">Soham Kamble</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Akshay Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyawahare_M/0/1/0/all/0/1">Medha Wyawahare</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10698">
                                    <div class="article-summary-box-inner">
                                        <span>One of the important and tedious task in agricultural practices is the
detection of the disease on crops. It requires huge time as well as skilled
labor. This paper proposes a smart and efficient technique for detection of
crop disease which uses computer vision and machine learning techniques. The
proposed system is able to detect 20 different diseases of 5 common plants with
93% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IsMo-GAN: Adversarial Learning for Monocular Non-Rigid 3D Reconstruction. (arXiv:1904.12144v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shimada_S/0/1/0/all/0/1">Soshi Shimada</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.12144">
                                    <div class="article-summary-box-inner">
                                        <span>The majority of the existing methods for non-rigid 3D surface regression from
monocular 2D images require an object template or point tracks over multiple
frames as an input, and are still far from real-time processing rates. In this
work, we present the Isometry-Aware Monocular Generative Adversarial Network
(IsMo-GAN) - an approach for direct 3D reconstruction from a single image,
trained for the deformation model in an adversarial manner on a light-weight
synthetic dataset. IsMo-GAN reconstructs surfaces from real images under
varying illumination, camera poses, textures and shading at over 250 Hz. In
multiple experiments, it consistently outperforms several approaches in the
reconstruction accuracy, runtime, generalisation to unknown surfaces and
robustness to occlusions. In comparison to the state-of-the-art, we reduce the
reconstruction error by 10-30% including the textureless case and our surfaces
evince fewer artefacts qualitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A non-alternating graph hashing algorithm for large scale image search. (arXiv:2012.13138v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hemati_S/0/1/0/all/0/1">Sobhan Hemati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdizavareh_M/0/1/0/all/0/1">Mohammad Hadi Mehdizavareh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenouri_S/0/1/0/all/0/1">Shojaeddin Chenouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R Tizhoosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13138">
                                    <div class="article-summary-box-inner">
                                        <span>In the era of big data, methods for improving memory and computational
efficiency have become crucial for successful deployment of technologies.
Hashing is one of the most effective approaches to deal with computational
limitations that come with big data. One natural way for formulating this
problem is spectral hashing that directly incorporates affinity to learn binary
codes. However, due to binary constraints, the optimization becomes
intractable. To mitigate this challenge, different relaxation approaches have
been proposed to reduce the computational load of obtaining binary codes and
still attain a good solution. The problem with all existing relaxation methods
is resorting to one or more additional auxiliary variables to attain high
quality binary codes while relaxing the problem. The existence of auxiliary
variables leads to coordinate descent approach which increases the
computational complexity. We argue that introducing these variables is
unnecessary. To this end, we propose a novel relaxed formulation for spectral
hashing that adds no additional variables to the problem. Furthermore, instead
of solving the problem in original space where number of variables is equal to
the data points, we solve the problem in a much smaller space and retrieve the
binary codes from this solution. This trick reduces both the memory and
computational complexity at the same time. We apply two optimization
techniques, namely projected gradient and optimization on manifold, to obtain
the solution. Using comprehensive experiments on four public datasets, we show
that the proposed efficient spectral hashing (ESH) algorithm achieves highly
competitive retrieval performance compared with state of the art at low
complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge, Ridge, and Blob Detection with Symmetric Molecules. (arXiv:1901.09723v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reisenhofer_R/0/1/0/all/0/1">Rafael Reisenhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+King_E/0/1/0/all/0/1">Emily J. King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.09723">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to the detection and characterization of edges,
ridges, and blobs in two-dimensional images which exploits the symmetry
properties of directionally sensitive analyzing functions in multiscale systems
that are constructed in the framework of alpha-molecules. The proposed feature
detectors are inspired by the notion of phase congruency, stable in the
presence of noise, and by definition invariant to changes in contrast. We also
show how the behavior of coefficients corresponding to differently scaled and
oriented analyzing functions can be used to obtain a comprehensive
characterization of the geometry of features in terms of local tangent
directions, widths, and heights. The accuracy and robustness of the proposed
measures are validated and compared to various state-of-the-art algorithms in
extensive numerical experiments in which we consider sets of clean and
distorted synthetic images that are associated with reliable ground truths. To
further demonstrate the applicability, we show how the proposed ridge measure
can be used to detect and characterize blood vessels in digital retinal images
and how the proposed blob measure can be applied to automatically count the
number of cell colonies in a Petri dish.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal learning for Audio-Visual Video Parsing. (arXiv:2104.04598v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lamba_J/0/1/0/all/0/1">Jatin Lamba</a>, <a href="http://arxiv.org/find/cs/1/au:+Abhishek/0/1/0/all/0/1">Abhishek</a>, <a href="http://arxiv.org/find/cs/1/au:+Akula_J/0/1/0/all/0/1">Jayaprakash Akula</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabral_R/0/1/0/all/0/1">Rishabh Dabral</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04598">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel approach to the audio-visual video parsing
(AVVP) task that demarcates events from a video separately for audio and visual
modalities. The proposed parsing approach simultaneously detects the temporal
boundaries in terms of start and end times of such events. We show how AVVP can
benefit from the following techniques geared towards effective cross-modal
learning: (i) adversarial training and skip connections (ii) global context
aware attention and, (iii) self-supervised pretraining using an audio-video
grounding objective to obtain cross-modal audio-video representations. We
present extensive experimental evaluations on the Look, Listen, and Parse (LLP)
dataset and show that we outperform the state-of-the-art Hybrid Attention
Network (HAN) on all five metrics proposed for AVVP. We also present several
ablations to validate the effect of pretraining, global attention and
adversarial training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-Stream Consensus Network: Submission to HACS Challenge 2021 Weakly-Supervised Learning Track. (arXiv:2106.10829v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1">Yuanhao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1">David Doermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Junsong Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10829">
                                    <div class="article-summary-box-inner">
                                        <span>This technical report presents our solution to the HACS Temporal Action
Localization Challenge 2021, Weakly-Supervised Learning Track. The goal of
weakly-supervised temporal action localization is to temporally locate and
classify action of interest in untrimmed videos given only video-level labels.
We adopt the two-stream consensus network (TSCN) as the main framework in this
challenge. The TSCN consists of a two-stream base model training procedure and
a pseudo ground truth learning procedure. The base model training encourages
the model to predict reliable predictions based on single modality (i.e., RGB
or optical flow), based on the fusion of which a pseudo ground truth is
generated and in turn used as supervision to train the base models. On the HACS
v1.1.1 dataset, without fine-tuning the feature-extraction I3D models, our
method achieves 22.20% on the validation set and 21.68% on the testing set in
terms of average mAP. Our solution ranked the 2rd in this challenge, and we
hope our method can serve as a baseline for future academic research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Modeling of Probabilities for Coding the Octree Representation of Point Clouds. (arXiv:2106.06482v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1">Emre Can Kaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1">Ioan Tabus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06482">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a novel lossless point cloud compression algorithm that
uses a neural network for estimating the coding probabilities for the occupancy
status of voxels, depending on wide three dimensional contexts around the voxel
to be encoded. The point cloud is represented as an octree, with each
resolution layer being sequentially encoded and decoded using arithmetic
coding, starting from the lowest resolution, until the final resolution is
reached. The occupancy probability of each voxel of the splitting pattern at
each node of the octree is modeled by a neural network, having at its input the
already encoded occupancy status of several octree nodes (belonging to the past
and current resolutions), corresponding to a 3D context surrounding the node to
be encoded. The algorithm has a fast and a slow version, the fast version
selecting differently several voxels of the context, which allows an increased
parallelization by sending larger batches of templates to be estimated by the
neural network, at both encoder and decoder. The proposed algorithms yield
state-of-the-art results on benchmark datasets. The implementation will be made
available at https://github.com/marmus12/nnctx</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image Forensic Technique Based on JPEG Ghosts. (arXiv:2106.06439v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1">Divakar Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06439">
                                    <div class="article-summary-box-inner">
                                        <span>The unprecedented growth in the easy availability of photo-editing tools has
endangered the power of digital images.An image was supposed to be worth more
than a thousand words,but now this can be said only if it can be authenticated
orthe integrity of the image can be proved to be intact. In thispaper, we
propose a digital image forensic technique for JPEG images. It can detect any
forgery in the image if the forged portion called a ghost image is having a
compression quality different from that of the cover image. It is based on
resaving the JPEG image at different JPEG qualities, and the detection of the
forged portion is maximum when it is saved at the same JPEG quality as the
cover image. Also, we can precisely predictthe JPEG quality of the cover image
by analyzing the similarity using Structural Similarity Index Measure (SSIM) or
the energyof the images. The first maxima in SSIM or the first minima inenergy
correspond to the cover image JPEG quality. We created adataset for varying
JPEG compression qualities of the ghost and the cover images and validated the
scalability of the experimental results.We also, experimented with varied
attack scenarios, e.g. high-quality ghost image embedded in low quality of
cover image,low-quality ghost image embedded in high-quality of cover image,and
ghost image and cover image both at the same quality.The proposed method is
able to localize the tampered portions accurately even for forgeries as small
as 10x10 sized pixel blocks.Our technique is also robust against other attack
scenarios like copy-move forgery, inserting text into image, rescaling
(zoom-out/zoom-in) ghost image and then pasting on cover image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization. (arXiv:2105.13084v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yihao Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwen Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13084">
                                    <div class="article-summary-box-inner">
                                        <span>Most consumer-grade digital cameras can only capture a limited range of
luminance in real-world scenes due to sensor constraints. Besides, noise and
quantization errors are often introduced in the imaging process. In order to
obtain high dynamic range (HDR) images with excellent visual quality, the most
common solution is to combine multiple images with different exposures.
However, it is not always feasible to obtain multiple images of the same scene
and most HDR reconstruction methods ignore the noise and quantization loss. In
this work, we propose a novel learning-based approach using a spatially dynamic
encoder-decoder network, HDRUNet, to learn an end-to-end mapping for single
image HDR reconstruction with denoising and dequantization. The network
consists of a UNet-style base network to make full use of the hierarchical
multi-scale information, a condition network to perform pattern-specific
modulation and a weighting network for selectively retaining information.
Moreover, we propose a Tanh_L1 loss function to balance the impact of
over-exposed values and well-exposed values on the network learning. Our method
achieves the state-of-the-art performance in quantitative comparisons and
visual quality. The proposed HDRUNet model won the second place in the single
frame track of NITRE2021 High Dynamic Range Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring breathing induced oesophageal motion and its dosimetric impact. (arXiv:2010.09391v3 [physics.med-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Fechter_T/0/1/0/all/0/1">Tobias Fechter</a>, <a href="http://arxiv.org/find/physics/1/au:+Adebahr_S/0/1/0/all/0/1">Sonja Adebahr</a>, <a href="http://arxiv.org/find/physics/1/au:+Grosu_A/0/1/0/all/0/1">Anca-Ligia Grosu</a>, <a href="http://arxiv.org/find/physics/1/au:+Baltas_D/0/1/0/all/0/1">Dimos Baltas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09391">
                                    <div class="article-summary-box-inner">
                                        <span>Stereotactic body radiation therapy allows for a precise and accurate dose
delivery. Organ motion during treatment bears the risk of undetected high dose
healthy tissue exposure. An organ very susceptible to high dose is the
oesophagus. Its low contrast on CT and the oblong shape renders motion
estimation difficult. We tackle this issue by modern algorithms to measure the
oesophageal motion voxel-wise and to estimate motion related dosimetric impact.
Oesophageal motion was measured using deformable image registration and 4DCT of
11 internal and 5 public datasets. Current clinical practice of contouring the
organ on 3DCT was compared to timely resolved 4DCT contours. The dosimetric
impact of the motion was estimated by analysing the trajectory of each voxel in
the 4D dose distribution. Finally an organ motion model was built, allowing for
easier patient-wise comparisons. Motion analysis showed mean absolute maximal
motion amplitudes of 4.55 +/- 1.81 mm left-right, 5.29 +/- 2.67 mm
anterior-posterior and 10.78 +/- 5.30 mm superior-inferior. Motion between the
cohorts differed significantly. In around 50 % of the cases the dosimetric
passing criteria was violated. Contours created on 3DCT did not cover 14 % of
the organ for 50 % of the respiratory cycle and the 3D contour is around 38 %
smaller than the union of all 4D contours. The motion model revealed that the
maximal motion is not limited to the lower part of the organ. Our results
showed motion amplitudes higher than most reported values in the literature and
that motion is very heterogeneous across patients. Therefore, individual motion
information should be considered in contouring and planning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised learning for crop/weed classification based on color and texture features. (arXiv:2106.10581v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mekhalfa_F/0/1/0/all/0/1">Faiza Mekhalfa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yacef_F/0/1/0/all/0/1">Fouad Yacef</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10581">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision techniques have attracted a great interest in precision
agriculture, recently. The common goal of all computer vision-based precision
agriculture tasks is to detect the objects of interest (e.g., crop, weed) and
discriminating them from the background. The Weeds are unwanted plants growing
among crops competing for nutrients, water, and sunlight, causing losses to
crop yields. Weed detection and mapping is critical for site-specific weed
management to reduce the cost of labor and impact of herbicides. This paper
investigates the use of color and texture features for discrimination of
Soybean crops and weeds. Feature extraction methods including two color spaces
(RGB, HSV), gray level Co-occurrence matrix (GLCM), and Local Binary Pattern
(LBP) are used to train the Support Vector Machine (SVM) classifier. The
experiment was carried out on image dataset of soybean crop, obtained from an
unmanned aerial vehicle (UAV), which is publicly available. The results from
the experiment showed that the highest accuracy (above 96%) was obtained from
the combination of color and LBP features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiGS : Divergence guided shape implicit neural representation for unoriented point clouds. (arXiv:2106.10811v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Shabat_Y/0/1/0/all/0/1">Yizhak Ben-Shabat</a>, <a href="http://arxiv.org/find/cs/1/au:+Koneputugodage_C/0/1/0/all/0/1">Chamin Hewa Koneputugodage</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10811">
                                    <div class="article-summary-box-inner">
                                        <span>Neural shape representations have recently shown to be effective in shape
analysis and reconstruction tasks. Existing neural network methods require
point coordinates and corresponding normal vectors to learn the implicit level
sets of the shape. Normal vectors are often not provided as raw data,
therefore, approximation and reorientation are required as pre-processing
stages, both of which can introduce noise. In this paper, we propose a
divergence guided shape representation learning approach that does not require
normal vectors as input. We show that incorporating a soft constraint on the
divergence of the distance function favours smooth solutions that reliably
orients gradients to match the unknown normal at each point, in some cases even
better than approaches that use ground truth normal vectors directly.
Additionally, we introduce a novel geometric initialization method for
sinusoidal shape representation networks that further improves convergence to
the desired solution. We evaluate the effectiveness of our approach on the task
of surface reconstruction and show state-of-the-art performance compared to
other unoriented methods and on-par performance compared to oriented methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning for Deep Neural Networks on Edge Devices. (arXiv:2106.10836v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Senzaki_Y/0/1/0/all/0/1">Yuya Senzaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamelain_C/0/1/0/all/0/1">Christian Hamelain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10836">
                                    <div class="article-summary-box-inner">
                                        <span>When dealing with deep neural network (DNN) applications on edge devices,
continuously updating the model is important. Although updating a model with
real incoming data is ideal, using all of them is not always feasible due to
limits, such as labeling and communication costs. Thus, it is necessary to
filter and select the data to use for training (i.e., active learning) on the
device. In this paper, we formalize a practical active learning problem for
DNNs on edge devices and propose a general task-agnostic framework to tackle
this problem, which reduces it to a stream submodular maximization. This
framework is light enough to be run with low computational resources, yet
provides solutions whose quality is theoretically guaranteed thanks to the
submodular property. Through this framework, we can configure data selection
criteria flexibly, including using methods proposed in previous active learning
studies. We evaluate our approach on both classification and object detection
tasks in a practical setting to simulate a real-life scenario. The results of
our study show that the proposed framework outperforms all other methods in
both tasks, while running at a practical speed on real devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Object Classification on Partial Point Clouds: A Practical Perspective. (arXiv:2012.10042v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zelin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Changxing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaowei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10042">
                                    <div class="article-summary-box-inner">
                                        <span>As a 3D counterpart of object classification in images, object point cloud
classification is fundamental to 3D scene understanding, and has drawn great
research attention since the release of benchmarking datasets, such as the
ModelNet and the ShapeNet. These benchmarks assume point clouds covering
complete surfaces of object instances, for which plenty of high-performing
methods have been developed. However, their settings deviate from those often
met in practice, where, due to (self-)occlusion, a point cloud covering partial
surface of an object is captured from an arbitrary view. We show in this paper
that performance of existing point cloud classification methods drops
drastically under the considered practical single-view, partial setting; the
phenomenon is consistent with the observation that semantic category of a
partial object surface is less ambiguous only when its distribution on the
whole surface is clearly specified. To this end, we argue for a single-view,
partial setting where supervised learning of object pose estimation should be
accompanied with classification. Technically, we propose a baseline method of
Pose-Accompanied Point cloud classification Network (PAPNet); built upon
SE(3)-equivariant convolutions, the PAPNet learns intermediate pose
transformations for equivariant features defined on vector fields, which makes
the subsequent classification easier (ideally) in the category-level, canonical
pose. We adapt existing ModelNet40 and ScanNet datasets on point set
classification to the introduced single-view, partial setting to verify our
hypothesis. Thorough experiments confirm the necessity of object pose
estimation; our PAPNet also outperforms existing methods greatly on the new
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented 2D-TAN: A Two-stage Approach for Human-centric Spatio-Temporal Video Grounding. (arXiv:2106.10634v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chaolei Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zihang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jian-Fang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wei-Shi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10634">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an effective two-stage approach to tackle the problem of
language-based Human-centric Spatio-Temporal Video Grounding (HC-STVG) task. In
the first stage, we propose an Augmented 2D Temporal Adjacent Network
(Augmented 2D-TAN) to temporally ground the target moment corresponding to the
given description. Primarily, we improve the original 2D-TAN from two aspects:
First, a temporal context-aware Bi-LSTM Aggregation Module is developed to
aggregate clip-level representations, replacing the original max-pooling.
Second, we propose to employ Random Concatenation Augmentation (RCA) mechanism
during the training phase. In the second stage, we use pretrained MDETR model
to generate per-frame bounding boxes via language query, and design a set of
hand-crafted rules to select the best matching bounding box outputted by MDETR
for each frame within the grounded moment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Remote Sensing Images Semantic Segmentation with General Remote Sensing Vision Model via a Self-Supervised Contrastive Learning Method. (arXiv:2106.10605v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruoyun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haozhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chao Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10605">
                                    <div class="article-summary-box-inner">
                                        <span>A new learning paradigm, self-supervised learning (SSL), can be used to solve
such problems by pre-training a general model with large unlabeled images and
then fine-tuning on a downstream task with very few labeled samples.
Contrastive learning is a typical method of SSL, which can learn general
invariant features. However, most of the existing contrastive learning is
designed for classification tasks to obtain an image-level representation,
which may be sub-optimal for semantic segmentation tasks requiring pixel-level
discrimination. Therefore, we propose Global style and Local matching
Contrastive Learning Network (GLCNet) for remote sensing semantic segmentation.
Specifically, the global style contrastive module is used to learn an
image-level representation better, as we consider the style features can better
represent the overall image features; The local features matching contrastive
module is designed to learn representations of local regions which is
beneficial for semantic segmentation. We evaluate four remote sensing semantic
segmentation datasets, and the experimental results show that our method mostly
outperforms state-of-the-art self-supervised methods and ImageNet pre-training.
Specifically, with 1\% annotation from the original dataset, our approach
improves Kappa by 6\% on the ISPRS Potsdam dataset and 3\% on Deep Globe Land
Cover Classification dataset relative to the existing baseline. Moreover, our
method outperforms supervised learning when there are some differences between
the datasets of upstream tasks and downstream tasks. Our study promotes the
development of self-supervised learning in the field of remote sensing semantic
segmentation. The source code is available at
https://github.com/GeoX-Lab/G-RSIM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Underwater Image Restoration via Contrastive Learning and a Real-world Dataset. (arXiv:2106.10718v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Han_J/0/1/0/all/0/1">Junlin Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Shoeiby_M/0/1/0/all/0/1">Mehrdad Shoeiby</a>, <a href="http://arxiv.org/find/eess/1/au:+Malthus_T/0/1/0/all/0/1">Tim Malthus</a>, <a href="http://arxiv.org/find/eess/1/au:+Botha_E/0/1/0/all/0/1">Elizabeth Botha</a>, <a href="http://arxiv.org/find/eess/1/au:+Anstee_J/0/1/0/all/0/1">Janet Anstee</a>, <a href="http://arxiv.org/find/eess/1/au:+Anwar_S/0/1/0/all/0/1">Saeed Anwar</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_R/0/1/0/all/0/1">Ran Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Armin_M/0/1/0/all/0/1">Mohammad Ali Armin</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hongdong Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10718">
                                    <div class="article-summary-box-inner">
                                        <span>Underwater image restoration is of significant importance in unveiling the
underwater world. Numerous techniques and algorithms have been developed in the
past decades. However, due to fundamental difficulties associated with
imaging/sensing, lighting, and refractive geometric distortions, in capturing
clear underwater images, no comprehensive evaluations have been conducted of
underwater image restoration. To address this gap, we have constructed a
large-scale real underwater image dataset, dubbed &#x60;HICRD&#x27; (Heron Island Coral
Reef Dataset), for the purpose of benchmarking existing methods and supporting
the development of new deep-learning based methods. We employ accurate water
parameter (diffuse attenuation coefficient) in generating reference images.
There are 2000 reference restored images and 6003 original underwater images in
the unpaired training set. Further, we present a novel method for underwater
image restoration based on unsupervised image-to-image translation framework.
Our proposed method leveraged contrastive learning and generative adversarial
networks to maximize the mutual information between raw and restored images.
Extensive experiments with comparisons to recent approaches further demonstrate
the superiority of our proposed method. Our code and dataset are publicly
available at GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Power Multi-Camera Object Re-Identification using Hierarchical Neural Networks. (arXiv:2106.10588v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goel_A/0/1/0/all/0/1">Abhinav Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_C/0/1/0/all/0/1">Caleb Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James C. Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiruvathukal_G/0/1/0/all/0/1">George K. Thiruvathukal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yung-Hsiang Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10588">
                                    <div class="article-summary-box-inner">
                                        <span>Low-power computer vision on embedded devices has many applications. This
paper describes a low-power technique for the object re-identification (reID)
problem: matching a query image against a gallery of previously seen images.
State-of-the-art techniques rely on large, computationally-intensive Deep
Neural Networks (DNNs). We propose a novel hierarchical DNN architecture that
uses attribute labels in the training dataset to perform efficient object reID.
At each node in the hierarchy, a small DNN identifies a different attribute of
the query image. The small DNN at each leaf node is specialized to re-identify
a subset of the gallery: only the images with the attributes identified along
the path from the root to a leaf. Thus, a query image is re-identified
accurately after processing with a few small DNNs. We compare our method with
state-of-the-art object reID techniques. With a 4% loss in accuracy, our
approach realizes significant resource savings: 74% less memory, 72% fewer
operations, and 67% lower query latency, yielding 65% less energy consumption.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Inversion: A Survey. (arXiv:2101.05278v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Weihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yulun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yujiu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jing-Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05278">
                                    <div class="article-summary-box-inner">
                                        <span>GAN inversion aims to invert a given image back into the latent space of a
pretrained GAN model, for the image to be faithfully reconstructed from the
inverted code by the generator. As an emerging technique to bridge the real and
fake image domains, GAN inversion plays an essential role in enabling the
pretrained GAN models such as StyleGAN and BigGAN to be used for real image
editing applications. Meanwhile, GAN inversion also provides insights on the
interpretation of GAN&#x27;s latent space and how the realistic images can be
generated. In this paper, we provide an overview of GAN inversion with a focus
on its recent algorithms and applications. We cover important techniques of GAN
inversion and their applications to image restoration and image manipulation.
We further elaborate on some trends and challenges for future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Track Object Position through Occlusion. (arXiv:2106.10766v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Satyaki Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Hebert_M/0/1/0/all/0/1">Martial Hebert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10766">
                                    <div class="article-summary-box-inner">
                                        <span>Occlusion is one of the most significant challenges encountered by object
detectors and trackers. While both object detection and tracking has received a
lot of attention in the past, most existing methods in this domain do not
target detecting or tracking objects when they are occluded. However, being
able to detect or track an object of interest through occlusion has been a long
standing challenge for different autonomous tasks. Traditional methods that
employ visual object trackers with explicit occlusion modeling experience drift
and make several fundamental assumptions about the data. We propose to address
this with a &#x60;tracking-by-detection&#x60; approach that builds upon the success of
region based video object detectors. Our video level object detector uses a
novel recurrent computational unit at its core that enables long term
propagation of object features even under occlusion. Finally, we compare our
approach with existing state-of-the-art video object detectors and show that
our approach achieves superior results on a dataset of furniture assembly
videos collected from the internet, where small objects like screws, nuts, and
bolts often get occluded from the camera viewpoint.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Model&#x27;s Uncertainty and Confidences for Adversarial Example Detection. (arXiv:2103.05354v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aldahdooh_A/0/1/0/all/0/1">Ahmed Aldahdooh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1">Olivier D&#xe9;forges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05354">
                                    <div class="article-summary-box-inner">
                                        <span>Security-sensitive applications that rely on Deep Neural Networks (DNNs) are
vulnerable to small perturbations that are crafted to generate Adversarial
Examples(AEs). The AEs are imperceptible to humans and cause DNN to misclassify
them. Many defense and detection techniques have been proposed. Model&#x27;s
confidences and Dropout, as a popular way to estimate the model&#x27;s uncertainty,
have been used for AE detection but they showed limited success against black-
and gray-box attacks. Moreover, the state-of-the-art detection techniques have
been designed for specific attacks or broken by others, need knowledge about
the attacks, are not consistent, increase model parameters overhead, are
time-consuming, or have latency in inference time. To trade off these factors,
we revisit the model&#x27;s uncertainty and confidences and propose a novel
unsupervised ensemble AE detection mechanism that 1) uses the uncertainty
method called SelectiveNet, 2) processes model layers outputs, i.e.feature
maps, to generate new confidence probabilities. The detection method is called
Selective and Feature based Adversarial Detection (SFAD). Experimental results
show that the proposed approach achieves better performance against black- and
gray-box attacks than the state-of-the-art methods and achieves comparable
performance against white-box attacks. Moreover, results show that SFAD is
fully robust against High Confidence Attacks (HCAs) for MNIST and partially
robust for CIFAR10 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Generative Learning via Schr\&quot;{o}dinger Bridge. (arXiv:2106.10410v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gefei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Can Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10410">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to learn a generative model via entropy interpolation with a
Schr\&quot;{o}dinger Bridge. The generative learning task can be formulated as
interpolating between a reference distribution and a target distribution based
on the Kullback-Leibler divergence. At the population level, this entropy
interpolation is characterized via an SDE on $[0,1]$ with a time-varying drift
term. At the sample level, we derive our Schr\&quot;{o}dinger Bridge algorithm by
plugging the drift term estimated by a deep score estimator and a deep density
ratio estimator into the Euler-Maruyama method. Under some mild smoothness
assumptions of the target distribution, we prove the consistency of both the
score estimator and the density ratio estimator, and then establish the
consistency of the proposed Schr\&quot;{o}dinger Bridge approach. Our theoretical
results guarantee that the distribution learned by our approach converges to
the target distribution. Experimental results on multimodal synthetic data and
benchmark data support our theoretical findings and indicate that the
generative model via Schr\&quot;{o}dinger Bridge is comparable with state-of-the-art
GANs, suggesting a new formulation of generative learning. We demonstrate its
usefulness in image interpolation and image inpainting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Deepfake Detection. (arXiv:2106.10705v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10705">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose to utilize Automated Machine Learning to
automatically search architecture for deepfake detection. Unlike previous
works, our method benefits from the superior capability of deep learning while
relieving us from the high labor cost in the manual network design process. It
is experimentally proved that our proposed method not only outperforms previous
non-deep learning methods but achieves comparable or even better prediction
accuracy compared to previous deep learning methods. To improve the generality
of our method, especially when training data and testing data are manipulated
by different methods, we propose a multi-task strategy in our network learning
process, making it estimate potential manipulation regions in given samples as
well as predict whether the samples are real. Comparing to previous works using
similar strategies, our method depends much less on prior knowledge, such as no
need to know which manipulation method is utilized and whether it is utilized
already. Extensive experimental results on two benchmark datasets demonstrate
the effectiveness of our proposed method on deepfake detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task Attended Meta-Learning for Few-Shot Learning. (arXiv:2106.10642v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aimen_A/0/1/0/all/0/1">Aroof Aimen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidheekh_S/0/1/0/all/0/1">Sahil Sidheekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_N/0/1/0/all/0/1">Narayanan C. Krishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10642">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning (ML) has emerged as a promising direction in learning models
under constrained resource settings like few-shot learning. The popular
approaches for ML either learn a generalizable initial model or a generic
parametric optimizer through episodic training. The former approaches leverage
the knowledge from a batch of tasks to learn an optimal prior. In this work, we
study the importance of a batch for ML. Specifically, we first incorporate a
batch episodic training regimen to improve the learning of the generic
parametric optimizer. We also hypothesize that the common assumption in batch
episodic training that each task in a batch has an equal contribution to
learning an optimal meta-model need not be true. We propose to weight the tasks
in a batch according to their &quot;importance&quot; in improving the meta-model&#x27;s
learning. To this end, we introduce a training curriculum motivated by
selective focus in humans, called task attended meta-training, to weight the
tasks in a batch. Task attention is a standalone module that can be integrated
with any batch episodic training regimen. The comparisons of the models with
their non-task-attended counterparts on complex datasets like miniImageNet and
tieredImageNet validate its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Vision Transformers for Fine-grained Classification. (arXiv:2106.10587v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1">Marcos V. Conde</a>, <a href="http://arxiv.org/find/cs/1/au:+Turgutlu_K/0/1/0/all/0/1">Kerem Turgutlu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10587">
                                    <div class="article-summary-box-inner">
                                        <span>Existing computer vision research in categorization struggles with
fine-grained attributes recognition due to the inherently high intra-class
variances and low inter-class variances. SOTA methods tackle this challenge by
locating the most informative image regions and rely on them to classify the
complete image. The most recent work, Vision Transformer (ViT), shows its
strong performance in both traditional and fine-grained classification tasks.
In this work, we propose a multi-stage ViT framework for fine-grained image
classification tasks, which localizes the informative image regions without
requiring architectural changes using the inherent multi-head self-attention
mechanism. We also introduce attention-guided augmentations for improving the
model&#x27;s capabilities. We demonstrate the value of our approach by experimenting
with four popular fine-grained benchmarks: CUB-200-2011, Stanford Cars,
Stanford Dogs, and FGVC7 Plant Pathology. We also prove our model&#x27;s
interpretability via qualitative results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDA-Net: Fusion of Persistent Homology and Deep Learning Features for COVID-19 Detection in Chest X-Ray Images. (arXiv:2101.08398v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1">Mustafa Hajij</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Batayneh_F/0/1/0/all/0/1">Fawwaz Batayneh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08398">
                                    <div class="article-summary-box-inner">
                                        <span>Topological Data Analysis (TDA) has emerged recently as a robust tool to
extract and compare the structure of datasets. TDA identifies features in data
such as connected components and holes and assigns a quantitative measure to
these features. Several studies reported that topological features extracted by
TDA tools provide unique information about the data, discover new insights, and
determine which feature is more related to the outcome. On the other hand, the
overwhelming success of deep neural networks in learning patterns and
relationships has been proven on a vast array of data applications, images in
particular. To capture the characteristics of both powerful tools, we propose
\textit{TDA-Net}, a novel ensemble network that fuses topological and deep
features for the purpose of enhancing model generalizability and accuracy. We
apply the proposed \textit{TDA-Net} to a critical application, which is the
automated detection of COVID-19 from CXR images. The experimental results
showed that the proposed network achieved excellent performance and suggests
the applicability of our method in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AINet: Association Implantation for Superpixel Segmentation. (arXiv:2101.10696v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xueming Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Li Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10696">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, some approaches are proposed to harness deep convolutional networks
to facilitate superpixel segmentation. The common practice is to first evenly
divide the image into a pre-defined number of grids and then learn to associate
each pixel with its surrounding grids. However, simply applying a series of
convolution operations with limited receptive fields can only implicitly
perceive the relations between the pixel and its surrounding grids.
Consequently, existing methods often fail to provide an effective context when
inferring the association map. To remedy this issue, we propose a novel
\textbf{A}ssociation \textbf{I}mplantation (AI) module to enable the network to
explicitly capture the relations between the pixel and its surrounding grids.
The proposed AI module directly implants the features of grid cells to the
surrounding of its corresponding central pixel, and conducts convolution on the
padded window to adaptively transfer knowledge between them. With such an
implantation operation, the network could explicitly harvest the pixel-grid
level context, which is more in line with the target of superpixel segmentation
comparing to the pixel-wise relation. Furthermore, to pursue better boundary
precision, we design a boundary-perceiving loss to help the network
discriminate the pixels around boundaries in hidden feature level, which could
benefit the subsequent inferring modules to accurately identify more boundary
pixels. Extensive experiments on BSDS500 and NYUv2 datasets show that our
method could not only achieve state-of-the-art performance but maintain
satisfactory inference efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Semantic Relationships for Unpaired Image Captioning. (arXiv:2106.10658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fenglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1">Meng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10658">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, image captioning has aroused great interest in both academic and
industrial worlds. Most existing systems are built upon large-scale datasets
consisting of image-sentence pairs, which, however, are time-consuming to
construct. In addition, even for the most advanced image captioning systems, it
is still difficult to realize deep image understanding. In this work, we
achieve unpaired image captioning by bridging the vision and the language
domains with high-level semantic information. The motivation stems from the
fact that the semantic concepts with the same modality can be extracted from
both images and descriptions. To further improve the quality of captions
generated by the model, we propose the Semantic Relationship Explorer, which
explores the relationships between semantic concepts for better understanding
of the image. Extensive experiments on MSCOCO dataset show that we can generate
desirable captions without paired datasets. Furthermore, the proposed approach
boosts five strong baselines under the paired setting, where the most
significant improvement in CIDEr score reaches 8%, demonstrating that it is
effective and generalizes well to a wide range of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias. (arXiv:2101.07296v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stojanov_S/0/1/0/all/0/1">Stefan Stojanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Thai_A/0/1/0/all/0/1">Anh Thai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1">James M. Rehg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07296">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely accepted that reasoning about object shape is important for
object recognition. However, the most powerful object recognition methods today
do not explicitly make use of object shape during learning. In this work,
motivated by recent developments in low-shot learning, findings in
developmental psychology, and the increased use of synthetic data in computer
vision research, we investigate how reasoning about 3D shape can be used to
improve low-shot learning methods&#x27; generalization performance. We propose a new
way to improve existing low-shot learning approaches by learning a
discriminative embedding space using 3D object shape, and using this embedding
by learning how to map images into it. Our new approach improves the
performance of image-only low-shot learning approaches on multiple datasets. We
also introduce Toys4K, a 3D object dataset with the largest number of object
categories currently available, which supports low-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CompConv: A Compact Convolution Module for Efficient Feature Learning. (arXiv:2106.10486v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yujun Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10486">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) have achieved remarkable success in
various computer vision tasks but rely on tremendous computational cost. To
solve this problem, existing approaches either compress well-trained
large-scale models or learn lightweight models with carefully designed network
structures. In this work, we make a close study of the convolution operator,
which is the basic unit used in CNNs, to reduce its computing load. In
particular, we propose a compact convolution module, called CompConv, to
facilitate efficient feature learning. With the divide-and-conquer strategy,
CompConv is able to save a great many computations as well as parameters to
produce a certain dimensional feature map. Furthermore, CompConv discreetly
integrates the input features into the outputs to efficiently inherit the input
information. More importantly, the novel CompConv is a plug-and-play module
that can be directly applied to modern CNN structures to replace the vanilla
convolution layers without further effort. Extensive experimental results
suggest that CompConv can adequately compress the benchmark CNN structures yet
barely sacrifice the performance, surpassing other competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Humble Teachers Teach Better Students for Semi-Supervised Object Detection. (arXiv:2106.10456v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yihe Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yijun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuting Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10456">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a semi-supervised approach for contemporary object detectors
following the teacher-student dual model framework. Our method is featured with
1) the exponential moving averaging strategy to update the teacher from the
student online, 2) using plenty of region proposals and soft pseudo-labels as
the student&#x27;s training targets, and 3) a light-weighted detection-specific data
ensemble for the teacher to generate more reliable pseudo-labels. Compared to
the recent state-of-the-art -- STAC, which uses hard labels on sparsely
selected hard pseudo samples, the teacher in our model exposes richer
information to the student with soft-labels on many proposals. Our model
achieves COCO-style AP of 53.04% on VOC07 val set, 8.4% better than STAC, when
using VOC12 as unlabeled data. On MS-COCO, it outperforms prior work when only
a small percentage of data is taken as labeled. It also reaches 53.8% AP on
MS-COCO test-dev with 3.1% gain over the fully supervised ResNet-152 Cascaded
R-CNN, by tapping into unlabeled data of a similar size to the labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Place recognition survey: An update on deep learning approaches. (arXiv:2106.10458v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barros_T/0/1/0/all/0/1">Tiago Barros</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1">Ricardo Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrote_L/0/1/0/all/0/1">Lu&#xed;s Garrote</a>, <a href="http://arxiv.org/find/cs/1/au:+Premebida_C/0/1/0/all/0/1">Cristiano Premebida</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunes_U/0/1/0/all/0/1">Urbano J. Nunes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10458">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous Vehicles (AV) are becoming more capable of navigating in complex
environments with dynamic and changing conditions. A key component that enables
these intelligent vehicles to overcome such conditions and become more
autonomous is the sophistication of the perception and localization systems. As
part of the localization system, place recognition has benefited from recent
developments in other perception tasks such as place categorization or object
recognition, namely with the emergence of deep learning (DL) frameworks. This
paper surveys recent approaches and methods used in place recognition,
particularly those based on deep learning. The contributions of this work are
twofold: surveying recent sensors such as 3D LiDARs and RADARs, applied in
place recognition; and categorizing the various DL-based place recognition
works into supervised, unsupervised, semi-supervised, parallel, and
hierarchical categories. First, this survey introduces key place recognition
concepts to contextualize the reader. Then, sensor characteristics are
addressed. This survey proceeds by elaborating on the various DL-based works,
presenting summaries for each framework. Some lessons learned from this survey
include: the importance of NetVLAD for supervised end-to-end learning; the
advantages of unsupervised approaches in place recognition, namely for
cross-domain applications; or the increasing tendency of recent works to seek,
not only for higher performance but also for higher efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Transferability Estimation for Image Classification Tasks. (arXiv:2106.10479v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shao-Lun Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10479">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability estimation is an essential problem in transfer learning to
predict how good the performance is when transfer a source model (source task)
to a target task. Recent analytical transferability metrics have been widely
used for source model selection and multi-task learning. Earlier metrics does
not work sufficiently well under the challenging cross-domain cross-task
transfer settings, but recent OTCE score achieves a noteworthy performance
using auxiliary tasks. A simplified version named OT-based NCE score sacrifices
accuracy to be more efficient, but it can be further improved. Consequently, we
propose a practical transferability metric called JC-NCE score to further
improve the cross-domain cross-task transferability estimation performance,
which is more efficient than the OTCE score and more accurate than the OT-based
NCE score. Specifically, we build the joint correspondences between source and
target data via solving an optimal transport problem with considering both the
sample distance and label distance, and then compute the transferability score
as the negative conditional entropy. Extensive validations under the
intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE
score outperforms the OT-based NCE score with about 7% and 12% gains,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Channel Pruning Guided by Spatial and Channel Attention for DNNs in Intelligent Edge Computing. (arXiv:2011.03891v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1">Weiwei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaodong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_N/0/1/0/all/0/1">Naixue Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03891">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have achieved remarkable success in many computer
vision tasks recently, but the huge number of parameters and the high
computation overhead hinder their deployments on resource-constrained edge
devices. It is worth noting that channel pruning is an effective approach for
compressing DNN models. A critical challenge is to determine which channels are
to be removed, so that the model accuracy will not be negatively affected. In
this paper, we first propose Spatial and Channel Attention (SCA), a new
attention module combining both spatial and channel attention that respectively
focuses on &quot;where&quot; and &quot;what&quot; are the most informative parts. Guided by the
scale values generated by SCA for measuring channel importance, we further
propose a new channel pruning approach called Channel Pruning guided by Spatial
and Channel Attention (CPSCA). Experimental results indicate that SCA achieves
the best inference accuracy, while incurring negligibly extra resource
consumption, compared to other state-of-the-art attention modules. Our
evaluation on two benchmark datasets shows that, with the guidance of SCA, our
CPSCA approach achieves higher inference accuracy than other state-of-the-art
pruning methods under the same pruning ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetrical Bi-RNN for pedestrian trajectory encoding. (arXiv:2106.04419v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozenberg_R/0/1/0/all/0/1">Rapha&#xeb;l Rozenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gesnouin_J/0/1/0/all/0/1">Joseph Gesnouin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moutarde_F/0/1/0/all/0/1">Fabien Moutarde</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04419">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian motion behavior involves a combination of individual goals and
social interactions with other agents. In this article, we present an
asymmetrical bidirectional recurrent neural network architecture called U-RNN
to encode pedestrian trajectories and evaluate its relevance to replace LSTMs
for various forecasting models. Experimental results on the Trajnet++ benchmark
show that the U-LSTM variant yields better results regarding every available
metrics (ADE, FDE, Collision rate) than common trajectory encoders for a
variety of approaches and interaction modules, suggesting that the proposed
approach is a viable alternative to the de facto sequence encoding RNNs.

Our implementation of the asymmetrical Bi-RNNs for the Trajnet++ benchmark is
available at:
github.com/JosephGesnouin/Asymmetrical-Bi-RNNs-to-encode-pedestrian-trajectories</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamical Deep Generative Latent Modeling of 3D Skeletal Motion. (arXiv:2106.10393v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farnoosh_A/0/1/0/all/0/1">Amirreza Farnoosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostadabbas_S/0/1/0/all/0/1">Sarah Ostadabbas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10393">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a Bayesian switching dynamical model for
segmentation of 3D pose data over time that uncovers interpretable patterns in
the data and is generative. Our model decomposes highly correlated skeleton
data into a set of few spatial basis of switching temporal processes in a
low-dimensional latent framework. We parameterize these temporal processes with
regard to a switching deep vector autoregressive prior in order to accommodate
both multimodal and higher-order nonlinear inter-dependencies. This results in
a dynamical deep generative latent model that parses the meaningful intrinsic
states in the dynamics of 3D pose data using approximate variational inference,
and enables a realistic low-level dynamical generation and segmentation of
complex skeleton movements. Our experiments on four biological motion data
containing bat flight, salsa dance, walking, and golf datasets substantiate
superior performance of our model in comparison with the state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">This Looks Like That... Does it? Shortcomings of Latent Space Prototype Interpretability in Deep Networks. (arXiv:2105.02968v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_A/0/1/0/all/0/1">Adrian Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanconi_C/0/1/0/all/0/1">Claudio Fanconi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rade_R/0/1/0/all/0/1">Rahul Rade</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks that yield human interpretable decisions by
architectural design have lately become an increasingly popular alternative to
post hoc interpretation of traditional black-box models. Among these networks,
the arguably most widespread approach is so-called prototype learning, where
similarities to learned latent prototypes serve as the basis of classifying an
unseen data point. In this work, we point to an important shortcoming of such
approaches. Namely, there is a semantic gap between similarity in latent space
and similarity in input space, which can corrupt interpretability. We design
two experiments that exemplify this issue on the so-called ProtoPNet.
Specifically, we find that this network&#x27;s interpretability mechanism can be led
astray by intentionally crafted or even JPEG compression artefacts, which can
produce incomprehensible decisions. We argue that practitioners ought to have
this shortcoming in mind when deploying prototype-based models in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Universal Template for Few-shot Dataset Generalization. (arXiv:2105.07029v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Triantafillou_E/0/1/0/all/0/1">Eleni Triantafillou</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07029">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot dataset generalization is a challenging variant of the well-studied
few-shot classification problem where a diverse training set of several
datasets is given, for the purpose of training an adaptable model that can then
learn classes from new datasets using only a few examples. To this end, we
propose to utilize the diverse training set to construct a universal template:
a partial model that can define a wide array of dataset-specialized models, by
plugging in appropriate components. For each new few-shot classification
problem, our approach therefore only requires inferring a small number of
parameters to insert into the universal template. We design a separate network
that produces an initialization of those parameters for each given task, and we
then fine-tune its proposed initialization via a few steps of gradient descent.
Our approach is more parameter-efficient, scalable and adaptable compared to
previous methods, and achieves the state-of-the-art on the challenging
Meta-Dataset benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Object Segmentation with Dynamic Click Transform. (arXiv:2106.10465v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chun-Tse Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1">Wei-Chih Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chih-Ting Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1">Shao-Yi Chien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10465">
                                    <div class="article-summary-box-inner">
                                        <span>In the interactive segmentation, users initially click on the target object
to segment the main body and then provide corrections on mislabeled regions to
iteratively refine the segmentation masks. Most existing methods transform
these user-provided clicks into interaction maps and concatenate them with
image as the input tensor. Typically, the interaction maps are determined by
measuring the distance of each pixel to the clicked points, ignoring the
relation between clicks and mislabeled regions. We propose a Dynamic Click
Transform Network~(DCT-Net), consisting of Spatial-DCT and Feature-DCT, to
better represent user interactions. Spatial-DCT transforms each user-provided
click with individual diffusion distance according to the target scale, and
Feature-DCT normalizes the extracted feature map to a specific distribution
predicted from the clicked points. We demonstrate the effectiveness of our
proposed method and achieve favorable performance compared to the
state-of-the-art on three standard benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection. (arXiv:2106.00666v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuxin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1">Bencheng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinggang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiemin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jiyang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_J/0/1/0/all/0/1">Jianwei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wenyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00666">
                                    <div class="article-summary-box-inner">
                                        <span>Can Transformer perform $2\mathrm{D}$ object-level recognition from a pure
sequence-to-sequence perspective with minimal knowledge about the $2\mathrm{D}$
spatial structure? To answer this question, we present You Only Look at One
Sequence (YOLOS), a series of object detection models based on the na\&quot;ive
Vision Transformer with the fewest possible modifications as well as inductive
biases. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset
only can already achieve competitive object detection performance on COCO,
\textit{e.g.}, YOLOS-Base directly adopted from BERT-Base can achieve $42.0$
box AP. We also discuss the impacts as well as limitations of current pre-train
schemes and model scaling strategies for Transformer in vision through object
detection. Code and model weights are available at
\url{https://github.com/hustvl/YOLOS}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aggregating Nested Transformers. (arXiv:2105.12723v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zizhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Long Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1">Tomas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12723">
                                    <div class="article-summary-box-inner">
                                        <span>Although hierarchical structures are popular in recent vision transformers,
they require sophisticated designs and massive datasets to work well. In this
work, we explore the idea of nesting basic local transformers on
non-overlapping image blocks and aggregating them in a hierarchical manner. We
find that the block aggregation function plays a critical role in enabling
cross-block non-local information communication. This observation leads us to
design a simplified architecture with minor code changes upon the original
vision transformer and obtains improved performance compared to existing
methods. Our empirical results show that the proposed method NesT converges
faster and requires much less training data to achieve good generalization. For
example, a NesT with 68M parameters trained on ImageNet for 100/300 epochs
achieves $82.3\%/83.8\%$ accuracy evaluated on $224\times 224$ image size,
outperforming previous methods with up to $57\%$ parameter reduction. Training
a NesT with 6M parameters from scratch on CIFAR10 achieves $96\%$ accuracy
using a single GPU, setting a new state of the art for vision transformers.
Beyond image classification, we extend the key idea to image generation and
show NesT leads to a strong decoder that is 8$\times$ faster than previous
transformer based generators. Furthermore, we also propose a novel method for
visually interpreting the learned model. Source code is available
https://github.com/google-research/nested-transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yufei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10507">
                                    <div class="article-summary-box-inner">
                                        <span>Graphically-rich applications such as games are ubiquitous with attractive
visual effects of Graphical User Interface (GUI) that offers a bridge between
software applications and end-users. However, various types of graphical
glitches may arise from such GUI complexity and have become one of the main
component of software compatibility issues. Our study on bug reports from game
development teams in NetEase Inc. indicates that graphical glitches frequently
occur during the GUI rendering and severely degrade the quality of
graphically-rich applications such as video games. Existing automated testing
techniques for such applications focus mainly on generating various GUI test
sequences and check whether the test sequences can cause crashes. These
techniques require constant human attention to captures non-crashing bugs such
as bugs causing graphical glitches. In this paper, we present the first step in
automating the test oracle for detecting non-crashing bugs in graphically-rich
applications. Specifically, we propose \texttt{GLIB} based on a code-based data
augmentation technique to detect game GUI glitches. We perform an evaluation of
\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the
result shows that \texttt{GLIB} can achieve 100\% precision and 99.5\% recall
in detecting non-crashing bugs such as game GUI glitches. Practical application
of \texttt{GLIB} on another 14 real-world games (without bug reports) further
demonstrates that \texttt{GLIB} can effectively uncover GUI glitches, with 48
of 53 bugs reported by \texttt{GLIB} having been confirmed and fixed so far.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering. (arXiv:2106.10446v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_A/0/1/0/all/0/1">Ahjeong Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1">Gi-Cheon Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Joonhan Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Byoung-Tak Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10446">
                                    <div class="article-summary-box-inner">
                                        <span>Video Question Answering is a task which requires an AI agent to answer
questions grounded in video. This task entails three key challenges: (1)
understand the intention of various questions, (2) capturing various elements
of the input video (e.g., object, action, causality), and (3) cross-modal
grounding between language and vision information. We propose Motion-Appearance
Synergistic Networks (MASN), which embed two cross-modal features grounded on
motion and appearance information and selectively utilize them depending on the
question&#x27;s intentions. MASN consists of a motion module, an appearance module,
and a motion-appearance fusion module. The motion module computes the
action-oriented cross-modal joint representations, while the appearance module
focuses on the appearance aspect of the input video. Finally, the
motion-appearance fusion module takes each output of the motion module and the
appearance module as input, and performs question-guided fusion. As a result,
MASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA
datasets. We also conduct qualitative analysis by visualizing the inference
results of MASN. The code is available at
https://github.com/ahjeongseo/MASN-pytorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct Reconstruction of Linear Parametric Images from Dynamic PET Using Nonlocal Deep Image Prior. (arXiv:2106.10359v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gong_K/0/1/0/all/0/1">Kuang Gong</a>, <a href="http://arxiv.org/find/eess/1/au:+Catana_C/0/1/0/all/0/1">Ciprian Catana</a>, <a href="http://arxiv.org/find/eess/1/au:+Qi_J/0/1/0/all/0/1">Jinyi Qi</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1">Quanzheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10359">
                                    <div class="article-summary-box-inner">
                                        <span>Direct reconstruction methods have been developed to estimate parametric
images directly from the measured PET sinograms by combining the PET imaging
model and tracer kinetics in an integrated framework. Due to limited counts
received, signal-to-noise-ratio (SNR) and resolution of parametric images
produced by direct reconstruction frameworks are still limited. Recently
supervised deep learning methods have been successfully applied to medical
imaging denoising/reconstruction when large number of high-quality training
labels are available. For static PET imaging, high-quality training labels can
be acquired by extending the scanning time. However, this is not feasible for
dynamic PET imaging, where the scanning time is already long enough. In this
work, we proposed an unsupervised deep learning framework for direct parametric
reconstruction from dynamic PET, which was tested on the Patlak model and the
relative equilibrium Logan model. The patient&#x27;s anatomical prior image, which
is readily available from PET/CT or PET/MR scans, was supplied as the network
input to provide a manifold constraint, and also utilized to construct a kernel
layer to perform non-local feature denoising. The linear kinetic model was
embedded in the network structure as a 1x1 convolution layer. The training
objective function was based on the PET statistical model. Evaluations based on
dynamic datasets of 18F-FDG and 11C-PiB tracers show that the proposed
framework can outperform the traditional and the kernel method-based direct
reconstruction methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Specular reflections removal in colposcopic images based on neural networks: Supervised training with no ground truth previous knowledge. (arXiv:2106.02221v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jimenez_Martin_L/0/1/0/all/0/1">Lauren Jimenez-Martin</a>, <a href="http://arxiv.org/find/eess/1/au:+Perez_D/0/1/0/all/0/1">Daniel A. Vald&#xe9;s P&#xe9;rez</a>, <a href="http://arxiv.org/find/eess/1/au:+Asteasuainzarra_A/0/1/0/all/0/1">Ana M. Solares Asteasuainzarra</a>, <a href="http://arxiv.org/find/eess/1/au:+Leonard_L/0/1/0/all/0/1">Ludwig Leonard</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_Romanach_M/0/1/0/all/0/1">Marta L. Baguer D&#xed;az-Roma&#xf1;ach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02221">
                                    <div class="article-summary-box-inner">
                                        <span>Cervical cancer is a malignant tumor that seriously threatens women&#x27;s health,
and is one of the most common that affects women worldwide. For its early
detection, colposcopic images of the cervix are used for searching for possible
injuries or abnormalities. An inherent characteristic of these images is the
presence of specular reflections (brightness) that make it difficult to observe
some regions, which might imply misdiagnosis. In this paper, a new strategy
based on neural networks is introduced for eliminating specular reflections and
estimating the unobserved anatomical cervix portion under the bright zones. For
overcoming the fact that the ground truth corresponding to the specular
reflection regions is always unknown, the new strategy proposes the supervised
training of a neural network to learn how to restore any hidden regions of
colposcopic images. Once the specular reflections are identified, they are
removed from the image, and the previously trained network is used to fulfill
these deleted areas. The quality of the processed images was evaluated
quantitatively and qualitatively. In 21 of the 22 evaluated images, the
detected specular reflections were eliminated, whereas, in the remaining one,
these reflections were almost completely eliminated. The distribution of the
colors and the content of the restored images are similar to those of the
originals. The evaluation carried out by a specialist in Cervix Pathology
concluded that, after eliminating the specular reflections, the anatomical and
physiological elements of the cervix are observable in the restored images,
which facilitates the medical diagnosis of cervical pathologies. Our method has
the potential to improve the early detection of cervical cancer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-CAM: Group Score-Weighted Visual Explanations for Deep Convolutional Networks. (arXiv:2103.13859v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qinglong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_L/0/1/0/all/0/1">Lu Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yubin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13859">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an efficient saliency map generation method, called
Group score-weighted Class Activation Mapping (Group-CAM), which adopts the
&quot;split-transform-merge&quot; strategy to generate saliency maps. Specifically, for
an input image, the class activations are firstly split into groups. In each
group, the sub-activations are summed and de-noised as an initial mask. After
that, the initial masks are transformed with meaningful perturbations and then
applied to preserve sub-pixels of the input (i.e., masked inputs), which are
then fed into the network to calculate the confidence scores. Finally, the
initial masks are weighted summed to form the final saliency map, where the
weights are confidence scores produced by the masked inputs. Group-CAM is
efficient yet effective, which only requires dozens of queries to the network
while producing target-related saliency maps. As a result, Group-CAM can be
served as an effective data augment trick for fine-tuning the networks. We
comprehensively evaluate the performance of Group-CAM on common-used
benchmarks, including deletion and insertion tests on ImageNet-1k, and pointing
game tests on COCO2017. Extensive experimental results demonstrate that
Group-CAM achieves better visual performance than the current state-of-the-art
explanation approaches. The code is available at
https://github.com/wofmanaf/Group-CAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention to Warp: Deep Metric Learning for Multivariate Time Series. (arXiv:2103.15074v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matsuo_S/0/1/0/all/0/1">Shinnosuke Matsuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaomeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Atarsaikhan_G/0/1/0/all/0/1">Gantugs Atarsaikhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1">Akisato Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashino_K/0/1/0/all/0/1">Kunio Kashino</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1">Brian Kenji Iwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15074">
                                    <div class="article-summary-box-inner">
                                        <span>Deep time series metric learning is challenging due to the difficult
trade-off between temporal invariance to nonlinear distortion and
discriminative power in identifying non-matching sequences. This paper proposes
a novel neural network-based approach for robust yet discriminative time series
classification and verification. This approach adapts a parameterized attention
model to time warping for greater and more adaptive temporal invariance. It is
robust against not only local but also large global distortions, so that even
matching pairs that do not satisfy the monotonicity, continuity, and boundary
conditions can still be successfully identified. Learning of this model is
further guided by dynamic time warping to impose temporal constraints for
stabilized training and higher discriminative power. It can learn to augment
the inter-class variation through warping, so that similar but different
classes can be effectively distinguished. We experimentally demonstrate the
superiority of the proposed approach over previous non-parametric and deep
models by combining it with a deep online signature verification framework,
after confirming its promising behavior in single-letter handwriting
classification on the Unipen dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis Towards Classification of Infection and Ischaemia of Diabetic Foot Ulcers. (arXiv:2104.03068v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yap_M/0/1/0/all/0/1">Moi Hoon Yap</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassidy_B/0/1/0/all/0/1">Bill Cassidy</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappachan_J/0/1/0/all/0/1">Joseph M. Pappachan</a>, <a href="http://arxiv.org/find/cs/1/au:+OShea_C/0/1/0/all/0/1">Claire O&#x27;Shea</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillespie_D/0/1/0/all/0/1">David Gillespie</a>, <a href="http://arxiv.org/find/cs/1/au:+Reeves_N/0/1/0/all/0/1">Neil Reeves</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03068">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the Diabetic Foot Ulcers dataset (DFUC2021) for
analysis of pathology, focusing on infection and ischaemia. We describe the
data preparation of DFUC2021 for ground truth annotation, data curation and
data analysis. The final release of DFUC2021 consists of 15,683 DFU patches,
with 5,955 training, 5,734 for testing and 3,994 unlabeled DFU patches. The
ground truth labels are four classes, i.e. control, infection, ischaemia and
both conditions. We curate the dataset using image hashing techniques and
analyse the separability using UMAP projection. We benchmark the performance of
five key backbones of deep learning, i.e. VGG16, ResNet101, InceptionV3,
DenseNet121 and EfficientNet on DFUC2021. We report the optimised results of
these key backbones with different strategies. Based on our observations, we
conclude that EfficientNetB0 with data augmentation and transfer learning
provided the best results for multi-class (4-class) classification with
macro-average Precision, Recall and F1-score of 0.57, 0.62 and 0.55,
respectively. In ischaemia and infection recognition, when trained on
one-versus-all, EfficientNetB0 achieved comparable results with the state of
the art. Finally, we interpret the results with statistical analysis and
Grad-CAM visualisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1">Roland S. Zimmermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1">Steffen Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1">Matthias Bethge</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08850">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning has recently seen tremendous success in self-supervised
learning. So far, however, it is largely unclear why the learned
representations generalize so effectively to a large variety of downstream
tasks. We here prove that feedforward models trained with objectives belonging
to the commonly used InfoNCE family learn to implicitly invert the underlying
generative model of the observed data. While the proofs make certain
statistical assumptions about the generative model, we observe empirically that
our findings hold even if these assumptions are severely violated. Our theory
highlights a fundamental connection between contrastive learning, generative
modeling, and nonlinear independent component analysis, thereby furthering our
understanding of the learned representations as well as providing a theoretical
foundation to derive more effective contrastive losses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis. (arXiv:2103.15348v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zejiang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruochen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dell_M/0/1/0/all/0/1">Melissa Dell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Benjamin Charles Germain Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlson_J/0/1/0/all/0/1">Jacob Carlson</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weining Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15348">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in document image analysis (DIA) have been primarily driven
by the application of neural networks. Ideally, research outcomes could be
easily deployed in production and extended for further investigation. However,
various factors like loosely organized codebases and sophisticated model
configurations complicate the easy reuse of important innovations by a wide
audience. Though there have been on-going efforts to improve reusability and
simplify deep learning (DL) model development in disciplines like natural
language processing and computer vision, none of them are optimized for
challenges in the domain of DIA. This represents a major gap in the existing
toolkit, as DIA is central to academic research across a wide range of
disciplines in the social sciences and humanities. This paper introduces
layoutparser, an open-source library for streamlining the usage of DL in DIA
research and applications. The core layoutparser library comes with a set of
simple and intuitive interfaces for applying and customizing DL models for
layout detection, character recognition, and many other document processing
tasks. To promote extensibility, layoutparser also incorporates a community
platform for sharing both pre-trained models and full document digitization
pipelines. We demonstrate that layoutparser is helpful for both lightweight and
large-scale digitization pipelines in real-word use cases. The library is
publicly available at https://layout-parser.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EDDA: Explanation-driven Data Augmentation to Improve Model and Explanation Alignment. (arXiv:2105.14162v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruiwen Li</a> (co-first author), <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhibo Zhang</a> (co-first author), <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiani Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1">Jongseong Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1">Yeonjeong Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shim_D/0/1/0/all/0/1">Dongsub Shim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14162">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen the introduction of a range of methods for post-hoc
explainability of image classifier predictions. However, these post-hoc
explanations may not always align perfectly with classifier predictions, which
poses a significant challenge when attempting to debug models based on such
explanations. To this end, we seek a methodology that can improve alignment
between model predictions and explanation method that is both agnostic to the
model and explanation classes and which does not require ground truth
explanations. We achieve this through a novel explanation-driven data
augmentation (EDDA) method that augments the training data with occlusions of
existing data stemming from model-explanations; this is based on the simple
motivating principle that occluding salient regions for the model prediction
should decrease the model confidence in the prediction, while occluding
non-salient regions should not change the prediction -- if the model and
explainer are aligned. To verify that this augmentation method improves model
and explainer alignment, we evaluate the methodology on a variety of datasets,
image classification models, and explanation methods. We verify in all cases
that our explanation-driven data augmentation method improves alignment of the
model and explanation in comparison to no data augmentation and non-explanation
driven data augmentation methods. In conclusion, this approach provides a novel
model- and explainer-agnostic methodology for improving alignment between model
predictions and explanations, which we see as a critical step forward for
practical deployment and debugging of image classification models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning for Gastritis Detection with Gastric X-ray Images. (arXiv:2104.02864v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Togo_R/0/1/0/all/0/1">Ren Togo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogawa_T/0/1/0/all/0/1">Takahiro Ogawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Haseyama_M/0/1/0/all/0/1">Miki Haseyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02864">
                                    <div class="article-summary-box-inner">
                                        <span>Background and Objective: Manually annotating gastric X-ray images for
gastritis detection is time-consuming and expensive because it typically
requires expert knowledge. This paper proposes a self-supervised learning
method to solve this problem. This study aims to verify the effectiveness of
the proposed self-supervised learning method in gastritis detection using a few
annotated gastric X-ray images. Methods: In this paper, we propose a novel
self-supervised learning method that can perform explicit self-supervised
learning and learn discriminative representations from gastric X-ray images.
Models trained with the proposed method were fine-tuned on datasets with a few
annotated gastric X-ray images. For comparison, several state-of-the-art
self-supervised learning methods, i.e., containing SimSiam, BYOL, PIRL-jigsaw,
PIRL-rotation, and SimCLR, were compared with the proposed method. Furthermore,
two baseline methods, one pretrained on ImageNet and the other trained from
scratch, were compared with the proposed method. Results: The proposed method&#x27;s
harmonic mean score of sensitivity and specificity after fine-tuning with the
annotated data of 10, 20, 30, and 40 patients were 0.875, 0.911, 0.915, and
0.931, respectively. The proposed method outperformed all comparative methods,
including the five state-of-the-art self-supervised learning and two baseline
methods. Experimental results showed the effectiveness of the proposed method
in gastritis detection with a few annotated gastric X-ray images. Conclusions:
The proposed self-supervised learning method shows potential for clinical use
in gastritis detection using a few annotated gastric X-ray images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Animal ID Problem: Continual Curation. (arXiv:2106.10377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1">Charles V. Stewart</a>, <a href="http://arxiv.org/find/cs/1/au:+Parham_J/0/1/0/all/0/1">Jason R. Parham</a>, <a href="http://arxiv.org/find/cs/1/au:+Holmberg_J/0/1/0/all/0/1">Jason Holmberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1">Tanya Y. Berger-Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10377">
                                    <div class="article-summary-box-inner">
                                        <span>Hoping to stimulate new research in individual animal identification from
images, we propose to formulate the problem as the human-machine Continual
Curation of images and animal identities. This is an open world recognition
problem, where most new animals enter the system after its algorithms are
initially trained and deployed. Continual Curation, as defined here, requires
(1) an improvement in the effectiveness of current recognition methods, (2) a
pairwise verification algorithm that allows the possibility of no decision, and
(3) an algorithmic decision mechanism that seeks human input to guide the
curation process. Error metrics must evaluate the ability of recognition
algorithms to identify not only animals that have been seen just once or twice
but also recognize new animals not in the database. An important measure of
overall system performance is accuracy as a function of the amount of human
input required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Hierarchical Variational Autoencoders for Large-Scale Video Prediction. (arXiv:2103.04174v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bohan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Suraj Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Martin-Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04174">
                                    <div class="article-summary-box-inner">
                                        <span>A video prediction model that generalizes to diverse scenes would enable
intelligent agents such as robots to perform a variety of tasks via planning
with the model. However, while existing video prediction models have produced
promising results on small datasets, they suffer from severe underfitting when
trained on large and diverse datasets. To address this underfitting challenge,
we first observe that the ability to train larger video prediction models is
often bottlenecked by the memory constraints of GPUs or TPUs. In parallel, deep
hierarchical latent variable models can produce higher quality predictions by
capturing the multi-level stochasticity of future observations, but end-to-end
optimization of such models is notably difficult. Our key insight is that
greedy and modular optimization of hierarchical autoencoders can simultaneously
address both the memory constraints and the optimization challenges of
large-scale video prediction. We introduce Greedy Hierarchical Variational
Autoencoders (GHVAEs), a method that learns high-fidelity video predictions by
greedily training each level of a hierarchical autoencoder. In comparison to
state-of-the-art models, GHVAEs provide 17-55% gains in prediction performance
on four video datasets, a 35-40% higher success rate on real robot tasks, and
can improve performance monotonically by simply adding more modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recent Advances in Large Margin Learning. (arXiv:2103.13598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiwen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13598">
                                    <div class="article-summary-box-inner">
                                        <span>This paper serves as a survey of recent advances in large margin training and
its theoretical foundations, mostly for (nonlinear) deep neural networks (DNNs)
that are probably the most prominent machine learning models for large-scale
data in the community over the past decade. We generalize the formulation of
classification margins from classical research to latest DNNs, summarize
theoretical connections between the margin, network generalization, and
robustness, and introduce recent efforts in enlarging the margins for DNNs
comprehensively. Since the viewpoint of different methods is discrepant, we
categorize them into groups for ease of comparison and discussion in the paper.
Hopefully, our discussions and overview inspire new research work in the
community that aim to improve the performance of DNNs, and we also point to
directions where the large margin principle can be verified to provide
theoretical evidence why certain regularizations for DNNs function well in
practice. We managed to shorten the paper such that the crucial spirit of large
margin learning and related methods are better emphasized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2 Visual Field Data based on Retinal Structure. (arXiv:2010.07488v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1">Shounak Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mariottoni_E/0/1/0/all/0/1">Eduardo B. Mariottoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dov_D/0/1/0/all/0/1">David Dov</a>, <a href="http://arxiv.org/find/cs/1/au:+Jammal_A/0/1/0/all/0/1">Alessandro A. Jammal</a>, <a href="http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/cs/1/au:+Medeiros_F/0/1/0/all/0/1">Felipe A. Medeiros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07488">
                                    <div class="article-summary-box-inner">
                                        <span>Glaucoma is the leading cause of irreversible blindness in the world,
affecting over 70 million people. The cumbersome Standard Automated Perimetry
(SAP) test is most frequently used to detect visual loss due to glaucoma. Due
to the SAP test&#x27;s innate difficulty and its high test-retest variability, we
propose the RetiNerveNet, a deep convolutional recursive neural network for
obtaining estimates of the SAP visual field. RetiNerveNet uses information from
the more objective Spectral-Domain Optical Coherence Tomography (SDOCT).
RetiNerveNet attempts to trace-back the arcuate convergence of the retinal
nerve fibers, starting from the Retinal Nerve Fiber Layer (RNFL) thickness
around the optic disc, to estimate individual age-corrected 24-2 SAP values.
Recursive passes through the proposed network sequentially yield estimates of
the visual locations progressively farther from the optic disc. While all the
methods used for our experiments exhibit lower performance for the advanced
disease group, the proposed network is observed to be more accurate than all
the baselines for estimating the individual visual field values. We further
augment RetiNerveNet to additionally predict the SAP Mean Deviation values and
also create an ensemble of RetiNerveNets that further improves the performance,
by increasingly weighting-up underrepresented parts of the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural Networks via Guided Distribution Calibration. (arXiv:2102.08946v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhiqiang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zechun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Kwang-Ting Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1">Marios Savvides</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08946">
                                    <div class="article-summary-box-inner">
                                        <span>Previous studies dominantly target at self-supervised learning on real-valued
networks and have achieved many promising results. However, on the more
challenging binary neural networks (BNNs), this task has not yet been fully
explored in the community. In this paper, we focus on this more difficult
scenario: learning networks where both weights and activations are binary,
meanwhile, without any human annotated labels. We observe that the commonly
used contrastive objective is not satisfying on BNNs for competitive accuracy,
since the backbone network contains relatively limited capacity and
representation ability. Hence instead of directly applying existing
self-supervised methods, which cause a severe decline in performance, we
present a novel guided learning paradigm from real-valued to distill binary
networks on the final prediction distribution, to minimize the loss and obtain
desirable accuracy. Our proposed method can boost the simple contrastive
learning baseline by an absolute gain of 5.5~15% on BNNs. We further reveal
that it is difficult for BNNs to recover the similar predictive distributions
as real-valued models when training without labels. Thus, how to calibrate them
is key to address the degradation in performance. Extensive experiments are
conducted on the large-scale ImageNet and downstream datasets. Our method
achieves substantial improvement over the simple contrastive learning baseline,
and is even comparable to many mainstream supervised BNN methods. Code is
available at https://github.com/szq0214/S2-BNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intriguing Properties of Contrastive Losses. (arXiv:2011.02803v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Calvin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lala Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02803">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive loss and its variants have become very popular recently for
learning visual representations without supervision. In this work, we study
three intriguing properties of contrastive learning. We first generalize the
standard contrastive loss to a broader family of losses, and we find that
various instantiations of the generalized loss perform similarly under the
presence of a multi-layer non-linear projection head. We then study if
instance-based contrastive learning (such as in SimCLR, MoCo, BYOL, and so on,
which are based on global image representation) can learn well on images with
multiple objects present. We find that meaningful hierarchical local features
can be learned despite the fact that these objectives operate on global
instance-level features.

Finally, we study an intriguing phenomenon of feature suppression among
competing features shared across augmented views, such as &quot;color distribution&quot;
vs &quot;object class&quot;. We construct datasets with explicit and controllable
competing features, and show that, for contrastive learning, a few bits of
easy-to-learn shared features can suppress, and even fully prevent, the
learning of other sets of competing features. In scenarios where there are
multiple objects in an image, the dominant object would suppress the learning
of smaller objects. Existing contrastive learning methods critically rely on
data augmentation to favor certain sets of features over others, and face
potential limitation for scenarios where existing augmentations cannot fully
address the feature suppression. This poses open challenges to existing
contrastive learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Stitching Algorithm for Automated Surface Inspection of Rotationally Symmetric Components. (arXiv:2012.00308v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlagenhauf_T/0/1/0/all/0/1">Tobias Schlagenhauf</a>, <a href="http://arxiv.org/find/cs/1/au:+Brander_T/0/1/0/all/0/1">Tim Brander</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleischer_J/0/1/0/all/0/1">Juergen Fleischer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00308">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides a novel approach to stitching surface images of
rotationally symmetric parts. It presents a process pipeline that uses a
feature-based stitching approach to create a distortion-free and true-to-life
image from a video file. The developed process thus enables, for example,
condition monitoring without having to view many individual images. For
validation purposes, this will be demonstrated in the paper using the concrete
example of a worn ball screw drive spindle. The developed algorithm aims at
reproducing the functional principle of a line scan camera system, whereby the
physical measuring systems are replaced by a feature-based approach. For
evaluation of the stitching algorithms, metrics are used, some of which have
only been developed in this work or have been supplemented by test procedures
already in use. The applicability of the developed algorithm is not only
limited to machine tool spindles. Instead, the developed method allows a
general approach to the surface inspection of various rotationally symmetric
components and can therefore be used in a variety of industrial applications.
Deep-learning-based detection Algorithms can easily be implemented to generate
a complete pipeline for failure detection and condition monitoring on
rotationally symmetric parts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LEGAN: Disentangled Manipulation of Directional Lighting and Facial Expressions by Leveraging Human Perceptual Judgements. (arXiv:2010.01464v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Sandipan Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Ajjen Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_P/0/1/0/all/0/1">Prashant Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sneha Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyal_S/0/1/0/all/0/1">Survi Kyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_T/0/1/0/all/0/1">Taniya Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01464">
                                    <div class="article-summary-box-inner">
                                        <span>Building facial analysis systems that generalize to extreme variations in
lighting and facial expressions is a challenging problem that can potentially
be alleviated using natural-looking synthetic data. Towards that, we propose
LEGAN, a novel synthesis framework that leverages perceptual quality judgments
for jointly manipulating lighting and expressions in face images, without
requiring paired training data. LEGAN disentangles the lighting and expression
subspaces and performs transformations in the feature space before upscaling to
the desired output image. The fidelity of the synthetic image is further
refined by integrating a perceptual quality estimation model, trained with face
images rendered using multiple synthesis methods and their crowd-sourced
naturalness ratings, into the LEGAN framework as an auxiliary discriminator.
Using objective metrics like FID and LPIPS, LEGAN is shown to generate higher
quality face images when compared with popular GAN models like StarGAN and
StarGAN-v2 for lighting and expression synthesis. We also conduct a perceptual
study using images synthesized by LEGAN and other GAN models and show the
correlation between our quality estimation and visual fidelity. Finally, we
demonstrate the effectiveness of LEGAN as training data augmenter for
expression recognition and face verification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Object Detection with Pointformer. (arXiv:2012.11409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xuran Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1">Zhuofan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Li Erran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11409">
                                    <div class="article-summary-box-inner">
                                        <span>Feature learning for 3D object detection from point clouds is very
challenging due to the irregularity of 3D point cloud data. In this paper, we
propose Pointformer, a Transformer backbone designed for 3D point clouds to
learn features effectively. Specifically, a Local Transformer module is
employed to model interactions among points in a local region, which learns
context-dependent region features at an object level. A Global Transformer is
designed to learn context-aware representations at the scene level. To further
capture the dependencies among multi-scale representations, we propose
Local-Global Transformer to integrate local features with global features from
higher resolution. In addition, we introduce an efficient coordinate refinement
module to shift down-sampled points closer to object centroids, which improves
object proposal generation. We use Pointformer as the backbone for
state-of-the-art object detection models and demonstrate significant
improvements over original models on both indoor and outdoor datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unlocking Pixels for Reinforcement Learning via Implicit Attention. (arXiv:2102.04353v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Deepali Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1">Valerii Likhosherstov</a>, <a href="http://arxiv.org/find/cs/1/au:+Santara_A/0/1/0/all/0/1">Anirban Santara</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yunhao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04353">
                                    <div class="article-summary-box-inner">
                                        <span>There has recently been significant interest in training reinforcement
learning (RL) agents in vision-based environments. This poses many challenges,
such as high dimensionality and potential for observational overfitting through
spurious correlations. A promising approach to solve both of these problems is
a self-attention bottleneck, which provides a simple and effective framework
for learning high performing policies, even in the presence of distractions.
However, due to poor scalability of attention architectures, these methods do
not scale beyond low resolution visual inputs, using large patches (thus small
attention matrices). In this paper we make use of new efficient attention
algorithms, recently shown to be highly effective for Transformers, and
demonstrate that these new techniques can be applied in the RL setting. This
allows our attention-based controllers to scale to larger visual inputs, and
facilitate the use of smaller patches, even individual pixels, improving
generalization. In addition, we propose a new efficient algorithm approximating
softmax attention with what we call hybrid random features, leveraging the
theory of angular kernels. We show theoretically and empirically that hybrid
random features is a promising approach when using attention for vision-based
RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Representation Learning with Feedback for Single Image Deraining. (arXiv:2101.12463v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1">Chenghao Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12463">
                                    <div class="article-summary-box-inner">
                                        <span>A deraining network can be interpreted as a conditional generator that aims
at removing rain streaks from image. Most existing image deraining methods
ignore model errors caused by uncertainty that reduces embedding quality.
Unlike existing image deraining methods that embed low-quality features into
the model directly, we replace low-quality features by latent high-quality
features. The spirit of closed-loop feedback in the automatic control field is
borrowed to obtain latent high-quality features. A new method for error
detection and feature compensation is proposed to address model errors.
Extensive experiments on benchmark datasets as well as specific real datasets
demonstrate that the proposed method outperforms recent state-of-the-art
methods. Code is available at: \\ https://github.com/LI-Hao-SJTU/DerainRLNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Space-time Neural Irradiance Fields for Free-Viewpoint Video. (arXiv:2011.12950v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xian_W/0/1/0/all/0/1">Wenqi Xian</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jia-Bin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopf_J/0/1/0/all/0/1">Johannes Kopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Changil Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12950">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method that learns a spatiotemporal neural irradiance field for
dynamic scenes from a single video. Our learned representation enables
free-viewpoint rendering of the input video. Our method builds upon recent
advances in implicit representations. Learning a spatiotemporal irradiance
field from a single video poses significant challenges because the video
contains only one observation of the scene at any point in time. The 3D
geometry of a scene can be legitimately represented in numerous ways since
varying geometry (motion) can be explained with varying appearance and vice
versa. We address this ambiguity by constraining the time-varying geometry of
our dynamic scene representation using the scene depth estimated from video
depth estimation methods, aggregating contents from individual frames into a
single global representation. We provide an extensive quantitative evaluation
and demonstrate compelling free-viewpoint rendering results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Distortion for Learned Video Compression. (arXiv:2004.09508v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Veerabadran_V/0/1/0/all/0/1">Vijay Veerabadran</a>, <a href="http://arxiv.org/find/eess/1/au:+Pourreza_R/0/1/0/all/0/1">Reza Pourreza</a>, <a href="http://arxiv.org/find/eess/1/au:+Habibian_A/0/1/0/all/0/1">Amirhossein Habibian</a>, <a href="http://arxiv.org/find/eess/1/au:+Cohen_T/0/1/0/all/0/1">Taco Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09508">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel adversarial lossy video compression model.
At extremely low bit-rates, standard video coding schemes suffer from
unpleasant reconstruction artifacts such as blocking, ringing etc. Existing
learned neural approaches to video compression have achieved reasonable success
on reducing the bit-rate for efficient transmission and reduce the impact of
artifacts to an extent. However, they still tend to produce blurred results
under extreme compression. In this paper, we present a deep adversarial learned
video compression model that minimizes an auxiliary adversarial distortion
objective. We find this adversarial objective to correlate better with human
perceptual quality judgement relative to traditional quality metrics such as
MS-SSIM and PSNR. Our experiments using a state-of-the-art learned video
compression system demonstrate a reduction of perceptual artifacts and
reconstruction of detail lost especially under extremely high compression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Semantic Description of Objects based on Prototype Theory. (arXiv:1906.03365v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pino_O/0/1/0/all/0/1">Omar Vidal Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1">Erickson Rangel Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Campos_M/0/1/0/all/0/1">Mario Fernando Montenegro Campos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.03365">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a novel semantic description approach inspired on
Prototype Theory foundations. We propose a Computational Prototype Model (CPM)
that encodes and stores the central semantic meaning of objects category: the
semantic prototype. Also, we introduce a Prototype-based Description Model that
encodes the semantic meaning of an object while describing its features using
our CPM model. Our description method uses semantic prototypes computed by
CNN-classifications models to create discriminative signatures that describe an
object highlighting its most distinctive features within the category. Our
experiments show that: i) our CPM model (semantic prototype + distance metric)
is able to describe the internal semantic structure of objects categories; ii)
our semantic distance metric can be understood as the object visual typicality
score within a category; iii) our descriptor encoding is semantically
interpretable and significantly outperforms other image global encodings in
clustering and classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Invariant Adversarial Learning. (arXiv:2104.00322v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levi_M/0/1/0/all/0/1">Matan Levi</a>, <a href="http://arxiv.org/find/cs/1/au:+Attias_I/0/1/0/all/0/1">Idan Attias</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1">Aryeh Kontorovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00322">
                                    <div class="article-summary-box-inner">
                                        <span>The phenomenon of adversarial examples illustrates one of the most basic
vulnerabilities of deep neural networks. Among the variety of techniques
introduced to surmount this inherent weakness, adversarial training has emerged
as the most common and efficient strategy to achieve robustness. Typically,
this is achieved by balancing robust and natural objectives. In this work, we
aim to achieve better trade-off between robust and natural performances by
enforcing a domain-invariant feature representation. We present a new
adversarial training method, Domain Invariant Adversarial Learning (DIAL),
which learns a feature representation which is both robust and domain
invariant. DIAL uses a variant of Domain Adversarial Neural Network (DANN) on
the natural domain and its corresponding adversarial domain. In a case where
the source domain consists of natural examples and the target domain is the
adversarially perturbed examples, our method learns a feature representation
constrained not to discriminate between the natural and adversarial examples,
and can therefore achieve a more robust representation. Our experiments
indicate that our method improves both robustness and natural accuracy, when
compared to current state-of-the-art adversarial training methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Localize in New Environments from Synthetic Training Data. (arXiv:2011.04539v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Winkelbauer_D/0/1/0/all/0/1">Dominik Winkelbauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Denninger_M/0/1/0/all/0/1">Maximilian Denninger</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04539">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing approaches for visual localization either need a detailed 3D
model of the environment or, in the case of learning-based methods, must be
retrained for each new scene. This can either be very expensive or simply
impossible for large, unknown environments, for example in search-and-rescue
scenarios. Although there are learning-based approaches that operate
scene-agnostically, the generalization capability of these methods is still
outperformed by classical approaches. In this paper, we present an approach
that can generalize to new scenes by applying specific changes to the model
architecture, including an extended regression part, the use of hierarchical
correlation layers, and the exploitation of scale and uncertainty information.
Our approach outperforms the 5-point algorithm using SIFT features on equally
big images and additionally surpasses all previous learning-based approaches
that were trained on different data. It is also superior to most of the
approaches that were specifically trained on the respective scenes. We also
evaluate our approach in a scenario where only very few reference images are
available, showing that under such more realistic conditions our learning-based
approach considerably exceeds both existing learning-based and classical
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Object Detection for Autonomous Driving: A Survey. (arXiv:2106.10823v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1">Xin Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xirong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10823">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous driving is regarded as one of the most promising remedies to
shield human beings from severe crashes. To this end, 3D object detection
serves as the core basis of such perception system especially for the sake of
path planning, motion prediction, collision avoidance, etc. Generally, stereo
or monocular images with corresponding 3D point clouds are already standard
layout for 3D object detection, out of which point clouds are increasingly
prevalent with accurate depth information being provided. Despite existing
efforts, 3D object detection on point clouds is still in its infancy due to
high sparseness and irregularity of point clouds by nature, misalignment view
between camera view and LiDAR bird&#x27;s eye of view for modality synergies,
occlusions and scale variations at long distances, etc. Recently, profound
progress has been made in 3D object detection, with a large body of literature
being investigated to address this vision task. As such, we present a
comprehensive review of the latest progress in this field covering all the main
topics including sensors, fundamentals, and the recent state-of-the-art
detection methods with their pros and cons. Furthermore, we introduce metrics
and provide quantitative comparisons on popular public datasets. The avenues
for future work are going to be judiciously identified after an in-deep
analysis of the surveyed works. Finally, we conclude this paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Survey of Regularization and Normalization in GANs. (arXiv:2008.08930v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xintian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1">Muhammad Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1">Rentuo Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_P/0/1/0/all/0/1">Pengfei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08930">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have been widely applied in different
scenarios thanks to the development of deep neural networks. The original GAN
was proposed based on the non-parametric assumption of the infinite capacity of
networks. However, it is still unknown whether GANs can generate realistic
samples without any prior information. Due to the overconfident assumption,
many issues remain unaddressed in GANs&#x27; training, such as non-convergence, mode
collapses, gradient vanishing. Regularization and normalization are common
methods of introducing prior information to stabilize training and improve
discrimination. Although a handful number of regularization and normalization
methods have been proposed for GANs, to the best of our knowledge, there exists
no comprehensive survey which primarily focuses on objectives and development
of these methods, apart from some in-comprehensive and limited scope studies.
In this work, we conduct a comprehensive survey on the regularization and
normalization techniques from different perspectives of GANs training. First,
we systematically describe different perspectives of GANs training and thus
obtain the different objectives of regularization and normalization. Based on
these objectives, we propose a new taxonomy. Furthermore, we compare the
performance of the mainstream methods on different datasets and investigate the
regularization and normalization techniques that have been frequently employed
in SOTA GANs. Finally, we highlight potential future directions of research in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12135">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial learning has emerged as one of the successful techniques to
circumvent the susceptibility of existing methods against adversarial
perturbations. However, the majority of existing defense methods are tailored
to defend against a single category of adversarial perturbation (e.g.
$\ell_\infty$-attack). In safety-critical applications, this makes these
methods extraneous as the attacker can adopt diverse adversaries to deceive the
system. Moreover, training on multiple perturbations simultaneously
significantly increases the computational overhead during training. To address
these challenges, we propose a novel meta-learning framework that explicitly
learns to generate noise to improve the model&#x27;s robustness against multiple
types of attacks. Its key component is Meta Noise Generator (MNG) that outputs
optimal noise to stochastically perturb a given sample, such that it helps
lower the error on diverse adversarial perturbations. By utilizing samples
generated by MNG, we train a model by enforcing the label consistency across
multiple perturbations. We validate the robustness of models trained by our
scheme on various datasets and against a wide variety of perturbations,
demonstrating that it significantly outperforms the baselines across multiple
perturbations with a marginal computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Face Manipulation Detection via Feature Whitening. (arXiv:2106.10834v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yingying Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengju Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Shiming Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10834">
                                    <div class="article-summary-box-inner">
                                        <span>Why should we trust the detections of deep neural networks for manipulated
faces? Understanding the reasons is important for users in improving the
fairness, reliability, privacy and trust of the detection models. In this work,
we propose an interpretable face manipulation detection approach to achieve the
trustworthy and accurate inference. The approach could make the face
manipulation detection process transparent by embedding the feature whitening
module. This module aims to whiten the internal working mechanism of deep
networks through feature decorrelation and feature constraint. The experimental
results demonstrate that our proposed approach can strike a balance between the
detection accuracy and the model interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term Pedestrian Trajectory Prediction using Mutable Intention Filter and Warp LSTM. (arXiv:2007.00113v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Aamir Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1">Kazuki Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruohua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1">Katherine Driggs-Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00113">
                                    <div class="article-summary-box-inner">
                                        <span>Trajectory prediction is one of the key capabilities for robots to safely
navigate and interact with pedestrians. Critical insights from human intention
and behavioral patterns need to be integrated to effectively forecast long-term
pedestrian behavior. Thus, we propose a framework incorporating a Mutable
Intention Filter and a Warp LSTM (MIF-WLSTM) to simultaneously estimate human
intention and perform trajectory prediction. The Mutable Intention Filter is
inspired by particle filtering and genetic algorithms, where particles
represent intention hypotheses that can be mutated throughout the pedestrian
motion. Instead of predicting sequential displacement over time, our Warp LSTM
learns to generate offsets on a full trajectory predicted by a nominal
intention-aware linear model, which considers the intention hypotheses during
filtering process. Through experiments on a publicly available dataset, we show
that our method outperforms baseline approaches and demonstrate the robust
performance of our method under abnormal intention-changing scenarios. Code is
available at https://github.com/tedhuang96/mifwlstm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solution for Large-scale Long-tailed Recognition with Noisy Labels. (arXiv:2106.10683v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1">Yuqiao Xian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jia-Xin Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fufu Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10683">
                                    <div class="article-summary-box-inner">
                                        <span>This is a technical report for CVPR 2021 AliProducts Challenge. AliProducts
Challenge is a competition proposed for studying the large-scale and
fine-grained commodity image recognition problem encountered by worldleading
ecommerce companies. The large-scale product recognition simultaneously meets
the challenge of noisy annotations, imbalanced (long-tailed) data distribution
and fine-grained classification. In our solution, we adopt stateof-the-art
model architectures of both CNNs and Transformer, including ResNeSt,
EfficientNetV2, and DeiT. We found that iterative data cleaning, classifier
weight normalization, high-resolution finetuning, and test time augmentation
are key components to improve the performance of training with the noisy and
imbalanced dataset. Finally, we obtain 6.4365% mean class error rate in the
leaderboard with our ensemble model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Assessment of Generalization Performance Robustness for Deep Networks via Contrastive Examples. (arXiv:2106.10653v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuanyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10653">
                                    <div class="article-summary-box-inner">
                                        <span>Training images with data transformations have been suggested as contrastive
examples to complement the testing set for generalization performance
evaluation of deep neural networks (DNNs). In this work, we propose a practical
framework ContRE (The word &quot;contre&quot; means &quot;against&quot; or &quot;versus&quot; in French.)
that uses Contrastive examples for DNN geneRalization performance Estimation.
Specifically, ContRE follows the assumption in contrastive learning that robust
DNN models with good generalization performance are capable of extracting a
consistent set of features and making consistent predictions from the same
image under varying data transformations. Incorporating with a set of
randomized strategies for well-designed data transformations over the training
set, ContRE adopts classification errors and Fisher ratios on the generated
contrastive examples to assess and analyze the generalization performance of
deep models in complement with a testing set. To show the effectiveness and the
efficiency of ContRE, extensive experiments have been done using various DNN
models on three open source benchmark datasets with thorough ablation studies
and applicability analyses. Our experiment results confirm that (1) behaviors
of deep models on contrastive examples are strongly correlated to what on the
testing set, and (2) ContRE is a robust measure of generalization performance
complementing to the testing set in various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ToAlign: Task-oriented Alignment for Unsupervised Domain Adaptation. (arXiv:2106.10812v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1">Guoqiang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10812">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptive classification intends to improve
theclassification performance on unlabeled target domain. To alleviate the
adverse effect of domain shift, many approaches align the source and target
domains in the feature space. However, a feature is usually taken as a whole
for alignment without explicitly making domain alignment proactively serve the
classification task, leading to sub-optimal solution. What sub-feature should
be aligned for better adaptation is under-explored. In this paper, we propose
an effective Task-oriented Alignment (ToAlign) for unsupervised domain
adaptation (UDA). We study what features should be aligned across domains and
propose to make the domain alignment proactively serve classification by
performing feature decomposition and alignment under the guidance of the prior
knowledge induced from the classification taskitself. Particularly, we
explicitly decompose a feature in the source domain intoa
task-related/discriminative feature that should be aligned, and a
task-irrelevant feature that should be avoided/ignored, based on the
classification meta-knowledge. Extensive experimental results on various
benchmarks (e.g., Office-Home, Visda-2017, and DomainNet) under different
domain adaptation settings demonstrate theeffectiveness of ToAlign which helps
achieve the state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quality-Aware Memory Network for Interactive Volumetric Image Segmentation. (arXiv:2106.10686v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianfei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liulei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bredell_G/0/1/0/all/0/1">Gustav Bredell</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianwu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1">Ender Konukoglu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10686">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent progress of automatic medical image segmentation techniques,
fully automatic results usually fail to meet the clinical use and typically
require further refinement. In this work, we propose a quality-aware memory
network for interactive segmentation of 3D medical images. Provided by user
guidance on an arbitrary slice, an interaction network is firstly employed to
obtain an initial 2D segmentation. The quality-aware memory network
subsequently propagates the initial segmentation estimation bidirectionally
over the entire volume. Subsequent refinement based on additional user guidance
on other slices can be incorporated in the same manner. To further facilitate
interactive segmentation, a quality assessment module is introduced to suggest
the next slice to segment based on the current segmentation quality of each
slice. The proposed network has two appealing characteristics: 1) The
memory-augmented network offers the ability to quickly encode past segmentation
information, which will be retrieved for the segmentation of other slices; 2)
The quality assessment module enables the model to directly estimate the
qualities of segmentation predictions, which allows an active learning paradigm
where users preferentially label the lowest-quality slice for multi-round
refinement. The proposed network leads to a robust interactive segmentation
engine, which can generalize well to various types of user annotations (e.g.,
scribbles, boxes). Experimental results on various medical datasets demonstrate
the superiority of our approach in comparison with existing techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile Sensing for Multipurpose Applications in Transportation. (arXiv:2106.10733v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aboah_A/0/1/0/all/0/1">Armstrong Aboah</a>, <a href="http://arxiv.org/find/cs/1/au:+Boeding_M/0/1/0/all/0/1">Michael Boeding</a>, <a href="http://arxiv.org/find/cs/1/au:+Adu_Gyamfi_Y/0/1/0/all/0/1">Yaw Adu-Gyamfi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10733">
                                    <div class="article-summary-box-inner">
                                        <span>Routine and consistent data collection is required to address contemporary
transportation issues.The cost of data collection increases significantly when
sophisticated machines are used to collect data. Due to this constraint, State
Departments of Transportation struggles to collect consistent data for
analyzing and resolving transportation problems in a timely manner. Recent
advancements in the sensors integrated into smartphones have resulted in a more
affordable method of data collection.The primary objective of this study is to
develop and implement a smartphone application for data collection.The
currently designed app consists of three major modules: a frontend graphical
user interface (GUI), a sensor module, and a backend module. While the frontend
user interface enables interaction with the app, the sensor modules collect
relevant data such as video and accelerometer readings while the app is in use.
The backend, on the other hand, is made up of firebase storage, which is used
to store the gathered data.In comparison to other developed apps for collecting
pavement information, this current app is not overly reliant on the internet
enabling the app to be used in areas of restricted internet access.The
developed application was evaluated by collecting data on the i70W highway
connecting Columbia, Missouri, and Kansas City, Missouri.The data was analyzed
for a variety of purposes, including calculating the International Roughness
Index (IRI), identifying pavement distresses, and understanding driver&#x27;s
behaviour and environment .The results of the application indicate that the
data collected by the app is of high quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Sparse R-CNN for Direct Scene Graph Generation. (arXiv:2106.10815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1">Yao Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10815">
                                    <div class="article-summary-box-inner">
                                        <span>Scene graph generation (SGG) is to detect entity pairs with their relations
in an image. Existing SGG approaches often use multi-stage pipelines to
decompose this task into object detection, relation graph construction, and
dense or dense-to-sparse relation prediction. Instead, from a perspective on
SGG as a direct set prediction, this paper presents a simple, sparse, and
unified framework for relation detection, termed as Structured Sparse R-CNN.
The key to our method is a set of learnable triplet queries and structured
triplet detectors which could be jointly optimized from the training set in an
end-to-end manner. Specifically, the triplet queries encode the general prior
for entity pair locations, categories, and their relations, and provide an
initial guess of relation detection for subsequent refinement. The triplet
detector presents a cascaded dynamic head design to progressively refine the
results of relation detection. In addition, to relieve the training difficulty
of Structured Sparse R-CNN, we propose a relaxed and enhanced training strategy
based on knowledge distillation from a Siamese Sparse R-CNN. We also propose
adaptive focusing parameter and average logit approach for imbalance data
distribution. We perform experiments on two benchmarks: Visual Genome and Open
Images, and the results demonstrate that our method achieves the
state-of-the-art performance. Meanwhile, we perform in-depth ablation studies
to provide insights on our structured modeling in triplet detector design and
training strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction. (arXiv:2106.10689v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Komura_T/0/1/0/all/0/1">Taku Komura</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10689">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel neural surface reconstruction method, called NeuS, for
reconstructing objects and scenes with high fidelity from 2D image inputs.
Existing neural surface reconstruction approaches, such as DVR and IDR, require
foreground mask as supervision, easily get trapped in local minima, and
therefore struggle with the reconstruction of objects with severe
self-occlusion or thin structures. Meanwhile, recent neural methods for novel
view synthesis, such as NeRF and its variants, use volume rendering to produce
a neural scene representation with robustness of optimization, even for highly
complex objects. However, extracting high-quality surfaces from this learned
implicit representation is difficult because there are not sufficient surface
constraints in the representation. In NeuS, we propose to represent a surface
as the zero-level set of a signed distance function (SDF) and develop a new
volume rendering method to train a neural SDF representation. We observe that
the conventional volume rendering method causes inherent geometric errors (i.e.
bias) for surface reconstruction, and therefore propose a new formulation that
is free of bias in the first order of approximation, thus leading to more
accurate surface reconstruction even without the mask supervision. Experiments
on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the
state-of-the-arts in high-quality surface reconstruction, especially for
objects and scenes with complex structures and self-occlusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for Visual Information Extraction using Sequences. (arXiv:2106.10681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiapeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Guozhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weihong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kai Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yichao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10681">
                                    <div class="article-summary-box-inner">
                                        <span>Visual information extraction (VIE) has attracted increasing attention in
recent years. The existing methods usually first organized optical character
recognition (OCR) results into plain texts and then utilized token-level entity
annotations as supervision to train a sequence tagging model. However, it
expends great annotation costs and may be exposed to label confusion, and the
OCR errors will also significantly affect the final performance. In this paper,
we propose a unified weakly-supervised learning framework called TCPN (Tag,
Copy or Predict Network), which introduces 1) an efficient encoder to
simultaneously model the semantic and layout information in 2D OCR results; 2)
a weakly-supervised training strategy that utilizes only key information
sequences as supervision; and 3) a flexible and switchable decoder which
contains two inference modes: one (Copy or Predict Mode) is to output key
information sequences of different categories by copying a token from the input
or predicting one in each time step, and the other (Tag Mode) is to directly
tag the input sequence in a single forward pass. Our method shows new
state-of-the-art performance on several public benchmarks, which fully proves
its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implementing a Detection System for COVID-19 based on Lung Ultrasound Imaging and Deep Learning. (arXiv:2106.10651v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rojas_Azabache_C/0/1/0/all/0/1">Carlos Rojas-Azabache</a>, <a href="http://arxiv.org/find/eess/1/au:+Vilca_Janampa_K/0/1/0/all/0/1">Karen Vilca-Janampa</a>, <a href="http://arxiv.org/find/eess/1/au:+Guerrero_Huayta_R/0/1/0/all/0/1">Renzo Guerrero-Huayta</a>, <a href="http://arxiv.org/find/eess/1/au:+Nunez_Fernandez_D/0/1/0/all/0/1">Dennis N&#xfa;&#xf1;ez-Fern&#xe1;ndez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10651">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 pandemic started in China in December 2019 and quickly spread to
several countries. The consequences of this pandemic are incalculable, causing
the death of millions of people and damaging the global economy. To achieve
large-scale control of this pandemic, fast tools for detection and treatment of
patients are needed. Thus, the demand for alternative tools for the diagnosis
of COVID-19 has increased dramatically since accurated and automated tools are
not available. In this paper we present the ongoing work on a system for
COVID-19 detection using ultrasound imaging and using Deep Learning techniques.
Furthermore, such a system is implemented on a Raspberry Pi to make it portable
and easy to use in remote regions without an Internet connection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-scale image segmentation based on distributed clustering algorithms. (arXiv:2106.10795v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Ran Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zlateski_A/0/1/0/all/0/1">Aleksandar Zlateski</a>, <a href="http://arxiv.org/find/cs/1/au:+Seung_H/0/1/0/all/0/1">H. Sebastian Seung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10795">
                                    <div class="article-summary-box-inner">
                                        <span>Many approaches to 3D image segmentation are based on hierarchical clustering
of supervoxels into image regions. Here we describe a distributed algorithm
capable of handling a tremendous number of supervoxels. The algorithm works
recursively, the regions are divided into chunks that are processed
independently in parallel by multiple workers. At each round of the recursive
procedure, the chunk size in all dimensions are doubled until a single chunk
encompasses the entire image. The final result is provably independent of the
chunking scheme, and the same as if the entire image were processed without
division into chunks. This is nontrivial because a pair of adjacent regions is
scored by some statistical property (e.g. mean or median) of the affinities at
the interface, and the interface may extend over arbitrarily many chunks. The
trick is to delay merge decisions for regions that touch chunk boundaries, and
only complete them in a later round after the regions are fully contained
within a chunk. We demonstrate the algorithm by clustering an affinity graph
with over 1.5 trillion edges between 135 billion supervoxels derived from a 3D
electron microscopic brain image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Manifold Matching via Deep Metric Learning for Generative Modeling. (arXiv:2106.10777v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_M/0/1/0/all/0/1">Mengyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hang_H/0/1/0/all/0/1">Haibin Hang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10777">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a manifold matching approach to generative models which includes a
distribution generator (or data generator) and a metric generator. In our
framework, we view the real data set as some manifold embedded in a
high-dimensional Euclidean space. The distribution generator aims at generating
samples that follow some distribution condensed around the real data manifold.
It is achieved by matching two sets of points using their geometric shape
descriptors, such as centroid and $p$-diameter, with learned distance metric;
the metric generator utilizes both real data and generated samples to learn a
distance metric which is close to some intrinsic geodesic distance on the real
data manifold. The produced distance metric is further used for manifold
matching. The two networks are learned simultaneously during the training
process. We apply the approach on both unsupervised and supervised learning
tasks: in unconditional image generation task, the proposed method obtains
competitive results compared with existing generative models; in
super-resolution task, we incorporate the framework in perception-based models
and improve visual qualities by producing samples with more natural textures.
Both theoretical analysis and real data experiments guarantee the feasibility
and effectiveness of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAMERAS: Enhanced Resolution And Sanity preserving Class Activation Mapping for image saliency. (arXiv:2106.10649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalwana_M/0/1/0/all/0/1">Mohammad A. A. K. Jalwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10649">
                                    <div class="article-summary-box-inner">
                                        <span>Backpropagation image saliency aims at explaining model predictions by
estimating model-centric importance of individual pixels in the input. However,
class-insensitivity of the earlier layers in a network only allows saliency
computation with low resolution activation maps of the deeper layers, resulting
in compromised image saliency. Remedifying this can lead to sanity failures. We
propose CAMERAS, a technique to compute high-fidelity backpropagation saliency
maps without requiring any external priors and preserving the map sanity. Our
method systematically performs multi-scale accumulation and fusion of the
activation maps and backpropagated gradients to compute precise saliency maps.
From accurate image saliency to articulation of relative importance of input
features for different models, and precise discrimination between model
perception of visually similar objects, our high-resolution mapping offers
multiple novel insights into the black-box deep visual models, which are
presented in the paper. We also demonstrate the utility of our saliency maps in
adversarial setup by drastically reducing the norm of attack signals by
focusing them on the precise regions identified by our maps. Our method also
inspires new evaluation metrics and a sanity check for this developing research
direction. Code is available here https://github.com/VisMIL/CAMERAS</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbalanced Feature Transport for Exemplar-based Image Translation. (arXiv:2106.10482v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kaiwen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jianxiong Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changgong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Feiying Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xuansong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10482">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great success of GANs in images translation with different
conditioned inputs such as semantic segmentation and edge maps, generating
high-fidelity realistic images with reference styles remains a grand challenge
in conditional image-to-image translation. This paper presents a general image
translation framework that incorporates optimal transport for feature alignment
between conditional inputs and style exemplars in image translation. The
introduction of optimal transport mitigates the constraint of many-to-one
feature matching significantly while building up accurate semantic
correspondences between conditional inputs and exemplars. We design a novel
unbalanced optimal transport to address the transport between features with
deviational distributions which exists widely between conditional inputs and
exemplars. In addition, we design a semantic-activation normalization scheme
that injects style features of exemplars into the image translation process
successfully. Extensive experiments over multiple image translation tasks show
that our method achieves superior image translation qualitatively and
quantitatively as compared with the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-to-many Approach for Improving Super-Resolution. (arXiv:2106.10437v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Sieun Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_E/0/1/0/all/0/1">Eunho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10437">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution (SR) is a one-to-many task with multiple possible solutions.
However, previous works were not concerned about this characteristic. For a
one-to-many pipeline, the generator should be able to generate multiple
estimates of the reconstruction, and not be penalized for generating similar
and equally realistic images. To achieve this, we propose adding weighted
pixel-wise noise after every Residual-in-Residual Dense Block (RRDB) to enable
the generator to generate various images. We modify the strict content loss to
not penalize the stochastic variation in reconstructed images as long as it has
consistent content. Additionally, we observe that there are out-of-focus
regions in the DIV2K, DIV8K datasets that provide unhelpful guidelines. We
filter blurry regions in the training data using the method of [10]. Finally,
we modify the discriminator to receive the low-resolution image as a reference
image along with the target image to provide better feedback to the generator.
Using our proposed methods, we were able to improve the performance of ESRGAN
in x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16
perceptual extreme SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of the facial growth direction with Machine Learning methods. (arXiv:2106.10464v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazmierczak_S/0/1/0/all/0/1">Stanis&#x142;aw Ka&#x17a;mierczak</a>, <a href="http://arxiv.org/find/cs/1/au:+Juszka_Z/0/1/0/all/0/1">Zofia Juszka</a>, <a href="http://arxiv.org/find/cs/1/au:+Fudalej_P/0/1/0/all/0/1">Piotr Fudalej</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandziuk_J/0/1/0/all/0/1">Jacek Ma&#x144;dziuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10464">
                                    <div class="article-summary-box-inner">
                                        <span>First attempts of prediction of the facial growth (FG) direction were made
over half of a century ago. Despite numerous attempts and elapsed time, a
satisfactory method has not been established yet and the problem still poses a
challenge for medical experts. To our knowledge, this paper is the first
Machine Learning approach to the prediction of FG direction. Conducted data
analysis reveals the inherent complexity of the problem and explains the
reasons of difficulty in FG direction prediction based on 2D X-ray images. To
perform growth forecasting, we employ a wide range of algorithms, from logistic
regression, through tree ensembles to neural networks and consider three,
slightly different, problem formulations. The resulting classification accuracy
varies between 71% and 75%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VQA-Aid: Visual Question Answering for Post-Disaster Damage Assessment and Analysis. (arXiv:2106.10548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1">Argho Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnemoonfar_M/0/1/0/all/0/1">Maryam Rahnemoonfar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10548">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Question Answering system integrated with Unmanned Aerial Vehicle
(UAV) has a lot of potentials to advance the post-disaster damage assessment
purpose. Providing assistance to affected areas is highly dependent on
real-time data assessment and analysis. Scope of the Visual Question Answering
is to understand the scene and provide query related answer which certainly
faster the recovery process after any disaster. In this work, we address the
importance of \textit{visual question answering (VQA)} task for post-disaster
damage assessment by presenting our recently developed VQA dataset called
\textit{HurMic-VQA} collected during hurricane Michael, and comparing the
performances of baseline VQA models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Informative Class Activation Maps. (arXiv:2106.10472v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10472">
                                    <div class="article-summary-box-inner">
                                        <span>We study how to evaluate the quantitative information content of a region
within an image for a particular label. To this end, we bridge class activation
maps with information theory. We develop an informative class activation map
(infoCAM). Given a classification task, infoCAM depict how to accumulate
information of partial regions to that of the entire image toward a label.
Thus, we can utilise infoCAM to locate the most informative features for a
label. When applied to an image classification task, infoCAM performs better
than the traditional classification map in the weakly supervised object
localisation task. We achieve state-of-the-art results on Tiny-ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition. (arXiv:2106.10598v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wenyuan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Baosheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10598">
                                    <div class="article-summary-box-inner">
                                        <span>A table arranging data in rows and columns is a very effective data
structure, which has been widely used in business and scientific research.
Considering large-scale tabular data in online and offline documents, automatic
table recognition has attracted increasing attention from the document analysis
community. Though human can easily understand the structure of tables, it
remains a challenge for machines to understand that, especially due to a
variety of different table layouts and styles. Existing methods usually model a
table as either the markup sequence or the adjacency matrix between different
table cells, failing to address the importance of the logical location of table
cells, e.g., a cell is located in the first row and the second column of the
table. In this paper, we reformulate the problem of table structure recognition
as the table graph reconstruction, and propose an end-to-end trainable table
graph reconstruction network (TGRNet) for table structure recognition.
Specifically, the proposed method has two main branches, a cell detection
branch and a cell logical location branch, to jointly predict the spatial
location and the logical location of different cells. Experimental results on
three popular table recognition datasets and a new dataset with table graph
annotations (TableGraph-350K) demonstrate the effectiveness of the proposed
TGRNet for table structure recognition. Code and annotations will be made
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Summarization through Reinforcement Learning with a 3D Spatio-Temporal U-Net. (arXiv:2106.10528v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qingjie Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jun-Jie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10528">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent video summarization algorithms allow to quickly convey the most
relevant information in videos through the identification of the most essential
and explanatory content while removing redundant video frames. In this paper,
we introduce the 3DST-UNet-RL framework for video summarization. A 3D
spatio-temporal U-Net is used to efficiently encode spatio-temporal information
of the input videos for downstream reinforcement learning (RL). An RL agent
learns from spatio-temporal latent scores and predicts actions for keeping or
rejecting a video frame in a video summary. We investigate if real/inflated 3D
spatio-temporal CNN features are better suited to learn representations from
videos than commonly used 2D image features. Our framework can operate in both,
a fully unsupervised mode and a supervised training mode. We analyse the impact
of prescribed summary lengths and show experimental evidence for the
effectiveness of 3DST-UNet-RL on two commonly used general video summarization
benchmarks. We also applied our method on a medical video summarization task.
The proposed video summarization method has the potential to save storage costs
of ultrasound screening videos as well as to increase efficiency when browsing
patient video data during retrospective analysis or audit without loosing
essential information</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReGO: Reference-Guided Outpainting for Scenery Image. (arXiv:2106.10601v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xueming Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Li Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10601">
                                    <div class="article-summary-box-inner">
                                        <span>We aim to tackle the challenging yet practical scenery image outpainting task
in this work. Recently, generative adversarial learning has significantly
advanced the image outpainting by producing semantic consistent content for the
given image. However, the existing methods always suffer from the blurry
texture and the artifacts of the generative part, making the overall
outpainting results lack authenticity. To overcome the weakness, this work
investigates a principle way to synthesize texture-rich results by borrowing
pixels from its neighbors (\ie, reference images), named
\textbf{Re}ference-\textbf{G}uided \textbf{O}utpainting (ReGO). Particularly,
the ReGO designs an Adaptive Content Selection (ACS) module to transfer the
pixel of reference images for texture compensating of the target one. To
prevent the style of the generated part from being affected by the reference
images, a style ranking loss is further proposed to augment the ReGO to
synthesize style-consistent results. Extensive experiments on two popular
benchmarks, NS6K~\cite{yangzx} and NS8K~\cite{wang}, well demonstrate the
effectiveness of our ReGO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Visual Context for Weakly Supervised Person Search. (arXiv:2106.10506v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yichao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jinpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shengcai Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10506">
                                    <div class="article-summary-box-inner">
                                        <span>Person search has recently emerged as a challenging task that jointly
addresses pedestrian detection and person re-identification. Existing
approaches follow a fully supervised setting where both bounding box and
identity annotations are available. However, annotating identities is
labor-intensive, limiting the practicability and scalability of current
frameworks. This paper inventively considers weakly supervised person search
with only bounding box annotations. We proposed the first framework to address
this novel task, namely Context-Guided Person Search (CGPS), by investigating
three levels of context clues (i.e., detection, memory and scene) in
unconstrained natural images. The first two are employed to promote local and
global discriminative capabilities, while the latter enhances clustering
accuracy. Despite its simple design, our CGPS boosts the baseline model by 8.3%
in mAP on CUHK-SYSU. Surprisingly, it even achieves comparable performance to
two-step person search models, while displaying higher efficiency. Our code is
available at https://github.com/ljpadam/CGPS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More than Encoder: Introducing Transformer Decoder to Upsample. (arXiv:2106.10637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yijiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Wentian Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Ying Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiping Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10637">
                                    <div class="article-summary-box-inner">
                                        <span>General segmentation models downsample images and then upsample to restore
resolution for pixel level prediction. In such schema, upsample technique is
vital in maintaining information for better performance. In this paper, we
present a new upsample approach, Attention Upsample (AU), that could serve as
general upsample method and be incorporated into any segmentation model that
possesses lateral connections. AU leverages pixel-level attention to model long
range dependency and global information for better reconstruction. It consists
of Attention Decoder (AD) and bilinear upsample as residual connection to
complement the upsampled features. AD adopts the idea of decoder from
transformer which upsamples features conditioned on local and detailed
information from contracting path. Moreover, considering the extensive memory
and computation cost of pixel-level attention, we further propose to use window
attention scheme to restrict attention computation in local windows instead of
global range. Incorporating window attention, we denote our decoder as Window
Attention Decoder (WAD) and our upsample method as Window Attention Upsample
(WAU). We test our method on classic U-Net structure with lateral connection to
deliver information from contracting path and achieve state-of-the-arts
performance on Synapse (80.30 DSC and 23.12 HD) and MSD Brain (74.75 DSC)
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CenterAtt: Fast 2-stage Center Attention Network. (arXiv:2106.10493v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jianyun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_J/0/1/0/all/0/1">Jian Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1">Xu Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yushi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10493">
                                    <div class="article-summary-box-inner">
                                        <span>In this technical report, we introduce the methods of HIKVISION_LiDAR_Det in
the challenge of waymo open dataset real-time 3D detection. Our solution for
the competition are built upon Centerpoint 3D detection framework. Several
variants of CenterPoint are explored, including center attention head and
feature pyramid network neck. In order to achieve real time detection, methods
like batchnorm merge, half-precision floating point network and GPU-accelerated
voxelization process are adopted. By using these methods, our team ranks 6th
among all the methods on real-time 3D detection challenge in the waymo open
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reversible Colour Density Compression of Images using cGANs. (arXiv:2106.10542v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jose_A/0/1/0/all/0/1">Arun Jose</a>, <a href="http://arxiv.org/find/eess/1/au:+Francis_A/0/1/0/all/0/1">Abraham Francis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10542">
                                    <div class="article-summary-box-inner">
                                        <span>Image compression using colour densities is historically impractical to
decompress losslessly. We examine the use of conditional generative adversarial
networks in making this transformation more feasible, through learning a
mapping between the images and a loss function to train on. We show that this
method is effective at producing visually lossless generations, indicating that
efficient colour compression is viable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Single Stage Weakly Supervised Semantic Segmentation. (arXiv:2106.10309v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akiva_P/0/1/0/all/0/1">Peri Akiva</a>, <a href="http://arxiv.org/find/cs/1/au:+Dana_K/0/1/0/all/0/1">Kristin Dana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10309">
                                    <div class="article-summary-box-inner">
                                        <span>The costly process of obtaining semantic segmentation labels has driven
research towards weakly supervised semantic segmentation (WSSS) methods, using
only image-level, point, or box labels. The lack of dense scene representation
requires methods to increase complexity to obtain additional semantic
information about the scene, often done through multiple stages of training and
refinement. Current state-of-the-art (SOTA) models leverage image-level labels
to produce class activation maps (CAMs) which go through multiple stages of
refinement before they are thresholded to make pseudo-masks for supervision.
The multi-stage approach is computationally expensive, and dependency on
image-level labels for CAMs generation lacks generalizability to more complex
scenes. In contrary, our method offers a single-stage approach generalizable to
arbitrary dataset, that is trainable from scratch, without any dependency on
pre-trained backbones, classification, or separate refinement tasks. We utilize
point annotations to generate reliable, on-the-fly pseudo-masks through refined
and filtered features. While our method requires point annotations that are
only slightly more expensive than image-level annotations, we are to
demonstrate SOTA performance on benchmark datasets (PascalVOC 2012), as well as
significantly outperform other SOTA WSSS methods on recent real-world datasets
(CRAID, CityPersons, IAD).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single View Physical Distance Estimation using Human Pose. (arXiv:2106.10335v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fei_X/0/1/0/all/0/1">Xiaohan Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Henry Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiangyu Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheong_L/0/1/0/all/0/1">Lin Lee Cheong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tighe_J/0/1/0/all/0/1">Joseph Tighe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10335">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a fully automated system that simultaneously estimates the camera
intrinsics, the ground plane, and physical distances between people from a
single RGB image or video captured by a camera viewing a 3-D scene from a fixed
vantage point. To automate camera calibration and distance estimation, we
leverage priors about human pose and develop a novel direct formulation for
pose-based auto-calibration and distance estimation, which shows
state-of-the-art performance on publicly available datasets. The proposed
approach enables existing camera systems to measure physical distances without
needing a dedicated calibration process or range sensors, and is applicable to
a broad range of use cases such as social distancing and workplace safety.
Furthermore, to enable evaluation and drive research in this area, we
contribute to the publicly available MEVA dataset with additional distance
annotations, resulting in MEVADA -- the first evaluation benchmark in the world
for the pose-based auto-calibration and distance estimation problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Contextual Design of Convolutional Neural Network for Steganalysis. (arXiv:2106.10430v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_B/0/1/0/all/0/1">Brijesh Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sur_A/0/1/0/all/0/1">Arijit Sur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_P/0/1/0/all/0/1">Pinaki Mitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10430">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, deep learning-based steganalysis classifiers became popular
due to their state-of-the-art performance. Most deep steganalysis classifiers
usually extract noise residuals using high-pass filters as preprocessing steps
and feed them to their deep model for classification. It is observed that
recent steganographic embedding does not always restrict their embedding in the
high-frequency zone; instead, they distribute it as per embedding policy.
Therefore, besides noise residual, learning the embedding zone is another
challenging task. In this work, unlike the conventional approaches, the
proposed model first extracts the noise residual using learned denoising
kernels to boost the signal-to-noise ratio. After preprocessing, the sparse
noise residuals are fed to a novel Multi-Contextual Convolutional Neural
Network (M-CNET) that uses heterogeneous context size to learn the sparse and
low-amplitude representation of noise residuals. The model performance is
further improved by incorporating the Self-Attention module to focus on the
areas prone to steganalytic embedding. A set of comprehensive experiments is
performed to show the proposed scheme&#x27;s efficacy over the prior arts. Besides,
an ablation study is given to justify the contribution of various modules of
the proposed architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSN: Efficient Online Mask Selection Network for Video Instance Segmentation. (arXiv:2106.10452v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goel_V/0/1/0/all/0/1">Vidit Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Shubhika Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Maheshwari_H/0/1/0/all/0/1">Harsh Maheshwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10452">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a novel solution for Video Instance
Segmentation(VIS), that is automatically generating instance level segmentation
masks along with object class and tracking them in a video. Our method improves
the masks from segmentation and propagation branches in an online manner using
the Mask Selection Network (MSN) hence limiting the noise accumulation during
mask tracking. We propose an effective design of MSN by using patch-based
convolutional neural network. The network is able to distinguish between very
subtle differences between the masks and choose the better masks out of the
associated masks accurately. Further, we make use of temporal consistency and
process the video sequences in both forward and reverse manner as a post
processing step to recover lost objects. The proposed method can be used to
adapt any video object segmentation method for the task of VIS. Our method
achieves a score of 49.1 mAP on 2021 YouTube-VIS Challenge and was ranked third
place among more than 30 global teams. Our code will be available at
https://github.com/SHI-Labs/Mask-Selection-Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaZoom: Adaptive Zoom Network for Multi-Scale Object Detection in Large Scenes. (arXiv:2106.10409v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingtao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yali Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10409">
                                    <div class="article-summary-box-inner">
                                        <span>Detection in large-scale scenes is a challenging problem due to small objects
and extreme scale variation. It is essential to focus on the image regions of
small objects. In this paper, we propose a novel Adaptive Zoom (AdaZoom)
network as a selective magnifier with flexible shape and focal length to
adaptively zoom the focus regions for object detection. Based on policy
gradient, we construct a reinforcement learning framework for focus region
generation, with the reward formulated by object distributions. The scales and
aspect ratios of the generated regions are adaptive to the scales and
distribution of objects inside. We apply variable magnification according to
the scale of the region for adaptive multi-scale detection. We further propose
collaborative training to complementarily promote the performance of AdaZoom
and the detection network. To validate the effectiveness, we conduct extensive
experiments on VisDrone2019, UAVDT, and DOTA datasets. The experiments show
AdaZoom brings a consistent and significant improvement over different
detection networks, achieving state-of-the-art performance on these datasets,
especially outperforming the existing methods by AP of 4.64% on Vis-Drone2019.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Training via Boosting Pruning Plasticity with Neuroregeneration. (arXiv:2106.10404v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Atashgahi_Z/0/1/0/all/0/1">Zahra Atashgahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kou_H/0/1/0/all/0/1">Huanyu Kou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1">Decebal Constantin Mocanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10404">
                                    <div class="article-summary-box-inner">
                                        <span>Works on lottery ticket hypothesis (LTH) and single-shot network pruning
(SNIP) have raised a lot of attention currently on post-training pruning
(iterative magnitude pruning), and before-training pruning (pruning at
initialization). The former method suffers from an extremely large computation
cost and the latter category of methods usually struggles with insufficient
performance. In comparison, during-training pruning, a class of pruning methods
that simultaneously enjoys the training/inference efficiency and the comparable
performance, temporarily, has been less explored. To better understand
during-training pruning, we quantitatively study the effect of pruning
throughout training from the perspective of pruning plasticity (the ability of
the pruned networks to recover the original performance). Pruning plasticity
can help explain several other empirical observations about neural network
pruning in literature. We further find that pruning plasticity can be
substantially improved by injecting a brain-inspired mechanism called
neuroregeneration, i.e., to regenerate the same number of connections as
pruned. Based on the insights from pruning plasticity, we design a novel
gradual magnitude pruning (GMP) method, named gradual pruning with zero-cost
neuroregeneration (GraNet), and its dynamic sparse training (DST) variant
(GraNet-ST). Both of them advance state of the art. Perhaps most impressively,
the latter for the first time boosts the sparse-to-sparse training performance
over various dense-to-sparse methods by a large margin with ResNet-50 on
ImageNet. We will release all codes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A system of vision sensor based deep neural networks for complex driving scene analysis in support of crash risk assessment and prevention. (arXiv:2106.10319v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Muhammad Monjurul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Ruwen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhaozheng Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10319">
                                    <div class="article-summary-box-inner">
                                        <span>To assist human drivers and autonomous vehicles in assessing crash risks,
driving scene analysis using dash cameras on vehicles and deep learning
algorithms is of paramount importance. Although these technologies are
increasingly available, driving scene analysis for this purpose still remains a
challenge. This is mainly due to the lack of annotated large image datasets for
analyzing crash risk indicators and crash likelihood, and the lack of an
effective method to extract lots of required information from complex driving
scenes. To fill the gap, this paper develops a scene analysis system. The
Multi-Net of the system includes two multi-task neural networks that perform
scene classification to provide four labels for each scene. The DeepLab v3 and
YOLO v3 are combined by the system to detect and locate risky pedestrians and
the nearest vehicles. All identified information can provide the situational
awareness to autonomous vehicles or human drivers for identifying crash risks
from the surrounding traffic. To address the scarcity of annotated image
datasets for studying traffic crashes, two completely new datasets have been
developed by this paper and made available to the public, which were proved to
be effective in training the proposed deep neural networks. The paper further
evaluates the performance of the Multi-Net and the efficiency of the developed
system. Comprehensive scene analysis is further illustrated with representative
examples. Results demonstrate the effectiveness of the developed system and
datasets for driving scene analysis, and their supportiveness for crash risk
assessment and crash prevention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Facial Authentication for Public Electric Vehicle Charging Station. (arXiv:2106.10432v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haris_M/0/1/0/all/0/1">Muhamad Amin Husni Abdul Haris</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Sin Liang Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10432">
                                    <div class="article-summary-box-inner">
                                        <span>This study is to investigate and compare the facial recognition accuracy
performance of Dlib ResNet against a K-Nearest Neighbour (KNN) classifier.
Particularly when used against a dataset from an Asian ethnicity as Dlib ResNet
was reported to have an accuracy deficiency when it comes to Asian faces. The
comparisons are both implemented on the facial vectors extracted using the
Histogram of Oriented Gradients (HOG) method and use the same dataset for a
fair comparison. Authentication of a user by facial recognition in an electric
vehicle (EV) charging station demonstrates a practical use case for such an
authentication system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Aware Legal Citation Recommendation using Deep Learning. (arXiv:2106.10776v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zihan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_C/0/1/0/all/0/1">Charles Low</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_M/0/1/0/all/0/1">Mengqiu Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Krass_M/0/1/0/all/0/1">Mark S. Krass</a>, <a href="http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1">Matthias Grabmair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10776">
                                    <div class="article-summary-box-inner">
                                        <span>Lawyers and judges spend a large amount of time researching the proper legal
authority to cite while drafting decisions. In this paper, we develop a
citation recommendation tool that can help improve efficiency in the process of
opinion drafting. We train four types of machine learning models, including a
citation-list based method (collaborative filtering) and three context-based
methods (text similarity, BiLSTM and RoBERTa classifiers). Our experiments show
that leveraging local textual context improves recommendation, and that deep
neural models achieve decent performance. We show that non-deep text-based
methods benefit from access to structured case metadata, but deep models only
benefit from such access when predicting from context of insufficient length.
We also find that, even after extensive training, RoBERTa does not outperform a
recurrent neural model, despite its benefits of pretraining. Our behavior
analysis of the RoBERTa model further shows that predictive performance is
stable across time and citation classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization of Service Addition in Multilevel Index Model for Edge Computing. (arXiv:2106.04494v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiayan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anjum_A/0/1/0/all/0/1">Ashiq Anjum</a>, <a href="http://arxiv.org/find/cs/1/au:+Panneerselvam_J/0/1/0/all/0/1">John Panneerselvam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Bo Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04494">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of Edge Computing and Artificial Intelligence (AI)
technologies, edge devices are witnessed to generate data at unprecedented
volume. The Edge Intelligence (EI) has led to the emergence of edge devices in
various application domains. The EI can provide efficient services to
delay-sensitive applications, where the edge devices are deployed as edge nodes
to host the majority of execution, which can effectively manage services and
improve service discovery efficiency. The multilevel index model is a
well-known model used for indexing service, such a model is being introduced
and optimized in the edge environments to efficiently services discovery whilst
managing large volumes of data. However, effectively updating the multilevel
index model by adding new services timely and precisely in the dynamic Edge
Computing environments is still a challenge. Addressing this issue, this paper
proposes a designated key selection method to improve the efficiency of adding
services in the multilevel index models. Our experimental results show that in
the partial index and the full index of multilevel index model, our method
reduces the service addition time by around 84% and 76%, respectively when
compared with the original key selection method and by around 78% and 66%,
respectively when compared with the random selection method. Our proposed
method significantly improves the service addition efficiency in the multilevel
index model, when compared with existing state-of-the-art key selection
methods, without compromising the service retrieval stability to any notable
level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Graph-based Search for Lessons-Learned Documents in the Semiconductor Industry. (arXiv:2105.08442v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abu_Rasheed_H/0/1/0/all/0/1">Hasan Abu-Rasheed</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1">Christian Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Zenkert_J/0/1/0/all/0/1">Johannes Zenkert</a>, <a href="http://arxiv.org/find/cs/1/au:+Krumm_R/0/1/0/all/0/1">Roland Krumm</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathi_M/0/1/0/all/0/1">Madjid Fathi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08442">
                                    <div class="article-summary-box-inner">
                                        <span>Industrial processes produce a considerable volume of data and thus
information. Whether it is structured sensory data or semi- to unstructured
textual data, the knowledge that can be derived from it is critical to the
sustainable development of the industrial process. A key challenge of this
sustainability is the intelligent management of the generated data, as well as
the knowledge extracted from it, in order to utilize this knowledge for
improving future procedures. This challenge is a result of the tailored
documentation methods and domain-specific requirements, which include the need
for quick visibility of the documented knowledge. In this paper, we utilize the
expert knowledge documented in chip-design failure reports in supporting user
access to information that is relevant to a current chip design. Unstructured,
free, textual data in previous failure documentations provides a valuable
source of lessons-learned, which expert design-engineers have experienced,
solved and documented. To achieve a sustainable utilization of knowledge within
the company, not only the inherent knowledge has to be mined from unstructured
textual data, but also the relations between the lessons-learned, uncovering
potentially unknown links. In this research, a knowledge graph is constructed,
in order to represent and use the interconnections between reported design
failures. A search engine is developed and applied onto the graph to answer
queries. In contrast to mere keyword-based searching, the searchability of the
knowledge graph offers enhanced search results beyond direct matches and acts
as a mean for generating explainable results and result recommendations.
Results are provided to the design engineer through an interactive search
interface, in which, the feedback from the user is used to further optimize
relations for future iterations of the knowledge graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Review on Non-Neural Networks Collaborative Filtering Recommendation Systems. (arXiv:2106.10679v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wenga_C/0/1/0/all/0/1">Carmel Wenga</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Fansi_M/0/1/0/all/0/1">Majirus Fansi</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Chabrier_S/0/1/0/all/0/1">S&#xe9;bastien Chabrier</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Mari_J/0/1/0/all/0/1">Jean-Martial Mari</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gabillon_A/0/1/0/all/0/1">Alban Gabillon</a> (1) ((1) University of French Polynesia, (2) NzhinuSoft)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10679">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past two decades, recommender systems have attracted a lot of
interest due to the explosion in the amount of data in online applications. A
particular attention has been paid to collaborative filtering, which is the
most widely used in applications that involve information recommendations.
Collaborative filtering (CF) uses the known preference of a group of users to
make predictions and recommendations about the unknown preferences of other
users (recommendations are made based on the past behavior of users). First
introduced in the 1990s, a wide variety of increasingly successful models have
been proposed. Due to the success of machine learning techniques in many areas,
there has been a growing emphasis on the application of such algorithms in
recommendation systems. In this article, we present an overview of the CF
approaches for recommender systems, their two main categories, and their
evaluation metrics. We focus on the application of classical Machine Learning
algorithms to CF recommender systems by presenting their evolution from their
first use-cases to advanced Machine Learning models. We attempt to provide a
comprehensive and comparative overview of CF systems (with python
implementations) that can serve as a guideline for research and practice in
this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential Recommendation in Online Games with Multiple Sequences, Tasks and User Levels. (arXiv:2102.06950v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yuqiu Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06950">
                                    <div class="article-summary-box-inner">
                                        <span>Online gaming is growing faster than ever before, with increasing challenges
of providing better user experience. Recommender systems (RS) for online games
face unique challenges since they must fulfill players&#x27; distinct desires, at
different user levels, based on their action sequences of various action types.
Although many sequential RS already exist, they are mainly single-sequence,
single-task, and single-user-level. In this paper, we introduce a new
sequential recommendation model for multiple sequences, multiple tasks, and
multiple user levels (abbreviated as M$^3$Rec) in Tencent Games platform, which
can fully utilize complex data in online games. We leverage Graph Neural
Network and multi-task learning to design M$^3$Rec in order to model the
complex information in the heterogeneous sequential recommendation scenario of
Tencent Games. We verify the effectiveness of M$^3$Rec on three online games of
Tencent Games platform, in both offline and online evaluations. The results
show that M$^3$Rec successfully addresses the challenges of recommendation in
online games, and it generates superior recommendations compared with
state-of-the-art sequential recommendation approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for Visual Information Extraction using Sequences. (arXiv:2106.10681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiapeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Guozhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weihong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kai Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yichao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10681">
                                    <div class="article-summary-box-inner">
                                        <span>Visual information extraction (VIE) has attracted increasing attention in
recent years. The existing methods usually first organized optical character
recognition (OCR) results into plain texts and then utilized token-level entity
annotations as supervision to train a sequence tagging model. However, it
expends great annotation costs and may be exposed to label confusion, and the
OCR errors will also significantly affect the final performance. In this paper,
we propose a unified weakly-supervised learning framework called TCPN (Tag,
Copy or Predict Network), which introduces 1) an efficient encoder to
simultaneously model the semantic and layout information in 2D OCR results; 2)
a weakly-supervised training strategy that utilizes only key information
sequences as supervision; and 3) a flexible and switchable decoder which
contains two inference modes: one (Copy or Predict Mode) is to output key
information sequences of different categories by copying a token from the input
or predicting one in each time step, and the other (Tag Mode) is to directly
tag the input sequence in a single forward pass. Our method shows new
state-of-the-art performance on several public benchmarks, which fully proves
its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Multiple Online Sources for Accurate Income Verification. (arXiv:2106.10547v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahapatra_C/0/1/0/all/0/1">Chirag Mahapatra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellare_K/0/1/0/all/0/1">Kedar Bellare</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10547">
                                    <div class="article-summary-box-inner">
                                        <span>Income verification is the problem of validating a person&#x27;s stated income
given basic identity information such as name, location, job title and
employer. It is widely used in the context of mortgage lending, rental
applications and other financial risk models. However, the current processes
surrounding verification involve significant human effort and document
gathering which can be both time-consuming and expensive. In this paper, we
propose a novel model for verifying an individual&#x27;s income given very limited
identity information typically available in loan applications. Our model is a
combination of a deep neural network and hand-engineered features. The hand
engineered features are based upon matching the input information against
income records extracted automatically from various publicly available online
sources (e.g. payscale.com, H-1B filings, government employee salaries). We
conduct experiments on two data sets, one simulated from H-1B records and the
other from a real-world data set of peer-to-peer (P2P) loan applications
obtained from one of the world&#x27;s largest P2P lending platform. Our results show
a significant reduction in error of 3-6% relative to several strong baselines.
We also perform ablation studies to demonstrate that a combined model is indeed
necessary to achieve state-of-the-art performance on this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Sampling Top-K Recommendation Evaluation. (arXiv:2106.10621v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Ruoming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jing Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10621">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Rendle has warned that the use of sampling-based top-$k$ metrics
might not suffice. This throws a number of recent studies on deep
learning-based recommendation algorithms, and classic non-deep-learning
algorithms using such a metric, into jeopardy. In this work, we thoroughly
investigate the relationship between the sampling and global top-$K$ Hit-Ratio
(HR, or Recall), originally proposed by Koren[2] and extensively used by
others. By formulating the problem of aligning sampling top-$k$ ($SHR@k$) and
global top-$K$ ($HR@K$) Hit-Ratios through a mapping function $f$, so that
$SHR@k\approx HR@f(k)$, we demonstrate both theoretically and experimentally
that the sampling top-$k$ Hit-Ratio provides an accurate approximation of its
global (exact) counterpart, and can consistently predict the correct winners
(the same as indicate by their corresponding global Hit-Ratios).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of MRR and NDCG models for Visual Dialog. (arXiv:2104.07511v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1">Idan Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07511">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing an AI agent that can converse in human language and understand
visual content is challenging. Generation metrics, such as BLEU scores favor
correct syntax over semantics. Hence a discriminative approach is often used,
where an agent ranks a set of candidate options. The mean reciprocal rank (MRR)
metric evaluates the model performance by taking into account the rank of a
single human-derived answer. This approach, however, raises a new challenge:
the ambiguity and synonymy of answers, for instance, semantic equivalence
(e.g., &#x60;yeah&#x27; and &#x60;yes&#x27;). To address this, the normalized discounted cumulative
gain (NDCG) metric has been used to capture the relevance of all the correct
answers via dense annotations. However, the NDCG metric favors the usually
applicable uncertain answers such as &#x60;I don&#x27;t know. Crafting a model that
excels on both MRR and NDCG metrics is challenging. Ideally, an AI agent should
answer a human-like reply and validate the correctness of any answer. To
address this issue, we describe a two-step non-parametric ranking approach that
can merge strong MRR and NDCG models. Using our approach, we manage to keep
most MRR state-of-the-art performance (70.41% vs. 71.24%) and the NDCG
state-of-the-art performance (72.16% vs. 75.35%). Moreover, our approach won
the recent Visual Dialog 2020 challenge. Source code is available at
https://github.com/idansc/mrr-ndcg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certification of Iterative Predictions in Bayesian Neural Networks. (arXiv:2105.10134v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wicker_M/0/1/0/all/0/1">Matthew Wicker</a>, <a href="http://arxiv.org/find/cs/1/au:+Laurenti_L/0/1/0/all/0/1">Luca Laurenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Patane_A/0/1/0/all/0/1">Andrea Patane</a>, <a href="http://arxiv.org/find/cs/1/au:+Paoletti_N/0/1/0/all/0/1">Nicola Paoletti</a>, <a href="http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwiatkowska_M/0/1/0/all/0/1">Marta Kwiatkowska</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10134">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of computing reach-avoid probabilities for iterative
predictions made with Bayesian neural network (BNN) models. Specifically, we
leverage bound propagation techniques and backward recursion to compute lower
bounds for the probability that trajectories of the BNN model reach a given set
of states while avoiding a set of unsafe states. We use the lower bounds in the
context of control and reinforcement learning to provide safety certification
for given control policies, as well as to synthesize control policies that
improve the certification bounds. On a set of benchmarks, we demonstrate that
our framework can be employed to certify policies over BNNs predictions for
problems of more than $10$ dimensions, and to effectively synthesize policies
that significantly increase the lower bound on the satisfaction probability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Basic and Depression Specific Emotion Identification in Tweets: Multi-label Classification Experiments. (arXiv:2105.12364v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farruque_N/0/1/0/all/0/1">Nawshad Farruque</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chenyang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaiane_O/0/1/0/all/0/1">Osmar Zaiane</a>, <a href="http://arxiv.org/find/cs/1/au:+Goebel_R/0/1/0/all/0/1">Randy Goebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12364">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present empirical analysis on basic and depression specific
multi-emotion mining in Tweets with the help of state of the art multi-label
classifiers. We choose our basic emotions from a hybrid emotion model
consisting of the common emotions from four highly regarded psychological
models of emotions. Moreover, we augment that emotion model with new emotion
categories because of their importance in the analysis of depression. Most of
those additional emotions have not been used in previous emotion mining
research. Our experimental analyses show that a cost sensitive RankSVM
algorithm and a Deep Learning model are both robust, measured by both Macro
F-measures and Micro F-measures. This suggests that these algorithms are
superior in addressing the widely known data imbalance problem in multi-label
learning. Moreover, our application of Deep Learning performs the best, giving
it an edge in modeling deep semantic features of our extended emotional
categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis. (arXiv:2106.07524v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kollias_D/0/1/0/all/0/1">Dimitrios Kollias</a>, <a href="http://arxiv.org/find/eess/1/au:+Arsenos_A/0/1/0/all/0/1">Anastasios Arsenos</a>, <a href="http://arxiv.org/find/eess/1/au:+Soukissian_L/0/1/0/all/0/1">Levon Soukissian</a>, <a href="http://arxiv.org/find/eess/1/au:+Kollias_S/0/1/0/all/0/1">Stefanos Kollias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07524">
                                    <div class="article-summary-box-inner">
                                        <span>Early and reliable COVID-19 diagnosis based on chest 3-D CT scans can assist
medical specialists in vital circumstances. Deep learning methodologies
constitute a main approach for chest CT scan analysis and disease prediction.
However, large annotated databases are necessary for developing deep learning
models that are able to provide COVID-19 diagnosis across various medical
environments in different countries. Due to privacy issues, publicly available
COVID-19 CT datasets are highly difficult to obtain, which hinders the research
and development of AI-enabled diagnosis methods of COVID-19 based on CT scans.
In this paper we present the COV19-CT-DB database which is annotated for
COVID-19, consisting of about 5,000 3-D CT scans, We have split the database in
training, validation and test datasets. The former two datasets can be used for
training and validation of machine learning models, while the latter will be
used for evaluation of the developed models. We also present a deep learning
approach, based on a CNN-RNN network and report its performance on the
COVID19-CT-DB database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Autonomous Road Vehicle Integrated Approaches to an Emergency Obstacle Avoidance Maneuver. (arXiv:2105.09446v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lowe_E/0/1/0/all/0/1">Evan Lowe</a>, <a href="http://arxiv.org/find/cs/1/au:+Guvenc_L/0/1/0/all/0/1">Levent Guven&#xe7;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09446">
                                    <div class="article-summary-box-inner">
                                        <span>As passenger vehicle technologies have advanced, so have their capabilities
to avoid obstacles, especially with developments in tires, suspensions,
steering, as well as safety technologies like ABS, ESC, and more recently, ADAS
systems. However, environments around passenger vehicles have also become more
complex, and dangerous. There have previously been studies that outline driver
tendencies and performance capabilities when attempting to avoid obstacles
while driving passenger vehicles. Now that autonomous vehicles are being
developed with obstacle avoidance capabilities, it is important to target
performance that meets or exceeds that of human drivers. This manuscript
highlights systems that are crucial for an emergency obstacle avoidance
maneuver (EOAM) and identifies the state-of-the-art for each of the related
systems, while considering the nuances of traveling at highway speeds. Some of
the primary EOAM-related systems/areas that are discussed in this review are:
general path planning methods, system hierarchies, decision-making, trajectory
generation, and trajectory-tracking control methods. After concluding remarks,
suggestions for future work which could lead to an ideal EOAM development, are
discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Rate-Distortion-Perception Representations for Lossy Compression. (arXiv:2106.10311v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">George Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jingjing Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Khisti_A/0/1/0/all/0/1">Ashish Khisti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10311">
                                    <div class="article-summary-box-inner">
                                        <span>In the context of lossy compression, Blau &amp; Michaeli (2019) adopt a
mathematical notion of perceptual quality and define the information
rate-distortion-perception function, generalizing the classical rate-distortion
tradeoff. We consider the notion of universal representations in which one may
fix an encoder and vary the decoder to achieve any point within a collection of
distortion and perception constraints. We prove that the corresponding
information-theoretic universal rate-distortion-perception function is
operationally achievable in an approximate sense. Under MSE distortion, we show
that the entire distortion-perception tradeoff of a Gaussian source can be
achieved by a single encoder of the same rate asymptotically. We then
characterize the achievable distortion-perception region for a fixed
representation in the case of arbitrary distributions, identify conditions
under which the aforementioned results continue to hold approximately, and
study the case when the rate is not fixed in advance. This motivates the study
of practical constructions that are approximately universal across the RDP
tradeoff, thereby alleviating the need to design a new encoder for each
objective. We provide experimental results on MNIST and SVHN suggesting that on
image compression tasks, the operational tradeoffs achieved by machine learning
models with a fixed encoder suffer only a small penalty when compared to their
variable encoder counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-domain Multi-relational Link Prediction. (arXiv:2106.06171v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Phuc_L/0/1/0/all/0/1">Luu Huu Phuc</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1">Koh Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1">Seiji Okajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1">Arseny Tolmachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1">Tomoyoshi Takebayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06171">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-relational graph is a ubiquitous and important data structure, allowing
flexible representation of multiple types of interactions and relations between
entities. Similar to other graph-structured data, link prediction is one of the
most important tasks on multi-relational graphs and is often used for knowledge
completion. When related graphs coexist, it is of great benefit to build a
larger graph via integrating the smaller ones. The integration requires
predicting hidden relational connections between entities belonged to different
graphs (inter-domain link prediction). However, this poses a real challenge to
existing methods that are exclusively designed for link prediction between
entities of the same graph only (intra-domain link prediction). In this study,
we propose a new approach to tackle the inter-domain link prediction problem by
softly aligning the entity distributions between different domains with optimal
transport and maximum mean discrepancy regularizers. Experiments on real-world
datasets show that optimal transport regularizer is beneficial and considerably
improves the performance of baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MTC: Multiresolution Tensor Completion from Partial and Coarse Observations. (arXiv:2106.07135v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Yang_C/0/1/0/all/0/1">Chaoqi Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Singh_N/0/1/0/all/0/1">Navjot Singh</a>, <a href="http://arxiv.org/find/math/1/au:+Xiao_C/0/1/0/all/0/1">Cao Xiao</a>, <a href="http://arxiv.org/find/math/1/au:+Qian_C/0/1/0/all/0/1">Cheng Qian</a>, <a href="http://arxiv.org/find/math/1/au:+Solomonik_E/0/1/0/all/0/1">Edgar Solomonik</a>, <a href="http://arxiv.org/find/math/1/au:+Sun_J/0/1/0/all/0/1">Jimeng Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07135">
                                    <div class="article-summary-box-inner">
                                        <span>Existing tensor completion formulation mostly relies on partial observations
from a single tensor. However, tensors extracted from real-world data are often
more complex due to: (i) Partial observation: Only a small subset (e.g., 5%) of
tensor elements are available. (ii) Coarse observation: Some tensor modes only
present coarse and aggregated patterns (e.g., monthly summary instead of daily
reports). In this paper, we are given a subset of the tensor and some
aggregated/coarse observations (along one or more modes) and seek to recover
the original fine-granular tensor with low-rank factorization. We formulate a
coupled tensor completion problem and propose an efficient Multi-resolution
Tensor Completion model (MTC) to solve the problem. Our MTC model explores
tensor mode properties and leverages the hierarchy of resolutions to
recursively initialize an optimization setup, and optimizes on the coupled
system using alternating least squares. MTC ensures low computational and space
complexity. We evaluate our model on two COVID-19 related spatio-temporal
tensors. The experiments show that MTC could provide 65.20% and 75.79%
percentage of fitness (PoF) in tensor completion with only 5% fine granular
observations, which is 27.96% relative improvement over the best baseline. To
evaluate the learned low-rank factors, we also design a tensor prediction task
for daily and cumulative disease case predictions, where MTC achieves 50% in
PoF and 30% relative improvements over the best baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dependency Structure Misspecification in Multi-Source Weak Supervision Models. (arXiv:2106.10302v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1">Salva R&#xfc;hling Cachay</a>, <a href="http://arxiv.org/find/cs/1/au:+Boecking_B/0/1/0/all/0/1">Benedikt Boecking</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1">Artur Dubrawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10302">
                                    <div class="article-summary-box-inner">
                                        <span>Data programming (DP) has proven to be an attractive alternative to costly
hand-labeling of data.

In DP, users encode domain knowledge into \emph{labeling functions} (LF),
heuristics that label a subset of the data noisily and may have complex
dependencies. A label model is then fit to the LFs to produce an estimate of
the unknown class label.

The effects of label model misspecification on test set performance of a
downstream classifier are understudied. This presents a serious awareness gap
to practitioners, in particular since the dependency structure among LFs is
frequently ignored in field applications of DP.

We analyse modeling errors due to structure over-specification.

We derive novel theoretical bounds on the modeling error and empirically show
that this error can be substantial, even when modeling a seemingly sensible
structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory compression and thermal efficiency of quantum implementations of non-deterministic hidden Markov models. (arXiv:2105.06285v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Elliott_T/0/1/0/all/0/1">Thomas J. Elliott</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06285">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic modelling is an essential component of the quantitative sciences,
with hidden Markov models (HMMs) often playing a central role. Concurrently,
the rise of quantum technologies promises a host of advantages in computational
problems, typically in terms of the scaling of requisite resources such as time
and memory. HMMs are no exception to this, with recent results highlighting
quantum implementations of deterministic HMMs exhibiting superior memory and
thermal efficiency relative to their classical counterparts. In many contexts
however, non-deterministic HMMs are viable alternatives; compared to them the
advantages of current quantum implementations do not always hold. Here, we
provide a systematic prescription for constructing quantum implementations of
non-deterministic HMMs that re-establish the quantum advantages against this
broader class. Crucially, we show that whenever the classical implementation
suffers from thermal dissipation due to its need to process information in a
time-local manner, our quantum implementations will both mitigate some of this
dissipation, and achieve an advantage in memory compression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1">Roland S. Zimmermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1">Steffen Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1">Matthias Bethge</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08850">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning has recently seen tremendous success in self-supervised
learning. So far, however, it is largely unclear why the learned
representations generalize so effectively to a large variety of downstream
tasks. We here prove that feedforward models trained with objectives belonging
to the commonly used InfoNCE family learn to implicitly invert the underlying
generative model of the observed data. While the proofs make certain
statistical assumptions about the generative model, we observe empirically that
our findings hold even if these assumptions are severely violated. Our theory
highlights a fundamental connection between contrastive learning, generative
modeling, and nonlinear independent component analysis, thereby furthering our
understanding of the learned representations as well as providing a theoretical
foundation to derive more effective contrastive losses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Kinds of Functions do Deep Neural Networks Learn? Insights from Variational Spline Theory. (arXiv:2105.03361v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1">Rahul Parhi</a>, <a href="http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1">Robert D. Nowak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03361">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a variational framework to understand the properties of functions
learned by deep neural networks with ReLU activation functions fit to data. We
propose a new function space, which is reminiscent of classical bounded
variation spaces, that captures the compositional structure associated with
deep neural networks. We derive a representer theorem showing that deep ReLU
networks are solutions to regularized data fitting problems in this function
space. The function space consists of compositions of functions from the
(non-reflexive) Banach spaces of second-order bounded variation in the Radon
domain. These are Banach spaces with sparsity-promoting norms, giving insight
into the role of sparsity in deep neural networks. The neural network solutions
have skip connections and rank bounded weight matrices, providing new
theoretical support for these common architectural choices. The variational
problem we study can be recast as a finite-dimensional neural network training
problem with regularization schemes related to the notions of weight decay and
path-norm regularization. Finally, our analysis builds on techniques from
variational spline theory, providing new connections between deep neural
networks and splines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Model&#x27;s Uncertainty and Confidences for Adversarial Example Detection. (arXiv:2103.05354v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aldahdooh_A/0/1/0/all/0/1">Ahmed Aldahdooh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1">Olivier D&#xe9;forges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05354">
                                    <div class="article-summary-box-inner">
                                        <span>Security-sensitive applications that rely on Deep Neural Networks (DNNs) are
vulnerable to small perturbations that are crafted to generate Adversarial
Examples(AEs). The AEs are imperceptible to humans and cause DNN to misclassify
them. Many defense and detection techniques have been proposed. Model&#x27;s
confidences and Dropout, as a popular way to estimate the model&#x27;s uncertainty,
have been used for AE detection but they showed limited success against black-
and gray-box attacks. Moreover, the state-of-the-art detection techniques have
been designed for specific attacks or broken by others, need knowledge about
the attacks, are not consistent, increase model parameters overhead, are
time-consuming, or have latency in inference time. To trade off these factors,
we revisit the model&#x27;s uncertainty and confidences and propose a novel
unsupervised ensemble AE detection mechanism that 1) uses the uncertainty
method called SelectiveNet, 2) processes model layers outputs, i.e.feature
maps, to generate new confidence probabilities. The detection method is called
Selective and Feature based Adversarial Detection (SFAD). Experimental results
show that the proposed approach achieves better performance against black- and
gray-box attacks than the state-of-the-art methods and achieves comparable
performance against white-box attacks. Moreover, results show that SFAD is
fully robust against High Confidence Attacks (HCAs) for MNIST and partially
robust for CIFAR10 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inferring Black Hole Properties from Astronomical Multivariate Time Series with Bayesian Attentive Neural Processes. (arXiv:2106.01450v2 [astro-ph.IM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Park_J/0/1/0/all/0/1">Ji Won Park</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Villar_A/0/1/0/all/0/1">Ashley Villar</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Li_Y/0/1/0/all/0/1">Yin Li</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jiang_Y/0/1/0/all/0/1">Yan-Fei Jiang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1">Shirley Ho</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Lin_J/0/1/0/all/0/1">Joshua Yao-Yu Lin</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Marshall_P/0/1/0/all/0/1">Philip J. Marshall</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Roodman_A/0/1/0/all/0/1">Aaron Roodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01450">
                                    <div class="article-summary-box-inner">
                                        <span>Among the most extreme objects in the Universe, active galactic nuclei (AGN)
are luminous centers of galaxies where a black hole feeds on surrounding
matter. The variability patterns of the light emitted by an AGN contain
information about the physical properties of the underlying black hole.
Upcoming telescopes will observe over 100 million AGN in multiple broadband
wavelengths, yielding a large sample of multivariate time series with long gaps
and irregular sampling. We present a method that reconstructs the AGN time
series and simultaneously infers the posterior probability density distribution
(PDF) over the physical quantities of the black hole, including its mass and
luminosity. We apply this method to a simulated dataset of 11,000 AGN and
report precision and accuracy of 0.4 dex and 0.3 dex in the inferred black hole
mass. This work is the first to address probabilistic time series
reconstruction and parameter inference for AGN in an end-to-end fashion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computing Differential Privacy Guarantees for Heterogeneous Compositions Using FFT. (arXiv:2102.12412v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koskela_A/0/1/0/all/0/1">Antti Koskela</a>, <a href="http://arxiv.org/find/cs/1/au:+Honkela_A/0/1/0/all/0/1">Antti Honkela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12412">
                                    <div class="article-summary-box-inner">
                                        <span>The recently proposed Fast Fourier Transform (FFT)-based accountant for
evaluating $(\varepsilon,\delta)$-differential privacy guarantees using the
privacy loss distribution formalism has been shown to give tighter bounds than
commonly used methods such as R\&#x27;enyi accountants when applied to homogeneous
compositions, i.e., to compositions of identical mechanisms. In this paper, we
extend this approach to heterogeneous compositions. We carry out a full error
analysis that allows choosing the parameters of the algorithm such that a
desired accuracy is obtained. The analysis also extends previous results by
taking into account all the parameters of the algorithm. Using the error
analysis, we also give a bound for the computational complexity in terms of the
error which is analogous to and slightly tightens the one given by Murtagh and
Vadhan (2018). We also show how to speed up the evaluation of tight privacy
guarantees using the Plancherel theorem at the cost of increased
pre-computation and memory usage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FNet: Mixing Tokens with Fourier Transforms. (arXiv:2105.03824v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1">James Lee-Thorp</a>, <a href="http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1">Joshua Ainslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_I/0/1/0/all/0/1">Ilya Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Ontanon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03824">
                                    <div class="article-summary-box-inner">
                                        <span>We show that Transformer encoder architectures can be massively sped up, with
limited accuracy costs, by replacing the self-attention sublayers with simple
linear transformations that &quot;mix&quot; input tokens. These linear transformations,
along with standard nonlinearities in feed-forward layers, prove competent at
modeling semantic relationships in several text classification tasks. Most
surprisingly, we find that replacing the self-attention sublayer in a
Transformer encoder with a standard, unparameterized Fourier Transform achieves
92-97% of the accuracy of BERT counterparts on the GLUE benchmark, but trains
nearly seven times faster on GPUs and twice as fast on TPUs. The resulting
model, FNet, also scales very efficiently to long inputs. Specifically, when
compared to the &quot;efficient&quot; Transformers on the Long Range Arena benchmark,
FNet matches the accuracy of the most accurate models, but is faster than the
fastest models across all sequence lengths on GPUs (and across relatively
shorter lengths on TPUs). Finally, FNet has a light memory footprint and is
particularly efficient at smaller model sizes: for a fixed speed and accuracy
budget, small FNet models outperform Transformer counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topological obstructions in neural networks learning. (arXiv:2012.15834v1 [cs.LG] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1">Serguei Barannikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotnikov_G/0/1/0/all/0/1">Grigorii Sotnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1">Ilya Trofimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1">Alexander Korotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15834">
                                    <div class="article-summary-box-inner">
                                        <span>We apply methods of topological data analysis to loss functions to gain
insights on learning of deep neural networks and their generalization
properties. We study global properties of the loss function gradient flow. We
use topological data analysis of the loss function and its Morse complex to
relate local behavior along gradient trajectories with global properties of the
loss surface. We define neural network Topological Obstructions score,
TO-score, with help of robust topological invariants, barcodes of loss
function, that quantify the badness of local minima for gradient-based
optimization. We have made several experiments for computing these invariants,
for small neural networks, and for fully connected, convolutional and
ResNet-like neural networks on different datasets: MNIST, Fashion MNIST,
CIFAR10, SVHN. Our two principal observations are as follows. Firstly, the
neural network barcode and TO-score decrease with the increase of the neural
network depth and width. Secondly, there is an intriguing connection between
the length of minima segments in the barcode and the minima generalization
error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive-Control-Oriented Meta-Learning for Nonlinear Systems. (arXiv:2103.04490v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Richards_S/0/1/0/all/0/1">Spencer M. Richards</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1">Navid Azizan</a>, <a href="http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1">Jean-Jacques Slotine</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04490">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time adaptation is imperative to the control of robots operating in
complex, dynamic environments. Adaptive control laws can endow even nonlinear
systems with good trajectory tracking performance, provided that any uncertain
dynamics terms are linearly parameterizable with known nonlinear features.
However, it is often difficult to specify such features a priori, such as for
aerodynamic disturbances on rotorcraft or interaction forces between a
manipulator arm and various objects. In this paper, we turn to data-driven
modeling with neural networks to learn, offline from past data, an adaptive
controller with an internal parametric model of these nonlinear features. Our
key insight is that we can better prepare the controller for deployment with
control-oriented meta-learning of features in closed-loop simulation, rather
than regression-oriented meta-learning of features to fit input-output data.
Specifically, we meta-learn the adaptive controller with closed-loop tracking
simulation as the base-learner and the average tracking error as the
meta-objective. With a nonlinear planar rotorcraft subject to wind, we
demonstrate that our adaptive controller outperforms other controllers trained
with regression-oriented meta-learning when deployed in closed-loop for
trajectory tracking control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the intrinsic robustness to noise of some leading classifiers and symmetric loss function -- an empirical evaluation. (arXiv:2010.13570v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baher_H/0/1/0/all/0/1">Hugo Le Baher</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lemaire_V/0/1/0/all/0/1">Vincent Lemaire</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Trinquart_R/0/1/0/all/0/1">Romain Trinquart</a> (2) ((1) Polytech Nantes (France), (2) Orange Labs (France))
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13570">
                                    <div class="article-summary-box-inner">
                                        <span>In some industrial applications such as fraud detection, the performance of
common supervision techniques may be affected by the poor quality of the
available labels : in actual operational use-cases, these labels may be weak in
quantity, quality or trustworthiness. We propose a benchmark to evaluate the
natural robustness of different algorithms taken from various paradigms on
artificially corrupted datasets, with a focus on noisy labels. This paper
studies the intrinsic robustness of some leading classifiers. The algorithms
under scrutiny include SVM, logistic regression, random forests, XGBoost,
Khiops. Furthermore, building on results from recent literature, the study is
supplemented with an investigation into the opportunity to enhance some
algorithms with symmetric loss functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiplicative Reweighting for Robust Neural Network Optimization. (arXiv:2102.12192v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bar_N/0/1/0/all/0/1">Noga Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12192">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are widespread due to their powerful performance. Yet,
they suffer from degraded performance in the presence of noisy labels at train
time or adversarial examples during inference. Inspired by the setting of
learning with expert advice, where multiplicative weights (MW) updates were
recently shown to be robust to moderate adversarial corruptions, we propose to
use MW for reweighting examples during neural networks optimization. We
establish the convergence of our method when used with gradient descent and
show its advantage in two simple examples. We then validate empirically our
findings by demonstrating that MW improve networks accuracy in the presence of
label noise on CIFAR-10, CIFAR-100 and Clothing1M, and leads to better
robustness to adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection. (arXiv:2106.00666v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuxin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1">Bencheng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinggang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiemin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jiyang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_J/0/1/0/all/0/1">Jianwei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wenyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00666">
                                    <div class="article-summary-box-inner">
                                        <span>Can Transformer perform $2\mathrm{D}$ object-level recognition from a pure
sequence-to-sequence perspective with minimal knowledge about the $2\mathrm{D}$
spatial structure? To answer this question, we present You Only Look at One
Sequence (YOLOS), a series of object detection models based on the na\&quot;ive
Vision Transformer with the fewest possible modifications as well as inductive
biases. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset
only can already achieve competitive object detection performance on COCO,
\textit{e.g.}, YOLOS-Base directly adopted from BERT-Base can achieve $42.0$
box AP. We also discuss the impacts as well as limitations of current pre-train
schemes and model scaling strategies for Transformer in vision through object
detection. Code and model weights are available at
\url{https://github.com/hustvl/YOLOS}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1">David Gaddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01933">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an improved model for voicing silent speech, where
audio is synthesized from facial electromyography (EMG) signals. To give our
model greater flexibility to learn its own input features, we directly use EMG
signals as input in the place of hand-designed features used by prior work. Our
model uses convolutional layers to extract features from the signals and
Transformer layers to propagate information across longer distances. To provide
better signal for learning, we also introduce an auxiliary task of predicting
phoneme labels in addition to predicting speech audio features. On an open
vocabulary intelligibility evaluation, our model improves the state of the art
for this task by an absolute 25.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement learning for pursuit and evasion of microswimmers at low Reynolds number. (arXiv:2106.08609v1 [physics.flu-dyn] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Borra_F/0/1/0/all/0/1">Francesco Borra</a>, <a href="http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1">Luca Biferale</a>, <a href="http://arxiv.org/find/physics/1/au:+Cencini_M/0/1/0/all/0/1">Massimo Cencini</a>, <a href="http://arxiv.org/find/physics/1/au:+Celani_A/0/1/0/all/0/1">Antonio Celani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08609">
                                    <div class="article-summary-box-inner">
                                        <span>Aquatic organisms can use hydrodynamic cues to navigate, find their preys and
escape from predators. We consider a model of two competing microswimmers
engaged in a pursue-evasion task while immersed in a low-Reynolds-number
environment. The players have limited abilities: they can only sense
hydrodynamic disturbances, which provide some cue about the opponent&#x27;s
position, and perform simple manoeuvres. The goal of the pursuer is to
capturethe evader in the shortest possible time. Conversely the evader aims at
deferring capture as much as possible. We show that by means of Reinforcement
Learning the players find efficient and physically explainable strategies which
non-trivially exploit the hydrodynamic environment. This Letter offers a
proof-of-concept for the use of Reinforcement Learning to discover
prey-predator strategies in aquatic environments, with potential applications
to underwater robotics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Represent Action Values as a Hypergraph on the Action Vertices. (arXiv:2010.14680v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tavakoli_A/0/1/0/all/0/1">Arash Tavakoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatemi_M/0/1/0/all/0/1">Mehdi Fatemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kormushev_P/0/1/0/all/0/1">Petar Kormushev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14680">
                                    <div class="article-summary-box-inner">
                                        <span>Action-value estimation is a critical component of many reinforcement
learning (RL) methods whereby sample complexity relies heavily on how fast a
good estimator for action value can be learned. By viewing this problem through
the lens of representation learning, good representations of both state and
action can facilitate action-value estimation. While advances in deep learning
have seamlessly driven progress in learning state representations, given the
specificity of the notion of agency to RL, little attention has been paid to
learning action representations. We conjecture that leveraging the
combinatorial structure of multi-dimensional action spaces is a key ingredient
for learning good representations of action. To test this, we set forth the
action hypergraph networks framework -- a class of functions for learning
action representations in multi-dimensional discrete action spaces with a
structural inductive bias. Using this framework we realise an agent class based
on a combination with deep Q-networks, which we dub hypergraph Q-networks. We
show the effectiveness of our approach on a myriad of domains: illustrative
prediction problems under minimal confounding effects, Atari 2600 games, and
discretised physical control benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-NERD: A Few-Shot Named Entity Recognition Dataset. (arXiv:2105.07464v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guangwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yulin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaobin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengjun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07464">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, considerable literature has grown up around the theme of few-shot
named entity recognition (NER), but little published benchmark data
specifically focused on the practical and challenging task. Current approaches
collect existing supervised NER datasets and re-organize them to the few-shot
setting for empirical study. These strategies conventionally aim to recognize
coarse-grained entity types with few examples, while in practice, most unseen
entity types are fine-grained. In this paper, we present Few-NERD, a
large-scale human-annotated few-shot NER dataset with a hierarchy of 8
coarse-grained and 66 fine-grained entity types. Few-NERD consists of 188,238
sentences from Wikipedia, 4,601,160 words are included and each is annotated as
context or a part of a two-level entity type. To the best of our knowledge,
this is the first few-shot NER dataset and the largest human-crafted NER
dataset. We construct benchmark tasks with different emphases to
comprehensively assess the generalization capability of models. Extensive
empirical results and analysis show that Few-NERD is challenging and the
problem requires further research. We make Few-NERD public at
https://ningding97.github.io/fewnerd/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Topological Framework for Deep Learning. (arXiv:2008.13697v13 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1">Mustafa Hajij</a>, <a href="http://arxiv.org/find/cs/1/au:+Istvan_K/0/1/0/all/0/1">Kyle Istvan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.13697">
                                    <div class="article-summary-box-inner">
                                        <span>We utilize classical facts from topology to show that the classification
problem in machine learning is always solvable under very mild conditions.
Furthermore, we show that a softmax classification network acts on an input
topological space by a finite sequence of topological moves to achieve the
classification task. Moreover, given a training dataset, we show how
topological formalism can be used to suggest the appropriate architectural
choices for neural networks designed to be trained as classifiers on the data.
Finally, we show how the architecture of a neural network cannot be chosen
independently from the shape of the underlying data. To demonstrate these
results, we provide example datasets and show how they are acted upon by neural
nets from this topological perspective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Invariant Adversarial Learning. (arXiv:2104.00322v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levi_M/0/1/0/all/0/1">Matan Levi</a>, <a href="http://arxiv.org/find/cs/1/au:+Attias_I/0/1/0/all/0/1">Idan Attias</a>, <a href="http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1">Aryeh Kontorovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00322">
                                    <div class="article-summary-box-inner">
                                        <span>The phenomenon of adversarial examples illustrates one of the most basic
vulnerabilities of deep neural networks. Among the variety of techniques
introduced to surmount this inherent weakness, adversarial training has emerged
as the most common and efficient strategy to achieve robustness. Typically,
this is achieved by balancing robust and natural objectives. In this work, we
aim to achieve better trade-off between robust and natural performances by
enforcing a domain-invariant feature representation. We present a new
adversarial training method, Domain Invariant Adversarial Learning (DIAL),
which learns a feature representation which is both robust and domain
invariant. DIAL uses a variant of Domain Adversarial Neural Network (DANN) on
the natural domain and its corresponding adversarial domain. In a case where
the source domain consists of natural examples and the target domain is the
adversarially perturbed examples, our method learns a feature representation
constrained not to discriminate between the natural and adversarial examples,
and can therefore achieve a more robust representation. Our experiments
indicate that our method improves both robustness and natural accuracy, when
compared to current state-of-the-art adversarial training methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recent Advances in Large Margin Learning. (arXiv:2103.13598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiwen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13598">
                                    <div class="article-summary-box-inner">
                                        <span>This paper serves as a survey of recent advances in large margin training and
its theoretical foundations, mostly for (nonlinear) deep neural networks (DNNs)
that are probably the most prominent machine learning models for large-scale
data in the community over the past decade. We generalize the formulation of
classification margins from classical research to latest DNNs, summarize
theoretical connections between the margin, network generalization, and
robustness, and introduce recent efforts in enlarging the margins for DNNs
comprehensively. Since the viewpoint of different methods is discrepant, we
categorize them into groups for ease of comparison and discussion in the paper.
Hopefully, our discussions and overview inspire new research work in the
community that aim to improve the performance of DNNs, and we also point to
directions where the large margin principle can be verified to provide
theoretical evidence why certain regularizations for DNNs function well in
practice. We managed to shorten the paper such that the crucial spirit of large
margin learning and related methods are better emphasized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intriguing Properties of Contrastive Losses. (arXiv:2011.02803v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Calvin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lala Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02803">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive loss and its variants have become very popular recently for
learning visual representations without supervision. In this work, we study
three intriguing properties of contrastive learning. We first generalize the
standard contrastive loss to a broader family of losses, and we find that
various instantiations of the generalized loss perform similarly under the
presence of a multi-layer non-linear projection head. We then study if
instance-based contrastive learning (such as in SimCLR, MoCo, BYOL, and so on,
which are based on global image representation) can learn well on images with
multiple objects present. We find that meaningful hierarchical local features
can be learned despite the fact that these objectives operate on global
instance-level features.

Finally, we study an intriguing phenomenon of feature suppression among
competing features shared across augmented views, such as &quot;color distribution&quot;
vs &quot;object class&quot;. We construct datasets with explicit and controllable
competing features, and show that, for contrastive learning, a few bits of
easy-to-learn shared features can suppress, and even fully prevent, the
learning of other sets of competing features. In scenarios where there are
multiple objects in an image, the dominant object would suppress the learning
of smaller objects. Existing contrastive learning methods critically rely on
data augmentation to favor certain sets of features over others, and face
potential limitation for scenarios where existing augmentations cannot fully
address the feature suppression. This poses open challenges to existing
contrastive learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why flatness does and does not correlate with generalization for deep neural networks. (arXiv:2103.06219v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuofeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1">Isaac Reid</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1">Guillermo Valle P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1">Ard Louis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06219">
                                    <div class="article-summary-box-inner">
                                        <span>The intuition that local flatness of the loss landscape is correlated with
better generalization for deep neural networks (DNNs) has been explored for
decades, spawning many different flatness measures. Recently, this link with
generalization has been called into question by a demonstration that many
measures of flatness are vulnerable to parameter re-scaling which arbitrarily
changes their value without changing neural network outputs.

Here we show that, in addition, some popular variants of SGD such as Adam and
Entropy-SGD, can also break the flatness-generalization correlation. As an
alternative to flatness measures, we use a function based picture and propose
using the log of Bayesian prior upon initialization, $\log P(f)$, as a
predictor of the generalization when a DNN converges on function $f$ after
training to zero error. The prior is directly proportional to the Bayesian
posterior for functions that give zero error on a test set. For the case of
image classification, we show that $\log P(f)$ is a significantly more robust
predictor of generalization than flatness measures are.

Whilst local flatness measures fail under parameter re-scaling, the
prior/posterior, which is global quantity, remains invariant under re-scaling.
Moreover, the correlation with generalization as a function of data complexity
remains good for different variants of SGD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Inference Queries with Bayesian Optimization. (arXiv:2102.05308v2 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lockhart_B/0/1/0/all/0/1">Brandon Lockhart</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jinglin Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Weiyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1">Eugene Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05308">
                                    <div class="article-summary-box-inner">
                                        <span>Obtaining an explanation for an SQL query result can enrich the analysis
experience, reveal data errors, and provide deeper insight into the data.
Inference query explanation seeks to explain unexpected aggregate query results
on inference data; such queries are challenging to explain because an
explanation may need to be derived from the source, training, or inference data
in an ML pipeline. In this paper, we model an objective function as a black-box
function and propose BOExplain, a novel framework for explaining inference
queries using Bayesian optimization (BO). An explanation is a predicate
defining the input tuples that should be removed so that the query result of
interest is significantly affected. BO - a technique for finding the global
optimum of a black-box function - is used to find the best predicate. We
develop two new techniques (individual contribution encoding and warm start) to
handle categorical variables. We perform experiments showing that the
predicates found by BOExplain have a higher degree of explanation compared to
those found by the state-of-the-art query explanation engines. We also show
that BOExplain is effective at deriving explanations for inference queries from
source and training data on a variety of real-world datasets. BOExplain is
open-sourced as a Python package at https://github.com/sfu-db/BOExplain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness in Credit Scoring: Assessment, Implementation and Profit Implications. (arXiv:2103.01907v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kozodoi_N/0/1/0/all/0/1">Nikita Kozodoi</a>, <a href="http://arxiv.org/find/stat/1/au:+Jacob_J/0/1/0/all/0/1">Johannes Jacob</a>, <a href="http://arxiv.org/find/stat/1/au:+Lessmann_S/0/1/0/all/0/1">Stefan Lessmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01907">
                                    <div class="article-summary-box-inner">
                                        <span>The rise of algorithmic decision-making has spawned much research on fair
machine learning (ML). Financial institutions use ML for building risk
scorecards that support a range of credit-related decisions. Yet, the
literature on fair ML in credit scoring is scarce. The paper makes three
contributions. First, we revisit statistical fairness criteria and examine
their adequacy for credit scoring. Second, we catalog algorithmic options for
incorporating fairness goals in the ML model development pipeline. Last, we
empirically compare different fairness processors in a profit-oriented credit
scoring context using real-world data. The empirical results substantiate the
evaluation of fairness measures, identify suitable options to implement fair
credit scoring, and clarify the profit-fairness trade-off in lending decisions.
We find that multiple fairness criteria can be approximately satisfied at once
and recommend separation as a proper criterion for measuring the fairness of a
scorecard. We also find fair in-processors to deliver a good balance between
profit and fairness and show that algorithmic discrimination can be reduced to
a reasonable level at a relatively low cost. The codes corresponding to the
paper are available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data. (arXiv:2104.02005v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Qendro_L/0/1/0/all/0/1">Lorena Qendro</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1">Ting Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1">Cecilia Mascolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02005">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, sound-based COVID-19 detection studies have shown great promise to
achieve scalable and prompt digital pre-screening. However, there are still two
unsolved issues hindering the practice. First, collected datasets for model
training are often imbalanced, with a considerably smaller proportion of users
tested positive, making it harder to learn representative and robust features.
Second, deep learning models are generally overconfident in their predictions.
Clinically, false predictions aggravate healthcare costs. Estimation of the
uncertainty of screening would aid this. To handle these issues, we propose an
ensemble framework where multiple deep learning models for sound-based COVID-19
detection are developed from different but balanced subsets from original data.
As such, data are utilized more effectively compared to traditional up-sampling
and down-sampling approaches: an AUC of 0.74 with a sensitivity of 0.68 and a
specificity of 0.69 is achieved. Simultaneously, we estimate uncertainty from
the disagreement across multiple models. It is shown that false predictions
often yield higher uncertainty, enabling us to suggest the users with certainty
higher than a threshold to repeat the audio test on their phones or to take
clinical tests if digital diagnosis still fails. This study paves the way for a
more robust sound-based COVID-19 automated screening system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Input Gradients Highlight Discriminative Features?. (arXiv:2102.12781v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1">Harshay Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1">Praneeth Netrapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12781">
                                    <div class="article-summary-box-inner">
                                        <span>Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,
Smilkov et al., 2017] that provide instance-specific explanations of model
predictions are often based on assumption (A): magnitude of input gradients --
gradients of logits with respect to input -- noisily highlight discriminative
task-relevant features. In this work, we test the validity of assumption (A)
using a three-pronged approach. First, we develop an evaluation framework,
DiffROAR, to test assumption (A) on four image classification benchmarks. Our
results suggest that (i) input gradients of standard models (i.e., trained on
original data) may grossly violate (A), whereas (ii) input gradients of
adversarially robust models satisfy (A). Second, we then introduce BlockMNIST,
an MNIST-based semi-real dataset, that by design encodes a priori knowledge of
discriminative features. Our analysis on BlockMNIST leverages this information
to validate as well as characterize differences between input gradient
attributions of standard and robust models. Finally, we theoretically prove
that our empirical findings hold on a simplified version of the BlockMNIST
dataset. Specifically, we prove that input gradients of standard
one-hidden-layer MLPs trained on this dataset do not highlight
instance-specific signal coordinates, thus grossly violating assumption (A).
Our findings motivate the need to formalize and test common assumptions in
interpretability in a falsifiable manner [Leavitt and Morcos, 2020].
Additionally, we believe that the DiffROAR evaluation framework and
BlockMNIST-based datasets can serve as sanity checks to audit instance-specific
interpretability methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unlocking Pixels for Reinforcement Learning via Implicit Attention. (arXiv:2102.04353v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Deepali Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1">Valerii Likhosherstov</a>, <a href="http://arxiv.org/find/cs/1/au:+Santara_A/0/1/0/all/0/1">Anirban Santara</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yunhao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04353">
                                    <div class="article-summary-box-inner">
                                        <span>There has recently been significant interest in training reinforcement
learning (RL) agents in vision-based environments. This poses many challenges,
such as high dimensionality and potential for observational overfitting through
spurious correlations. A promising approach to solve both of these problems is
a self-attention bottleneck, which provides a simple and effective framework
for learning high performing policies, even in the presence of distractions.
However, due to poor scalability of attention architectures, these methods do
not scale beyond low resolution visual inputs, using large patches (thus small
attention matrices). In this paper we make use of new efficient attention
algorithms, recently shown to be highly effective for Transformers, and
demonstrate that these new techniques can be applied in the RL setting. This
allows our attention-based controllers to scale to larger visual inputs, and
facilitate the use of smaller patches, even individual pixels, improving
generalization. In addition, we propose a new efficient algorithm approximating
softmax attention with what we call hybrid random features, leveraging the
theory of angular kernels. We show theoretically and empirically that hybrid
random features is a promising approach when using attention for vision-based
RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Hierarchical Variational Autoencoders for Large-Scale Video Prediction. (arXiv:2103.04174v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bohan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Suraj Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Martin-Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04174">
                                    <div class="article-summary-box-inner">
                                        <span>A video prediction model that generalizes to diverse scenes would enable
intelligent agents such as robots to perform a variety of tasks via planning
with the model. However, while existing video prediction models have produced
promising results on small datasets, they suffer from severe underfitting when
trained on large and diverse datasets. To address this underfitting challenge,
we first observe that the ability to train larger video prediction models is
often bottlenecked by the memory constraints of GPUs or TPUs. In parallel, deep
hierarchical latent variable models can produce higher quality predictions by
capturing the multi-level stochasticity of future observations, but end-to-end
optimization of such models is notably difficult. Our key insight is that
greedy and modular optimization of hierarchical autoencoders can simultaneously
address both the memory constraints and the optimization challenges of
large-scale video prediction. We introduce Greedy Hierarchical Variational
Autoencoders (GHVAEs), a method that learns high-fidelity video predictions by
greedily training each level of a hierarchical autoencoder. In comparison to
state-of-the-art models, GHVAEs provide 17-55% gains in prediction performance
on four video datasets, a 35-40% higher success rate on real robot tasks, and
can improve performance monotonically by simply adding more modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus Spike Proteins. (arXiv:2105.00351v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chung_M/0/1/0/all/0/1">Moo K. Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Ombao_H/0/1/0/all/0/1">Hernando Ombao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00351">
                                    <div class="article-summary-box-inner">
                                        <span>Topological data analysis, including persistent homology, has undergone
significant development in recent years. However, one outstanding challenge is
to build a coherent statistical inference procedure on persistent diagrams. The
paired dependent data structure, which are the births and deaths in persistent
diagrams, adds complexity to statistical inference. In this paper, we present a
new lattice path representation for persistent diagrams. A new exact
statistical inference procedure is developed for lattice paths via
combinatorial enumerations. The proposed lattice path method is applied to
study the topological characterization of the protein structures of the
COVID-19 virus. We demonstrate that there are topological changes during the
conformational change of spike proteins, a necessary step in infecting host
cells.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Characterizing GAN Convergence Through Proximal Duality Gap. (arXiv:2105.04801v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sidheekh_S/0/1/0/all/0/1">Sahil Sidheekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Aimen_A/0/1/0/all/0/1">Aroof Aimen</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_N/0/1/0/all/0/1">Narayanan C. Krishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04801">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the accomplishments of Generative Adversarial Networks (GANs) in
modeling data distributions, training them remains a challenging task. A
contributing factor to this difficulty is the non-intuitive nature of the GAN
loss curves, which necessitates a subjective evaluation of the generated output
to infer training progress. Recently, motivated by game theory, duality gap has
been proposed as a domain agnostic measure to monitor GAN training. However, it
is restricted to the setting when the GAN converges to a Nash equilibrium. But
GANs need not always converge to a Nash equilibrium to model the data
distribution. In this work, we extend the notion of duality gap to proximal
duality gap that is applicable to the general context of training GANs where
Nash equilibria may not exist. We show theoretically that the proximal duality
gap is capable of monitoring the convergence of GANs to a wider spectrum of
equilibria that subsumes Nash equilibria. We also theoretically establish the
relationship between the proximal duality gap and the divergence between the
real and generated data distributions for different GAN formulations. Our
results provide new insights into the nature of GAN convergence. Finally, we
validate experimentally the usefulness of proximal duality gap for monitoring
and influencing GAN training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Bayesian Optimization. (arXiv:2006.05109v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Perrone_V/0/1/0/all/0/1">Valerio Perrone</a>, <a href="http://arxiv.org/find/stat/1/au:+Donini_M/0/1/0/all/0/1">Michele Donini</a>, <a href="http://arxiv.org/find/stat/1/au:+Zafar_M/0/1/0/all/0/1">Muhammad Bilal Zafar</a>, <a href="http://arxiv.org/find/stat/1/au:+Schmucker_R/0/1/0/all/0/1">Robin Schmucker</a>, <a href="http://arxiv.org/find/stat/1/au:+Kenthapadi_K/0/1/0/all/0/1">Krishnaram Kenthapadi</a>, <a href="http://arxiv.org/find/stat/1/au:+Archambeau_C/0/1/0/all/0/1">C&#xe9;dric Archambeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05109">
                                    <div class="article-summary-box-inner">
                                        <span>Given the increasing importance of machine learning (ML) in our lives,
several algorithmic fairness techniques have been proposed to mitigate biases
in the outcomes of the ML models. However, most of these techniques are
specialized to cater to a single family of ML models and a specific definition
of fairness, limiting their adaptibility in practice. We introduce a general
constrained Bayesian optimization (BO) framework to optimize the performance of
any ML model while enforcing one or multiple fairness constraints. BO is a
model-agnostic optimization method that has been successfully applied to
automatically tune the hyperparameters of ML models. We apply BO with fairness
constraints to a range of popular models, including random forests, gradient
boosting, and neural networks, showing that we can obtain accurate and fair
solutions by acting solely on the hyperparameters. We also show empirically
that our approach is competitive with specialized techniques that enforce
model-specific fairness constraints, and outperforms preprocessing methods that
learn fair representations of the input data. Moreover, our method can be used
in synergy with such specialized fairness techniques to tune their
hyperparameters. Finally, we study the relationship between fairness and the
hyperparameters selected by BO. We observe a correlation between regularization
and unbiased models, explaining why acting on the hyperparameters leads to ML
models that generalize well and are fair.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Power of the Weisfeiler-Leman Algorithm for Machine Learning with Graphs. (arXiv:2105.05911v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1">Christopher Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1">Matthias Fey</a>, <a href="http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1">Nils M. Kriege</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05911">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, algorithms and neural architectures based on the
Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism
problem, emerged as a powerful tool for (supervised) machine learning with
graphs and relational data. Here, we give a comprehensive overview of the
algorithm&#x27;s use in a machine learning setting. We discuss the theoretical
background, show how to use it for supervised graph- and node classification,
discuss recent extensions, and its connection to neural architectures.
Moreover, we give an overview of current applications and future directions to
stimulate research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing is Knowing! Fact-based Visual Question Answering using Knowledge Graph Embeddings. (arXiv:2012.15484v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramnath_K/0/1/0/all/0/1">Kiran Ramnath</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1">Mark Hasegawa-Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15484">
                                    <div class="article-summary-box-inner">
                                        <span>Fact-based Visual Question Answering (FVQA), a challenging variant of VQA,
requires a QA-system to include facts from a diverse knowledge graph (KG) in
its reasoning process to produce an answer. Large KGs, especially common-sense
KGs, are known to be incomplete, i.e., not all non-existent facts are always
incorrect. Therefore, being able to reason over incomplete KGs for QA is a
critical requirement in real-world applications that has not been addressed
extensively in the literature. We develop a novel QA architecture that allows
us to reason over incomplete KGs, something current FVQA state-of-the-art
(SOTA) approaches lack due to their critical reliance on fact retrieval. We use
KG Embeddings, a technique widely used for KG completion, for the downstream
task of FVQA. We also employ a new image representation technique we call
&#x27;Image-as-Knowledge&#x27; to enable this capability, alongside a simple one-step
CoAttention mechanism to attend to text and image during QA. Our FVQA
architecture is faster during inference time, being O(m), as opposed to
existing FVQA SOTA methods which are O(N log N), where m &#x3D; number of vertices,
N &#x3D; number of edges &#x3D; O(m^2). KG embeddings are shown to hold complementary
information to word embeddings: a combination of both metrics permits
performance comparable to SOTA methods in the standard answer retrieval task,
and significantly better (26% absolute) in the proposed missing-edge reasoning
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">State Entropy Maximization with Random Encoders for Efficient Exploration. (arXiv:2102.09430v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1">Younggyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09430">
                                    <div class="article-summary-box-inner">
                                        <span>Recent exploration methods have proven to be a recipe for improving
sample-efficiency in deep reinforcement learning (RL). However, efficient
exploration in high-dimensional observation spaces still remains a challenge.
This paper presents Random Encoders for Efficient Exploration (RE3), an
exploration method that utilizes state entropy as an intrinsic reward. In order
to estimate state entropy in environments with high-dimensional observations,
we utilize a k-nearest neighbor entropy estimator in the low-dimensional
representation space of a convolutional encoder. In particular, we find that
the state entropy can be estimated in a stable and compute-efficient manner by
utilizing a randomly initialized encoder, which is fixed throughout training.
Our experiments show that RE3 significantly improves the sample-efficiency of
both model-free and model-based RL methods on locomotion and navigation tasks
from DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3
allows learning diverse behaviors without extrinsic rewards, effectively
improving sample-efficiency in downstream tasks. Source code and videos are
available at https://sites.google.com/view/re3-rl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability. (arXiv:2103.00065v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1">Jeremy M. Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaur_S/0/1/0/all/0/1">Simran Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1">Ameet Talwalkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00065">
                                    <div class="article-summary-box-inner">
                                        <span>We empirically demonstrate that full-batch gradient descent on neural network
training objectives typically operates in a regime we call the Edge of
Stability. In this regime, the maximum eigenvalue of the training loss Hessian
hovers just above the numerical value $2 / \text{(step size)}$, and the
training loss behaves non-monotonically over short timescales, yet consistently
decreases over long timescales. Since this behavior is inconsistent with
several widespread presumptions in the field of optimization, our findings
raise questions as to whether these presumptions are relevant to neural network
training. We hope that our findings will inspire future efforts aimed at
rigorously understanding optimization at the Edge of Stability. Code is
available at https://github.com/locuslab/edge-of-stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations. (arXiv:2011.12854v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stammer_W/0/1/0/all/0/1">Wolfgang Stammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1">Patrick Schramowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12854">
                                    <div class="article-summary-box-inner">
                                        <span>Most explanation methods in deep learning map importance estimates for a
model&#x27;s prediction back to the original input space. These &quot;visual&quot;
explanations are often insufficient, as the model&#x27;s actual concept remains
elusive. Moreover, without insights into the model&#x27;s semantic concept, it is
difficult -- if not impossible -- to intervene on the model&#x27;s behavior via its
explanations, called Explanatory Interactive Learning. Consequently, we propose
to intervene on a Neuro-Symbolic scene representation, which allows one to
revise the model on the semantic level, e.g. &quot;never focus on the color to make
your decision&quot;. We compiled a novel confounded visual scene data set, the
CLEVR-Hans data set, capturing complex compositions of different objects. The
results of our experiments on CLEVR-Hans demonstrate that our semantic
explanations, i.e. compositional explanations at a per-object level, can
identify confounders that are not identifiable using &quot;visual&quot; explanations
only. More importantly, feedback on this semantic level makes it possible to
revise the model from focusing on these factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defense Against Reward Poisoning Attacks in Reinforcement Learning. (arXiv:2102.05776v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banihashem_K/0/1/0/all/0/1">Kiarash Banihashem</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1">Adish Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Radanovic_G/0/1/0/all/0/1">Goran Radanovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05776">
                                    <div class="article-summary-box-inner">
                                        <span>We study defense strategies against reward poisoning attacks in reinforcement
learning. As a threat model, we consider attacks that minimally alter rewards
to make the attacker&#x27;s target policy uniquely optimal under the poisoned
rewards, with the optimality gap specified by an attack parameter. Our goal is
to design agents that are robust against such attacks in terms of the
worst-case utility w.r.t. the true, unpoisoned, rewards while computing their
policies under the poisoned rewards. We propose an optimization framework for
deriving optimal defense policies, both when the attack parameter is known and
unknown. Moreover, we show that defense policies that are solutions to the
proposed optimization problems have provable performance guarantees. In
particular, we provide the following bounds with respect to the true,
unpoisoned, rewards: a) lower bounds on the expected return of the defense
policies, and b) upper bounds on how suboptimal these defense policies are
compared to the attacker&#x27;s target policy. We conclude the paper by illustrating
the intuitions behind our formal results, and showing that the derived bounds
are non-trivial.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of MRR and NDCG models for Visual Dialog. (arXiv:2104.07511v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1">Idan Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07511">
                                    <div class="article-summary-box-inner">
                                        <span>Assessing an AI agent that can converse in human language and understand
visual content is challenging. Generation metrics, such as BLEU scores favor
correct syntax over semantics. Hence a discriminative approach is often used,
where an agent ranks a set of candidate options. The mean reciprocal rank (MRR)
metric evaluates the model performance by taking into account the rank of a
single human-derived answer. This approach, however, raises a new challenge:
the ambiguity and synonymy of answers, for instance, semantic equivalence
(e.g., &#x60;yeah&#x27; and &#x60;yes&#x27;). To address this, the normalized discounted cumulative
gain (NDCG) metric has been used to capture the relevance of all the correct
answers via dense annotations. However, the NDCG metric favors the usually
applicable uncertain answers such as &#x60;I don&#x27;t know. Crafting a model that
excels on both MRR and NDCG metrics is challenging. Ideally, an AI agent should
answer a human-like reply and validate the correctness of any answer. To
address this issue, we describe a two-step non-parametric ranking approach that
can merge strong MRR and NDCG models. Using our approach, we manage to keep
most MRR state-of-the-art performance (70.41% vs. 71.24%) and the NDCG
state-of-the-art performance (72.16% vs. 75.35%). Moreover, our approach won
the recent Visual Dialog 2020 challenge. Source code is available at
https://github.com/idansc/mrr-ndcg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning on a Budget via Teacher Imitation. (arXiv:2104.08440v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilhan_E/0/1/0/all/0/1">Ercument Ilhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gow_J/0/1/0/all/0/1">Jeremy Gow</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1">Diego Perez-Liebana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08440">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Reinforcement Learning (RL) techniques can benefit greatly from
leveraging prior experience, which can be either self-generated or acquired
from other entities. Action advising is a framework that provides a flexible
way to transfer such knowledge in the form of actions between teacher-student
peers. However, due to the realistic concerns, the number of these interactions
is limited with a budget; therefore, it is crucial to perform these in the most
appropriate moments. There have been several promising studies recently that
address this problem setting especially from the student&#x27;s perspective. Despite
their success, they have some shortcomings when it comes to the practical
applicability and integrity as an overall solution to the learning from advice
challenge. In this paper, we extend the idea of advice reusing via teacher
imitation to construct a unified approach that addresses both advice collection
and advice utilisation problems. We also propose a method to automatically tune
the relevant hyperparameters of these components on-the-fly to make it able to
adapt to any task with minimal human intervention. The experiments we performed
in $5$ different Atari games verify that our algorithm either surpasses or
performs on-par with its top competitors while being far simpler to be
employed. Furthermore, its individual components are also found to be providing
significant advantages alone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jacqueline Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1">Adam Vagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09507">
                                    <div class="article-summary-box-inner">
                                        <span>Text classifiers are at the core of many NLP applications and use a variety
of algorithmic approaches and software. This paper introduces infrastructure
and methodologies for text classifiers based on large-scale regular
expressions. In particular, we describe how Facebook determines if a given
piece of text - anything from a hashtag to a post - belongs to a narrow topic
such as COVID-19. To fully define a topic and evaluate classifier performance
we employ human-guided iterations of keyword discovery, but do not require
labeled data. For COVID-19, we build two sets of regular expressions: (1) for
66 languages, with 99% precision and recall &gt;50%, (2) for the 11 most common
languages, with precision &gt;90% and recall &gt;90%. Regular expressions enable
low-latency queries from multiple platforms. Response to challenges like
COVID-19 is fast and so are revisions. Comparisons to a DNN classifier show
explainable results, higher precision and recall, and less overfitting. Our
learnings can be applied to other narrow-topic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural Networks via Guided Distribution Calibration. (arXiv:2102.08946v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhiqiang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zechun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Kwang-Ting Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1">Marios Savvides</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08946">
                                    <div class="article-summary-box-inner">
                                        <span>Previous studies dominantly target at self-supervised learning on real-valued
networks and have achieved many promising results. However, on the more
challenging binary neural networks (BNNs), this task has not yet been fully
explored in the community. In this paper, we focus on this more difficult
scenario: learning networks where both weights and activations are binary,
meanwhile, without any human annotated labels. We observe that the commonly
used contrastive objective is not satisfying on BNNs for competitive accuracy,
since the backbone network contains relatively limited capacity and
representation ability. Hence instead of directly applying existing
self-supervised methods, which cause a severe decline in performance, we
present a novel guided learning paradigm from real-valued to distill binary
networks on the final prediction distribution, to minimize the loss and obtain
desirable accuracy. Our proposed method can boost the simple contrastive
learning baseline by an absolute gain of 5.5~15% on BNNs. We further reveal
that it is difficult for BNNs to recover the similar predictive distributions
as real-valued models when training without labels. Thus, how to calibrate them
is key to address the degradation in performance. Extensive experiments are
conducted on the large-scale ImageNet and downstream datasets. Our method
achieves substantial improvement over the simple contrastive learning baseline,
and is even comparable to many mainstream supervised BNN methods. Code is
available at https://github.com/szq0214/S2-BNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixture of Robust Experts (MoRE). (arXiv:2104.10586v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaidi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldhahn_R/0/1/0/all/0/1">Ryan Goldhahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10586">
                                    <div class="article-summary-box-inner">
                                        <span>To tackle the susceptibility of deep neural networks to examples, the
adversarial training has been proposed which provides a notion of robust
through an inner maximization problem presenting the first-order embedded
within the outer minimization of the training loss. To generalize the
adversarial robustness over different perturbation types, the adversarial
training method has been augmented with the improved inner maximization
presenting a union of multiple perturbations e.g., various $\ell_p$
norm-bounded perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">This Looks Like That... Does it? Shortcomings of Latent Space Prototype Interpretability in Deep Networks. (arXiv:2105.02968v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_A/0/1/0/all/0/1">Adrian Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanconi_C/0/1/0/all/0/1">Claudio Fanconi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rade_R/0/1/0/all/0/1">Rahul Rade</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks that yield human interpretable decisions by
architectural design have lately become an increasingly popular alternative to
post hoc interpretation of traditional black-box models. Among these networks,
the arguably most widespread approach is so-called prototype learning, where
similarities to learned latent prototypes serve as the basis of classifying an
unseen data point. In this work, we point to an important shortcoming of such
approaches. Namely, there is a semantic gap between similarity in latent space
and similarity in input space, which can corrupt interpretability. We design
two experiments that exemplify this issue on the so-called ProtoPNet.
Specifically, we find that this network&#x27;s interpretability mechanism can be led
astray by intentionally crafted or even JPEG compression artefacts, which can
produce incomprehensible decisions. We argue that practitioners ought to have
this shortcoming in mind when deploying prototype-based models in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variance-Dependent Best Arm Identification. (arXiv:2106.10417v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chao Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaojin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10417">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of identifying the best arm in a stochastic multi-armed
bandit game. Given a set of $n$ arms indexed from $1$ to $n$, each arm $i$ is
associated with an unknown reward distribution supported on $[0,1]$ with mean
$\theta_i$ and variance $\sigma_i^2$. Assume $\theta_1 &gt; \theta_2 \geq \cdots
\geq\theta_n$. We propose an adaptive algorithm which explores the gaps and
variances of the rewards of the arms and makes future decisions based on the
gathered information using a novel approach called \textit{grouped median
elimination}. The proposed algorithm guarantees to output the best arm with
probability $(1-\delta)$ and uses at most $O \left(\sum_{i &#x3D; 1}^n
\left(\frac{\sigma_i^2}{\Delta_i^2} + \frac{1}{\Delta_i}\right)(\ln \delta^{-1}
+ \ln \ln \Delta_i^{-1})\right)$ samples, where $\Delta_i$ ($i \geq 2$) denotes
the reward gap between arm $i$ and the best arm and we define $\Delta_1 &#x3D;
\Delta_2$. This achieves a significant advantage over the variance-independent
algorithms in some favorable scenarios and is the first result that removes the
extra $\ln n$ factor on the best arm compared with the state-of-the-art. We
further show that $\Omega \left( \sum_{i &#x3D; 1}^n \left(
\frac{\sigma_i^2}{\Delta_i^2} + \frac{1}{\Delta_i} \right) \ln \delta^{-1}
\right)$ samples are necessary for an algorithm to achieve the same goal,
thereby illustrating that our algorithm is optimal up to doubly logarithmic
terms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Designing Interpretable Approximations to Deep Reinforcement Learning. (arXiv:2010.14785v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dahlin_N/0/1/0/all/0/1">Nathan Dahlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalagarla_K/0/1/0/all/0/1">Krishna Chaitanya Kalagarla</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1">Nikhil Naik</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuzzo_P/0/1/0/all/0/1">Pierluigi Nuzzo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14785">
                                    <div class="article-summary-box-inner">
                                        <span>In an ever expanding set of research and application areas, deep neural
networks (DNNs) set the bar for algorithm performance. However, depending upon
additional constraints such as processing power and execution time limits, or
requirements such as verifiable safety guarantees, it may not be feasible to
actually use such high-performing DNNs in practice. Many techniques have been
developed in recent years to compress or distill complex DNNs into smaller,
faster or more understandable models and controllers. This work seeks to
identify reduced models that not only preserve a desired performance level, but
also, for example, succinctly explain the latent knowledge represented by a
DNN. We illustrate the effectiveness of the proposed approach on the evaluation
of decision tree variants and kernel machines in the context of benchmark
reinforcement learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EDDA: Explanation-driven Data Augmentation to Improve Model and Explanation Alignment. (arXiv:2105.14162v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruiwen Li</a> (co-first author), <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhibo Zhang</a> (co-first author), <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiani Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1">Jongseong Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1">Yeonjeong Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shim_D/0/1/0/all/0/1">Dongsub Shim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14162">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen the introduction of a range of methods for post-hoc
explainability of image classifier predictions. However, these post-hoc
explanations may not always align perfectly with classifier predictions, which
poses a significant challenge when attempting to debug models based on such
explanations. To this end, we seek a methodology that can improve alignment
between model predictions and explanation method that is both agnostic to the
model and explanation classes and which does not require ground truth
explanations. We achieve this through a novel explanation-driven data
augmentation (EDDA) method that augments the training data with occlusions of
existing data stemming from model-explanations; this is based on the simple
motivating principle that occluding salient regions for the model prediction
should decrease the model confidence in the prediction, while occluding
non-salient regions should not change the prediction -- if the model and
explainer are aligned. To verify that this augmentation method improves model
and explainer alignment, we evaluate the methodology on a variety of datasets,
image classification models, and explanation methods. We verify in all cases
that our explanation-driven data augmentation method improves alignment of the
model and explanation in comparison to no data augmentation and non-explanation
driven data augmentation methods. In conclusion, this approach provides a novel
model- and explainer-agnostic methodology for improving alignment between model
predictions and explanations, which we see as a critical step forward for
practical deployment and debugging of image classification models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proper Value Equivalence. (arXiv:2106.10316v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grimm_C/0/1/0/all/0/1">Christopher Grimm</a>, <a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1">Andr&#xe9; Barreto</a>, <a href="http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1">Gregory Farquhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1">David Silver</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satinder Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10316">
                                    <div class="article-summary-box-inner">
                                        <span>One of the main challenges in model-based reinforcement learning (RL) is to
decide which aspects of the environment should be modeled. The
value-equivalence (VE) principle proposes a simple answer to this question: a
model should capture the aspects of the environment that are relevant for
value-based planning. Technically, VE distinguishes models based on a set of
policies and a set of functions: a model is said to be VE to the environment if
the Bellman operators it induces for the policies yield the correct result when
applied to the functions. As the number of policies and functions increase, the
set of VE models shrinks, eventually collapsing to a single point corresponding
to a perfect model. A fundamental question underlying the VE principle is thus
how to select the smallest sets of policies and functions that are sufficient
for planning. In this paper we take an important step towards answering this
question. We start by generalizing the concept of VE to order-$k$ counterparts
defined with respect to $k$ applications of the Bellman operator. This leads to
a family of VE classes that increase in size as $k \rightarrow \infty$. In the
limit, all functions become value functions, and we have a special
instantiation of VE which we call proper VE or simply PVE. Unlike VE, the PVE
class may contain multiple models even in the limit when all value functions
are used. Crucially, all these models are sufficient for planning, meaning that
they will yield an optimal policy despite the fact that they may ignore many
aspects of the environment. We construct a loss function for learning PVE
models and argue that popular algorithms such as MuZero and Muesli can be
understood as minimizing an upper bound for this loss. We leverage this
connection to propose a modification to MuZero and show that it can lead to
improved performance in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yulun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1">Nicholas Choma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Andrew Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1">Mikaela Cashman</a>, <a href="http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1">&#xc9;rica T. Prates</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Manesh Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1">Ver&#xf3;nica G. Melesse Vergara</a>, <a href="http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1">Austin Clyde</a>, <a href="http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1">Thomas S. Brettin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1">Wibe A. de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1">Neeraj Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1">Martha S. Head</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1">Rick L. Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1">Peter Nugent</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1">Daniel A. Jacobson</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1">James B. Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02190">
                                    <div class="article-summary-box-inner">
                                        <span>We developed Distilled Graph Attention Policy Networks (DGAPNs), a
curiosity-driven reinforcement learning model to generate novel
graph-structured chemical representations that optimize user-defined objectives
by efficiently navigating a physically constrained domain. The framework is
examined on the task of generating molecules that are designed to bind,
noncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial
Graph Attention Network (sGAT) that leverages self-attention over both node and
edge attributes as well as encoding spatial structure -- this capability is of
considerable interest in areas such as molecular and synthetic biology and drug
discovery. An attentional policy network is then introduced to learn decision
rules for a dynamic, fragment-based chemical environment, and state-of-the-art
policy gradient techniques are employed to train the network with enhanced
stability. Exploration is efficiently encouraged by incorporating innovation
reward bonuses learned and proposed by random network distillation. In
experiments, our framework achieved outstanding results compared to
state-of-the-art algorithms, while increasing the diversity of proposed
molecules and reducing the complexity of paths to chemical synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Self Reported Symptoms Predict Daily COVID-19 Cases?. (arXiv:2105.08321v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1">Parth Patwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_V/0/1/0/all/0/1">Viswanatha Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukumaran_R/0/1/0/all/0/1">Rohan Sukumaran</a>, <a href="http://arxiv.org/find/cs/1/au:+TV_S/0/1/0/all/0/1">Sethuraman TV</a>, <a href="http://arxiv.org/find/cs/1/au:+Nashnoush_E/0/1/0/all/0/1">Eptehal Nashnoush</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_S/0/1/0/all/0/1">Sheshank Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaur_R/0/1/0/all/0/1">Rishemjit Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Abhishek Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1">Ramesh Raskar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08321">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 pandemic has impacted lives and economies across the globe,
leading to many deaths. While vaccination is an important intervention, its
roll-out is slow and unequal across the globe. Therefore, extensive testing
still remains one of the key methods to monitor and contain the virus. Testing
on a large scale is expensive and arduous. Hence, we need alternate methods to
estimate the number of cases. Online surveys have been shown to be an effective
method for data collection amidst the pandemic. In this work, we develop
machine learning models to estimate the prevalence of COVID-19 using
self-reported symptoms. Our best model predicts the daily cases with a mean
absolute error (MAE) of 226.30 (normalized MAE of 27.09%) per state, which
demonstrates the possibility of predicting the actual number of confirmed cases
by utilizing self-reported symptoms. The models are developed at two levels of
data granularity - local models, which are trained at the state level, and a
single global model which is trained on the combined data aggregated across all
states. Our results indicate a lower error on the local models as opposed to
the global model. In addition, we also show that the most important symptoms
(features) vary considerably from state to state. This work demonstrates that
the models developed on crowd-sourced data, curated via online platforms, can
complement the existing epidemiological surveillance infrastructure in a
cost-effective manner. The code is publicly available at
https://github.com/parthpatwa/Can-Self-Reported-Symptoms-Predict-Daily-COVID-19-Cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pattern Transfer Learning for Reinforcement Learning in Order Dispatching. (arXiv:2105.13218v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_R/0/1/0/all/0/1">Runzhe Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chengchun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shikai Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13218">
                                    <div class="article-summary-box-inner">
                                        <span>Order dispatch is one of the central problems to ride-sharing platforms.
Recently, value-based reinforcement learning algorithms have shown promising
performance on this problem. However, in real-world applications, the
non-stationarity of the demand-supply system poses challenges to re-utilizing
data generated in different time periods to learn the value function. In this
work, motivated by the fact that the relative relationship between the values
of some states is largely stable across various environments, we propose a
pattern transfer learning framework for value-based reinforcement learning in
the order dispatch problem. Our method efficiently captures the value patterns
by incorporating a concordance penalty. The superior performance of the
proposed method is supported by experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nearly Minimax Optimal Adversarial Imitation Learning with Known and Unknown Transitions. (arXiv:2106.10424v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziniu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10424">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is dedicated to designing provably efficient adversarial imitation
learning (AIL) algorithms that directly optimize policies from expert
demonstrations. Firstly, we develop a transition-aware AIL algorithm named TAIL
with an expert sample complexity of $\tilde{O}(H^{3/2} |S|/\varepsilon)$ under
the known transition setting, where $H$ is the planning horizon, $|S|$ is the
state space size and $\varepsilon$ is desired policy value gap. This improves
upon the previous best bound of $\tilde{O}(H^2 |S| / \varepsilon^2)$ for AIL
methods and matches the lower bound of $\tilde{\Omega} (H^{3/2}
|S|/\varepsilon)$ in [Rajaraman et al., 2021] up to a logarithmic factor. The
key ingredient of TAIL is a fine-grained estimator for expert state-action
distribution, which explicitly utilizes the transition function information.
Secondly, considering practical settings where the transition functions are
usually unknown but environment interaction is allowed, we accordingly develop
a model-based transition-aware AIL algorithm named MB-TAIL. In particular,
MB-TAIL builds an empirical transition model by interacting with the
environment and performs imitation under the recovered empirical model. The
interaction complexity of MB-TAIL is $\tilde{O} (H^3 |S|^2 |A| /
\varepsilon^2)$, which improves the best known result of $\tilde{O} (H^4 |S|^2
|A| / \varepsilon^2)$ in [Shani et al., 2021]. Finally, our theoretical results
are supported by numerical evaluation and detailed analysis on two challenging
MDPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How COVID-19 Have Changed Crowdfunding: Evidence From GoFundMe. (arXiv:2106.09981v1 [cs.CY] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junda Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xupin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09981">
                                    <div class="article-summary-box-inner">
                                        <span>While the long-term effects of COVID-19 are yet to be determined, its
immediate impact on crowdfunding is nonetheless significant. This study takes a
computational approach to more deeply comprehend this change. Using a unique
data set of all the campaigns published over the past two years on GoFundMe, we
explore the factors that have led to the successful funding of a crowdfunding
project. In particular, we study a corpus of crowdfunded projects, analyzing
cover images and other variables commonly present on crowdfunding sites.
Furthermore, we construct a classifier and a regression model to assess the
significance of features based on XGBoost. In addition, we employ
counterfactual analysis to investigate the causality between features and the
success of crowdfunding. More importantly, sentiment analysis and the paired
sample t-test are performed to examine the differences in crowdfunding
campaigns before and after the COVID-19 outbreak that started in March 2020.
First, we note that there is significant racial disparity in crowdfunding
success. Second, we find that sad emotion expressed through the campaign&#x27;s
description became significant after the COVID-19 outbreak. Considering all
these factors, our findings shed light on the impact of COVID-19 on
crowdfunding campaigns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and Robust Online Inference with Stochastic Gradient Descent via Random Scaling. (arXiv:2106.03156v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1">Sokbae Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Liao_Y/0/1/0/all/0/1">Yuan Liao</a>, <a href="http://arxiv.org/find/stat/1/au:+Seo_M/0/1/0/all/0/1">Myung Hwan Seo</a>, <a href="http://arxiv.org/find/stat/1/au:+Shin_Y/0/1/0/all/0/1">Youngki Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03156">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a new method of online inference for a vector of parameters
estimated by the Polyak-Ruppert averaging procedure of stochastic gradient
descent (SGD) algorithms. We leverage insights from time series regression in
econometrics and construct asymptotically pivotal statistics via random
scaling. Our approach is fully operational with online data and is rigorously
underpinned by a functional central limit theorem. Our proposed inference
method has a couple of key advantages over the existing methods. First, the
test statistic is computed in an online fashion with only SGD iterates and the
critical values can be obtained without any resampling methods, thereby
allowing for efficient implementation suitable for massive online data. Second,
there is no need to estimate the asymptotic variance and our inference method
is shown to be robust to changes in the tuning parameters for SGD algorithms in
simulation experiments with synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Outbreak Prediction and Analysis using Self Reported Symptoms. (arXiv:2101.10266v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sukumaran_R/0/1/0/all/0/1">Rohan Sukumaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1">Parth Patwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethuraman_T/0/1/0/all/0/1">T V Sethuraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_S/0/1/0/all/0/1">Sheshank Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanaparti_R/0/1/0/all/0/1">Rishank Kanaparti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1">Joseph Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathur_Y/0/1/0/all/0/1">Yash Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Abhishek Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chopra_A/0/1/0/all/0/1">Ayush Chopra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Myungsun Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramaswamy_P/0/1/0/all/0/1">Priya Ramaswamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1">Ramesh Raskar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10266">
                                    <div class="article-summary-box-inner">
                                        <span>It is crucial for policymakers to understand the community prevalence of
COVID-19 so combative resources can be effectively allocated and prioritized
during the COVID-19 pandemic. Traditionally, community prevalence has been
assessed through diagnostic and antibody testing data. However, despite the
increasing availability of COVID-19 testing, the required level has not been
met in most parts of the globe, introducing a need for an alternative method
for communities to determine disease prevalence. This is further complicated by
the observation that COVID-19 prevalence and spread varies across different
spatial, temporal, and demographics. In this study, we understand trends in the
spread of COVID-19 by utilizing the results of self-reported COVID-19 symptoms
surveys as an alternative to COVID-19 testing reports. This allows us to assess
community disease prevalence, even in areas with low COVID-19 testing ability.
Using individually reported symptom data from various populations, our method
predicts the likely percentage of the population that tested positive for
COVID-19. We do so with a Mean Absolute Error (MAE) of 1.14 and Mean Relative
Error (MRE) of 60.40\% with 95\% confidence interval as (60.12, 60.67). This
implies that our model predicts +/- 1140 cases than the original in a
population of 1 million. In addition, we forecast the location-wise percentage
of the population testing positive for the next 30 days using self-reported
symptoms data from previous days. The MAE for this method is as low as 0.15
(MRE of 23.61\% with 95\% confidence interval as (23.6, 13.7)) for New York. We
present an analysis of these results, exposing various clinical attributes of
interest across different demographics. Lastly, we qualitatively analyze how
various policy enactments (testing, curfew) affect the prevalence of COVID-19
in a community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Honey, I Shrunk The Actor: A Case Study on Preserving Performance with Smaller Actors in Actor-Critic RL. (arXiv:2102.11893v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1">Siddharth Mysore</a>, <a href="http://arxiv.org/find/cs/1/au:+Mabsout_B/0/1/0/all/0/1">Bassel Mabsout</a>, <a href="http://arxiv.org/find/cs/1/au:+Mancuso_R/0/1/0/all/0/1">Renato Mancuso</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11893">
                                    <div class="article-summary-box-inner">
                                        <span>Actors and critics in actor-critic reinforcement learning algorithms are
functionally separate, yet they often use the same network architectures. This
case study explores the performance impact of network sizes when considering
actor and critic architectures independently. By relaxing the assumption of
architectural symmetry, it is often possible for smaller actors to achieve
comparable policy performance to their symmetric counterparts. Our experiments
show up to 99% reduction in the number of network weights with an average
reduction of 77% over multiple actor-critic algorithms on 9 independent tasks.
Given that reducing actor complexity results in a direct reduction of run-time
inference cost, we believe configurations of actors and critics are aspects of
actor-critic design that deserve to be considered independently, particularly
in resource-constrained applications or when deploying multiple actors
simultaneously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal learning for Audio-Visual Video Parsing. (arXiv:2104.04598v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lamba_J/0/1/0/all/0/1">Jatin Lamba</a>, <a href="http://arxiv.org/find/cs/1/au:+Abhishek/0/1/0/all/0/1">Abhishek</a>, <a href="http://arxiv.org/find/cs/1/au:+Akula_J/0/1/0/all/0/1">Jayaprakash Akula</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabral_R/0/1/0/all/0/1">Rishabh Dabral</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04598">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel approach to the audio-visual video parsing
(AVVP) task that demarcates events from a video separately for audio and visual
modalities. The proposed parsing approach simultaneously detects the temporal
boundaries in terms of start and end times of such events. We show how AVVP can
benefit from the following techniques geared towards effective cross-modal
learning: (i) adversarial training and skip connections (ii) global context
aware attention and, (iii) self-supervised pretraining using an audio-video
grounding objective to obtain cross-modal audio-video representations. We
present extensive experimental evaluations on the Look, Listen, and Parse (LLP)
dataset and show that we outperform the state-of-the-art Hybrid Attention
Network (HAN) on all five metrics proposed for AVVP. We also present several
ablations to validate the effect of pretraining, global attention and
adversarial training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDA-Net: Fusion of Persistent Homology and Deep Learning Features for COVID-19 Detection in Chest X-Ray Images. (arXiv:2101.08398v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1">Mustafa Hajij</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Batayneh_F/0/1/0/all/0/1">Fawwaz Batayneh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08398">
                                    <div class="article-summary-box-inner">
                                        <span>Topological Data Analysis (TDA) has emerged recently as a robust tool to
extract and compare the structure of datasets. TDA identifies features in data
such as connected components and holes and assigns a quantitative measure to
these features. Several studies reported that topological features extracted by
TDA tools provide unique information about the data, discover new insights, and
determine which feature is more related to the outcome. On the other hand, the
overwhelming success of deep neural networks in learning patterns and
relationships has been proven on a vast array of data applications, images in
particular. To capture the characteristics of both powerful tools, we propose
\textit{TDA-Net}, a novel ensemble network that fuses topological and deep
features for the purpose of enhancing model generalizability and accuracy. We
apply the proposed \textit{TDA-Net} to a critical application, which is the
automated detection of COVID-19 from CXR images. The experimental results
showed that the proposed network achieved excellent performance and suggests
the applicability of our method in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Survey of Regularization and Normalization in GANs. (arXiv:2008.08930v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xintian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1">Muhammad Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1">Rentuo Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_P/0/1/0/all/0/1">Pengfei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08930">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have been widely applied in different
scenarios thanks to the development of deep neural networks. The original GAN
was proposed based on the non-parametric assumption of the infinite capacity of
networks. However, it is still unknown whether GANs can generate realistic
samples without any prior information. Due to the overconfident assumption,
many issues remain unaddressed in GANs&#x27; training, such as non-convergence, mode
collapses, gradient vanishing. Regularization and normalization are common
methods of introducing prior information to stabilize training and improve
discrimination. Although a handful number of regularization and normalization
methods have been proposed for GANs, to the best of our knowledge, there exists
no comprehensive survey which primarily focuses on objectives and development
of these methods, apart from some in-comprehensive and limited scope studies.
In this work, we conduct a comprehensive survey on the regularization and
normalization techniques from different perspectives of GANs training. First,
we systematically describe different perspectives of GANs training and thus
obtain the different objectives of regularization and normalization. Based on
these objectives, we propose a new taxonomy. Furthermore, we compare the
performance of the mainstream methods on different datasets and investigate the
regularization and normalization techniques that have been frequently employed
in SOTA GANs. Finally, we highlight potential future directions of research in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forecasting the Olympic medal distribution during a pandemic: a socio-economic machine learning model. (arXiv:2012.04378v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlembach_C/0/1/0/all/0/1">Christoph Schlembach</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_S/0/1/0/all/0/1">Sascha L. Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreyer_D/0/1/0/all/0/1">Dominik Schreyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wunderlich_L/0/1/0/all/0/1">Linus Wunderlich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04378">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the number of Olympic medals for each nation is highly relevant
for different stakeholders: Ex ante, sports betting companies can determine the
odds while sponsors and media companies can allocate their resources to
promising teams. Ex post, sports politicians and managers can benchmark the
performance of their teams and evaluate the drivers of success. To
significantly increase the Olympic medal forecasting accuracy, we apply machine
learning, more specifically a two-staged Random Forest, thus outperforming more
traditional na\&quot;ive forecast for three previous Olympics held between 2008 and
2016 for the first time. Regarding the Tokyo 2020 Games in 2021, our model
suggests that the United States will lead the Olympic medal table, winning 120
medals, followed by China (87) and Great Britain (74). Intriguingly, we predict
that the current COVID-19 pandemic will not significantly alter the medal count
as all countries suffer from the pandemic to some extent (data inherent) and
limited historical data points on comparable diseases (model inherent).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Consistency of Decision Trees in High Dimensions. (arXiv:2104.13881v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Klusowski_J/0/1/0/all/0/1">Jason M. Klusowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13881">
                                    <div class="article-summary-box-inner">
                                        <span>This paper shows that decision trees constructed with Classification and
Regression Trees (CART) methodology are universally consistent in an additive
model context, even when the number of predictor variables scales exponentially
with the sample size, under certain $1$-norm sparsity constraints. The
consistency is universal in the sense that there are no a priori assumptions on
the distribution of the predictor variables. Amazingly, this adaptivity to
(approximate or exact) sparsity is achieved with a single tree, as opposed to
what might be expected for an ensemble. Finally, we show that these qualitative
properties of individual trees are inherited by Breiman&#x27;s random forests.
Another surprise is that consistency holds even when the &quot;mtry&quot; tuning
parameter vanishes as a fraction of the number of predictor variables, thus
speeding up computation of the forest. A key step in the analysis is the
establishment of an oracle inequality, which precisely characterizes the
goodness-of-fit and complexity tradeoff for a misspecified model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Probabilistic State Space Model for Joint Inference from Differential Equations and Data. (arXiv:2103.10153v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Schmidt_J/0/1/0/all/0/1">Jonathan Schmidt</a>, <a href="http://arxiv.org/find/stat/1/au:+Kramer_N/0/1/0/all/0/1">Nicholas Kr&#xe4;mer</a>, <a href="http://arxiv.org/find/stat/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10153">
                                    <div class="article-summary-box-inner">
                                        <span>Mechanistic models with differential equations are a key component of
scientific applications of machine learning. Inference in such models is
usually computationally demanding, because it involves repeatedly solving the
differential equation. The main problem here is that the numerical solver is
hard to combine with standard inference techniques. Recent work in
probabilistic numerics has developed a new class of solvers for ordinary
differential equations (ODEs) that phrase the solution process directly in
terms of Bayesian filtering. We here show that this allows such methods to be
combined very directly, with conceptual and numerical ease, with latent force
models in the ODE itself. It then becomes possible to perform approximate
Bayesian inference on the latent force as well as the ODE solution in a single,
linear complexity pass of an extended Kalman filter / smoother - that is, at
the cost of computing a single ODE solution. We demonstrate the expressiveness
and performance of the algorithm by training, among others, a non-parametric
SIRD model on data from the COVID-19 outbreak.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Learning Based Denoising Autoencoder. (arXiv:2101.07937v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Woong-Hee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozger_M/0/1/0/all/0/1">Mustafa Ozger</a>, <a href="http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1">Ursula Challita</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_K/0/1/0/all/0/1">Ki Won Sung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07937">
                                    <div class="article-summary-box-inner">
                                        <span>This letter introduces a new denoiser that modifies the structure of
denoising autoencoder (DAE), namely noise learning based DAE (nlDAE). The
proposed nlDAE learns the noise of the input data. Then, the denoising is
performed by subtracting the regenerated noise from the noisy input. Hence,
nlDAE is more effective than DAE when the noise is simpler to regenerate than
the original data. To validate the performance of nlDAE, we provide three case
studies: signal restoration, symbol demodulation, and precise localization.
Numerical results suggest that nlDAE requires smaller latent space dimension
and smaller training dataset compared to DAE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge. (arXiv:2012.11696v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dognin_P/0/1/0/all/0/1">Pierre Dognin</a>, <a href="http://arxiv.org/find/cs/1/au:+Melnyk_I/0/1/0/all/0/1">Igor Melnyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1">Inkit Padhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigotti_M/0/1/0/all/0/1">Mattia Rigotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1">Jarret Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/cs/1/au:+Young_R/0/1/0/all/0/1">Richard A. Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Belgodere_B/0/1/0/all/0/1">Brian Belgodere</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11696">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning has recently demonstrated impressive progress largely owing
to the introduction of neural network algorithms trained on curated dataset
like MS-COCO. Often work in this field is motivated by the promise of
deployment of captioning systems in practical applications. However, the
scarcity of data and contexts in many competition datasets renders the utility
of systems trained on these datasets limited as an assistive technology in
real-world settings, such as helping visually impaired people navigate and
accomplish everyday tasks. This gap motivated the introduction of the novel
VizWiz dataset, which consists of images taken by the visually impaired and
captions that have useful, task-oriented information. In an attempt to help the
machine learning computer vision field realize its promise of producing
technologies that have positive social impact, the curators of the VizWiz
dataset host several competitions, including one for image captioning. This
work details the theory and engineering from our winning submission to the 2020
captioning competition. Our work provides a step towards improved assistive
image captioning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Framelets Enhance Graph Neural Networks. (arXiv:2102.06986v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xuebin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bingxin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Guang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Lio</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Ming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1">Guido Montufar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06986">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new approach for assembling graph neural networks based
on framelet transforms. The latter provides a multi-scale representation for
graph-structured data. We decompose an input graph into low-pass and high-pass
frequencies coefficients for network training, which then defines a
framelet-based graph convolution. The framelet decomposition naturally induces
a graph pooling strategy by aggregating the graph feature into low-pass and
high-pass spectra, which considers both the feature values and geometry of the
graph data and conserves the total information. The graph neural networks with
the proposed framelet convolution and pooling achieve state-of-the-art
performance in many node and graph prediction tasks. Moreover, we propose
shrinkage as a new activation for the framelet convolution, which thresholds
high-frequency information at different scales. Compared to ReLU, shrinkage
activation improves model performance on denoising and signal compression:
noises in both node and structure can be significantly reduced by accurately
cutting off the high-pass coefficients from framelet decomposition, and the
signal can be compressed to less than half its original size with
well-preserved prediction performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Capturing Label Characteristics in VAEs. (arXiv:2006.10102v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joy_T/0/1/0/all/0/1">Tom Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmon_S/0/1/0/all/0/1">Sebastian M. Schmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1">N. Siddharth</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10102">
                                    <div class="article-summary-box-inner">
                                        <span>We present a principled approach to incorporating labels in VAEs that
captures the rich characteristic information associated with those labels.
While prior work has typically conflated these by learning latent variables
that directly correspond to label values, we argue this is contrary to the
intended effect of supervision in VAEs-capturing rich label characteristics
with the latents. For example, we may want to capture the characteristics of a
face that make it look young, rather than just the age of the person. To this
end, we develop the CCVAE, a novel VAE model and concomitant variational
objective which captures label characteristics explicitly in the latent space,
eschewing direct correspondences between label values and latents. Through
judicious structuring of mappings between such characteristic latents and
labels, we show that the CCVAE can effectively learn meaningful representations
of the characteristics of interest across a variety of supervision schemes. In
particular, we show that the CCVAE allows for more effective and more general
interventions to be performed, such as smooth traversals within the
characteristics for a given label, diverse conditional generation, and
transferring characteristics across datapoints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Agnostic Explanations using Minimal Forcing Subsets. (arXiv:2011.00639v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_J/0/1/0/all/0/1">Joydeep Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00639">
                                    <div class="article-summary-box-inner">
                                        <span>How can we find a subset of training samples that are most responsible for a
specific prediction made by a complex black-box machine learning model? More
generally, how can we explain the model&#x27;s decisions to end-users in a
transparent way? We propose a new model-agnostic algorithm to identify a
minimal set of training samples that are indispensable for a given model&#x27;s
decision at a particular test point, i.e., the model&#x27;s decision would have
changed upon the removal of this subset from the training dataset. Our
algorithm identifies such a set of &quot;indispensable&quot; samples iteratively by
solving a constrained optimization problem. Further, we speed up the algorithm
through efficient approximations and provide theoretical justification for its
performance. To demonstrate the applicability and effectiveness of our
approach, we apply it to a variety of tasks including data poisoning detection,
training set debugging and understanding loan decisions. The results show that
our algorithm is an effective and easy-to-comprehend tool that helps to better
understand local model behavior, and therefore facilitates the adoption of
machine learning in domains where such understanding is a requisite.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Factor Graphs for Inference from Stationary Time Sequences. (arXiv:2006.03258v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shlezinger_N/0/1/0/all/0/1">Nir Shlezinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Farsad_N/0/1/0/all/0/1">Nariman Farsad</a>, <a href="http://arxiv.org/find/cs/1/au:+Eldar_Y/0/1/0/all/0/1">Yonina C. Eldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldsmith_A/0/1/0/all/0/1">Andrea J. Goldsmith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03258">
                                    <div class="article-summary-box-inner">
                                        <span>The design of methods for inference from time sequences has traditionally
relied on statistical models that describe the relation between a latent
desired sequence and the observed one. A broad family of model-based algorithms
have been derived to carry out inference at controllable complexity using
recursive computations over the factor graph representing the underlying
distribution. An alternative model-agnostic approach utilizes machine learning
(ML) methods. Here we propose a framework that combines model-based algorithms
and data-driven ML tools for stationary time sequences. In the proposed
approach, neural networks are developed to separately learn specific components
of a factor graph describing the distribution of the time sequence, rather than
the complete inference task. By exploiting stationary properties of this
distribution, the resulting approach can be applied to sequences of varying
temporal duration. Learned factor graph can be realized using compact neural
networks that are trainable using small training sets, or alternatively, be
used to improve upon existing deep inference systems. We present an inference
algorithm based on learned stationary factor graphs, which learns to implement
the sum-product scheme from labeled data, and can be applied to sequences of
different lengths. Our experimental results demonstrate the ability of the
proposed learned factor graphs to learn to carry out accurate inference from
small training sets for sleep stage detection using the Sleep-EDF dataset, as
well as for symbol detection in digital communications with unknown channels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2 Visual Field Data based on Retinal Structure. (arXiv:2010.07488v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1">Shounak Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mariottoni_E/0/1/0/all/0/1">Eduardo B. Mariottoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dov_D/0/1/0/all/0/1">David Dov</a>, <a href="http://arxiv.org/find/cs/1/au:+Jammal_A/0/1/0/all/0/1">Alessandro A. Jammal</a>, <a href="http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/cs/1/au:+Medeiros_F/0/1/0/all/0/1">Felipe A. Medeiros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07488">
                                    <div class="article-summary-box-inner">
                                        <span>Glaucoma is the leading cause of irreversible blindness in the world,
affecting over 70 million people. The cumbersome Standard Automated Perimetry
(SAP) test is most frequently used to detect visual loss due to glaucoma. Due
to the SAP test&#x27;s innate difficulty and its high test-retest variability, we
propose the RetiNerveNet, a deep convolutional recursive neural network for
obtaining estimates of the SAP visual field. RetiNerveNet uses information from
the more objective Spectral-Domain Optical Coherence Tomography (SDOCT).
RetiNerveNet attempts to trace-back the arcuate convergence of the retinal
nerve fibers, starting from the Retinal Nerve Fiber Layer (RNFL) thickness
around the optic disc, to estimate individual age-corrected 24-2 SAP values.
Recursive passes through the proposed network sequentially yield estimates of
the visual locations progressively farther from the optic disc. While all the
methods used for our experiments exhibit lower performance for the advanced
disease group, the proposed network is observed to be more accurate than all
the baselines for estimating the individual visual field values. We further
augment RetiNerveNet to additionally predict the SAP Mean Deviation values and
also create an ensemble of RetiNerveNets that further improves the performance,
by increasingly weighting-up underrepresented parts of the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressive Sensing and Neural Networks from a Statistical Learning Perspective. (arXiv:2010.15658v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Behboodi_A/0/1/0/all/0/1">Arash Behboodi</a>, <a href="http://arxiv.org/find/math/1/au:+Rauhut_H/0/1/0/all/0/1">Holger Rauhut</a>, <a href="http://arxiv.org/find/math/1/au:+Schnoor_E/0/1/0/all/0/1">Ekkehard Schnoor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15658">
                                    <div class="article-summary-box-inner">
                                        <span>Various iterative reconstruction algorithms for inverse problems can be
unfolded as neural networks. Empirically, this approach has often led to
improved results, but theoretical guarantees are still scarce. While some
progress on generalization properties of neural networks have been made, great
challenges remain. In this chapter, we discuss and combine these topics to
present a generalization error analysis for a class of neural networks suitable
for sparse reconstruction from few linear measurements. The hypothesis class
considered is inspired by the classical iterative soft-thresholding algorithm
(ISTA). The neural networks in this class are obtained by unfolding iterations
of ISTA and learning some of the weights. Based on training samples, we aim at
learning the optimal network parameters via empirical risk minimization and
thereby the optimal network that reconstructs signals from their compressive
linear measurements. In particular, we may learn a sparsity basis that is
shared by all of the iterations/layers and thereby obtain a new approach for
dictionary learning. For this class of networks, we present a generalization
bound, which is based on bounding the Rademacher complexity of hypothesis
classes consisting of such deep networks via Dudley&#x27;s integral. Remarkably,
under realistic conditions, the generalization error scales only
logarithmically in the number of layers, and at most linear in number of
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tight Differential Privacy for Discrete-Valued Mechanisms and for the Subsampled Gaussian Mechanism Using FFT. (arXiv:2006.07134v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Koskela_A/0/1/0/all/0/1">Antti Koskela</a>, <a href="http://arxiv.org/find/stat/1/au:+Jalko_J/0/1/0/all/0/1">Joonas J&#xe4;lk&#xf6;</a>, <a href="http://arxiv.org/find/stat/1/au:+Prediger_L/0/1/0/all/0/1">Lukas Prediger</a>, <a href="http://arxiv.org/find/stat/1/au:+Honkela_A/0/1/0/all/0/1">Antti Honkela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07134">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a numerical accountant for evaluating the tight
$(\varepsilon,\delta)$-privacy loss for algorithms with discrete one
dimensional output. The method is based on the privacy loss distribution
formalism and it uses the recently introduced fast Fourier transform based
accounting technique. We carry out an error analysis of the method in terms of
moment bounds of the privacy loss distribution which leads to rigorous lower
and upper bounds for the true $(\varepsilon,\delta)$-values. As an application,
we present a novel approach to accurate privacy accounting of the subsampled
Gaussian mechanism. This completes the previously proposed analysis by giving
strict lower and upper bounds for the privacy parameters. We demonstrate the
performance of the accountant on the binomial mechanism and show that our
approach allows decreasing noise variance up to 75 percent at equal privacy
compared to existing bounds in the literature. We also illustrate how to
compute tight bounds for the exponential mechanism applied to counting queries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12135">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial learning has emerged as one of the successful techniques to
circumvent the susceptibility of existing methods against adversarial
perturbations. However, the majority of existing defense methods are tailored
to defend against a single category of adversarial perturbation (e.g.
$\ell_\infty$-attack). In safety-critical applications, this makes these
methods extraneous as the attacker can adopt diverse adversaries to deceive the
system. Moreover, training on multiple perturbations simultaneously
significantly increases the computational overhead during training. To address
these challenges, we propose a novel meta-learning framework that explicitly
learns to generate noise to improve the model&#x27;s robustness against multiple
types of attacks. Its key component is Meta Noise Generator (MNG) that outputs
optimal noise to stochastically perturb a given sample, such that it helps
lower the error on diverse adversarial perturbations. By utilizing samples
generated by MNG, we train a model by enforcing the label consistency across
multiple perturbations. We validate the robustness of models trained by our
scheme on various datasets and against a wide variety of perturbations,
demonstrating that it significantly outperforms the baselines across multiple
perturbations with a marginal computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mostly Harmless Machine Learning: Learning Optimal Instruments in Linear IV Models. (arXiv:2011.06158v3 [econ.EM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Chen_J/0/1/0/all/0/1">Jiafeng Chen</a>, <a href="http://arxiv.org/find/econ/1/au:+Chen_D/0/1/0/all/0/1">Daniel L. Chen</a>, <a href="http://arxiv.org/find/econ/1/au:+Lewis_G/0/1/0/all/0/1">Greg Lewis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06158">
                                    <div class="article-summary-box-inner">
                                        <span>We offer straightforward theoretical results that justify incorporating
machine learning in the standard linear instrumental variable setting. The key
idea is to use machine learning, combined with sample-splitting, to predict the
treatment variable from the instrument and any exogenous covariates, and then
use this predicted treatment and the covariates as technical instruments to
recover the coefficients in the second-stage. This allows the researcher to
extract non-linear co-variation between the treatment and instrument that may
dramatically improve estimation precision and robustness by boosting instrument
strength. Importantly, we constrain the machine-learned predictions to be
linear in the exogenous covariates, thus avoiding spurious identification
arising from non-linear relationships between the treatment and the covariates.
We show that this approach delivers consistent and asymptotically normal
estimates under weak conditions and that it may be adapted to be
semiparametrically efficient (Chamberlain, 1992). Our method preserves standard
intuitions and interpretations of linear instrumental variable methods,
including under weak identification, and provides a simple, user-friendly
upgrade to the applied economics toolbox. We illustrate our method with an
example in law and criminal justice, examining the causal effect of appellate
court reversals on district court sentencing decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Firefly Neural Architecture Descent: a General Approach for Growing Neural Networks. (arXiv:2102.08574v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lemeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1">Peter Stone</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08574">
                                    <div class="article-summary-box-inner">
                                        <span>We propose firefly neural architecture descent, a general framework for
progressively and dynamically growing neural networks to jointly optimize the
networks&#x27; parameters and architectures. Our method works in a steepest descent
fashion, which iteratively finds the best network within a functional
neighborhood of the original network that includes a diverse set of candidate
network structures. By using Taylor approximation, the optimal network
structure in the neighborhood can be found with a greedy selection procedure.
We show that firefly descent can flexibly grow networks both wider and deeper,
and can be applied to learn accurate but resource-efficient neural
architectures that avoid catastrophic forgetting in continual learning.
Empirically, firefly descent achieves promising results on both neural
architecture search and continual learning. In particular, on a challenging
continual image classification task, it learns networks that are smaller in
size but have higher average accuracy than those learned by the
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IGANI: Iterative Generative Adversarial Networks for Imputation with Application to Traffic Data. (arXiv:2008.04847v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kazemi_A/0/1/0/all/0/1">Amir Kazemi</a>, <a href="http://arxiv.org/find/stat/1/au:+Meidani_H/0/1/0/all/0/1">Hadi Meidani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04847">
                                    <div class="article-summary-box-inner">
                                        <span>Increasing use of sensor data in intelligent transportation systems calls for
accurate imputation algorithms that can enable reliable traffic management in
the occasional absence of data. As one of the effective imputation approaches,
generative adversarial networks (GANs) are implicit generative models that can
be used for data imputation, which is formulated as an unsupervised learning
problem. This work introduces a novel iterative GAN architecture, called
Iterative Generative Adversarial Networks for Imputation (IGANI), for data
imputation. IGANI imputes data in two steps and maintains the invertibility of
the generative imputer, which will be shown to be a sufficient condition for
the convergence of the proposed GAN-based imputation. The performance of our
proposed method is evaluated on (1) the imputation of traffic speed data
collected in the city of Guangzhou in China, and the training of short-term
traffic prediction models using imputed data, and (2) the imputation of
multi-variable traffic data of highways in Portland-Vancouver metropolitan
region which includes volume, occupancy, and speed with different missing rates
for each of them. It is shown that our proposed algorithm mostly produces more
accurate results compared to those of previous GAN-based imputation
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning for Deep Neural Networks on Edge Devices. (arXiv:2106.10836v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Senzaki_Y/0/1/0/all/0/1">Yuya Senzaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamelain_C/0/1/0/all/0/1">Christian Hamelain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10836">
                                    <div class="article-summary-box-inner">
                                        <span>When dealing with deep neural network (DNN) applications on edge devices,
continuously updating the model is important. Although updating a model with
real incoming data is ideal, using all of them is not always feasible due to
limits, such as labeling and communication costs. Thus, it is necessary to
filter and select the data to use for training (i.e., active learning) on the
device. In this paper, we formalize a practical active learning problem for
DNNs on edge devices and propose a general task-agnostic framework to tackle
this problem, which reduces it to a stream submodular maximization. This
framework is light enough to be run with low computational resources, yet
provides solutions whose quality is theoretically guaranteed thanks to the
submodular property. Through this framework, we can configure data selection
criteria flexibly, including using methods proposed in previous active learning
studies. We evaluate our approach on both classification and object detection
tasks in a practical setting to simulate a real-life scenario. The results of
our study show that the proposed framework outperforms all other methods in
both tasks, while running at a practical speed on real devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CD-SGD: Distributed Stochastic Gradient Descent with Compression and Delay Compensation. (arXiv:2106.10796v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1">Enda Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1">Dezun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yemao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1">Shuo Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xiangke Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10796">
                                    <div class="article-summary-box-inner">
                                        <span>Communication overhead is the key challenge for distributed training.
Gradient compression is a widely used approach to reduce communication traffic.
When combining with parallel communication mechanism method like pipeline,
gradient compression technique can greatly alleviate the impact of
communication overhead. However, there exists two problems of gradient
compression technique to be solved. Firstly, gradient compression brings in
extra computation cost, which will delay the next training iteration. Secondly,
gradient compression usually leads to the decrease of convergence accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pointwise Binary Classification with Pairwise Confidence Comparisons. (arXiv:2010.01875v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_S/0/1/0/all/0/1">Senlin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1">Nan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Miao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01875">
                                    <div class="article-summary-box-inner">
                                        <span>To alleviate the data requirement for training effective binary classifiers
in binary classification, many weakly supervised learning settings have been
proposed. Among them, some consider using pairwise but not pointwise labels,
when pointwise labels are not accessible due to privacy, confidentiality, or
security reasons. However, as a pairwise label denotes whether or not two data
points share a pointwise label, it cannot be easily collected if either point
is equally likely to be positive or negative. Thus, in this paper, we propose a
novel setting called pairwise comparison (Pcomp) classification, where we have
only pairs of unlabeled data that we know one is more likely to be positive
than the other. Firstly, we give a Pcomp data generation process, derive an
unbiased risk estimator (URE) with theoretical guarantee, and further improve
URE using correction functions. Secondly, we link Pcomp classification to
noisy-label learning to develop a progressive URE and improve it by imposing
consistency regularization. Finally, we demonstrate by experiments the
effectiveness of our methods, which suggests Pcomp is a valuable and
practically useful type of pairwise supervision besides the pairwise label.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL. (arXiv:2012.08005v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zanette_A/0/1/0/all/0/1">Andrea Zanette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08005">
                                    <div class="article-summary-box-inner">
                                        <span>Several practical applications of reinforcement learning involve an agent
learning from past data without the possibility of further exploration. Often
these applications require us to 1) identify a near optimal policy or to 2)
estimate the value of a target policy. For both tasks we derive
\emph{exponential} information-theoretic lower bounds in discounted infinite
horizon MDPs with a linear function representation for the action value
function even if 1) \emph{realizability} holds, 2) the batch algorithm observes
the exact reward and transition \emph{functions}, and 3) the batch algorithm is
given the \emph{best} a priori data distribution for the problem class. Our
work introduces a new &#x60;oracle + batch algorithm&#x27; framework to prove lower
bounds that hold for every distribution. The work shows an exponential
separation between batch and online reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Squared: A Meta AutoML System. (arXiv:2012.05390v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Jason Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_T/0/1/0/all/0/1">Tony Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Yung_D/0/1/0/all/0/1">Dylan Yung</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasseri_S/0/1/0/all/0/1">S. Ali Nasseri</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05390">
                                    <div class="article-summary-box-inner">
                                        <span>There are currently many barriers that prevent non-experts from exploiting
machine learning solutions ranging from the lack of intuition on statistical
learning techniques to the trickiness of hyperparameter tuning. Such barriers
have led to an explosion of interest in automated machine learning (AutoML),
whereby an off-the-shelf system can take care of many of the steps for
end-users without the need for expertise in machine learning. This paper
presents Ensemble Squared (Ensemble$^2$), an AutoML system that ensembles the
results of state-of-the-art open-source AutoML systems. Ensemble$^2$ exploits
the diversity of existing AutoML systems by leveraging the differences in their
model search space and heuristics. Empirically, we show that diversity of each
AutoML system is sufficient to justify ensembling at the AutoML system level.
In demonstrating this, we also establish new state-of-the-art AutoML results on
the OpenML tabular classification benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Piano Skills Assessment. (arXiv:2101.04884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parmar_P/0/1/0/all/0/1">Paritosh Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_J/0/1/0/all/0/1">Jaiden Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04884">
                                    <div class="article-summary-box-inner">
                                        <span>Can a computer determine a piano player&#x27;s skill level? Is it preferable to
base this assessment on visual analysis of the player&#x27;s performance or should
we trust our ears over our eyes? Since current CNNs have difficulty processing
long video videos, how can shorter clips be sampled to best reflect the players
skill level? In this work, we collect and release a first-of-its-kind dataset
for multimodal skill assessment focusing on assessing piano player&#x27;s skill
level, answer the asked questions, initiate work in automated evaluation of
piano playing skills and provide baselines for future work. Dataset is
available from: https://github.com/ParitoshParmar/Piano-Skills-Assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Rough Differential Equations for Long Time Series. (arXiv:2009.08295v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morrill_J/0/1/0/all/0/1">James Morrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvi_C/0/1/0/all/0/1">Cristopher Salvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kidger_P/0/1/0/all/0/1">Patrick Kidger</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1">James Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyons_T/0/1/0/all/0/1">Terry Lyons</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08295">
                                    <div class="article-summary-box-inner">
                                        <span>Neural controlled differential equations (CDEs) are the continuous-time
analogue of recurrent neural networks, as Neural ODEs are to residual networks,
and offer a memory-efficient continuous-time way to model functions of
potentially irregular time series. Existing methods for computing the forward
pass of a Neural CDE involve embedding the incoming time series into path
space, often via interpolation, and using evaluations of this path to drive the
hidden state. Here, we use rough path theory to extend this formulation.
Instead of directly embedding into path space, we instead represent the input
signal over small time intervals through its \textit{log-signature}, which are
statistics describing how the signal drives a CDE. This is the approach for
solving \textit{rough differential equations} (RDEs), and correspondingly we
describe our main contribution as the introduction of Neural RDEs. This
extension has a purpose: by generalising the Neural CDE approach to a broader
class of driving signals, we demonstrate particular advantages for tackling
long time series. In this regime, we demonstrate efficacy on problems of length
up to 17k observations and observe significant training speed-ups, improvements
in model performance, and reduced memory requirements compared to existing
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing Catastrophic Forgetting in Few-Shot Problems. (arXiv:2005.00146v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yap_P/0/1/0/all/0/1">Pauching Yap</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritter_H/0/1/0/all/0/1">Hippolyt Ritter</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1">David Barber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00146">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are known to suffer from catastrophic forgetting when trained
on sequential datasets. While there have been numerous attempts to solve this
problem in large-scale supervised classification, little has been done to
overcome catastrophic forgetting in few-shot classification problems. We
demonstrate that the popular gradient-based model-agnostic meta-learning
algorithm (MAML) indeed suffers from catastrophic forgetting and introduce a
Bayesian online meta-learning framework that tackles this problem. Our
framework utilises Bayesian online learning and meta-learning along with
Laplace approximation and variational inference to overcome catastrophic
forgetting in few-shot classification problems. The experimental evaluations
demonstrate that our framework can effectively achieve this goal in comparison
with various baselines. As an additional utility, we also demonstrate
empirically that our framework is capable of meta-learning on sequentially
arriving few-shot tasks from a stationary task distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Nonconvex Framework for Structured Dynamic Covariance Recovery. (arXiv:2011.05601v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tsai_K/0/1/0/all/0/1">Katherine Tsai</a>, <a href="http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1">Mladen Kolar</a>, <a href="http://arxiv.org/find/stat/1/au:+Koyejo_O/0/1/0/all/0/1">Oluwasanmi Koyejo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05601">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a flexible yet interpretable model for high-dimensional data with
time-varying second order statistics, motivated and applied to functional
neuroimaging data. Motivated by the neuroscience literature, we factorize the
covariances into sparse spatial and smooth temporal components. While this
factorization results in both parsimony and domain interpretability, the
resulting estimation problem is nonconvex. To this end, we design a two-stage
optimization scheme with a carefully tailored spectral initialization, combined
with iteratively refined alternating projected gradient descent. We prove a
linear convergence rate up to a nontrivial statistical error for the proposed
descent scheme and establish sample complexity guarantees for the estimator. We
further quantify the statistical error for the multivariate Gaussian case.
Empirical results using simulated and real brain imaging data illustrate that
our approach outperforms existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Contrastive Learning for Few-Shot Classification. (arXiv:2012.13831v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouali_Y/0/1/0/all/0/1">Yassine Ouali</a>, <a href="http://arxiv.org/find/cs/1/au:+Hudelot_C/0/1/0/all/0/1">C&#xe9;line Hudelot</a>, <a href="http://arxiv.org/find/cs/1/au:+Tami_M/0/1/0/all/0/1">Myriam Tami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13831">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore contrastive learning for few-shot classification,
in which we propose to use it as an additional auxiliary training objective
acting as a data-dependent regularizer to promote more general and transferable
features. In particular, we present a novel attention-based spatial contrastive
objective to learn locally discriminative and class-agnostic features. As a
result, our approach overcomes some of the limitations of the cross-entropy
loss, such as its excessive discrimination towards seen classes, which reduces
the transferability of features to unseen classes. With extensive experiments,
we show that the proposed method outperforms state-of-the-art approaches,
confirming the importance of learning good and transferable embeddings for
few-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A non-alternating graph hashing algorithm for large scale image search. (arXiv:2012.13138v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hemati_S/0/1/0/all/0/1">Sobhan Hemati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdizavareh_M/0/1/0/all/0/1">Mohammad Hadi Mehdizavareh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenouri_S/0/1/0/all/0/1">Shojaeddin Chenouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R Tizhoosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13138">
                                    <div class="article-summary-box-inner">
                                        <span>In the era of big data, methods for improving memory and computational
efficiency have become crucial for successful deployment of technologies.
Hashing is one of the most effective approaches to deal with computational
limitations that come with big data. One natural way for formulating this
problem is spectral hashing that directly incorporates affinity to learn binary
codes. However, due to binary constraints, the optimization becomes
intractable. To mitigate this challenge, different relaxation approaches have
been proposed to reduce the computational load of obtaining binary codes and
still attain a good solution. The problem with all existing relaxation methods
is resorting to one or more additional auxiliary variables to attain high
quality binary codes while relaxing the problem. The existence of auxiliary
variables leads to coordinate descent approach which increases the
computational complexity. We argue that introducing these variables is
unnecessary. To this end, we propose a novel relaxed formulation for spectral
hashing that adds no additional variables to the problem. Furthermore, instead
of solving the problem in original space where number of variables is equal to
the data points, we solve the problem in a much smaller space and retrieve the
binary codes from this solution. This trick reduces both the memory and
computational complexity at the same time. We apply two optimization
techniques, namely projected gradient and optimization on manifold, to obtain
the solution. Using comprehensive experiments on four public datasets, we show
that the proposed efficient spectral hashing (ESH) algorithm achieves highly
competitive retrieval performance compared with state of the art at low
complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PIVEN: A Deep Neural Network for Prediction Intervals with Specific Value Prediction. (arXiv:2006.05139v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simhayev_E/0/1/0/all/0/1">Eli Simhayev</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Gilad Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1">Lior Rokach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05139">
                                    <div class="article-summary-box-inner">
                                        <span>Improving the robustness of neural nets in regression tasks is key to their
application in multiple domains. Deep learning-based approaches aim to achieve
this goal either by improving their prediction of specific values (i.e., point
prediction), or by producing prediction intervals (PIs) that quantify
uncertainty. We present PIVEN, a deep neural network for producing both a PI
and a value prediction. Our loss function expresses the value prediction as a
function of the upper and lower bounds, thus ensuring that it falls within the
interval without increasing model complexity. Moreover, our approach makes no
assumptions regarding data distribution within the PI, making its value
prediction more effective for various real-world problems. Experiments and
ablation tests on known benchmarks show that our approach produces tighter
uncertainty bounds than the current state-of-the-art approaches for producing
PIs, while maintaining comparable performance to the state-of-the-art approach
for value-prediction. Additionally, we go beyond previous work and include
large image datasets in our evaluation, where PIVEN is combined with modern
neural nets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximation in shift-invariant spaces with deep ReLU neural networks. (arXiv:2005.11949v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yunfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.11949">
                                    <div class="article-summary-box-inner">
                                        <span>We study the expressive power of deep ReLU neural networks for approximating
functions in dilated shift-invariant spaces, which are widely used in signal
processing, image processing, communications and so on. Approximation error
bounds are estimated with respect to the width and depth of neural networks.
The network construction is based on the bit extraction and data-fitting
capacity of deep neural networks. As applications of our main results, the
approximation rates of classical function spaces such as Sobolev spaces and
Besov spaces are obtained. We also give lower bounds of the $L^p (1\le p \le
\infty)$ approximation error for Sobolev spaces, which show that our
construction of neural network is asymptotically optimal up to a logarithmic
factor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Libraries: A Deep Learning Framework Designed from Engineers&#x27; Perspectives. (arXiv:2102.06725v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narihira_T/0/1/0/all/0/1">Takuya Narihira</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonsogarcia_J/0/1/0/all/0/1">Javier Alonsogarcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardinaux_F/0/1/0/all/0/1">Fabien Cardinaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayakawa_A/0/1/0/all/0/1">Akio Hayakawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1">Masato Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwaki_K/0/1/0/all/0/1">Kazunori Iwaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemp_T/0/1/0/all/0/1">Thomas Kemp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_Y/0/1/0/all/0/1">Yoshiyuki Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mauch_L/0/1/0/all/0/1">Lukas Mauch</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakamura_A/0/1/0/all/0/1">Akira Nakamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Obuchi_Y/0/1/0/all/0/1">Yukio Obuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_A/0/1/0/all/0/1">Andrew Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_K/0/1/0/all/0/1">Kenji Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiedmann_S/0/1/0/all/0/1">Stephen Tiedmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Uhlich_S/0/1/0/all/0/1">Stefan Uhlich</a>, <a href="http://arxiv.org/find/cs/1/au:+Yashima_T/0/1/0/all/0/1">Takuya Yashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshiyama_K/0/1/0/all/0/1">Kazuki Yoshiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06725">
                                    <div class="article-summary-box-inner">
                                        <span>While there exist a plethora of deep learning tools and frameworks, the
fast-growing complexity of the field brings new demands and challenges, such as
more flexible network design, speedy computation on distributed setting, and
compatibility between different tools. In this paper, we introduce Neural
Network Libraries (https://nnabla.org), a deep learning framework designed from
engineer&#x27;s perspective, with emphasis on usability and compatibility as its
core design principles. We elaborate on each of our design principles and its
merits, and validate our attempts via experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Graph Neural Networks. (arXiv:2006.02684v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gao_Z/0/1/0/all/0/1">Zhan Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Isufi_E/0/1/0/all/0/1">Elvin Isufi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02684">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) model nonlinear representations in graph data
with applications in distributed agent coordination, control, and planning
among others. Current GNN architectures assume ideal scenarios and ignore link
fluctuations that occur due to environment, human factors, or external attacks.
In these situations, the GNN fails to address its distributed task if the
topological randomness is not considered accordingly. To overcome this issue,
we put forth the stochastic graph neural network (SGNN) model: a GNN where the
distributed graph convolution module accounts for the random network changes.
Since stochasticity brings in a new learning paradigm, we conduct a statistical
analysis on the SGNN output variance to identify conditions the learned filters
should satisfy for achieving robust transference to perturbed scenarios,
ultimately revealing the explicit impact of random link losses. We further
develop a stochastic gradient descent (SGD) based learning process for the SGNN
and derive conditions on the learning rate under which this learning process
converges to a stationary point. Numerical results corroborate our theoretical
findings and compare the benefits of SGNN robust transference with a
conventional GNN that ignores graph perturbations during learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoreGen: Contextualized Code Representation Learning for Commit Message Generation. (arXiv:2007.06934v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Lun Yiu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Cuiyun Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhicong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1">Wai Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06934">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic generation of high-quality commit messages for code commits can
substantially facilitate software developers&#x27; works and coordination. However,
the semantic gap between source code and natural language poses a major
challenge for the task. Several studies have been proposed to alleviate the
challenge but none explicitly involves code contextual information during
commit message generation. Specifically, existing research adopts static
embedding for code tokens, which maps a token to the same vector regardless of
its context. In this paper, we propose a novel Contextualized code
representation learning strategy for commit message Generation (CoreGen).
CoreGen first learns contextualized code representations which exploit the
contextual information behind code commit sequences. The learned
representations of code commits built upon Transformer are then fine-tuned for
downstream commit message generation. Experiments on the benchmark dataset
demonstrate the superior effectiveness of our model over the baseline models
with at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also
highlight the future opportunities in training contextualized code
representations on larger code corpus as a solution to low-resource tasks and
adapting the contextualized code representation framework to other code-to-text
generation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Inference of the Value Function for Reinforcement Learning in Infinite Horizon Settings. (arXiv:2001.04515v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1">C. Shi</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1">S. Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_W/0/1/0/all/0/1">W. Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Song_R/0/1/0/all/0/1">R. Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04515">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning is a general technique that allows an agent to learn
an optimal policy and interact with an environment in sequential decision
making problems. The goodness of a policy is measured by its value function
starting from some initial state. The focus of this paper is to construct
confidence intervals (CIs) for a policy&#x27;s value in infinite horizon settings
where the number of decision points diverges to infinity. We propose to model
the action-value state function (Q-function) associated with a policy based on
series/sieve method to derive its confidence interval. When the target policy
depends on the observed data as well, we propose a SequentiAl Value Evaluation
(SAVE) method to recursively update the estimated policy and its value
estimator. As long as either the number of trajectories or the number of
decision points diverges to infinity, we show that the proposed CI achieves
nominal coverage even in cases where the optimal policy is not unique.
Simulation studies are conducted to back up our theoretical findings. We apply
the proposed method to a dataset from mobile health studies and find that
reinforcement learning algorithms could help improve patient&#x27;s health status. A
Python implementation of the proposed procedure is available at
https://github.com/shengzhang37/SAVE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed-Privacy Forgetting in Deep Networks. (arXiv:2012.13431v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golatkar_A/0/1/0/all/0/1">Aditya Golatkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1">Alessandro Achille</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1">Avinash Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Polito_M/0/1/0/all/0/1">Marzia Polito</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13431">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the influence of a subset of the training samples can be removed
-- or &quot;forgotten&quot; -- from the weights of a network trained on large-scale image
classification tasks, and we provide strong computable bounds on the amount of
remaining information after forgetting. Inspired by real-world applications of
forgetting techniques, we introduce a novel notion of forgetting in
mixed-privacy setting, where we know that a &quot;core&quot; subset of the training
samples does not need to be forgotten. While this variation of the problem is
conceptually simple, we show that working in this setting significantly
improves the accuracy and guarantees of forgetting methods applied to vision
classification tasks. Moreover, our method allows efficient removal of all
information contained in non-core data by simply setting to zero a subset of
the weights with minimal loss in performance. We achieve these results by
replacing a standard deep network with a suitable linear approximation. With
opportune changes to the network architecture and training procedure, we show
that such linear approximation achieves comparable performance to the original
network and that the forgetting problem becomes quadratic and can be solved
efficiently even for large models. Unlike previous forgetting methods on deep
networks, ours can achieve close to the state-of-the-art accuracy on large
scale vision tasks. In particular, we show that our method allows forgetting
without having to trade off the model accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demonstration of Panda: A Weakly Supervised Entity Matching System. (arXiv:2106.10821v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Renzhi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakala_P/0/1/0/all/0/1">Prem Sakala</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yeye He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10821">
                                    <div class="article-summary-box-inner">
                                        <span>Entity matching (EM) refers to the problem of identifying tuple pairs in one
or more relations that refer to the same real world entities. Supervised
machine learning (ML) approaches, and deep learning based approaches in
particular, typically achieve state-of-the-art matching results. However, these
approaches require many labeled examples, in the form of matching and
non-matching pairs, which are expensive and time-consuming to label. In this
paper, we introduce Panda, a weakly supervised system specifically designed for
EM. Panda uses the same labeling function abstraction as Snorkel, where
labeling functions (LF) are user-provided programs that can generate large
amounts of (somewhat noisy) labels quickly and cheaply, which can then be
combined via a labeling model to generate accurate final predictions. To
support users developing LFs for EM, Panda provides an integrated development
environment (IDE) that lives in a modern browser architecture. Panda&#x27;s IDE
facilitates the development, debugging, and life-cycle management of LFs in the
context of EM tasks, similar to how IDEs such as Visual Studio or Eclipse excel
in general-purpose programming. Panda&#x27;s IDE includes many novel features
purpose-built for EM, such as smart data sampling, a builtin library of EM
utility functions, automatically generated LFs, visual debugging of LFs, and
finally, an EM-specific labeling model. We show in this demo that Panda IDE can
greatly accelerate the development of high-quality EM solutions using weak
supervision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constraint-Based Regularization of Neural Networks. (arXiv:2006.10114v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leimkuhler_B/0/1/0/all/0/1">Benedict Leimkuhler</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouchon_T/0/1/0/all/0/1">Timoth&#xe9;e Pouchon</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlaar_T/0/1/0/all/0/1">Tiffany Vlaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1">Amos Storkey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10114">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method for efficiently incorporating constraints into a
stochastic gradient Langevin framework for the training of deep neural
networks. Constraints allow direct control of the parameter space of the model.
Appropriately designed, they reduce the vanishing/exploding gradient problem,
control weight magnitudes and stabilize deep neural networks and thus improve
the robustness of training algorithms and the generalization capabilities of
the trained neural network. We present examples of constrained training methods
motivated by orthogonality preservation for weight matrices and explicit weight
normalizations. We describe the methods in the overdamped formulation of
Langevin dynamics and the underdamped form, in which momenta help to improve
sampling efficiency. The methods are explored in test examples in image
classification and natural language processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Neural Network Verification via Shadow Prices. (arXiv:1902.07247v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rubies_Royo_V/0/1/0/all/0/1">Vicenc Rubies-Royo</a>, <a href="http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1">Roberto Calandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Stipanovic_D/0/1/0/all/0/1">Dusan M. Stipanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1">Claire Tomlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.07247">
                                    <div class="article-summary-box-inner">
                                        <span>To use neural networks in safety-critical settings it is paramount to provide
assurances on their runtime operation. Recent work on ReLU networks has sought
to verify whether inputs belonging to a bounded box can ever yield some
undesirable output. Input-splitting procedures, a particular type of
verification mechanism, do so by recursively partitioning the input set into
smaller sets. The efficiency of these methods is largely determined by the
number of splits the box must undergo before the property can be verified. In
this work, we propose a new technique based on shadow prices that fully
exploits the information of the problem yielding a more efficient generation of
splits than the state-of-the-art. Results on the Airborne Collision Avoidance
System (ACAS) benchmark verification tasks show a considerable reduction in the
partitions generated which substantially reduces computation times. These
results open the door to improved verification methods for a wide variety of
machine learning applications including vision and control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiGS : Divergence guided shape implicit neural representation for unoriented point clouds. (arXiv:2106.10811v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Shabat_Y/0/1/0/all/0/1">Yizhak Ben-Shabat</a>, <a href="http://arxiv.org/find/cs/1/au:+Koneputugodage_C/0/1/0/all/0/1">Chamin Hewa Koneputugodage</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10811">
                                    <div class="article-summary-box-inner">
                                        <span>Neural shape representations have recently shown to be effective in shape
analysis and reconstruction tasks. Existing neural network methods require
point coordinates and corresponding normal vectors to learn the implicit level
sets of the shape. Normal vectors are often not provided as raw data,
therefore, approximation and reorientation are required as pre-processing
stages, both of which can introduce noise. In this paper, we propose a
divergence guided shape representation learning approach that does not require
normal vectors as input. We show that incorporating a soft constraint on the
divergence of the distance function favours smooth solutions that reliably
orients gradients to match the unknown normal at each point, in some cases even
better than approaches that use ground truth normal vectors directly.
Additionally, we introduce a novel geometric initialization method for
sinusoidal shape representation networks that further improves convergence to
the desired solution. We evaluate the effectiveness of our approach on the task
of surface reconstruction and show state-of-the-art performance compared to
other unoriented methods and on-par performance compared to oriented methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive Experiments and a Paradox Concerning Logging Policy. (arXiv:2010.03792v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1">Masahiro Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasui_S/0/1/0/all/0/1">Shota Yasui</a>, <a href="http://arxiv.org/find/cs/1/au:+McAlinn_K/0/1/0/all/0/1">Kenichiro McAlinn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03792">
                                    <div class="article-summary-box-inner">
                                        <span>The doubly robust (DR) estimator, which consists of two nuisance parameters,
the conditional mean outcome and the logging policy (the probability of
choosing an action), is crucial in causal inference. This paper proposes a DR
estimator for dependent samples obtained from adaptive experiments. To obtain
an asymptotically normal semiparametric estimator from dependent samples with
non-Donsker nuisance estimators, we propose adaptive-fitting as a variant of
sample-splitting. We also report an empirical paradox that our proposed DR
estimator tends to show better performances compared to other estimators
utilizing the true logging policy. While a similar phenomenon is known for
estimators with i.i.d. samples, traditional explanations based on asymptotic
efficiency cannot elucidate our case with dependent samples. We confirm this
hypothesis through simulation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On predicting research grants productivity. (arXiv:2106.10700v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tohalino_J/0/1/0/all/0/1">Jorge A. V. Tohalino</a>, <a href="http://arxiv.org/find/cs/1/au:+Amancio_D/0/1/0/all/0/1">Diego R. Amancio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10700">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the reasons associated with successful proposals is of
paramount importance to improve evaluation processes. In this context, we
analyzed whether bibliometric features are able to predict the success of
research grants. We extracted features aiming at characterizing the academic
history of Brazilian researchers, including research topics, affiliations,
number of publications and visibility. The extracted features were then used to
predict grants productivity via machine learning in three major research areas,
namely Medicine, Dentistry and Veterinary Medicine. We found that research
subject and publication history play a role in predicting productivity. In
addition, institution-based features turned out to be relevant when combined
with other features. While the best results outperformed text-based attributes,
the evaluated features were not highly discriminative. Our findings indicate
that predicting grants success, at least with the considered set of
bibliometric features, is not a trivial task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting. (arXiv:2003.10392v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lemeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Mao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.10392">
                                    <div class="article-summary-box-inner">
                                        <span>Developing efficient and principled neural architecture optimization methods
is a critical challenge of modern deep learning. Recently, Liu et al.[19]
proposed a splitting steepest descent (S2D) method that jointly optimizes the
neural parameters and architectures based on progressively growing network
structures by splitting neurons into multiple copies in a steepest descent
fashion. However, S2D suffers from a local optimality issue when all the
neurons become &quot;splitting stable&quot;, a concept akin to local stability in
parametric optimization. In this work, we develop a significant and surprising
extension of the splitting descent framework that addresses the local
optimality issue. The idea is to observe that the original S2D is unnecessarily
restricted to splitting neurons into positive weighted copies. By simply
allowing both positive and negative weights during splitting, we can eliminate
the appearance of splitting stability in S2D and hence escape the local optima
to obtain better performance. By incorporating signed splittings, we
significantly extend the optimization power of splitting steepest descent both
theoretically and empirically. We verify our method on various challenging
benchmarks such as CIFAR-100, ImageNet and ModelNet40, on which we outperform
S2D and other advanced methods on learning accurate and energy-efficient neural
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Urdu Caption Generation using Attention based LSTM. (arXiv:2008.01663v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilahi_I/0/1/0/all/0/1">Inaam Ilahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zia_H/0/1/0/all/0/1">Hafiz Muhammad Abdullah Zia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahsan_M/0/1/0/all/0/1">Muhammad Ahtazaz Ahsan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabassam_R/0/1/0/all/0/1">Rauf Tabassam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Armaghan Ahmed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01663">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep learning have created many opportunities to solve
real-world problems that remained unsolved for more than a decade. Automatic
caption generation is a major research field, and the research community has
done a lot of work on it in most common languages like English. Urdu is the
national language of Pakistan and also much spoken and understood in the
sub-continent region of Pakistan-India, and yet no work has been done for Urdu
language caption generation. Our research aims to fill this gap by developing
an attention-based deep learning model using techniques of sequence modeling
specialized for the Urdu language. We have prepared a dataset in the Urdu
language by translating a subset of the &quot;Flickr8k&quot; dataset containing 700 &#x27;man&#x27;
images. We evaluate our proposed technique on this dataset and show that it can
achieve a BLEU score of 0.83 in the Urdu language. We improve on the previous
state-of-the-art by using better CNN architectures and optimization techniques.
Furthermore, we provide a discussion on how the generated captions can be made
correct grammar-wise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending against Backdoor Attack on Deep Neural Networks. (arXiv:2002.12162v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaidi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.12162">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep neural networks (DNNs) have achieved a great success in various
computer vision tasks, it is recently found that they are vulnerable to
adversarial attacks. In this paper, we focus on the so-called \textit{backdoor
attack}, which injects a backdoor trigger to a small portion of training data
(also known as data poisoning) such that the trained DNN induces
misclassification while facing examples with this trigger. To be specific, we
carefully study the effect of both real and synthetic backdoor attacks on the
internal response of vanilla and backdoored DNNs through the lens of Gard-CAM.
Moreover, we show that the backdoor attack induces a significant bias in neuron
activation in terms of the $\ell_\infty$ norm of an activation map compared to
its $\ell_1$ and $\ell_2$ norm. Spurred by our results, we propose the
\textit{$\ell_\infty$-based neuron pruning} to remove the backdoor from the
backdoored DNN. Experiments show that our method could effectively decrease the
attack success rate, and also hold a high classification accuracy for clean
images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic heterogeneous quantization of deep neural networks for low-latency inference on the edge for particle detectors. (arXiv:2006.10159v3 [physics.ins-det] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Coelho_C/0/1/0/all/0/1">Claudionor N. Coelho Jr.</a>, <a href="http://arxiv.org/find/physics/1/au:+Kuusela_A/0/1/0/all/0/1">Aki Kuusela</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_S/0/1/0/all/0/1">Shan Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhuang_H/0/1/0/all/0/1">Hao Zhuang</a>, <a href="http://arxiv.org/find/physics/1/au:+Aarrestad_T/0/1/0/all/0/1">Thea Aarrestad</a>, <a href="http://arxiv.org/find/physics/1/au:+Loncar_V/0/1/0/all/0/1">Vladimir Loncar</a>, <a href="http://arxiv.org/find/physics/1/au:+Ngadiuba_J/0/1/0/all/0/1">Jennifer Ngadiuba</a>, <a href="http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a>, <a href="http://arxiv.org/find/physics/1/au:+Pol_A/0/1/0/all/0/1">Adrian Alan Pol</a>, <a href="http://arxiv.org/find/physics/1/au:+Summers_S/0/1/0/all/0/1">Sioni Summers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10159">
                                    <div class="article-summary-box-inner">
                                        <span>Although the quest for more accurate solutions is pushing deep learning
research towards larger and more complex algorithms, edge devices demand
efficient inference and therefore reduction in model size, latency and energy
consumption. One technique to limit model size is quantization, which implies
using fewer bits to represent weights and biases. Such an approach usually
results in a decline in performance. Here, we introduce a method for designing
optimally heterogeneously quantized versions of deep neural network models for
minimum-energy, high-accuracy, nanosecond inference and fully automated
deployment on chip. With a per-layer, per-parameter type automatic quantization
procedure, sampling from a wide range of quantizers, model energy consumption
and size are minimized while high accuracy is maintained. This is crucial for
the event selection procedure in proton-proton collisions at the CERN Large
Hadron Collider, where resources are strictly limited and a latency of
${\mathcal O}(1)~\mu$s is required. Nanosecond inference and a resource
consumption reduced by a factor of 50 when implemented on field-programmable
gate array hardware are achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimation of Causal Effects in the Presence of Unobserved Confounding in the Alzheimer&#x27;s Continuum. (arXiv:2006.13135v4 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Polsterl_S/0/1/0/all/0/1">Sebastian P&#xf6;lsterl</a>, <a href="http://arxiv.org/find/stat/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13135">
                                    <div class="article-summary-box-inner">
                                        <span>Studying the relationship between neuroanatomy and cognitive decline due to
Alzheimer&#x27;s has been a major research focus in the last decade. However, to
infer cause-effect relationships rather than simple associations from
observational data, we need to (i) express the causal relationships leading to
cognitive decline in a graphical model, and (ii) ensure the causal effect of
interest is identifiable from the collected data. We derive a causal graph from
the current clinical knowledge on cause and effect in the Alzheimer&#x27;s disease
continuum, and show that identifiability of the causal effect requires all
confounders to be known and measured. However, in complex neuroimaging studies,
we neither know all potential confounders nor do we have data on them. To
alleviate this requirement, we leverage the dependencies among multiple causes
by deriving a substitute confounder via a probabilistic latent factor model. In
our theoretical analysis, we prove that using the substitute confounder enables
identifiability of the causal effect of neuroanatomy on cognition. We
quantitatively evaluate the effectiveness of our approach on semi-synthetic
data, where we know the true causal effects, and illustrate its use on real
data on the Alzheimer&#x27;s disease continuum, where it reveals important causes
that otherwise would have been missed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multilayered Block Network Model to Forecast Large Dynamic Transportation Graphs: an Application to US Air Transport. (arXiv:1911.13136v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rodriguez_Deniz_H/0/1/0/all/0/1">Hector Rodriguez-Deniz</a>, <a href="http://arxiv.org/find/stat/1/au:+Villani_M/0/1/0/all/0/1">Mattias Villani</a>, <a href="http://arxiv.org/find/stat/1/au:+Voltes_Dorta_A/0/1/0/all/0/1">Augusto Voltes-Dorta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.13136">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic transportation networks have been analyzed for years by means of
static graph-based indicators in order to study the temporal evolution of
relevant network components, and to reveal complex dependencies that would not
be easily detected by a direct inspection of the data. This paper presents a
state-of-the-art latent network model to forecast multilayer dynamic graphs
that are increasingly common in transportation and proposes a community-based
extension to reduce the computational burden. Flexible time series analysis is
obtained by modeling the probability of edges between vertices through latent
Gaussian processes. The models and Bayesian inference are illustrated on a
sample of 10-year data from four major airlines within the US air
transportation system. Results show how the estimated latent parameters from
the models are related to the airline&#x27;s connectivity dynamics, and their
ability to project the multilayer graph into the future for out-of-sample full
network forecasts, while stochastic blockmodeling allows for the identification
of relevant communities. Reliable network predictions would allow policy-makers
to better understand the dynamics of the transport system, and help in their
planning on e.g. route development, or the deployment of new regulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressing Deep ODE-Nets using Basis Function Expansions. (arXiv:2106.10820v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Queiruga_A/0/1/0/all/0/1">Alejandro Queiruga</a>, <a href="http://arxiv.org/find/cs/1/au:+Erichson_N/0/1/0/all/0/1">N. Benjamin Erichson</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodgkinson_L/0/1/0/all/0/1">Liam Hodgkinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10820">
                                    <div class="article-summary-box-inner">
                                        <span>The recently-introduced class of ordinary differential equation networks
(ODE-Nets) establishes a fruitful connection between deep learning and
dynamical systems. In this work, we reconsider formulations of the weights as
continuous-depth functions using linear combinations of basis functions. This
perspective allows us to compress the weights through a change of basis,
without retraining, while maintaining near state-of-the-art performance. In
turn, both inference time and the memory footprint are reduced, enabling quick
and rigorous adaptation between computational environments. Furthermore, our
framework enables meaningful continuous-in-time batch normalization layers
using function projections. The performance of basis function compression is
demonstrated by applying continuous-depth models to (a) image classification
tasks using convolutional units and (b) sentence-tagging tasks using
transformer encoder units.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analytical confidence intervals for the number of different objects in data streams. (arXiv:1909.11564v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Aletti_G/0/1/0/all/0/1">Giacomo Aletti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11564">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops a new mathematical-statistical approach to analyze a
class of Flajolet-Martin algorithms (FMa), and provides analytical confidence
intervals for the number F0 of distinct elements in a stream, based on Chernoff
bounds. The class of FMa has reached a significant popularity in bigdata stream
learning, and the attention of the literature has mainly been based on
algorithmic aspects, basically complexity optimality, while the statistical
analysis of these class of algorithms has been often faced heuristically. The
analysis provided here shows deep connections with mathematical special
functions and with extreme value theory. The latter connection may help in
explaining heuristic considerations, while the first opens many numerical
issues, faced at the end of the present paper. Finally, the algorithms are
tested on an anonymized real data stream and MonteCarlo simulations are
provided to support our analytical choice in this context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization in the Face of Adaptivity: A Bayesian Perspective. (arXiv:2106.10761v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shenfeld_M/0/1/0/all/0/1">Moshe Shenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Ligett_K/0/1/0/all/0/1">Katrina Ligett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10761">
                                    <div class="article-summary-box-inner">
                                        <span>Repeated use of a data sample via adaptively chosen queries can rapidly lead
to overfitting, wherein the issued queries yield answers on the sample that
differ wildly from the values of those queries on the underlying data
distribution. Differential privacy provides a tool to ensure generalization
despite adaptively-chosen queries, but its worst-case nature means that it
cannot, for example, yield improved results for low-variance queries. In this
paper, we give a simple new characterization that illuminates the core problem
of adaptive data analysis. We show explicitly that the harms of adaptivity come
from the covariance between the behavior of future queries and a Bayes
factor-based measure of how much information about the data sample was encoded
in the responses given to past queries. We leverage this intuition to introduce
a new stability notion; we then use it to prove new generalization results for
the most basic noise-addition mechanisms (Laplace and Gaussian noise addition),
with guarantees that scale with the variance of the queries rather than the
square of their range. Our characterization opens the door to new insights and
new algorithms for the fundamental problem of achieving generalization in
adaptive data analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Examples Make Strong Poisons. (arXiv:2106.10807v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1">Liam Fowl</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_P/0/1/0/all/0/1">Ping-yeh Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Czaja_W/0/1/0/all/0/1">Wojtek Czaja</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10807">
                                    <div class="article-summary-box-inner">
                                        <span>The adversarial machine learning literature is largely partitioned into
evasion attacks on testing data and poisoning attacks on training data. In this
work, we show that adversarial examples, originally intended for attacking
pre-trained models, are even more effective for data poisoning than recent
methods designed specifically for poisoning. Our findings indicate that
adversarial examples, when assigned the original label of their natural base
image, cannot be used to train a classifier for natural images. Furthermore,
when adversarial examples are assigned their adversarial class label, they are
useful for training. This suggests that adversarial examples contain useful
semantic content, just with the &#x60;&#x60;wrong&#x27;&#x27; labels (according to a network, but
not a human). Our method, adversarial poisoning, is substantially more
effective than existing poisoning methods for secure dataset release, and we
release a poisoned version of ImageNet, ImageNet-P, to encourage research into
the strength of this form of data obfuscation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Cryptographic Hardness of Learning Single Periodic Neurons. (arXiv:2106.10744v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Min Jae Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zadik_I/0/1/0/all/0/1">Ilias Zadik</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10744">
                                    <div class="article-summary-box-inner">
                                        <span>We show a simple reduction which demonstrates the cryptographic hardness of
learning a single periodic neuron over isotropic Gaussian distributions in the
presence of noise. More precisely, our reduction shows that any polynomial-time
algorithm (not necessarily gradient-based) for learning such functions under
small noise implies a polynomial-time quantum algorithm for solving worst-case
lattice problems, whose hardness form the foundation of lattice-based
cryptography. Our core hard family of functions, which are well-approximated by
one-layer neural networks, take the general form of a univariate periodic
function applied to an affine projection of the data. These functions have
appeared in previous seminal works which demonstrate their hardness against
gradient-based (Shamir&#x27;18), and Statistical Query (SQ) algorithms (Song et
al.&#x27;17). We show that if (polynomially) small noise is added to the labels, the
intractability of learning these functions applies to all polynomial-time
algorithms under the aforementioned cryptographic assumptions.

Moreover, we demonstrate the necessity of noise in the hardness result by
designing a polynomial-time algorithm for learning certain families of such
functions under exponentially small adversarial noise. Our proposed algorithm
is not a gradient-based or an SQ algorithm, but is rather based on the
celebrated Lenstra-Lenstra-Lov\&#x27;asz (LLL) lattice basis reduction algorithm.
Furthermore, in the absence of noise, this algorithm can be directly applied to
solve CLWE detection (Bruna et al.&#x27;21) and phase retrieval with an optimal
sample complexity of $d+1$ samples. In the former case, this improves upon the
quadratic-in-$d$ sample complexity required in (Bruna et al.&#x27;21). In the latter
case, this improves upon the state-of-the-art AMP-based algorithm, which
requires approximately $1.128d$ samples (Barbier et al.&#x27;19).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multirate Training of Neural Networks. (arXiv:2106.10771v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vlaar_T/0/1/0/all/0/1">Tiffany Vlaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Leimkuhler_B/0/1/0/all/0/1">Benedict Leimkuhler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10771">
                                    <div class="article-summary-box-inner">
                                        <span>We propose multirate training of neural networks: partitioning neural network
parameters into &quot;fast&quot; and &quot;slow&quot; parts which are trained simultaneously using
different learning rates. By choosing appropriate partitionings we can obtain
large computational speed-ups for transfer learning tasks. We show that for
various transfer learning applications in vision and NLP we can fine-tune deep
neural networks in almost half the time, without reducing the generalization
performance of the resulting model. We also discuss other splitting choices for
the neural network parameters which are beneficial in enhancing generalization
performance in settings where neural networks are trained from scratch.
Finally, we propose an additional multirate technique which can learn different
features present in the data by training the full network on different time
scales simultaneously. The benefits of using this approach are illustrated for
ResNet architectures on image data. Our paper unlocks the potential of using
multirate techniques for neural network training and provides many starting
points for future work in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROPE: Reading Order Equivariant Positional Encoding for Graph-based Document Information Extraction. (arXiv:2106.10786v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chun-Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Renshen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1">Yasuhisa Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1">Siyang Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Popat_A/0/1/0/all/0/1">Ashok Popat</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1">Tomas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10786">
                                    <div class="article-summary-box-inner">
                                        <span>Natural reading orders of words are crucial for information extraction from
form-like documents. Despite recent advances in Graph Convolutional Networks
(GCNs) on modeling spatial layout patterns of documents, they have limited
ability to capture reading orders of given word-level node representations in a
graph. We propose Reading Order Equivariant Positional Encoding (ROPE), a new
positional encoding technique designed to apprehend the sequential presentation
of words in documents. ROPE generates unique reading order codes for
neighboring words relative to the target word given a word-level graph
connectivity. We study two fundamental document entity extraction tasks
including word labeling and word grouping on the public FUNSD dataset and a
large-scale payment dataset. We show that ROPE consistently improves existing
GCNs with a margin up to 8.4% F1-score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I-MAD: Interpretable Malware Detector Using Galaxy Transformer. (arXiv:1909.06865v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Miles Q. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_B/0/1/0/all/0/1">Benjamin C. M. Fung</a>, <a href="http://arxiv.org/find/cs/1/au:+Charland_P/0/1/0/all/0/1">Philippe Charland</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Steven H.H. Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.06865">
                                    <div class="article-summary-box-inner">
                                        <span>Malware currently presents a number of serious threats to computer users.
Signature-based malware detection methods are limited in detecting new malware
samples that are significantly different from known ones. Therefore, machine
learning-based methods have been proposed, but there are two challenges these
methods face. The first is to model the full semantics behind the assembly code
of malware. The second challenge is to provide interpretable results while
keeping excellent detection performance. In this paper, we propose an
Interpretable MAlware Detector (I-MAD) that outperforms state-of-the-art static
malware detection models regarding accuracy with excellent interpretability. To
improve the detection performance, I-MAD incorporates a novel network component
called the Galaxy Transformer network that can understand assembly code at the
basic block, function, and executable levels. It also incorporates our proposed
interpretable feed-forward neural network to provide interpretations for its
detection results by quantifying the impact of each feature with respect to the
prediction. Experiment results show that our model significantly outperforms
existing state-of-the-art static malware detection models and presents
meaningful interpretations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Machine Learning: Fad or Future?. (arXiv:2106.10714v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Ishtiaq_A/0/1/0/all/0/1">Arhum Ishtiaq</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Mahmood_S/0/1/0/all/0/1">Sara Mahmood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10714">
                                    <div class="article-summary-box-inner">
                                        <span>For the last few decades, classical machine learning has allowed us to
improve the lives of many through automation, natural language processing,
predictive analytics and much more. However, a major concern is the fact that
we&#x27;re fast approach the threshold of the maximum possible computational
capacity available to us by the means of classical computing devices including
CPUs, GPUs and Application Specific Integrated Circuits (ASICs). This is due to
the exponential increase in model sizes which now have parameters in the
magnitude of billions and trillions, requiring a significant amount of
computing resources across a significant amount of time, just to converge one
single model. To observe the efficacy of using quantum computing for certain
machine learning tasks and explore the improved potential of convergence, error
reduction and robustness to noisy data, this paper will look forth to test and
verify the aspects in which quantum machine learning can help improve over
classical machine learning approaches while also shedding light on the likely
limitations that have prevented quantum approaches to become the mainstream. A
major focus will be to recreate the work by Farhi et al and conduct experiments
using their theory of performing machine learning in a quantum context, with
assistance from the Tensorflow Quantum documentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning audio sequence representations for acoustic event classification. (arXiv:1707.08729v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zixing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Ding Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1">Kun Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn Schuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1707.08729">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic Event Classification (AEC) has become a significant task for
machines to perceive the surrounding auditory scene. However, extracting
effective representations that capture the underlying characteristics of the
acoustic events is still challenging. Previous methods mainly focused on
designing the audio features in a &#x60;hand-crafted&#x27; manner. Interestingly,
data-learnt features have been recently reported to show better performance. Up
to now, these were only considered on the frame level. In this article, we
propose an unsupervised learning framework to learn a vector representation of
an audio sequence for AEC. This framework consists of a Recurrent Neural
Network (RNN) encoder and an RNN decoder, which respectively transforms the
variable-length audio sequence into a fixed-length vector and reconstructs the
input sequence on the generated vector. After training the encoder-decoder, we
feed the audio sequences to the encoder and then take the learnt vectors as the
audio sequence representations. Compared with previous methods, the proposed
method can not only deal with the problem of arbitrary-lengths of audio
streams, but also learn the salient information of the sequence. Extensive
evaluation on a large-size acoustic event database is performed, and the
empirical results demonstrate that the learnt audio sequence representation
yields a significant performance improvement by a large margin compared with
other state-of-the-art hand-crafted sequence features for AEC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Bayesian Meta-learning via Weighted Free Energy Minimization. (arXiv:2106.10711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jose_S/0/1/0/all/0/1">Sharu Theresa Jose</a>, <a href="http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1">Osvaldo Simeone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10711">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning optimizes the hyperparameters of a training procedure, such as
its initialization, kernel, or learning rate, based on data sampled from a
number of auxiliary tasks. A key underlying assumption is that the auxiliary
tasks, known as meta-training tasks, share the same generating distribution as
the tasks to be encountered at deployment time, known as meta-test tasks. This
may, however, not be the case when the test environment differ from the
meta-training conditions. To address shifts in task generating distribution
between meta-training and meta-testing phases, this paper introduces weighted
free energy minimization (WFEM) for transfer meta-learning. We instantiate the
proposed approach for non-parametric Bayesian regression and classification via
Gaussian Processes (GPs). The method is validated on a toy sinusoidal
regression problem, as well as on classification using miniImagenet and CUB
data sets, through comparison with standard meta-learning of GP priors as
implemented by PACOH.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Signal Representations for EEG Cross-Subject Channel Selection and Trial Classification. (arXiv:2106.10633v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Massi_M/0/1/0/all/0/1">Michela C. Massi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ieva_F/0/1/0/all/0/1">Francesca Ieva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10633">
                                    <div class="article-summary-box-inner">
                                        <span>EEG technology finds applications in several domains. Currently, most EEG
systems require subjects to wear several electrodes on the scalp to be
effective. However, several channels might include noisy information, redundant
signals, induce longer preparation times and increase computational times of
any automated system for EEG decoding. One way to reduce the signal-to-noise
ratio and improve classification accuracy is to combine channel selection with
feature extraction, but EEG signals are known to present high inter-subject
variability. In this work we introduce a novel algorithm for
subject-independent channel selection of EEG recordings. Considering
multi-channel trial recordings as statistical units and the EEG decoding task
as the class of reference, the algorithm (i) exploits channel-specific
1D-Convolutional Neural Networks (1D-CNNs) as feature extractors in a
supervised fashion to maximize class separability; (ii) it reduces a high
dimensional multi-channel trial representation into a unique trial vector by
concatenating the channels&#x27; embeddings and (iii) recovers the complex
inter-channel relationships during channel selection, by exploiting an ensemble
of AutoEncoders (AE) to identify from these vectors the most relevant channels
to perform classification. After training, the algorithm can be exploited by
transferring only the parametrized subgroup of selected channel-specific
1D-CNNs to new signals from new subjects and obtain low-dimensional and highly
informative trial vectors to be fed to any classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast PDN Impedance Prediction Using Deep Learning. (arXiv:2106.10693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Ling Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Juang_J/0/1/0/all/0/1">Jack Juang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiguradze_Z/0/1/0/all/0/1">Zurab Kiguradze</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_B/0/1/0/all/0/1">Bo Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1">Shuai Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Songping Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiping Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_C/0/1/0/all/0/1">Chulsoon Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10693">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling and simulating a power distribution network (PDN) for printed
circuit boards (PCBs) with irregular board shapes and multi-layer stackup is
computationally inefficient using full-wave simulations. This paper presents a
new concept of using deep learning for PDN impedance prediction. A boundary
element method (BEM) is applied to efficiently calculate the impedance for
arbitrary board shape and stackup. Then over one million boards with different
shapes, stackup, IC location, and decap placement are randomly generated to
train a deep neural network (DNN). The trained DNN can predict the impedance
accurately for new board configurations that have not been used for training.
The consumed time using the trained DNN is only 0.1 seconds, which is over 100
times faster than the BEM method and 5000 times faster than full-wave
simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging directed causal discovery to detect latent common causes. (arXiv:1910.10174v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lee_C/0/1/0/all/0/1">Ciar&#xe1;n M. Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Hart_C/0/1/0/all/0/1">Christopher Hart</a>, <a href="http://arxiv.org/find/stat/1/au:+Richens_J/0/1/0/all/0/1">Jonathan G. Richens</a>, <a href="http://arxiv.org/find/stat/1/au:+Johri_S/0/1/0/all/0/1">Saurabh Johri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10174">
                                    <div class="article-summary-box-inner">
                                        <span>The discovery of causal relationships is a fundamental problem in science and
medicine. In recent years, many elegant approaches to discovering causal
relationships between two variables from observational data have been proposed.
However, most of these deal only with purely directed causal relationships and
cannot detect latent common causes. Here, we devise a general heuristic which
takes a causal discovery algorithm that can only distinguish purely directed
causal relations and modifies it to also detect latent common causes. We apply
our method to two directed causal discovery algorithms, the Information
Geometric Causal Inference of (Daniusis et al., 2010) and the Kernel
Conditional Deviance for Causal Inference of (Mitrovic, Sejdinovic, &amp; Teh,
2018), and extensively test on synthetic data -- detecting latent common causes
in additive, multiplicative and complex noise regimes -- and on real data,
where we are able to detect known common causes. In addition to detecting
latent common causes, our experiments demonstrate that both the modified
algorithms preserve the performance of the original in distinguishing directed
causal relations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representations and Strategies for Transferable Machine Learning Models in Chemical Discovery. (arXiv:2106.10768v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Harper_D/0/1/0/all/0/1">Daniel R. Harper</a>, <a href="http://arxiv.org/find/physics/1/au:+Nandy_A/0/1/0/all/0/1">Aditya Nandy</a>, <a href="http://arxiv.org/find/physics/1/au:+Arunachalam_N/0/1/0/all/0/1">Naveen Arunachalam</a>, <a href="http://arxiv.org/find/physics/1/au:+Duan_C/0/1/0/all/0/1">Chenru Duan</a>, <a href="http://arxiv.org/find/physics/1/au:+Janet_J/0/1/0/all/0/1">Jon Paul Janet</a>, <a href="http://arxiv.org/find/physics/1/au:+Kulik_H/0/1/0/all/0/1">Heather J. Kulik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10768">
                                    <div class="article-summary-box-inner">
                                        <span>Strategies for machine-learning(ML)-accelerated discovery that are general
across materials composition spaces are essential, but demonstrations of ML
have been primarily limited to narrow composition variations. By addressing the
scarcity of data in promising regions of chemical space for challenging targets
like open-shell transition-metal complexes, general representations and
transferable ML models that leverage known relationships in existing data will
accelerate discovery. Over a large set (ca. 1000) of isovalent transition-metal
complexes, we quantify evident relationships for different properties (i.e.,
spin-splitting and ligand dissociation) between rows of the periodic table
(i.e., 3d/4d metals and 2p/3p ligands). We demonstrate an extension to
graph-based revised autocorrelation (RAC) representation (i.e., eRAC) that
incorporates the effective nuclear charge alongside the nuclear charge
heuristic that otherwise overestimates dissimilarity of isovalent complexes. To
address the common challenge of discovery in a new space where data is limited,
we introduce a transfer learning approach in which we seed models trained on a
large amount of data from one row of the periodic table with a small number of
data points from the additional row. We demonstrate the synergistic value of
the eRACs alongside this transfer learning strategy to consistently improve
model performance. Analysis of these models highlights how the approach
succeeds by reordering the distances between complexes to be more consistent
with the periodic table, a property we expect to be broadly useful for other
materials domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IG-RL: Inductive Graph Reinforcement Learning for Massive-Scale Traffic Signal Control. (arXiv:2003.05738v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Devailly_F/0/1/0/all/0/1">Fran&#xe7;ois-Xavier Devailly</a>, <a href="http://arxiv.org/find/cs/1/au:+Larocque_D/0/1/0/all/0/1">Denis Larocque</a>, <a href="http://arxiv.org/find/cs/1/au:+Charlin_L/0/1/0/all/0/1">Laurent Charlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.05738">
                                    <div class="article-summary-box-inner">
                                        <span>Scaling adaptive traffic-signal control involves dealing with combinatorial
state and action spaces. Multi-agent reinforcement learning attempts to address
this challenge by distributing control to specialized agents. However,
specialization hinders generalization and transferability, and the
computational graphs underlying neural-networks architectures -- dominating in
the multi-agent setting -- do not offer the flexibility to handle an arbitrary
number of entities which changes both between road networks, and over time as
vehicles traverse the network. We introduce Inductive Graph Reinforcement
Learning (IG-RL) based on graph-convolutional networks which adapts to the
structure of any road network, to learn detailed representations of
traffic-controllers and their surroundings. Our decentralized approach enables
learning of a transferable-adaptive-traffic-signal-control policy. After being
trained on an arbitrary set of road networks, our model can generalize to new
road networks, traffic distributions, and traffic regimes, with no additional
training and a constant number of parameters, enabling greater scalability
compared to prior methods. Furthermore, our approach can exploit the
granularity of available data by capturing the (dynamic) demand at both the
lane and the vehicle levels. The proposed method is tested on both road
networks and traffic settings never experienced during training. We compare
IG-RL to multi-agent reinforcement learning and domain-specific baselines. In
both synthetic road networks and in a larger experiment involving the control
of the 3,971 traffic signals of Manhattan, we show that different
instantiations of IG-RL outperform baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossy Compression for Lossless Prediction. (arXiv:2106.10800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1">Yann Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloem_Reddy_B/0/1/0/all/0/1">Benjamin Bloem-Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1">Karen Ullrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1">Chris J. Maddison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10800">
                                    <div class="article-summary-box-inner">
                                        <span>Most data is automatically collected and only ever &quot;seen&quot; by algorithms. Yet,
data compressors preserve perceptual fidelity rather than just the information
needed by algorithms performing downstream tasks. In this paper, we
characterize the bit-rate required to ensure high performance on all predictive
tasks that are invariant under a set of transformations, such as data
augmentations. Based on our theory, we design unsupervised objectives for
training neural compressors. Using these objectives, we train a generic image
compressor that achieves substantial rate savings (more than $1000\times$ on
ImageNet) compared to JPEG on 8 datasets, without decreasing downstream
classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Shapley Value fair? Improving Client Selection for Mavericks in Federated Learning. (arXiv:2106.10734v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1">Chi Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lydia Y. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roos_S/0/1/0/all/0/1">Stefanie Roos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10734">
                                    <div class="article-summary-box-inner">
                                        <span>Shapley Value is commonly adopted to measure and incentivize client
participation in federated learning. In this paper, we show -- theoretically
and through simulations -- that Shapley Value underestimates the contribution
of a common type of client: the Maverick. Mavericks are clients that differ
both in data distribution and data quantity and can be the sole owners of
certain types of data. Selecting the right clients at the right moment is
important for federated learning to reduce convergence times and improve
accuracy. We propose FedEMD, an adaptive client selection strategy based on the
Wasserstein distance between the local and global data distributions. As FedEMD
adapts the selection probability such that Mavericks are preferably selected
when the model benefits from improvement on rare classes, it consistently
ensures the fast convergence in the presence of different types of Mavericks.
Compared to existing strategies, including Shapley Value-based ones, FedEMD
improves the convergence of neural network classifiers by at least 26.9% for
FedAvg aggregation compared with the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Better Training using Weight-Constrained Stochastic Dynamics. (arXiv:2106.10704v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leimkuhler_B/0/1/0/all/0/1">Benedict Leimkuhler</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlaar_T/0/1/0/all/0/1">Tiffany Vlaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouchon_T/0/1/0/all/0/1">Timoth&#xe9;e Pouchon</a>, <a href="http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1">Amos Storkey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10704">
                                    <div class="article-summary-box-inner">
                                        <span>We employ constraints to control the parameter space of deep neural networks
throughout training. The use of customized, appropriately designed constraints
can reduce the vanishing/exploding gradients problem, improve smoothness of
classification boundaries, control weight magnitudes and stabilize deep neural
networks, and thus enhance the robustness of training algorithms and the
generalization capabilities of neural networks. We provide a general approach
to efficiently incorporate constraints into a stochastic gradient Langevin
framework, allowing enhanced exploration of the loss landscape. We also present
specific examples of constrained training methods motivated by orthogonality
preservation for weight matrices and explicit weight normalizations.
Discretization schemes are provided both for the overdamped formulation of
Langevin dynamics and the underdamped form, in which momenta further improve
sampling efficiency. These optimization schemes can be used directly, without
needing to adapt neural network architecture design choices or to modify the
objective with regularization terms, and see performance improvements in
classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Catastrophic Forgetting by Generative Regularization. (arXiv:1912.01238v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Patrick H. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.01238">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a new method to overcome catastrophic forgetting by
adding generative regularization to Bayesian inference framework. Bayesian
method provides a general framework for continual learning. We could further
construct a generative regularization term for all given classification models
by leveraging energy-based models and Langevin-dynamic sampling to enrich the
features learned in each task. By combining discriminative and generative loss
together, we empirically show that the proposed method outperforms
state-of-the-art methods on a variety of tasks, avoiding catastrophic
forgetting in continual learning. In particular, the proposed method
outperforms baseline methods over 15% on the Fashion-MNIST dataset and 10% on
the CUB dataset</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Strategies for Decision Theoretic Online Learning. (arXiv:2106.10717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Freund_Y/0/1/0/all/0/1">Yoav Freund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10717">
                                    <div class="article-summary-box-inner">
                                        <span>We extend the drifting games analysis to continuous time and show that the
optimal adversary, if the value function has strictly positive derivative up to
fourth order is bronian motion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plant Disease Detection Using Image Processing and Machine Learning. (arXiv:2106.10698v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1">Pranesh Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Karwande_A/0/1/0/all/0/1">Atharva Karwande</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolhe_T/0/1/0/all/0/1">Tejas Kolhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamble_S/0/1/0/all/0/1">Soham Kamble</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1">Akshay Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyawahare_M/0/1/0/all/0/1">Medha Wyawahare</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10698">
                                    <div class="article-summary-box-inner">
                                        <span>One of the important and tedious task in agricultural practices is the
detection of the disease on crops. It requires huge time as well as skilled
labor. This paper proposes a smart and efficient technique for detection of
crop disease which uses computer vision and machine learning techniques. The
proposed system is able to detect 20 different diseases of 5 common plants with
93% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients. (arXiv:2106.10784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Miao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Steven Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiaojun Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasnejad_E/0/1/0/all/0/1">Ehsan Abbasnejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Haffari_R/0/1/0/all/0/1">Reza Haffari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10784">
                                    <div class="article-summary-box-inner">
                                        <span>\textit{Differentiable ARchiTecture Search} (DARTS) has recently become the
mainstream of neural architecture search (NAS) due to its efficiency and
simplicity. With a gradient-based bi-level optimization, DARTS alternately
optimizes the inner model weights and the outer architecture parameter in a
weight-sharing supernet. A key challenge to the scalability and quality of the
learned architectures is the need for differentiating through the inner-loop
optimisation. While much has been discussed about several potentially fatal
factors in DARTS, the architecture gradient, a.k.a. hypergradient, has received
less attention. In this paper, we tackle the hypergradient computation in DARTS
based on the implicit function theorem, making it only depends on the obtained
solution to the inner-loop optimization and agnostic to the optimization path.
To further reduce the computational requirements, we formulate a stochastic
hypergradient approximation for differentiable NAS, and theoretically show that
the architecture optimization with the proposed method, named iDARTS, is
expected to converge to a stationary point. Comprehensive experiments on two
NAS benchmark search spaces and the common NAS search space verify the
effectiveness of our proposed method. It leads to architectures outperforming,
with large margins, those learned by the baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-Scale Network Embedding in Apache Spark. (arXiv:2106.10620v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wenqing Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10620">
                                    <div class="article-summary-box-inner">
                                        <span>Network embedding has been widely used in social recommendation and network
analysis, such as recommendation systems and anomaly detection with graphs.
However, most of previous approaches cannot handle large graphs efficiently,
due to that (i) computation on graphs is often costly and (ii) the size of
graph or the intermediate results of vectors could be prohibitively large,
rendering it difficult to be processed on a single machine. In this paper, we
propose an efficient and effective distributed algorithm for network embedding
on large graphs using Apache Spark, which recursively partitions a graph into
several small-sized subgraphs to capture the internal and external structural
information of nodes, and then computes the network embedding for each subgraph
in parallel. Finally, by aggregating the outputs on all subgraphs, we obtain
the embeddings of nodes in a linear cost. After that, we demonstrate in various
experiments that our proposed approach is able to handle graphs with billions
of edges within a few hours and is at least 4 times faster than the
state-of-the-art approaches. Besides, it achieves up to $4.25\%$ and $4.27\%$
improvements on link prediction and node classification tasks respectively. In
the end, we deploy the proposed algorithms in two online games of Tencent with
the applications of friend recommendation and item recommendation, which
improve the competitors by up to $91.11\%$ in running time and up to $12.80\%$
in the corresponding evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep splitting method for parabolic PDEs. (arXiv:1907.03452v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Beck_C/0/1/0/all/0/1">Christian Beck</a>, <a href="http://arxiv.org/find/math/1/au:+Becker_S/0/1/0/all/0/1">Sebastian Becker</a>, <a href="http://arxiv.org/find/math/1/au:+Cheridito_P/0/1/0/all/0/1">Patrick Cheridito</a>, <a href="http://arxiv.org/find/math/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/math/1/au:+Neufeld_A/0/1/0/all/0/1">Ariel Neufeld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.03452">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we introduce a numerical method for nonlinear parabolic PDEs
that combines operator splitting with deep learning. It divides the PDE
approximation problem into a sequence of separate learning problems. Since the
computational graph for each of the subproblems is comparatively small, the
approach can handle extremely high-dimensional PDEs. We test the method on
different examples from physics, stochastic control and mathematical finance.
In all cases, it yields very good results in up to 10,000 dimensions with short
run times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Generalization Bounds of Group Invariant / Equivariant Deep Networks via Quotient Feature Spaces. (arXiv:1910.06552v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sannai_A/0/1/0/all/0/1">Akiyoshi Sannai</a>, <a href="http://arxiv.org/find/stat/1/au:+Imaizumi_M/0/1/0/all/0/1">Masaaki Imaizumi</a>, <a href="http://arxiv.org/find/stat/1/au:+Kawano_M/0/1/0/all/0/1">Makoto Kawano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.06552">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous invariant (or equivariant) neural networks have succeeded in
handling invariant data such as point clouds and graphs. However, a
generalization theory for the neural networks has not been well developed,
because several essential factors for the theory, such as network size and
margin distribution, are not deeply connected to the invariance and
equivariance. In this study, we develop a novel generalization error bound for
invariant and equivariant deep neural networks. To describe the effect of
invariance and equivariance on generalization, we develop a notion of a
\textit{quotient feature space}, which measures the effect of group actions for
the properties. Our main result proves that the volume of quotient feature
spaces can describe the generalization error. Furthermore, the bound shows that
the invariance and equivariance significantly improve the leading term of the
bound. We apply our result to specific invariant and equivariant networks, such
as DeepSets (Zaheer et al. (2017)), and show that their generalization bound is
considerably improved by $\sqrt{n!}$, where $n!$ is the number of permutations.
We also discuss the expressive power of invariant DNNs and show that they can
achieve an optimal approximation rate. Our experimental result supports our
theoretical claims.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densities of Almost Surely Terminating Probabilistic Programs are Differentiable Almost Everywhere. (arXiv:2004.03924v2 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mak_C/0/1/0/all/0/1">Carol Mak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1">C.-H. Luke Ong</a>, <a href="http://arxiv.org/find/cs/1/au:+Paquet_H/0/1/0/all/0/1">Hugo Paquet</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1">Dominik Wagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03924">
                                    <div class="article-summary-box-inner">
                                        <span>We study the differential properties of higher-order statistical
probabilistic programs with recursion and conditioning. Our starting point is
an open problem posed by Hongseok Yang: what class of statistical probabilistic
programs have densities that are differentiable almost everywhere? To formalise
the problem, we consider Statistical PCF (SPCF), an extension of call-by-value
PCF with real numbers, and constructs for sampling and conditioning. We give
SPCF a sampling-style operational semantics a la Borgstrom et al., and study
the associated weight (commonly referred to as the density) function and value
function on the set of possible execution traces. Our main result is that
almost-surely terminating SPCF programs, generated from a set of primitive
functions (e.g. the set of analytic functions) satisfying mild closure
properties, have weight and value functions that are almost-everywhere
differentiable. We use a stochastic form of symbolic execution to reason about
almost-everywhere differentiability. A by-product of this work is that
almost-surely terminating deterministic (S)PCF programs with real parameters
denote functions that are almost-everywhere differentiable. Our result is of
practical interest, as almost-everywhere differentiability of the density
function is required to hold for the correctness of major gradient-based
inference algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Regression via Model Based Methods. (arXiv:2106.10759v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moharrer_A/0/1/0/all/0/1">Armin Moharrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamran_K/0/1/0/all/0/1">Khashayar Kamran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_E/0/1/0/all/0/1">Edmund Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1">Stratis Ioannidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10759">
                                    <div class="article-summary-box-inner">
                                        <span>The mean squared error loss is widely used in many applications, including
auto-encoders, multi-target regression, and matrix factorization, to name a
few. Despite computational advantages due to its differentiability, it is not
robust to outliers. In contrast, l_p norms are known to be robust, but cannot
be optimized via, e.g., stochastic gradient descent, as they are
non-differentiable. We propose an algorithm inspired by so-called model-based
optimization (MBO) [35, 36], which replaces a non-convex objective with a
convex model function and alternates between optimizing the model function and
updating the solution. We apply this to robust regression, proposing SADM, a
stochastic variant of the Online Alternating Direction Method of Multipliers
(OADM) [50] to solve the inner optimization in MBO. We show that SADM converges
with the rate O(log T/T). Finally, we demonstrate experimentally (a) the
robustness of l_p norms to outliers and (b) the efficiency of our proposed
model-based algorithms in comparison with gradient methods on autoencoders and
multi-target regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A compressive multi-kernel method for privacy-preserving machine learning. (arXiv:2106.10671v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chanyaswad_T/0/1/0/all/0/1">Thee Chanyaswad</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">J. Morris Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kung_S/0/1/0/all/0/1">S.Y. Kung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10671">
                                    <div class="article-summary-box-inner">
                                        <span>As the analytic tools become more powerful, and more data are generated on a
daily basis, the issue of data privacy arises. This leads to the study of the
design of privacy-preserving machine learning algorithms. Given two objectives,
namely, utility maximization and privacy-loss minimization, this work is based
on two previously non-intersecting regimes -- Compressive Privacy and
multi-kernel method. Compressive Privacy is a privacy framework that employs
utility-preserving lossy-encoding scheme to protect the privacy of the data,
while multi-kernel method is a kernel based machine learning regime that
explores the idea of using multiple kernels for building better predictors. The
compressive multi-kernel method proposed consists of two stages -- the
compression stage and the multi-kernel stage. The compression stage follows the
Compressive Privacy paradigm to provide the desired privacy protection. Each
kernel matrix is compressed with a lossy projection matrix derived from the
Discriminant Component Analysis (DCA). The multi-kernel stage uses the
signal-to-noise ratio (SNR) score of each kernel to non-uniformly combine
multiple compressive kernels. The proposed method is evaluated on two
mobile-sensing datasets -- MHEALTH and HAR -- where activity recognition is
defined as utility and person identification is defined as privacy. The results
show that the compression regime is successful in privacy preservation as the
privacy classification accuracies are almost at the random-guess level in all
experiments. On the other hand, the novel SNR-based multi-kernel shows utility
classification accuracy improvement upon the state-of-the-art in both datasets.
These results indicate a promising direction for research in privacy-preserving
machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Outlier Detection and Spatial Analysis Algorithms. (arXiv:2106.10669v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+John_J/0/1/0/all/0/1">Jacob John</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10669">
                                    <div class="article-summary-box-inner">
                                        <span>Outlier detection is a significant area in data mining. It can be either used
to pre-process the data prior to an analysis or post the processing phase
(before visualization) depending on the effectiveness of the outlier and its
importance. Outlier detection extends to several fields such as detection of
credit card fraud, network intrusions, machine failure prediction, potential
terrorist attacks, and so on. Outliers are those data points with
characteristics considerably different. They deviate from the data set causing
inconsistencies, noise and anomalies during analysis and result in modification
of the original points However, a common misconception is that outliers have to
be immediately eliminated or replaced from the data set. Such points could be
considered useful if analyzed separately as they could be obtained from a
separate mechanism entirely making it important to the research question. This
study surveys the different methods of outlier detection for spatial analysis.
Spatial data or geospatial data are those that exhibit geographic properties or
attributes such as position or areas. An example would be weather data such as
precipitation, temperature, wind velocity, and so on collected for a defined
region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAMERAS: Enhanced Resolution And Sanity preserving Class Activation Mapping for image saliency. (arXiv:2106.10649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalwana_M/0/1/0/all/0/1">Mohammad A. A. K. Jalwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10649">
                                    <div class="article-summary-box-inner">
                                        <span>Backpropagation image saliency aims at explaining model predictions by
estimating model-centric importance of individual pixels in the input. However,
class-insensitivity of the earlier layers in a network only allows saliency
computation with low resolution activation maps of the deeper layers, resulting
in compromised image saliency. Remedifying this can lead to sanity failures. We
propose CAMERAS, a technique to compute high-fidelity backpropagation saliency
maps without requiring any external priors and preserving the map sanity. Our
method systematically performs multi-scale accumulation and fusion of the
activation maps and backpropagated gradients to compute precise saliency maps.
From accurate image saliency to articulation of relative importance of input
features for different models, and precise discrimination between model
perception of visually similar objects, our high-resolution mapping offers
multiple novel insights into the black-box deep visual models, which are
presented in the paper. We also demonstrate the utility of our saliency maps in
adversarial setup by drastically reducing the norm of attack signals by
focusing them on the precise regions identified by our maps. Our method also
inspires new evaluation metrics and a sanity check for this developing research
direction. Code is available here https://github.com/VisMIL/CAMERAS</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighborhood Contrastive Learning for Novel Class Discovery. (arXiv:2106.10731v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fini_E/0/1/0/all/0/1">Enrico Fini</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhankar Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhiming Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1">Elisa Ricci</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10731">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address Novel Class Discovery (NCD), the task of unveiling
new classes in a set of unlabeled samples given a labeled dataset with known
classes. We exploit the peculiarities of NCD to build a new framework, named
Neighborhood Contrastive Learning (NCL), to learn discriminative
representations that are important to clustering performance. Our contribution
is twofold. First, we find that a feature extractor trained on the labeled set
generates representations in which a generic query sample and its neighbors are
likely to share the same class. We exploit this observation to retrieve and
aggregate pseudo-positive pairs with contrastive learning, thus encouraging the
model to learn more discriminative representations. Second, we notice that most
of the instances are easily discriminated by the network, contributing less to
the contrastive loss. To overcome this issue, we propose to generate hard
negatives by mixing labeled and unlabeled samples in the feature space. We
experimentally demonstrate that these two ingredients significantly contribute
to clustering performance and lead our model to outperform state-of-the-art
methods by a large margin (e.g., clustering accuracy +13% on CIFAR-100 and +8%
on ImageNet).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opportunities and challenges in partitioning the graph measure space of real-world networks. (arXiv:2106.10753v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jozsa_M/0/1/0/all/0/1">M&#xe1;t&#xe9; J&#xf3;zsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazar_A/0/1/0/all/0/1">Alp&#xe1;r S. L&#xe1;z&#xe1;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazar_Z/0/1/0/all/0/1">Zsolt I. L&#xe1;z&#xe1;r</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10753">
                                    <div class="article-summary-box-inner">
                                        <span>Based on a large dataset containing thousands of real-world networks ranging
from genetic, protein interaction, and metabolic networks to brain, language,
ecology, and social networks we search for defining structural measures of the
different complex network domains (CND). We calculate 208 measures for all
networks and using a comprehensive and scrupulous workflow of statistical and
machine learning methods we investigated the limitations and possibilities of
identifying the key graph measures of CNDs. Our approach managed to identify
well distinguishable groups of network domains and confer their relevant
features. These features turn out to be CND specific and not unique even at the
level of individual CNDs. The presented methodology may be applied to other
similar scenarios involving highly unbalanced and skewed datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Attack on Graph Neural Networks as An Influence Maximization Problem. (arXiv:2106.10785v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiaqi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Junwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10785">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have attracted increasing interests. With broad
deployments of GNNs in real-world applications, there is an urgent need for
understanding the robustness of GNNs under adversarial attacks, especially in
realistic setups. In this work, we study the problem of attacking GNNs in a
restricted and realistic setup, by perturbing the features of a small set of
nodes, with no access to model parameters and model predictions. Our formal
analysis draws a connection between this type of attacks and an influence
maximization problem on the graph. This connection not only enhances our
understanding on the problem of adversarial attack on GNNs, but also allows us
to propose a group of effective and practical attack strategies. Our
experiments verify that the proposed attack strategies significantly degrade
the performance of three popular GNN models and outperform baseline adversarial
attack strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cogradient Descent for Dependable Learning. (arXiv:2106.10617v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baochang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Li&#x27;an Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Doermann_D/0/1/0/all/0/1">David Doermann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10617">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional gradient descent methods compute the gradients for multiple
variables through the partial derivative. Treating the coupled variables
independently while ignoring the interaction, however, leads to an insufficient
optimization for bilinear models. In this paper, we propose a dependable
learning based on Cogradient Descent (CoGD) algorithm to address the bilinear
optimization problem, providing a systematic way to coordinate the gradients of
coupling variables based on a kernelized projection function. CoGD is
introduced to solve bilinear problems when one variable is with sparsity
constraint, as often occurs in modern learning paradigms. CoGD can also be used
to decompose the association of features and weights, which further generalizes
our method to better train convolutional neural networks (CNNs) and improve the
model capacity. CoGD is applied in representative bilinear problems, including
image reconstruction, image inpainting, network pruning and CNN training.
Extensive experiments show that CoGD improves the state-of-the-arts by
significant margins. Code is available at
{https://github.com/bczhangbczhang/CoGD}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning in the social and health sciences. (arXiv:2106.10716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leist_A/0/1/0/all/0/1">Anja K. Leist</a>, <a href="http://arxiv.org/find/cs/1/au:+Klee_M/0/1/0/all/0/1">Matthias Klee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jung Hyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehkopf_D/0/1/0/all/0/1">David H. Rehkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bordas_S/0/1/0/all/0/1">St&#xe9;phane P. A. Bordas</a>, <a href="http://arxiv.org/find/cs/1/au:+Muniz_Terrera_G/0/1/0/all/0/1">Graciela Muniz-Terrera</a>, <a href="http://arxiv.org/find/cs/1/au:+Wade_S/0/1/0/all/0/1">Sara Wade</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10716">
                                    <div class="article-summary-box-inner">
                                        <span>The uptake of machine learning (ML) approaches in the social and health
sciences has been rather slow, and research using ML for social and health
research questions remains fragmented. This may be due to the separate
development of research in the computational/data versus social and health
sciences as well as a lack of accessible overviews and adequate training in ML
techniques for non data science researchers. This paper provides a meta-mapping
of research questions in the social and health sciences to appropriate ML
approaches, by incorporating the necessary requirements to statistical analysis
in these disciplines. We map the established classification into description,
prediction, and causal inference to common research goals, such as estimating
prevalence of adverse health or social outcomes, predicting the risk of an
event, and identifying risk factors or causes of adverse outcomes. This
meta-mapping aims at overcoming disciplinary barriers and starting a fluid
dialogue between researchers from the social and health sciences and
methodologically trained researchers. Such mapping may also help to fully
exploit the benefits of ML while considering domain-specific aspects relevant
to the social and health sciences, and hopefully contribute to the acceleration
of the uptake of ML applications to advance both basic and applied social and
health sciences research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedXGBoost: Privacy-Preserving XGBoost for Federated Learning. (arXiv:2106.10662v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Nhan Khanh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quang Minh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fangzhou Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Quanwei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirche_S/0/1/0/all/0/1">Sandra Hirche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10662">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is the distributed machine learning framework that enables
collaborative training across multiple parties while ensuring data privacy.
Practical adaptation of XGBoost, the state-of-the-art tree boosting framework,
to federated learning remains limited due to high cost incurred by conventional
privacy-preserving methods. To address the problem, we propose two variants of
federated XGBoost with privacy guarantee: FedXGBoost-SMM and FedXGBoost-LDP.
Our first protocol FedXGBoost-SMM deploys enhanced secure matrix multiplication
method to preserve privacy with lossless accuracy and lower overhead than
encryption-based techniques. Developed independently, the second protocol
FedXGBoost-LDP is heuristically designed with noise perturbation for local
differential privacy, and empirically evaluated on real-world and synthetic
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Vision Transformers for Fine-grained Classification. (arXiv:2106.10587v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1">Marcos V. Conde</a>, <a href="http://arxiv.org/find/cs/1/au:+Turgutlu_K/0/1/0/all/0/1">Kerem Turgutlu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10587">
                                    <div class="article-summary-box-inner">
                                        <span>Existing computer vision research in categorization struggles with
fine-grained attributes recognition due to the inherently high intra-class
variances and low inter-class variances. SOTA methods tackle this challenge by
locating the most informative image regions and rely on them to classify the
complete image. The most recent work, Vision Transformer (ViT), shows its
strong performance in both traditional and fine-grained classification tasks.
In this work, we propose a multi-stage ViT framework for fine-grained image
classification tasks, which localizes the informative image regions without
requiring architectural changes using the inherent multi-head self-attention
mechanism. We also introduce attention-guided augmentations for improving the
model&#x27;s capabilities. We demonstrate the value of our approach by experimenting
with four popular fine-grained benchmarks: CUB-200-2011, Stanford Cars,
Stanford Dogs, and FGVC7 Plant Pathology. We also prove our model&#x27;s
interpretability via qualitative results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yufei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10507">
                                    <div class="article-summary-box-inner">
                                        <span>Graphically-rich applications such as games are ubiquitous with attractive
visual effects of Graphical User Interface (GUI) that offers a bridge between
software applications and end-users. However, various types of graphical
glitches may arise from such GUI complexity and have become one of the main
component of software compatibility issues. Our study on bug reports from game
development teams in NetEase Inc. indicates that graphical glitches frequently
occur during the GUI rendering and severely degrade the quality of
graphically-rich applications such as video games. Existing automated testing
techniques for such applications focus mainly on generating various GUI test
sequences and check whether the test sequences can cause crashes. These
techniques require constant human attention to captures non-crashing bugs such
as bugs causing graphical glitches. In this paper, we present the first step in
automating the test oracle for detecting non-crashing bugs in graphically-rich
applications. Specifically, we propose \texttt{GLIB} based on a code-based data
augmentation technique to detect game GUI glitches. We perform an evaluation of
\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the
result shows that \texttt{GLIB} can achieve 100\% precision and 99.5\% recall
in detecting non-crashing bugs such as game GUI glitches. Practical application
of \texttt{GLIB} on another 14 real-world games (without bug reports) further
demonstrates that \texttt{GLIB} can effectively uncover GUI glitches, with 48
of 53 bugs reported by \texttt{GLIB} having been confirmed and fixed so far.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combinatorial Semi-Bandit in the Non-Stationary Environment. (arXiv:2002.03580v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.03580">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the non-stationary combinatorial semi-bandit
problem, both in the switching case and in the dynamic case. In the general
case where (a) the reward function is non-linear, (b) arms may be
probabilistically triggered, and (c) only approximate offline oracle exists
\cite{wang2017improving}, our algorithm achieves
$\tilde{\mathcal{O}}(\sqrt{\mathcal{S} T})$ distribution-dependent regret in
the switching case, and $\tilde{\mathcal{O}}(\mathcal{V}^{1/3}T^{2/3})$ in the
dynamic case, where $\mathcal S$ is the number of switchings and $\mathcal V$
is the sum of the total &#x60;&#x60;distribution changes&#x27;&#x27;. The regret bounds in both
scenarios are nearly optimal, but our algorithm needs to know the parameter
$\mathcal S$ or $\mathcal V$ in advance.

We further show that by employing another technique, our algorithm no longer
needs to know the parameters $\mathcal S$ or $\mathcal V$ but the regret bounds
could become suboptimal.

In a special case where the reward function is linear and we have an exact
oracle, we design a parameter-free algorithm that achieves nearly optimal
regret both in the switching case and in the dynamic case without knowing the
parameters in advance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for Visual Information Extraction using Sequences. (arXiv:2106.10681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiapeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Guozhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weihong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kai Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yichao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10681">
                                    <div class="article-summary-box-inner">
                                        <span>Visual information extraction (VIE) has attracted increasing attention in
recent years. The existing methods usually first organized optical character
recognition (OCR) results into plain texts and then utilized token-level entity
annotations as supervision to train a sequence tagging model. However, it
expends great annotation costs and may be exposed to label confusion, and the
OCR errors will also significantly affect the final performance. In this paper,
we propose a unified weakly-supervised learning framework called TCPN (Tag,
Copy or Predict Network), which introduces 1) an efficient encoder to
simultaneously model the semantic and layout information in 2D OCR results; 2)
a weakly-supervised training strategy that utilizes only key information
sequences as supervision; and 3) a flexible and switchable decoder which
contains two inference modes: one (Copy or Predict Mode) is to output key
information sequences of different categories by copying a token from the input
or predicting one in each time step, and the other (Tag Mode) is to directly
tag the input sequence in a single forward pass. Our method shows new
state-of-the-art performance on several public benchmarks, which fully proves
its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OptiDICE: Offline Policy Optimization via Stationary Distribution Correction Estimation. (arXiv:2106.10783v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jongmin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_W/0/1/0/all/0/1">Wonseok Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Byung-Jun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kee-Eung Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10783">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the offline reinforcement learning (RL) setting where the agent
aims to optimize the policy solely from the data without further environment
interactions. In offline RL, the distributional shift becomes the primary
source of difficulty, which arises from the deviation of the target policy
being optimized from the behavior policy used for data collection. This
typically causes overestimation of action values, which poses severe problems
for model-free algorithms that use bootstrapping. To mitigate the problem,
prior offline RL algorithms often used sophisticated techniques that encourage
underestimation of action values, which introduces an additional set of
hyperparameters that need to be tuned properly. In this paper, we present an
offline RL algorithm that prevents overestimation in a more principled way. Our
algorithm, OptiDICE, directly estimates the stationary distribution corrections
of the optimal policy and does not rely on policy-gradients, unlike previous
offline RL algorithms. Using an extensive set of benchmark datasets for offline
RL, we show that OptiDICE performs competitively with the state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-Faced Humans on Twitter and Facebook: Harvesting Social Multimedia for Human Personality Profiling. (arXiv:2106.10673v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Farseev_A/0/1/0/all/0/1">Aleksandr Farseev</a>, <a href="http://arxiv.org/find/cs/1/au:+Filchenkov_A/0/1/0/all/0/1">Andrey Filchenkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10673">
                                    <div class="article-summary-box-inner">
                                        <span>Human personality traits are the key drivers behind our decision-making,
influencing our life path on a daily basis. Inference of personality traits,
such as Myers-Briggs Personality Type, as well as an understanding of
dependencies between personality traits and users&#x27; behavior on various social
media platforms is of crucial importance to modern research and industry
applications. The emergence of diverse and cross-purpose social media avenues
makes it possible to perform user personality profiling automatically and
efficiently based on data represented across multiple data modalities. However,
the research efforts on personality profiling from multi-source multi-modal
social media data are relatively sparse, and the level of impact of different
social network data on machine learning performance has yet to be
comprehensively evaluated. Furthermore, there is not such dataset in the
research community to benchmark. This study is one of the first attempts
towards bridging such an important research gap. Specifically, in this work, we
infer the Myers-Briggs Personality Type indicators, by applying a novel
multi-view fusion framework, called &quot;PERS&quot; and comparing the performance
results not just across data modalities but also with respect to different
social network data sources. Our experimental results demonstrate the PERS&#x27;s
ability to learn from multi-view data for personality profiling by efficiently
leveraging on the significantly different data arriving from diverse social
multimedia sources. We have also found that the selection of a machine learning
approach is of crucial importance when choosing social network data sources and
that people tend to reveal multiple facets of their personality in different
social media avenues. Our released social multimedia dataset facilitates future
research on this direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Spectral Marked Point Processes. (arXiv:2106.10773v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Shixiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuyuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10773">
                                    <div class="article-summary-box-inner">
                                        <span>Self- and mutually-exciting point processes are popular models in machine
learning and statistics for dependent discrete event data. To date, most
existing models assume stationary kernels (including the classical Hawkes
processes) and simple parametric models. Modern applications with complex event
data require more general point process models that can incorporate contextual
information of the events, called marks, besides the temporal and location
information. Moreover, such applications often require non-stationary models to
capture more complex spatio-temporal dependence. To tackle these challenges, a
key question is to devise a versatile influence kernel in the point process
model. In this paper, we introduce a novel and general neural network-based
non-stationary influence kernel with high expressiveness for handling complex
discrete events data while providing theoretical performance guarantees. We
demonstrate the superior performance of our proposed method compared with the
state-of-the-art on synthetic and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Reach, Swim, Walk and Fly in One Trial: Data-Driven Control with Scarce Data and Side Information. (arXiv:2106.10533v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Djeumou_F/0/1/0/all/0/1">Franck Djeumou</a>, <a href="http://arxiv.org/find/eess/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10533">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a learning-based control algorithm for unknown dynamical systems
under very severe data limitations. Specifically, the algorithm has access to
streaming data only from a single and ongoing trial. Despite the scarcity of
data, we show -- through a series of examples -- that the algorithm can provide
performance comparable to reinforcement learning algorithms trained over
millions of environment interactions. It accomplishes such performance by
effectively leveraging various forms of side information on the dynamics to
reduce the sample complexity. Such side information typically comes from
elementary laws of physics and qualitative properties of the system. More
precisely, the algorithm approximately solves an optimal control problem
encoding the system&#x27;s desired behavior. To this end, it constructs and refines
a differential inclusion that contains the unknown vector field of the
dynamics. The differential inclusion, used in an interval Taylor-based method,
enables to over-approximate the set of states the system may reach.
Theoretically, we establish a bound on the suboptimality of the approximate
solution with respect to the case of known dynamics. We show that the longer
the trial or the more side information is available, the tighter the bound.
Empirically, experiments in a high-fidelity F-16 aircraft simulator and
MuJoCo&#x27;s environments such as the Reacher, Swimmer, and Cheetah illustrate the
algorithm&#x27;s effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Stein Variational Neural Network Ensembles. (arXiv:2106.10760v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DAngelo_F/0/1/0/all/0/1">Francesco D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1">Vincent Fortuin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenzel_F/0/1/0/all/0/1">Florian Wenzel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10760">
                                    <div class="article-summary-box-inner">
                                        <span>Ensembles of deep neural networks have achieved great success recently, but
they do not offer a proper Bayesian justification. Moreover, while they allow
for averaging of predictions over several hypotheses, they do not provide any
guarantees for their diversity, leading to redundant solutions in function
space. In contrast, particle-based inference methods, such as Stein variational
gradient descent (SVGD), offer a Bayesian framework, but rely on the choice of
a kernel to measure the similarity between ensemble members. In this work, we
study different SVGD methods operating in the weight space, function space, and
in a hybrid setting. % Defining the kernel directly on the neural network
functions seems promising to overcome the limitations of deep ensembles. %
However, ensuring diversity in function space while maintaining SVGD&#x27;s
theoretical guarantees is not trivial. % In this work, we provide an overview
over different ensembling and SVGD methods in weight space and function space
and propose new and assess their theoretical and empirical properties on
synthetic and real-world tasks. We compare the SVGD approaches to other
ensembling-based methods in terms of their theoretical properties and assess
their empirical performance on synthetic and real-world tasks. We find that
SVGD using functional and hybrid kernels can overcome the limitations of deep
ensembles. It improves on functional diversity and uncertainty estimation and
approaches the true Bayesian posterior more closely. Moreover, we show that
using stochastic SVGD updates, as opposed to the standard deterministic ones,
can further improve the performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking Perturbation-based Saliency Maps for Explaining Atari Agents. (arXiv:2101.07312v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_T/0/1/0/all/0/1">Tobias Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Limmer_B/0/1/0/all/0/1">Benedikt Limmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Andre_E/0/1/0/all/0/1">Elisabeth Andr&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07312">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years saw a plethora of work on explaining complex intelligent agents.
One example is the development of several algorithms that generate saliency
maps which show how much each pixel attributed to the agents&#x27; decision.
However, most evaluations of such saliency maps focus on image classification
tasks. As far as we know, there is no work that thoroughly compares different
saliency maps for Deep Reinforcement Learning agents. This paper compares four
perturbation-based approaches to create saliency maps for Deep Reinforcement
Learning agents trained on four different Atari 2600 games. All four approaches
work by perturbing parts of the input and measuring how much this affects the
agent&#x27;s output. The approaches are compared using three computational metrics:
dependence on the learned parameters of the agent (sanity checks), faithfulness
to the agent&#x27;s reasoning (input degradation), and run-time. In particular,
during the sanity checks we find issues with two approaches and propose a
solution to fix one of those issues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust M-estimation-based Tensor Ring Completion: a Half-quadratic Minimization Approach. (arXiv:2106.10422v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yicong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Atia_G/0/1/0/all/0/1">George K. Atia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10422">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor completion is the problem of estimating the missing values of
high-order data from partially observed entries. Among several definitions of
tensor rank, tensor ring rank affords the flexibility and accuracy needed to
model tensors of different orders, which motivated recent efforts on
tensor-ring completion. However, data corruption due to prevailing outliers
poses major challenges to existing algorithms. In this paper, we develop a
robust approach to tensor ring completion that uses an M-estimator as its error
statistic, which can significantly alleviate the effect of outliers. Leveraging
a half-quadratic (HQ) method, we reformulate the problem as one of weighted
tensor completion. We present two HQ-based algorithms based on truncated
singular value decomposition and matrix factorization along with their
convergence and complexity analysis. Extendibility of the proposed approach to
alternative definitions of tensor rank is also discussed. The experimental
results demonstrate the superior performance of the proposed approach over
state-of-the-art robust algorithms for tensor completion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Animal ID Problem: Continual Curation. (arXiv:2106.10377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1">Charles V. Stewart</a>, <a href="http://arxiv.org/find/cs/1/au:+Parham_J/0/1/0/all/0/1">Jason R. Parham</a>, <a href="http://arxiv.org/find/cs/1/au:+Holmberg_J/0/1/0/all/0/1">Jason Holmberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1">Tanya Y. Berger-Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10377">
                                    <div class="article-summary-box-inner">
                                        <span>Hoping to stimulate new research in individual animal identification from
images, we propose to formulate the problem as the human-machine Continual
Curation of images and animal identities. This is an open world recognition
problem, where most new animals enter the system after its algorithms are
initially trained and deployed. Continual Curation, as defined here, requires
(1) an improvement in the effectiveness of current recognition methods, (2) a
pairwise verification algorithm that allows the possibility of no decision, and
(3) an algorithmic decision mechanism that seeks human input to guide the
curation process. Error metrics must evaluate the ability of recognition
algorithms to identify not only animals that have been seen just once or twice
but also recognize new animals not in the database. An important measure of
overall system performance is accuracy as a function of the amount of human
input required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rayleigh-Gauss-Newton optimization with enhanced sampling for variational Monte Carlo. (arXiv:2106.10558v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Webber_R/0/1/0/all/0/1">Robert J. Webber</a>, <a href="http://arxiv.org/find/stat/1/au:+Lindsey_M/0/1/0/all/0/1">Michael Lindsey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10558">
                                    <div class="article-summary-box-inner">
                                        <span>Variational Monte Carlo (VMC) is an approach for computing ground-state
wavefunctions that has recently become more powerful due to the introduction of
neural network-based wavefunction parametrizations. However, efficiently
training neural wavefunctions to converge to an energy minimum remains a
difficult problem. In this work, we analyze optimization and sampling methods
used in VMC and introduce alterations to improve their performance. First,
based on theoretical convergence analysis in a noiseless setting, we motivate a
new optimizer that we call the Rayleigh-Gauss-Newton method, which can improve
upon gradient descent and natural gradient descent to achieve superlinear
convergence. Second, in order to realize this favorable comparison in the
presence of stochastic noise, we analyze the effect of sampling error on VMC
parameter updates and experimentally demonstrate that it can be reduced by the
parallel tempering method. In particular, we demonstrate that RGN can be made
robust to energy spikes that occur when new regions of configuration space
become available to the sampler over the course of optimization. Finally,
putting theory into practice, we apply our enhanced optimization and sampling
methods to the transverse-field Ising and XXZ models on large lattices,
yielding ground-state energy estimates with remarkably high accuracy after just
200-500 parameter updates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiffMG: Differentiable Meta Graph Search for Heterogeneous Graph Neural Networks. (arXiv:2010.03250v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuhui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Huan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03250">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel framework to automatically utilize
task-dependent semantic information which is encoded in heterogeneous
information networks (HINs). Specifically, we search for a meta graph, which
can capture more complex semantic relations than a meta path, to determine how
graph neural networks (GNNs) propagate messages along different types of edges.
We formalize the problem within the framework of neural architecture search
(NAS) and then perform the search in a differentiable manner. We design an
expressive search space in the form of a directed acyclic graph (DAG) to
represent candidate meta graphs for a HIN, and we propose task-dependent type
constraint to filter out those edge types along which message passing has no
effect on the representations of nodes that are related to the downstream task.
The size of the search space we define is huge, so we further propose a novel
and efficient search algorithm to make the total search cost on a par with
training a single GNN once. Compared with existing popular NAS algorithms, our
proposed search algorithm improves the search efficiency. We conduct extensive
experiments on different HINs and downstream tasks to evaluate our method, and
experimental results show that our method can outperform state-of-the-art
heterogeneous GNNs and also improves efficiency compared with those methods
which can implicitly learn meta paths.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Generative Learning via Schr\&quot;{o}dinger Bridge. (arXiv:2106.10410v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gefei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Can Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10410">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to learn a generative model via entropy interpolation with a
Schr\&quot;{o}dinger Bridge. The generative learning task can be formulated as
interpolating between a reference distribution and a target distribution based
on the Kullback-Leibler divergence. At the population level, this entropy
interpolation is characterized via an SDE on $[0,1]$ with a time-varying drift
term. At the sample level, we derive our Schr\&quot;{o}dinger Bridge algorithm by
plugging the drift term estimated by a deep score estimator and a deep density
ratio estimator into the Euler-Maruyama method. Under some mild smoothness
assumptions of the target distribution, we prove the consistency of both the
score estimator and the density ratio estimator, and then establish the
consistency of the proposed Schr\&quot;{o}dinger Bridge approach. Our theoretical
results guarantee that the distribution learned by our approach converges to
the target distribution. Experimental results on multimodal synthetic data and
benchmark data support our theoretical findings and indicate that the
generative model via Schr\&quot;{o}dinger Bridge is comparable with state-of-the-art
GANs, suggesting a new formulation of generative learning. We demonstrate its
usefulness in image interpolation and image inpainting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Model Adversarial Training for Deep Compressed Sensing. (arXiv:2106.10696v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Esmaeili_A/0/1/0/all/0/1">Ashkan Esmaeili</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10696">
                                    <div class="article-summary-box-inner">
                                        <span>Deep compressed sensing assumes the data has sparse representation in a
latent space, i.e., it is intrinsically of low-dimension. The original data is
assumed to be mapped from a low-dimensional space through a
low-to-high-dimensional generator. In this work, we propound how to design such
a low-to-high dimensional deep learning-based generator suiting for compressed
sensing, while satisfying robustness to universal adversarial perturbations in
the latent domain. We also justify why the noise is considered in the latent
space. The work is also buttressed with theoretical analysis on the robustness
of the trained generator to adversarial perturbations. Experiments on
real-world datasets are provided to substantiate the efficacy of the proposed
\emph{generative model adversarial training for deep compressed sensing.}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning and Generalization in Overparameterized Normalizing Flows. (arXiv:2106.10535v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_K/0/1/0/all/0/1">Kulin Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amit Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1">Navin Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10535">
                                    <div class="article-summary-box-inner">
                                        <span>In supervised learning, it is known that overparameterized neural networks
with one hidden layer provably and efficiently learn and generalize, when
trained using stochastic gradient descent with sufficiently small learning rate
and suitable initialization. In contrast, the benefit of overparameterization
in unsupervised learning is not well understood. Normalizing flows (NFs)
constitute an important class of models in unsupervised learning for sampling
and density estimation. In this paper, we theoretically and empirically analyze
these models when the underlying neural network is one-hidden-layer
overparameterized network. Our main contributions are two-fold: (1) On the one
hand, we provide theoretical and empirical evidence that for a class of NFs
containing most of the existing NF models, overparametrization hurts training.
(2) On the other hand, we prove that unconstrained NFs, a recently introduced
model, can efficiently learn any reasonable data distribution under minimal
assumptions when the underlying network is overparametrized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid approach to detecting symptoms of depression in social media entries. (arXiv:2106.10485v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolk_A/0/1/0/all/0/1">Agnieszka Wo&#x142;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Chlasta_K/0/1/0/all/0/1">Karol Chlasta</a>, <a href="http://arxiv.org/find/cs/1/au:+Holas_P/0/1/0/all/0/1">Pawe&#x142; Holas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10485">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment and lexical analyses are widely used to detect depression or
anxiety disorders. It has been documented that there are significant
differences in the language used by a person with emotional disorders in
comparison to a healthy individual. Still, the effectiveness of these lexical
approaches could be improved further because the current analysis focuses on
what the social media entries are about, and not how they are written. In this
study, we focus on aspects in which these short texts are similar to each
other, and how they were created. We present an innovative approach to the
depression screening problem by applying Collgram analysis, which is a known
effective method of obtaining linguistic information from texts. We compare
these results with sentiment analysis based on the BERT architecture. Finally,
we create a hybrid model achieving a diagnostic accuracy of 71%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trainable Class Prototypes for Few-Shot Learning. (arXiv:2106.10846v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guizhong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10846">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning is a widely used method for few shot learning in which the
quality of prototypes plays a key role in the algorithm. In this paper we
propose the trainable prototypes for distance measure instead of the artificial
ones within the meta-training and task-training framework. Also to avoid the
disadvantages that the episodic meta-training brought, we adopt non-episodic
meta-training based on self-supervised learning. Overall we solve the few-shot
tasks in two phases: meta-training a transferable feature extractor via
self-supervised learning and training the prototypes for metric classification.
In addition, the simple attention mechanism is used in both meta-training and
task-training. Our method achieves state-of-the-art performance in a variety of
established few-shot tasks on the standard few-shot visual classification
dataset, with about 20% increase compared to the available unsupervised
few-shot learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory Augmented Optimizers for Deep Learning. (arXiv:2106.10708v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McRae_P/0/1/0/all/0/1">Paul-Aymeric McRae</a>, <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Assran_M/0/1/0/all/0/1">Mahmoud Assran</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10708">
                                    <div class="article-summary-box-inner">
                                        <span>Popular approaches for minimizing loss in data-driven learning often involve
an abstraction or an explicit retention of the history of gradients for
efficient parameter updates. The aggregated history of gradients nudges the
parameter updates in the right direction even when the gradients at any given
step are not informative. Although the history of gradients summarized in
meta-parameters or explicitly stored in memory has been shown effective in
theory and practice, the question of whether $all$ or only a subset of the
gradients in the history are sufficient in deciding the parameter updates
remains unanswered. In this paper, we propose a framework of memory-augmented
gradient descent optimizers that retain a limited view of their gradient
history in their internal memory. Such optimizers scale well to large real-life
datasets, and our experiments show that the memory augmented extensions of
standard optimizers enjoy accelerated convergence and improved performance on a
majority of computer vision and language tasks that we considered.
Additionally, we prove that the proposed class of optimizers with fixed-size
memory converge under assumptions of strong convexity, regardless of which
gradients are selected or how they are linearly combined to form the update
step.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TD-GEN: Graph Generation With Tree Decomposition. (arXiv:2106.10656v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shirzad_H/0/1/0/all/0/1">Hamed Shirzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajimirsadeghi_H/0/1/0/all/0/1">Hossein Hajimirsadeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdi_A/0/1/0/all/0/1">Amir H. Abdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mori_G/0/1/0/all/0/1">Greg Mori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10656">
                                    <div class="article-summary-box-inner">
                                        <span>We propose TD-GEN, a graph generation framework based on tree decomposition,
and introduce a reduced upper bound on the maximum number of decisions needed
for graph generation. The framework includes a permutation invariant tree
generation model which forms the backbone of graph generation. Tree nodes are
supernodes, each representing a cluster of nodes in the graph. Graph nodes and
edges are incrementally generated inside the clusters by traversing the tree
supernodes, respecting the structure of the tree decomposition, and following
node sharing decisions between the clusters. Finally, we discuss the
shortcomings of standard evaluation criteria based on statistical properties of
the generated graphs as performance measures. We propose to compare the
performance of models based on likelihood. Empirical results on a variety of
standard graph generation datasets demonstrate the superior performance of our
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerated Policy Evaluation: Learning Adversarial Environments with Adaptive Importance Sampling. (arXiv:2106.10566v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengdi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Peide Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fengpei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiacheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xuewei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oguchi_K/0/1/0/all/0/1">Kentaro Oguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1">Henry Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10566">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of rare but high-stakes events remains one of the main
difficulties in obtaining reliable policies from intelligent agents, especially
in large or continuous state/action spaces where limited scalability enforces
the use of a prohibitively large number of testing iterations. On the other
hand, a biased or inaccurate policy evaluation in a safety-critical system
could potentially cause unexpected catastrophic failures during deployment. In
this paper, we propose the Accelerated Policy Evaluation (APE) method, which
simultaneously uncovers rare events and estimates the rare event probability in
Markov decision processes. The APE method treats the environment nature as an
adversarial agent and learns towards, through adaptive importance sampling, the
zero-variance sampling distribution for the policy evaluation. Moreover, APE is
scalable to large discrete or continuous spaces by incorporating function
approximators. We investigate the convergence properties of proposed algorithms
under suitable regularity conditions. Our empirical studies show that APE
estimates rare event probability with a smaller variance while only using
orders of magnitude fewer samples compared to baseline methods in both
multi-agent and single-agent environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attack to Fool and Explain Deep Networks. (arXiv:2106.10606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalwana_M/0/1/0/all/0/1">Muhammad A. A. K. Jalwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep visual models are susceptible to adversarial perturbations to inputs.
Although these signals are carefully crafted, they still appear noise-like
patterns to humans. This observation has led to the argument that deep visual
representation is misaligned with human perception. We counter-argue by
providing evidence of human-meaningful patterns in adversarial perturbations.
We first propose an attack that fools a network to confuse a whole category of
objects (source class) with a target label. Our attack also limits the
unintended fooling by samples from non-sources classes, thereby circumscribing
human-defined semantic notions for network fooling. We show that the proposed
attack not only leads to the emergence of regular geometric patterns in the
perturbations, but also reveals insightful information about the decision
boundaries of deep models. Exploring this phenomenon further, we alter the
&#x60;adversarial&#x27; objective of our attack to use it as a tool to &#x60;explain&#x27; deep
visual representation. We show that by careful channeling and projection of the
perturbations computed by our method, we can visualize a model&#x27;s understanding
of human-defined semantic notions. Finally, we exploit the explanability
properties of our perturbations to perform image generation, inpainting and
interactive image manipulation by attacking adversarialy robust
&#x60;classifiers&#x27;.In all, our major contribution is a novel pragmatic adversarial
attack that is subsequently transformed into a tool to interpret the visual
models. The article also makes secondary contributions in terms of establishing
the utility of our attack beyond the adversarial objective with multiple
interesting applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TinyML: Analysis of Xtensa LX6 microprocessor for Neural Network Applications by ESP32 SoC. (arXiv:2106.10652v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zim_M/0/1/0/all/0/1">Md Ziaul Haque Zim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10652">
                                    <div class="article-summary-box-inner">
                                        <span>In recent decades, Machine Learning (ML) has become extremely important for
many computing applications. The pervasiveness of ultra-low-power embedded
devices such as ESP32 or ESP32 Cam with tiny Machine Learning (tinyML)
applications will enable the mass proliferation of Artificial Intelligent
powered Embedded IoT Devices. In the last few years, the microcontroller device
(Espressif ESP32) became powerful enough to be used for small/tiny machine
learning (tinyML) tasks. The ease of use of platforms like Arduino IDE,
MicroPython and TensorFlow Lite (TF) with tinyML application make it an
indispensable topic of research for mobile robotics, modern computer science
and electrical engineering. The goal of this paper is to analyze the speed of
the Xtensa dual core 32-bit LX6 microprocessor by running a neural network
application. The different number of inputs (9, 36, 144 and 576) inputted
through the different number of neurons in neural networks with one and two
hidden layers. Xtensa LX6 microprocessor has been analyzed because it comes
inside with Espressif ESP32 and ESP32 Cam which are very easy to use, plug and
play IoT device. In this paper speed of the Xtensa LX6 microprocessor in
feed-forward mode has been analyzed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algorithm Unrolling for Massive Access via Deep Neural Network with Theoretical Guarantee. (arXiv:2106.10426v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yandong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hayoung Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuanming Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yong Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10426">
                                    <div class="article-summary-box-inner">
                                        <span>Massive access is a critical design challenge of Internet of Things (IoT)
networks. In this paper, we consider the grant-free uplink transmission of an
IoT network with a multiple-antenna base station (BS) and a large number of
single-antenna IoT devices. Taking into account the sporadic nature of IoT
devices, we formulate the joint activity detection and channel estimation
(JADCE) problem as a group-sparse matrix estimation problem. This problem can
be solved by applying the existing compressed sensing techniques, which however
either suffer from high computational complexities or lack of algorithm
robustness. To this end, we propose a novel algorithm unrolling framework based
on the deep neural network to simultaneously achieve low computational
complexity and high robustness for solving the JADCE problem. Specifically, we
map the original iterative shrinkage thresholding algorithm (ISTA) into an
unrolled recurrent neural network (RNN), thereby improving the convergence rate
and computational efficiency through end-to-end training. Moreover, the
proposed algorithm unrolling approach inherits the structure and domain
knowledge of the ISTA, thereby maintaining the algorithm robustness, which can
handle non-Gaussian preamble sequence matrix in massive access. With rigorous
theoretical analysis, we further simplify the unrolled network structure by
reducing the redundant training parameters. Furthermore, we prove that the
simplified unrolled deep neural network structures enjoy a linear convergence
rate. Extensive simulations based on various preamble signatures show that the
proposed unrolled networks outperform the existing methods in terms of the
convergence rate, robustness and estimation accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural network interpretability for forecasting of aggregated renewable generatiion. (arXiv:2106.10476v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yucun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Murzakhanov_I/0/1/0/all/0/1">Ilgiz Murzakhanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1">Spyros Chatzivasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10476">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of renewable energy, lots of small photovoltaic (PV)
prosumers emerge. Due to the uncertainty of solar power generation, there is a
need for aggregated prosumers to predict solar power generation and whether
solar power generation will be larger than load. This paper presents two
interpretable neural networks to solve the problem: one binary classification
neural network and one regression neural network. The neural networks are built
using TensorFlow. The global feature importance and local feature contributions
are examined by three gradient-based methods: Integrated Gradients, Expected
Gradients, and DeepLIFT. Moreover, we detect abnormal cases when predictions
might fail by estimating the prediction uncertainty using Bayesian neural
networks. Neural networks, which are interpreted by gradient-based methods and
complemented with uncertainty estimation, provide robust and explainable
forecasting for decision-makers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Offline Reinforcement Learning with Residual Generative Modeling. (arXiv:2106.10411v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hua Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1">Deheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Bo Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhenhui/0/1/0/all/0/1">Zhenhui</a> (Jessie)Li
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10411">
                                    <div class="article-summary-box-inner">
                                        <span>Offline reinforcement learning (RL) tries to learn the near-optimal policy
with recorded offline experience without online exploration. Current offline RL
research includes: 1) generative modeling, i.e., approximating a policy using
fixed data; and 2) learning the state-action value function. While most
research focuses on the state-action function part through reducing the
bootstrapping error in value function approximation induced by the distribution
shift of training data, the effects of error propagation in generative modeling
have been neglected. In this paper, we analyze the error in generative
modeling. We propose AQL (action-conditioned Q-learning), a residual generative
model to reduce policy approximation error for offline RL. We show that our
method can learn more accurate policy approximations in different benchmark
datasets. In addition, we show that the proposed offline RL method can learn
more competitive AI agents in complex control tasks under the multiplayer
online battle arena (MOBA) game Honor of Kings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Particle Filtering without Modifying the Forward Pass. (arXiv:2106.10314v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Scibior_A/0/1/0/all/0/1">Adam &#x15a;cibior</a>, <a href="http://arxiv.org/find/stat/1/au:+Masrani_V/0/1/0/all/0/1">Vaden Masrani</a>, <a href="http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10314">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years particle filters have being used as components in systems
optimized end-to-end with gradient descent. However, the resampling step in a
particle filter is not differentiable, which biases gradients and interferes
with optimization. To remedy this problem, several differentiable variants of
resampling have been proposed, all of which modify the behavior of the particle
filter in significant and potentially undesirable ways. In this paper, we show
how to obtain unbiased estimators of the gradient of the marginal likelihood by
only modifying messages used in backpropagation, leaving the standard forward
pass of a particle filter unchanged. Our method is simple to implement, has a
low computational overhead, does not introduce additional hyperparameters, and
extends to derivatives of higher orders. We call it stop-gradient resampling,
since it can easily be implemented with automatic differentiation libraries
using the stop-gradient operator instead of explicitly modifying the backward
messages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Review on Non-Neural Networks Collaborative Filtering Recommendation Systems. (arXiv:2106.10679v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wenga_C/0/1/0/all/0/1">Carmel Wenga</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Fansi_M/0/1/0/all/0/1">Majirus Fansi</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Chabrier_S/0/1/0/all/0/1">S&#xe9;bastien Chabrier</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Mari_J/0/1/0/all/0/1">Jean-Martial Mari</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gabillon_A/0/1/0/all/0/1">Alban Gabillon</a> (1) ((1) University of French Polynesia, (2) NzhinuSoft)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10679">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past two decades, recommender systems have attracted a lot of
interest due to the explosion in the amount of data in online applications. A
particular attention has been paid to collaborative filtering, which is the
most widely used in applications that involve information recommendations.
Collaborative filtering (CF) uses the known preference of a group of users to
make predictions and recommendations about the unknown preferences of other
users (recommendations are made based on the past behavior of users). First
introduced in the 1990s, a wide variety of increasingly successful models have
been proposed. Due to the success of machine learning techniques in many areas,
there has been a growing emphasis on the application of such algorithms in
recommendation systems. In this article, we present an overview of the CF
approaches for recommender systems, their two main categories, and their
evaluation metrics. We focus on the application of classical Machine Learning
algorithms to CF recommender systems by presenting their evolution from their
first use-cases to advanced Machine Learning models. We attempt to provide a
comprehensive and comparative overview of CF systems (with python
implementations) that can serve as a guideline for research and practice in
this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Assessment of Generalization Performance Robustness for Deep Networks via Contrastive Examples. (arXiv:2106.10653v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xuanyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10653">
                                    <div class="article-summary-box-inner">
                                        <span>Training images with data transformations have been suggested as contrastive
examples to complement the testing set for generalization performance
evaluation of deep neural networks (DNNs). In this work, we propose a practical
framework ContRE (The word &quot;contre&quot; means &quot;against&quot; or &quot;versus&quot; in French.)
that uses Contrastive examples for DNN geneRalization performance Estimation.
Specifically, ContRE follows the assumption in contrastive learning that robust
DNN models with good generalization performance are capable of extracting a
consistent set of features and making consistent predictions from the same
image under varying data transformations. Incorporating with a set of
randomized strategies for well-designed data transformations over the training
set, ContRE adopts classification errors and Fisher ratios on the generated
contrastive examples to assess and analyze the generalization performance of
deep models in complement with a testing set. To show the effectiveness and the
efficiency of ContRE, extensive experiments have been done using various DNN
models on three open source benchmark datasets with thorough ablation studies
and applicability analyses. Our experiment results confirm that (1) behaviors
of deep models on contrastive examples are strongly correlated to what on the
testing set, and (2) ContRE is a robust measure of generalization performance
complementing to the testing set in various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter Optimization. (arXiv:2106.10575v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1">Ondrej Bohdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Timothy Hospedales</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10575">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient-based meta-learning and hyperparameter optimization have seen
significant progress recently, enabling practical end-to-end training of neural
networks together with many hyperparameters. Nevertheless, existing approaches
are relatively expensive as they need to compute second-order derivatives and
store a longer computational graph. This cost prevents scaling them to larger
network architectures. We present EvoGrad, a new approach to meta-learning that
draws upon evolutionary techniques to more efficiently compute hypergradients.
EvoGrad estimates hypergradient with respect to hyperparameters without
calculating second-order gradients, or storing a longer computational graph,
leading to significant improvements in efficiency. We evaluate EvoGrad on two
substantial recent meta-learning applications, namely cross-domain few-shot
learning with feature-wise transformations and noisy label learning with
MetaWeightNet. The results show that EvoGrad significantly improves efficiency
and enables scaling meta-learning to bigger CNN architectures such as from
ResNet18 to ResNet34.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-rank Characteristic Tensor Density Estimation Part II: Compression and Latent Density Estimation. (arXiv:2106.10591v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Amiridi_M/0/1/0/all/0/1">Magda Amiridi</a>, <a href="http://arxiv.org/find/stat/1/au:+Kargas_N/0/1/0/all/0/1">Nikos Kargas</a>, <a href="http://arxiv.org/find/stat/1/au:+Sidiropoulos_N/0/1/0/all/0/1">Nicholas D. Sidiropoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10591">
                                    <div class="article-summary-box-inner">
                                        <span>Learning generative probabilistic models is a core problem in machine
learning, which presents significant challenges due to the curse of
dimensionality. This paper proposes a joint dimensionality reduction and
non-parametric density estimation framework, using a novel estimator that can
explicitly capture the underlying distribution of appropriate reduced-dimension
representations of the input data. The idea is to jointly design a nonlinear
dimensionality reducing auto-encoder to model the training data in terms of a
parsimonious set of latent random variables, and learn a canonical low-rank
tensor model of the joint distribution of the latent variables in the Fourier
domain. The proposed latent density model is non-parametric and universal, as
opposed to the predefined prior that is assumed in variational auto-encoders.
Joint optimization of the auto-encoder and the latent density estimator is
pursued via a formulation which learns both by minimizing a combination of the
negative log-likelihood in the latent domain and the auto-encoder
reconstruction loss. We demonstrate that the proposed model achieves very
promising results on toy, tabular, and image datasets on regression tasks,
sampling, and anomaly detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the benefits of maximum likelihood estimation for Regression and Forecasting. (arXiv:2106.10370v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Awasthi_P/0/1/0/all/0/1">Pranjal Awasthi</a>, <a href="http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1">Abhimanyu Das</a>, <a href="http://arxiv.org/find/stat/1/au:+Sen_R/0/1/0/all/0/1">Rajat Sen</a>, <a href="http://arxiv.org/find/stat/1/au:+Suresh_A/0/1/0/all/0/1">Ananda Theertha Suresh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10370">
                                    <div class="article-summary-box-inner">
                                        <span>We advocate for a practical Maximum Likelihood Estimation (MLE) approach for
regression and forecasting, as an alternative to the typical approach of
Empirical Risk Minimization (ERM) for a specific target metric. This approach
is better suited to capture inductive biases such as prior domain knowledge in
datasets, and can output post-hoc estimators at inference time that can
optimize different types of target metrics. We present theoretical results to
demonstrate that our approach is always competitive with any estimator for the
target metric under some general conditions, and in many practical settings
(such as Poisson Regression) can actually be much superior to ERM. We
demonstrate empirically that our method instantiated with a well-designed
general purpose mixture likelihood family can obtain superior performance over
ERM for a variety of tasks across time-series forecasting and regression
datasets with different data distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified View of Algorithms for Path Planning Using Probabilistic Inference on Factor Graphs. (arXiv:2106.10442v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palmieri_F/0/1/0/all/0/1">Francesco A.N. Palmieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pattipati_K/0/1/0/all/0/1">Krishna R. Pattipati</a>, <a href="http://arxiv.org/find/cs/1/au:+Gennaro_G/0/1/0/all/0/1">Giovanni Di Gennaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Fioretti_G/0/1/0/all/0/1">Giovanni Fioretti</a>, <a href="http://arxiv.org/find/cs/1/au:+Verolla_F/0/1/0/all/0/1">Francesco Verolla</a>, <a href="http://arxiv.org/find/cs/1/au:+Buonanno_A/0/1/0/all/0/1">Amedeo Buonanno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10442">
                                    <div class="article-summary-box-inner">
                                        <span>Even if path planning can be solved using standard techniques from dynamic
programming and control, the problem can also be approached using probabilistic
inference. The algorithms that emerge using the latter framework bear some
appealing characteristics that qualify the probabilistic approach as a powerful
alternative to the more traditional control formulations. The idea of using
estimation on stochastic models to solve control problems is not new and the
inference approach considered here falls under the rubric of Active Inference
(AI) and Control as Inference (CAI). In this work, we look at the specific
recursions that arise from various cost functions that, although they may
appear similar in scope, bear noticeable differences, at least when applied to
typical path planning problems. We start by posing the path planning problem on
a probabilistic factor graph, and show how the various algorithms translate
into specific message composition rules. We then show how this unified
approach, presented both in probability space and in log space, provides a very
general framework that includes the Sum-product, the Max-product, Dynamic
programming and mixed Reward/Entropy criteria-based algorithms. The framework
also expands algorithmic design options for smoother or sharper policy
distributions, including generalized Sum/Max-product algorithm, a Smooth
Dynamic programming algorithm and modified versions of the Reward/Entropy
recursions. We provide a comprehensive table of recursions and a comparison
through simulations, first on a synthetic small grid with a single goal with
obstacles, and then on a grid extrapolated from a real-world scene with
multiple goals and a semantic map.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signal Processing Based Deep Learning for Blind Symbol Decoding and Modulation Classification. (arXiv:2106.10543v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hanna_S/0/1/0/all/0/1">Samer Hanna</a>, <a href="http://arxiv.org/find/eess/1/au:+Dick_C/0/1/0/all/0/1">Chris Dick</a>, <a href="http://arxiv.org/find/eess/1/au:+Cabric_D/0/1/0/all/0/1">Danijela Cabric</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10543">
                                    <div class="article-summary-box-inner">
                                        <span>Blindly decoding a signal requires estimating its unknown transmit
parameters, compensating for the wireless channel impairments, and identifying
the modulation type. While deep learning can solve complex problems, digital
signal processing (DSP) is interpretable and can be more computationally
efficient. To combine both, we propose the dual path network (DPN). It consists
of a signal path of DSP operations that recover the signal, and a feature path
of neural networks that estimate the unknown transmit parameters. By
interconnecting the paths over several recovery stages, later stages benefit
from the recovered signals and reuse all the previously extracted features. The
proposed design is demonstrated to provide 5% improvement in modulation
classification compared to alternative designs lacking either feature sharing
or access to recovered signals. The estimation results of DPN along with its
blind decoding performance are shown to outperform a blind signal processing
algorithm for BPSK and QPSK on a simulated dataset. An over-the-air
software-defined-radio capture was used to verify DPN results at high SNRs. DPN
design can process variable length inputs and is shown to outperform relying on
fixed length inputs with prediction averaging on longer signals by up to 15% in
modulation classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Max-Min Entropy Framework for Reinforcement Learning. (arXiv:2106.10517v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Seungyul Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Youngchul Sung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10517">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a max-min entropy framework for reinforcement
learning (RL) to overcome the limitation of the maximum entropy RL framework in
model-free sample-based learning. Whereas the maximum entropy RL framework
guides learning for policies to reach states with high entropy in the future,
the proposed max-min entropy framework aims to learn to visit states with low
entropy and maximize the entropy of these low-entropy states to promote
exploration. For general Markov decision processes (MDPs), an efficient
algorithm is constructed under the proposed max-min entropy framework based on
disentanglement of exploration and exploitation. Numerical results show that
the proposed algorithm yields drastic performance improvement over the current
state-of-the-art RL algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-to-many Approach for Improving Super-Resolution. (arXiv:2106.10437v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Sieun Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_E/0/1/0/all/0/1">Eunho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10437">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution (SR) is a one-to-many task with multiple possible solutions.
However, previous works were not concerned about this characteristic. For a
one-to-many pipeline, the generator should be able to generate multiple
estimates of the reconstruction, and not be penalized for generating similar
and equally realistic images. To achieve this, we propose adding weighted
pixel-wise noise after every Residual-in-Residual Dense Block (RRDB) to enable
the generator to generate various images. We modify the strict content loss to
not penalize the stochastic variation in reconstructed images as long as it has
consistent content. Additionally, we observe that there are out-of-focus
regions in the DIV2K, DIV8K datasets that provide unhelpful guidelines. We
filter blurry regions in the training data using the method of [10]. Finally,
we modify the discriminator to receive the low-resolution image as a reference
image along with the target image to provide better feedback to the generator.
Using our proposed methods, we were able to improve the performance of ESRGAN
in x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16
perceptual extreme SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Classifier as Mutual Information Evaluator. (arXiv:2106.10471v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10471">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-entropy loss with softmax output is a standard choice to train neural
network classifiers. We give a new view of neural network classifiers with
softmax and cross-entropy as mutual information evaluators. We show that when
the dataset is balanced, training a neural network with cross-entropy maximises
the mutual information between inputs and labels through a variational form of
mutual information. Thereby, we develop a new form of softmax that also
converts a classifier to a mutual information evaluator when the dataset is
imbalanced. Experimental results show that the new form leads to better
classification accuracy, in particular for imbalanced datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterogeneous Multi-task Learning with Expert Diversity. (arXiv:2106.10595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aoki_R/0/1/0/all/0/1">Raquel Aoki</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_F/0/1/0/all/0/1">Frederick Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_G/0/1/0/all/0/1">Gabriel L. Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10595">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting multiple heterogeneous biological and medical targets is a
challenge for traditional deep learning models. In contrast to single-task
learning, in which a separate model is trained for each target, multi-task
learning (MTL) optimizes a single model to predict multiple related targets
simultaneously. To address this challenge, we propose the Multi-gate
Mixture-of-Experts with Exclusivity (MMoEEx). Our work aims to tackle the
heterogeneous MTL setting, in which the same model optimizes multiple tasks
with different characteristics. Such a scenario can overwhelm current MTL
approaches due to the challenges in balancing shared and task-specific
representations and the need to optimize tasks with competing optimization
paths. Our method makes two key contributions: first, we introduce an approach
to induce more diversity among experts, thus creating representations more
suitable for highly imbalanced and heterogenous MTL learning; second, we adopt
a two-step optimization [6, 11] approach to balancing the tasks at the gradient
level. We validate our method on three MTL benchmark datasets, including
Medical Information Mart for Intensive Care (MIMIC-III) and PubChem BioAssay
(PCBA).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">STEM: A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal Sample and Communication Complexities for Federated Learning. (arXiv:2106.10435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khanduri_P/0/1/0/all/0/1">Prashant Khanduri</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Pranay Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Mingyi Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajawat_K/0/1/0/all/0/1">Ketan Rajawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Varshney_P/0/1/0/all/0/1">Pramod K. Varshney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10435">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) refers to the paradigm where multiple worker nodes
(WNs) build a joint model by using local data. Despite extensive research, for
a generic non-convex FL problem, it is not clear, how to choose the WNs&#x27; and
the server&#x27;s update directions, the minibatch sizes, and the local update
frequency, so that the WNs use the minimum number of samples and communication
rounds to achieve the desired solution. This work addresses the above question
and considers a class of stochastic algorithms where the WNs perform a few
local updates before communication. We show that when both the WN&#x27;s and the
server&#x27;s directions are chosen based on a stochastic momentum estimator, the
algorithm requires $\tilde{\mathcal{O}}(\epsilon^{-3/2})$ samples and
$\tilde{\mathcal{O}}(\epsilon^{-1})$ communication rounds to compute an
$\epsilon$-stationary solution. To the best of our knowledge, this is the first
FL algorithm that achieves such {\it near-optimal} sample and communication
complexities simultaneously. Further, we show that there is a trade-off curve
between local update frequencies and local minibatch sizes, on which the above
sample and communication complexities can be maintained. Finally, we show that
for the classical FedAvg (a.k.a. Local SGD, which is a momentum-less special
case of the STEM), a similar trade-off curve exists, albeit with worse sample
and communication complexities. Our insights on this trade-off provides
guidelines for choosing the four important design elements for FL algorithms,
the update frequency, directions, and minibatch sizes to achieve the best
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Transferability Estimation for Image Classification Tasks. (arXiv:2106.10479v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shao-Lun Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10479">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability estimation is an essential problem in transfer learning to
predict how good the performance is when transfer a source model (source task)
to a target task. Recent analytical transferability metrics have been widely
used for source model selection and multi-task learning. Earlier metrics does
not work sufficiently well under the challenging cross-domain cross-task
transfer settings, but recent OTCE score achieves a noteworthy performance
using auxiliary tasks. A simplified version named OT-based NCE score sacrifices
accuracy to be more efficient, but it can be further improved. Consequently, we
propose a practical transferability metric called JC-NCE score to further
improve the cross-domain cross-task transferability estimation performance,
which is more efficient than the OTCE score and more accurate than the OT-based
NCE score. Specifically, we build the joint correspondences between source and
target data via solving an optimal transport problem with considering both the
sample distance and label distance, and then compute the transferability score
as the negative conditional entropy. Extensive validations under the
intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE
score outperforms the OT-based NCE score with about 7% and 12% gains,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Preferences of Uncertain Humans with Inverse Decision Theory. (arXiv:2106.10394v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/stat/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10394">
                                    <div class="article-summary-box-inner">
                                        <span>Existing observational approaches for learning human preferences, such as
inverse reinforcement learning, usually make strong assumptions about the
observability of the human&#x27;s environment. However, in reality, people make many
important decisions under uncertainty. To better understand preference learning
in these cases, we study the setting of inverse decision theory (IDT), a
previously proposed framework where a human is observed making non-sequential
binary decisions under uncertainty. In IDT, the human&#x27;s preferences are
conveyed through their loss function, which expresses a tradeoff between
different types of mistakes. We give the first statistical analysis of IDT,
providing conditions necessary to identify these preferences and characterizing
the sample complexity -- the number of decisions that must be observed to learn
the tradeoff the human is making to a desired precision. Interestingly, we show
that it is actually easier to identify preferences when the decision problem is
more uncertain. Furthermore, uncertain decision problems allow us to relax the
unrealistic assumption that the human is an optimal decision maker but still
identify their exact preferences; we give sample complexities in this
suboptimal case as well. Our analysis contradicts the intuition that partial
observability should make preference learning more difficult. It also provides
a first step towards understanding and improving preference learning methods
for uncertain and suboptimal humans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task Attended Meta-Learning for Few-Shot Learning. (arXiv:2106.10642v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aimen_A/0/1/0/all/0/1">Aroof Aimen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidheekh_S/0/1/0/all/0/1">Sahil Sidheekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_N/0/1/0/all/0/1">Narayanan C. Krishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10642">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning (ML) has emerged as a promising direction in learning models
under constrained resource settings like few-shot learning. The popular
approaches for ML either learn a generalizable initial model or a generic
parametric optimizer through episodic training. The former approaches leverage
the knowledge from a batch of tasks to learn an optimal prior. In this work, we
study the importance of a batch for ML. Specifically, we first incorporate a
batch episodic training regimen to improve the learning of the generic
parametric optimizer. We also hypothesize that the common assumption in batch
episodic training that each task in a batch has an equal contribution to
learning an optimal meta-model need not be true. We propose to weight the tasks
in a batch according to their &quot;importance&quot; in improving the meta-model&#x27;s
learning. To this end, we introduce a training curriculum motivated by
selective focus in humans, called task attended meta-training, to weight the
tasks in a batch. Task attention is a standalone module that can be integrated
with any batch episodic training regimen. The comparisons of the models with
their non-task-attended counterparts on complex datasets like miniImageNet and
tieredImageNet validate its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score-Based Explanations in Data Management and Machine Learning: An Answer-Set Programming Approach to Counterfactual Analysis. (arXiv:2106.10562v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1">Leopoldo Bertossi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10562">
                                    <div class="article-summary-box-inner">
                                        <span>We describe some recent approaches to score-based explanations for query
answers in databases and outcomes from classification models in machine
learning. The focus is on work done by the author and collaborators. Special
emphasis is placed on declarative approaches based on answer-set programming to
the use of counterfactual reasoning for score specification and computation.
Several examples that illustrate the flexibility of these methods are shown.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Critical Nodes in Temporal Networks by Dynamic Graph Convolutional Networks. (arXiv:2106.10419v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1">En-Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun-Lin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hong-Liang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Duan-Bing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10419">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world systems can be expressed in temporal networks with nodes
playing far different roles in structure and function and edges representing
the relationships between nodes. Identifying critical nodes can help us control
the spread of public opinions or epidemics, predict leading figures in
academia, conduct advertisements for various commodities, and so on. However,
it is rather difficult to identify critical nodes because the network structure
changes over time in temporal networks. In this paper, considering the sequence
topological information of temporal networks, a novel and effective learning
framework based on the combination of special GCNs and RNNs is proposed to
identify nodes with the best spreading ability. The effectiveness of the
approach is evaluated by weighted Susceptible-Infected-Recovered model.
Experimental results on four real-world temporal networks demonstrate that the
proposed method outperforms both traditional and deep learning benchmark
methods in terms of the Kendall $\tau$ coefficient and top $k$ hit rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teacher&#x27;s pet: understanding and mitigating biases in distillation. (arXiv:2106.10494v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1">Michal Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1">Srinadh Bhojanapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Krishna Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10494">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation is widely used as a means of improving the performance
of a relatively simple student model using the predictions from a complex
teacher model. Several works have shown that distillation significantly boosts
the student&#x27;s overall performance; however, are these gains uniform across all
data subgroups? In this paper, we show that distillation can harm performance
on certain subgroups, e.g., classes with few associated samples. We trace this
behaviour to errors made by the teacher distribution being transferred to and
amplified by the student model. To mitigate this problem, we present techniques
which soften the teacher influence for subgroups where it is less reliable.
Experiments on several image classification benchmarks show that these
modifications of distillation maintain boost in overall accuracy, while
additionally ensuring improvement in subgroup performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stability of Graph Convolutional Neural Networks to Stochastic Perturbations. (arXiv:2106.10526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Isufi_E/0/1/0/all/0/1">Elvin Isufi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10526">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional neural networks (GCNNs) are nonlinear processing tools to
learn representations from network data. A key property of GCNNs is their
stability to graph perturbations. Current analysis considers deterministic
perturbations but fails to provide relevant insights when topological changes
are random. This paper investigates the stability of GCNNs to stochastic graph
perturbations induced by link losses. In particular, it proves the expected
output difference between the GCNN over random perturbed graphs and the GCNN
over the nominal graph is upper bounded by a factor that is linear in the link
loss probability. We perform the stability analysis in the graph spectral
domain such that the result holds uniformly for any graph. This result also
shows the role of the nonlinearity and the architecture width and depth, and
allows identifying handle to improve the GCNN robustness. Numerical simulations
on source localization and robot swarm control corroborate our theoretical
findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Perils of Learning Before Optimizing. (arXiv:2106.10349v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cameron_C/0/1/0/all/0/1">Chris Cameron</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartford_J/0/1/0/all/0/1">Jason Hartford</a>, <a href="http://arxiv.org/find/cs/1/au:+Lundy_T/0/1/0/all/0/1">Taylor Lundy</a>, <a href="http://arxiv.org/find/cs/1/au:+Leyton_Brown_K/0/1/0/all/0/1">Kevin Leyton-Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10349">
                                    <div class="article-summary-box-inner">
                                        <span>Formulating real-world optimization problems often begins with making
predictions from historical data (e.g., an optimizer that aims to recommend
fast routes relies upon travel-time predictions). Typically, learning the
prediction model used to generate the optimization problem and solving that
problem are performed in two separate stages. Recent work has showed how such
prediction models can be learned end-to-end by differentiating through the
optimization task. Such methods often yield empirical improvements, which are
typically attributed to end-to-end making better error tradeoffs than the
standard loss function used in a two-stage solution. We refine this explanation
and more precisely characterize when end-to-end can improve performance. When
prediction targets are stochastic, a two-stage solution must make an a priori
choice about which statistics of the target distribution to model -- we
consider expectations over prediction targets -- while an end-to-end solution
can make this choice adaptively. We show that the performance gap between a
two-stage and end-to-end approach is closely related to the \emph{price of
correlation} concept in stochastic optimization and show the implications of
some existing POC results for our predict-then-optimize problem. We then
consider a novel and particularly practical setting, where coefficients in the
objective function depend on multiple prediction targets. We give explicit
constructions where (1) two-stage performs unboundedly worse than end-to-end;
and (2) two-stage is optimal. We identify a large set of real-world
applications whose objective functions rely on multiple prediction targets but
which nevertheless deploy two-stage solutions. We also use simulations to
experimentally quantify performance gaps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Space Partitions for Path Planning. (arXiv:2106.10544v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kevin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummins_C/0/1/0/all/0/1">Chris Cummins</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Brandon Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_B/0/1/0/all/0/1">Benoit Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linnan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10544">
                                    <div class="article-summary-box-inner">
                                        <span>Path planning, the problem of efficiently discovering high-reward
trajectories, often requires optimizing a high-dimensional and multimodal
reward function. Popular approaches like CEM and CMA-ES greedily focus on
promising regions of the search space and may get trapped in local maxima. DOO
and VOOT balance exploration and exploitation, but use space partitioning
strategies independent of the reward function to be optimized. Recently, LaMCTS
empirically learns to partition the search space in a reward-sensitive manner
for black-box optimization. In this paper, we develop a novel formal regret
analysis for when and why such an adaptive region partitioning scheme works. We
also propose a new path planning method PlaLaM which improves the function
value estimation within each sub-region, and uses a latent representation of
the search space. Empirically, PlaLaM outperforms existing path planning
methods in 2D navigation tasks, especially in the presence of
difficult-to-escape local optima, and shows benefits when plugged into
model-based RL with planning components such as PETS. These gains transfer to
highly multimodal real-world tasks, where we outperform strong baselines in
compiler phase ordering by up to 245% and in molecular design by up to 0.4 on
properties on a 0-1 scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Neural Networks for Learning Real-Time Prices in Electricity Market. (arXiv:2106.10529v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaohui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chengyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10529">
                                    <div class="article-summary-box-inner">
                                        <span>Solving the optimal power flow (OPF) problem in real-time electricity market
improves the efficiency and reliability in the integration of low-carbon energy
resources into the power grids. To address the scalability and adaptivity
issues of existing end-to-end OPF learning solutions, we propose a new graph
neural network (GNN) framework for predicting the electricity market prices
from solving OPFs. The proposed GNN-for-OPF framework innovatively exploits the
locality property of prices and introduces physics-aware regularization, while
attaining reduced model complexity and fast adaptivity to varying grid
topology. Numerical tests have validated the learning efficiency and adaptivity
improvements of our proposed method over existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of the facial growth direction with Machine Learning methods. (arXiv:2106.10464v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazmierczak_S/0/1/0/all/0/1">Stanis&#x142;aw Ka&#x17a;mierczak</a>, <a href="http://arxiv.org/find/cs/1/au:+Juszka_Z/0/1/0/all/0/1">Zofia Juszka</a>, <a href="http://arxiv.org/find/cs/1/au:+Fudalej_P/0/1/0/all/0/1">Piotr Fudalej</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandziuk_J/0/1/0/all/0/1">Jacek Ma&#x144;dziuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10464">
                                    <div class="article-summary-box-inner">
                                        <span>First attempts of prediction of the facial growth (FG) direction were made
over half of a century ago. Despite numerous attempts and elapsed time, a
satisfactory method has not been established yet and the problem still poses a
challenge for medical experts. To our knowledge, this paper is the first
Machine Learning approach to the prediction of FG direction. Conducted data
analysis reveals the inherent complexity of the problem and explains the
reasons of difficulty in FG direction prediction based on 2D X-ray images. To
perform growth forecasting, we employ a wide range of algorithms, from logistic
regression, through tree ensembles to neural networks and consider three,
slightly different, problem formulations. The resulting classification accuracy
varies between 71% and 75%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Informative Class Activation Maps. (arXiv:2106.10472v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10472">
                                    <div class="article-summary-box-inner">
                                        <span>We study how to evaluate the quantitative information content of a region
within an image for a particular label. To this end, we bridge class activation
maps with information theory. We develop an informative class activation map
(infoCAM). Given a classification task, infoCAM depict how to accumulate
information of partial regions to that of the entire image toward a label.
Thus, we can utilise infoCAM to locate the most informative features for a
label. When applied to an image classification task, infoCAM performs better
than the traditional classification map in the weakly supervised object
localisation task. We achieve state-of-the-art results on Tiny-ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Timestamp-Level Representations for Time Series with Hierarchical Contrastive Loss. (arXiv:2106.10466v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zhihan Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Juanyong Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianmeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Congrui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bixiong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10466">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents TS2Vec, a universal framework for learning
timestamp-level representations of time series. Unlike existing methods, TS2Vec
performs timestamp-wise discrimination, which learns a contextual
representation vector directly for each timestamp. We find that the learned
representations have superior predictive ability. A linear regression trained
on top of the learned representations outperforms previous SOTAs for supervised
time series forecasting. Also, the instance-level representations can be simply
obtained by applying a max pooling layer on top of learned representations of
all timestamps. We conduct extensive experiments on time series classification
tasks to evaluate the quality of instance-level representations. As a result,
TS2Vec achieves significant improvement compared with existing SOTAs of
unsupervised time series representation on 125 UCR datasets and 29 UEA
datasets. The source code is publicly available at
https://github.com/yuezhihan/ts2vec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiffLoop: Tuning PID controllers by differentiating through the feedback loop. (arXiv:2106.10516v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Athindran Ramesh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramadge_P/0/1/0/all/0/1">Peter J. Ramadge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10516">
                                    <div class="article-summary-box-inner">
                                        <span>Since most industrial control applications use PID controllers, PID tuning
and anti-windup measures are significant problems. This paper investigates
tuning the feedback gains of a PID controller via back-calculation and
automatic differentiation tools. In particular, we episodically use a cost
function to generate gradients and perform gradient descent to improve
controller performance. We provide a theoretical framework for analyzing this
non-convex optimization and establish a relationship between back-calculation
and disturbance feedback policies. We include numerical experiments on linear
systems with actuator saturation to show the efficacy of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSN: Efficient Online Mask Selection Network for Video Instance Segmentation. (arXiv:2106.10452v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goel_V/0/1/0/all/0/1">Vidit Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Shubhika Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Maheshwari_H/0/1/0/all/0/1">Harsh Maheshwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10452">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a novel solution for Video Instance
Segmentation(VIS), that is automatically generating instance level segmentation
masks along with object class and tracking them in a video. Our method improves
the masks from segmentation and propagation branches in an online manner using
the Mask Selection Network (MSN) hence limiting the noise accumulation during
mask tracking. We propose an effective design of MSN by using patch-based
convolutional neural network. The network is able to distinguish between very
subtle differences between the masks and choose the better masks out of the
associated masks accurately. Further, we make use of temporal consistency and
process the video sequences in both forward and reverse manner as a post
processing step to recover lost objects. The proposed method can be used to
adapt any video object segmentation method for the task of VIS. Our method
achieves a score of 49.1 mAP on 2021 YouTube-VIS Challenge and was ranked third
place among more than 30 global teams. Our code will be available at
https://github.com/SHI-Labs/Mask-Selection-Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Compositional Generalization in Classification Tasks via Structure Annotations. (arXiv:2106.10434v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1">Joshua Ainslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10434">
                                    <div class="article-summary-box-inner">
                                        <span>Compositional generalization is the ability to generalize systematically to a
new data distribution by combining known components. Although humans seem to
have a great ability to generalize compositionally, state-of-the-art neural
models struggle to do so. In this work, we study compositional generalization
in classification tasks and present two main contributions. First, we study
ways to convert a natural language sequence-to-sequence dataset to a
classification dataset that also requires compositional generalization. Second,
we show that providing structural hints (specifically, providing parse trees
and entity links as attention masks for a Transformer model) helps
compositional generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel frequency function-deep neural network for efficient complex broadband signal approximation. (arXiv:2106.10401v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zeng_Z/0/1/0/all/0/1">Zhi Zeng</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_P/0/1/0/all/0/1">Pengpeng Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_F/0/1/0/all/0/1">Fulei Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Qi_P/0/1/0/all/0/1">Peihan Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10401">
                                    <div class="article-summary-box-inner">
                                        <span>A neural network is essentially a high-dimensional complex mapping model by
adjusting network weights for feature fitting. However, the spectral bias in
network training leads to unbearable training epochs for fitting the
high-frequency components in broadband signals. To improve the fitting
efficiency of high-frequency components, the PhaseDNN was proposed recently by
combining complex frequency band extraction and frequency shift techniques [Cai
et al. SIAM J. SCI. COMPUT. 42, A3285 (2020)]. Our paper is devoted to an
alternative candidate for fitting complex signals with high-frequency
components. Here, a parallel frequency function-deep neural network (PFF-DNN)
is proposed to suppress computational overhead while ensuring fitting accuracy
by utilizing fast Fourier analysis of broadband signals and the spectral bias
nature of neural networks. The effectiveness and efficiency of the proposed
PFF-DNN method are verified based on detailed numerical experiments for six
typical broadband signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Optimal Transport with Self-paced Ensemble for Cross-hospital Sepsis Early Detection. (arXiv:2106.10352v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Ruiqing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Q/0/1/0/all/0/1">Qiqiang Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">He Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanlin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Leye Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Man Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10352">
                                    <div class="article-summary-box-inner">
                                        <span>The utilization of computer technology to solve problems in medical scenarios
has attracted considerable attention in recent years, which still has great
potential and space for exploration. Among them, machine learning has been
widely used in the prediction, diagnosis and even treatment of Sepsis. However,
state-of-the-art methods require large amounts of labeled medical data for
supervised learning. In real-world applications, the lack of labeled data will
cause enormous obstacles if one hospital wants to deploy a new Sepsis detection
system. Different from the supervised learning setting, we need to use known
information (e.g., from another hospital with rich labeled data) to help build
a model with acceptable performance, i.e., transfer learning. In this paper, we
propose a semi-supervised optimal transport with self-paced ensemble framework
for Sepsis early detection, called SPSSOT, to transfer knowledge from the other
that has rich labeled data. In SPSSOT, we first extract the same clinical
indicators from the source domain (e.g., hospital with rich labeled data) and
the target domain (e.g., hospital with little labeled data), then we combine
the semi-supervised domain adaptation based on optimal transport theory with
self-paced under-sampling to avoid a negative transfer possibly caused by
covariate shift and class imbalance. On the whole, SPSSOT is an end-to-end
transfer learning method for Sepsis early detection which can automatically
select suitable samples from two domains respectively according to the number
of iterations and align feature space of two domains. Extensive experiments on
two open clinical datasets demonstrate that comparing with other methods, our
proposed SPSSOT, can significantly improve the AUC values with only 1% labeled
data in the target domain in two transfer learning scenarios, MIMIC
$rightarrow$ Challenge and Challenge $rightarrow$ MIMIC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Task Learning for User Engagement and Adoption in Live Video Streaming Events. (arXiv:2106.10305v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antaris_S/0/1/0/all/0/1">Stefanos Antaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafailidis_D/0/1/0/all/0/1">Dimitrios Rafailidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Arriaza_R/0/1/0/all/0/1">Romina Arriaza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10305">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, live video streaming events have become a mainstay in viewer&#x27;s
communication in large international enterprises. Provided that viewers are
distributed worldwide, the main challenge resides on how to schedule the
optimal event&#x27;s time so as to improve both the viewer&#x27;s engagement and
adoption. In this paper we present a multi-task deep reinforcement learning
model to select the time of a live video streaming event, aiming to optimize
the viewer&#x27;s engagement and adoption at the same time. We consider the
engagement and adoption of the viewers as independent tasks and formulate a
unified loss function to learn a common policy. In addition, we account for the
fact that each task might have different contribution to the training strategy
of the agent. Therefore, to determine the contribution of each task to the
agent&#x27;s training, we design a Transformer&#x27;s architecture for the state-action
transitions of each task. We evaluate our proposed model on four real-world
datasets, generated by the live video streaming events of four large
enterprises spanning from January 2019 until March 2021. Our experiments
demonstrate the effectiveness of the proposed model when compared with several
state-of-the-art strategies. For reproduction purposes, our evaluation datasets
and implementation are publicly available at
https://github.com/stefanosantaris/merlin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OLIVAW: Mastering Othello with neither Humans nor a Penny. (arXiv:2103.17228v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Norelli_A/0/1/0/all/0/1">Antonio Norelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Panconesi_A/0/1/0/all/0/1">Alessandro Panconesi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17228">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce OLIVAW, an AI Othello player adopting the design principles of
the famous AlphaGo series. The main motivation behind OLIVAW was to attain
exceptional competence in a non-trivial board game at a tiny fraction of the
cost of its illustrious predecessors. In this paper, we show how the AlphaGo
Zero&#x27;s paradigm can be successfully applied to the popular game of Othello
using only commodity hardware and free cloud services. While being simpler than
Chess or Go, Othello maintains a considerable search space and difficulty in
evaluating board positions. To achieve this result, OLIVAW implements some
improvements inspired by recent works to accelerate the standard AlphaGo Zero
learning process. The main modification implies doubling the positions
collected per game during the training phase, by including also positions not
played but largely explored by the agent. We tested the strength of OLIVAW in
three different ways: by pitting it against Edax, the strongest open-source
Othello engine, by playing anonymous games on the web platform OthelloQuest,
and finally in two in-person matches against top-notch human players: a
national champion and a former world champion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias. (arXiv:2101.07296v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stojanov_S/0/1/0/all/0/1">Stefan Stojanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Thai_A/0/1/0/all/0/1">Anh Thai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1">James M. Rehg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07296">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely accepted that reasoning about object shape is important for
object recognition. However, the most powerful object recognition methods today
do not explicitly make use of object shape during learning. In this work,
motivated by recent developments in low-shot learning, findings in
developmental psychology, and the increased use of synthetic data in computer
vision research, we investigate how reasoning about 3D shape can be used to
improve low-shot learning methods&#x27; generalization performance. We propose a new
way to improve existing low-shot learning approaches by learning a
discriminative embedding space using 3D object shape, and using this embedding
by learning how to map images into it. Our new approach improves the
performance of image-only low-shot learning approaches on multiple datasets. We
also introduce Toys4K, a 3D object dataset with the largest number of object
categories currently available, which supports low-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Dialog Systems for Negotiation with Personality Modeling. (arXiv:2010.09954v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Runzhe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1">Karthik Narasimhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09954">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the ability to model and infer personality types of
opponents, predict their responses, and use this information to adapt a dialog
agent&#x27;s high-level strategy in negotiation tasks. Inspired by the idea of
incorporating a theory of mind (ToM) into machines, we introduce a
probabilistic formulation to encapsulate the opponent&#x27;s personality type during
both learning and inference. We test our approach on the CraigslistBargain
dataset and show that our method using ToM inference achieves a 20% higher
dialog agreement rate compared to baselines on a mixed population of opponents.
We also find that our model displays diverse negotiation behavior with
different types of opponents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Pilot Study on Visually Stimulated Cognitive Tasks for EEG-Based Dementia Recognition. (arXiv:2103.03854v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kongwudhikunakorn_S/0/1/0/all/0/1">Supavit Kongwudhikunakorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiatthaveephong_S/0/1/0/all/0/1">Suktipol Kiatthaveephong</a>, <a href="http://arxiv.org/find/cs/1/au:+Thanontip_K/0/1/0/all/0/1">Kamonwan Thanontip</a>, <a href="http://arxiv.org/find/cs/1/au:+Leelaarporn_P/0/1/0/all/0/1">Pitshaporn Leelaarporn</a>, <a href="http://arxiv.org/find/cs/1/au:+Piriyajitakonkij_M/0/1/0/all/0/1">Maytus Piriyajitakonkij</a>, <a href="http://arxiv.org/find/cs/1/au:+Charoenpattarawut_T/0/1/0/all/0/1">Thananya Charoenpattarawut</a>, <a href="http://arxiv.org/find/cs/1/au:+Autthasan_P/0/1/0/all/0/1">Phairot Autthasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaisaen_R/0/1/0/all/0/1">Rattanaphon Chaisaen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dujada_P/0/1/0/all/0/1">Pathitta Dujada</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1">Thapanun Sudhawiyangkul</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Senanarong_V/0/1/0/all/0/1">Vorapun Senanarong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1">Theerawit Wilaiprasitporn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03854">
                                    <div class="article-summary-box-inner">
                                        <span>In the status quo, dementia is yet to be cured. Precise diagnosis prior to
the onset of the symptoms can prevent the rapid progression of the emerging
cognitive impairment. Recent progress has shown that Electroencephalography
(EEG) is the promising and cost-effective test to facilitate the detection of
neurocognitive disorders. However, most of the existing works have been using
only resting-state EEG. The efficiencies of EEG signals from various cognitive
tasks, for dementia classification, have yet to be thoroughly investigated. In
this study, we designed four cognitive tasks that engage different cognitive
performances: attention, working memory, and executive function. We
investigated these tasks by using statistical analysis on both time and
frequency domains of EEG signals from three classes of human subjects: Dementia
(DEM), Mild Cognitive Impairment (MCI), and Normal Control (NC). We also
further evaluated the classification performances of two features extraction
methods: Principal Component Analysis (PCA) and Filter Bank Common Spatial
Pattern (FBCSP). We found that the working memory related tasks yielded good
performances for dementia recognition in both cases using PCA and FBCSP.
Moreover, FBCSP with features combination from four tasks revealed the best
sensitivity of 0.87 and the specificity of 0.80. To our best knowledge, this is
the first work that concurrently investigated several cognitive tasks for
dementia recognition using both statistical analysis and classification scores.
Our results give essential information to design and aid in conducting further
experimental tasks to early diagnose dementia patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual World: A Robotic Benchmark For Continual Reinforcement Learning. (arXiv:2105.10919v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1">Maciej Wo&#x142;czyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Zajac_M/0/1/0/all/0/1">Micha&#x142; Zaj&#x105;c</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kucinski_L/0/1/0/all/0/1">&#x141;ukasz Kuci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1">Piotr Mi&#x142;o&#x15b;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10919">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning (CL) -- the ability to continuously learn, building on
previously acquired knowledge -- is a natural requirement for long-lived
autonomous reinforcement learning (RL) agents. While building such agents, one
needs to balance opposing desiderata, such as constraints on capacity and
compute, the ability to not catastrophically forget, and to exhibit positive
transfer on new tasks. Understanding the right trade-off is conceptually and
computationally challenging, which we argue has led the community to overly
focus on catastrophic forgetting. In response to these issues, we advocate for
the need to prioritize forward transfer and propose Continual World, a
benchmark consisting of realistic and meaningfully diverse robotic tasks built
on top of Meta-World as a testbed. Following an in-depth empirical evaluation
of existing CL methods, we pinpoint their limitations and highlight unique
algorithmic challenges in the RL setting. Our benchmark aims to provide a
meaningful and computationally inexpensive challenge for the community and thus
help better understand the performance of existing and future solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised on Graphs: Contrastive, Generative,or Predictive. (arXiv:2105.07342v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haitao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhangyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan.Z.Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07342">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning on graphs has recently achieved remarkable success on a variety
of tasks while such success relies heavily on the massive and carefully labeled
data. However, precise annotations are generally very expensive and
time-consuming. To address this problem, self-supervised learning (SSL) is
emerging as a new paradigm for extracting informative knowledge through
well-designed pretext tasks without relying on manual labels. In this survey,
we extend the concept of SSL, which first emerged in the fields of computer
vision and natural language processing, to present a timely and comprehensive
review of the existing SSL techniques for graph data. Specifically, we divide
existing graph SSL methods into three categories: contrastive, generative, and
predictive. More importantly, unlike many other surveys that only provide a
high-level description of published research, we present an additional
mathematical summary of the existing works in a unified framework. Furthermore,
to facilitate methodological development and empirical comparisons, we also
summarize the commonly used datasets, evaluation metrics, downstream tasks, and
open-source implementations of various algorithms. Finally, we discuss the
technical challenges and potential future directions for improving graph
self-supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amazon SageMaker Automatic Model Tuning: Scalable Gradient-Free Optimization. (arXiv:2012.08489v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1">Valerio Perrone</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huibin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zolic_A/0/1/0/all/0/1">Aida Zolic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shcherbatyi_I/0/1/0/all/0/1">Iaroslav Shcherbatyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Amr Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_T/0/1/0/all/0/1">Tanya Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1">Michele Donini</a>, <a href="http://arxiv.org/find/cs/1/au:+Winkelmolen_F/0/1/0/all/0/1">Fela Winkelmolen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1">Rodolphe Jenatton</a>, <a href="http://arxiv.org/find/cs/1/au:+Faddoul_J/0/1/0/all/0/1">Jean Baptiste Faddoul</a>, <a href="http://arxiv.org/find/cs/1/au:+Pogorzelska_B/0/1/0/all/0/1">Barbara Pogorzelska</a>, <a href="http://arxiv.org/find/cs/1/au:+Miladinovic_M/0/1/0/all/0/1">Miroslav Miladinovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1">Krishnaram Kenthapadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1">Matthias Seeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1">C&#xe9;dric Archambeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08489">
                                    <div class="article-summary-box-inner">
                                        <span>Tuning complex machine learning systems is challenging. Machine learning
typically requires to set hyperparameters, be it regularization, architecture,
or optimization parameters, whose tuning is critical to achieve good predictive
performance. To democratize access to machine learning systems, it is essential
to automate the tuning. This paper presents Amazon SageMaker Automatic Model
Tuning (AMT), a fully managed system for gradient-free optimization at scale.
AMT finds the best version of a trained machine learning model by repeatedly
evaluating it with different hyperparameter configurations. It leverages either
random search or Bayesian optimization to choose the hyperparameter values
resulting in the best model, as measured by the metric chosen by the user. AMT
can be used with built-in algorithms, custom algorithms, and Amazon SageMaker
pre-built containers for machine learning frameworks. We discuss the core
functionality, system architecture, our design principles, and lessons learned.
We also describe more advanced features of AMT, such as automated early
stopping and warm-starting, showing in experiments their benefits to users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A cappella: Audio-visual Singing Voice Separation. (arXiv:2104.09946v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Montesinos_J/0/1/0/all/0/1">Juan F. Montesinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadandale_V/0/1/0/all/0/1">Venkatesh S. Kadandale</a>, <a href="http://arxiv.org/find/cs/1/au:+Haro_G/0/1/0/all/0/1">Gloria Haro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09946">
                                    <div class="article-summary-box-inner">
                                        <span>Music source separation can be interpreted as the estimation of the
constituent music sources that a music clip is composed of. In this work, we
explore the single-channel singing voice separation problem from a multimodal
perspective, by jointly learning from audio and visual modalities. To do so, we
present Acappella, a dataset spanning around 46 hours of a cappella solo
singing videos sourced from YouTube. We propose Y-Net, an audio-visual
convolutional neural network which achieves state-of-the-art singing voice
separation results on the Acappella dataset and compare it against its
audio-only counterpart, U-Net, and a state-of-the-art audio-visual speech
separation model. Singing voice separation can be particularly challenging when
the audio mixture also comprises of other accompaniment voices and background
sounds along with the target voice of interest. We demonstrate that our model
can outperform the baseline models in the singing voice separation task in such
challenging scenarios. The code, the pre-trained models and the dataset will be
publicly available at https://ipcv.github.io/Acappella/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks. (arXiv:2103.08143v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Nikitin_O/0/1/0/all/0/1">Oleg Nikitin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lukyanova_O/0/1/0/all/0/1">Olga Lukyanova</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kunin_A/0/1/0/all/0/1">Alex Kunin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08143">
                                    <div class="article-summary-box-inner">
                                        <span>Biological neurons have adaptive nature and perform complex computations
involving the filtering of redundant information. However, most common neural
cell models, including biologically plausible, such as Hodgkin-Huxley or
Izhikevich, do not possess predictive dynamics on a single-cell level.
Moreover, the modern rules of synaptic plasticity or interconnections weights
adaptation also do not provide grounding for the ability of neurons to adapt to
the ever-changing input signal intensity. While natural neuron synaptic growth
is precisely controlled and restricted by protein supply and recycling, weight
correction rules such as widely used STDP are efficiently unlimited in change
rate and scale. The present article introduces new mechanics of interconnection
between neuron firing rate homeostasis and weight change through STDP growth
bounded by abstract protein reserve, controlled by the intracellular
optimization algorithm. We show how these cellular dynamics help neurons filter
out the intense noise signals to help neurons keep a stable firing rate. We
also examine that such filtering does not affect the ability of neurons to
recognize the correlated inputs in unsupervised mode. Such an approach might be
used in the machine learning domain to improve the robustness of AI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Efficient Social Navigation Using Inverse Reinforcement Learning. (arXiv:2106.10318v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baghi_B/0/1/0/all/0/1">Bobak H. Baghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Gregory Dudek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10318">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an algorithm to efficiently learn
socially-compliant navigation policies from observations of human trajectories.
As mobile robots come to inhabit and traffic social spaces, they must account
for social cues and behave in a socially compliant manner. We focus on learning
such cues from examples. We describe an inverse reinforcement learning based
algorithm which learns from human trajectory observations without knowing their
specific actions. We increase the sample-efficiency of our approach over
alternative methods by leveraging the notion of a replay buffer (found in many
off-policy reinforcement learning methods) to eliminate the additional sample
complexity associated with inverse reinforcement learning. We evaluate our
method by training agents using publicly available pedestrian motion data sets
and compare it to related methods. We show that our approach yields better
performance while also decreasing training time and sample complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-Structured Adversarial Training. (arXiv:2106.10324v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farnia_F/0/1/0/all/0/1">Farzan Farnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghazadeh_A/0/1/0/all/0/1">Amirali Aghazadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_D/0/1/0/all/0/1">David Tse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10324">
                                    <div class="article-summary-box-inner">
                                        <span>Robust training methods against perturbations to the input data have received
great attention in the machine learning literature. A standard approach in this
direction is adversarial training which learns a model using
adversarially-perturbed training samples. However, adversarial training
performs suboptimally against perturbations structured across samples such as
universal and group-sparse shifts that are commonly present in biological data
such as gene expression levels of different tissues. In this work, we seek to
close this optimality gap and introduce Group-Structured Adversarial Training
(GSAT) which learns a model robust to perturbations structured across samples.
We formulate GSAT as a non-convex concave minimax optimization problem which
minimizes a group-structured optimal transport cost. Specifically, we focus on
the applications of GSAT for group-sparse and rank-constrained perturbations
modeled using group and nuclear norm penalties. In order to solve GSAT&#x27;s
non-smooth optimization problem in those cases, we propose a new minimax
optimization algorithm called GDADMM by combining Gradient Descent Ascent (GDA)
and Alternating Direction Method of Multipliers (ADMM). We present several
applications of the GSAT framework to gain robustness against structured
perturbations for image recognition and computational biology datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Universal Template for Few-shot Dataset Generalization. (arXiv:2105.07029v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Triantafillou_E/0/1/0/all/0/1">Eleni Triantafillou</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07029">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot dataset generalization is a challenging variant of the well-studied
few-shot classification problem where a diverse training set of several
datasets is given, for the purpose of training an adaptable model that can then
learn classes from new datasets using only a few examples. To this end, we
propose to utilize the diverse training set to construct a universal template:
a partial model that can define a wide array of dataset-specialized models, by
plugging in appropriate components. For each new few-shot classification
problem, our approach therefore only requires inferring a small number of
parameters to insert into the universal template. We design a separate network
that produces an initialization of those parameters for each given task, and we
then fine-tune its proposed initialization via a few steps of gradient descent.
Our approach is more parameter-efficient, scalable and adaptable compared to
previous methods, and achieves the state-of-the-art on the challenging
Meta-Dataset benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Distortion for Learned Video Compression. (arXiv:2004.09508v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Veerabadran_V/0/1/0/all/0/1">Vijay Veerabadran</a>, <a href="http://arxiv.org/find/eess/1/au:+Pourreza_R/0/1/0/all/0/1">Reza Pourreza</a>, <a href="http://arxiv.org/find/eess/1/au:+Habibian_A/0/1/0/all/0/1">Amirhossein Habibian</a>, <a href="http://arxiv.org/find/eess/1/au:+Cohen_T/0/1/0/all/0/1">Taco Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09508">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel adversarial lossy video compression model.
At extremely low bit-rates, standard video coding schemes suffer from
unpleasant reconstruction artifacts such as blocking, ringing etc. Existing
learned neural approaches to video compression have achieved reasonable success
on reducing the bit-rate for efficient transmission and reduce the impact of
artifacts to an extent. However, they still tend to produce blurred results
under extreme compression. In this paper, we present a deep adversarial learned
video compression model that minimizes an auxiliary adversarial distortion
objective. We find this adversarial objective to correlate better with human
perceptual quality judgement relative to traditional quality metrics such as
MS-SSIM and PSNR. Our experiments using a state-of-the-art learned video
compression system demonstrate a reduction of perceptual artifacts and
reconstruction of detail lost especially under extremely high compression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DPlis: Boosting Utility of Differentially Private Deep Learning via Randomized Smoothing. (arXiv:2103.01496v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenxiao Wang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianhao Wang</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lun Wang</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Luo_N/0/1/0/all/0/1">Nanqing Luo</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruoxi Jia</a> (5) ((1) Tsinghua University, (2) Harvard University, (3) University of California, Berkeley, (4) Huazhong University of Science and Technology, (5) Virginia Tech)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01496">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning techniques have achieved remarkable performance in wide-ranging
tasks. However, when trained on privacy-sensitive datasets, the model
parameters may expose private information in training data. Prior attempts for
differentially private training, although offering rigorous privacy guarantees,
lead to much lower model performance than the non-private ones. Besides,
different runs of the same training algorithm produce models with large
performance variance. To address these issues, we propose DPlis--Differentially
Private Learning wIth Smoothing. The core idea of DPlis is to construct a
smooth loss function that favors noise-resilient models lying in large flat
regions of the loss landscape. We provide theoretical justification for the
utility improvements of DPlis. Extensive experiments also demonstrate that
DPlis can effectively boost model quality and training stability under a given
privacy budget.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algorithmic Instabilities of Accelerated Gradient Descent. (arXiv:2102.02167v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Attia_A/0/1/0/all/0/1">Amit Attia</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02167">
                                    <div class="article-summary-box-inner">
                                        <span>We study the algorithmic stability of Nesterov&#x27;s accelerated gradient method.
For convex quadratic objectives, Chen et al. (2018) proved that the uniform
stability of the method grows quadratically with the number of optimization
steps, and conjectured that the same is true for the general convex and smooth
case. We disprove this conjecture and show, for two notions of algorithmic
stability (including uniform stability), that the stability of Nesterov&#x27;s
accelerated method in fact deteriorates exponentially fast with the number of
gradient steps. This stands in sharp contrast to the bounds in the quadratic
case, but also to known results for non-accelerated gradient methods where
stability typically grows linearly with the number of steps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-agnostic Feature Importance and Effects with Dependent Features -- A Conditional Subgroup Approach. (arXiv:2006.04628v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Molnar_C/0/1/0/all/0/1">Christoph Molnar</a>, <a href="http://arxiv.org/find/stat/1/au:+Konig_G/0/1/0/all/0/1">Gunnar K&#xf6;nig</a>, <a href="http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>, <a href="http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1">Giuseppe Casalicchio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04628">
                                    <div class="article-summary-box-inner">
                                        <span>The interpretation of feature importance in machine learning models is
challenging when features are dependent. Permutation feature importance (PFI)
ignores such dependencies, which can cause misleading interpretations due to
extrapolation. A possible remedy is more advanced conditional PFI approaches
that enable the assessment of feature importance conditional on all other
features. Due to this shift in perspective and in order to enable correct
interpretations, it is therefore important that the conditioning is transparent
and humanly comprehensible. In this paper, we propose a new sampling mechanism
for the conditional distribution based on permutations in conditional
subgroups. As these subgroups are constructed using decision trees
(transformation trees), the conditioning becomes inherently interpretable. This
not only provides a simple and effective estimator of conditional PFI, but also
local PFI estimates within the subgroups. In addition, we apply the conditional
subgroups approach to partial dependence plots (PDP), a popular method for
describing feature effects that can also suffer from extrapolation when
features are dependent and interactions are present in the model. We show that
PFI and PDP based on conditional subgroups often outperform methods such as
conditional PFI based on knockoffs, or accumulated local effect plots.
Furthermore, our approach allows for a more fine-grained interpretation of
feature effects and importance within the conditional subgroups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Training via Boosting Pruning Plasticity with Neuroregeneration. (arXiv:2106.10404v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Atashgahi_Z/0/1/0/all/0/1">Zahra Atashgahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kou_H/0/1/0/all/0/1">Huanyu Kou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1">Decebal Constantin Mocanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10404">
                                    <div class="article-summary-box-inner">
                                        <span>Works on lottery ticket hypothesis (LTH) and single-shot network pruning
(SNIP) have raised a lot of attention currently on post-training pruning
(iterative magnitude pruning), and before-training pruning (pruning at
initialization). The former method suffers from an extremely large computation
cost and the latter category of methods usually struggles with insufficient
performance. In comparison, during-training pruning, a class of pruning methods
that simultaneously enjoys the training/inference efficiency and the comparable
performance, temporarily, has been less explored. To better understand
during-training pruning, we quantitatively study the effect of pruning
throughout training from the perspective of pruning plasticity (the ability of
the pruned networks to recover the original performance). Pruning plasticity
can help explain several other empirical observations about neural network
pruning in literature. We further find that pruning plasticity can be
substantially improved by injecting a brain-inspired mechanism called
neuroregeneration, i.e., to regenerate the same number of connections as
pruned. Based on the insights from pruning plasticity, we design a novel
gradual magnitude pruning (GMP) method, named gradual pruning with zero-cost
neuroregeneration (GraNet), and its dynamic sparse training (DST) variant
(GraNet-ST). Both of them advance state of the art. Perhaps most impressively,
the latter for the first time boosts the sparse-to-sparse training performance
over various dense-to-sparse methods by a large margin with ResNet-50 on
ImageNet. We will release all codes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1">Ignacio Tampe Palma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1">Marcelo Mendoza</a>, <a href="http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1">Evangelos Milios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03953">
                                    <div class="article-summary-box-inner">
                                        <span>Summarization has usually relied on gold standard summaries to train
extractive or abstractive models. Social media brings a hurdle to summarization
techniques since it requires addressing a multi-document multi-author approach.
We address this challenging task by introducing a novel method that generates
abstractive summaries of online news discussions. Our method extends a
BERT-based architecture, including an attention encoding that fed comments&#x27;
likes during the training stage. To train our model, we define a task which
consists of reconstructing high impact comments based on popularity (likes).
Accordingly, our model learns to summarize online discussions based on their
most relevant comments. Our novel approach provides a summary that represents
the most relevant aspects of a news item that users comment on, incorporating
the social context as a source of information to summarize texts in online
social networks. Our model is evaluated using ROUGE scores between the
generated summary and each comment on the thread. Our model, including the
social attention encoding, significantly outperforms both extractive and
abstractive summarization methods based on such evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exoskeleton-Based Multimodal Action and Movement Recognition: Identifying and Developing the Optimal Boosted Learning Approach. (arXiv:2106.10331v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chia Y. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10331">
                                    <div class="article-summary-box-inner">
                                        <span>This paper makes two scientific contributions to the field of
exoskeleton-based action and movement recognition. First, it presents a novel
machine learning and pattern recognition-based framework that can detect a wide
range of actions and movements - walking, walking upstairs, walking downstairs,
sitting, standing, lying, stand to sit, sit to stand, sit to lie, lie to sit,
stand to lie, and lie to stand, with an overall accuracy of 82.63%. Second, it
presents a comprehensive comparative study of different learning approaches -
Random Forest, Artificial Neural Network, Decision Tree, Multiway Decision
Tree, Support Vector Machine, k-NN, Gradient Boosted Trees, Decision Stump,
Auto MLP, Linear Regression, Vector Linear Regression, Random Tree, Na\&quot;ive
Bayes, Na\&quot;ive Bayes (Kernel), Linear Discriminant Analysis, Quadratic
Discriminant Analysis, and Deep Learning applied to this framework. The
performance of each of these learning approaches was boosted by using the
AdaBoost algorithm, and the Cross Validation approach was used for training and
testing. The results show that in boosted form, the k- NN classifier
outperforms all the other boosted learning approaches and is, therefore, the
optimal learning method for this purpose. The results presented and discussed
uphold the importance of this work to contribute towards augmenting the
abilities of exoskeleton-based assisted and independent living of the elderly
in the future of Internet of Things-based living environments, such as Smart
Homes. As a specific use case, we also discuss how the findings of our work are
relevant for augmenting the capabilities of the Hybrid Assistive Limb
exoskeleton, a highly functional lower limb exoskeleton.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Whole MILC: generalizing learned dynamics across tasks, datasets, and populations. (arXiv:2007.16041v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_U/0/1/0/all/0/1">Usman Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md Mahfuzur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1">Alex Fedorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_N/0/1/0/all/0/1">Noah Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zening Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1">Vince D. Calhoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1">Sergey M. Plis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.16041">
                                    <div class="article-summary-box-inner">
                                        <span>Behavioral changes are the earliest signs of a mental disorder, but arguably,
the dynamics of brain function gets affected even earlier. Subsequently,
spatio-temporal structure of disorder-specific dynamics is crucial for early
diagnosis and understanding the disorder mechanism. A common way of learning
discriminatory features relies on training a classifier and evaluating feature
importance. Classical classifiers, based on handcrafted features are quite
powerful, but suffer the curse of dimensionality when applied to large input
dimensions of spatio-temporal data. Deep learning algorithms could handle the
problem and a model introspection could highlight discriminatory
spatio-temporal regions but need way more samples to train. In this paper we
present a novel self supervised training schema which reinforces whole sequence
mutual information local to context (whole MILC). We pre-train the whole MILC
model on unlabeled and unrelated healthy control data. We test our model on
three different disorders (i) Schizophrenia (ii) Autism and (iii) Alzheimers
and four different studies. Our algorithm outperforms existing self-supervised
pre-training methods and provides competitive classification results to
classical machine learning algorithms. Importantly, whole MILC enables
attribution of subject diagnosis to specific spatio-temporal regions in the
fMRI signal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time series forecasting with Gaussian Processes needs priors. (arXiv:2009.08102v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1">Giorgio Corani</a>, <a href="http://arxiv.org/find/stat/1/au:+Benavoli_A/0/1/0/all/0/1">Alessio Benavoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Zaffalon_M/0/1/0/all/0/1">Marco Zaffalon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08102">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic forecasting is the task of receiving a time series and returning a
forecast for the next time steps without any human intervention. Gaussian
Processes (GPs) are a powerful tool for modeling time series, but so far there
are no competitive approaches for automatic forecasting based on GPs. We
propose practical solutions to two problems: automatic selection of the optimal
kernel and reliable estimation of the hyperparameters. We propose a fixed
composition of kernels, which contains the components needed to model most time
series: linear trend, periodic patterns, and other flexible kernel for modeling
the non-linear trend. Not all components are necessary to model each time
series; during training the unnecessary components are automatically made
irrelevant via automatic relevance determination (ARD). We moreover assign
priors to the hyperparameters, in order to keep the inference within a
plausible range; we design such priors through an empirical Bayes approach. We
present results on many time series of different types; our GP model is more
accurate than state-of-the-art time series models. Thanks to the priors, a
single restart is enough the estimate the hyperparameters; hence the model is
also fast to train.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smooth Exploration for Robotic Reinforcement Learning. (arXiv:2005.05719v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raffin_A/0/1/0/all/0/1">Antonin Raffin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1">Jens Kober</a>, <a href="http://arxiv.org/find/cs/1/au:+Stulp_F/0/1/0/all/0/1">Freek Stulp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.05719">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) enables robots to learn skills from interactions
with the real world. In practice, the unstructured step-based exploration used
in Deep RL -- often very successful in simulation -- leads to jerky motion
patterns on real robots. Consequences of the resulting shaky behavior are poor
exploration, or even damage to the robot. We address these issues by adapting
state-dependent exploration (SDE) to current Deep RL algorithms. To enable this
adaptation, we propose two extensions to the original SDE, using more general
features and re-sampling the noise periodically, which leads to a new
exploration method generalized state-dependent exploration (gSDE). We evaluate
gSDE both in simulation, on PyBullet continuous control tasks, and directly on
three different real robots: a tendon-driven elastic robot, a quadruped and an
RC car. The noise sampling interval of gSDE permits to have a compromise
between performance and smoothness, which allows training directly on the real
robots without loss of performance. The code is available at
https://github.com/DLR-RM/stable-baselines3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scenic4RL: Programmatic Modeling and Generation of Reinforcement Learning Environments. (arXiv:2106.10365v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1">Abdus Salam Azad</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1">Edward Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiancheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1">Sanjit A. Seshia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10365">
                                    <div class="article-summary-box-inner">
                                        <span>The capability of reinforcement learning (RL) agent directly depends on the
diversity of learning scenarios the environment generates and how closely it
captures real-world situations. However, existing environments/simulators lack
the support to systematically model distributions over initial states and
transition dynamics. Furthermore, in complex domains such as soccer, the space
of possible scenarios is infinite, which makes it impossible for one research
group to provide a comprehensive set of scenarios to train, test, and benchmark
RL algorithms. To address this issue, for the first time, we adopt an existing
formal scenario specification language, SCENIC, to intuitively model and
generate interactive scenarios. We interfaced SCENIC to Google Research Soccer
environment to create a platform called SCENIC4RL. Using this platform, we
provide a dataset consisting of 36 scenario programs encoded in SCENIC and
demonstration data generated from a subset of them. We share our experimental
results to show the effectiveness of our dataset and the platform to train,
test, and benchmark RL algorithms. More importantly, we open-source our
platform to enable RL community to collectively contribute to constructing a
comprehensive set of scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Query-Optimal and Time-Efficient Algorithm for Clustering with a Faulty Oracle. (arXiv:2106.10374v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1">Pan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiapeng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10374">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by applications in crowdsourced entity resolution in database,
signed edge prediction in social networks and correlation clustering, Mazumdar
and Saha [NIPS 2017] proposed an elegant theoretical model for studying
clustering with a faulty oracle. In this model, given a set of $n$ items which
belong to $k$ unknown groups (or clusters), our goal is to recover the clusters
by asking pairwise queries to an oracle. This oracle can answer the query that
&#x60;&#x60;do items $u$ and $v$ belong to the same cluster?&#x27;&#x27;. However, the answer to
each pairwise query errs with probability $\varepsilon$, for some
$\varepsilon\in(0,\frac12)$. Mazumdar and Saha provided two algorithms under
this model: one algorithm is query-optimal while time-inefficient (i.e.,
running in quasi-polynomial time), the other is time efficient (i.e., in
polynomial time) while query-suboptimal. Larsen, Mitzenmacher and Tsourakakis
[WWW 2020] then gave a new time-efficient algorithm for the special case of $2$
clusters, which is query-optimal if the bias $\delta:&#x3D;1-2\varepsilon$ of the
model is large. It was left as an open question whether one can obtain a
query-optimal, time-efficient algorithm for the general case of $k$ clusters
and other regimes of $\delta$.

In this paper, we make progress on the above question and provide a
time-efficient algorithm with nearly-optimal query complexity (up to a factor
of $O(\log^2 n)$) for all constant $k$ and any $\delta$ in the regime when
information-theoretic recovery is possible. Our algorithm is built on a
connection to the stochastic block model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Liquid Sensing Using WiFi Signals. (arXiv:2106.10356v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ren_Y/0/1/0/all/0/1">Yili Ren</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10356">
                                    <div class="article-summary-box-inner">
                                        <span>The popularity of Internet-of-Things (IoT) has provided us with unprecedented
opportunities to enable a variety of emerging services in a smart home
environment. Among those services, sensing the liquid level in a container is
critical to building many smart home and mobile healthcare applications that
improve the quality of life. This paper presents LiquidSense, a liquid-level
sensing system that is low-cost, high accuracy, widely applicable to different
daily liquids and containers, and can be easily integrated with existing smart
home networks. LiquidSense uses an existing home WiFi network and a low-cost
transducer that attached to the container to sense the resonance of the
container for liquid level detection. In particular, our system mounts a
low-cost transducer on the surface of the container and emits a well-designed
chirp signal to make the container resonant, which introduces subtle changes to
the home WiFi signals. By analyzing the subtle phase changes of the WiFi
signals, LiquidSense extracts the resonance frequency as a feature for liquid
level detection. Our system constructs prediction models for both continuous
and discrete predictions using curve fitting and SVM respectively. We evaluate
LiquidSense in home environments with containers of three different materials
and six types of liquids. Results show that LiquidSense achieves an overall
accuracy of 97% for continuous prediction and an overall F-score of 0.968 for
discrete prediction. Results also show that our system has a large coverage in
a home environment and works well under non-line-of-sight (NLOS) scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction-Free, Real-Time Flexible Control of Tidal Lagoons through Proximal Policy Optimisation: A Case Study for the Swansea Lagoon. (arXiv:2106.10360v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreira_T/0/1/0/all/0/1">T&#xfa;lio Marcondes Moreira</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Faria_J/0/1/0/all/0/1">Jackson Geraldo de Faria Jr</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Melo_P/0/1/0/all/0/1">Pedro O.S. Vaz de Melo</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chaimowicz_L/0/1/0/all/0/1">Luiz Chaimowicz</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Medeiros_Ribeiro_G/0/1/0/all/0/1">Gilberto Medeiros-Ribeiro</a> (1) ((1) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10360">
                                    <div class="article-summary-box-inner">
                                        <span>Tidal range structures have been considered for large scale electricity
generation for their potential ability to produce reasonable predictable energy
without the emission of greenhouse gases. Once the main forcing components for
driving the tides have deterministic dynamics, the available energy in a given
tidal power plant has been estimated, through analytical and numerical
optimisation routines, as a mostly predictable event. This constraint imposes
state-of-art flexible operation methods to rely on tidal predictions
(concurrent with measured data and up to a multiple of half-tidal cycles into
the future) to infer best operational strategies for tidal lagoons, with the
additional cost of requiring to run optimisation routines for every new tide.
In this paper, we propose a novel optimised operation of tidal lagoons with
proximal policy optimisation through Unity ML-Agents. We compare this technique
with 6 different operation optimisation approaches (baselines) devised from the
literature, utilising the Swansea Bay Tidal Lagoon as a case study. We show
that our approach is successful in maximising energy generation through an
optimised operational policy of turbines and sluices, yielding competitive
results with state-of-the-art methods of optimisation, regardless of test data
used, requiring training once and performing real-time flexible control with
measured ocean data only.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-parametric Differentially Private Confidence Intervals for the Median. (arXiv:2106.10333v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drechsler_J/0/1/0/all/0/1">Joerg Drechsler</a>, <a href="http://arxiv.org/find/cs/1/au:+Globus_Harris_I/0/1/0/all/0/1">Ira Globus-Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+McMillan_A/0/1/0/all/0/1">Audra McMillan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarathy_J/0/1/0/all/0/1">Jayshree Sarathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10333">
                                    <div class="article-summary-box-inner">
                                        <span>Differential privacy is a restriction on data processing algorithms that
provides strong confidentiality guarantees for individual records in the data.
However, research on proper statistical inference, that is, research on
properly quantifying the uncertainty of the (noisy) sample estimate regarding
the true value in the population, is currently still limited. This paper
proposes and evaluates several strategies to compute valid differentially
private confidence intervals for the median. Instead of computing a
differentially private point estimate and deriving its uncertainty, we directly
estimate the interval bounds and discuss why this approach is superior if
ensuring privacy is important. We also illustrate that addressing both sources
of uncertainty--the error from sampling and the error from protecting the
output--simultaneously should be preferred over simpler approaches that
incorporate the uncertainty in a sequential fashion. We evaluate the
performance of the different algorithms under various parameter settings in
extensive simulation studies and demonstrate how the findings could be applied
in practical settings using data from the 1940 Decennial Census.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage. (arXiv:2106.10277v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Yao_L/0/1/0/all/0/1">Lizhong Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10277">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a new acoustic leakage dataset of gas pipelines,
called as GPLA-12, which has 12 categories over 684 training/testing acoustic
signals. Unlike massive image and voice datasets, there have relatively few
acoustic signal datasets, especially for engineering fault detection. In order
to enhance the development of fault diagnosis, we collect acoustic leakage
signals on the basis of an intact gas pipe system with external artificial
leakages, and then preprocess the collected data with structured tailoring
which are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning
dataset for time-series tasks and classifications. To further understand the
dataset, we train both shadow and deep learning algorithms to observe the
performance. The dataset as well as the pretrained models have been released at
both www.daip.club and github.com/Deep-AI-Application-DAIP</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Functional Data Analysis with Adaptive Basis Layers. (arXiv:2106.10414v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yao_J/0/1/0/all/0/1">Junwen Yao</a>, <a href="http://arxiv.org/find/stat/1/au:+Mueller_J/0/1/0/all/0/1">Jonas Mueller</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jane-Ling Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10414">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their widespread success, the application of deep neural networks to
functional data remains scarce today. The infinite dimensionality of functional
data means standard learning algorithms can be applied only after appropriate
dimension reduction, typically achieved via basis expansions. Currently, these
bases are chosen a priori without the information for the task at hand and thus
may not be effective for the designated task. We instead propose to adaptively
learn these bases in an end-to-end fashion. We introduce neural networks that
employ a new Basis Layer whose hidden units are each basis functions themselves
implemented as a micro neural network. Our architecture learns to apply
parsimonious dimension reduction to functional inputs that focuses only on
information relevant to the target rather than irrelevant variation in the
input function. Across numerous classification/regression tasks with functional
data, our method empirically outperforms other types of neural networks, and we
prove that our approach is statistically consistent with low generalization
error. Code is available at: \url{https://github.com/jwyyy/AdaFNN}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-level Features for Resource Economy and Fast Learning in Skill Transfer. (arXiv:2106.10354v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmetoglu_A/0/1/0/all/0/1">Alper Ahmetoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ugur_E/0/1/0/all/0/1">Emre Ugur</a>, <a href="http://arxiv.org/find/cs/1/au:+Asada_M/0/1/0/all/0/1">Minoru Asada</a>, <a href="http://arxiv.org/find/cs/1/au:+Oztop_E/0/1/0/all/0/1">Erhan Oztop</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10354">
                                    <div class="article-summary-box-inner">
                                        <span>Abstraction is an important aspect of intelligence which enables agents to
construct robust representations for effective decision making. In the last
decade, deep networks are proven to be effective due to their ability to form
increasingly complex abstractions. However, these abstractions are distributed
over many neurons, making the re-use of a learned skill costly. Previous work
either enforced formation of abstractions creating a designer bias, or used a
large number of neural units without investigating how to obtain high-level
features that may more effectively capture the source task. For avoiding
designer bias and unsparing resource use, we propose to exploit neural response
dynamics to form compact representations to use in skill transfer. For this, we
consider two competing methods based on (1) maximum information compression
principle and (2) the notion that abstract events tend to generate slowly
changing signals, and apply them to the neural signals generated during task
execution. To be concrete, in our simulation experiments, we either apply
principal component analysis (PCA) or slow feature analysis (SFA) on the
signals collected from the last hidden layer of a deep network while it
performs a source task, and use these features for skill transfer in a new
target task. We compare the generalization performance of these alternatives
with the baselines of skill transfer with full layer output and no-transfer
settings. Our results show that SFA units are the most successful for skill
transfer. SFA as well as PCA, incur less resources compared to usual skill
transfer, whereby many units formed show a localized response reflecting
end-effector-obstacle-goal relations. Finally, SFA units with lowest
eigenvalues resembles symbolic representations that highly correlate with
high-level features such as joint angles which might be thought of precursors
for fully symbolic systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Faster R-CNN: Towards Accurate Few-Shot Object Detection with Attentive Feature Alignment. (arXiv:2104.07719v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1">Guangxing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shiyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiawei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yicheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07719">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot object detection (FSOD) aims to detect objects using only few
examples. It&#x27;s critically needed for many practical applications but so far
remains challenging. We propose a meta-learning based few-shot object detection
method by transferring meta-knowledge learned from data-abundant base classes
to data-scarce novel classes. Our method incorporates a coarse-to-fine approach
into the proposal based object detection framework and integrates prototype
based classifiers into both the proposal generation and classification stages.
To improve proposal generation for few-shot novel classes, we propose to learn
a lightweight matching network to measure the similarity between each spatial
position in the query image feature map and spatially-pooled class features,
instead of the traditional object/nonobject classifier, thus generating
category-specific proposals and improving proposal recall for novel classes. To
address the spatial misalignment between generated proposals and few-shot class
examples, we propose a novel attentive feature alignment method, thus improving
the performance of few-shot object detection. Meanwhile we jointly learn a
Faster R-CNN detection head for base classes. Extensive experiments conducted
on multiple FSOD benchmarks show our proposed approach achieves state of the
art results under (incremental) few-shot learning settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Key Technologies for Networked Virtual Environments. (arXiv:2102.09847v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Juan Gonz&#xe1;lez</a>, <a href="http://arxiv.org/find/cs/1/au:+Boronat_F/0/1/0/all/0/1">Fernando Boronat</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapena_A/0/1/0/all/0/1">Almanzor Sapena</a>, <a href="http://arxiv.org/find/cs/1/au:+Pastor_J/0/1/0/all/0/1">Javier Pastor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09847">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to the improvements experienced in technology in the last few years,
most especially in virtual reality systems, the number and potential of
networked virtual environments or NVEs and their users are increasing. NVEs aim
to give distributed users a feeling of immersion in a virtual world and the
possibility of interacting with other users or with virtual objects inside it,
like when they interact in the real world. Being able to provide that feeling
and natural interactions when the users are geographically separated is one of
the goals of these systems. Nevertheless, this goal is especially sensitive to
different issues, such as different connections with heterogeneous throughput
or different network latencies, which can lead to consistency and
synchronization problems and, thus, to a worsening of the users&#x27; quality of
experience or QoE. With the purpose of solving these issues, researchers have
proposed and evaluated numerous technical solutions, in fields like network
architectures, data distribution and filtering, resource balancing, computing
models, predictive modeling and synchronization in NVEs. This paper gathers and
classifies them, summarizing their advantages and disadvantages, using a new
way of classification. With the current increase of the number of NVEs and the
multiple solutions proposed so far, this work aims to become a useful tool and
a starting point not only for future researchers in this field but also for
those who are new in NVEs development, in which guaranteeing a good users&#x27; QoE
is essential.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-Faced Humans on Twitter and Facebook: Harvesting Social Multimedia for Human Personality Profiling. (arXiv:2106.10673v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Farseev_A/0/1/0/all/0/1">Aleksandr Farseev</a>, <a href="http://arxiv.org/find/cs/1/au:+Filchenkov_A/0/1/0/all/0/1">Andrey Filchenkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10673">
                                    <div class="article-summary-box-inner">
                                        <span>Human personality traits are the key drivers behind our decision-making,
influencing our life path on a daily basis. Inference of personality traits,
such as Myers-Briggs Personality Type, as well as an understanding of
dependencies between personality traits and users&#x27; behavior on various social
media platforms is of crucial importance to modern research and industry
applications. The emergence of diverse and cross-purpose social media avenues
makes it possible to perform user personality profiling automatically and
efficiently based on data represented across multiple data modalities. However,
the research efforts on personality profiling from multi-source multi-modal
social media data are relatively sparse, and the level of impact of different
social network data on machine learning performance has yet to be
comprehensively evaluated. Furthermore, there is not such dataset in the
research community to benchmark. This study is one of the first attempts
towards bridging such an important research gap. Specifically, in this work, we
infer the Myers-Briggs Personality Type indicators, by applying a novel
multi-view fusion framework, called &quot;PERS&quot; and comparing the performance
results not just across data modalities but also with respect to different
social network data sources. Our experimental results demonstrate the PERS&#x27;s
ability to learn from multi-view data for personality profiling by efficiently
leveraging on the significantly different data arriving from diverse social
multimedia sources. We have also found that the selection of a machine learning
approach is of crucial importance when choosing social network data sources and
that people tend to reveal multiple facets of their personality in different
social media avenues. Our released social multimedia dataset facilitates future
research on this direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for Visual Information Extraction using Sequences. (arXiv:2106.10681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiapeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Guozhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weihong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kai Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yichao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10681">
                                    <div class="article-summary-box-inner">
                                        <span>Visual information extraction (VIE) has attracted increasing attention in
recent years. The existing methods usually first organized optical character
recognition (OCR) results into plain texts and then utilized token-level entity
annotations as supervision to train a sequence tagging model. However, it
expends great annotation costs and may be exposed to label confusion, and the
OCR errors will also significantly affect the final performance. In this paper,
we propose a unified weakly-supervised learning framework called TCPN (Tag,
Copy or Predict Network), which introduces 1) an efficient encoder to
simultaneously model the semantic and layout information in 2D OCR results; 2)
a weakly-supervised training strategy that utilizes only key information
sequences as supervision; and 3) a flexible and switchable decoder which
contains two inference modes: one (Copy or Predict Mode) is to output key
information sequences of different categories by copying a token from the input
or predicting one in each time step, and the other (Tag Mode) is to directly
tag the input sequence in a single forward pass. Our method shows new
state-of-the-art performance on several public benchmarks, which fully proves
its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Subverting the Jewtocracy&quot;: Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v3 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1">Mohit Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Pailla_D/0/1/0/all/0/1">Dheeraj Pailla</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1">Himanshu Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchawala_A/0/1/0/all/0/1">Aadilmehdi Sanchawala</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Manish Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1">Manish Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1">Ponnurangam Kumaraguru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05947">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential rise of online social media has enabled the creation,
distribution, and consumption of information at an unprecedented rate. However,
it has also led to the burgeoning of various forms of online abuse. Increasing
cases of online antisemitism have become one of the major concerns because of
its socio-political consequences. Unlike other major forms of online abuse like
racism, sexism, etc., online antisemitism has not been studied much from a
machine learning perspective. To the best of our knowledge, we present the
first work in the direction of automated multimodal detection of online
antisemitism. The task poses multiple challenges that include extracting
signals across multiple modalities, contextual references, and handling
multiple aspects of antisemitism. Unfortunately, there does not exist any
publicly available benchmark corpus for this critical task. Hence, we collect
and label two datasets with 3,102 and 3,509 social media posts from Twitter and
Gab respectively. Further, we present a multimodal deep learning system that
detects the presence of antisemitic content and its specific antisemitism
category using text and images from posts. We perform an extensive set of
experiments on the two datasets to evaluate the efficacy of the proposed
system. Finally, we also present a qualitative analysis of our study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Piano Skills Assessment. (arXiv:2101.04884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parmar_P/0/1/0/all/0/1">Paritosh Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_J/0/1/0/all/0/1">Jaiden Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04884">
                                    <div class="article-summary-box-inner">
                                        <span>Can a computer determine a piano player&#x27;s skill level? Is it preferable to
base this assessment on visual analysis of the player&#x27;s performance or should
we trust our ears over our eyes? Since current CNNs have difficulty processing
long video videos, how can shorter clips be sampled to best reflect the players
skill level? In this work, we collect and release a first-of-its-kind dataset
for multimodal skill assessment focusing on assessing piano player&#x27;s skill
level, answer the asked questions, initiate work in automated evaluation of
piano playing skills and provide baselines for future work. Dataset is
available from: https://github.com/ParitoshParmar/Piano-Skills-Assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Contextual Design of Convolutional Neural Network for Steganalysis. (arXiv:2106.10430v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_B/0/1/0/all/0/1">Brijesh Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sur_A/0/1/0/all/0/1">Arijit Sur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_P/0/1/0/all/0/1">Pinaki Mitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10430">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, deep learning-based steganalysis classifiers became popular
due to their state-of-the-art performance. Most deep steganalysis classifiers
usually extract noise residuals using high-pass filters as preprocessing steps
and feed them to their deep model for classification. It is observed that
recent steganographic embedding does not always restrict their embedding in the
high-frequency zone; instead, they distribute it as per embedding policy.
Therefore, besides noise residual, learning the embedding zone is another
challenging task. In this work, unlike the conventional approaches, the
proposed model first extracts the noise residual using learned denoising
kernels to boost the signal-to-noise ratio. After preprocessing, the sparse
noise residuals are fed to a novel Multi-Contextual Convolutional Neural
Network (M-CNET) that uses heterogeneous context size to learn the sparse and
low-amplitude representation of noise residuals. The model performance is
further improved by incorporating the Self-Attention module to focus on the
areas prone to steganalytic embedding. A set of comprehensive experiments is
performed to show the proposed scheme&#x27;s efficacy over the prior arts. Besides,
an ablation study is given to justify the contribution of various modules of
the proposed architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-21">2021-06-21</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Transformers for Neural Machine Translation. (arXiv:2106.02242v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1">Shijie Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02242">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer has been widely adopted in Neural Machine Translation (NMT)
because of its large capacity and parallel training of sequence generation.
However, the deployment of Transformer is challenging because different
scenarios require models of different complexities and scales. Naively training
multiple Transformers is redundant in terms of both computation and memory. In
this paper, we propose a novel Scalable Transformers, which naturally contains
sub-Transformers of different scales and have shared parameters. Each
sub-Transformer can be easily obtained by cropping the parameters of the
largest Transformer. A three-stage training scheme is proposed to tackle the
difficulty of training the Scalable Transformers, which introduces additional
supervisions from word-level and sequence-level self-distillation. Extensive
experiments were conducted on WMT EN-De and En-Fr to validate our proposed
Scalable Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Profanity and Hate Speech in Social Media with Semantic Subspaces. (arXiv:2106.07505v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hahn_V/0/1/0/all/0/1">Vanessa Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiter_D/0/1/0/all/0/1">Dana Ruiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinbauer_T/0/1/0/all/0/1">Thomas Kleinbauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1">Dietrich Klakow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07505">
                                    <div class="article-summary-box-inner">
                                        <span>Hate speech and profanity detection suffer from data sparsity, especially for
languages other than English, due to the subjective nature of the tasks and the
resulting annotation incompatibility of existing corpora. In this study, we
identify profane subspaces in word and sentence representations and explore
their generalization capability on a variety of similar and distant target
tasks in a zero-shot setting. This is done monolingually (German) and
cross-lingually to closely-related (English), distantly-related (French) and
non-related (Arabic) tasks. We observe that, on both similar and distant target
tasks and across all languages, the subspace-based representations transfer
more effectively than standard BERT representations in the zero-shot setting,
with improvements between F1 +10.9 and F1 +42.9 over the baselines across all
tested monolingual and cross-lingual scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Speech Translation via Cross-modal Progressive Training. (arXiv:2104.10380v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rong Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10380">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end speech translation models have become a new trend in research due
to their potential of reducing error propagation. However, these models still
suffer from the challenge of data scarcity. How to effectively use unlabeled or
other parallel corpora from machine translation is promising but still an open
problem. In this paper, we propose Cross Speech-Text Network (XSTNet), an
end-to-end model for speech-to-text translation. XSTNet takes both speech and
text as input and outputs both transcription and translation text. The model
benefits from its three key design aspects: a self-supervised pre-trained
sub-network as the audio encoder, a multi-task training objective to exploit
additional parallel bilingual text, and a progressive training procedure. We
evaluate the performance of XSTNet and baselines on the MuST-C En-X and
LibriSpeech En-Fr datasets. In particular, XSTNet achieves state-of-the-art
results on all language directions with an average BLEU of 28.8, outperforming
the previous best method by 3.2 BLEU. Code, models, cases, and more detailed
analysis are available at https://github.com/ReneeYe/XSTNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit. (arXiv:2102.01547v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhuoyuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhendong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xin Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01547">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an open source, production first, and production
ready speech recognition toolkit called WeNet in which a new two-pass approach
is implemented to unify streaming and non-streaming end-to-end (E2E) speech
recognition in a single model. The main motivation of WeNet is to close the gap
between the research and the production of E2E speechrecognition models. WeNet
provides an efficient way to ship ASR applications in several real-world
scenarios, which is the main difference and advantage to other open source E2E
speech recognition toolkits. In our toolkit, a new two-pass method is
implemented. Our method propose a dynamic chunk-based attention strategy of the
the transformer layers to allow arbitrary right context length modifies in
hybrid CTC/attention architecture. The inference latency could be easily
controlled by only changing the chunk size. The CTC hypotheses are then
rescored by the attention decoder to get the final result. Our experiments on
the AISHELL-1 dataset using WeNet show that, our model achieves 5.03\% relative
character error rate (CER) reduction in non-streaming ASR compared to a
standard non-streaming transformer. After model quantification, our model
perform reasonable RTF and latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSFCube -- A Test Collection of Computer Science Research Articles for Faceted Query by Example. (arXiv:2103.12906v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1">Sheshera Mysore</a>, <a href="http://arxiv.org/find/cs/1/au:+OGorman_T/0/1/0/all/0/1">Tim O&#x27;Gorman</a>, <a href="http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1">Andrew McCallum</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1">Hamed Zamani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12906">
                                    <div class="article-summary-box-inner">
                                        <span>Query by Example is a well-known information retrieval task in which a
document is chosen by the user as the search query and the goal is to retrieve
relevant documents from a large collection. However, a document often covers
multiple aspects of a topic. To address this scenario we introduce the task of
faceted Query by Example in which users can also specify a finer grained aspect
in addition to the input query document. We focus on the application of this
task in scientific literature search. We envision models which are able to
retrieve scientific papers analogous to a query scientific paper along
specifically chosen rhetorical structure elements as one solution to this
problem. In this work, the rhetorical structure elements, which we refer to as
facets, indicate backgrounds, methods, or results of a scientific paper. We
introduce and describe an expert annotated test collection to evaluate models
trained to perform this task. Our test collection consists of a diverse set of
50 query documents, drawn from computational linguistics and machine learning
venues. We carefully followed the annotation guideline used by TREC for depth-k
pooling (k &#x3D; 100 or 250) and the resulting data collection consists of graded
relevance scores with high annotation agreement. The data is freely available
for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-Device Personalization of Automatic Speech Recognition Models for Disordered Speech. (arXiv:2106.10259v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tomanek_K/0/1/0/all/0/1">Katrin Tomanek</a>, <a href="http://arxiv.org/find/eess/1/au:+Beaufays_F/0/1/0/all/0/1">Fran&#xe7;oise Beaufays</a>, <a href="http://arxiv.org/find/eess/1/au:+Cattiau_J/0/1/0/all/0/1">Julie Cattiau</a>, <a href="http://arxiv.org/find/eess/1/au:+Chandorkar_A/0/1/0/all/0/1">Angad Chandorkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Sim_K/0/1/0/all/0/1">Khe Chai Sim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10259">
                                    <div class="article-summary-box-inner">
                                        <span>While current state-of-the-art Automatic Speech Recognition (ASR) systems
achieve high accuracy on typical speech, they suffer from significant
performance degradation on disordered speech and other atypical speech
patterns. Personalization of ASR models, a commonly applied solution to this
problem, is usually performed in a server-based training environment posing
problems around data privacy, delayed model-update times, and communication
cost for copying data and models between mobile device and server
infrastructure. In this paper, we present an approach to on-device based ASR
personalization with very small amounts of speaker-specific data. We test our
approach on a diverse set of 100 speakers with disordered speech and find
median relative word error rate improvement of 71% with only 50 short
utterances required per speaker. When tested on a voice-controlled home
automation platform, on-device personalized models show a median task success
rate of 81%, compared to only 40% of the unadapted models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Self-training for Punctuation Prediction. (arXiv:2104.10339v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mengzhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qinglin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10339">
                                    <div class="article-summary-box-inner">
                                        <span>Punctuation prediction for automatic speech recognition (ASR) output
transcripts plays a crucial role for improving the readability of the ASR
transcripts and for improving the performance of downstream natural language
processing applications. However, achieving good performance on punctuation
prediction often requires large amounts of labeled speech transcripts, which is
expensive and laborious. In this paper, we propose a Discriminative
Self-Training approach with weighted loss and discriminative label smoothing to
exploit unlabeled speech transcripts. Experimental results on the English
IWSLT2011 benchmark test set and an internal Chinese spoken language dataset
demonstrate that the proposed approach achieves significant improvement on
punctuation prediction accuracy over strong baselines including BERT, RoBERTa,
and ELECTRA models. The proposed Discriminative Self-Training approach
outperforms the vanilla self-training approach. We establish a new
state-of-the-art (SOTA) on the IWSLT2011 test set, outperforming the current
SOTA model by 1.3% absolute gain on F$_1$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning. (arXiv:2104.10357v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qinglin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10357">
                                    <div class="article-summary-box-inner">
                                        <span>In the traditional cascading architecture for spoken language understanding
(SLU), it has been observed that automatic speech recognition errors could be
detrimental to the performance of natural language understanding. End-to-end
(E2E) SLU models have been proposed to directly map speech input to desired
semantic frame with a single model, hence mitigating ASR error propagation.
Recently, pre-training technologies have been explored for these E2E models. In
this paper, we propose a novel joint textual-phonetic pre-training approach for
learning spoken language representations, aiming at exploring the full
potentials of phonetic information to improve SLU robustness to ASR errors. We
explore phoneme labels as high-level speech features, and design and compare
pre-training tasks based on conditional masked language model objectives and
inter-sentence relation objectives. We also investigate the efficacy of
combining textual and phonetic information during fine-tuning. Experimental
results on spoken language understanding benchmarks, Fluent Speech Commands and
SNIPS, show that the proposed approach significantly outperforms strong
baseline models and improves robustness of spoken language understanding to ASR
errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Back Attention Knowledge Transfer for Low-Resource Named Entity Recognition. (arXiv:1906.01183v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Shengfei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Linghao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1">Huixiong Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.01183">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, great success has been achieved in the field of natural
language processing (NLP), thanks in part to the considerable amount of
annotated resources. For named entity recognition (NER), most languages do not
have such an abundance of labeled data as English, so the performances of those
languages are relatively lower. To improve the performance, we propose a
general approach called Back Attention Network (BAN). BAN uses a translation
system to translate other language sentences into English and then applies a
new mechanism named back attention knowledge transfer to obtain task-specific
information from pre-trained high-resource languages NER model. This strategy
can transfer high-layer features of well-trained model and enrich the semantic
representations of the original language. Experiments on three different
language datasets indicate that the proposed approach outperforms other
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEUS: A Data-driven Approach to Estimate User Satisfaction in Multi-turn Dialogues. (arXiv:2103.01287v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dookun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiseleva_J/0/1/0/all/0/1">Julia Kiseleva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Bum Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01287">
                                    <div class="article-summary-box-inner">
                                        <span>Digital assistants are experiencing rapid growth due to their ability to
assist users with day-to-day tasks where most dialogues are happening
multi-turn. However, evaluating multi-turn dialogues remains challenging,
especially at scale. We suggest a context-sensitive method to estimate the
turn-level satisfaction for dialogue considering various types of user
preferences. The costs of interactions between users and dialogue systems are
formulated using a budget consumption concept. We assume users have an initial
interaction budget for a dialogue formed based on the task complexity and that
each turn has a cost. When the task is completed, or the budget has been
exhausted, users quit the dialogue. We demonstrate our method&#x27;s effectiveness
by extensive experimentation with a simulated dialogue platform and real
multi-turn dialogues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition. (arXiv:2106.10169v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruirui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_C/0/1/0/all/0/1">Chelsea J.-T. Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeya Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Hongda Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Elibol_O/0/1/0/all/0/1">Oguz Elibol</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10169">
                                    <div class="article-summary-box-inner">
                                        <span>By implicitly recognizing a user based on his/her speech input, speaker
identification enables many downstream applications, such as personalized
system behavior and expedited shopping checkouts. Based on whether the speech
content is constrained or not, both text-dependent (TD) and text-independent
(TI) speaker recognition models may be used. We wish to combine the advantages
of both types of models through an ensemble system to make more reliable
predictions. However, any such combined approach has to be robust to incomplete
inputs, i.e., when either TD or TI input is missing. As a solution we propose a
fusion of embeddings network foenet architecture, combining joint learning with
neural attention. We compare foenet with four competitive baseline methods on a
dataset of voice assistant inputs, and show that it achieves higher accuracy
than the baseline and score fusion methods, especially in the presence of
incomplete inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models. (arXiv:2106.10199v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaken_E/0/1/0/all/0/1">Elad Ben Zaken</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1">Shauli Ravfogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10199">
                                    <div class="article-summary-box-inner">
                                        <span>We show that with small-to-medium training data, fine-tuning only the bias
terms (or a subset of the bias terms) of pre-trained BERT models is competitive
with (and sometimes better than) fine-tuning the entire model. For larger data,
bias-only fine-tuning is competitive with other sparse fine-tuning methods.
Besides their practical utility, these findings are relevant for the question
of understanding the commonly-used process of finetuning: they support the
hypothesis that finetuning is mainly about exposing knowledge induced by
language-modeling training, rather than learning new task-specific linguistic
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent Stacking of Layers in Neural Networks: An Application to Neural Machine Translation. (arXiv:2106.10002v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1">Raj Dabre</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujita_A/0/1/0/all/0/1">Atsushi Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10002">
                                    <div class="article-summary-box-inner">
                                        <span>In deep neural network modeling, the most common practice is to stack a
number of recurrent, convolutional, or feed-forward layers in order to obtain
high-quality continuous space representations which in turn improves the
quality of the network&#x27;s prediction. Conventionally, each layer in the stack
has its own parameters which leads to a significant increase in the number of
model parameters. In this paper, we propose to share parameters across all
layers thereby leading to a recurrently stacked neural network model. We report
on an extensive case study on neural machine translation (NMT), where we apply
our proposed method to an encoder-decoder based neural network model, i.e., the
Transformer model, and experiment with three Japanese--English translation
datasets. We empirically demonstrate that the translation quality of a model
that recurrently stacks a single layer 6 times, despite having significantly
fewer parameters, approaches that of a model that stacks 6 layers where each
layer has different parameters. We also explore the limits of recurrent
stacking where we train extremely deep NMT models. This paper also examines the
utility of our recurrently stacked model as a student model through transfer
learning via leveraging pre-trained parameters and knowledge distillation, and
shows that it compensates for the performance drops in translation quality that
the direct training of recurrently stacked model brings. We also show how
transfer learning helps in faster decoding on top of the already reduced number
of parameters due to recurrent stacking. Finally, we analyze the effects of
recurrently stacked layers by visualizing the attentions of models that use
recurrently stacked layers and models that do not.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subjective Bias in Abstractive Summarization. (arXiv:2106.10084v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Litvak_M/0/1/0/all/0/1">Marina Litvak</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanetik_N/0/1/0/all/0/1">Natalia Vanetik</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jiacheng Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yinan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1">Siya Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10084">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the subjectivity of the summarization, it is a good practice to have
more than one gold summary for each training document. However, many modern
large-scale abstractive summarization datasets have only one-to-one samples
written by different human with different styles. The impact of this phenomenon
is understudied. We formulate the differences among possible multiple
expressions summarizing the same content as subjective bias and examine the
role of this bias in the context of abstractive summarization. In this paper a
lightweight and effective method to extract the feature embeddings of
subjective styles is proposed. Results of summarization models trained on
style-clustered datasets show that there are certain types of styles that lead
to better convergence, abstraction and generalization. The reproducible code
and generated summaries are available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting gender of Brazilian names using deep learning. (arXiv:2106.10156v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rego_R/0/1/0/all/0/1">Rosana C. B. Rego</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1">Ver&#xf4;nica M. L. Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10156">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting gender by the name is not a simple task. In many applications,
especially in the natural language processing (NLP) field, this task may be
necessary, mainly when considering foreign names. Some machine learning
algorithms can satisfactorily perform the prediction. In this paper, we
examined and implemented feedforward and recurrent deep neural network models,
such as MLP, RNN, GRU, CNN, and BiLSTM, to classify gender through the first
name. A dataset of Brazilian names is used to train and evaluate the models. We
analyzed the accuracy, recall, precision, and confusion matrix to measure the
models&#x27; performances. The results indicate that the gender prediction can be
performed from the feature extraction strategy looking at the names as a set of
strings. Some models accurately predict the gender in more than 90% of the
cases. The recurrent models overcome the feedforward models in this binary
classification problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges and Limitations with the Metrics Measuring the Complexity of Code-Mixed Text. (arXiv:2106.10123v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1">Vivek Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10123">
                                    <div class="article-summary-box-inner">
                                        <span>Code-mixing is a frequent communication style among multilingual speakers
where they mix words and phrases from two different languages in the same
utterance of text or speech. Identifying and filtering code-mixed text is a
challenging task due to its co-existence with monolingual and noisy text. Over
the years, several code-mixing metrics have been extensively used to identify
and validate code-mixed text quality. This paper demonstrates several inherent
limitations of code-mixing metrics with examples from the already existing
datasets that are popularly used across various experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synchronising speech segments with musical beats in Mandarin and English singing. (arXiv:2106.10045v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jian Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10045">
                                    <div class="article-summary-box-inner">
                                        <span>Generating synthesised singing voice with models trained on speech data has
many advantages due to the models&#x27; flexibility and controllability. However,
since the information about the temporal relationship between segments and
beats are lacking in speech training data, the synthesised singing may sound
off-beat at times. Therefore, the availability of the information on the
temporal relationship between speech segments and music beats is crucial. The
current study investigated the segment-beat synchronisation in singing data,
with hypotheses formed based on the linguistics theories of P-centre and
sonority hierarchy. A Mandarin corpus and an English corpus of professional
singing data were manually annotated and analysed. The results showed that the
presence of musical beats was more dependent on segment duration than sonority.
However, the sonority hierarchy and the P-centre theory were highly related to
the location of beats. Mandarin and English demonstrated cross-linguistic
variations despite exhibiting common patterns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPBERT: Pre-training BERT on SPARQL Queries for End-to-end Question Answering over Knowledge Graphs. (arXiv:2106.09997v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1">Hieu Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1">Long Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Truong-Son Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09997">
                                    <div class="article-summary-box-inner">
                                        <span>We aim to create an unprecedented attempt to build an end-to-end Question
Answering (QA) over Knowledge Graphs (KGs), which can construct SPARQL queries
from natural language questions and generate a verbalized answer to its
queries. Hence, we introduce SPBERT, a Transformer-based language model
pre-trained on massive SPARQL query logs. By incorporating masked language
modelling objective and word structural objective, SPBERT can learn
general-purpose representations in both natural language and SPARQL query
language and make the most of the sequential order of words that are crucial
for structured language like SPARQL. In this paper, we investigate how SPBERT
and encoder-decoder architecture can be adapted for Knowledge-based QA corpora.
We conduct exhaustive experiments on two auxiliary tasks, including SPARQL
Query Construction and Answer Verbalization Generation. Results show that
SPBERT obtains promising performance and achieves state-of-the-art results on
several of these tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Financial Sentiment Analysis in a South African Landscape. (arXiv:2106.10004v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terblanche_M/0/1/0/all/0/1">Michelle Terblanche</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10004">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis as a sub-field of natural language processing has received
increased attention in the past decade enabling organisations to more
effectively manage their reputation through online media monitoring. Many
drivers impact reputation, however, this thesis focuses only the aspect of
financial performance and explores the gap with regards to financial sentiment
analysis in a South African context. Results showed that pre-trained sentiment
analysers are least effective for this task and that traditional lexicon-based
and machine learning approaches are best suited to predict financial sentiment
of news articles. The evaluated methods produced accuracies of 84\%-94\%. The
predicted sentiments correlated quite well with share price and highlighted the
potential use of sentiment as an indicator of financial performance. A main
contribution of the study was updating an existing sentiment dictionary for
financial sentiment analysis. Model generalisation was less acceptable due to
the limited amount of training data used. Future work includes expanding the
data set to improve general usability and contribute to an open-source
financial sentiment analyser for South African data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing user creativity: Semantic measures for idea generation. (arXiv:2106.10131v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Georgiev_G/0/1/0/all/0/1">Georgi V. Georgiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgiev_D/0/1/0/all/0/1">Danko D. Georgiev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10131">
                                    <div class="article-summary-box-inner">
                                        <span>Human creativity generates novel ideas to solve real-world problems. This
thereby grants us the power to transform the surrounding world and extend our
human attributes beyond what is currently possible. Creative ideas are not just
new and unexpected, but are also successful in providing solutions that are
useful, efficient and valuable. Thus, creativity optimizes the use of available
resources and increases wealth. The origin of human creativity, however, is
poorly understood, and semantic measures that could predict the success of
generated ideas are currently unknown. Here, we analyze a dataset of design
problem-solving conversations in real-world settings by using 49 semantic
measures based on WordNet 3.1 and demonstrate that a divergence of semantic
similarity, an increased information content, and a decreased polysemy predict
the success of generated ideas. The first feedback from clients also enhances
information content and leads to a divergence of successful ideas in creative
problem solving. These results advance cognitive science by identifying
real-world processes in human problem solving that are relevant to the success
of produced solutions and provide tools for real-time monitoring of problem
solving, student training and skill acquisition. A selected subset of
information content (IC S\&#x27;anchez-Batet) and semantic similarity
(Lin/S\&#x27;anchez-Batet) measures, which are both statistically powerful and
computationally fast, could support the development of technologies for
computer-assisted enhancements of human creativity or for the implementation of
creativity in machines endowed with general artificial intelligence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label Mask for Multi-Label Text Classification. (arXiv:2106.10076v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingbing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zelong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_H/0/1/0/all/0/1">Haining An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hao Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10076">
                                    <div class="article-summary-box-inner">
                                        <span>One of the key problems in multi-label text classification is how to take
advantage of the correlation among labels. However, it is very challenging to
directly model the correlations among labels in a complex and unknown label
space. In this paper, we propose a Label Mask multi-label text classification
model (LM-MTC), which is inspired by the idea of cloze questions of language
model. LM-MTC is able to capture implicit relationships among labels through
the powerful ability of pre-train language models. On the basis, we assign a
different token to each potential label, and randomly mask the token with a
certain probability to build a label based Masked Language Model (MLM). We
train the MTC and MLM together, further improving the generalization ability of
the model. A large number of experiments on multiple datasets demonstrate the
effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Pre-Training for Multi-Hop Retriever. (arXiv:2106.09983v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seonwoo_Y/0/1/0/all/0/1">Yeon Seonwoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sang-Woo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Ji-Hoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1">Jung-Woo Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1">Alice Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09983">
                                    <div class="article-summary-box-inner">
                                        <span>In multi-hop QA, answering complex questions entails iterative document
retrieval for finding the missing entity of the question. The main steps of
this process are sub-question detection, document retrieval for the
sub-question, and generation of a new query for the final document retrieval.
However, building a dataset that contains complex questions with sub-questions
and their corresponding documents requires costly human annotation. To address
the issue, we propose a new method for weakly supervised multi-hop retriever
pre-training without human efforts. Our method includes 1) a pre-training task
for generating vector representations of complex questions, 2) a scalable data
generation method that produces the nested structure of question and
sub-question as weak supervision for pre-training, and 3) a pre-training model
structure based on dense encoders. We conduct experiments to compare the
performance of our pre-trained retriever with several state-of-the-art models
on end-to-end multi-hop QA as well as document retrieval. The experimental
results show that our pre-trained retriever is effective and also robust on
limited data and computational resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Edge-Editing Approach for Document-Level Relation Graph Extraction. (arXiv:2106.09900v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makino_K/0/1/0/all/0/1">Kohei Makino</a>, <a href="http://arxiv.org/find/cs/1/au:+Miwa_M/0/1/0/all/0/1">Makoto Miwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_Y/0/1/0/all/0/1">Yutaka Sasaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09900">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel edge-editing approach to extract relation
information from a document. We treat the relations in a document as a relation
graph among entities in this approach. The relation graph is iteratively
constructed by editing edges of an initial graph, which might be a graph
extracted by another system or an empty graph. The way to edit edges is to
classify them in a close-first manner using the document and
temporally-constructed graph information; each edge is represented with a
document context information by a pretrained transformer model and a graph
context information by a graph convolutional neural network model. We evaluate
our approach on the task to extract material synthesis procedures from
materials science texts. The experimental results show the effectiveness of our
approach in editing the graphs initialized by our in-house rule-based system
and empty graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating the Role of Negatives in Contrastive Representation Learning. (arXiv:2106.09943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1">Dipendra Misra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09943">
                                    <div class="article-summary-box-inner">
                                        <span>Noise contrastive learning is a popular technique for unsupervised
representation learning. In this approach, a representation is obtained via
reduction to supervised learning, where given a notion of semantic similarity,
the learner tries to distinguish a similar (positive) example from a collection
of random (negative) examples. The success of modern contrastive learning
pipelines relies on many parameters such as the choice of data augmentation,
the number of negative examples, and the batch size; however, there is limited
understanding as to how these parameters interact and affect downstream
performance. We focus on disambiguating the role of one of these parameters:
the number of negative examples. Theoretically, we show the existence of a
collision-coverage trade-off suggesting that the optimal number of negative
examples should scale with the number of underlying concepts in the data.
Empirically, we scrutinize the role of the number of negatives in both NLP and
vision tasks. In the NLP task, we find that the results broadly agree with our
theory, while our vision experiments are murkier with performance sometimes
even being insensitive to the number of negatives. We discuss plausible
explanations for this behavior and suggest future directions to better align
theory and practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking. (arXiv:2106.09795v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurajada_S/0/1/0/all/0/1">Sairam Gurajada</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qiuhao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Neelam_S/0/1/0/all/0/1">Sumit Neelam</a>, <a href="http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1">Lucian Popa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_P/0/1/0/all/0/1">Prithviraj Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1">Alexander Gray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09795">
                                    <div class="article-summary-box-inner">
                                        <span>Entity linking (EL), the task of disambiguating mentions in text by linking
them to entities in a knowledge graph, is crucial for text understanding,
question answering or conversational systems. Entity linking on short text
(e.g., single sentence or question) poses particular challenges due to limited
context. While prior approaches use either heuristics or black-box neural
methods, here we propose LNN-EL, a neuro-symbolic approach that combines the
advantages of using interpretable rules based on first-order logic with the
performance of neural learning. Even though constrained to using rules, LNN-EL
performs competitively against SotA black-box neural approaches, with the added
benefits of extensibility and transferability. In particular, we show that we
can easily blend existing rule templates given by a human expert, with multiple
types of features (priors, BERT encodings, box embeddings, etc), and even
scores resulting from previous EL methods, thus improving on such methods. For
instance, on the LC-QuAD-1.0 dataset, we show more than $4$\% increase in F1
score over previous SotA. Finally, we show that the inductive bias offered by
using logic results in learned rules that transfer well across datasets, even
without fine tuning, while maintaining high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction. (arXiv:2106.09895v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hengyi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_R/0/1/0/all/0/1">Rui Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yifan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bin Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Ming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09895">
                                    <div class="article-summary-box-inner">
                                        <span>Joint extraction of entities and relations from unstructured texts is a
crucial task in information extraction. Recent methods achieve considerable
performance but still suffer from some inherent limitations, such as redundancy
of relation prediction, poor generalization of span-based extraction and
inefficiency. In this paper, we decompose this task into three subtasks,
Relation Judgement, Entity Extraction and Subject-object Alignment from a novel
perspective and then propose a joint relational triple extraction framework
based on Potential Relation and Global Correspondence (PRGC). Specifically, we
design a component to predict potential relations, which constrains the
following entity extraction to the predicted relation subset rather than all
relations; then a relation-specific sequence tagging component is applied to
handle the overlapping problem between subjects and objects; finally, a global
correspondence component is designed to align the subject and object into a
triple with low-complexity. Extensive experiments show that PRGC achieves
state-of-the-art performance on public benchmarks with higher efficiency and
delivers consistent performance gain on complex scenarios of overlapping
triples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations. (arXiv:2106.09896v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xingshan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haisong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1">Kam-Fai Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09896">
                                    <div class="article-summary-box-inner">
                                        <span>Quotations are crucial for successful explanations and persuasions in
interpersonal communications. However, finding what to quote in a conversation
is challenging for both humans and machines. This work studies automatic
quotation generation in an online conversation and explores how language
consistency affects whether a quotation fits the given context. Here, we
capture the contextual consistency of a quotation in terms of latent topics,
interactions with the dialogue history, and coherence to the query turn&#x27;s
existing content. Further, an encoder-decoder neural framework is employed to
continue the context with a quotation via language generation. Experiment
results on two large-scale datasets in English and Chinese demonstrate that our
quotation generation model outperforms the state-of-the-art models. Further
analysis shows that topic, interaction, and query consistency are all helpful
to learn how to quote in online conversations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Joint Pandemic Concern and Relation Extraction on Twitter. (arXiv:2106.09929v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jingli Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weihua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yongchareon_S/0/1/0/all/0/1">Sira Yongchareon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1">Quan Bai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09929">
                                    <div class="article-summary-box-inner">
                                        <span>Public concern detection provides potential guidance to the authorities for
crisis management before or during a pandemic outbreak. Detecting people&#x27;s
concerns and attention from online social media platforms has been widely
acknowledged as an effective approach to relieve public panic and prevent a
social crisis. However, detecting concerns in time from massive information in
social media turns out to be a big challenge, especially when sufficient
manually labeled data is in the absence of public health emergencies, e.g.,
COVID-19. In this paper, we propose a novel end-to-end deep learning model to
identify people&#x27;s concerns and the corresponding relations based on Graph
Convolutional Network and Bi-directional Long Short Term Memory integrated with
Concern Graph. Except for the sequential features from BERT embeddings, the
regional features of tweets can be extracted by the Concern Graph module, which
not only benefits the concern detection but also enables our model to be high
noise-tolerant. Thus, our model can address the issue of insufficient manually
labeled data. We conduct extensive experiments to evaluate the proposed model
by using both manually labeled tweets and automatically labeled tweets. The
experimental results show that our model can outperform the state-of-art models
on real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bad Characters: Imperceptible NLP Attacks. (arXiv:2106.09898v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boucher_N/0/1/0/all/0/1">Nicholas Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1">Ross Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09898">
                                    <div class="article-summary-box-inner">
                                        <span>Several years of research have shown that machine-learning systems are
vulnerable to adversarial examples, both in theory and in practice. Until now,
such attacks have primarily targeted visual models, exploiting the gap between
human and machine perception. Although text-based models have also been
attacked with adversarial examples, such attacks struggled to preserve semantic
meaning and indistinguishability. In this paper, we explore a large class of
adversarial examples that can be used to attack text-based models in a
black-box setting without making any human-perceptible visual modification to
inputs. We use encoding-specific perturbations that are imperceptible to the
human eye to manipulate the outputs of a wide range of Natural Language
Processing (NLP) systems from neural machine-translation pipelines to web
search engines. We find that with a single imperceptible encoding injection --
representing one invisible character, homoglyph, reordering, or deletion -- an
attacker can significantly reduce the performance of vulnerable models, and
with three injections most models can be functionally broken. Our attacks work
against currently-deployed commercial systems, including those produced by
Microsoft and Google, in addition to open source models published by Facebook
and IBM. This novel series of attacks presents a significant threat to many
language processing systems: an attacker can affect systems in a targeted
manner without any assumptions about the underlying model. We conclude that
text-based NLP systems require careful input sanitization, just like
conventional applications, and that given such systems are now being deployed
rapidly at scale, the urgent attention of architects and operators is required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GEM: A General Evaluation Benchmark for Multimodal Tasks. (arXiv:2106.09889v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Lin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_E/0/1/0/all/0/1">Edward Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Huaishao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1">Ming Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharti_T/0/1/0/all/0/1">Taroon Bharti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sacheti_A/0/1/0/all/0/1">Arun Sacheti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09889">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present GEM as a General Evaluation benchmark for
Multimodal tasks. Different from existing datasets such as GLUE, SuperGLUE,
XGLUE and XTREME that mainly focus on natural language tasks, GEM is a
large-scale vision-language benchmark, which consists of GEM-I for
image-language tasks and GEM-V for video-language tasks. Comparing with
existing multimodal datasets such as MSCOCO and Flicker30K for image-language
tasks, YouCook2 and MSR-VTT for video-language tasks, GEM is not only the
largest vision-language dataset covering image-language tasks and
video-language tasks at the same time, but also labeled in multiple languages.
We also provide two baseline models for this benchmark. We will release the
dataset, code and baseline models, aiming to advance the development of
multilingual multimodal research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Task Learning and Adapted Knowledge Models for Emotion-Cause Extraction. (arXiv:2106.09790v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turcan_E/0/1/0/all/0/1">Elsbeth Turcan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1">Rishita Anubhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharjee_K/0/1/0/all/0/1">Kasturi Bhattacharjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Onaizan_Y/0/1/0/all/0/1">Yaser Al-Onaizan</a>, <a href="http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1">Smaranda Muresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09790">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting what emotions are expressed in text is a well-studied problem in
natural language processing. However, research on finer grained emotion
analysis such as what causes an emotion is still in its infancy. We present
solutions that tackle both emotion recognition and emotion cause detection in a
joint fashion. Considering that common-sense knowledge plays an important role
in understanding implicitly expressed emotions and the reasons for those
emotions, we propose novel methods that combine common-sense knowledge via
adapted knowledge models with multi-task learning to perform joint emotion
classification and emotion cause tagging. We show performance improvement on
both tasks when including common-sense reasoning and a multitask framework. We
provide a thorough analysis to gain insights into model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-mode Transformer Transducer with Stochastic Future Context. (arXiv:2106.09760v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kim_K/0/1/0/all/0/1">Kwangyoun Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_F/0/1/0/all/0/1">Felix Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sridhar_P/0/1/0/all/0/1">Prashant Sridhar</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_K/0/1/0/all/0/1">Kyu J. Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09760">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) models make fewer errors when more
surrounding speech information is presented as context. Unfortunately,
acquiring a larger future context leads to higher latency. There exists an
inevitable trade-off between speed and accuracy. Naively, to fit different
latency requirements, people have to store multiple models and pick the best
one under the constraints. Instead, a more desirable approach is to have a
single model that can dynamically adjust its latency based on different
constraints, which we refer to as Multi-mode ASR. A Multi-mode ASR model can
fulfill various latency requirements during inference -- when a larger latency
becomes acceptable, the model can process longer future context to achieve
higher accuracy and when a latency budget is not flexible, the model can be
less dependent on future context but still achieve reliable accuracy. In
pursuit of Multi-mode ASR, we propose Stochastic Future Context, a simple
training procedure that samples one streaming configuration in each iteration.
Through extensive experiments on AISHELL-1 and LibriSpeech datasets, we show
that a Multi-mode ASR model rivals, if not surpasses, a set of competitive
streaming baselines trained with different latency budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information Retrieval Approach to Building Datasets for Hate Speech Detection. (arXiv:2106.09775v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md Mustafizur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Balakrishnan_D/0/1/0/all/0/1">Dinesh Balakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Murthy_D/0/1/0/all/0/1">Dhiraj Murthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutlu_M/0/1/0/all/0/1">Mucahid Kutlu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1">Matthew Lease</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09775">
                                    <div class="article-summary-box-inner">
                                        <span>Building a benchmark dataset for hate speech detection presents several
challenges. Firstly, because hate speech is relatively rare -- e.g., less than
3\% of Twitter posts are hateful \citep{founta2018large} -- random sampling of
tweets to annotate is inefficient in capturing hate speech. A common practice
is to only annotate tweets containing known &#x60;&#x60;hate words&#x27;&#x27;, but this risks
yielding a biased benchmark that only partially captures the real-world
phenomenon of interest. A second challenge is that definitions of hate speech
tend to be highly variable and subjective. Annotators having diverse prior
notions of hate speech may not only disagree with one another but also struggle
to conform to specified labeling guidelines. Our key insight is that the rarity
and subjectivity of hate speech are akin to that of relevance in information
retrieval (IR). This connection suggests that well-established methodologies
for creating IR test collections might also be usefully applied to create
better benchmark datasets for hate speech detection. Firstly, to intelligently
and efficiently select which tweets to annotate, we apply established IR
techniques of {\em pooling} and {\em active learning}. Secondly, to improve
both consistency and value of annotations, we apply {\em task decomposition}
\cite{Zhang-sigir14} and {\em annotator rationale} \cite{mcdonnell16-hcomp}
techniques. Using the above techniques, we create and share a new benchmark
dataset\footnote{We will release the dataset upon publication.} for hate speech
detection with broader coverage than prior datasets. We also show a dramatic
drop in accuracy of existing detection models when tested on these broader
forms of hate. Collected annotator rationales not only provide documented
support for labeling decisions but also create exciting future work
opportunities for dual-supervision and/or explanation generation in modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Go with the Flows: Mixtures of Normalizing Flows for Point Cloud Generation and Reconstruction. (arXiv:2106.03135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Postels_J/0/1/0/all/0/1">Janis Postels</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengya Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Spezialetti_R/0/1/0/all/0/1">Riccardo Spezialetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03135">
                                    <div class="article-summary-box-inner">
                                        <span>Recently normalizing flows (NFs) have demonstrated state-of-the-art
performance on modeling 3D point clouds while allowing sampling with arbitrary
resolution at inference time. However, these flow-based models still require
long training times and large models for representing complicated geometries.
This work enhances their representational power by applying mixtures of NFs to
point clouds. We show that in this more general framework each component learns
to specialize in a particular subregion of an object in a completely
unsupervised fashion. By instantiating each mixture component with a
comparatively small NF we generate point clouds with improved details compared
to single-flow-based models while using fewer parameters and considerably
reducing the inference runtime. We further demonstrate that by adding data
augmentation, individual mixture components can learn to specialize in a
semantically meaningful manner. We evaluate mixtures of NFs on generation,
autoencoding and single-view reconstruction based on the ShapeNet dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHARP: Shape-Aware Reconstruction of People In Loose Clothing. (arXiv:2106.04778v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jinka_S/0/1/0/all/0/1">Sai Sagar Jinka</a>, <a href="http://arxiv.org/find/cs/1/au:+Chacko_R/0/1/0/all/0/1">Rohan Chacko</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1">Astitva Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Avinash Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1">P.J. Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04778">
                                    <div class="article-summary-box-inner">
                                        <span>3D human body reconstruction from monocular images is an interesting and
ill-posed problem in computer vision with wider applications in multiple
domains. In this paper, we propose SHARP, a novel end-to-end trainable network
that accurately recovers the detailed geometry and appearance of 3D people in
loose clothing from a monocular image. We propose a sparse and efficient fusion
of a parametric body prior with a non-parametric peeled depth map
representation of clothed models. The parametric body prior constraints our
model in two ways: first, the network retains geometrically consistent body
parts that are not occluded by clothing, and second, it provides a body shape
context that improves prediction of the peeled depth maps. This enables SHARP
to recover fine-grained 3D geometrical details with just L1 losses on the 2D
maps, given an input image. We evaluate SHARP on publicly available Cloth3D and
THuman datasets and report superior performance to state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistent Posterior Distributions under Vessel-Mixing: A Regularization for Cross-Domain Retinal Artery/Vein Classification. (arXiv:2103.09097v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunlong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1">Zhehan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wenao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xinghao Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09097">
                                    <div class="article-summary-box-inner">
                                        <span>Retinal artery/vein (A/V) classification is a critical technique for
diagnosing diabetes and cardiovascular diseases. Although deep learning based
methods achieve impressive results in A/V classification, their performances
usually degrade severely when being directly applied to another database, due
to the domain shift, e.g., caused by the variations in imaging protocols. In
this paper, we propose a novel vessel-mixing based consistency regularization
framework, for cross-domain learning in retinal A/V classification. Specially,
to alleviate the severe bias to source domain, based on the label smooth prior,
the model is regularized to give consistent predictions for unlabeled
target-domain inputs that are under perturbation. This consistency
regularization implicitly introduces a mechanism where the model and the
perturbation is opponent to each other, where the model is pushed to be robust
enough to cope with the perturbation. Thus, we investigate a more difficult
opponent to further inspire the robustness of model, in the scenario of retinal
A/V, called vessel-mixing perturbation. Specially, it effectively disturbs the
fundus images especially the vessel structures by mixing two images regionally.
We conduct extensive experiments on cross-domain A/V classification using four
public datasets, which are collected by diverse institutions and imaging
devices. The results demonstrate that our method achieves the state-of-the-art
cross-domain performance, which is also close to the upper bound obtained by
fully supervised learning on target domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CompositeTasking: Understanding Images by Spatial Composition of Tasks. (arXiv:2012.09030v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Popovic_N/0/1/0/all/0/1">Nikola Popovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudel_D/0/1/0/all/0/1">Danda Pani Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Probst_T/0/1/0/all/0/1">Thomas Probst</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Guolei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09030">
                                    <div class="article-summary-box-inner">
                                        <span>We define the concept of CompositeTasking as the fusion of multiple,
spatially distributed tasks, for various aspects of image understanding.
Learning to perform spatially distributed tasks is motivated by the frequent
availability of only sparse labels across tasks, and the desire for a compact
multi-tasking network. To facilitate CompositeTasking, we introduce a novel
task conditioning model -- a single encoder-decoder network that performs
multiple, spatially varying tasks at once. The proposed network takes an image
and a set of pixel-wise dense task requests as inputs, and performs the
requested prediction task for each pixel. Moreover, we also learn the
composition of tasks that needs to be performed according to some
CompositeTasking rules, which includes the decision of where to apply which
task. It not only offers us a compact network for multi-tasking, but also
allows for task-editing. Another strength of the proposed method is
demonstrated by only having to supply sparse supervision per task. The obtained
results are on par with our baselines that use dense supervision and a
multi-headed multi-tasking design. The source code will be made publicly
available at www.github.com/nikola3794/composite-tasking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Semantic Segmentation Augmented with Image-Level Weak Annotations. (arXiv:2007.01496v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1">Shuo Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jianfeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fanglan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chang-Tien Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01496">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great progress made by deep neural networks in the semantic
segmentation task, traditional neural-networkbased methods typically suffer
from a shortage of large amounts of pixel-level annotations. Recent progress in
fewshot semantic segmentation tackles the issue by only a few pixel-level
annotated examples. However, these few-shot approaches cannot easily be applied
to multi-way or weak annotation settings. In this paper, we advance the
few-shot segmentation paradigm towards a scenario where image-level annotations
are available to help the training process of a few pixel-level annotations.
Our key idea is to learn a better prototype representation of the class by
fusing the knowledge from the image-level labeled data. Specifically, we
propose a new framework, called PAIA, to learn the class prototype
representation in a metric space by integrating image-level annotations.
Furthermore, by considering the uncertainty of pseudo-masks, a distilled soft
masked average pooling strategy is designed to handle distractions in
image-level annotations. Extensive empirical results on two datasets show
superior performance of PAIA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pseudo-healthy synthesis with pathology disentanglement and adversarial learning. (arXiv:2005.01607v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xia_T/0/1/0/all/0/1">Tian Xia</a>, <a href="http://arxiv.org/find/eess/1/au:+Chartsias_A/0/1/0/all/0/1">Agisilaos Chartsias</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsaftaris_S/0/1/0/all/0/1">Sotirios A. Tsaftaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01607">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-healthy synthesis is the task of creating a subject-specific &#x60;healthy&#x27;
image from a pathological one. Such images can be helpful in tasks such as
anomaly detection and understanding changes induced by pathology and disease.
In this paper, we present a model that is encouraged to disentangle the
information of pathology from what seems to be healthy. We disentangle what
appears to be healthy and where disease is as a segmentation map, which are
then recombined by a network to reconstruct the input disease image. We train
our models adversarially using either paired or unpaired settings, where we
pair disease images and maps when available. We quantitatively and
subjectively, with a human study, evaluate the quality of pseudo-healthy images
using several criteria. We show in a series of experiments, performed on ISLES,
BraTS and Cam-CAN datasets, that our method is better than several baselines
and methods from the literature. We also show that due to better training
processes we could recover deformations, on surrounding tissue, caused by
disease. Our implementation is publicly available at
https://github.com/xiat0616/pseudo-healthy-synthesis. This paper has been
accepted by Medical Image Analysis:
https://doi.org/10.1016/j.media.2020.101719.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">All You Can Embed: Natural Language based Vehicle Retrieval with Spatio-Temporal Transformers. (arXiv:2106.10153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scribano_C/0/1/0/all/0/1">Carmelo Scribano</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapienza_D/0/1/0/all/0/1">Davide Sapienza</a>, <a href="http://arxiv.org/find/cs/1/au:+Franchini_G/0/1/0/all/0/1">Giorgia Franchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Verucchi_M/0/1/0/all/0/1">Micaela Verucchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertogna_M/0/1/0/all/0/1">Marko Bertogna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10153">
                                    <div class="article-summary-box-inner">
                                        <span>Combining Natural Language with Vision represents a unique and interesting
challenge in the domain of Artificial Intelligence. The AI City Challenge Track
5 for Natural Language-Based Vehicle Retrieval focuses on the problem of
combining visual and textual information, applied to a smart-city use case. In
this paper, we present All You Can Embed (AYCE), a modular solution to
correlate single-vehicle tracking sequences with natural language. The main
building blocks of the proposed architecture are (i) BERT to provide an
embedding of the textual descriptions, (ii) a convolutional backbone along with
a Transformer model to embed the visual information. For the training of the
retrieval model, a variation of the Triplet Margin Loss is proposed to learn a
distance measure between the visual and language embeddings. The code is
publicly available at https://github.com/cscribano/AYCE_2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers. (arXiv:2106.10270v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1">Andreas Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wightman_R/0/1/0/all/0/1">Ross Wightman</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10270">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformers (ViT) have been shown to attain highly competitive
performance for a wide range of vision applications, such as image
classification, object detection and semantic image segmentation. In comparison
to convolutional neural networks, the Vision Transformer&#x27;s weaker inductive
bias is generally found to cause an increased reliance on model regularization
or data augmentation (&#x60;&#x60;AugReg&#x27;&#x27; for short) when training on smaller training
datasets. We conduct a systematic empirical study in order to better understand
the interplay between the amount of training data, AugReg, model size and
compute budget. As one result of this study we find that the combination of
increased compute and AugReg can yield models with the same performance as
models trained on an order of magnitude more training data: we train ViT models
of various sizes on the public ImageNet-21k dataset which either match or
outperform their counterparts trained on the larger, but not publicly available
JFT-300M dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Delving Deep into the Generalization of Vision Transformers under Distribution Shifts. (arXiv:2106.07617v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongzhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mingyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Daisheng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qiang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianglong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07617">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformers (ViTs) have achieved impressive results on
various vision tasks. Yet, their generalization ability under different
distribution shifts is rarely understood. In this work, we provide a
comprehensive study on the out-of-distribution generalization of ViTs. To
support a systematic investigation, we first present a taxonomy of distribution
shifts by categorizing them into five conceptual groups: corruption shift,
background shift, texture shift, destruction shift, and style shift. Then we
perform extensive evaluations of ViT variants under different groups of
distribution shifts and compare their generalization ability with CNNs. Several
important observations are obtained: 1) ViTs generalize better than CNNs under
multiple distribution shifts. With the same or fewer parameters, ViTs are ahead
of corresponding CNNs by more than 5% in top-1 accuracy under most distribution
shifts. 2) Larger ViTs gradually narrow the in-distribution and
out-of-distribution performance gap. To further improve the generalization of
ViTs, we design the Generalization-Enhanced ViTs by integrating adversarial
learning, information theory, and self-supervised learning. By investigating
three types of generalization-enhanced ViTs, we observe their
gradient-sensitivity and design a smoother learning strategy to achieve a
stable training process. With modified training schemes, we achieve
improvements on performance towards out-of-distribution data by 4% from vanilla
ViTs. We comprehensively compare three generalization-enhanced ViTs with their
corresponding CNNs, and observe that: 1) For the enhanced model, larger ViTs
still benefit more for the out-of-distribution generalization. 2)
generalization-enhanced ViTs are more sensitive to the hyper-parameters than
corresponding CNNs. We hope our comprehensive study could shed light on the
design of more generalizable learning architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Hashing Methods. (arXiv:2003.03369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Daqing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1">Minghua Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03369">
                                    <div class="article-summary-box-inner">
                                        <span>Nearest neighbor search is to find the data points in the database such that
the distances from them to the query are the smallest, which is a fundamental
problem in various domains, such as computer vision, recommendation systems and
machine learning. Hashing is one of the most widely used methods for its
computational and storage efficiency. With the development of deep learning,
deep hashing methods show more advantages than traditional methods. In this
paper, we present a comprehensive survey of the deep hashing algorithms.
Specifically, we categorize deep supervised hashing methods into pairwise
similarity preserving, multiwise similarity preserving, implicit similarity
preserving, classification-oriented preserving as well as quantization
according to the manners of preserving the similarities. In addition, we also
introduce some other topics such as deep unsupervised hashing and multi-modal
deep hashing methods. Meanwhile, we also present some commonly used public
datasets and the scheme to measure the performance of deep hashing algorithms.
Finally, we discussed some potential research directions in conclusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1">Marcos Vendramini</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1">Alexei Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10013">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification methods are usually trained to perform predictions
taking into account a predefined group of known classes. Real-world problems,
however, may not allow for a full knowledge of the input and label spaces,
making failures in recognition a hazard to deep visual learning. Open set
recognition methods are characterized by the ability to correctly identifying
inputs of known and unknown classes. In this context, we propose GeMOS: simple
and plug-and-play open set recognition modules that can be attached to
pretrained Deep Neural Networks for visual recognition. The GeMOS framework
pairs pre-trained Convolutional Neural Networks with generative models for open
set recognition to extract open set scores for each sample, allowing for
failure recognition in object recognition tasks. We conduct a thorough
evaluation of the proposed method in comparison with state-of-the-art open set
algorithms, finding that GeMOS either outperforms or is statistically
indistinguishable from more complex and costly models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Consensual Collaborative Learning Method for Remote Sensing Image Classification Under Noisy Multi-Labels. (arXiv:2105.05496v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aksoy_A/0/1/0/all/0/1">Ahmet Kerem Aksoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravanbakhsh_M/0/1/0/all/0/1">Mahdyar Ravanbakhsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreuziger_T/0/1/0/all/0/1">Tristan Kreuziger</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_B/0/1/0/all/0/1">Begum Demir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05496">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting a large number of reliable training images annotated by multiple
land-cover class labels in the framework of multi-label classification is
time-consuming and costly in remote sensing (RS). To address this problem,
publicly available thematic products are often used for annotating RS images
with zero-labeling-cost. However, such an approach may result in constructing a
training set with noisy multi-labels, distorting the learning process. To
address this problem, we propose a Consensual Collaborative Multi-Label
Learning (CCML) method. The proposed CCML identifies, ranks and corrects
training images with noisy multi-labels through four main modules: 1)
discrepancy module; 2) group lasso module; 3) flipping module; and 4) swap
module. The discrepancy module ensures that the two networks learn diverse
features, while obtaining the same predictions. The group lasso module detects
the potentially noisy labels by estimating the label uncertainty based on the
aggregation of two collaborative networks. The flipping module corrects the
identified noisy labels, whereas the swap module exchanges the ranking
information between the two networks. The experimental results confirm the
success of the proposed CCML under high (synthetically added) multi-label noise
rates. The code of the proposed method is publicly available at
https://noisy-labels-in-rs.org</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1">Wang Yifan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1">Lukas Rahmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1">Olga Sorkine-Hornung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05187">
                                    <div class="article-summary-box-inner">
                                        <span>We present implicit displacement fields, a novel representation for detailed
3D geometry. Inspired by a classic surface deformation technique, displacement
mapping, our method represents a complex surface as a smooth base surface plus
a displacement along the base&#x27;s normal directions, resulting in a
frequency-based shape decomposition, where the high frequency signal is
constrained geometrically by the low frequency signal. Importantly, this
disentanglement is unsupervised thanks to a tailored architectural design that
has an innate frequency hierarchy by construction. We explore implicit
displacement field surface reconstruction and detail transfer and demonstrate
superior representational power, training stability and generalizability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Temporal Action Detection with Transformer. (arXiv:2106.10271v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaolong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qimeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1">Song Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiang Bai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10271">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal action detection (TAD) aims to determine the semantic label and the
boundaries of every action instance in an untrimmed video. It is a fundamental
task in video understanding and significant progress has been made in TAD.
Previous methods involve multiple stages or networks and hand-designed rules or
operations, which fall short in efficiency and flexibility. Here, we construct
an end-to-end framework for TAD upon Transformer, termed \textit{TadTR}, which
simultaneously predicts all action instances as a set of labels and temporal
locations in parallel. TadTR is able to adaptively extract temporal context
information needed for making action predictions, by selectively attending to a
number of snippets in a video. It greatly simplifies the pipeline of TAD and
runs much faster than previous detectors. Our method achieves state-of-the-art
performance on HACS Segments and THUMOS14 and competitive performance on
ActivityNet-1.3. Our code will be made available at
\url{https://github.com/xlliu7/TadTR}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning of Generalized Game Representations. (arXiv:2106.10060v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trivedi_C/0/1/0/all/0/1">Chintan Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liapis_A/0/1/0/all/0/1">Antonios Liapis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakakis_G/0/1/0/all/0/1">Georgios N. Yannakakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10060">
                                    <div class="article-summary-box-inner">
                                        <span>Representing games through their pixels offers a promising approach for
building general-purpose and versatile game models. While games are not merely
images, neural network models trained on game pixels often capture differences
of the visual style of the image rather than the content of the game. As a
result, such models cannot generalize well even within similar games of the
same genre. In this paper we build on recent advances in contrastive learning
and showcase its benefits for representation learning in games. Learning to
contrast images of games not only classifies games in a more efficient manner;
it also yields models that separate games in a more meaningful fashion by
ignoring the visual style and focusing, instead, on their content. Our results
in a large dataset of sports video games containing 100k images across 175
games and 10 game genres suggest that contrastive learning is better suited for
learning generalized game representations compared to conventional supervised
learning. The findings of this study bring us closer to universal visual
encoders for games that can be reused across previously unseen games without
requiring retraining or fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering Relationships between Object Categories via Universal Canonical Maps. (arXiv:2106.09758v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neverova_N/0/1/0/all/0/1">Natalia Neverova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanakoyeu_A/0/1/0/all/0/1">Artsiom Sanakoyeu</a>, <a href="http://arxiv.org/find/cs/1/au:+Labatut_P/0/1/0/all/0/1">Patrick Labatut</a>, <a href="http://arxiv.org/find/cs/1/au:+Novotny_D/0/1/0/all/0/1">David Novotny</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1">Andrea Vedaldi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09758">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the problem of learning the geometry of multiple categories of
deformable objects jointly. Recent work has shown that it is possible to learn
a unified dense pose predictor for several categories of related objects.
However, training such models requires to initialize inter-category
correspondences by hand. This is suboptimal and the resulting models fail to
maintain correct correspondences as individual categories are learned. In this
paper, we show that improved correspondences can be learned automatically as a
natural byproduct of learning category-specific dense pose predictors. To do
this, we express correspondences between different categories and between
images and categories using a unified embedding. Then, we use the latter to
enforce two constraints: symmetric inter-category cycle consistency and a new
asymmetric image-to-category cycle consistency. Without any manual annotations
for the inter-category correspondences, we obtain state-of-the-art alignment
results, outperforming dedicated methods for matching 3D shapes. Moreover, the
new model is also better at the task of dense pose prediction than prior work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning and Meshing from Deep Implicit Surface Networks Using an Efficient Implementation of Analytic Marching. (arXiv:2106.10031v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jiabao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10031">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstruction of object or scene surfaces has tremendous applications in
computer vision, computer graphics, and robotics. In this paper, we study a
fundamental problem in this context about recovering a surface mesh from an
implicit field function whose zero-level set captures the underlying surface.
To achieve the goal, existing methods rely on traditional meshing algorithms;
while promising, they suffer from loss of precision learned in the implicit
surface networks, due to the use of discrete space sampling in marching cubes.
Given that an MLP with activations of Rectified Linear Unit (ReLU) partitions
its input space into a number of linear regions, we are motivated to connect
this local linearity with a same property owned by the desired result of
polygon mesh. More specifically, we identify from the linear regions,
partitioned by an MLP based implicit function, the analytic cells and analytic
faces that are associated with the function&#x27;s zero-level isosurface. We prove
that under mild conditions, the identified analytic faces are guaranteed to
connect and form a closed, piecewise planar surface. Based on the theorem, we
propose an algorithm of analytic marching, which marches among analytic cells
to exactly recover the mesh captured by an implicit surface network. We also
show that our theory and algorithm are equally applicable to advanced MLPs with
shortcut connections and max pooling. Given the parallel nature of analytic
marching, we contribute AnalyticMesh, a software package that supports
efficient meshing of implicit surface networks via CUDA parallel computing, and
mesh simplification for efficient downstream processing. We apply our method to
different settings of generative shape modeling using implicit surface
networks. Extensive experiments demonstrate our advantages over existing
methods in terms of both meshing accuracy and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Virtual Temporal Samples for Recurrent Neural Networks: applied to semantic segmentation in agriculture. (arXiv:2106.10118v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmadi_A/0/1/0/all/0/1">Alireza Ahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Halstead_M/0/1/0/all/0/1">Michael Halstead</a>, <a href="http://arxiv.org/find/cs/1/au:+McCool_C/0/1/0/all/0/1">Chris McCool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10118">
                                    <div class="article-summary-box-inner">
                                        <span>This paper explores the potential for performing temporal semantic
segmentation in the context of agricultural robotics without temporally
labelled data. We achieve this by proposing to generate virtual temporal
samples from labelled still images. This allows us, with no extra annotation
effort, to generate virtually labelled temporal sequences. Normally, to train a
recurrent neural network (RNN), labelled samples from a video (temporal)
sequence are required which is laborious and has stymied work in this
direction. By generating virtual temporal samples, we demonstrate that it is
possible to train a lightweight RNN to perform semantic segmentation on two
challenging agricultural datasets. Our results show that by training a temporal
semantic segmenter using virtual samples we can increase the performance by an
absolute amount of 4.6 and 4.9 on sweet pepper and sugar beet datasets,
respectively. This indicates that our virtual data augmentation technique is
able to accurately classify agricultural images temporally without the use of
complicated synthetic data generation techniques nor with the overhead of
labelling large amounts of temporal sequences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novelty Detection via Contrastive Learning with Negative Data Augmentation. (arXiv:2106.09958v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chengwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shaohui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Ruizhi Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xin Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09958">
                                    <div class="article-summary-box-inner">
                                        <span>Novelty detection is the process of determining whether a query example
differs from the learned training distribution. Previous methods attempt to
learn the representation of the normal samples via generative adversarial
networks (GANs). However, they will suffer from instability training, mode
dropping, and low discriminative ability. Recently, various pretext tasks (e.g.
rotation prediction and clustering) have been proposed for self-supervised
learning in novelty detection. However, the learned latent features are still
low discriminative. We overcome such problems by introducing a novel
decoder-encoder framework. Firstly, a generative network (a.k.a. decoder)
learns the representation by mapping the initialized latent vector to an image.
In particular, this vector is initialized by considering the entire
distribution of training data to avoid the problem of mode-dropping. Secondly,
a contrastive network (a.k.a. encoder) aims to &#x60;&#x60;learn to compare&#x27;&#x27; through
mutual information estimation, which directly helps the generative network to
obtain a more discriminative representation by using a negative data
augmentation strategy. Extensive experiments show that our model has
significant superiority over cutting-edge novelty detectors and achieves new
state-of-the-art results on some novelty detection benchmarks, e.g. CIFAR10 and
DCASE. Moreover, our model is more stable for training in a non-adversarial
manner, compared to other adversarial based novelty detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Residual Contrastive Learning for Joint Demosaicking and Denoising. (arXiv:2106.10070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1">Nanqing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Maggioni_M/0/1/0/all/0/1">Matteo Maggioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Pellitero_E/0/1/0/all/0/1">Eduardo P&#xe9;rez-Pellitero</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1">Ales Leonardis</a>, <a href="http://arxiv.org/find/cs/1/au:+McDonagh_S/0/1/0/all/0/1">Steven McDonagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10070">
                                    <div class="article-summary-box-inner">
                                        <span>The breakthrough of contrastive learning (CL) has fueled the recent success
of self-supervised learning (SSL) in high-level vision tasks on RGB images.
However, CL is still ill-defined for low-level vision tasks, such as joint
demosaicking and denoising (JDD), in the RAW domain. To bridge this
methodological gap, we present a novel CL approach on RAW images, residual
contrastive learning (RCL), which aims to learn meaningful representations for
JDD. Our work is built on the assumption that noise contained in each RAW image
is signal-dependent, thus two crops from the same RAW image should have more
similar noise distribution than two crops from different RAW images. We use
residuals as a discriminative feature and the earth mover&#x27;s distance to measure
the distribution divergence for the contrastive loss. To evaluate the proposed
CL strategy, we simulate a series of unsupervised JDD experiments with
large-scale data corrupted by synthetic signal-dependent noise, where we set a
new benchmark for unsupervised JDD tasks with unknown (random) noise variance.
Our empirical study not only validates that CL can be applied on distributions
(c.f. features), but also exposes the lack of robustness of previous non-ML and
SSL JDD methods when the statistics of the noise are unknown, thus providing
some further insight into signal-dependent noise problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Longitudinal Neighbourhood Embedding. (arXiv:2103.03840v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1">Jiahong Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qingyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_E/0/1/0/all/0/1">Edith V Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfefferbaum_A/0/1/0/all/0/1">Adolf Pfefferbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaharchuk_G/0/1/0/all/0/1">Greg Zaharchuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1">Kilian M Pohl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03840">
                                    <div class="article-summary-box-inner">
                                        <span>Longitudinal MRIs are often used to capture the gradual deterioration of
brain structure and function caused by aging or neurological diseases.
Analyzing this data via machine learning generally requires a large number of
ground-truth labels, which are often missing or expensive to obtain. Reducing
the need for labels, we propose a self-supervised strategy for representation
learning named Longitudinal Neighborhood Embedding (LNE). Motivated by concepts
in contrastive learning, LNE explicitly models the similarity between
trajectory vectors across different subjects. We do so by building a graph in
each training iteration defining neighborhoods in the latent space so that the
progression direction of a subject follows the direction of its neighbors. This
results in a smooth trajectory field that captures the global morphological
change of the brain while maintaining the local continuity. We apply LNE to
longitudinal T1w MRIs of two neuroimaging studies: a dataset composed of 274
healthy subjects, and Alzheimer&#x27;s Disease Neuroimaging Initiative (ADNI,
N&#x3D;632). The visualization of the smooth trajectory vector field and superior
performance on downstream tasks demonstrate the strength of the proposed method
over existing self-supervised methods in extracting information associated with
normal aging and in revealing the impact of neurodegenerative disorders. The
code is available at
\url{https://github.com/ouyangjiahong/longitudinal-neighbourhood-embedding.git}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical Image Analysis on Left Atrial LGE MRI for Atrial Fibrillation Studies: A Review. (arXiv:2106.09862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmer_V/0/1/0/all/0/1">Veronika A. Zimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09862">
                                    <div class="article-summary-box-inner">
                                        <span>Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is commonly
used to visualize and quantify left atrial (LA) scars. The position and extent
of scars provide important information of the pathophysiology and progression
of atrial fibrillation (AF). Hence, LA scar segmentation and quantification
from LGE MRI can be useful in computer-assisted diagnosis and treatment
stratification of AF patients. Since manual delineation can be time-consuming
and subject to intra- and inter-expert variability, automating this computing
is highly desired, which nevertheless is still challenging and
under-researched.

This paper aims to provide a systematic review on computing methods for LA
cavity, wall, scar and ablation gap segmentation and quantification from LGE
MRI, and the related literature for AF studies. Specifically, we first
summarize AF-related imaging techniques, particularly LGE MRI. Then, we review
the methodologies of the four computing tasks in detail, and summarize the
validation strategies applied in each task. Finally, the possible future
developments are outlined, with a brief survey on the potential clinical
applications of the aforementioned methods. The review shows that the research
into this topic is still in early stages. Although several methods have been
proposed, especially for LA segmentation, there is still large scope for
further algorithmic developments due to performance issues related to the high
variability of enhancement appearance and differences in image acquisition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Teacher Class-Incremental Learning With Data-Free Generative Replay. (arXiv:2106.09835v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yoojin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Khamy_M/0/1/0/all/0/1">Mostafa El-Khamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungwon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09835">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes two novel knowledge transfer techniques for
class-incremental learning (CIL). First, we propose data-free generative replay
(DF-GR) to mitigate catastrophic forgetting in CIL by using synthetic samples
from a generative model. In the conventional generative replay, the generative
model is pre-trained for old data and shared in extra memory for later
incremental learning. In our proposed DF-GR, we train a generative model from
scratch without using any training data, based on the pre-trained
classification model from the past, so we curtail the cost of sharing
pre-trained generative models. Second, we introduce dual-teacher information
distillation (DT-ID) for knowledge distillation from two teachers to one
student. In CIL, we use DT-ID to learn new classes incrementally based on the
pre-trained model for old classes and another model (pre-)trained on the new
data for new classes. We implemented the proposed schemes on top of one of the
state-of-the-art CIL methods and showed the performance improvement on
CIFAR-100 and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Video Representation Learning with Cross-Stream Prototypical Contrasting. (arXiv:2106.10137v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Toering_M/0/1/0/all/0/1">Martine Toering</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatopoulos_I/0/1/0/all/0/1">Ioannis Gatopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Stol_M/0/1/0/all/0/1">Maarten Stol</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_V/0/1/0/all/0/1">Vincent Tao Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10137">
                                    <div class="article-summary-box-inner">
                                        <span>Instance-level contrastive learning techniques, which rely on data
augmentation and a contrastive loss function, have found great success in the
domain of visual representation learning. They are not suitable for exploiting
the rich dynamical structure of video however, as operations are done on many
augmented instances. In this paper we propose &quot;Video Cross-Stream Prototypical
Contrasting&quot;, a novel method which predicts consistent prototype assignments
from both RGB and optical flow views, operating on sets of samples.
Specifically, we alternate the optimization process; while optimizing one of
the streams, all views are mapped to one set of stream prototype vectors. Each
of the assignments is predicted with all views except the one matching the
prediction, pushing representations closer to their assigned prototypes. As a
result, more efficient video embeddings with ingrained motion information are
learned, without the explicit need for optical flow computation during
inference. We obtain state-of-the-art results on nearest neighbour video
retrieval and action recognition, outperforming previous best by +3.2% on
UCF101 using the S3D backbone (90.5% Top-1 acc), and by +7.2% on UCF101 and
+15.1% on HMDB51 using the R(2+1)D backbone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResDepth: Learned Residual Stereo Reconstruction. (arXiv:2001.08026v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stucker_C/0/1/0/all/0/1">Corinne Stucker</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.08026">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an embarrassingly simple but very effective scheme for
high-quality dense stereo reconstruction: (i) generate an approximate
reconstruction with your favourite stereo matcher; (ii) rewarp the input images
with that approximate model; (iii) with the initial reconstruction and the
warped images as input, train a deep network to enhance the reconstruction by
regressing a residual correction; and (iv) if desired, iterate the refinement
with the new, improved reconstruction. The strategy to only learn the residual
greatly simplifies the learning problem. A standard Unet without bells and
whistles is enough to reconstruct even small surface details, like dormers and
roof substructures in satellite images. We also investigate residual
reconstruction with less information and find that even a single image is
enough to greatly improve an approximate reconstruction. Our full model reduces
the mean absolute error of state-of-the-art stereo reconstruction systems by
&gt;50%, both in our target domain of satellite stereo and on stereo pairs from
the ETH3D benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Residual Error: a New Performance Measure for Adversarial Robustness. (arXiv:2106.10212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aboutalebi_H/0/1/0/all/0/1">Hossein Aboutalebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1">Mohammad Javad Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Karg_M/0/1/0/all/0/1">Michelle Karg</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharfenberger_C/0/1/0/all/0/1">Christian Scharfenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10212">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the significant advances in deep learning over the past decade, a
major challenge that limits the wide-spread adoption of deep learning has been
their fragility to adversarial attacks. This sensitivity to making erroneous
predictions in the presence of adversarially perturbed data makes deep neural
networks difficult to adopt for certain real-world, mission-critical
applications. While much of the research focus has revolved around adversarial
example creation and adversarial hardening, the area of performance measures
for assessing adversarial robustness is not well explored. Motivated by this,
this study presents the concept of residual error, a new performance measure
for not only assessing the adversarial robustness of a deep neural network at
the individual sample level, but also can be used to differentiate between
adversarial and non-adversarial examples to facilitate for adversarial example
detection. Furthermore, we introduce a hybrid model for approximating the
residual error in a tractable manner. Experimental results using the case of
image classification demonstrates the effectiveness and efficacy of the
proposed residual error metric for assessing several well-known deep neural
network architectures. These results thus illustrate that the proposed measure
could be a useful tool for not only assessing the robustness of deep neural
networks used in mission-critical scenarios, but also in the design of
adversarially robust models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2021: Team M3EM Technical Report. (arXiv:2106.10026v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lijin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugano_Y/0/1/0/all/0/1">Yusuke Sugano</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1">Yoichi Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10026">
                                    <div class="article-summary-box-inner">
                                        <span>In this report, we describe the technical details of our submission to the
2021 EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action
Recognition. Leveraging multiple modalities has been proved to benefit the
Unsupervised Domain Adaptation (UDA) task. In this work, we present Multi-Modal
Mutual Enhancement Module (M3EM), a deep module for jointly considering
information from multiple modalities to find the most transferable
representations across domains. We achieve this by implementing two sub-modules
for enhancing each modality using the context of other modalities. The first
sub-module exchanges information across modalities through the semantic space,
while the second sub-module finds the most transferable spatial region based on
the consensus of all modalities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partition-Guided GANs. (arXiv:2104.00816v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Armandpour_M/0/1/0/all/0/1">Mohammadreza Armandpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadeghian_A/0/1/0/all/0/1">Ali Sadeghian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00816">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of Generative Adversarial Networks (GANs), their training
suffers from several well-known problems, including mode collapse and
difficulties learning a disconnected set of manifolds. In this paper, we break
down the challenging task of learning complex high dimensional distributions,
supporting diverse data samples, to simpler sub-tasks. Our solution relies on
designing a partitioner that breaks the space into smaller regions, each having
a simpler distribution, and training a different generator for each partition.
This is done in an unsupervised manner without requiring any labels.

We formulate two desired criteria for the space partitioner that aid the
training of our mixture of generators: 1) to produce connected partitions and
2) provide a proxy of distance between partitions and data samples, along with
a direction for reducing that distance. These criteria are developed to avoid
producing samples from places with non-existent data density, and also
facilitate training by providing additional direction to the generators. We
develop theoretical constraints for a space partitioner to satisfy the above
criteria. Guided by our theoretical analysis, we design an effective neural
architecture for the space partitioner that empirically assures these
conditions. Experimental results on various standard benchmarks show that the
proposed unsupervised model outperforms several recent methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Granularity Network with Modal Attention for Dense Affective Understanding. (arXiv:2106.09964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1">Baoming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1">Ke Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1">Bo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ban_C/0/1/0/all/0/1">Chao Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09964">
                                    <div class="article-summary-box-inner">
                                        <span>Video affective understanding, which aims to predict the evoked expressions
by the video content, is desired for video creation and recommendation. In the
recent EEV challenge, a dense affective understanding task is proposed and
requires frame-level affective prediction. In this paper, we propose a
multi-granularity network with modal attention (MGN-MA), which employs
multi-granularity features for better description of the target frame.
Specifically, the multi-granularity features could be divided into frame-level,
clips-level and video-level features, which corresponds to visual-salient
content, semantic-context and video theme information. Then the modal attention
fusion module is designed to fuse the multi-granularity features and emphasize
more affection-relevant modals. Finally, the fused feature is fed into a
Mixtures Of Experts (MOE) classifier to predict the expressions. Further
employing model-ensemble post-processing, the proposed method achieves the
correlation score of 0.02292 in the EEV challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Gastric Histopathology Subsize Image Database (GasHisSDB) for Classification Algorithm Test: from Linear Regression to Visual Transformer. (arXiv:2106.02473v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahaman_M/0/1/0/all/0/1">Md Mamunur Rahaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiquan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changhao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yudong Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1">Marcin Grzegorzek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02473">
                                    <div class="article-summary-box-inner">
                                        <span>GasHisSDB is a New Gastric Histopathology Subsize Image Database with a total
of 245196 images. GasHisSDB is divided into 160*160 pixels sub-database,
120*120 pixels sub-database and 80*80 pixels sub-database. GasHisSDB is made to
realize the function of valuating image classification. In order to prove that
the methods of different periods in the field of image classification have
discrepancies on GasHisSDB, we select a variety of classifiers for evaluation.
Seven classical machine learning classifiers, three CNN classifiers and a novel
transformer-based classifier are selected for testing on image classification
tasks. GasHisSDB is available at the
URL:https://github.com/NEUhwm/GasHisSDB.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing Adversarial Robustness of Deep Neural Networks in Pixel Space: a Semantic Perspective. (arXiv:2106.09872v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yawei Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xuemei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09872">
                                    <div class="article-summary-box-inner">
                                        <span>The vulnerability of deep neural networks to adversarial examples, which are
crafted maliciously by modifying the inputs with imperceptible perturbations to
misled the network produce incorrect outputs, reveals the lack of robustness
and poses security concerns. Previous works study the adversarial robustness of
image classifiers on image level and use all the pixel information in an image
indiscriminately, lacking of exploration of regions with different semantic
meanings in the pixel space of an image. In this work, we fill this gap and
explore the pixel space of the adversarial image by proposing an algorithm to
looking for possible perturbations pixel by pixel in different regions of the
segmented image. The extensive experimental results on CIFAR-10 and ImageNet
verify that searching for the modified pixel in only some pixels of an image
can successfully launch the one-pixel adversarial attacks without requiring all
the pixels of the entire image, and there exist multiple vulnerable points
scattered in different regions of an image. We also demonstrate that the
adversarial robustness of different regions on the image varies with the amount
of semantic information contained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIR: Self-supervised Image Rectification via Seeing the Same Scene from Multiple Different Lenses. (arXiv:2011.14611v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jinlong Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14611">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has demonstrated its power in image rectification by leveraging
the representation capacity of deep neural networks via supervised training
based on a large-scale synthetic dataset. However, the model may overfit the
synthetic images and generalize not well on real-world fisheye images due to
the limited universality of a specific distortion model and the lack of
explicitly modeling the distortion and rectification process. In this paper, we
propose a novel self-supervised image rectification (SIR) method based on an
important insight that the rectified results of distorted images of a same
scene from different lens should be the same. Specifically, we devise a new
network architecture with a shared encoder and several prediction heads, each
of which predicts the distortion parameter of a specific distortion model. We
further leverage a differentiable warping module to generate the rectified
images and re-distorted images from the distortion parameters and exploit the
intra- and inter-model consistency between them during training, thereby
leading to a self-supervised learning scheme without the need for ground-truth
distortion parameters or normal images. Experiments on synthetic dataset and
real-world fisheye images demonstrate that our method achieves comparable or
even better performance than the supervised baseline method and representative
state-of-the-art methods. Self-supervised learning also improves the
universality of distortion models while keeping their self-consistency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GEM: A General Evaluation Benchmark for Multimodal Tasks. (arXiv:2106.09889v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Lin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_E/0/1/0/all/0/1">Edward Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Huaishao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1">Ming Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharti_T/0/1/0/all/0/1">Taroon Bharti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sacheti_A/0/1/0/all/0/1">Arun Sacheti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09889">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present GEM as a General Evaluation benchmark for
Multimodal tasks. Different from existing datasets such as GLUE, SuperGLUE,
XGLUE and XTREME that mainly focus on natural language tasks, GEM is a
large-scale vision-language benchmark, which consists of GEM-I for
image-language tasks and GEM-V for video-language tasks. Comparing with
existing multimodal datasets such as MSCOCO and Flicker30K for image-language
tasks, YouCook2 and MSR-VTT for video-language tasks, GEM is not only the
largest vision-language dataset covering image-language tasks and
video-language tasks at the same time, but also labeled in multiple languages.
We also provide two baseline models for this benchmark. We will release the
dataset, code and baseline models, aiming to advance the development of
multilingual multimodal research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facial Expressions as a Vulnerability in Face Recognition. (arXiv:2011.08809v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pena_A/0/1/0/all/0/1">Alejandro Pe&#xf1;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Serna_I/0/1/0/all/0/1">Ignacio Serna</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapedriza_A/0/1/0/all/0/1">Agata Lapedriza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08809">
                                    <div class="article-summary-box-inner">
                                        <span>This work explores facial expression bias as a security vulnerability of face
recognition systems. Despite the great performance achieved by state-of-the-art
face recognition systems, the algorithms are still sensitive to a large range
of covariates. We present a comprehensive analysis of how facial expression
bias impacts the performance of face recognition technologies. Our study
analyzes: i) facial expression biases in the most popular face recognition
databases; and ii) the impact of facial expression in face recognition
performances. Our experimental framework includes two face detectors, three
face recognition models, and three different databases. Our results demonstrate
a huge facial expression bias in the most widely used databases, as well as a
related impact of face expression in the performance of state-of-the-art
algorithms. This work opens the door to new research lines focused on
mitigating the observed vulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge Computing for Real-Time Near-Crash Detection for Smart Transportation Applications. (arXiv:2008.00549v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_R/0/1/0/all/0/1">Ruimin Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhiyong Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Meixin Zhu</a>, Hao (Frank) <a href="http://arxiv.org/find/cs/1/au:+Yang/0/1/0/all/0/1">Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yinhai Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00549">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic near-crash events serve as critical data sources for various smart
transportation applications, such as being surrogate safety measures for
traffic safety research and corner case data for automated vehicle testing.
However, there are several key challenges for near-crash detection. First,
extracting near-crashes from original data sources requires significant
computing, communication, and storage resources. Also, existing methods lack
efficiency and transferability, which bottlenecks prospective large-scale
applications. To this end, this paper leverages the power of edge computing to
address these challenges by processing the video streams from existing dashcams
onboard in a real-time manner. We design a multi-thread system architecture
that operates on edge devices and model the bounding boxes generated by object
detection and tracking in linear complexity. The method is insensitive to
camera parameters and backward compatible with different vehicles. The edge
computing system has been evaluated with recorded videos and real-world tests
on two cars and four buses for over ten thousand hours. It filters out
irrelevant videos in real-time thereby saving labor cost, processing time,
network bandwidth, and data storage. It collects not only event videos but also
other valuable data such as road user type, event location, time to collision,
vehicle trajectory, vehicle speed, brake switch, and throttle. The experiments
demonstrate the promising performance of the system regarding efficiency,
accuracy, reliability, and transferability. It is among the first efforts in
applying edge computing for real-time traffic video analytics and is expected
to benefit multiple sub-fields in smart transportation research and
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embodied Language Grounding with 3D Visual Feature Representations. (arXiv:1910.01210v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Prabhudesai_M/0/1/0/all/0/1">Mihir Prabhudesai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_H/0/1/0/all/0/1">Hsiao-Yu Fish Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Javed_S/0/1/0/all/0/1">Syed Ashar Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Sieb_M/0/1/0/all/0/1">Maximilian Sieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Harley_A/0/1/0/all/0/1">Adam W. Harley</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1">Katerina Fragkiadaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.01210">
                                    <div class="article-summary-box-inner">
                                        <span>We propose associating language utterances to 3D visual abstractions of the
scene they describe. The 3D visual abstractions are encoded as 3-dimensional
visual feature maps. We infer these 3D visual scene feature maps from RGB
images of the scene via view prediction: when the generated 3D scene feature
map is neurally projected from a camera viewpoint, it should match the
corresponding RGB image. We present generative models that condition on the
dependency tree of an utterance and generate a corresponding visual 3D feature
map as well as reason about its plausibility, and detector models that
condition on both the dependency tree of an utterance and a related image and
localize the object referents in the 3D feature map inferred from the image.
Our model outperforms models of language and vision that associate language
with 2D CNN activations or 2D images by a large margin in a variety of tasks,
such as, classifying plausibility of utterances, detecting referential
expressions, and supplying rewards for trajectory optimization of object
placement policies from language instructions. We perform numerous ablations
and show the improved performance of our detectors is due to its better
generalization across camera viewpoints and lack of object interferences in the
inferred 3D feature space, and the improved performance of our generators is
due to their ability to spatially reason about objects and their configurations
in 3D when mapping from language to scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Radar Camera Fusion via Representation Learning in Autonomous Driving. (arXiv:2103.07825v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Binnan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yunxiang Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Langechuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07825">
                                    <div class="article-summary-box-inner">
                                        <span>Radars and cameras are mature, cost-effective, and robust sensors and have
been widely used in the perception stack of mass-produced autonomous driving
systems. Due to their complementary properties, outputs from radar detection
(radar pins) and camera perception (2D bounding boxes) are usually fused to
generate the best perception results. The key to successful radar-camera fusion
is the accurate data association. The challenges in the radar-camera
association can be attributed to the complexity of driving scenes, the noisy
and sparse nature of radar measurements, and the depth ambiguity from 2D
bounding boxes. Traditional rule-based association methods are susceptible to
performance degradation in challenging scenarios and failure in corner cases.
In this study, we propose to address radar-camera association via deep
representation learning, to explore feature-level interaction and global
reasoning. Additionally, we design a loss sampling mechanism and an innovative
ordinal loss to overcome the difficulty of imperfect labeling and to enforce
critical human-like reasoning. Despite being trained with noisy labels
generated by a rule-based algorithm, our proposed method achieves a performance
of 92.2% F1 score, which is 11.6% higher than the rule-based teacher. Moreover,
this data-driven method also lends itself to continuous improvement via corner
case mining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End 3D Point Cloud Learning for Registration Task Using Virtual Correspondences. (arXiv:2011.14579v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1">Zhijian Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Huanshu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Suo_C/0/1/0/all/0/1">Chuanzhe Suo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hesheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14579">
                                    <div class="article-summary-box-inner">
                                        <span>3D Point cloud registration is still a very challenging topic due to the
difficulty in finding the rigid transformation between two point clouds with
partial correspondences, and it&#x27;s even harder in the absence of any initial
estimation information. In this paper, we present an end-to-end deep-learning
based approach to resolve the point cloud registration problem. Firstly, the
revised LPD-Net is introduced to extract features and aggregate them with the
graph network. Secondly, the self-attention mechanism is utilized to enhance
the structure information in the point cloud and the cross-attention mechanism
is designed to enhance the corresponding information between the two input
point clouds. Based on which, the virtual corresponding points can be generated
by a soft pointer based method, and finally, the point cloud registration
problem can be solved by implementing the SVD method. Comparison results in
ModelNet40 dataset validate that the proposed approach reaches the
state-of-the-art in point cloud registration tasks and experiment resutls in
KITTI dataset validate the effectiveness of the proposed approach in real
applications.Our source code is available at
\url{https://github.com/qiaozhijian/VCR-Net.git}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Steerable Partial Differential Operators for Equivariant Neural Networks. (arXiv:2106.10163v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jenner_E/0/1/0/all/0/1">Erik Jenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1">Maurice Weiler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10163">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work in equivariant deep learning bears strong similarities to
physics. Fields over a base space are fundamental entities in both subjects, as
are equivariant maps between these fields. In deep learning, however, these
maps are usually defined by convolutions with a kernel, whereas they are
partial differential operators (PDOs) in physics. Developing the theory of
equivariant PDOs in the context of deep learning could bring these subjects
even closer together and lead to a stronger flow of ideas. In this work, we
derive a $G$-steerability constraint that completely characterizes when a PDO
between feature vector fields is equivariant, for arbitrary symmetry groups
$G$. We then fully solve this constraint for several important groups. We use
our solutions as equivariant drop-in replacements for convolutional layers and
benchmark them in that role. Finally, we develop a framework for equivariant
maps based on Schwartz distributions that unifies classical convolutions and
differential operators and gives insight about the relation between the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Clustering-friendly Representations: Subspace Clustering via Graph Filtering. (arXiv:2106.09874v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhengrui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guangchun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09874">
                                    <div class="article-summary-box-inner">
                                        <span>Finding a suitable data representation for a specific task has been shown to
be crucial in many applications. The success of subspace clustering depends on
the assumption that the data can be separated into different subspaces.
However, this simple assumption does not always hold since the raw data might
not be separable into subspaces. To recover the &#x60;&#x60;clustering-friendly&#x27;&#x27;
representation and facilitate the subsequent clustering, we propose a graph
filtering approach by which a smooth representation is achieved. Specifically,
it injects graph similarity into data features by applying a low-pass filter to
extract useful data representations for clustering. Extensive experiments on
image and document clustering datasets demonstrate that our method improves
upon state-of-the-art subspace clustering techniques. Especially, its
comparable performance with deep learning methods emphasizes the effectiveness
of the simple graph filtering scheme for many real-world applications. An
ablation study shows that graph filtering can remove noise, preserve structure
in the image, and increase the separability of classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Graph based Trajectory Predictor with Pseudo Oracle. (arXiv:2002.00391v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Biao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1">Guocheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1">Chingyao Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xiang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00391">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian trajectory prediction in dynamic scenes remains a challenging and
critical problem in numerous applications, such as self-driving cars and
socially aware robots. Challenges concentrate on capturing pedestrians&#x27; motion
patterns and social interactions, as well as handling the future uncertainties.
Recent studies focus on modeling pedestrians&#x27; motion patterns with recurrent
neural networks, capturing social interactions with pooling-based or
graph-based methods, and handling future uncertainties by using random Gaussian
noise as the latent variable. However, they do not integrate specific obstacle
avoidance experience (OAE) that may improve prediction performance. For
example, pedestrians&#x27; future trajectories are always influenced by others in
front. Here we propose GTPPO (Graph-based Trajectory Predictor with Pseudo
Oracle), an encoder-decoder-based method conditioned on pedestrians&#x27; future
behaviors. Pedestrians&#x27; motion patterns are encoded with a long short-term
memory unit, which introduces the temporal attention to highlight specific time
steps. Their interactions are captured by a graph-based attention mechanism,
which draws OAE into the data-driven learning process of graph attention.
Future uncertainties are handled by generating multi-modal outputs with an
informative latent variable. Such a variable is generated by a novel pseudo
oracle predictor, which minimizes the knowledge gap between historical and
ground-truth trajectories. Finally, the GTPPO is evaluated on ETH, UCY and
Stanford Drone datasets, and the results demonstrate state-of-the-art
performance. Besides, the qualitative evaluations show successful cases of
handling sudden motion changes in the future. Such findings indicate that GTPPO
can peek into the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source Domain Adaptation with Collaborative Learning for Semantic Segmentation. (arXiv:2103.04717v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jianzhong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xu Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuaijun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jianzhuang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04717">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-source unsupervised domain adaptation~(MSDA) aims at adapting models
trained on multiple labeled source domains to an unlabeled target domain. In
this paper, we propose a novel multi-source domain adaptation framework based
on collaborative learning for semantic segmentation. Firstly, a simple image
translation method is introduced to align the pixel value distribution to
reduce the gap between source domains and target domain to some extent. Then,
to fully exploit the essential semantic information across source domains, we
propose a collaborative learning method for domain adaptation without seeing
any data from target domain. In addition, similar to the setting of
unsupervised domain adaptation, unlabeled target domain data is leveraged to
further improve the performance of domain adaptation. This is achieved by
additionally constraining the outputs of multiple adaptation models with pseudo
labels online generated by an ensembled model. Extensive experiments and
ablation studies are conducted on the widely-used domain adaptation benchmark
datasets in semantic segmentation. Our proposed method achieves 59.0\% mIoU on
the validation set of Cityscapes by training on the labeled Synscapes and GTA5
datasets and unlabeled training set of Cityscapes. It significantly outperforms
all previous state-of-the-arts single-source and multi-source unsupervised
domain adaptation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Diverse-Structured Networks for Adversarial Robustness. (arXiv:2102.01886v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xuefeng Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01886">
                                    <div class="article-summary-box-inner">
                                        <span>In adversarial training (AT), the main focus has been the objective and
optimizer while the model has been less studied, so that the models being used
are still those classic ones in standard training (ST). Classic network
architectures (NAs) are generally worse than searched NAs in ST, which should
be the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NAs in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best one in a searched block of DS-Net, which is an essential trade-off between
exploring diverse structures and exploiting the best structures. Empirical
results demonstrate the advantages of DS-Net, i.e., weighting the atomic
blocks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CT Image Synthesis Using Weakly Supervised Segmentation and Geometric Inter-Label Relations For COVID Image Analysis. (arXiv:2106.10230v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mahapatra_D/0/1/0/all/0/1">Dwarikanath Mahapatra</a>, <a href="http://arxiv.org/find/eess/1/au:+Singh_A/0/1/0/all/0/1">Ankur Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10230">
                                    <div class="article-summary-box-inner">
                                        <span>While medical image segmentation is an important task for computer aided
diagnosis, the high expertise requirement for pixelwise manual annotations
makes it a challenging and time consuming task. Since conventional data
augmentations do not fully represent the underlying distribution of the
training set, the trained models have varying performance when tested on images
captured from different sources. Most prior work on image synthesis for data
augmentation ignore the interleaved geometric relationship between different
anatomical labels. We propose improvements over previous GAN-based medical
image synthesis methods by learning the relationship between different
anatomical labels. We use a weakly supervised segmentation method to obtain
pixel level semantic label map of images which is used learn the intrinsic
relationship of geometry and shape across semantic labels. Latent space
variable sampling results in diverse generated images from a base image and
improves robustness. We use the synthetic images from our method to train
networks for segmenting COVID-19 infected areas from lung CT images. The
proposed method outperforms state-of-the-art segmentation methods on a public
dataset. Ablation studies also demonstrate benefits of integrating geometry and
diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Reuse and Fusion for Real-time Semantic segmentation. (arXiv:2105.12964v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sixiang_T/0/1/0/all/0/1">Tan Sixiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12964">
                                    <div class="article-summary-box-inner">
                                        <span>For real-time semantic segmentation, how to increase the speed while
maintaining high resolution is a problem that has been discussed and solved.
Backbone design and fusion design have always been two essential parts of
real-time semantic segmentation. We hope to design a light-weight network based
on previous design experience and reach the level of state-of-the-art real-time
semantic segmentation without any pre-training. To achieve this goal, a
encoder-decoder architectures are proposed to solve this problem by applying a
decoder network onto a backbone model designed for real-time segmentation tasks
and designed three different ways to fuse semantics and detailed information in
the aggregation phase. We have conducted extensive experiments on two semantic
segmentation benchmarks. Experiments on the Cityscapes and CamVid datasets show
that the proposed FRFNet strikes a balance between speed calculation and
accuracy. It achieves 72% Mean Intersection over Union (mIoU%) on the
Cityscapes test dataset with the speed of 144 on a single RTX 1080Ti card. The
Code is available at https://github.com/favoMJ/FRFNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic segmentation of multispectral photoacoustic images using deep learning. (arXiv:2105.09624v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Grohl_J/0/1/0/all/0/1">Janek Gr&#xf6;hl</a>, <a href="http://arxiv.org/find/eess/1/au:+Schellenberg_M/0/1/0/all/0/1">Melanie Schellenberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Dreher_K/0/1/0/all/0/1">Kris Dreher</a>, <a href="http://arxiv.org/find/eess/1/au:+Holzwarth_N/0/1/0/all/0/1">Niklas Holzwarth</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizabi_M/0/1/0/all/0/1">Minu D. Tizabi</a>, <a href="http://arxiv.org/find/eess/1/au:+Seitel_A/0/1/0/all/0/1">Alexander Seitel</a>, <a href="http://arxiv.org/find/eess/1/au:+Maier_Hein_L/0/1/0/all/0/1">Lena Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09624">
                                    <div class="article-summary-box-inner">
                                        <span>Photoacoustic imaging has the potential to revolutionise healthcare due to
the valuable information on tissue physiology that is contained in
multispectral photoacoustic measurements. Clinical translation of the
technology requires conversion of the high-dimensional acquired data into
clinically relevant and interpretable information. In this work, we present a
deep learning-based approach to semantic segmentation of multispectral
photoacoustic images to facilitate the interpretability of recorded images.
Manually annotated multispectral photoacoustic imaging data are used as gold
standard reference annotations and enable the training of a deep learning-based
segmentation algorithm in a supervised manner. Based on a validation study with
experimentally acquired data of healthy human volunteers, we show that
automatic tissue segmentation can be used to create powerful analyses and
visualisations of multispectral photoacoustic images. Due to the intuitive
representation of high-dimensional information, such a processing algorithm
could be a valuable means to facilitate the clinical translation of
photoacoustic imaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dynamic Spatial-temporal Attention Network for Early Anticipation of Traffic Accidents. (arXiv:2106.10197v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Muhammad Monjurul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Ruwen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhaozheng Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10197">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, autonomous vehicles and those equipped with an Advanced Driver
Assistance System (ADAS) are emerging. They share the road with regular ones
operated by human drivers entirely. To ensure guaranteed safety for passengers
and other road users, it becomes essential for autonomous vehicles and ADAS to
anticipate traffic accidents from natural driving scenes. The dynamic
spatial-temporal interaction of the traffic agents is complex, and visual cues
for predicting a future accident are embedded deeply in dashcam video data.
Therefore, early anticipation of traffic accidents remains a challenge. To this
end, the paper presents a dynamic spatial-temporal attention (DSTA) network for
early anticipation of traffic accidents from dashcam videos. The proposed
DSTA-network learns to select discriminative temporal segments of a video
sequence with a module named Dynamic Temporal Attention (DTA). It also learns
to focus on the informative spatial regions of frames with another module named
Dynamic Spatial Attention (DSA). The spatial-temporal relational features of
accidents, along with scene appearance features, are learned jointly with a
Gated Recurrent Unit (GRU) network. The experimental evaluation of the
DSTA-network on two benchmark datasets confirms that it has exceeded the
state-of-the-art performance. A thorough ablation study evaluates the
contributions of individual components of the DSTA-network, revealing how the
network achieves such performance. Furthermore, this paper proposes a new
strategy that fuses the prediction scores from two complementary models and
verifies its effectiveness in further boosting the performance of early
accident anticipation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning. (arXiv:2101.08482v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhaowei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1">Avinash Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1">Charless Fowlkes</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08482">
                                    <div class="article-summary-box-inner">
                                        <span>We present a plug-in replacement for batch normalization (BN) called
exponential moving average normalization (EMAN), which improves the performance
of existing student-teacher based self- and semi-supervised learning
techniques. Unlike the standard BN, where the statistics are computed within
each batch, EMAN, used in the teacher, updates its statistics by exponential
moving average from the BN statistics of the student. This design reduces the
intrinsic cross-sample dependency of BN and enhances the generalization of the
teacher. EMAN improves strong baselines for self-supervised learning by 4-6/1-2
points and semi-supervised learning by about 7/2 points, when 1%/10% supervised
labels are available on ImageNet. These improvements are consistent across
methods, network architectures, training duration, and datasets, demonstrating
the general effectiveness of this technique. The code is available at
https://github.com/amazon-research/exponential-moving-average-normalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Level Set Stereo for Cooperative Grouping with Occlusion. (arXiv:2006.16094v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jialiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zickler_T/0/1/0/all/0/1">Todd Zickler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16094">
                                    <div class="article-summary-box-inner">
                                        <span>Localizing stereo boundaries is difficult because matching cues are absent in
the occluded regions that are adjacent to them. We introduce an energy and
level-set optimizer that improves boundaries by encoding the essential geometry
of occlusions: The spatial extent of an occlusion must equal the amplitude of
the disparity jump that causes it. In a collection of figure-ground scenes from
Middlebury and Falling Things stereo datasets, the model provides more accurate
boundaries than previous occlusion-handling techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discerning Generic Event Boundaries in Long-Form Wild Videos. (arXiv:2106.10090v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rai_A/0/1/0/all/0/1">Ayush K Rai</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_T/0/1/0/all/0/1">Tarun Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Dietlmeier_J/0/1/0/all/0/1">Julia Dietlmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1">Kevin McGuinness</a>, <a href="http://arxiv.org/find/cs/1/au:+Smeaton_A/0/1/0/all/0/1">Alan F Smeaton</a>, <a href="http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1">Noel E O&#x27;Connor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10090">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting generic, taxonomy-free event boundaries invideos represents a major
stride forward towards holisticvideo understanding. In this paper we present a
technique forgeneric event boundary detection based on a two stream in-flated
3D convolutions architecture, which can learn spatio-temporal features from
videos. Our work is inspired from theGeneric Event Boundary Detection Challenge
(part of CVPR2021 Long Form Video Understanding- LOVEU Workshop).Throughout the
paper we provide an in-depth analysis ofthe experiments performed along with an
interpretation ofthe results obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Iterative Phase Retrieval With Cascaded Neural Networks. (arXiv:2106.10195v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Uelwer_T/0/1/0/all/0/1">Tobias Uelwer</a>, <a href="http://arxiv.org/find/eess/1/au:+Hoffmann_T/0/1/0/all/0/1">Tobias Hoffmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Harmeling_S/0/1/0/all/0/1">Stefan Harmeling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10195">
                                    <div class="article-summary-box-inner">
                                        <span>Fourier phase retrieval is the problem of reconstructing a signal given only
the magnitude of its Fourier transformation. Optimization-based approaches,
like the well-established Gerchberg-Saxton or the hybrid input output
algorithm, struggle at reconstructing images from magnitudes that are not
oversampled. This motivates the application of learned methods, which allow
reconstruction from non-oversampled magnitude measurements after a learning
phase. In this paper, we want to push the limits of these learned methods by
means of a deep neural network cascade that reconstructs the image successively
on different resolutions from its non-oversampled Fourier magnitude. We
evaluate our method on four different datasets (MNIST, EMNIST, Fashion-MNIST,
and KMNIST) and demonstrate that it yields improved performance over other
non-iterative methods and optimization-based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SLSNet: Skin lesion segmentation using a lightweight generative adversarial network. (arXiv:1907.00856v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sarker_M/0/1/0/all/0/1">Md. Mostafa Kamal Sarker</a>, <a href="http://arxiv.org/find/eess/1/au:+Rashwan_H/0/1/0/all/0/1">Hatem A. Rashwan</a>, <a href="http://arxiv.org/find/eess/1/au:+Akram_F/0/1/0/all/0/1">Farhan Akram</a>, <a href="http://arxiv.org/find/eess/1/au:+Singh_V/0/1/0/all/0/1">Vivek Kumar Singh</a>, <a href="http://arxiv.org/find/eess/1/au:+Banu_S/0/1/0/all/0/1">Syeda Furruka Banu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhury_F/0/1/0/all/0/1">Forhad U H Chowdhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Choudhury_K/0/1/0/all/0/1">Kabir Ahmed Choudhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Chambon_S/0/1/0/all/0/1">Sylvie Chambon</a>, <a href="http://arxiv.org/find/eess/1/au:+Radeva_P/0/1/0/all/0/1">Petia Radeva</a>, <a href="http://arxiv.org/find/eess/1/au:+Puig_D/0/1/0/all/0/1">Domenec Puig</a>, <a href="http://arxiv.org/find/eess/1/au:+Abdel_Nasser_M/0/1/0/all/0/1">Mohamed Abdel-Nasser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.00856">
                                    <div class="article-summary-box-inner">
                                        <span>The determination of precise skin lesion boundaries in dermoscopic images
using automated methods faces many challenges, most importantly, the presence
of hair, inconspicuous lesion edges and low contrast in dermoscopic images, and
variability in the color, texture and shapes of skin lesions. Existing deep
learning-based skin lesion segmentation algorithms are expensive in terms of
computational time and memory. Consequently, running such segmentation
algorithms requires a powerful GPU and high bandwidth memory, which are not
available in dermoscopy devices. Thus, this article aims to achieve precise
skin lesion segmentation with minimum resources: a lightweight, efficient
generative adversarial network (GAN) model called SLSNet, which combines 1-D
kernel factorized networks, position and channel attention, and multiscale
aggregation mechanisms with a GAN model. The 1-D kernel factorized network
reduces the computational cost of 2D filtering. The position and channel
attention modules enhance the discriminative ability between the lesion and
non-lesion feature representations in spatial and channel dimensions,
respectively. A multiscale block is also used to aggregate the coarse-to-fine
features of input skin images and reduce the effect of the artifacts. SLSNet is
evaluated on two publicly available datasets: ISBI 2017 and the ISIC 2018.
Although SLSNet has only 2.35 million parameters, the experimental results
demonstrate that it achieves segmentation results on a par with the
state-of-the-art skin lesion segmentation methods with an accuracy of 97.61%,
and Dice and Jaccard similarity coefficients of 90.63% and 81.98%,
respectively. SLSNet can run at more than 110 frames per second (FPS) in a
single GTX1080Ti GPU, which is faster than well-known deep learning-based image
segmentation models, such as FCN. Therefore, SLSNet can be used for practical
dermoscopic applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Generalization in Deep Learning Applications for Land Cover Mapping. (arXiv:2008.10351v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lucas Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10351">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that deep learning models can be used to classify
land-use data from geospatial satellite imagery. We show that when these deep
learning models are trained on data from specific continents/seasons, there is
a high degree of variability in model performance on out-of-sample
continents/seasons. This suggests that just because a model accurately predicts
land-use classes in one continent or season does not mean that the model will
accurately predict land-use classes in a different continent or season. We then
use clustering techniques on satellite imagery from different continents to
visualize the differences in landscapes that make geospatial generalization
particularly difficult, and summarize our takeaways for future satellite
imagery-related applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Pollution Reduction in Nighttime Photography. (arXiv:2106.10046v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaolin Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10046">
                                    <div class="article-summary-box-inner">
                                        <span>Nighttime photographers are often troubled by light pollution of unwanted
artificial lights. Artificial lights, after scattered by aerosols in the
atmosphere, can inundate the starlight and degrade the quality of nighttime
images, by reducing contrast and dynamic range and causing hazes. In this paper
we develop a physically-based light pollution reduction (LPR) algorithm that
can substantially alleviate the aforementioned degradations of perceptual
quality and restore the pristine state of night sky. The key to the success of
the proposed LPR algorithm is an inverse method to estimate the spatial
radiance distribution and spectral signature of ground artificial lights.
Extensive experiments are carried out to evaluate the efficacy and limitations
of the LPR algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning. (arXiv:2102.04960v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Huan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuecheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1">Rong Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04960">
                                    <div class="article-summary-box-inner">
                                        <span>Place recognition is critical for both offline mapping and online
localization. However, current single-sensor based place recognition still
remains challenging in adverse conditions. In this paper, a heterogeneous
measurements based framework is proposed for long-term place recognition, which
retrieves the query radar scans from the existing lidar maps. To achieve this,
a deep neural network is built with joint training in the learning stage, and
then in the testing stage, shared embeddings of radar and lidar are extracted
for heterogeneous place recognition. To validate the effectiveness of the
proposed method, we conduct tests and generalization experiments on the
multi-session public datasets compared to other competitive methods. The
experimental results indicate that our model is able to perform multiple place
recognitions: lidar-to-lidar, radar-to-radar and radar-to-lidar, while the
learned model is trained only once. We also release the source code publicly:
https://github.com/ZJUYH/radar-to-lidar-place-recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise2Sim -- Similarity-based Self-Learning for Image Denoising. (arXiv:2011.03384v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_C/0/1/0/all/0/1">Chuang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1">Fenglei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03384">
                                    <div class="article-summary-box-inner">
                                        <span>Despite its best performance in image denoising, the supervised deep
denoising methods require paired noise-clean data, which are often unavailable.
To address this challenge, Noise2Noise was designed based on the fact that
paired noise-clean images can be replaced by paired noise-noise images that are
easier to collect. However, in many scenarios the collection of paired
noise-noise images is still impractical. To bypass labeled images, Noise2Void
methods predict masked pixels from their surroundings with single noisy images
only and give improved denoising results that still need improvements. An
observation on classic denoising methods is that non-local mean (NLM) outcomes
are typically superior to locally denoised results. In contrast, Noise2Void and
its variants do not utilize self-similarities in an image as the NLM-based
methods do. Here we propose Noise2Sim, an NLM-inspired self-learning method for
image denoising. Specifically, Noise2Sim leverages the self-similarity of image
pixels to train the denoising network, requiring single noisy images only. Our
theoretical analysis shows that Noise2Sim tends to be equivalent to Noise2Noise
under mild conditions. To efficiently manage the computational burden for
globally searching similar pixels, we design a two-step procedure to provide
data for Noise2Sim training. Extensive experiments demonstrate the superiority
of Noise2Sim on common benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No Routing Needed Between Capsules. (arXiv:2001.09136v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Byerly_A/0/1/0/all/0/1">Adam Byerly</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalganova_T/0/1/0/all/0/1">Tatiana Kalganova</a>, <a href="http://arxiv.org/find/cs/1/au:+Dear_I/0/1/0/all/0/1">Ian Dear</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09136">
                                    <div class="article-summary-box-inner">
                                        <span>Most capsule network designs rely on traditional matrix multiplication
between capsule layers and computationally expensive routing mechanisms to deal
with the capsule dimensional entanglement that the matrix multiplication
introduces. By using Homogeneous Vector Capsules (HVCs), which use element-wise
multiplication rather than matrix multiplication, the dimensions of the
capsules remain unentangled. In this work, we study HVCs as applied to the
highly structured MNIST dataset in order to produce a direct comparison to the
capsule research direction of Geoffrey Hinton, et al. In our study, we show
that a simple convolutional neural network using HVCs performs as well as the
prior best performing capsule network on MNIST using 5.5x fewer parameters, 4x
fewer training epochs, no reconstruction sub-network, and requiring no routing
mechanism. The addition of multiple classification branches to the network
establishes a new state of the art for the MNIST dataset with an accuracy of
99.87% for an ensemble of these models, as well as establishing a new state of
the art for a single model (99.83% accurate).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training or Architecture? How to Incorporate Invariance in Neural Networks. (arXiv:2106.10044v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gandikota_K/0/1/0/all/0/1">Kanchana Vaishnavi Gandikota</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahner_Z/0/1/0/all/0/1">Zorah L&#xe4;hner</a>, <a href="http://arxiv.org/find/cs/1/au:+Czaplinski_A/0/1/0/all/0/1">Adam Czapli&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10044">
                                    <div class="article-summary-box-inner">
                                        <span>Many applications require the robustness, or ideally the invariance, of a
neural network to certain transformations of input data. Most commonly, this
requirement is addressed by either augmenting the training data, using
adversarial training, or defining network architectures that include the
desired invariance automatically. Unfortunately, the latter often relies on the
ability to enlist all possible transformations, which make such approaches
largely infeasible for infinite sets of transformations, such as arbitrary
rotations or scaling. In this work, we propose a method for provably invariant
network architectures with respect to group actions by choosing one element
from a (possibly continuous) orbit based on a fixed criterion. In a nutshell,
we intend to &#x27;undo&#x27; any possible transformation before feeding the data into
the actual network. We analyze properties of such approaches, extend them to
equivariant networks, and demonstrate their advantages in terms of robustness
as well as computational efficiency in several numerical examples. In
particular, we investigate the robustness with respect to rotations of images
(which can possibly hold up to discretization artifacts only) as well as the
provable rotational and scaling invariance of 3D point cloud classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the Gap Between Object Detection and User Intent via Query-Modulation. (arXiv:2106.10258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fornoni_M/0/1/0/all/0/1">Marco Fornoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chaochao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Liangchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilber_K/0/1/0/all/0/1">Kimberly Wilber</a>, <a href="http://arxiv.org/find/cs/1/au:+Stark_A/0/1/0/all/0/1">Alex Stark</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Howard_A/0/1/0/all/0/1">Andrew Howard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10258">
                                    <div class="article-summary-box-inner">
                                        <span>When interacting with objects through cameras, or pictures, users often have
a specific intent. For example, they may want to perform a visual search.
However, most object detection models ignore the user intent, relying on image
pixels as their only input. This often leads to incorrect results, such as lack
of a high-confidence detection on the object of interest, or detection with a
wrong class label. In this paper we investigate techniques to modulate standard
object detectors to explicitly account for the user intent, expressed as an
embedding of a simple query. Compared to standard object detectors,
query-modulated detectors show superior performance at detecting objects for a
given label of interest. Thanks to large-scale training data synthesized from
standard object detection annotations, query-modulated detectors can also
outperform specialized referring expression recognition systems. Furthermore,
they can be simultaneously trained to solve for both query-modulated detection
and standard object detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VSAC: Efficient and Accurate Estimator for H and F. (arXiv:2106.10240v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ivashechkin_M/0/1/0/all/0/1">Maksym Ivashechkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Barath_D/0/1/0/all/0/1">Daniel Barath</a>, <a href="http://arxiv.org/find/cs/1/au:+Matas_J/0/1/0/all/0/1">Jiri Matas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10240">
                                    <div class="article-summary-box-inner">
                                        <span>We present VSAC, a RANSAC-type robust estimator with a number of novelties.
It benefits from the introduction of the concept of independent inliers that
improves significantly the efficacy of the dominant plane handling and, also,
allows near error-free rejection of incorrect models, without false positives.
The local optimization process and its application is improved so that it is
run on average only once. Further technical improvements include adaptive
sequential hypothesis verification and efficient model estimation via Gaussian
elimination. Experiments on four standard datasets show that VSAC is
significantly faster than all its predecessors and runs on average in 1-2 ms,
on a CPU. It is two orders of magnitude faster and yet as precise as MAGSAC++,
the currently most accurate estimator of two-view geometry. In the repeated
runs on EVD, HPatches, PhotoTourism, and Kusvod2 datasets, it never failed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">hSMAL: Detailed Horse Shape and Pose Reconstruction for Motion Pattern Recognition. (arXiv:2106.10102v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Ci Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghorbani_N/0/1/0/all/0/1">Nima Ghorbani</a>, <a href="http://arxiv.org/find/cs/1/au:+Broome_S/0/1/0/all/0/1">Sofia Broom&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1">Maheen Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernlund_E/0/1/0/all/0/1">Elin Hernlund</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuffi_S/0/1/0/all/0/1">Silvia Zuffi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10102">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present our preliminary work on model-based behavioral
analysis of horse motion. Our approach is based on the SMAL model, a 3D
articulated statistical model of animal shape. We define a novel SMAL model for
horses based on a new template, skeleton and shape space learned from $37$
horse toys. We test the accuracy of our hSMAL model in reconstructing a horse
from 3D mocap data and images. We apply the hSMAL model to the problem of
lameness detection from video, where we fit the model to images to recover 3D
pose and train an ST-GCN network on pose data. A comparison with the same
network trained on mocap points illustrates the benefit of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Coarse-to-Fine Instance Segmentation Network with Learning Boundary Representation. (arXiv:2106.10213v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Feng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1">Bin-Bin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jiangpeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10213">
                                    <div class="article-summary-box-inner">
                                        <span>Boundary-based instance segmentation has drawn much attention since of its
attractive efficiency. However, existing methods suffer from the difficulty in
long-distance regression. In this paper, we propose a coarse-to-fine module to
address the problem. Approximate boundary points are generated at the coarse
stage and then features of these points are sampled and fed to a refined
regressor for fine prediction. It is end-to-end trainable since differential
sampling operation is well supported in the module. Furthermore, we design a
holistic boundary-aware branch and introduce instance-agnostic supervision to
assist regression. Equipped with ResNet-101, our approach achieves 31.7\% mask
AP on COCO dataset with single-scale training and testing, outperforming the
baseline 1.3\% mask AP with less than 1\% additional parameters and GFLOPs.
Experiments also show that our proposed method achieves competitive performance
compared to existing boundary-based methods with a lightweight design and a
simple pipeline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Debiased Subjective Assessment of Real-World Image Enhancement. (arXiv:2106.10080v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhangyang_C/0/1/0/all/0/1">Cao Peibei. Wang Zhangyang</a>, <a href="http://arxiv.org/find/eess/1/au:+Kede_M/0/1/0/all/0/1">Ma Kede</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10080">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world image enhancement, it is often challenging (if not impossible)
to acquire ground-truth data, preventing the adoption of distance metrics for
objective quality assessment. As a result, one often resorts to subjective
quality assessment, the most straightforward and reliable means of evaluating
image enhancement. Conventional subjective testing requires manually
pre-selecting a small set of visual examples, which may suffer from three
sources of biases: 1) sampling bias due to the extremely sparse distribution of
the selected samples in the image space; 2) algorithmic bias due to potential
overfitting the selected samples; 3) subjective bias due to further potential
cherry-picking test results. This eventually makes the field of real-world
image enhancement more of an art than a science. Here we take steps towards
debiasing conventional subjective assessment by automatically sampling a set of
adaptive and diverse images for subsequent testing. This is achieved by casting
sample selection into a joint maximization of the discrepancy between the
enhancers and the diversity among the selected input images. Careful visual
inspection on the resulting enhanced images provides a debiased ranking of the
enhancement algorithms. We demonstrate our subjective assessment method using
three popular and practically demanding image enhancement tasks: dehazing,
super-resolution, and low-light enhancement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping. (arXiv:2106.09965v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Junwei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wenqing Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yongjian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09965">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a high fidelity face swapping method, called
HifiFace, which can well preserve the face shape of the source face and
generate photo-realistic results. Unlike other existing face swapping works
that only use face recognition model to keep the identity similarity, we
propose 3D shape-aware identity to control the face shape with the geometric
supervision from 3DMM and 3D face reconstruction method. Meanwhile, we
introduce the Semantic Facial Fusion module to optimize the combination of
encoder and decoder features and make adaptive blending, which makes the
results more photo-realistic. Extensive experiments on faces in the wild
demonstrate that our method can preserve better identity, especially on the
face shape, and can generate more photo-realistic results than previous
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework for Real-time Traffic Trajectory Tracking, Speed Estimation, and Driver Behavior Calibration at Urban Intersections Using Virtual Traffic Lanes. (arXiv:2106.09932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdelhalim_A/0/1/0/all/0/1">Awad Abdelhalim</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbas_M/0/1/0/all/0/1">Montasir Abbas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotha_B/0/1/0/all/0/1">Bhavi Bharat Kotha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wicks_A/0/1/0/all/0/1">Alfred Wicks</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09932">
                                    <div class="article-summary-box-inner">
                                        <span>In a previous study, we presented VT-Lane, a three-step framework for
real-time vehicle detection, tracking, and turn movement classification at
urban intersections. In this study, we present a case study incorporating the
highly accurate trajectories and movement classification obtained via VT-Lane
for the purpose of speed estimation and driver behavior calibration for traffic
at urban intersections. First, we use a highly instrumented vehicle to verify
the estimated speeds obtained from video inference. The results of the speed
validation show that our method can estimate the average travel speed of
detected vehicles in real-time with an error of 0.19 m/sec, which is equivalent
to 2% of the average observed travel speeds in the intersection of the study.
Instantaneous speeds (at the resolution of 30 Hz) were found to be estimated
with an average error of 0.21 m/sec and 0.86 m/sec respectively for
free-flowing and congested traffic conditions. We then use the estimated speeds
to calibrate the parameters of a driver behavior model for the vehicles in the
area of study. The results show that the calibrated model replicates the
driving behavior with an average error of 0.45 m/sec, indicating the high
potential for using this framework for automated, large-scale calibration of
car-following models from roadside traffic video data, which can lead to
substantial improvements in traffic modeling via microscopic simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Fault Detection in Industrial Welding Processes with Deep Learning and Data Augmentation. (arXiv:2106.10160v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antony_J/0/1/0/all/0/1">Jibinraj Antony</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlather_D/0/1/0/all/0/1">Dr. Florian Schlather</a>, <a href="http://arxiv.org/find/cs/1/au:+Safronov_G/0/1/0/all/0/1">Georgij Safronov</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitz_M/0/1/0/all/0/1">Markus Schmitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Laerhoven_P/0/1/0/all/0/1">Prof. Dr. Kristof Van Laerhoven</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10160">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of deep learning models in the field of computer vision, new
possibilities for their application in industrial processes proves to return
great benefits. Nevertheless, the actual fit of machine learning for highly
standardised industrial processes is still under debate. This paper addresses
the challenges on the industrial realization of the AI tools, considering the
use case of Laser Beam Welding quality control as an example. We use object
detection algorithms from the TensorFlow object detection API and adapt them to
our use case using transfer learning. The baseline models we develop are used
as benchmarks and evaluated and compared to models that undergo dataset scaling
and hyperparameter tuning. We find that moderate scaling of the dataset via
image augmentation leads to improvements in intersection over union (IoU) and
recall, whereas high levels of augmentation and scaling may lead to
deterioration of results. Finally, we put our results into perspective of the
underlying use case and evaluate their fit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving GANs: When Contradictions Turn into Compliance. (arXiv:2106.09946v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhar_S/0/1/0/all/0/1">Sauptik Dhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Heydari_J/0/1/0/all/0/1">Javad Heydari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Samarth Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurup_U/0/1/0/all/0/1">Unmesh Kurup</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mohak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09946">
                                    <div class="article-summary-box-inner">
                                        <span>Limited availability of labeled-data makes any supervised learning problem
challenging. Alternative learning settings like semi-supervised and universum
learning alleviate the dependency on labeled data, but still require a large
amount of unlabeled data, which may be unavailable or expensive to acquire.
GAN-based synthetic data generation methods have recently shown promise by
generating synthetic samples to improve task at hand. However, these samples
cannot be used for other purposes. In this paper, we propose a GAN game which
provides improved discriminator accuracy under limited data settings, while
generating realistic synthetic data. This provides the added advantage that now
the generated data can be used for other similar tasks. We provide the
theoretical guarantees and empirical results in support of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards interpreting computer vision based on transformation invariant optimization. (arXiv:2106.09982v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jinzhe Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tonghuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yaqian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Dongdong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">RenGang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09982">
                                    <div class="article-summary-box-inner">
                                        <span>Interpreting how does deep neural networks (DNNs) make predictions is a vital
field in artificial intelligence, which hinders wide applications of DNNs.
Visualization of learned representations helps we humans understand the vision
of DNNs. In this work, visualized images that can activate the neural network
to the target classes are generated by back-propagation method. Here, rotation
and scaling operations are applied to introduce the transformation invariance
in the image generating process, which we find a significant improvement on
visualization effect. Finally, we show some cases that such method can help us
to gain insight into neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">World-GAN: a Generative Model for Minecraft Worlds. (arXiv:2106.10155v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awiszus_M/0/1/0/all/0/1">Maren Awiszus</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubert_F/0/1/0/all/0/1">Frederik Schubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10155">
                                    <div class="article-summary-box-inner">
                                        <span>This work introduces World-GAN, the first method to perform data-driven
Procedural Content Generation via Machine Learning in Minecraft from a single
example. Based on a 3D Generative Adversarial Network (GAN) architecture, we
are able to create arbitrarily sized world snippets from a given sample. We
evaluate our approach on creations from the community as well as structures
generated with the Minecraft World Generator. Our method is motivated by the
dense representations used in Natural Language Processing (NLP) introduced with
word2vec [1]. The proposed block2vec representations make World-GAN independent
from the number of different blocks, which can vary a lot in Minecraft, and
enable the generation of larger levels. Finally, we demonstrate that changing
this new representation space allows us to change the generated style of an
already trained generator. World-GAN enables its users to generate Minecraft
worlds based on parts of their creations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Distraction-Robust Active Visual Tracking. (arXiv:2106.10110v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangwei Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_P/0/1/0/all/0/1">Peng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Wenhan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1">Tingyun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhou Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10110">
                                    <div class="article-summary-box-inner">
                                        <span>In active visual tracking, it is notoriously difficult when distracting
objects appear, as distractors often mislead the tracker by occluding the
target or bringing a confusing appearance. To address this issue, we propose a
mixed cooperative-competitive multi-agent game, where a target and multiple
distractors form a collaborative team to play against a tracker and make it
fail to follow. Through learning in our game, diverse distracting behaviors of
the distractors naturally emerge, thereby exposing the tracker&#x27;s weakness,
which helps enhance the distraction-robustness of the tracker. For effective
learning, we then present a bunch of practical methods, including a reward
function for distractors, a cross-modal teacher-student learning strategy, and
a recurrent attention mechanism for the tracker. The experimental results show
that our tracker performs desired distraction-robust active visual tracking and
can be well generalized to unseen environments. We also show that the
multi-agent game can be used to adversarially test the robustness of trackers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shape Prior Non-Uniform Sampling Guided Real-time Stereo 3D Object Detection. (arXiv:2106.10013v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_A/0/1/0/all/0/1">A. Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">J. Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Y. Pang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10013">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-LiDAR based 3D object detectors have gained popularity due to their
high accuracy. However, these methods need dense depth supervision and suffer
from inferior speed. To solve these two issues, a recently introduced RTS3D
builds an efficient 4D Feature-Consistency Embedding (FCE) space for the
intermediate representation of object without depth supervision. FCE space
splits the entire object region into 3D uniform grid latent space for feature
sampling point generation, which ignores the importance of different object
regions. However, we argue that, compared with the inner region, the outer
region plays a more important role for accurate 3D detection. To encode more
information from the outer region, we propose a shape prior non-uniform
sampling strategy that performs dense sampling in outer region and sparse
sampling in inner region. As a result, more points are sampled from the outer
region and more useful features are extracted for 3D detection. Further, to
enhance the feature discrimination of each sampling point, we propose a
high-level semantic enhanced FCE module to exploit more contextual information
and suppress noise better. Experiments on the KITTI dataset are performed to
show the effectiveness of the proposed method. Compared with the baseline
RTS3D, our proposed method has 2.57% improvement on AP3d almost without extra
network parameters. Moreover, our proposed method outperforms the
state-of-the-art methods without extra supervision at a real-time speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advanced Hough-based method for on-device document localization. (arXiv:2106.09987v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tropin_D/0/1/0/all/0/1">D.V. Tropin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ershov_A/0/1/0/all/0/1">A.M. Ershov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1">D.P. Nikolaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Arlazarov_V/0/1/0/all/0/1">V.V. Arlazarov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09987">
                                    <div class="article-summary-box-inner">
                                        <span>The demand for on-device document recognition systems increases in
conjunction with the emergence of more strict privacy and security
requirements. In such systems, there is no data transfer from the end device to
a third-party information processing servers. The response time is vital to the
user experience of on-device document recognition. Combined with the
unavailability of discrete GPUs, powerful CPUs, or a large RAM capacity on
consumer-grade end devices such as smartphones, the time limitations put
significant constraints on the computational complexity of the applied
algorithms for on-device execution.

In this work, we consider document location in an image without prior
knowledge of the document content or its internal structure. In accordance with
the published works, at least 5 systems offer solutions for on-device document
location. All these systems use a location method which can be considered
Hough-based. The precision of such systems seems to be lower than that of the
state-of-the-art solutions which were not designed to account for the limited
computational resources.

We propose an advanced Hough-based method. In contrast with other approaches,
it accounts for the geometric invariants of the central projection model and
combines both edge and color features for document boundary detection. The
proposed method allowed for the second best result for SmartDoc dataset in
terms of precision, surpassed by U-net like neural network. When evaluated on a
more challenging MIDV-500 dataset, the proposed algorithm guaranteed the best
precision compared to published methods. Our method retained the applicability
to on-device computations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equivariance-bridged SO(2)-Invariant Representation Learning using Graph Convolutional Network. (arXiv:2106.09996v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sungwon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1">Hyungtae Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Myung_H/0/1/0/all/0/1">Hyun Myung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09996">
                                    <div class="article-summary-box-inner">
                                        <span>Training a Convolutional Neural Network (CNN) to be robust against rotation
has mostly been done with data augmentation. In this paper, another progressive
vision of research direction is highlighted to encourage less dependence on
data augmentation by achieving structural rotational invariance of a network.
The deep equivariance-bridged SO(2) invariant network is proposed to echo such
vision. First, Self-Weighted Nearest Neighbors Graph Convolutional Network
(SWN-GCN) is proposed to implement Graph Convolutional Network (GCN) on the
graph representation of an image to acquire rotationally equivariant
representation, as GCN is more suitable for constructing deeper network than
spectral graph convolution-based approaches. Then, invariant representation is
eventually obtained with Global Average Pooling (GAP), a permutation-invariant
operation suitable for aggregating high-dimensional representations, over the
equivariant set of vertices retrieved from SWN-GCN. Our method achieves the
state-of-the-art image classification performance on rotated MNIST and CIFAR-10
images, where the models are trained with a non-augmented dataset only.
Quantitative validations over invariance of the representations also
demonstrate strong invariance of deep representations of SWN-GCN over
rotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Generative Adversarial Network Training via Self-Labeling and Self-Attention. (arXiv:2106.09914v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1">Tomoki Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09914">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel GAN training scheme that can handle any level of labeling
in a unified manner. Our scheme introduces a form of artificial labeling that
can incorporate manually defined labels, when available, and induce an
alignment between them. To define the artificial labels, we exploit the
assumption that neural network generators can be trained more easily to map
nearby latent vectors to data with semantic similarities, than across separate
categories. We use generated data samples and their corresponding artificial
conditioning labels to train a classifier. The classifier is then used to
self-label real data. To boost the accuracy of the self-labeling, we also use
the exponential moving average of the classifier. However, because the
classifier might still make mistakes, especially at the beginning of the
training, we also refine the labels through self-attention, by using the
labeling of real data samples only when the classifier outputs a high
classification probability score. We evaluate our approach on CIFAR-10, STL-10
and SVHN, and show that both self-labeling and self-attention consistently
improve the quality of generated data. More surprisingly, we find that the
proposed scheme can even outperform class-conditional GANs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Radar Localization on Lidar Maps Using Shared Embedding. (arXiv:2106.10000v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Huan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1">Rong Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10000">
                                    <div class="article-summary-box-inner">
                                        <span>We present a heterogeneous localization framework for solving radar global
localization and pose tracking on pre-built lidar maps. To bridge the gap of
sensing modalities, deep neural networks are constructed to create shared
embedding space for radar scans and lidar maps. Herein learned feature
embeddings are supportive for similarity measurement, thus improving map
retrieval and data matching respectively. In RobotCar and MulRan datasets, we
demonstrate the effectiveness of the proposed framework with the comparison to
Scan Context and RaLL. In addition, the proposed pose tracking pipeline is with
less neural networks compared to the original RaLL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combined Person Classification with Airborne Optical Sectioning. (arXiv:2106.10077v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kurmi_I/0/1/0/all/0/1">Indrajit Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schedl_D/0/1/0/all/0/1">David C. Schedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Bimber_O/0/1/0/all/0/1">Oliver Bimber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10077">
                                    <div class="article-summary-box-inner">
                                        <span>Fully autonomous drones have been demonstrated to find lost or injured
persons under strongly occluding forest canopy. Airborne Optical Sectioning
(AOS), a novel synthetic aperture imaging technique, together with
deep-learning-based classification enables high detection rates under realistic
search-and-rescue conditions. We demonstrate that false detections can be
significantly suppressed and true detections boosted by combining
classifications from multiple AOS rather than single integral images. This
improves classification rates especially in the presence of occlusion. To make
this possible, we modified the AOS imaging process to support large overlaps
between subsequent integrals, enabling real-time and on-board scanning and
processing of groundspeeds up to 10 m/s.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accumulative Poisoning Attacks on Real-time Data. (arXiv:2106.09993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09993">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting training data from untrusted sources exposes machine learning
services to poisoning adversaries, who maliciously manipulate training data to
degrade the model accuracy. When trained on offline datasets, poisoning
adversaries have to inject the poisoned data in advance before training, and
the order of feeding these poisoned batches into the model is stochastic. In
contrast, practical systems are more usually trained/fine-tuned on sequentially
captured real-time data, in which case poisoning adversaries could dynamically
poison each data batch according to the current model state. In this paper, we
focus on the real-time settings and propose a new attacking strategy, which
affiliates an accumulative phase with poisoning attacks to secretly (i.e.,
without affecting accuracy) magnify the destructive effect of a (poisoned)
trigger batch. By mimicking online learning and federated learning on CIFAR-10,
we show that the model accuracy will significantly drop by a single update step
on the trigger batch after the accumulative phase. Our work validates that a
well-designed but straightforward attacking strategy can dramatically amplify
the poisoning effects, with no need to explore complex techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples. (arXiv:2106.09947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1">Maura Pintor</a>, <a href="http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1">Luca Demetrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotgiu_A/0/1/0/all/0/1">Angelo Sotgiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Manca_G/0/1/0/all/0/1">Giovanni Manca</a>, <a href="http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1">Ambra Demontis</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>, <a href="http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1">Fabio Roli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09947">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating robustness of machine-learning models to adversarial examples is a
challenging problem. Many defenses have been shown to provide a false sense of
security by causing gradient-based attacks to fail, and they have been broken
under more rigorous evaluations. Although guidelines and best practices have
been suggested to improve current adversarial robustness evaluations, the lack
of automatic testing and debugging tools makes it difficult to apply these
recommendations in a systematic manner. In this work, we overcome these
limitations by (i) defining a set of quantitative indicators which unveil
common failures in the optimization of gradient-based attacks, and (ii)
proposing specific mitigation strategies within a systematic evaluation
protocol. Our extensive experimental analysis shows that the proposed
indicators of failure can be used to visualize, debug and improve current
adversarial robustness evaluations, providing a first concrete step towards
automatizing and systematizing current adversarial robustness evaluations. Our
open-source code is available at:
https://github.com/pralab/IndicatorsOfAttackFailure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Lies: Optical Adversarial Attack. (arXiv:2106.09908v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyu-Lim Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jeong-Soo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Seung-Ri Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jun-Ho Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_C/0/1/0/all/0/1">Chul-Min Joo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jong-Seok Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09908">
                                    <div class="article-summary-box-inner">
                                        <span>A significant amount of work has been done on adversarial attacks that inject
imperceptible noise to images to deteriorate the image classification
performance of deep models. However, most of the existing studies consider
attacks in the digital (pixel) domain where an image acquired by an image
sensor with sampling and quantization has been recorded. This paper, for the
first time, introduces an optical adversarial attack, which physically alters
the light field information arriving at the image sensor so that the
classification model yields misclassification. More specifically, we modulate
the phase of the light in the Fourier domain using a spatial light modulator
placed in the photographic system. The operative parameters of the modulator
are obtained by gradient-based optimization to maximize cross-entropy and
minimize distortions. We present experiments based on both simulation and a
real hardware optical system, from which the feasibility of the proposed
optical attack is demonstrated. It is also verified that the proposed attack is
completely different from common optical-domain distortions such as spherical
aberration, defocus, and astigmatism in terms of both perturbation patterns and
classification results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical Matting: A New Perspective on Medical Segmentation with Uncertainty. (arXiv:2106.09887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_L/0/1/0/all/0/1">Lie Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Donghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wanji He</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yelin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiwen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiufen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09887">
                                    <div class="article-summary-box-inner">
                                        <span>In medical image segmentation, it is difficult to mark ambiguous areas
accurately with binary masks, especially when dealing with small lesions.
Therefore, it is a challenge for radiologists to reach a consensus by using
binary masks under the condition of multiple annotations. However, these areas
may contain anatomical structures that are conducive to diagnosis. Uncertainty
is introduced to study these situations. Nevertheless, the uncertainty is
usually measured by the variances between predictions in a multiple trial way.
It is not intuitive, and there is no exact correspondence in the image.
Inspired by image matting, we introduce matting as a soft segmentation method
and a new perspective to deal with and represent uncertain regions into medical
scenes, namely medical matting. More specifically, because there is no
available medical matting dataset, we first labeled two medical datasets with
alpha matte. Secondly, the matting method applied to the natural image is not
suitable for the medical scene, so we propose a new architecture to generate
binary masks and alpha matte in a row. Thirdly, the uncertainty map is
introduced to highlight the ambiguous regions from the binary results and
improve the matting performance. Evaluated on these datasets, the proposed
model outperformed state-of-the-art matting algorithms by a large margin, and
alpha matte is proved to be a more efficient labeling form than a binary mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python. (arXiv:2106.09756v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Robert Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_P/0/1/0/all/0/1">Peizhen Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo E Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chasmai_M/0/1/0/all/0/1">Mustafa Chasmai</a>, <a href="http://arxiv.org/find/cs/1/au:+Schobs_L/0/1/0/all/0/1">Lawrence Schobs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09756">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning is a general-purpose technology holding promises for many
interdisciplinary research problems. However, significant barriers exist in
crossing disciplinary boundaries when most machine learning tools are developed
in different areas separately. We present Pykale - a Python library for
knowledge-aware machine learning on graphs, images, texts, and videos to enable
and accelerate interdisciplinary research. We formulate new green machine
learning guidelines based on standard software engineering practices and
propose a novel pipeline-based application programming interface (API). PyKale
focuses on leveraging knowledge from multiple sources for accurate and
interpretable prediction, thus supporting multimodal learning and transfer
learning (particularly domain adaptation) with latest deep learning and
dimensionality reduction models. We build PyKale on PyTorch and leverage the
rich PyTorch ecosystem. Our pipeline-based API design enforces standardization
and minimalism, embracing green machine learning concepts via reducing
repetitions and redundancy, reusing existing resources, and recycling learning
models across areas. We demonstrate its interdisciplinary nature via examples
in bioinformatics, knowledge graph, image/video recognition, and medical
imaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep reinforcement learning with automated label extraction from clinical reports accurately classifies 3D MRI brain volumes. (arXiv:2106.09812v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stember_J/0/1/0/all/0/1">Joseph Stember</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalu_H/0/1/0/all/0/1">Hrithwik Shalu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09812">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: Image classification is perhaps the most fundamental task in imaging
AI. However, labeling images is time-consuming and tedious. We have recently
demonstrated that reinforcement learning (RL) can classify 2D slices of MRI
brain images with high accuracy. Here we make two important steps toward
speeding image classification: Firstly, we automatically extract class labels
from the clinical reports. Secondly, we extend our prior 2D classification work
to fully 3D image volumes from our institution. Hence, we proceed as follows:
in Part 1, we extract labels from reports automatically using the SBERT natural
language processing approach. Then, in Part 2, we use these labels with RL to
train a classification Deep-Q Network (DQN) for 3D image volumes.

Methods: For Part 1, we trained SBERT with 90 radiology report impressions.
We then used the trained SBERT to predict class labels for use in Part 2. In
Part 2, we applied multi-step image classification to allow for combined Deep-Q
learning using 3D convolutions and TD(0) Q learning. We trained on a set of 90
images. We tested on a separate set of 61 images, again using the classes
predicted from patient reports by the trained SBERT in Part 1. For comparison,
we also trained and tested a supervised deep learning classification network on
the same set of training and testing images using the same labels.

Results: Part 1: Upon training with the corpus of radiology reports, the
SBERT model had 100% accuracy for both normal and metastasis-containing scans.
Part 2: Then, using these labels, whereas the supervised approach quickly
overfit the training data and as expected performed poorly on the testing set
(66% accuracy, just over random guessing), the reinforcement learning approach
achieved an accuracy of 92%. The results were found to be statistically
significant, with a p-value of 3.1 x 10^-5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantized Neural Networks via {-1, +1} Encoding Decomposition and Acceleration. (arXiv:2106.09886v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qigong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiufang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1">Fanhua Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09886">
                                    <div class="article-summary-box-inner">
                                        <span>The training of deep neural networks (DNNs) always requires intensive
resources for both computation and data storage. Thus, DNNs cannot be
efficiently applied to mobile phones and embedded devices, which severely
limits their applicability in industrial applications. To address this issue,
we propose a novel encoding scheme using {-1, +1} to decompose quantized neural
networks (QNNs) into multi-branch binary networks, which can be efficiently
implemented by bitwise operations (i.e., xnor and bitcount) to achieve model
compression, computational acceleration, and resource saving. By using our
method, users can achieve different encoding precisions arbitrarily according
to their requirements and hardware resources. The proposed mechanism is highly
suitable for the use of FPGA and ASIC in terms of data storage and computation,
which provides a feasible idea for smart chips. We validate the effectiveness
of our method on large-scale image classification (e.g., ImageNet), object
detection, and semantic segmentation tasks. In particular, our method with
low-bit encoding can still achieve almost the same performance as its high-bit
counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Model Sparsification by Scheduled Grow-and-Prune Methods. (arXiv:2106.09857v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zejiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1">Kun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Kuang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuan Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09857">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are effective in solving many real-world
problems. Larger DNN models usually exhibit better quality (e.g., accuracy) but
their excessive computation results in long training and inference time. Model
sparsification can reduce the computation and memory cost while maintaining
model quality. Most existing sparsification algorithms unidirectionally remove
weights, while others randomly or greedily explore a small subset of weights in
each layer. The inefficiency of the algorithms reduces the achievable sparsity
level. In addition, many algorithms still require pre-trained dense models and
thus suffer from large memory footprint and long training time. In this paper,
we propose a novel scheduled grow-and-prune (GaP) methodology without
pre-training the dense models. It addresses the shortcomings of the previous
works by repeatedly growing a subset of layers to dense and then pruning back
to sparse after some training. Experiments have shown that such models can
match or beat the quality of highly optimized dense models at 80% sparsity on a
variety of tasks, such as image classification, objective detection, 3D object
part segmentation, and translation. They also outperform other state-of-the-art
(SOTA) pruning methods, including pruning from pre-trained dense models. As an
example, a 90% sparse ResNet-50 obtained via GaP achieves 77.9% top-1 accuracy
on ImageNet, improving the SOTA results by 1.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Distance-based Separability Measure for Internal Cluster Validation. (arXiv:2106.09794v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Shuyue Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1">Murray Loew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09794">
                                    <div class="article-summary-box-inner">
                                        <span>To evaluate clustering results is a significant part of cluster analysis.
Since there are no true class labels for clustering in typical unsupervised
learning, many internal cluster validity indices (CVIs), which use predicted
labels and data, have been created. Without true labels, to design an effective
CVI is as difficult as to create a clustering method. And it is crucial to have
more CVIs because there are no universal CVIs that can be used to measure all
datasets and no specific methods of selecting a proper CVI for clusters without
true labels. Therefore, to apply a variety of CVIs to evaluate clustering
results is necessary. In this paper, we propose a novel internal CVI -- the
Distance-based Separability Index (DSI), based on a data separability measure.
We compared the DSI with eight internal CVIs including studies from early Dunn
(1974) to most recent CVDD (2019) and an external CVI as ground truth, by using
clustering results of five clustering algorithms on 12 real and 97 synthetic
datasets. Results show DSI is an effective, unique, and competitive CVI to
other compared CVIs. We also summarized the general process to evaluate CVIs
and created the rank-difference metric for comparison of CVIs&#x27; results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepLab2: A TensorFlow Library for Deep Labeling. (arXiv:2106.09748v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1">Mark Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huiyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1">Siyuan Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Collins_M/0/1/0/all/0/1">Maxwell D. Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yukun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dahun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qihang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1">Daniel Cremers</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taixe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan L. Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Schroff_F/0/1/0/all/0/1">Florian Schroff</a>, <a href="http://arxiv.org/find/cs/1/au:+Adam_H/0/1/0/all/0/1">Hartwig Adam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang-Chieh Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09748">
                                    <div class="article-summary-box-inner">
                                        <span>DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a
state-of-the-art and easy-to-use TensorFlow codebase for general dense pixel
prediction problems in computer vision. DeepLab2 includes all our recently
developed DeepLab model variants with pretrained checkpoints as well as model
training and evaluation code, allowing the community to reproduce and further
improve upon the state-of-art systems. To showcase the effectiveness of
DeepLab2, our Panoptic-DeepLab employing Axial-SWideRNet as network backbone
achieves 68.0% PQ or 83.5% mIoU on Cityscaspes validation set, with only
single-scale inference and ImageNet-1K pretrained checkpoints. We hope that
publicly sharing our library could facilitate future research on dense pixel
labeling tasks and envision new applications of this technology. Code is made
publicly available at \url{https://github.com/google-research/deeplab2}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RSG: A Simple but Effective Module for Learning Imbalanced Datasets. (arXiv:2106.09859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaolin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhenghua Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09859">
                                    <div class="article-summary-box-inner">
                                        <span>Imbalanced datasets widely exist in practice and area great challenge for
training deep neural models with agood generalization on infrequent classes. In
this work, wepropose a new rare-class sample generator (RSG) to solvethis
problem. RSG aims to generate some new samplesfor rare classes during training,
and it has in particularthe following advantages: (1) it is convenient to use
andhighly versatile, because it can be easily integrated intoany kind of
convolutional neural network, and it works wellwhen combined with different
loss functions, and (2) it isonly used during the training phase, and
therefore, no ad-ditional burden is imposed on deep neural networks duringthe
testing phase. In extensive experimental evaluations, weverify the
effectiveness of RSG. Furthermore, by leveragingRSG, we obtain competitive
results on Imbalanced CIFARand new state-of-the-art results on Places-LT,
ImageNet-LT, and iNaturalist 2018. The source code is available at
https://github.com/Jianf-Wang/RSG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid graph convolutional neural networks for landmark-based anatomical segmentation. (arXiv:2106.09832v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaggion_N/0/1/0/all/0/1">Nicol&#xe1;s Gaggion</a>, <a href="http://arxiv.org/find/eess/1/au:+Mansilla_L/0/1/0/all/0/1">Lucas Mansilla</a>, <a href="http://arxiv.org/find/eess/1/au:+Milone_D/0/1/0/all/0/1">Diego Milone</a>, <a href="http://arxiv.org/find/eess/1/au:+Ferrante_E/0/1/0/all/0/1">Enzo Ferrante</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09832">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we address the problem of landmark-based segmentation for
anatomical structures. We propose HybridGNet, an encoder-decoder neural
architecture which combines standard convolutions for image feature encoding,
with graph convolutional neural networks to decode plausible representations of
anatomical structures. We benchmark the proposed architecture considering other
standard landmark and pixel-based models for anatomical segmentation in chest
x-ray images, and found that HybridGNet is more robust to image occlusions. We
also show that it can be used to construct landmark-based segmentations from
pixel level annotations. Our experimental results suggest that HybridGNet
produces accurate and anatomically plausible landmark-based segmentations, by
naturally incorporating shape constraints within the decoding process via
spectral convolutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AI-Enabled Ultra-Low-Dose CT Reconstruction. (arXiv:2106.09834v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1">Weiwen Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Niu_C/0/1/0/all/0/1">Chuang Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ebrahimian_S/0/1/0/all/0/1">Shadi Ebrahimian</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1">Hengyong Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kalra_M/0/1/0/all/0/1">Mannu Kalra</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09834">
                                    <div class="article-summary-box-inner">
                                        <span>By the ALARA (As Low As Reasonably Achievable) principle, ultra-low-dose CT
reconstruction is a holy grail to minimize cancer risks and genetic damages,
especially for children. With the development of medical CT technologies, the
iterative algorithms are widely used to reconstruct decent CT images from a
low-dose scan. Recently, artificial intelligence (AI) techniques have shown a
great promise in further reducing CT radiation dose to the next level. In this
paper, we demonstrate that AI-powered CT reconstruction offers diagnostic image
quality at an ultra-low-dose level comparable to that of radiography.
Specifically, here we develop a Split Unrolled Grid-like Alternative
Reconstruction (SUGAR) network, in which deep learning, physical modeling and
image prior are integrated. The reconstruction results from clinical datasets
show that excellent images can be reconstructed using SUGAR from 36
projections. This approach has a potential to change future healthcare.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Self-supervised Vision Transformers for Representation Learning. (arXiv:2106.09785v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1">Mei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09785">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates two techniques for developing efficient
self-supervised vision transformers (EsViT) for visual representation learning.
First, we show through a comprehensive empirical study that multi-stage
architectures with sparse self-attentions can significantly reduce modeling
complexity but with a cost of losing the ability to capture fine-grained
correspondences between image regions. Second, we propose a new pre-training
task of region matching which allows the model to capture fine-grained region
dependencies and as a result significantly improves the quality of the learned
vision representations. Our results show that combining the two techniques,
EsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation,
outperforming prior arts with around an order magnitude of higher throughput.
When transferring to downstream linear classification tasks, EsViT outperforms
its supervised counterpart on 17 out of 18 datasets. The code and models will
be publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Integrated Gradients: An Adaptive Path Method for Removing Noise. (arXiv:2106.09788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kapishnikov_A/0/1/0/all/0/1">Andrei Kapishnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopalan_S/0/1/0/all/0/1">Subhashini Venugopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Avci_B/0/1/0/all/0/1">Besim Avci</a>, <a href="http://arxiv.org/find/cs/1/au:+Wedin_B/0/1/0/all/0/1">Ben Wedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Terry_M/0/1/0/all/0/1">Michael Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolukbasi_T/0/1/0/all/0/1">Tolga Bolukbasi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09788">
                                    <div class="article-summary-box-inner">
                                        <span>Integrated Gradients (IG) is a commonly used feature attribution method for
deep neural networks. While IG has many desirable properties, the method often
produces spurious/noisy pixel attributions in regions that are not related to
the predicted class when applied to visual models. While this has been
previously noted, most existing solutions are aimed at addressing the symptoms
by explicitly reducing the noise in the resulting attributions. In this work,
we show that one of the causes of the problem is the accumulation of noise
along the IG path. To minimize the effect of this source of noise, we propose
adapting the attribution path itself -- conditioning the path not just on the
image but also on the model being explained. We introduce Adaptive Path Methods
(APMs) as a generalization of path methods, and Guided IG as a specific
instance of an APM. Empirically, Guided IG creates saliency maps better aligned
with the model&#x27;s prediction and the input image that is being explained. We
show through qualitative and quantitative experiments that Guided IG
outperforms other, related methods in nearly every experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smoothed Multi-View Subspace Clustering. (arXiv:2106.09875v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhengrui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09875">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, multi-view subspace clustering has achieved impressive
performance due to the exploitation of complementary imformation across
multiple views. However, multi-view data can be very complicated and are not
easy to cluster in real-world applications. Most existing methods operate on
raw data and may not obtain the optimal solution. In this work, we propose a
novel multi-view clustering method named smoothed multi-view subspace
clustering (SMVSC) by employing a novel technique, i.e., graph filtering, to
obtain a smooth representation for each view, in which similar data points have
similar feature values. Specifically, it retains the graph geometric features
through applying a low-pass filter. Consequently, it produces a
&#x60;&#x60;clustering-friendly&quot; representation and greatly facilitates the downstream
clustering task. Extensive experiments on benchmark datasets validate the
superiority of our approach. Analysis shows that graph filtering increases the
separability of classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic COVID-19 Chest X-ray Dataset for Computer-Aided Diagnosis. (arXiv:2106.09759v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zunair_H/0/1/0/all/0/1">Hasib Zunair</a>, <a href="http://arxiv.org/find/eess/1/au:+Hamza_A/0/1/0/all/0/1">A. Ben Hamza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09759">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new dataset called Synthetic COVID-19 Chest X-ray Dataset for
training machine learning models. The dataset consists of 21,295 synthetic
COVID-19 chest X-ray images to be used for computer-aided diagnosis. These
images, generated via an unsupervised domain adaptation approach, are of high
quality. We find that the synthetic images not only improve performance of
various deep learning architectures when used as additional training data under
heavy imbalance conditions, but also detect the target class with high
confidence. We also find that comparable performance can also be achieved when
trained only on synthetic images. Further, salient features of the synthetic
COVID-19 images indicate that the distribution is significantly different from
Non-COVID-19 classes, enabling a proper decision boundary. We hope the
availability of such high fidelity chest X-ray images of COVID-19 will
encourage advances in the development of diagnostic and/or management tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Development of a conversing and body temperature scanning autonomously navigating robot to help screen for COVID-19. (arXiv:2106.09894v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_R/0/1/0/all/0/1">Ryan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09894">
                                    <div class="article-summary-box-inner">
                                        <span>Throughout the COVID-19 pandemic, the most common symptom displayed by
patients has been a fever, leading to the use of temperature scanning as a
preemptive measure to detect potential carriers of the virus. Human employees
with handheld thermometers have been used to fulfill this task, however this
puts them at risk as they cannot be physically distanced and the sequential
nature of this method leads to great inconveniences and inefficiency. The
proposed solution is an autonomously navigating robot capable of conversing and
scanning people&#x27;s temperature to detect fevers and help screen for COVID-19. To
satisfy this objective, the robot must be able to (1) navigate autonomously,
(2) detect and track people, and (3) get individuals&#x27; temperature reading and
converse with them if it exceeds 38{\deg}C. An autonomously navigating mobile
robot is used with a manipulator controlled using a face tracking algorithm,
and an end effector consisting of a thermal camera, smartphone, and chatbot.
The goal is to develop a functioning solution that performs the above tasks. In
addition, technical challenges encountered and their engineering solutions will
be presented, and recommendations will be made for enhancements that could be
incorporated when approaching commercialization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSFCube -- A Test Collection of Computer Science Research Articles for Faceted Query by Example. (arXiv:2103.12906v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1">Sheshera Mysore</a>, <a href="http://arxiv.org/find/cs/1/au:+OGorman_T/0/1/0/all/0/1">Tim O&#x27;Gorman</a>, <a href="http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1">Andrew McCallum</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1">Hamed Zamani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12906">
                                    <div class="article-summary-box-inner">
                                        <span>Query by Example is a well-known information retrieval task in which a
document is chosen by the user as the search query and the goal is to retrieve
relevant documents from a large collection. However, a document often covers
multiple aspects of a topic. To address this scenario we introduce the task of
faceted Query by Example in which users can also specify a finer grained aspect
in addition to the input query document. We focus on the application of this
task in scientific literature search. We envision models which are able to
retrieve scientific papers analogous to a query scientific paper along
specifically chosen rhetorical structure elements as one solution to this
problem. In this work, the rhetorical structure elements, which we refer to as
facets, indicate backgrounds, methods, or results of a scientific paper. We
introduce and describe an expert annotated test collection to evaluate models
trained to perform this task. Our test collection consists of a diverse set of
50 query documents, drawn from computational linguistics and machine learning
venues. We carefully followed the annotation guideline used by TREC for depth-k
pooling (k &#x3D; 100 or 250) and the resulting data collection consists of graded
relevance scores with high annotation agreement. The data is freely available
for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Graph Learning for Recommendation. (arXiv:2010.10783v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiancan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1">Jianxun Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10783">
                                    <div class="article-summary-box-inner">
                                        <span>Representation learning on user-item graph for recommendation has evolved
from using single ID or interaction history to exploiting higher-order
neighbors. This leads to the success of graph convolution networks (GCNs) for
recommendation such as PinSage and LightGCN. Despite effectiveness, we argue
that they suffer from two limitations: (1) high-degree nodes exert larger
impact on the representation learning, deteriorating the recommendations of
low-degree (long-tail) items; and (2) representations are vulnerable to noisy
interactions, as the neighborhood aggregation scheme further enlarges the
impact of observed edges.

In this work, we explore self-supervised learning on user-item graph, so as
to improve the accuracy and robustness of GCNs for recommendation. The idea is
to supplement the classical supervised task of recommendation with an auxiliary
self-supervised task, which reinforces node representation learning via
self-discrimination. Specifically, we generate multiple views of a node,
maximizing the agreement between different views of the same node compared to
that of other nodes. We devise three operators to generate the views -- node
dropout, edge dropout, and random walk -- that change the graph structure in
different manners. We term this new learning paradigm as
\textit{Self-supervised Graph Learning} (SGL), implementing it on the
state-of-the-art model LightGCN. Through theoretical analyses, we find that SGL
has the ability of automatically mining hard negatives. Empirical studies on
three benchmark datasets demonstrate the effectiveness of SGL, which improves
the recommendation accuracy, especially on long-tail items, and the robustness
against interaction noises. Our implementations are available at
\url{https://github.com/wujcan/SGL}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval. (arXiv:2104.09791v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xinyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yixing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09791">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-training and fine-tuning have achieved remarkable success in many
downstream natural language processing (NLP) tasks. Recently, pre-training
methods tailored for information retrieval (IR) have also been explored, and
the latest success is the PROP method which has reached new SOTA on a variety
of ad-hoc retrieval benchmarks. The basic idea of PROP is to construct the
\textit{representative words prediction} (ROP) task for pre-training inspired
by the query likelihood model. Despite its exciting performance, the
effectiveness of PROP might be bounded by the classical unigram language model
adopted in the ROP task construction process. To tackle this problem, we
propose a bootstrapped pre-training method (namely B-PROP) based on BERT for
ad-hoc retrieval. The key idea is to use the powerful contextual language model
BERT to replace the classical unigram language model for the ROP task
construction, and re-train BERT itself towards the tailored objective for IR.
Specifically, we introduce a novel contrastive method, inspired by the
divergence-from-randomness idea, to leverage BERT&#x27;s self-attention mechanism to
sample representative words from the document. By further fine-tuning on
downstream ad-hoc retrieval tasks, our method achieves significant improvements
over baselines without pre-training or with other pre-training methods, and
further pushes forward the SOTA on a variety of ad-hoc retrieval tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FinGAT: Financial Graph Attention Networks for Recommending Top-K Profitable Stocks. (arXiv:2106.10159v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1">Yi-Ling Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yu-Che Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Cheng-Te Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10159">
                                    <div class="article-summary-box-inner">
                                        <span>Financial technology (FinTech) has drawn much attention among investors and
companies. While conventional stock analysis in FinTech targets at predicting
stock prices, less effort is made for profitable stock recommendation. Besides,
in existing approaches on modeling time series of stock prices, the
relationships among stocks and sectors (i.e., categories of stocks) are either
neglected or pre-defined. Ignoring stock relationships will miss the
information shared between stocks while using pre-defined relationships cannot
depict the latent interactions or influence of stock prices between stocks. In
this work, we aim at recommending the top-K profitable stocks in terms of
return ratio using time series of stock prices and sector information. We
propose a novel deep learning-based model, Financial Graph Attention Networks
(FinGAT), to tackle the task under the setting that no pre-defined
relationships between stocks are given. The idea of FinGAT is three-fold.
First, we devise a hierarchical learning component to learn short-term and
long-term sequential patterns from stock time series. Second, a fully-connected
graph between stocks and a fully-connected graph between sectors are
constructed, along with graph attention networks, to learn the latent
interactions among stocks and sectors. Third, a multi-task objective is devised
to jointly recommend the profitable stocks and predict the stock movement.
Experiments conducted on Taiwan Stock, S&amp;P 500, and NASDAQ datasets exhibit
remarkable recommendation performance of our FinGAT, comparing to
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heuristic Stopping Rules For Technology-Assisted Review. (arXiv:2106.09871v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eugene Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_D/0/1/0/all/0/1">David D. Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Frieder_O/0/1/0/all/0/1">Ophir Frieder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09871">
                                    <div class="article-summary-box-inner">
                                        <span>Technology-assisted review (TAR) refers to human-in-the-loop active learning
workflows for finding relevant documents in large collections. These workflows
often must meet a target for the proportion of relevant documents found (i.e.
recall) while also holding down costs. A variety of heuristic stopping rules
have been suggested for striking this tradeoff in particular settings, but none
have been tested against a range of recall targets and tasks. We propose two
new heuristic stopping rules, Quant and QuantCI based on model-based estimation
techniques from survey research. We compare them against a range of proposed
heuristics and find they are accurate at hitting a range of recall targets
while substantially reducing review costs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Minimizing Cost in Legal Document Review Workflows. (arXiv:2106.09866v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eugene Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_D/0/1/0/all/0/1">David D. Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Frieder_O/0/1/0/all/0/1">Ophir Frieder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09866">
                                    <div class="article-summary-box-inner">
                                        <span>Technology-assisted review (TAR) refers to human-in-the-loop machine learning
workflows for document review in legal discovery and other high recall review
tasks. Attorneys and legal technologists have debated whether review should be
a single iterative process (one-phase TAR workflows) or whether model training
and review should be separate (two-phase TAR workflows), with implications for
the choice of active learning algorithm. The relative cost of manual labeling
for different purposes (training vs. review) and of different documents
(positive vs. negative examples) is a key and neglected factor in this debate.
Using a novel cost dynamics analysis, we show analytically and empirically that
these relative costs strongly impact whether a one-phase or two-phase workflow
minimizes cost. We also show how category prevalence, classification task
difficulty, and collection size impact the optimal choice not only of workflow
type, but of active learning method and stopping point.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point-of-Interest Recommender Systems: A Survey from an Experimental Perspective. (arXiv:2106.10069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1">Pablo S&#xe1;nchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellogin_A/0/1/0/all/0/1">Alejandro Bellog&#xed;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10069">
                                    <div class="article-summary-box-inner">
                                        <span>Point-of-Interest recommendation is an increasing research and developing
area within the widely adopted technologies known as Recommender Systems. Among
them, those that exploit information coming from Location-Based Social Networks
(LBSNs) are very popular nowadays and could work with different information
sources, which pose several challenges and research questions to the community
as a whole. We present a systematic review focused on the research done in the
last 10 years about this topic. We discuss and categorize the algorithms and
evaluation methodologies used in these works and point out the opportunities
and challenges that remain open in the field. More specifically, we report the
leading recommendation techniques and information sources that have been
exploited more often (such as the geographical signal and deep learning
approaches) while we also alert about the lack of reproducibility in the field
that may hinder real performance improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information Retrieval Approach to Building Datasets for Hate Speech Detection. (arXiv:2106.09775v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Md Mustafizur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Balakrishnan_D/0/1/0/all/0/1">Dinesh Balakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Murthy_D/0/1/0/all/0/1">Dhiraj Murthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutlu_M/0/1/0/all/0/1">Mucahid Kutlu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1">Matthew Lease</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09775">
                                    <div class="article-summary-box-inner">
                                        <span>Building a benchmark dataset for hate speech detection presents several
challenges. Firstly, because hate speech is relatively rare -- e.g., less than
3\% of Twitter posts are hateful \citep{founta2018large} -- random sampling of
tweets to annotate is inefficient in capturing hate speech. A common practice
is to only annotate tweets containing known &#x60;&#x60;hate words&#x27;&#x27;, but this risks
yielding a biased benchmark that only partially captures the real-world
phenomenon of interest. A second challenge is that definitions of hate speech
tend to be highly variable and subjective. Annotators having diverse prior
notions of hate speech may not only disagree with one another but also struggle
to conform to specified labeling guidelines. Our key insight is that the rarity
and subjectivity of hate speech are akin to that of relevance in information
retrieval (IR). This connection suggests that well-established methodologies
for creating IR test collections might also be usefully applied to create
better benchmark datasets for hate speech detection. Firstly, to intelligently
and efficiently select which tweets to annotate, we apply established IR
techniques of {\em pooling} and {\em active learning}. Secondly, to improve
both consistency and value of annotations, we apply {\em task decomposition}
\cite{Zhang-sigir14} and {\em annotator rationale} \cite{mcdonnell16-hcomp}
techniques. Using the above techniques, we create and share a new benchmark
dataset\footnote{We will release the dataset upon publication.} for hate speech
detection with broader coverage than prior datasets. We also show a dramatic
drop in accuracy of existing detection models when tested on these broader
forms of hate. Collected annotator rationales not only provide documented
support for labeling decisions but also create exciting future work
opportunities for dual-supervision and/or explanation generation in modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Sequential Shrinking: A Best Arm Identification Algorithm for Stochastic Bandits with Corruptions. (arXiv:2010.07904v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zixin Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1">Wang Chi Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07904">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a best arm identification (BAI) problem for stochastic bandits
with adversarial corruptions in the fixed-budget setting of T steps. We design
a novel randomized algorithm, Probabilistic Sequential Shrinking($u$)
(PSS($u$)), which is agnostic to the amount of corruptions. When the amount of
corruptions per step (CPS) is below a threshold, PSS($u$) identifies the best
arm or item with probability tending to $1$ as $T\rightarrow \infty$.
Otherwise, the optimality gap of the identified item degrades gracefully with
the CPS.We argue that such a bifurcation is necessary. In PSS($u$), the
parameter $u$ serves to balance between the optimality gap and success
probability. The injection of randomization is shown to be essential to
mitigate the impact of corruptions. To demonstrate this, we design two attack
strategies that are applicable to any algorithm. We apply one of them to a
deterministic analogue of PSS($u$) known as Successive Halving (SH) by Karnin
et al. (2013). The attack strategy results in a high failure probability for
SH, but PSS($u$) remains robust. In the absence of corruptions, PSS($2$)&#x27;s
performance guarantee matches SH&#x27;s. We show that when the CPS is sufficiently
large, no algorithm can achieve a BAI probability tending to $1$ as
$T\rightarrow \infty$. Numerical experiments corroborate our theoretical
findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program Analysis. (arXiv:2010.05050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yicheng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Filieri_A/0/1/0/all/0/1">Antonio Filieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05050">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic software analysis aims at quantifying the probability of a
target event occurring during the execution of a program processing uncertain
incoming data or written itself using probabilistic programming constructs.
Recent techniques combine symbolic execution with model counting or solution
space quantification methods to obtain accurate estimates of the occurrence
probability of rare target events, such as failures in a mission-critical
system. However, they face several scalability and applicability limitations
when analyzing software processing with high-dimensional and correlated
multivariate input distributions. In this paper, we present SYMbolic Parallel
Adaptive Importance Sampling (SYMPAIS), a new inference method tailored to
analyze path conditions generated from the symbolic execution of programs with
high-dimensional, correlated input distributions. SYMPAIS combines results from
importance sampling and constraint solving to produce accurate estimates of the
satisfaction probability for a broad class of constraints that cannot be
analyzed by current solution space quantification methods. We demonstrate
SYMPAIS&#x27;s generality and performance compared with state-of-the-art
alternatives on a set of problems from different application domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Materials Representation and Transfer Learning for Multi-Property Prediction. (arXiv:2106.02225v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1">Shufeng Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Guevarra_D/0/1/0/all/0/1">Dan Guevarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla P. Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Gregoire_J/0/1/0/all/0/1">John M. Gregoire</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02225">
                                    <div class="article-summary-box-inner">
                                        <span>The adoption of machine learning in materials science has rapidly transformed
materials property prediction. Hurdles limiting full capitalization of recent
advancements in machine learning include the limited development of methods to
learn the underlying interactions of multiple elements, as well as the
relationships among multiple properties, to facilitate property prediction in
new composition spaces. To address these issues, we introduce the Hierarchical
Correlation Learning for Multi-property Prediction (H-CLMP) framework that
seamlessly integrates (i) prediction using only a material&#x27;s composition, (ii)
learning and exploitation of correlations among target properties in
multi-target regression, and (iii) leveraging training data from tangential
domains via generative transfer learning. The model is demonstrated for
prediction of spectral optical absorption of complex metal oxides spanning 69
3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear
composition-property relationships in composition spaces for which no training
data is available, which broadens the purview of machine learning to the
discovery of materials with exceptional properties. This achievement results
from the principled integration of latent embedding learning, property
correlation learning, generative transfer learning, and attention models. The
best performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))
wherein a generative adversarial network is trained on computational density of
states data and deployed in the target domain to augment prediction of optical
absorption from composition. H-CLMP(T) aggregates multiple knowledge sources
with a framework that is well-suited for multi-target regression across the
physical sciences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Intervention Networks for Causal Effect Estimation. (arXiv:2106.01939v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1">Jean Kaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuchen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ricardo Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01939">
                                    <div class="article-summary-box-inner">
                                        <span>We address the estimation of conditional average treatment effects (CATEs)
when treatments are graph-structured (e.g., molecular graphs of drugs). Given a
weak condition on the effect, we propose a plug-in estimator that decomposes
CATE estimation into separate, simpler optimization problems. Our estimator (a)
isolates the causal estimands (reducing regularization bias), and (b) allows
one to plug in arbitrary models for learning. In experiments with small-world
and molecular graphs, we show that our approach outperforms prior approaches
and is robust to varying selection biases. Our implementation is online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Mathematical Foundation for Robust Machine Learning based on Bias-Variance Trade-off. (arXiv:2106.05522v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1">Ou Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weiyao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yingjun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haixiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1">Qinghu Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05522">
                                    <div class="article-summary-box-inner">
                                        <span>A common assumption in machine learning is that samples are independently and
identically distributed (i.i.d). However, the contributions of different
samples are not identical in training. Some samples are difficult to learn and
some samples are noisy. The unequal contributions of samples has a considerable
effect on training performances. Studies focusing on unequal sample
contributions (e.g., easy, hard, noisy) in learning usually refer to these
contributions as robust machine learning (RML). Weighing and regularization are
two common techniques in RML. Numerous learning algorithms have been proposed
but the strategies for dealing with easy/hard/noisy samples differ or even
contradict with different learning algorithms. For example, some strategies
take the hard samples first, whereas some strategies take easy first.
Conducting a clear comparison for existing RML algorithms in dealing with
different samples is difficult due to lack of a unified theoretical framework
for RML. This study attempts to construct a mathematical foundation for RML
based on the bias-variance trade-off theory. A series of definitions and
properties are presented and proved. Several classical learning algorithms are
also explained and compared. Improvements of existing methods are obtained
based on the comparison. A unified method that combines two classical learning
strategies is proposed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1">Wang Yifan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1">Lukas Rahmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1">Olga Sorkine-Hornung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05187">
                                    <div class="article-summary-box-inner">
                                        <span>We present implicit displacement fields, a novel representation for detailed
3D geometry. Inspired by a classic surface deformation technique, displacement
mapping, our method represents a complex surface as a smooth base surface plus
a displacement along the base&#x27;s normal directions, resulting in a
frequency-based shape decomposition, where the high frequency signal is
constrained geometrically by the low frequency signal. Importantly, this
disentanglement is unsupervised thanks to a tailored architectural design that
has an innate frequency hierarchy by construction. We explore implicit
displacement field surface reconstruction and detail transfer and demonstrate
superior representational power, training stability and generalizability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster Kernel Matrix Algebra via Density Estimation. (arXiv:2102.08341v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Backurs_A/0/1/0/all/0/1">Arturs Backurs</a>, <a href="http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1">Piotr Indyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_T/0/1/0/all/0/1">Tal Wagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08341">
                                    <div class="article-summary-box-inner">
                                        <span>We study fast algorithms for computing fundamental properties of a positive
semidefinite kernel matrix $K \in \mathbb{R}^{n \times n}$ corresponding to $n$
points $x_1,\ldots,x_n \in \mathbb{R}^d$. In particular, we consider estimating
the sum of kernel matrix entries, along with its top eigenvalue and
eigenvector.

We show that the sum of matrix entries can be estimated to $1+\epsilon$
relative error in time $sublinear$ in $n$ and linear in $d$ for many popular
kernels, including the Gaussian, exponential, and rational quadratic kernels.
For these kernels, we also show that the top eigenvalue (and an approximate
eigenvector) can be approximated to $1+\epsilon$ relative error in time
$subquadratic$ in $n$ and linear in $d$.

Our algorithms represent significant advances in the best known runtimes for
these problems. They leverage the positive definiteness of the kernel matrix,
along with a recent line of work on efficient kernel density estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN for time series prediction, data assimilation and uncertainty quantification. (arXiv:2105.13859v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1">Vinicius L. S. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Heaney_C/0/1/0/all/0/1">Claire E. Heaney</a>, <a href="http://arxiv.org/find/cs/1/au:+Pain_C/0/1/0/all/0/1">Christopher C. Pain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13859">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new method in which a generative adversarial network (GAN) is
used to quantify the uncertainty of forward simulations in the presence of
observed data. Previously, a method has been developed which enables GANs to
make time series predictions and data assimilation by training a GAN with
unconditional simulations of a high-fidelity numerical model. After training,
the GAN can be used to predict the evolution of the spatial distribution of the
simulation states and observed data is assimilated. In this paper, we describe
the process required in order to quantify uncertainty, during which no
additional simulations of the high-fidelity numerical model are required. These
methods take advantage of the adjoint-like capabilities of generative models
and the ability to simulate forwards and backwards in time. Set within a
reduced-order model framework for efficiency, we apply these methods to a
compartmental model in epidemiology to predict the spread of COVID-19 in an
idealised town. The results show that the proposed method can efficiently
quantify uncertainty in the presence of measurements using only unconditional
simulations of the high-fidelity numerical model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Combinatorial Sequential Monte Carlo Methods for Bayesian Phylogenetic Inference. (arXiv:2106.00075v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Moretti_A/0/1/0/all/0/1">Antonio Khalil Moretti</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1">Liyi Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Naesseth_C/0/1/0/all/0/1">Christian A. Naesseth</a>, <a href="http://arxiv.org/find/stat/1/au:+Venner_H/0/1/0/all/0/1">Hadiah Venner</a>, <a href="http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1">David Blei</a>, <a href="http://arxiv.org/find/stat/1/au:+Peer_I/0/1/0/all/0/1">Itsik Pe&#x27;er</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00075">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian phylogenetic inference is often conducted via local or sequential
search over topologies and branch lengths using algorithms such as random-walk
Markov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC).
However, when MCMC is used for evolutionary parameter learning, convergence
requires long runs with inefficient exploration of the state space. We
introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful
framework that establishes variational sequential search to learn distributions
over intricate combinatorial structures. We then develop nested CSMC, an
efficient proposal distribution for CSMC and prove that nested CSMC is an exact
approximation to the (intractable) locally optimal proposal. We use nested CSMC
to define a second objective, VNCSMC which yields tighter lower bounds than
VCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore
higher probability spaces than existing methods on a range of tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning. (arXiv:2104.02532v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feldman_T/0/1/0/all/0/1">Tal Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Peake_A/0/1/0/all/0/1">Ashley Peake</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02532">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning models have been deployed across many different aspects of
society, often in situations that affect social welfare. Although these models
offer streamlined solutions to large problems, they may contain biases and
treat groups or individuals unfairly based on protected attributes such as
gender. In this paper, we introduce several examples of machine learning gender
bias in practice followed by formalizations of fairness. We provide a survey of
fairness research by detailing influential pre-processing, in-processing, and
post-processing bias mitigation algorithms. We then propose an
\textup{end-to-end bias mitigation} framework, which employs a fusion of pre-,
in-, and post-processing methods to leverage the strengths of each individual
technique. We test this method, along with the standard techniques we review,
on a deep neural network to analyze bias mitigation in a deep learning setting.
We find that our end-to-end bias mitigation framework outperforms the baselines
with respect to several fairness metrics, suggesting its promise as a method
for improving fairness. As society increasingly relies on artificial
intelligence to help in decision-making, addressing gender biases present in
deep learning models is imperative. To provide readers with the tools to assess
the fairness of machine learning models and mitigate the biases present in
them, we discuss multiple open source packages for fairness in AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1">Marcos Vendramini</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1">Alexei Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10013">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification methods are usually trained to perform predictions
taking into account a predefined group of known classes. Real-world problems,
however, may not allow for a full knowledge of the input and label spaces,
making failures in recognition a hazard to deep visual learning. Open set
recognition methods are characterized by the ability to correctly identifying
inputs of known and unknown classes. In this context, we propose GeMOS: simple
and plug-and-play open set recognition modules that can be attached to
pretrained Deep Neural Networks for visual recognition. The GeMOS framework
pairs pre-trained Convolutional Neural Networks with generative models for open
set recognition to extract open set scores for each sample, allowing for
failure recognition in object recognition tasks. We conduct a thorough
evaluation of the proposed method in comparison with state-of-the-art open set
algorithms, finding that GeMOS either outperforms or is statistically
indistinguishable from more complex and costly models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Clustering-friendly Representations: Subspace Clustering via Graph Filtering. (arXiv:2106.09874v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhengrui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guangchun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09874">
                                    <div class="article-summary-box-inner">
                                        <span>Finding a suitable data representation for a specific task has been shown to
be crucial in many applications. The success of subspace clustering depends on
the assumption that the data can be separated into different subspaces.
However, this simple assumption does not always hold since the raw data might
not be separable into subspaces. To recover the &#x60;&#x60;clustering-friendly&#x27;&#x27;
representation and facilitate the subsequent clustering, we propose a graph
filtering approach by which a smooth representation is achieved. Specifically,
it injects graph similarity into data features by applying a low-pass filter to
extract useful data representations for clustering. Extensive experiments on
image and document clustering datasets demonstrate that our method improves
upon state-of-the-art subspace clustering techniques. Especially, its
comparable performance with deep learning methods emphasizes the effectiveness
of the simple graph filtering scheme for many real-world applications. An
ablation study shows that graph filtering can remove noise, preserve structure
in the image, and increase the separability of classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection. (arXiv:2106.09989v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yulin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuni Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kaifa Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiapu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Mingquan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09989">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based Anomaly Detection (GAD) is becoming prevalent due to the powerful
representation abilities of graphs as well as recent advances in graph mining
techniques. These GAD tools, however, expose a new attacking surface,
ironically due to their unique advantage of being able to exploit the relations
among data. That is, attackers now can manipulate those relations (i.e., the
structure of the graph) to allow some target nodes to evade detection. In this
paper, we exploit this vulnerability by designing a new type of targeted
structural poisoning attacks to a representative regression-based GAD system
termed OddBall. Specially, we formulate the attack against OddBall as a
bi-level optimization problem, where the key technical challenge is to
efficiently solve the problem in a discrete domain. We propose a novel attack
method termed BinarizedAttack based on gradient descent. Comparing to prior
arts, BinarizedAttack can better use the gradient information, making it
particularly suitable for solving combinatorial optimization problems.
Furthermore, we investigate the attack transferability of BinarizedAttack by
employing it to attack other representation-learning-based GAD systems. Our
comprehensive experiments demonstrate that BinarizedAttack is very effective in
enabling target nodes to evade graph-based anomaly detection tools with limited
attackers&#x27; budget, and in the black-box transfer attack setting,
BinarizedAttack is also tested effective and in particular, can significantly
change the node embeddings learned by the GAD systems. Our research thus opens
the door to studying a new type of attack against security analytic tools that
rely on graph data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimising simulations for diphoton production at hadron colliders using amplitude neural networks. (arXiv:2106.09474v1 [hep-ph] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ph/1/au:+Aylett_Bullock_J/0/1/0/all/0/1">Joseph Aylett-Bullock</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Badger_S/0/1/0/all/0/1">Simon Badger</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Moodie_R/0/1/0/all/0/1">Ryan Moodie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09474">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning technology has the potential to dramatically optimise event
generation and simulations. We continue to investigate the use of neural
networks to approximate matrix elements for high-multiplicity scattering
processes. We focus on the case of loop-induced diphoton production through
gluon fusion and develop a realistic simulation method that can be applied to
hadron collider observables. Neural networks are trained using the one-loop
amplitudes implemented in the NJet C++ library and interfaced to the Sherpa
Monte Carlo event generator where we perform a detailed study for $2\to3$ and
$2\to4$ scattering problems. We also consider how the trained networks perform
when varying the kinematic cuts effecting the phase space and the reliability
of the neural network simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coresets for Classification -- Simplified and Strengthened. (arXiv:2106.04254v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1">Tung Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anup B. Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04254">
                                    <div class="article-summary-box-inner">
                                        <span>We give relative error coresets for training linear classifiers with a broad
class of loss functions, including the logistic loss and hinge loss. Our
construction achieves $(1\pm \epsilon)$ relative error with $\tilde O(d \cdot
\mu_y(X)^2/\epsilon^2)$ points, where $\mu_y(X)$ is a natural complexity
measure of the data matrix $X \in \mathbb{R}^{n \times d}$ and label vector $y
\in \{-1,1\}^n$, introduced in by Munteanu et al. 2018. Our result is based on
subsampling data points with probabilities proportional to their $\ell_1$
$Lewis$ $weights$. It significantly improves on existing theoretical bounds and
performs well in practice, outperforming uniform subsampling along with other
importance sampling methods. Our sampling distribution does not depend on the
labels, so can be used for active learning. It also does not depend on the
specific loss function, so a single coreset can be used in multiple training
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Doubly Constrained Batch Reinforcement Learning. (arXiv:2102.09225v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1">Rasool Fakoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1">Jonas Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1">Kavosh Asadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1">Pratik Chaudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09225">
                                    <div class="article-summary-box-inner">
                                        <span>Reliant on too many experiments to learn good actions, current Reinforcement
Learning (RL) algorithms have limited applicability in real-world settings,
which can be too expensive to allow exploration. We propose an algorithm for
batch RL, where effective policies are learned using only a fixed offline
dataset instead of online interactions with the environment. The limited data
in batch RL produces inherent uncertainty in value estimates of states/actions
that were insufficiently represented in the training data. This leads to
particularly severe extrapolation when our candidate policies diverge from one
that generated the data. We propose to mitigate this issue via two
straightforward penalties: a policy-constraint to reduce this divergence and a
value-constraint that discourages overly optimistic estimates. Over a
comprehensive set of 32 continuous-action batch RL benchmarks, our approach
compares favorably to state-of-the-art methods, regardless of how the offline
data were collected.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Implicit Networks via Non-Euclidean Contractions. (arXiv:2106.03194v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarpour_S/0/1/0/all/0/1">Saber Jafarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Davydov_A/0/1/0/all/0/1">Alexander Davydov</a>, <a href="http://arxiv.org/find/cs/1/au:+Proskurnikov_A/0/1/0/all/0/1">Anton V. Proskurnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bullo_F/0/1/0/all/0/1">Francesco Bullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03194">
                                    <div class="article-summary-box-inner">
                                        <span>Implicit neural networks, a.k.a., deep equilibrium networks, are a class of
implicit-depth learning models where function evaluation is performed by
solving a fixed point equation. They generalize classic feedforward models and
are equivalent to infinite-depth weight-tied feedforward networks. While
implicit models show improved accuracy and significant reduction in memory
consumption, they can suffer from ill-posedness and convergence instability.

This paper provides a new framework to design well-posed and robust implicit
neural networks based upon contraction theory for the non-Euclidean norm
$\ell_\infty$. Our framework includes (i) a novel condition for well-posedness
based on one-sided Lipschitz constants, (ii) an average iteration for computing
fixed-points, and (iii) explicit estimates on input-output Lipschitz constants.
Additionally, we design a training problem with the well-posedness condition
and the average iteration as constraints and, to achieve robust models, with
the input-output Lipschitz constant as a regularizer. Our $\ell_\infty$
well-posedness condition leads to a larger polytopic training search space than
existing conditions and our average iteration enjoys accelerated convergence.
Finally, we perform several numerical experiments for function estimation and
digit classification through the MNIST data set. Our numerical results
demonstrate improved accuracy and robustness of the implicit models with
smaller input-output Lipschitz bounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sumon Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1">Hridesh Rajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06054">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, many incidents have been reported where machine learning
models exhibited discrimination among people based on race, sex, age, etc.
Research has been conducted to measure and mitigate unfairness in machine
learning models. For a machine learning task, it is a common practice to build
a pipeline that includes an ordered set of data preprocessing stages followed
by a classifier. However, most of the research on fairness has considered a
single classifier based prediction task. What are the fairness impacts of the
preprocessing stages in machine learning pipeline? Furthermore, studies showed
that often the root cause of unfairness is ingrained in the data itself, rather
than the model. But no research has been conducted to measure the unfairness
caused by a specific transformation made in the data preprocessing stage. In
this paper, we introduced the causal method of fairness to reason about the
fairness impact of data preprocessing stages in ML pipeline. We leveraged
existing metrics to define the fairness measures of the stages. Then we
conducted a detailed fairness evaluation of the preprocessing stages in 37
pipelines collected from three different sources. Our results show that certain
data transformers are causing the model to exhibit unfairness. We identified a
number of fairness patterns in several categories of data transformers.
Finally, we showed how the local fairness of a preprocessing stage composes in
the global fairness of the pipeline. We used the fairness composition to choose
appropriate downstream transformer that mitigates unfairness in the machine
learning pipeline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ray-based framework for state identification in quantum dot devices. (arXiv:2102.11784v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Zwolak_J/0/1/0/all/0/1">Justyna P. Zwolak</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+McJunkin_T/0/1/0/all/0/1">Thomas McJunkin</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kalantre_S/0/1/0/all/0/1">Sandesh S. Kalantre</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Neyens_S/0/1/0/all/0/1">Samuel F. Neyens</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+MacQuarrie_E/0/1/0/all/0/1">E. R. MacQuarrie</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eriksson_M/0/1/0/all/0/1">Mark A. Eriksson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Taylor_J/0/1/0/all/0/1">Jacob M. Taylor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11784">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum dots (QDs) defined with electrostatic gates are a leading platform
for a scalable quantum computing implementation. However, with increasing
numbers of qubits, the complexity of the control parameter space also grows.
Traditional measurement techniques, relying on complete or near-complete
exploration via two-parameter scans (images) of the device response, quickly
become impractical with increasing numbers of gates. Here we propose to
circumvent this challenge by introducing a measurement technique relying on
one-dimensional projections of the device response in the multidimensional
parameter space. Dubbed the &#x60;&#x60;ray-based classification (RBC) framework,&#x27;&#x27; we
use this machine learning approach to implement a classifier for QD states,
enabling automated recognition of qubit-relevant parameter regimes. We show
that RBC surpasses the 82 % accuracy benchmark from the experimental
implementation of image-based classification techniques from prior work while
reducing the number of measurement points needed by up to 70 %. The reduction
in measurement cost is a significant gain for time-intensive QD measurements
and is a step forward toward the scalability of these devices. We also discuss
how the RBC-based optimizer, which tunes the device to a multiqubit regime,
performs when tuning in the two-dimensional and three-dimensional parameter
spaces defined by plunger and barrier gates that control the QDs.This work
provides experimental validation of both efficient state identification and
optimization with machine learning techniques for non-traditional measurements
in quantum systems with high-dimensional parameter spaces and time-intensive
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Slow Momentum with Fast Reversion: A Trading Strategy Using Deep Learning and Changepoint Detection. (arXiv:2105.13727v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wood_K/0/1/0/all/0/1">Kieran Wood</a>, <a href="http://arxiv.org/find/stat/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>, <a href="http://arxiv.org/find/stat/1/au:+Zohren_S/0/1/0/all/0/1">Stefan Zohren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13727">
                                    <div class="article-summary-box-inner">
                                        <span>Momentum strategies are an important part of alternative investments and are
at the heart of commodity trading advisors (CTAs). These strategies have
however been found to have difficulties adjusting to rapid changes in market
conditions, such as during the 2020 market crash. In particular, immediately
after momentum turning points, where a trend reverses from an uptrend
(downtrend) to a downtrend (uptrend), time-series momentum (TSMOM) strategies
are prone to making bad bets. To improve the response to regime change, we
introduce a novel approach, where we insert an online change-point detection
(CPD) module into a Deep Momentum Network (DMN) [1904.04912] pipeline, which
uses an LSTM deep-learning architecture to simultaneously learn both trend
estimation and position sizing. Furthermore, our model is able to optimise the
way in which it balances 1) a slow momentum strategy which exploits persisting
trends, but does not overreact to localised price moves, and 2) a fast
mean-reversion strategy regime by quickly flipping its position, then swapping
it back again to exploit localised price moves. Our CPD module outputs a
changepoint location and severity score, allowing our model to learn to respond
to varying degrees of disequilibrium, or smaller and more localised
changepoints, in a data driven manner. Using a portfolio of 50, liquid,
continuous futures contracts over the period 1990-2020, the addition of the CPD
module leads to an improvement in Sharpe ratio of one-third. Even more notably,
this module is especially beneficial in periods of significant nonstationarity,
and in particular, over the most recent years tested (2015-2020) the
performance boost is approximately two-thirds. This is especially interesting
as traditional momentum strategies have been underperforming in this period.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Max-Margin is Dead, Long Live Max-Margin!. (arXiv:2105.15069v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nowak_Vila_A/0/1/0/all/0/1">Alex Nowak-Vila</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15069">
                                    <div class="article-summary-box-inner">
                                        <span>The foundational concept of Max-Margin in machine learning is ill-posed for
output spaces with more than two labels such as in structured prediction. In
this paper, we show that the Max-Margin loss can only be consistent to the
classification task under highly restrictive assumptions on the discrete loss
measuring the error between outputs. These conditions are satisfied by
distances defined in tree graphs, for which we prove consistency, thus being
the first losses shown to be consistent for Max-Margin beyond the binary
setting. We finally address these limitations by correcting the concept of
Max-Margin and introducing the Restricted-Max-Margin, where the maximization of
the loss-augmented scores is maintained, but performed over a subset of the
original domain. The resulting loss is also a generalization of the binary
support vector machine and it is consistent under milder conditions on the
discrete loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Pharmacodynamic State Space Modeling. (arXiv:2102.11218v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussain_Z/0/1/0/all/0/1">Zeshan Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_R/0/1/0/all/0/1">Rahul G. Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1">David Sontag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11218">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling the time-series of high-dimensional, longitudinal data is important
for predicting patient disease progression. However, existing neural network
based approaches that learn representations of patient state, while very
flexible, are susceptible to overfitting. We propose a deep generative model
that makes use of a novel attention-based neural architecture inspired by the
physics of how treatments affect disease state. The result is a scalable and
accurate model of high-dimensional patient biomarkers as they vary over time.
Our proposed model yields significant improvements in generalization and, on
real-world clinical data, provides interpretable insights into the dynamics of
cancer progression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Diverse-Structured Networks for Adversarial Robustness. (arXiv:2102.01886v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xuefeng Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01886">
                                    <div class="article-summary-box-inner">
                                        <span>In adversarial training (AT), the main focus has been the objective and
optimizer while the model has been less studied, so that the models being used
are still those classic ones in standard training (ST). Classic network
architectures (NAs) are generally worse than searched NAs in ST, which should
be the same in AT. In this paper, we argue that NA and AT cannot be handled
independently, since given a dataset, the optimal NA in ST would be no longer
optimal in AT. That being said, AT is time-consuming itself; if we directly
search NAs in AT over large search spaces, the computation will be practically
infeasible. Thus, we propose a diverse-structured network (DS-Net), to
significantly reduce the size of the search space: instead of low-level
operations, we only consider predefined atomic blocks, where an atomic block is
a time-tested building block like the residual block. There are only a few
atomic blocks and thus we can weight all atomic blocks rather than find the
best one in a searched block of DS-Net, which is an essential trade-off between
exploring diverse structures and exploiting the best structures. Empirical
results demonstrate the advantages of DS-Net, i.e., weighting the atomic
blocks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning. (arXiv:2101.08482v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhaowei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1">Avinash Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1">Charless Fowlkes</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08482">
                                    <div class="article-summary-box-inner">
                                        <span>We present a plug-in replacement for batch normalization (BN) called
exponential moving average normalization (EMAN), which improves the performance
of existing student-teacher based self- and semi-supervised learning
techniques. Unlike the standard BN, where the statistics are computed within
each batch, EMAN, used in the teacher, updates its statistics by exponential
moving average from the BN statistics of the student. This design reduces the
intrinsic cross-sample dependency of BN and enhances the generalization of the
teacher. EMAN improves strong baselines for self-supervised learning by 4-6/1-2
points and semi-supervised learning by about 7/2 points, when 1%/10% supervised
labels are available on ImageNet. These improvements are consistent across
methods, network architectures, training duration, and datasets, demonstrating
the general effectiveness of this technique. The code is available at
https://github.com/amazon-research/exponential-moving-average-normalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Assimilation Predictive GAN (DA-PredGAN): applied to determine the spread of COVID-19. (arXiv:2105.07729v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1">Vinicius L. S. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Heaney_C/0/1/0/all/0/1">Claire E. Heaney</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pain_C/0/1/0/all/0/1">Christopher C. Pain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07729">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the novel use of a generative adversarial network (GAN) (i) to
make predictions in time (PredGAN) and (ii) to assimilate measurements
(DA-PredGAN). In the latter case, we take advantage of the natural adjoint-like
properties of generative models and the ability to simulate forwards and
backwards in time. GANs have received much attention recently, after achieving
excellent results for their generation of realistic-looking images. We wish to
explore how this property translates to new applications in computational
modelling and to exploit the adjoint-like properties for efficient data
assimilation. To predict the spread of COVID-19 in an idealised town, we apply
these methods to a compartmental model in epidemiology that is able to model
space and time variations. To do this, the GAN is set within a reduced-order
model (ROM), which uses a low-dimensional space for the spatial distribution of
the simulation states. Then the GAN learns the evolution of the low-dimensional
states over time. The results show that the proposed methods can accurately
predict the evolution of the high-fidelity numerical simulation, and can
efficiently assimilate observed data and determine the corresponding model
parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quasi-Global Momentum: Accelerating Decentralized Deep Learning on Heterogeneous Data. (arXiv:2102.04761v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04761">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized training of deep learning models is a key element for enabling
data privacy and on-device learning over networks. In realistic learning
scenarios, the presence of heterogeneity across different clients&#x27; local
datasets poses an optimization challenge and may severely deteriorate the
generalization performance. In this paper, we investigate and identify the
limitation of several decentralized optimization algorithms for different
degrees of data heterogeneity. We propose a novel momentum-based method to
mitigate this decentralized training difficulty. We show in extensive empirical
experiments on various CV/NLP datasets (CIFAR-10, ImageNet, and AG News) and
several network topologies (Ring and Social Network) that our method is much
more robust to the heterogeneity of clients&#x27; data than other existing methods,
by a significant improvement in test performance ($1\% \!-\! 20\%$). Our code
is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Dropout Variational Inference for Bayesian Neural Networks. (arXiv:2102.07927v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1">Son Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Duong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Khai Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_N/0/1/0/all/0/1">Nhat Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Than_K/0/1/0/all/0/1">Khoat Than</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_H/0/1/0/all/0/1">Hung Bui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07927">
                                    <div class="article-summary-box-inner">
                                        <span>Approximate inference in deep Bayesian networks exhibits a dilemma of how to
yield high fidelity posterior approximations while maintaining computational
efficiency and scalability. We tackle this challenge by introducing a novel
variational structured approximation inspired by the Bayesian interpretation of
Dropout regularization. Concretely, we focus on the inflexibility of the
factorized structure in Dropout posterior and then propose an improved method
called Variational Structured Dropout (VSD). VSD employs an orthogonal
transformation to learn a structured representation on the variational noise
and consequently induces statistical dependencies in the approximate posterior.
Theoretically, VSD successfully addresses the pathologies of previous
Variational Dropout methods and thus offers a standard Bayesian justification.
We further show that VSD induces an adaptive regularization term with several
desirable properties which contribute to better generalization. Finally, we
conduct extensive experiments on standard benchmarks to demonstrate the
effectiveness of VSD over state-of-the-art variational methods on predictive
accuracy, uncertainty estimation, and out-of-distribution detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Helmholtz equation solver using unsupervised learning: Application to transcranial ultrasound. (arXiv:2010.15761v2 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Stanziola_A/0/1/0/all/0/1">Antonio Stanziola</a>, <a href="http://arxiv.org/find/physics/1/au:+Arridge_S/0/1/0/all/0/1">Simon R. Arridge</a>, <a href="http://arxiv.org/find/physics/1/au:+Cox_B/0/1/0/all/0/1">Ben T. Cox</a>, <a href="http://arxiv.org/find/physics/1/au:+Treeby_B/0/1/0/all/0/1">Bradley E. Treeby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15761">
                                    <div class="article-summary-box-inner">
                                        <span>Transcranial ultrasound therapy is increasingly used for the non-invasive
treatment of brain disorders. However, conventional numerical wave solvers are
currently too computationally expensive to be used online during treatments to
predict the acoustic field passing through the skull (e.g., to account for
subject-specific dose and targeting variations). As a step towards real-time
predictions, in the current work, a fast iterative solver for the heterogeneous
Helmholtz equation in 2D is developed using a fully-learned optimizer. The
lightweight network architecture is based on a modified UNet that includes a
learned hidden state. The network is trained using a physics-based loss
function and a set of idealized sound speed distributions with fully
unsupervised training (no knowledge of the true solution is required). The
learned optimizer shows excellent performance on the test set, and is capable
of generalization well outside the training examples, including to much larger
computational domains, and more complex source and sound speed distributions,
for example, those derived from x-ray computed tomography images of the skull.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Mesh-Based Simulation with Graph Networks. (arXiv:2010.03409v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pfaff_T/0/1/0/all/0/1">Tobias Pfaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortunato_M/0/1/0/all/0/1">Meire Fortunato</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1">Alvaro Sanchez-Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1">Peter W. Battaglia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03409">
                                    <div class="article-summary-box-inner">
                                        <span>Mesh-based simulations are central to modeling complex physical systems in
many disciplines across science and engineering. Mesh representations support
powerful numerical integration methods and their resolution can be adapted to
strike favorable trade-offs between accuracy and efficiency. However,
high-dimensional scientific simulations are very expensive to run, and solvers
and parameters must often be tuned individually to each system studied. Here we
introduce MeshGraphNets, a framework for learning mesh-based simulations using
graph neural networks. Our model can be trained to pass messages on a mesh
graph and to adapt the mesh discretization during forward simulation. Our
results show it can accurately predict the dynamics of a wide range of physical
systems, including aerodynamics, structural mechanics, and cloth. The model&#x27;s
adaptivity supports learning resolution-independent dynamics and can scale to
more complex state spaces at test time. Our method is also highly efficient,
running 1-2 orders of magnitude faster than the simulation on which it is
trained. Our approach broadens the range of problems on which neural network
simulators can operate and promises to improve the efficiency of complex,
scientific modeling tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bootstrap an end-to-end ASR system by multilingual training, transfer learning, text-to-text mapping and synthetic audio. (arXiv:2011.12696v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Giollo_M/0/1/0/all/0/1">Manuel Giollo</a>, <a href="http://arxiv.org/find/eess/1/au:+Gunceler_D/0/1/0/all/0/1">Deniz Gunceler</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yulan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Willett_D/0/1/0/all/0/1">Daniel Willett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12696">
                                    <div class="article-summary-box-inner">
                                        <span>Bootstrapping speech recognition on limited data resources has been an area
of active research for long. The recent transition to all-neural models and
end-to-end (E2E) training brought along particular challenges as these models
are known to be data hungry, but also came with opportunities around
language-agnostic representations derived from multilingual data as well as
shared word-piece output representations across languages that share script and
roots. We investigate here the effectiveness of different strategies to
bootstrap an RNN-Transducer (RNN-T) based automatic speech recognition (ASR)
system in the low resource regime, while exploiting the abundant resources
available in other languages as well as the synthetic audio from a
text-to-speech (TTS) engine. Our experiments demonstrate that transfer learning
from a multilingual model, using a post-ASR text-to-text mapping and synthetic
audio deliver additive improvements, allowing us to bootstrap a model for a new
language with a fraction of the data that would otherwise be needed. The best
system achieved a 46% relative word error rate (WER) reduction compared to the
monolingual baseline, among which 25% relative WER improvement is attributed to
the post-ASR text-to-text mappings and the TTS synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partition-Guided GANs. (arXiv:2104.00816v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Armandpour_M/0/1/0/all/0/1">Mohammadreza Armandpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadeghian_A/0/1/0/all/0/1">Ali Sadeghian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00816">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of Generative Adversarial Networks (GANs), their training
suffers from several well-known problems, including mode collapse and
difficulties learning a disconnected set of manifolds. In this paper, we break
down the challenging task of learning complex high dimensional distributions,
supporting diverse data samples, to simpler sub-tasks. Our solution relies on
designing a partitioner that breaks the space into smaller regions, each having
a simpler distribution, and training a different generator for each partition.
This is done in an unsupervised manner without requiring any labels.

We formulate two desired criteria for the space partitioner that aid the
training of our mixture of generators: 1) to produce connected partitions and
2) provide a proxy of distance between partitions and data samples, along with
a direction for reducing that distance. These criteria are developed to avoid
producing samples from places with non-existent data density, and also
facilitate training by providing additional direction to the generators. We
develop theoretical constraints for a space partitioner to satisfy the above
criteria. Guided by our theoretical analysis, we design an effective neural
architecture for the space partitioner that empirically assures these
conditions. Experimental results on various standard benchmarks show that the
proposed unsupervised model outperforms several recent methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoPhy-PGNN: Learning Physics-guided Neural Networks with Competing Loss Functions for Solving Eigenvalue Problems. (arXiv:2007.01420v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhamod_M/0/1/0/all/0/1">Mohannad Elhamod</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1">Jie Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1">Christopher Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Redell_M/0/1/0/all/0/1">Matthew Redell</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Abantika Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Podolskiy_V/0/1/0/all/0/1">Viktor Podolskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wei-Cheng Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Karpatne_A/0/1/0/all/0/1">Anuj Karpatne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01420">
                                    <div class="article-summary-box-inner">
                                        <span>Physics-guided Neural Networks (PGNNs) represent an emerging class of neural
networks that are trained using physics-guided (PG) loss functions (capturing
violations in network outputs with known physics), along with the supervision
contained in data. Existing work in PGNNs have demonstrated the efficacy of
adding single PG loss functions in the neural network objectives, using
constant trade-off parameters, to ensure better generalizability. However, in
the presence of multiple physics loss functions with competing gradient
directions, there is a need to adaptively tune the contribution of competing PG
loss functions during the course of training to arrive at generalizable
solutions. We demonstrate the presence of competing PG losses in the generic
neural network problem of solving for the lowest (or highest) eigenvector of a
physics-based eigenvalue equation, common to many scientific problems. We
present a novel approach to handle competing PG losses and demonstrate its
efficacy in learning generalizable solutions in two motivating applications of
quantum mechanics and electromagnetic propagation. All the code and data used
in this work is available at https://github.com/jayroxis/Cophy-PGNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise2Sim -- Similarity-based Self-Learning for Image Denoising. (arXiv:2011.03384v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_C/0/1/0/all/0/1">Chuang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1">Fenglei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03384">
                                    <div class="article-summary-box-inner">
                                        <span>Despite its best performance in image denoising, the supervised deep
denoising methods require paired noise-clean data, which are often unavailable.
To address this challenge, Noise2Noise was designed based on the fact that
paired noise-clean images can be replaced by paired noise-noise images that are
easier to collect. However, in many scenarios the collection of paired
noise-noise images is still impractical. To bypass labeled images, Noise2Void
methods predict masked pixels from their surroundings with single noisy images
only and give improved denoising results that still need improvements. An
observation on classic denoising methods is that non-local mean (NLM) outcomes
are typically superior to locally denoised results. In contrast, Noise2Void and
its variants do not utilize self-similarities in an image as the NLM-based
methods do. Here we propose Noise2Sim, an NLM-inspired self-learning method for
image denoising. Specifically, Noise2Sim leverages the self-similarity of image
pixels to train the denoising network, requiring single noisy images only. Our
theoretical analysis shows that Noise2Sim tends to be equivalent to Noise2Noise
under mild conditions. To efficiently manage the computational burden for
globally searching similar pixels, we design a two-step procedure to provide
data for Noise2Sim training. Extensive experiments demonstrate the superiority
of Noise2Sim on common benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Graph Learning for Recommendation. (arXiv:2010.10783v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiancan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1">Jianxun Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10783">
                                    <div class="article-summary-box-inner">
                                        <span>Representation learning on user-item graph for recommendation has evolved
from using single ID or interaction history to exploiting higher-order
neighbors. This leads to the success of graph convolution networks (GCNs) for
recommendation such as PinSage and LightGCN. Despite effectiveness, we argue
that they suffer from two limitations: (1) high-degree nodes exert larger
impact on the representation learning, deteriorating the recommendations of
low-degree (long-tail) items; and (2) representations are vulnerable to noisy
interactions, as the neighborhood aggregation scheme further enlarges the
impact of observed edges.

In this work, we explore self-supervised learning on user-item graph, so as
to improve the accuracy and robustness of GCNs for recommendation. The idea is
to supplement the classical supervised task of recommendation with an auxiliary
self-supervised task, which reinforces node representation learning via
self-discrimination. Specifically, we generate multiple views of a node,
maximizing the agreement between different views of the same node compared to
that of other nodes. We devise three operators to generate the views -- node
dropout, edge dropout, and random walk -- that change the graph structure in
different manners. We term this new learning paradigm as
\textit{Self-supervised Graph Learning} (SGL), implementing it on the
state-of-the-art model LightGCN. Through theoretical analyses, we find that SGL
has the ability of automatically mining hard negatives. Empirical studies on
three benchmark datasets demonstrate the effectiveness of SGL, which improves
the recommendation accuracy, especially on long-tail items, and the robustness
against interaction noises. Our implementations are available at
\url{https://github.com/wujcan/SGL}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RobustSleepNet: Transfer learning for automated sleep staging at scale. (arXiv:2101.02452v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guillot_A/0/1/0/all/0/1">Antoine Guillot</a>, <a href="http://arxiv.org/find/stat/1/au:+Thorey_V/0/1/0/all/0/1">Valentin Thorey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02452">
                                    <div class="article-summary-box-inner">
                                        <span>Sleep disorder diagnosis relies on the analysis of polysomnography (PSG)
records. As a preliminary step of this examination, sleep stages are
systematically determined. In practice, sleep stage classification relies on
the visual inspection of 30-second epochs of polysomnography signals. Numerous
automatic approaches have been developed to replace this tedious and expensive
task. Although these methods demonstrated better performance than human sleep
experts on specific datasets, they remain largely unused in sleep clinics. The
main reason is that each sleep clinic uses a specific PSG montage that most
automatic approaches cannot handle out-of-the-box. Moreover, even when the PSG
montage is compatible, publications have shown that automatic approaches
perform poorly on unseen data with different demographics. To address these
issues, we introduce RobustSleepNet, a deep learning model for automatic sleep
stage classification able to handle arbitrary PSG montages. We trained and
evaluated this model in a leave-one-out-dataset fashion on a large corpus of 8
heterogeneous sleep staging datasets to make it robust to demographic changes.
When evaluated on an unseen dataset, RobustSleepNet reaches 97% of the F1 of a
model explicitly trained on this dataset. Hence, RobustSleepNet unlocks the
possibility to perform high-quality out-of-the-box automatic sleep staging with
any clinical setup. We further show that finetuning RobustSleepNet, using a
part of the unseen dataset, increases the F1 by 2% when compared to a model
trained specifically for this dataset. Therefore, finetuning might be used to
reach a state-of-the-art level of performance on a specific population.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overparameterization of deep ResNet: zero loss and mean-field analysis. (arXiv:2105.14417v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhiyan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_S/0/1/0/all/0/1">Stephen Wright</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14417">
                                    <div class="article-summary-box-inner">
                                        <span>Finding parameters in a deep neural network (NN) that fit training data is a
nonconvex optimization problem, but a basic first-order optimization method
(gradient descent) finds a global solution with perfect fit in many practical
situations. We examine this phenomenon for the case of Residual Neural Networks
(ResNet) with smooth activation functions in a limiting regime in which both
the number of layers (depth) and the number of neurons in each layer (width) go
to infinity. First, we use a mean-field-limit argument to prove that the
gradient descent for parameter training becomes a partial differential equation
(PDE) that characterizes gradient flow for a probability distribution in the
large-NN limit. Next, we show that the solution to the PDE converges in the
training time to a zero-loss solution. Together, these results imply that
training of the ResNet also gives a near-zero loss if the Resnet is large
enough. We give estimates of the depth and width needed to reduce the loss
below a given threshold, with high probability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Learning Vector Quantization for Classification in Randomized Neural Networks and Hyperdimensional Computing. (arXiv:2106.09821v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diao_C/0/1/0/all/0/1">Cameron Diao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1">Denis Kleyko</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabaey_J/0/1/0/all/0/1">Jan M. Rabaey</a>, <a href="http://arxiv.org/find/cs/1/au:+Olshausen_B/0/1/0/all/0/1">Bruno A. Olshausen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09821">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning algorithms deployed on edge devices must meet certain
resource constraints and efficiency requirements. Random Vector Functional Link
(RVFL) networks are favored for such applications due to their simple design
and training efficiency. We propose a modified RVFL network that avoids
computationally expensive matrix operations during training, thus expanding the
network&#x27;s range of potential applications. Our modification replaces the
least-squares classifier with the Generalized Learning Vector Quantization
(GLVQ) classifier, which only employs simple vector and distance calculations.
The GLVQ classifier can also be considered an improvement upon certain
classification algorithms popularly used in the area of Hyperdimensional
Computing. The proposed approach achieved state-of-the-art accuracy on a
collection of datasets from the UCI Machine Learning Repository - higher than
previously proposed RVFL networks. We further demonstrate that our approach
still achieves high accuracy while severely limited in training iterations
(using on average only 21% of the least-squares classifier computational
costs).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedADC: Accelerated Federated Learning with Drift Control. (arXiv:2012.09102v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_E/0/1/0/all/0/1">Emre Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_K/0/1/0/all/0/1">Kerem Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz Gunduz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09102">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) has become de facto framework for collaborative
learning among edge devices with privacy concern. The core of the FL strategy
is the use of stochastic gradient descent (SGD) in a distributed manner. Large
scale implementation of FL brings new challenges, such as the incorporation of
acceleration techniques designed for SGD into the distributed setting, and
mitigation of the drift problem due to non-homogeneous distribution of local
datasets. These two problems have been separately studied in the literature;
whereas, in this paper, we show that it is possible to address both problems
using a single strategy without any major alteration to the FL framework, or
introducing additional computation and communication load. To achieve this
goal, we propose FedADC, which is an accelerated FL algorithm with drift
control. We empirically illustrate the advantages of FedADC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Teacher Class-Incremental Learning With Data-Free Generative Replay. (arXiv:2106.09835v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yoojin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Khamy_M/0/1/0/all/0/1">Mostafa El-Khamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungwon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09835">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes two novel knowledge transfer techniques for
class-incremental learning (CIL). First, we propose data-free generative replay
(DF-GR) to mitigate catastrophic forgetting in CIL by using synthetic samples
from a generative model. In the conventional generative replay, the generative
model is pre-trained for old data and shared in extra memory for later
incremental learning. In our proposed DF-GR, we train a generative model from
scratch without using any training data, based on the pre-trained
classification model from the past, so we curtail the cost of sharing
pre-trained generative models. Second, we introduce dual-teacher information
distillation (DT-ID) for knowledge distillation from two teachers to one
student. In CIL, we use DT-ID to learn new classes incrementally based on the
pre-trained model for old classes and another model (pre-)trained on the new
data for new classes. We implemented the proposed schemes on top of one of the
state-of-the-art CIL methods and showed the performance improvement on
CIFAR-100 and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Architectural Patterns for the Design of Federated Learning Systems. (arXiv:2101.02373v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Sin Kit Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qinghua Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Liming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Paik_H/0/1/0/all/0/1">Hye-young Paik</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02373">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has received fast-growing interests from academia and
industry to tackle the challenges of data hungriness and privacy in machine
learning. A federated learning system can be viewed as a large-scale
distributed system with different components and stakeholders as numerous
client devices participate in federated learning. Designing a federated
learning system requires software system design thinking apart from machine
learning knowledge. Although much effort has been put into federated learning
from the machine learning technique aspects, the software architecture design
concerns in building federated learning systems have been largely ignored.
Therefore, in this paper, we present a collection of architectural patterns to
deal with the design challenges of federated learning systems. Architectural
patterns present reusable solutions to a commonly occurring problem within a
given context during software architecture design. The presented patterns are
based on the results of a systematic literature review and include three client
management patterns, four model management patterns, three model training
patterns, and four model aggregation patterns. The patterns are associated to
the particular state transitions in a federated learning model lifecycle,
serving as a guidance for effective use of the patterns in the design of
federated learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Water Temperature Dynamics of Unmonitored Lakes with Meta Transfer Learning. (arXiv:2011.05369v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Willard_J/0/1/0/all/0/1">Jared D. Willard</a>, <a href="http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1">Jordan S. Read</a>, <a href="http://arxiv.org/find/cs/1/au:+Appling_A/0/1/0/all/0/1">Alison P. Appling</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliver_S/0/1/0/all/0/1">Samantha K. Oliver</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaowei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05369">
                                    <div class="article-summary-box-inner">
                                        <span>Most environmental data come from a minority of well-monitored sites. An
ongoing challenge in the environmental sciences is transferring knowledge from
monitored sites to unmonitored sites. Here, we demonstrate a novel transfer
learning framework that accurately predicts depth-specific temperature in
unmonitored lakes (targets) by borrowing models from well-monitored lakes
(sources). This method, Meta Transfer Learning (MTL), builds a meta-learning
model to predict transfer performance from candidate source models to targets
using lake attributes and candidates&#x27; past performance. We constructed source
models at 145 well-monitored lakes using calibrated process-based modeling (PB)
and a recently developed approach called process-guided deep learning (PGDL).
We applied MTL to either PB or PGDL source models (PB-MTL or PGDL-MTL,
respectively) to predict temperatures in 305 target lakes treated as
unmonitored in the Upper Midwestern United States. We show significantly
improved performance relative to the uncalibrated process-based General Lake
Model, where the median RMSE for the target lakes is $2.52^{\circ}C$. PB-MTL
yielded a median RMSE of $2.43^{\circ}C$; PGDL-MTL yielded $2.16^{\circ}C$; and
a PGDL-MTL ensemble of nine sources per target yielded $1.88^{\circ}C$. For
sparsely monitored target lakes, PGDL-MTL often outperformed PGDL models
trained on the target lakes themselves. Differences in maximum depth between
the source and target were consistently the most important predictors. Our
approach readily scales to thousands of lakes in the Midwestern United States,
demonstrating that MTL with meaningful predictor variables and high-quality
source models is a promising approach for many kinds of unmonitored systems and
environmental variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why Mixup Improves the Model Performance. (arXiv:2006.06231v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kimura_M/0/1/0/all/0/1">Masanari Kimura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06231">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques are used in a wide range of domains. However,
machine learning models often suffer from the problem of over-fitting. Many
data augmentation methods have been proposed to tackle such a problem, and one
of them is called mixup. Mixup is a recently proposed regularization procedure,
which linearly interpolates a random pair of training examples. This
regularization method works very well experimentally, but its theoretical
guarantee is not adequately discussed. In this study, we aim to discover why
mixup works well from the aspect of the statistical learning theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep State Space Models for Nonlinear System Identification. (arXiv:2003.14162v3 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gedon_D/0/1/0/all/0/1">Daniel Gedon</a>, <a href="http://arxiv.org/find/eess/1/au:+Wahlstrom_N/0/1/0/all/0/1">Niklas Wahlstr&#xf6;m</a>, <a href="http://arxiv.org/find/eess/1/au:+Schon_T/0/1/0/all/0/1">Thomas B. Sch&#xf6;n</a>, <a href="http://arxiv.org/find/eess/1/au:+Ljung_L/0/1/0/all/0/1">Lennart Ljung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.14162">
                                    <div class="article-summary-box-inner">
                                        <span>Deep state space models (SSMs) are an actively researched model class for
temporal models developed in the deep learning community which have a close
connection to classic SSMs. The use of deep SSMs as a black-box identification
model can describe a wide range of dynamics due to the flexibility of deep
neural networks. Additionally, the probabilistic nature of the model class
allows the uncertainty of the system to be modelled. In this work a deep SSM
class and its parameter learning algorithm are explained in an effort to extend
the toolbox of nonlinear identification methods with a deep learning based
method. Six recent deep SSMs are evaluated in a first unified implementation on
nonlinear system identification benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Finite Reward Automaton Inference and Reinforcement Learning Using Queries and Counterexamples. (arXiv:2006.15714v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ojha_A/0/1/0/all/0/1">Aditya Ojha</a>, <a href="http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1">Daniel Neider</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15714">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the fact that deep reinforcement learning (RL) has surpassed
human-level performances in various tasks, it still has several fundamental
challenges. First, most RL methods require intensive data from the exploration
of the environment to achieve satisfactory performance. Second, the use of
neural networks in RL renders it hard to interpret the internals of the system
in a way that humans can understand. To address these two challenges, we
propose a framework that enables an RL agent to reason over its exploration
process and distill high-level knowledge for effectively guiding its future
explorations. Specifically, we propose a novel RL algorithm that learns
high-level knowledge in the form of a finite reward automaton by using the L*
learning algorithm. We prove that in episodic RL, a finite reward automaton can
express any non-Markovian bounded reward functions with finitely many reward
values and approximate any non-Markovian bounded reward function (with
infinitely many reward values) with arbitrary precision. We also provide a
lower bound for the episode length such that the proposed RL approach almost
surely converges to an optimal policy in the limit. We test this approach on
two RL environments with non-Markovian reward functions, choosing a variety of
tasks with increasing complexity for each environment. We compare our algorithm
with the state-of-the-art RL algorithms for non-Markovian reward functions,
such as Joint Inference of Reward machines and Policies for RL (JIRP), Learning
Reward Machine (LRM), and Proximal Policy Optimization (PPO2). Our results show
that our algorithm converges to an optimal policy faster than other baseline
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Semantic Segmentation Augmented with Image-Level Weak Annotations. (arXiv:2007.01496v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1">Shuo Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jianfeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fanglan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chang-Tien Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01496">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great progress made by deep neural networks in the semantic
segmentation task, traditional neural-networkbased methods typically suffer
from a shortage of large amounts of pixel-level annotations. Recent progress in
fewshot semantic segmentation tackles the issue by only a few pixel-level
annotated examples. However, these few-shot approaches cannot easily be applied
to multi-way or weak annotation settings. In this paper, we advance the
few-shot segmentation paradigm towards a scenario where image-level annotations
are available to help the training process of a few pixel-level annotations.
Our key idea is to learn a better prototype representation of the class by
fusing the knowledge from the image-level labeled data. Specifically, we
propose a new framework, called PAIA, to learn the class prototype
representation in a metric space by integrating image-level annotations.
Furthermore, by considering the uncertainty of pseudo-masks, a distilled soft
masked average pooling strategy is designed to handle distractions in
image-level annotations. Extensive empirical results on two datasets show
superior performance of PAIA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concurrent Neural Network : A model of competition between times series. (arXiv:2009.14610v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Garnier_R/0/1/0/all/0/1">R&#xe9;my Garnier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14610">
                                    <div class="article-summary-box-inner">
                                        <span>Competition between times series often arises in sales prediction, when
similar products are on sale on a marketplace. This article provides a model of
the presence of cannibalization between times series. This model creates a
&quot;competitiveness&quot; function that depends on external features such as price and
margin. It also provides a theoretical guaranty on the error of the model under
some reasonable conditions, and implement this model using a neural network to
compute this competitiveness function. This implementation outperforms other
traditional time series methods and classical neural networks for market share
prediction on a real-world data set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Information Agent Modelling in Partially-Observable Environments. (arXiv:2006.09447v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1">Georgios Papoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1">Filippos Christianos</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09447">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling the behaviours of other agents is essential for understanding how
agents interact and making effective decisions. Existing methods for agent
modelling commonly assume knowledge of the local observations and chosen
actions of the modelled agents during execution. To eliminate this assumption,
we extract representations from the local information of the controlled agent
using encoder-decoder architectures. Using the observations and actions of the
modelled agents during training, our models learn to extract representations
about the modelled agents conditioned only on the local observations of the
controlled agent. The representations are used to augment the controlled
agent&#x27;s decision policy which is trained via deep reinforcement learning; thus,
during execution, the policy does not require access to other agents&#x27;
information. We provide a comprehensive evaluation and ablations studies in
cooperative, competitive and mixed multi-agent environments, showing that our
method achieves significantly higher returns than baseline methods which do not
use the learned representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CIRA Guide to Custom Loss Functions for Neural Networks in Environmental Sciences -- Version 1. (arXiv:2106.09757v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ebert_Uphoff_I/0/1/0/all/0/1">Imme Ebert-Uphoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Lagerquist_R/0/1/0/all/0/1">Ryan Lagerquist</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilburn_K/0/1/0/all/0/1">Kyle Hilburn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yoonjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Haynes_K/0/1/0/all/0/1">Katherine Haynes</a>, <a href="http://arxiv.org/find/cs/1/au:+Stock_J/0/1/0/all/0/1">Jason Stock</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumler_C/0/1/0/all/0/1">Christina Kumler</a>, <a href="http://arxiv.org/find/cs/1/au:+Stewart_J/0/1/0/all/0/1">Jebb Q. Stewart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09757">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are increasingly used in environmental science applications.
Furthermore, neural network models are trained by minimizing a loss function,
and it is crucial to choose the loss function very carefully for environmental
science applications, as it determines what exactly is being optimized.
Standard loss functions do not cover all the needs of the environmental
sciences, which makes it important for scientists to be able to develop their
own custom loss functions so that they can implement many of the classic
performance measures already developed in environmental science, including
measures developed for spatial model verification. However, there are very few
resources available that cover the basics of custom loss function development
comprehensively, and to the best of our knowledge none that focus on the needs
of environmental scientists. This document seeks to fill this gap by providing
a guide on how to write custom loss functions targeted toward environmental
science applications. Topics include the basics of writing custom loss
functions, common pitfalls, functions to use in loss functions, examples such
as fractions skill score as loss function, how to incorporate physical
constraints, discrete and soft discretization, and concepts such as focal,
robust, and adaptive loss. While examples are currently provided in this guide
for Python with Keras and the TensorFlow backend, the basic concepts also apply
to other environments, such as Python with PyTorch. Similarly, while the sample
loss functions provided here are from meteorology, these are just examples of
how to create custom loss functions. Other fields in the environmental sciences
have very similar needs for custom loss functions, e.g., for evaluating spatial
forecasts effectively, and the concepts discussed here can be applied there as
well. All code samples are provided in a GitHub repository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MARS: Masked Automatic Ranks Selection in Tensor Decompositions. (arXiv:2006.10859v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kodryan_M/0/1/0/all/0/1">Maxim Kodryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kropotov_D/0/1/0/all/0/1">Dmitry Kropotov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1">Dmitry Vetrov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10859">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor decomposition methods are known to be efficient for compressing and
accelerating neural networks. However, the problem of optimal decomposition
structure determination is still not well studied while being quite important.
Specifically, decomposition ranks present the crucial parameter controlling the
compression-accuracy trade-off. In this paper, we introduce MARS -- a new
efficient method for the automatic selection of ranks in general tensor
decompositions. During training, the procedure learns binary masks over
decomposition cores that &quot;select&quot; the optimal tensor structure. The learning is
performed via relaxed maximum a posteriori (MAP) estimation in a specific
Bayesian model. The proposed method achieves better results compared to
previous works in various tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Stochastic Compositional Optimization is Nearly as Easy as Solving Stochastic Optimization. (arXiv:2008.10847v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1">Tianyi Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yuejiao Sun</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10847">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic compositional optimization generalizes classic (non-compositional)
stochastic optimization to the minimization of compositions of functions. Each
composition may introduce an additional expectation. The series of expectations
may be nested. Stochastic compositional optimization is gaining popularity in
applications such as reinforcement learning and meta learning. This paper
presents a new Stochastically Corrected Stochastic Compositional gradient
method (SCSC). SCSC runs in a single-time scale with a single loop, uses a
fixed batch size, and guarantees to converge at the same rate as the stochastic
gradient descent (SGD) method for non-compositional stochastic optimization.
This is achieved by making a careful improvement to a popular stochastic
compositional gradient method. It is easy to apply SGD-improvement techniques
to accelerate SCSC. This helps SCSC achieve state-of-the-art performance for
stochastic compositional optimization. In particular, we apply Adam to SCSC,
and the exhibited rate of convergence matches that of the original Adam on
non-compositional stochastic optimization. We test SCSC using the portfolio
management and model-agnostic meta-learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Change-Point Detection with Training Sequences in the Large and Moderate Deviations Regimes. (arXiv:2003.06511v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Haiyun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiaosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06511">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates a novel offline change-point detection problem from
an information-theoretic perspective. In contrast to most related works, we
assume that the knowledge of the underlying pre- and post-change distributions
are not known and can only be learned from the training sequences which are
available. We further require the probability of the \emph{estimation error} to
decay either exponentially or sub-exponentially fast (corresponding
respectively to the large and moderate deviations regimes in information theory
parlance). Based on the training sequences as well as the test sequence
consisting of a single change-point, we design a change-point estimator and
further show that this estimator is optimal by establishing matching (strong)
converses. This leads to a full characterization of the optimal confidence
width (i.e., half the width of the confidence interval within which the true
change-point is located at with high probability) as a function of the
undetected error, under both the large and moderate deviations regimes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Trimmed Lasso: Sparse Recovery Guarantees and Practical Optimization by the Generalized Soft-Min Penalty. (arXiv:2005.09021v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amir_T/0/1/0/all/0/1">Tal Amir</a>, <a href="http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1">Ronen Basri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadler_B/0/1/0/all/0/1">Boaz Nadler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09021">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new approach to solve the sparse approximation or best subset
selection problem, namely find a $k$-sparse vector ${\bf x}\in\mathbb{R}^d$
that minimizes the $\ell_2$ residual $\lVert A{\bf x}-{\bf y} \rVert_2$. We
consider a regularized approach, whereby this residual is penalized by the
non-convex $\textit{trimmed lasso}$, defined as the $\ell_1$-norm of ${\bf x}$
excluding its $k$ largest-magnitude entries. We prove that the trimmed lasso
has several appealing theoretical properties, and in particular derive sparse
recovery guarantees assuming successful optimization of the penalized
objective. Next, we show empirically that directly optimizing this objective
can be quite challenging. Instead, we propose a surrogate for the trimmed
lasso, called the $\textit{generalized soft-min}$. This penalty smoothly
interpolates between the classical lasso and the trimmed lasso, while taking
into account all possible $k$-sparse patterns. The generalized soft-min penalty
involves summation over $\binom{d}{k}$ terms, yet we derive a polynomial-time
algorithm to compute it. This, in turn, yields a practical method for the
original sparse approximation problem. Via simulations, we demonstrate its
competitive performance compared to current state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leakage of Dataset Properties in Multi-Party Machine Learning. (arXiv:2006.07267v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wanrong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1">Shruti Tople</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohrimenko_O/0/1/0/all/0/1">Olga Ohrimenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07267">
                                    <div class="article-summary-box-inner">
                                        <span>Secure multi-party machine learning allows several parties to build a model
on their pooled data to increase utility while not explicitly sharing data with
each other. We show that such multi-party computation can cause leakage of
global dataset properties between the parties even when parties obtain only
black-box access to the final model. In particular, a &#x60;&#x60;curious&#x27;&#x27; party can
infer the distribution of sensitive attributes in other parties&#x27; data with high
accuracy. This raises concerns regarding the confidentiality of properties
pertaining to the whole dataset as opposed to individual data records. We show
that our attack can leak population-level properties in datasets of different
types, including tabular, text, and graph data. To understand and measure the
source of leakage, we consider several models of correlation between a
sensitive attribute and the rest of the data. Using multiple machine learning
models, we show that leakage occurs even if the sensitive attribute is not
included in the training data and has a low correlation with other attributes
or the target variable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NoiseGrad: enhancing explanations by introducing stochasticity to model weights. (arXiv:2106.10185v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bykov_K/0/1/0/all/0/1">Kirill Bykov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hedstrom_A/0/1/0/all/0/1">Anna Hedstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1">Shinichi Nakajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_M/0/1/0/all/0/1">Marina M.-C. H&#xf6;hne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10185">
                                    <div class="article-summary-box-inner">
                                        <span>Attribution methods remain a practical instrument that is used in real-world
applications to explain the decision-making process of complex learning
machines. It has been shown that a simple method called SmoothGrad can
effectively reduce the visual diffusion of gradient-based attribution methods
and has established itself among both researchers and practitioners. What
remains unexplored in research, however, is how explanations can be improved by
introducing stochasticity to the model weights. In the light of this, we
introduce - NoiseGrad - a stochastic, method-agnostic explanation-enhancing
method that adds noise to the weights instead of the input data. We investigate
our proposed method through various experiments including different datasets,
explanation methods and network architectures and conclude that NoiseGrad (and
its extension NoiseGrad++) with multiplicative Gaussian noise offers a clear
advantage compared to SmoothGrad on several evaluation criteria. We connect our
proposed method to Bayesian Learning and provide the user with a heuristic for
choosing hyperparameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FinGAT: Financial Graph Attention Networks for Recommending Top-K Profitable Stocks. (arXiv:2106.10159v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1">Yi-Ling Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yu-Che Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Cheng-Te Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10159">
                                    <div class="article-summary-box-inner">
                                        <span>Financial technology (FinTech) has drawn much attention among investors and
companies. While conventional stock analysis in FinTech targets at predicting
stock prices, less effort is made for profitable stock recommendation. Besides,
in existing approaches on modeling time series of stock prices, the
relationships among stocks and sectors (i.e., categories of stocks) are either
neglected or pre-defined. Ignoring stock relationships will miss the
information shared between stocks while using pre-defined relationships cannot
depict the latent interactions or influence of stock prices between stocks. In
this work, we aim at recommending the top-K profitable stocks in terms of
return ratio using time series of stock prices and sector information. We
propose a novel deep learning-based model, Financial Graph Attention Networks
(FinGAT), to tackle the task under the setting that no pre-defined
relationships between stocks are given. The idea of FinGAT is three-fold.
First, we devise a hierarchical learning component to learn short-term and
long-term sequential patterns from stock time series. Second, a fully-connected
graph between stocks and a fully-connected graph between sectors are
constructed, along with graph attention networks, to learn the latent
interactions among stocks and sectors. Third, a multi-task objective is devised
to jointly recommend the profitable stocks and predict the stock movement.
Experiments conducted on Taiwan Stock, S&amp;P 500, and NASDAQ datasets exhibit
remarkable recommendation performance of our FinGAT, comparing to
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low Resource German ASR with Untranscribed Data Spoken by Non-native Children -- INTERSPEECH 2021 Shared Task SPAPL System. (arXiv:2106.09963v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jinhan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1">Yunzheng Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_R/0/1/0/all/0/1">Ruchao Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Chu_W/0/1/0/all/0/1">Wei Chu</a>, <a href="http://arxiv.org/find/eess/1/au:+Alwan_A/0/1/0/all/0/1">Abeer Alwan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09963">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the SPAPL system for the INTERSPEECH 2021 Challenge:
Shared Task on Automatic Speech Recognition for Non-Native Children&#x27;s Speech in
German. ~ 5 hours of transcribed data and ~ 60 hours of untranscribed data are
provided to develop a German ASR system for children. For the training of the
transcribed data, we propose a non-speech state discriminative loss (NSDL) to
mitigate the influence of long-duration non-speech segments within speech
utterances. In order to explore the use of the untranscribed data, various
approaches are implemented and combined together to incrementally improve the
system performance. First, bidirectional autoregressive predictive coding
(Bi-APC) is used to learn initial parameters for acoustic modelling using the
provided untranscribed data. Second, incremental semi-supervised learning is
further used to iteratively generate pseudo-transcribed data. Third, different
data augmentation schemes are used at different training stages to increase the
variability and size of the training data. Finally, a recurrent neural network
language model (RNNLM) is used for rescoring. Our system achieves a word error
rate (WER) of 39.68% on the evaluation data, an approximately 12% relative
improvement over the official baseline (45.21%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Code Sketches. (arXiv:2106.10158v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1">Daya Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1">Alexey Svyatkovskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jian Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1">Marc Brockschmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Allamanis_M/0/1/0/all/0/1">Miltiadis Allamanis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10158">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional generative models are limited to predicting sequences of terminal
tokens. However, ambiguities in the generation task may lead to incorrect
outputs. Towards addressing this, we introduce Grammformers, transformer-based
grammar-guided models that learn (without explicit supervision) to generate
sketches -- sequences of tokens with holes. Through reinforcement learning,
Grammformers learn to introduce holes avoiding the generation of incorrect
tokens where there is ambiguity in the target task.

We train Grammformers for statement-level source code completion, i.e., the
generation of code snippets given an ambiguous user intent, such as a partial
code context. We evaluate Grammformers on code completion for C# and Python and
show that it generates 10-50% more accurate sketches compared to traditional
generative models and 37-50% longer sketches compared to sketch-generating
baselines trained with similar techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating the Role of Negatives in Contrastive Representation Learning. (arXiv:2106.09943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1">Dipendra Misra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09943">
                                    <div class="article-summary-box-inner">
                                        <span>Noise contrastive learning is a popular technique for unsupervised
representation learning. In this approach, a representation is obtained via
reduction to supervised learning, where given a notion of semantic similarity,
the learner tries to distinguish a similar (positive) example from a collection
of random (negative) examples. The success of modern contrastive learning
pipelines relies on many parameters such as the choice of data augmentation,
the number of negative examples, and the batch size; however, there is limited
understanding as to how these parameters interact and affect downstream
performance. We focus on disambiguating the role of one of these parameters:
the number of negative examples. Theoretically, we show the existence of a
collision-coverage trade-off suggesting that the optimal number of negative
examples should scale with the number of underlying concepts in the data.
Empirically, we scrutinize the role of the number of negatives in both NLP and
vision tasks. In the NLP task, we find that the results broadly agree with our
theory, while our vision experiments are murkier with performance sometimes
even being insensitive to the number of negatives. We discuss plausible
explanations for this behavior and suggest future directions to better align
theory and practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">World-GAN: a Generative Model for Minecraft Worlds. (arXiv:2106.10155v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awiszus_M/0/1/0/all/0/1">Maren Awiszus</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubert_F/0/1/0/all/0/1">Frederik Schubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10155">
                                    <div class="article-summary-box-inner">
                                        <span>This work introduces World-GAN, the first method to perform data-driven
Procedural Content Generation via Machine Learning in Minecraft from a single
example. Based on a 3D Generative Adversarial Network (GAN) architecture, we
are able to create arbitrarily sized world snippets from a given sample. We
evaluate our approach on creations from the community as well as structures
generated with the Minecraft World Generator. Our method is motivated by the
dense representations used in Natural Language Processing (NLP) introduced with
word2vec [1]. The proposed block2vec representations make World-GAN independent
from the number of different blocks, which can vary a lot in Minecraft, and
enable the generation of larger levels. Finally, we demonstrate that changing
this new representation space allows us to change the generated style of an
already trained generator. World-GAN enables its users to generate Minecraft
worlds based on parts of their creations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Contrastive Representations of Stochastic Processes. (arXiv:2106.10052v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mathieu_E/0/1/0/all/0/1">Emile Mathieu</a>, <a href="http://arxiv.org/find/stat/1/au:+Foster_A/0/1/0/all/0/1">Adam Foster</a>, <a href="http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10052">
                                    <div class="article-summary-box-inner">
                                        <span>Learning representations of stochastic processes is an emerging problem in
machine learning with applications from meta-learning to physical object models
to time series. Typical methods rely on exact reconstruction of observations,
but this approach breaks down as observations become high-dimensional or noise
distributions become complex. To address this, we propose a unifying framework
for learning contrastive representations of stochastic processes (CRESP) that
does away with exact reconstruction. We dissect potential use cases for
stochastic process representations, and propose methods that accommodate each.
Empirically, we show that our methods are effective for learning
representations of periodic functions, 3D objects and dynamical processes. Our
methods tolerate noisy high-dimensional observations better than traditional
approaches, and the learned representations transfer to a range of downstream
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wide stochastic networks: Gaussian limit and PAC-Bayesian training. (arXiv:2106.09798v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Clerico_E/0/1/0/all/0/1">Eugenio Clerico</a>, <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09798">
                                    <div class="article-summary-box-inner">
                                        <span>The limit of infinite width allows for substantial simplifications in the
analytical study of overparameterized neural networks. With a suitable random
initialization, an extremely large network is well approximated by a Gaussian
process, both before and during training. In the present work, we establish a
similar result for a simple stochastic architecture whose parameters are random
variables. The explicit evaluation of the output distribution allows for a
PAC-Bayesian training procedure that directly optimizes the generalization
bound. For a large but finite-width network, we show empirically on MNIST that
this training approach can outperform standard PAC-Bayesian methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Analysis of the Deployment of Models Trained on Private Tabular Synthetic Data: Unexpected Surprises. (arXiv:2106.10241v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pereira_M/0/1/0/all/0/1">Mayana Pereira</a>, <a href="http://arxiv.org/find/stat/1/au:+Kshirsagar_M/0/1/0/all/0/1">Meghana Kshirsagar</a>, <a href="http://arxiv.org/find/stat/1/au:+Mukherjee_S/0/1/0/all/0/1">Sumit Mukherjee</a>, <a href="http://arxiv.org/find/stat/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>, <a href="http://arxiv.org/find/stat/1/au:+Ferres_J/0/1/0/all/0/1">Juan Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10241">
                                    <div class="article-summary-box-inner">
                                        <span>Diferentially private (DP) synthetic datasets are a powerful approach for
training machine learning models while respecting the privacy of individual
data providers. The effect of DP on the fairness of the resulting trained
models is not yet well understood. In this contribution, we systematically
study the effects of differentially private synthetic data generation on
classification. We analyze disparities in model utility and bias caused by the
synthetic dataset, measured through algorithmic fairness metrics. Our first set
of results show that although there seems to be a clear negative correlation
between privacy and utility (the more private, the less accurate) across all
data synthesizers we evaluated, more privacy does not necessarily imply more
bias. Additionally, we assess the effects of utilizing synthetic datasets for
model training and model evaluation. We show that results obtained on synthetic
data can misestimate the actual model performance when it is deployed on real
data. We hence advocate on the need for defining proper testing protocols in
scenarios where differentially private synthetic datasets are utilized for
model training and evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistency of Extreme Learning Machines and Regression under Non-Stationarity and Dependence for ML-Enhanced Moving Objects. (arXiv:2005.11115v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Steland_A/0/1/0/all/0/1">Ansgar Steland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.11115">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning by extreme learning machines resp. neural networks with
random weights is studied under a non-stationary spatial-temporal sampling
design which especially addresses settings where an autonomous object moving in
a non-stationary spatial environment collects and analyzes data. The stochastic
model especially allows for spatial heterogeneity and weak dependence. As
efficient and computationally cheap learning methods (unconstrained) least
squares, ridge regression and $\ell_s$-penalized least squares (including the
LASSO) are studied. Consistency and asymptotic normality of the least squares
and ridge regression estimates as well as corresponding consistency results for
the $\ell_s$-penalty are shown under weak conditions. The resuts also cover
bounds for the sample squared predicition error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Reduction and Neural Networks for Parametric PDEs. (arXiv:2005.03180v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Bhattacharya_K/0/1/0/all/0/1">Kaushik Bhattacharya</a>, <a href="http://arxiv.org/find/math/1/au:+Hosseini_B/0/1/0/all/0/1">Bamdad Hosseini</a>, <a href="http://arxiv.org/find/math/1/au:+Kovachki_N/0/1/0/all/0/1">Nikola B. Kovachki</a>, <a href="http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1">Andrew M. Stuart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03180">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a general framework for data-driven approximation of input-output
maps between infinite-dimensional spaces. The proposed approach is motivated by
the recent successes of neural networks and deep learning, in combination with
ideas from model reduction. This combination results in a neural network
approximation which, in principle, is defined on infinite-dimensional spaces
and, in practice, is robust to the dimension of finite-dimensional
approximations of these spaces required for computation. For a class of
input-output maps, and suitably chosen probability measures on the inputs, we
prove convergence of the proposed approximation methodology. We also include
numerical experiments which demonstrate the effectiveness of the method,
showing convergence and robustness of the approximation scheme with respect to
the size of the discretization, and compare it with existing algorithms from
the literature; our examples include the mapping from coefficient to solution
in a divergence form elliptic partial differential equation (PDE) problem, and
the solution operator for viscous Burgers&#x27; equation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Residual Error: a New Performance Measure for Adversarial Robustness. (arXiv:2106.10212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aboutalebi_H/0/1/0/all/0/1">Hossein Aboutalebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1">Mohammad Javad Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Karg_M/0/1/0/all/0/1">Michelle Karg</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharfenberger_C/0/1/0/all/0/1">Christian Scharfenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10212">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the significant advances in deep learning over the past decade, a
major challenge that limits the wide-spread adoption of deep learning has been
their fragility to adversarial attacks. This sensitivity to making erroneous
predictions in the presence of adversarially perturbed data makes deep neural
networks difficult to adopt for certain real-world, mission-critical
applications. While much of the research focus has revolved around adversarial
example creation and adversarial hardening, the area of performance measures
for assessing adversarial robustness is not well explored. Motivated by this,
this study presents the concept of residual error, a new performance measure
for not only assessing the adversarial robustness of a deep neural network at
the individual sample level, but also can be used to differentiate between
adversarial and non-adversarial examples to facilitate for adversarial example
detection. Furthermore, we introduce a hybrid model for approximating the
residual error in a tractable manner. Experimental results using the case of
image classification demonstrates the effectiveness and efficacy of the
proposed residual error metric for assessing several well-known deep neural
network architectures. These results thus illustrate that the proposed measure
could be a useful tool for not only assessing the robustness of deep neural
networks used in mission-critical scenarios, but also in the design of
adversarially robust models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No Routing Needed Between Capsules. (arXiv:2001.09136v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Byerly_A/0/1/0/all/0/1">Adam Byerly</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalganova_T/0/1/0/all/0/1">Tatiana Kalganova</a>, <a href="http://arxiv.org/find/cs/1/au:+Dear_I/0/1/0/all/0/1">Ian Dear</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09136">
                                    <div class="article-summary-box-inner">
                                        <span>Most capsule network designs rely on traditional matrix multiplication
between capsule layers and computationally expensive routing mechanisms to deal
with the capsule dimensional entanglement that the matrix multiplication
introduces. By using Homogeneous Vector Capsules (HVCs), which use element-wise
multiplication rather than matrix multiplication, the dimensions of the
capsules remain unentangled. In this work, we study HVCs as applied to the
highly structured MNIST dataset in order to produce a direct comparison to the
capsule research direction of Geoffrey Hinton, et al. In our study, we show
that a simple convolutional neural network using HVCs performs as well as the
prior best performing capsule network on MNIST using 5.5x fewer parameters, 4x
fewer training epochs, no reconstruction sub-network, and requiring no routing
mechanism. The addition of multiple classification branches to the network
establishes a new state of the art for the MNIST dataset with an accuracy of
99.87% for an ensemble of these models, as well as establishing a new state of
the art for a single model (99.83% accurate).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Private Graph Neural Networks. (arXiv:2006.05535v8 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sajadmanesh_S/0/1/0/all/0/1">Sina Sajadmanesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatica_Perez_D/0/1/0/all/0/1">Daniel Gatica-Perez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning node representations for various graph inference tasks. However,
learning over graph data can raise privacy concerns when nodes represent people
or human-related variables that involve sensitive or personal information.
While numerous techniques have been proposed for privacy-preserving deep
learning over non-relational data, there is less work addressing the privacy
issues pertained to applying deep learning algorithms on graphs. In this paper,
we study the problem of node data privacy, where graph nodes have potentially
sensitive data that is kept private, but they could be beneficial for a central
server for training a GNN over the graph. To address this problem, we develop a
privacy-preserving, architecture-agnostic GNN learning algorithm with formal
privacy guarantees based on Local Differential Privacy (LDP). Specifically, we
propose an LDP encoder and an unbiased rectifier, by which the server can
communicate with the graph nodes to privately collect their data and
approximate the GNN&#x27;s first layer. To further reduce the effect of the injected
noise, we propose to prepend a simple graph convolution layer, called KProp,
which is based on the multi-hop aggregation of the nodes&#x27; features acting as a
denoising mechanism. Finally, we propose a robust training framework, in which
we benefit from KProp&#x27;s denoising capability to increase the accuracy of
inference in the presence of noisy labels. Extensive experiments conducted over
real-world datasets demonstrate that our method can maintain a satisfying level
of accuracy with low privacy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Pseudo-Point and State Space Approximations for Sum-Separable Gaussian Processes. (arXiv:2106.10210v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tebbutt_W/0/1/0/all/0/1">Will Tebbutt</a>, <a href="http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1">Arno Solin</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10210">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) are important probabilistic tools for inference and
learning in spatio-temporal modelling problems such as those in climate science
and epidemiology. However, existing GP approximations do not simultaneously
support large numbers of off-the-grid spatial data-points and long time-series
which is a hallmark of many applications.

Pseudo-point approximations, one of the gold-standard methods for scaling GPs
to large data sets, are well suited for handling off-the-grid spatial data.
However, they cannot handle long temporal observation horizons effectively
reverting to cubic computational scaling in the time dimension. State space GP
approximations are well suited to handling temporal data, if the temporal GP
prior admits a Markov form, leading to linear complexity in the number of
temporal observations, but have a cubic spatial cost and cannot handle
off-the-grid spatial data.

In this work we show that there is a simple and elegant way to combine
pseudo-point methods with the state space GP approximation framework to get the
best of both worlds. The approach hinges on a surprising conditional
independence property which applies to space--time separable GPs. We
demonstrate empirically that the combined approach is more scalable and
applicable to a greater range of spatio-temporal problems than either method on
its own.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonparametric Hamiltonian Monte Carlo. (arXiv:2106.10238v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mak_C/0/1/0/all/0/1">Carol Mak</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaiser_F/0/1/0/all/0/1">Fabian Zaiser</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1">Luke Ong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10238">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic programming uses programs to express generative models whose
posterior probability is then computed by built-in inference engines. A
challenging goal is to develop general purpose inference algorithms that work
out-of-the-box for arbitrary programs in a universal probabilistic programming
language (PPL). The densities defined by such programs, which may use
stochastic branching and recursion, are (in general) nonparametric, in the
sense that they correspond to models on an infinite-dimensional parameter
space. However standard inference algorithms, such as the Hamiltonian Monte
Carlo (HMC) algorithm, target distributions with a fixed number of parameters.
This paper introduces the Nonparametric Hamiltonian Monte Carlo (NP-HMC)
algorithm which generalises HMC to nonparametric models. Inputs to NP-HMC are a
new class of measurable functions called &quot;tree representable&quot;, which serve as a
language-independent representation of the density functions of probabilistic
programs in a universal PPL. We provide a correctness proof of NP-HMC, and
empirically demonstrate significant performance improvements over existing
approaches on several nonparametric examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Some Theoretical Insights into Wasserstein GANs. (arXiv:2006.02682v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biau_G/0/1/0/all/0/1">G&#xe9;rard Biau</a> (LPSM (UMR\_8001)), <a href="http://arxiv.org/find/cs/1/au:+Sangnier_M/0/1/0/all/0/1">Maxime Sangnier</a> (LPSM (UMR\_8001)), <a href="http://arxiv.org/find/cs/1/au:+Tanielian_U/0/1/0/all/0/1">Ugo Tanielian</a> (LPSM (UMR\_8001))
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02682">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have been successful in producing
outstanding results in areas as diverse as image, video, and text generation.
Building on these successes, a large number of empirical studies have validated
the benefits of the cousin approach called Wasserstein GANs (WGANs), which
brings stabilization in the training process. In the present paper, we add a
new stone to the edifice by proposing some theoretical advances in the
properties of WGANs. First, we properly define the architecture of WGANs in the
context of integral probability metrics parameterized by neural networks and
highlight some of their basic mathematical features. We stress in particular
interesting optimization properties arising from the use of a parametric
1-Lipschitz discriminator. Then, in a statistically-driven approach, we study
the convergence of empirical WGANs as the sample size tends to infinity, and
clarify the adversarial effects of the generator and the discriminator by
underlining some trade-off properties. These features are finally illustrated
with experiments using both synthetic and real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boltzmann machine learning and regularization methods for inferring evolutionary fields and couplings from a multiple sequence alignment. (arXiv:1909.05006v3 [q-bio.PE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Miyazawa_S/0/1/0/all/0/1">Sanzo Miyazawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.05006">
                                    <div class="article-summary-box-inner">
                                        <span>The inverse Potts problem to infer a Boltzmann distribution for homologous
protein sequences from their single-site and pairwise amino acid frequencies
recently attracts a great deal of attention in the studies of protein structure
and evolution. We study regularization and learning methods and how to tune
regularization parameters to correctly infer interactions in Boltzmann machine
learning. Using $L_2$ regularization for fields, group $L_1$ for couplings is
shown to be very effective for sparse couplings in comparison with $L_2$ and
$L_1$. Two regularization parameters are tuned to yield equal values for both
the sample and ensemble averages of evolutionary energy. Both averages smoothly
change and converge, but their learning profiles are very different between
learning methods. The Adam method is modified to make stepsize proportional to
the gradient for sparse couplings and to use a soft-thresholding function for
group $L_1$. It is shown by first inferring interactions from protein sequences
and then from Monte Carlo samples that the fields and couplings can be well
recovered, but that recovering the pairwise correlations in the resolution of a
total energy is harder for the natural proteins than for the protein-like
sequences. Selective temperature for folding/structural constrains in protein
evolution is also estimated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-Device Personalization of Automatic Speech Recognition Models for Disordered Speech. (arXiv:2106.10259v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tomanek_K/0/1/0/all/0/1">Katrin Tomanek</a>, <a href="http://arxiv.org/find/eess/1/au:+Beaufays_F/0/1/0/all/0/1">Fran&#xe7;oise Beaufays</a>, <a href="http://arxiv.org/find/eess/1/au:+Cattiau_J/0/1/0/all/0/1">Julie Cattiau</a>, <a href="http://arxiv.org/find/eess/1/au:+Chandorkar_A/0/1/0/all/0/1">Angad Chandorkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Sim_K/0/1/0/all/0/1">Khe Chai Sim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10259">
                                    <div class="article-summary-box-inner">
                                        <span>While current state-of-the-art Automatic Speech Recognition (ASR) systems
achieve high accuracy on typical speech, they suffer from significant
performance degradation on disordered speech and other atypical speech
patterns. Personalization of ASR models, a commonly applied solution to this
problem, is usually performed in a server-based training environment posing
problems around data privacy, delayed model-update times, and communication
cost for copying data and models between mobile device and server
infrastructure. In this paper, we present an approach to on-device based ASR
personalization with very small amounts of speaker-specific data. We test our
approach on a diverse set of 100 speakers with disordered speech and find
median relative word error rate improvement of 71% with only 50 short
utterances required per speaker. When tested on a voice-controlled home
automation platform, on-device personalized models show a median task success
rate of 81%, compared to only 40% of the unadapted models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embodied Language Grounding with 3D Visual Feature Representations. (arXiv:1910.01210v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Prabhudesai_M/0/1/0/all/0/1">Mihir Prabhudesai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tung_H/0/1/0/all/0/1">Hsiao-Yu Fish Tung</a>, <a href="http://arxiv.org/find/cs/1/au:+Javed_S/0/1/0/all/0/1">Syed Ashar Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Sieb_M/0/1/0/all/0/1">Maximilian Sieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Harley_A/0/1/0/all/0/1">Adam W. Harley</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1">Katerina Fragkiadaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.01210">
                                    <div class="article-summary-box-inner">
                                        <span>We propose associating language utterances to 3D visual abstractions of the
scene they describe. The 3D visual abstractions are encoded as 3-dimensional
visual feature maps. We infer these 3D visual scene feature maps from RGB
images of the scene via view prediction: when the generated 3D scene feature
map is neurally projected from a camera viewpoint, it should match the
corresponding RGB image. We present generative models that condition on the
dependency tree of an utterance and generate a corresponding visual 3D feature
map as well as reason about its plausibility, and detector models that
condition on both the dependency tree of an utterance and a related image and
localize the object referents in the 3D feature map inferred from the image.
Our model outperforms models of language and vision that associate language
with 2D CNN activations or 2D images by a large margin in a variety of tasks,
such as, classifying plausibility of utterances, detecting referential
expressions, and supplying rewards for trajectory optimization of object
placement policies from language instructions. We perform numerous ablations
and show the improved performance of our detectors is due to its better
generalization across camera viewpoints and lack of object interferences in the
inferred 3D feature space, and the improved performance of our generators is
due to their ability to spatially reason about objects and their configurations
in 3D when mapping from language to scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Probabilistic Representation of DNNs: Bridging Mutual Information and Generalization. (arXiv:2106.10262v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_X/0/1/0/all/0/1">Xinjie Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Barner_K/0/1/0/all/0/1">Kenneth Barner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10262">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Mutual Information (MI) has attracted attention in bounding the
generalization error of Deep Neural Networks (DNNs). However, it is intractable
to accurately estimate the MI in DNNs, thus most previous works have to relax
the MI bound, which in turn weakens the information theoretic explanation for
generalization. To address the limitation, this paper introduces a
probabilistic representation of DNNs for accurately estimating the MI.
Leveraging the proposed MI estimator, we validate the information theoretic
explanation for generalization, and derive a tighter generalization bound than
the state-of-the-art relaxations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LoRMIkA: Local rule-based model interpretability with k-optimal associations. (arXiv:1908.03840v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajapaksha_D/0/1/0/all/0/1">Dilini Rajapaksha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a>, <a href="http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1">Wray Buntine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.03840">
                                    <div class="article-summary-box-inner">
                                        <span>As we rely more and more on machine learning models for real-life
decision-making, being able to understand and trust the predictions becomes
ever more important. Local explainer models have recently been introduced to
explain the predictions of complex machine learning models at the instance
level. In this paper, we propose Local Rule-based Model Interpretability with
k-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains
k-optimal association rules from a neighbourhood of the instance to be
explained. Compared with other rule-based approaches in the literature, we
argue that the most predictive rules are not necessarily the rules that provide
the best explanations. Consequently, the LoRMIkA framework provides a flexible
way to obtain predictive and interesting rules. It uses an efficient search
algorithm guaranteed to find the k-optimal rules with respect to objectives
such as confidence, lift, leverage, coverage, and support. It also provides
multiple rules which explain the decision and counterfactual rules, which give
indications for potential changes to obtain different outputs for given
instances. We compare our approach to other state-of-the-art approaches in
local model interpretability on three different datasets and achieve
competitive results in terms of local accuracy and interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Investigation into Deep and Shallow Rule Learning. (arXiv:2106.10254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_F/0/1/0/all/0/1">Florian Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnkranz_J/0/1/0/all/0/1">Johannes F&#xfc;rnkranz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10254">
                                    <div class="article-summary-box-inner">
                                        <span>Inductive rule learning is arguably among the most traditional paradigms in
machine learning. Although we have seen considerable progress over the years in
learning rule-based theories, all state-of-the-art learners still learn
descriptions that directly relate the input features to the target concept. In
the simplest case, concept learning, this is a disjunctive normal form (DNF)
description of the positive class. While it is clear that this is sufficient
from a logical point of view because every logical expression can be reduced to
an equivalent DNF expression, it could nevertheless be the case that more
structured representations, which form deep theories by forming intermediate
concepts, could be easier to learn, in very much the same way as deep neural
networks are able to outperform shallow networks, even though the latter are
also universal function approximators. In this paper, we empirically compare
deep and shallow rule learning with a uniform general algorithm, which relies
on greedy mini-batch based optimization. Our experiments on both artificial and
real-world benchmark data indicate that deep rule networks outperform shallow
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Riemannian Convex Potential Maps. (arXiv:2106.10272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Samuel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1">Brandon Amos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipman_Y/0/1/0/all/0/1">Yaron Lipman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10272">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling distributions on Riemannian manifolds is a crucial component in
understanding non-Euclidean data that arises, e.g., in physics and geology. The
budding approaches in this space are limited by representational and
computational tradeoffs. We propose and study a class of flows that uses convex
potentials from Riemannian optimal transport. These are universal and can model
distributions on any compact Riemannian manifold without requiring domain
knowledge of the manifold to be integrated into the architecture. We
demonstrate that these flows can model standard distributions on spheres, and
tori, on synthetic and geological data. Our source code is freely available
online at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-view Molecule Pre-training. (arXiv:2106.10234v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_J/0/1/0/all/0/1">Jinhua Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xia_Y/0/1/0/all/0/1">Yingce Xia</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10234">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by its success in natural language processing and computer vision,
pre-training has attracted substantial attention in cheminformatics and
bioinformatics, especially for molecule based tasks. A molecule can be
represented by either a graph (where atoms are connected by bonds) or a SMILES
sequence (where depth-first-search is applied to the molecular graph with
specific rules). Existing works on molecule pre-training use either graph
representations only or SMILES representations only. In this work, we propose
to leverage both the representations and design a new pre-training algorithm,
dual-view molecule pre-training (briefly, DMP), that can effectively combine
the strengths of both types of molecule representations. The model of DMP
consists of two branches: a Transformer branch that takes the SMILES sequence
of a molecule as input, and a GNN branch that takes a molecular graph as input.
The training of DMP contains three tasks: (1) predicting masked tokens in a
SMILES sequence by the Transformer branch, (2) predicting masked atoms in a
molecular graph by the GNN branch, and (3) maximizing the consistency between
the two high-level representations output by the Transformer and GNN branches
separately. After pre-training, we can use either the Transformer branch (this
one is recommended according to empirical results), the GNN branch, or both for
downstream tasks. DMP is tested on nine molecular property prediction tasks and
achieves state-of-the-art performances on seven of them. Furthermore, we test
DMP on three retrosynthesis tasks and achieve state-of-the-result on the
USPTO-full dataset. Our code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deterministic Gibbs Sampling via Ordinary Differential Equations. (arXiv:2106.10188v1 [stat.CO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Neklyudov_K/0/1/0/all/0/1">Kirill Neklyudov</a>, <a href="http://arxiv.org/find/stat/1/au:+Bondesan_R/0/1/0/all/0/1">Roberto Bondesan</a>, <a href="http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10188">
                                    <div class="article-summary-box-inner">
                                        <span>Deterministic dynamics is an essential part of many MCMC algorithms, e.g.
Hybrid Monte Carlo or samplers utilizing normalizing flows. This paper presents
a general construction of deterministic measure-preserving dynamics using
autonomous ODEs and tools from differential geometry. We show how Hybrid Monte
Carlo and other deterministic samplers follow as special cases of our theory.
We then demonstrate the utility of our approach by constructing a continuous
non-sequential version of Gibbs sampling in terms of an ODE flow and extending
it to discrete state spaces. We find that our deterministic samplers are more
sample efficient than stochastic counterparts, even if the latter generate
independent samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Deep Learning in Open Collaborations. (arXiv:2106.10207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diskin_M/0/1/0/all/0/1">Michael Diskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukhtiyarov_A/0/1/0/all/0/1">Alexey Bukhtiyarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryabinin_M/0/1/0/all/0/1">Max Ryabinin</a>, <a href="http://arxiv.org/find/cs/1/au:+Saulnier_L/0/1/0/all/0/1">Lucile Saulnier</a>, <a href="http://arxiv.org/find/cs/1/au:+Lhoest_Q/0/1/0/all/0/1">Quentin Lhoest</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinitsin_A/0/1/0/all/0/1">Anton Sinitsin</a>, <a href="http://arxiv.org/find/cs/1/au:+Popov_D/0/1/0/all/0/1">Dmitry Popov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyrkin_D/0/1/0/all/0/1">Dmitry Pyrkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashirin_M/0/1/0/all/0/1">Maxim Kashirin</a>, <a href="http://arxiv.org/find/cs/1/au:+Borzunov_A/0/1/0/all/0/1">Alexander Borzunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moral_A/0/1/0/all/0/1">Albert Villanova del Moral</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazur_D/0/1/0/all/0/1">Denis Mazur</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobelev_I/0/1/0/all/0/1">Ilia Kobelev</a>, <a href="http://arxiv.org/find/cs/1/au:+Jernite_Y/0/1/0/all/0/1">Yacine Jernite</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1">Thomas Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1">Gennady Pekhimenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10207">
                                    <div class="article-summary-box-inner">
                                        <span>Modern deep learning applications require increasingly more compute to train
state-of-the-art models. To address this demand, large corporations and
institutions use dedicated High-Performance Computing clusters, whose
construction and maintenance are both environmentally costly and well beyond
the budget of most organizations. As a result, some research directions become
the exclusive domain of a few large industrial and even fewer academic actors.
To alleviate this disparity, smaller groups may pool their computational
resources and run collaborative experiments that benefit all participants. This
paradigm, known as grid- or volunteer computing, has seen successful
applications in numerous scientific areas. However, using this approach for
machine learning is difficult due to high latency, asymmetric bandwidth, and
several challenges unique to volunteer computing. In this work, we carefully
analyze these constraints and propose a novel algorithmic framework designed
specifically for collaborative training. We demonstrate the effectiveness of
our approach for SwAV and ALBERT pretraining in realistic conditions and
achieve performance comparable to traditional setups at a fraction of the cost.
Finally, we provide a detailed report of successful collaborative language
model pretraining with 40 participants.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees. (arXiv:2002.05551v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rothfuss_J/0/1/0/all/0/1">Jonas Rothfuss</a>, <a href="http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1">Vincent Fortuin</a>, <a href="http://arxiv.org/find/stat/1/au:+Josifoski_M/0/1/0/all/0/1">Martin Josifoski</a>, <a href="http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05551">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning can successfully acquire useful inductive biases from data.
Yet, its generalization properties to unseen learning tasks are poorly
understood. Particularly if the number of meta-training tasks is small, this
raises concerns about overfitting. We provide a theoretical analysis using the
PAC-Bayesian framework and derive novel generalization bounds for
meta-learning. Using these bounds, we develop a class of PAC-optimal
meta-learning algorithms with performance guarantees and a principled
meta-level regularization. Unlike previous PAC-Bayesian meta-learners, our
method results in a standard stochastic optimization problem which can be
solved efficiently and scales well. When instantiating our PAC-optimal
hyper-posterior (PACOH) with Gaussian processes and Bayesian Neural Networks as
base learners, the resulting methods yield state-of-the-art performance, both
in terms of predictive accuracy and the quality of uncertainty estimates.
Thanks to their principled treatment of uncertainty, our meta-learners can also
be successfully employed for sequential decision problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A learned conditional prior for the VAE acoustic space of a TTS system. (arXiv:2106.10229v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Karanasou_P/0/1/0/all/0/1">Penny Karanasou</a>, <a href="http://arxiv.org/find/eess/1/au:+Karlapati_S/0/1/0/all/0/1">Sri Karlapati</a>, <a href="http://arxiv.org/find/eess/1/au:+Moinet_A/0/1/0/all/0/1">Alexis Moinet</a>, <a href="http://arxiv.org/find/eess/1/au:+Joly_A/0/1/0/all/0/1">Arnaud Joly</a>, <a href="http://arxiv.org/find/eess/1/au:+Abbas_A/0/1/0/all/0/1">Ammar Abbas</a>, <a href="http://arxiv.org/find/eess/1/au:+Slangen_S/0/1/0/all/0/1">Simon Slangen</a>, <a href="http://arxiv.org/find/eess/1/au:+Trueba_J/0/1/0/all/0/1">Jaime Lorenzo Trueba</a>, <a href="http://arxiv.org/find/eess/1/au:+Drugman_T/0/1/0/all/0/1">Thomas Drugman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10229">
                                    <div class="article-summary-box-inner">
                                        <span>Many factors influence speech yielding different renditions of a given
sentence. Generative models, such as variational autoencoders (VAEs), capture
this variability and allow multiple renditions of the same sentence via
sampling. The degree of prosodic variability depends heavily on the prior that
is used when sampling. In this paper, we propose a novel method to compute an
informative prior for the VAE latent space of a neural text-to-speech (TTS)
system. By doing so, we aim to sample with more prosodic variability, while
gaining controllability over the latent space&#x27;s structure.

By using as prior the posterior distribution of a secondary VAE, which we
condition on a speaker vector, we can sample from the primary VAE taking
explicitly the conditioning into account and resulting in samples from a
specific region of the latent space for each condition (i.e. speaker). A formal
preference test demonstrates significant preference of the proposed approach
over standard Conditional VAE. We also provide visualisations of the latent
space where well-separated condition-specific clusters appear, as well as
ablation studies to better understand the behaviour of the system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Training Helps Transfer Learning via Better Representations. (arXiv:2106.10189v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1">Kailas Vodrahalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1">Kenji Kawaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10189">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning aims to leverage models pre-trained on source data to
efficiently adapt to target setting, where only limited data are available for
model fine-tuning. Recent works empirically demonstrate that adversarial
training in the source data can improve the ability of models to transfer to
new domains. However, why this happens is not known. In this paper, we provide
a theoretical model to rigorously analyze how adversarial training helps
transfer learning. We show that adversarial training in the source data
generates provably better representations, so fine-tuning on top of this
representation leads to a more accurate predictor of the target data. We
further demonstrate both theoretically and empirically that semi-supervised
learning in the source data can also improve transfer learning by similarly
improving the representation. Moreover, performing adversarial training on top
of semi-supervised learning can further improve transferability, suggesting
that the two approaches have complementary benefits on representations. We
support our theories with experiments on popular data sets and deep learning
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Black-Box Importance Sampling for VaR and CVaR Estimation. (arXiv:2106.10236v1 [q-fin.RM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Deo_A/0/1/0/all/0/1">Anand Deo</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Murthy_K/0/1/0/all/0/1">Karthyek Murthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10236">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers Importance Sampling (IS) for the estimation of tail
risks of a loss defined in terms of a sophisticated object such as a machine
learning feature map or a mixed integer linear optimisation formulation.
Assuming only black-box access to the loss and the distribution of the
underlying random vector, the paper presents an efficient IS algorithm for
estimating the Value at Risk and Conditional Value at Risk. The key challenge
in any IS procedure, namely, identifying an appropriate change-of-measure, is
automated with a self-structuring IS transformation that learns and replicates
the concentration properties of the conditional excess from less rare samples.
The resulting estimators enjoy asymptotically optimal variance reduction when
viewed in the logarithmic scale. Simulation experiments highlight the efficacy
and practicality of the proposed scheme</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models. (arXiv:2106.10199v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaken_E/0/1/0/all/0/1">Elad Ben Zaken</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1">Shauli Ravfogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10199">
                                    <div class="article-summary-box-inner">
                                        <span>We show that with small-to-medium training data, fine-tuning only the bias
terms (or a subset of the bias terms) of pre-trained BERT models is competitive
with (and sometimes better than) fine-tuning the entire model. For larger data,
bias-only fine-tuning is competitive with other sparse fine-tuning methods.
Besides their practical utility, these findings are relevant for the question
of understanding the commonly-used process of finetuning: they support the
hypothesis that finetuning is mainly about exposing knowledge induced by
language-modeling training, rather than learning new task-specific linguistic
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MADE: Exploration via Maximizing Deviation from Explored Regions. (arXiv:2106.10268v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashidinejad_P/0/1/0/all/0/1">Paria Rashidinejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jiantao Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10268">
                                    <div class="article-summary-box-inner">
                                        <span>In online reinforcement learning (RL), efficient exploration remains
particularly challenging in high-dimensional environments with sparse rewards.
In low-dimensional environments, where tabular parameterization is possible,
count-based upper confidence bound (UCB) exploration methods achieve minimax
near-optimal rates. However, it remains unclear how to efficiently implement
UCB in realistic RL tasks that involve non-linear function approximation. To
address this, we propose a new exploration approach via \textit{maximizing} the
deviation of the occupancy of the next policy from the explored regions. We add
this term as an adaptive regularizer to the standard RL objective to balance
exploration vs. exploitation. We pair the new objective with a provably
convergent algorithm, giving rise to a new intrinsic reward that adjusts
existing bonuses. The proposed intrinsic reward is easy to implement and
combine with other existing RL algorithms to conduct exploration. As a proof of
concept, we evaluate the new intrinsic reward on tabular examples across a
variety of model-based and model-free algorithms, showing improvements over
count-only exploration strategies. When tested on navigation and locomotion
tasks from MiniGrid and DeepMind Control Suite benchmarks, our approach
significantly improves sample efficiency over state-of-the-art methods. Our
code is available at https://github.com/tianjunz/MADE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition. (arXiv:2106.10169v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruirui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_C/0/1/0/all/0/1">Chelsea J.-T. Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeya Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Hongda Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Elibol_O/0/1/0/all/0/1">Oguz Elibol</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10169">
                                    <div class="article-summary-box-inner">
                                        <span>By implicitly recognizing a user based on his/her speech input, speaker
identification enables many downstream applications, such as personalized
system behavior and expedited shopping checkouts. Based on whether the speech
content is constrained or not, both text-dependent (TD) and text-independent
(TI) speaker recognition models may be used. We wish to combine the advantages
of both types of models through an ensemble system to make more reliable
predictions. However, any such combined approach has to be robust to incomplete
inputs, i.e., when either TD or TI input is missing. As a solution we propose a
fusion of embeddings network foenet architecture, combining joint learning with
neural attention. We compare foenet with four competitive baseline methods on a
dataset of voice assistant inputs, and show that it achieves higher accuracy
than the baseline and score fusion methods, especially in the presence of
incomplete inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Incremental Deep Graph Learning for Ethereum Phishing Scam Detection. (arXiv:2106.10176v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shucheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fengyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runchuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1">Sheng Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10176">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, phishing scams have become the crime type with the largest
money involved on Ethereum, the second-largest blockchain platform. Meanwhile,
graph neural network (GNN) has shown promising performance in various node
classification tasks. However, for Ethereum transaction data, which could be
naturally abstracted to a real-world complex graph, the scarcity of labels and
the huge volume of transaction data make it difficult to take advantage of GNN
methods. Here in this paper, to address the two challenges, we propose a
Self-supervised Incremental deep Graph learning model (SIEGE), for the phishing
scam detection problem on Ethereum. In our model, two pretext tasks designed
from spatial and temporal perspectives help us effectively learn useful node
embedding from the huge amount of unlabelled transaction data. And the
incremental paradigm allows us to efficiently handle large-scale transaction
data and help the model maintain good performance when the data distribution is
drastically changing. We collect transaction records about half a year from
Ethereum and our extensive experiments show that our model consistently
outperforms strong baselines in both transductive and inductive settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Less is More: Feature Selection for Adversarial Robustness with Compressive Counter-Adversarial Attacks. (arXiv:2106.10252v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_E/0/1/0/all/0/1">Emre Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Hameed_M/0/1/0/all/0/1">Muhammad Zaid Hameed</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozfatura_K/0/1/0/all/0/1">Kerem Ozfatura</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz Gunduz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10252">
                                    <div class="article-summary-box-inner">
                                        <span>A common observation regarding adversarial attacks is that they mostly give
rise to false activation at the penultimate layer to fool the classifier.
Assuming that these activation values correspond to certain features of the
input, the objective becomes choosing the features that are most useful for
classification. Hence, we propose a novel approach to identify the important
features by employing counter-adversarial attacks, which highlights the
consistency at the penultimate layer with respect to perturbations on input
samples. First, we empirically show that there exist a subset of features,
classification based in which bridge the gap between the clean and robust
accuracy. Second, we propose a simple yet efficient mechanism to identify those
features by searching the neighborhood of input sample. We then select features
by observing the consistency of the activation values at the penultimate layer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Model Sparsification by Scheduled Grow-and-Prune Methods. (arXiv:2106.09857v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zejiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1">Kun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Kuang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuan Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09857">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are effective in solving many real-world
problems. Larger DNN models usually exhibit better quality (e.g., accuracy) but
their excessive computation results in long training and inference time. Model
sparsification can reduce the computation and memory cost while maintaining
model quality. Most existing sparsification algorithms unidirectionally remove
weights, while others randomly or greedily explore a small subset of weights in
each layer. The inefficiency of the algorithms reduces the achievable sparsity
level. In addition, many algorithms still require pre-trained dense models and
thus suffer from large memory footprint and long training time. In this paper,
we propose a novel scheduled grow-and-prune (GaP) methodology without
pre-training the dense models. It addresses the shortcomings of the previous
works by repeatedly growing a subset of layers to dense and then pruning back
to sparse after some training. Experiments have shown that such models can
match or beat the quality of highly optimized dense models at 80% sparsity on a
variety of tasks, such as image classification, objective detection, 3D object
part segmentation, and translation. They also outperform other state-of-the-art
(SOTA) pruning methods, including pruning from pre-trained dense models. As an
example, a 90% sparse ResNet-50 obtained via GaP achieves 77.9% top-1 accuracy
on ImageNet, improving the SOTA results by 1.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning. (arXiv:2106.10196v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Junyuan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haotao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiayu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10196">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) emerges as a popular distributed learning schema that
learns a model from a set of participating users without requiring raw data to
be shared. One major challenge of FL comes from heterogeneity in users, which
may have distributionally different (or non-iid) data and varying computation
resources. Just like in centralized learning, FL users also desire model
robustness against malicious attackers at test time. Whereas adversarial
training (AT) provides a sound solution for centralized learning, extending its
usage for FL users has imposed significant challenges, as many users may have
very limited training data as well as tight computational budgets, to afford
the data-hungry and costly AT. In this paper, we study a novel learning setting
that propagates adversarial robustness from high-resource users that can afford
AT, to those low-resource users that cannot afford it, during the FL process.
We show that existing FL techniques cannot effectively propagate adversarial
robustness among non-iid users, and propose a simple yet effective propagation
approach that transfers robustness through carefully designed
batch-normalization statistics. We demonstrate the rationality and
effectiveness of our method through extensive experiments. Especially, the
proposed method is shown to grant FL remarkable robustness even when only a
small portion of users afford AT during learning. Codes will be published upon
acceptance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation into Mini-Batch Rule Learning. (arXiv:2106.10202v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_F/0/1/0/all/0/1">Florian Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnkranz_J/0/1/0/all/0/1">Johannes F&#xfc;rnkranz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10202">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate whether it is possible to learn rule sets efficiently in a
network structure with a single hidden layer using iterative refinements over
mini-batches of examples. A first rudimentary version shows an acceptable
performance on all but one dataset, even though it does not yet reach the
performance levels of Ripper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">pyWATTS: Python Workflow Automation Tool for Time Series. (arXiv:2106.10157v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidrich_B/0/1/0/all/0/1">Benedikt Heidrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartschat_A/0/1/0/all/0/1">Andreas Bartschat</a>, <a href="http://arxiv.org/find/cs/1/au:+Turowski_M/0/1/0/all/0/1">Marian Turowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_O/0/1/0/all/0/1">Oliver Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Phipps_K/0/1/0/all/0/1">Kaleb Phipps</a>, <a href="http://arxiv.org/find/cs/1/au:+Meisenbacher_S/0/1/0/all/0/1">Stefan Meisenbacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmieder_K/0/1/0/all/0/1">Kai Schmieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Ludwig_N/0/1/0/all/0/1">Nicole Ludwig</a>, <a href="http://arxiv.org/find/cs/1/au:+Mikut_R/0/1/0/all/0/1">Ralf Mikut</a>, <a href="http://arxiv.org/find/cs/1/au:+Hagenmeyer_V/0/1/0/all/0/1">Veit Hagenmeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10157">
                                    <div class="article-summary-box-inner">
                                        <span>Time series data are fundamental for a variety of applications, ranging from
financial markets to energy systems. Due to their importance, the number and
complexity of tools and methods used for time series analysis is constantly
increasing. However, due to unclear APIs and a lack of documentation,
researchers struggle to integrate them into their research projects and
replicate results. Additionally, in time series analysis there exist many
repetitive tasks, which are often re-implemented for each project,
unnecessarily costing time. To solve these problems we present
\texttt{pyWATTS}, an open-source Python-based package that is a non-sequential
workflow automation tool for the analysis of time series data. pyWATTS includes
modules with clearly defined interfaces to enable seamless integration of new
or existing methods, subpipelining to easily reproduce repetitive tasks, load
and save functionality to simply replicate results, and native support for key
Python machine learning libraries such as scikit-learn, PyTorch, and Keras.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Robustness of Trigger Set-Based Watermarks Embedded in Deep Neural Networks. (arXiv:2106.10147v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Suyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wonho Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1">Suman Jana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1">Meeyoung Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_S/0/1/0/all/0/1">Sooel Son</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10147">
                                    <div class="article-summary-box-inner">
                                        <span>Trigger set-based watermarking schemes have gained emerging attention as they
provide a means to prove ownership for deep neural network model owners. In
this paper, we argue that state-of-the-art trigger set-based watermarking
algorithms do not achieve their designed goal of proving ownership. We posit
that this impaired capability stems from two common experimental flaws that the
existing research practice has committed when evaluating the robustness of
watermarking algorithms: (1) incomplete adversarial evaluation and (2)
overlooked adaptive attacks.

We conduct a comprehensive adversarial evaluation of 10 representative
watermarking schemes against six of the existing attacks and demonstrate that
each of these watermarking schemes lacks robustness against at least two
attacks. We also propose novel adaptive attacks that harness the adversary&#x27;s
knowledge of the underlying watermarking algorithm of a target model. We
demonstrate that the proposed attacks effectively break all of the 10
watermarking schemes, consequently allowing adversaries to obscure the
ownership of any watermarked model. We encourage follow-up studies to consider
our guidelines when evaluating the robustness of their watermarking schemes via
conducting comprehensive adversarial evaluation that include our adaptive
attacks to demonstrate a meaningful upper bound of watermark robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Offline Policy Selection. (arXiv:2106.10251v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Konyushkova_K/0/1/0/all/0/1">Ksenia Konyushkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yutian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1">Thomas Paine</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1">Caglar Gulcehre</a>, <a href="http://arxiv.org/find/cs/1/au:+Paduraru_C/0/1/0/all/0/1">Cosmin Paduraru</a>, <a href="http://arxiv.org/find/cs/1/au:+Mankowitz_D/0/1/0/all/0/1">Daniel J Mankowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Denil_M/0/1/0/all/0/1">Misha Denil</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1">Nando de Freitas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10251">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of policy selection in domains with abundant
logged data, but with a very restricted interaction budget. Solving this
problem would enable safe evaluation and deployment of offline reinforcement
learning policies in industry, robotics, and healthcare domain among others.
Several off-policy evaluation (OPE) techniques have been proposed to assess the
value of policies using only logged data. However, there is still a big gap
between the evaluation by OPE and the full online evaluation in the real
environment. To reduce this gap, we introduce a novel \emph{active offline
policy selection} problem formulation, which combined logged data and limited
online interactions to identify the best policy. We rely on the advances in OPE
to warm start the evaluation. We build upon Bayesian optimization to
iteratively decide which policies to evaluate in order to utilize the limited
environment interactions wisely. Many candidate policies could be proposed,
thus, we focus on making our approach scalable and introduce a kernel function
to model similarity between policies. We use several benchmark environments to
show that the proposed approach improves upon state-of-the-art OPE estimates
and fully online policy evaluation with limited budget. Additionally, we show
that each component of the proposed method is important, it works well with
various number and quality of OPE estimates and even with a large number of
candidate policies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid graph convolutional neural networks for landmark-based anatomical segmentation. (arXiv:2106.09832v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaggion_N/0/1/0/all/0/1">Nicol&#xe1;s Gaggion</a>, <a href="http://arxiv.org/find/eess/1/au:+Mansilla_L/0/1/0/all/0/1">Lucas Mansilla</a>, <a href="http://arxiv.org/find/eess/1/au:+Milone_D/0/1/0/all/0/1">Diego Milone</a>, <a href="http://arxiv.org/find/eess/1/au:+Ferrante_E/0/1/0/all/0/1">Enzo Ferrante</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09832">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we address the problem of landmark-based segmentation for
anatomical structures. We propose HybridGNet, an encoder-decoder neural
architecture which combines standard convolutions for image feature encoding,
with graph convolutional neural networks to decode plausible representations of
anatomical structures. We benchmark the proposed architecture considering other
standard landmark and pixel-based models for anatomical segmentation in chest
x-ray images, and found that HybridGNet is more robust to image occlusions. We
also show that it can be used to construct landmark-based segmentations from
pixel level annotations. Our experimental results suggest that HybridGNet
produces accurate and anatomically plausible landmark-based segmentations, by
naturally incorporating shape constraints within the decoding process via
spectral convolutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Being a Bit Frequentist Improves Bayesian Neural Networks. (arXiv:2106.10065v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1">Agustinus Kristiadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1">Matthias Hein</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10065">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their compelling theoretical properties, Bayesian neural networks
(BNNs) tend to perform worse than frequentist methods in classification-based
uncertainty quantification (UQ) tasks such as out-of-distribution (OOD)
detection and dataset-shift robustness. In this work, based on empirical
findings in prior works, we hypothesize that this issue is due to the avoidance
of Bayesian methods in the so-called &quot;OOD training&quot; -- a family of techniques
for incorporating OOD data during training process, which has since been an
integral part of state-of-the-art frequentist UQ methods. To validate this, we
treat OOD data as a first-class citizen in BNN training by exploring four
different ways of incorporating OOD data in Bayesian inference. We show in
extensive experiments that OOD-trained BNNs are competitive to, if not better
than recent frequentist baselines. This work thus provides strong baselines for
future work in both Bayesian and frequentist UQ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Problem Dependent View on Structured Thresholding Bandit Problems. (arXiv:2106.10166v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cheshire_J/0/1/0/all/0/1">James Cheshire</a>, <a href="http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1">Pierre M&#xe9;nard</a>, <a href="http://arxiv.org/find/stat/1/au:+Carpentier_A/0/1/0/all/0/1">Alexandra Carpentier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10166">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem dependent regime in the stochastic Thresholding
Bandit problem (TBP) under several shape constraints. In the TBP, the objective
of the learner is to output, at the end of a sequential game, the set of arms
whose means are above a given threshold. The vanilla, unstructured, case is
already well studied in the literature. Taking $K$ as the number of arms, we
consider the case where (i) the sequence of arm&#x27;s means $(\mu_k)_{k&#x3D;1}^K$ is
monotonically increasing (MTBP) and (ii) the case where $(\mu_k)_{k&#x3D;1}^K$ is
concave (CTBP). We consider both cases in the problem dependent regime and
study the probability of error - i.e. the probability to mis-classify at least
one arm. In the fixed budget setting, we provide upper and lower bounds for the
probability of error in both the concave and monotone settings, as well as
associated algorithms. In both settings the bounds match in the problem
dependent regime up to universal constants in the exponential.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rational Shapley Values. (arXiv:2106.10191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1">David S. Watson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10191">
                                    <div class="article-summary-box-inner">
                                        <span>Explaining the predictions of opaque machine learning algorithms is an
important and challenging task, especially as complex models are increasingly
used to assist in high-stakes decisions such as those arising in healthcare and
finance. Most popular tools for post-hoc explainable artificial intelligence
(XAI) are either insensitive to context (e.g., feature attributions) or
difficult to summarize (e.g., counterfactuals). In this paper, I introduce
\emph{rational Shapley values}, a novel XAI method that synthesizes and extends
these seemingly incompatible approaches in a rigorous, flexible manner. I
leverage tools from decision theory and causal modeling to formalize and
implement a pragmatic approach that resolves a number of known challenges in
XAI. By pairing the distribution of random variables with the appropriate
reference class for a given explanation task, I illustrate through theory and
experiments how user goals and knowledge can inform and constrain the solution
set in an iterative fashion. The method compares favorably to state of the art
XAI tools in a range of quantitative and qualitative comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Principles of Deep Learning Theory. (arXiv:2106.10165v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1">Daniel A. Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaida_S/0/1/0/all/0/1">Sho Yaida</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1">Boris Hanin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10165">
                                    <div class="article-summary-box-inner">
                                        <span>This book develops an effective theory approach to understanding deep neural
networks of practical relevance. Beginning from a first-principles
component-level picture of networks, we explain how to determine an accurate
description of the output of trained networks by solving layer-to-layer
iteration equations and nonlinear learning dynamics. A main result is that the
predictions of networks are described by nearly-Gaussian distributions, with
the depth-to-width aspect ratio of the network controlling the deviations from
the infinite-width Gaussian description. We explain how these effectively-deep
networks learn nontrivial representations from training and more broadly
analyze the mechanism of representation learning for nonlinear models. From a
nearly-kernel-methods perspective, we find that the dependence of such models&#x27;
predictions on the underlying learning algorithm can be expressed in a simple
and universal way. To obtain these results, we develop the notion of
representation group flow (RG flow) to characterize the propagation of signals
through the network. By tuning networks to criticality, we give a practical
solution to the exploding and vanishing gradient problem. We further explain
how RG flow leads to near-universal behavior and lets us categorize networks
built from different activation functions into universality classes.
Altogether, we show that the depth-to-width ratio governs the effective model
complexity of the ensemble of trained networks. By using information-theoretic
techniques, we estimate the optimal aspect ratio at which we expect the network
to be practically most useful and show how residual connections can be used to
push this scale to arbitrary depths. With these tools, we can learn in detail
about the inductive bias of architectures, hyperparameters, and optimizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Sample Complexity of Batch Reinforcement Learning with Policy-Induced Data. (arXiv:2106.09973v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chenjun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Ilbin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1">Dale Schuurmans</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesvari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09973">
                                    <div class="article-summary-box-inner">
                                        <span>We study the fundamental question of the sample complexity of learning a good
policy in finite Markov decision processes (MDPs) when the data available for
learning is obtained by following a logging policy that must be chosen without
knowledge of the underlying MDP. Our main results show that the sample
complexity, the minimum number of transitions necessary and sufficient to
obtain a good policy, is an exponential function of the relevant quantities
when the planning horizon $H$ is finite. In particular, we prove that the
sample complexity of obtaining $\epsilon$-optimal policies is at least
$\Omega(\mathrm{A}^{\min(\mathrm{S}-1, H+1)})$ for $\gamma$-discounted
problems, where $\mathrm{S}$ is the number of states, $\mathrm{A}$ is the
number of actions, and $H$ is the effective horizon defined as $H&#x3D;\lfloor
\tfrac{\ln(1/\epsilon)}{\ln(1/\gamma)} \rfloor$; and it is at least
$\Omega(\mathrm{A}^{\min(\mathrm{S}-1, H)}/\varepsilon^2)$ for finite horizon
problems, where $H$ is the planning horizon of the problem. This lower bound is
essentially matched by an upper bound. For the average-reward setting we show
that there is no algorithm finding $\epsilon$-optimal policies with a finite
amount of data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Labelling Drifts in a Fault Detection System for Wind Turbine Maintenance. (arXiv:2106.09951v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martinez_I/0/1/0/all/0/1">I&#xf1;igo Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Viles_E/0/1/0/all/0/1">Elisabeth Viles</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabrejas_I/0/1/0/all/0/1">I&#xf1;aki Cabrejas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09951">
                                    <div class="article-summary-box-inner">
                                        <span>A failure detection system is the first step towards predictive maintenance
strategies. A popular data-driven method to detect incipient failures and
anomalies is the training of normal behaviour models by applying a machine
learning technique like feed-forward neural networks (FFNN) or extreme learning
machines (ELM). However, the performance of any of these modelling techniques
can be deteriorated by the unexpected rise of non-stationarities in the dynamic
environment in which industrial assets operate. This unpredictable statistical
change in the measured variable is known as concept drift. In this article a
wind turbine maintenance case is presented, where non-stationarities of various
kinds can happen unexpectedly. Such concept drift events are desired to be
detected by means of statistical detectors and window-based approaches.
However, in real complex systems, concept drifts are not as clear and evident
as in artificially generated datasets. In order to evaluate the effectiveness
of current drift detectors and also to design an appropriate novel technique
for this specific industrial application, it is essential to dispose beforehand
of a characterization of the existent drifts. Under the lack of information in
this regard, a methodology for labelling concept drift events in the lifetime
of wind turbines is proposed. This methodology will facilitate the creation of
a drift database that will serve both as a training ground for concept drift
detectors and as a valuable information to enhance the knowledge about
maintenance of complex systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Context Encoder: Graph Feature Inpainting for Graph Generation and Self-supervised Pretraining. (arXiv:2106.10124v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frigo_O/0/1/0/all/0/1">Oriel Frigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Brossard_R/0/1/0/all/0/1">R&#xe9;my Brossard</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehaene_D/0/1/0/all/0/1">David Dehaene</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10124">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the Graph Context Encoder (GCE), a simple but efficient approach
for graph representation learning based on graph feature masking and
reconstruction.

GCE models are trained to efficiently reconstruct input graphs similarly to a
graph autoencoder where node and edge labels are masked. In particular, our
model is also allowed to change graph structures by masking and reconstructing
graphs augmented by random pseudo-edges.

We show that GCE can be used for novel graph generation, with applications
for molecule generation. Used as a pretraining method, we also show that GCE
improves baseline performances in supervised classification tasks tested on
multiple standard benchmark graph datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Plan via a Multi-Step Policy Regression Method. (arXiv:2106.10075v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wagner_S/0/1/0/all/0/1">Stefan Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Janschek_M/0/1/0/all/0/1">Michael Janschek</a>, <a href="http://arxiv.org/find/cs/1/au:+Uelwer_T/0/1/0/all/0/1">Tobias Uelwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Harmeling_S/0/1/0/all/0/1">Stefan Harmeling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10075">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new approach to increase inference performance in environments
that require a specific sequence of actions in order to be solved. This is for
example the case for maze environments where ideally an optimal path is
determined. Instead of learning a policy for a single step, we want to learn a
policy that can predict n actions in advance. Our proposed method called policy
horizon regression (PHR) uses knowledge of the environment sampled by A2C to
learn an n dimensional policy vector in a policy distillation setup which
yields n sequential actions per observation. We test our method on the MiniGrid
and Pong environments and show drastic speedup during inference time by
successfully predicting sequences of actions on a single observation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples. (arXiv:2106.09947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1">Maura Pintor</a>, <a href="http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1">Luca Demetrio</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotgiu_A/0/1/0/all/0/1">Angelo Sotgiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Manca_G/0/1/0/all/0/1">Giovanni Manca</a>, <a href="http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1">Ambra Demontis</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>, <a href="http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1">Fabio Roli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09947">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating robustness of machine-learning models to adversarial examples is a
challenging problem. Many defenses have been shown to provide a false sense of
security by causing gradient-based attacks to fail, and they have been broken
under more rigorous evaluations. Although guidelines and best practices have
been suggested to improve current adversarial robustness evaluations, the lack
of automatic testing and debugging tools makes it difficult to apply these
recommendations in a systematic manner. In this work, we overcome these
limitations by (i) defining a set of quantitative indicators which unveil
common failures in the optimization of gradient-based attacks, and (ii)
proposing specific mitigation strategies within a systematic evaluation
protocol. Our extensive experimental analysis shows that the proposed
indicators of failure can be used to visualize, debug and improve current
adversarial robustness evaluations, providing a first concrete step towards
automatizing and systematizing current adversarial robustness evaluations. Our
open-source code is available at:
https://github.com/pralab/IndicatorsOfAttackFailure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Dimpled Manifold Model of Adversarial Examples in Machine Learning. (arXiv:2106.10151v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shamir_A/0/1/0/all/0/1">Adi Shamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Melamed_O/0/1/0/all/0/1">Odelia Melamed</a>, <a href="http://arxiv.org/find/cs/1/au:+BenShmuel_O/0/1/0/all/0/1">Oriel BenShmuel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10151">
                                    <div class="article-summary-box-inner">
                                        <span>The extreme fragility of deep neural networks when presented with tiny
perturbations in their inputs was independently discovered by several research
groups in 2013, but in spite of enormous effort these adversarial examples
remained a baffling phenomenon with no clear explanation. In this paper we
introduce a new conceptual framework (which we call the Dimpled Manifold Model)
which provides a simple explanation for why adversarial examples exist, why
their perturbations have such tiny norms, why these perturbations look like
random noise, and why a network which was adversarially trained with
incorrectly labeled images can still correctly classify test images. In the
last part of the paper we describe the results of numerous experiments which
strongly support this new model, and in particular our assertion that
adversarial perturbations are roughly perpendicular to the low dimensional
manifold which contains all the training examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Vertical Federated Learning Framework for Horizontally Partitioned Labels. (arXiv:2106.10056v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wensheng Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Ying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xiaoyong Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10056">
                                    <div class="article-summary-box-inner">
                                        <span>Vertical federated learning is a collaborative machine learning framework to
train deep leaning models on vertically partitioned data with
privacy-preservation. It attracts much attention both from academia and
industry. Unfortunately, applying most existing vertical federated learning
methods in real-world applications still faces two daunting challenges. First,
most existing vertical federated learning methods have a strong assumption that
at least one party holds the complete set of labels of all data samples, while
this assumption is not satisfied in many practical scenarios, where labels are
horizontally partitioned and the parties only hold partial labels. Existing
vertical federated learning methods can only utilize partial labels, which may
lead to inadequate model update in end-to-end backpropagation. Second,
computational and communication resources vary in parties. Some parties with
limited computational and communication resources will become the stragglers
and slow down the convergence of training. Such straggler problem will be
exaggerated in the scenarios of horizontally partitioned labels in vertical
federated learning. To address these challenges, we propose a novel vertical
federated learning framework named Cascade Vertical Federated Learning (CVFL)
to fully utilize all horizontally partitioned labels to train neural networks
with privacy-preservation. To mitigate the straggler problem, we design a novel
optimization objective which can increase straggler&#x27;s contribution to the
trained models. We conduct a series of qualitative experiments to rigorously
verify the effectiveness of CVFL. It is demonstrated that CVFL can achieve
comparable performance (e.g., accuracy for classification tasks) with
centralized training. The new optimization objective can further mitigate the
straggler problem comparing with only using the asynchronous aggregation
mechanism during training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Differentially Private Federated Learning: Efficient Algorithms with Tight Risk Bounds. (arXiv:2106.09779v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1">Andrew Lowy</a>, <a href="http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1">Meisam Razaviyayn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09779">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is a distributed learning paradigm in which many
clients with heterogeneous, unbalanced, and often sensitive local data,
collaborate to learn a model. Local Differential Privacy (LDP) provides a
strong guarantee that each client&#x27;s data cannot be leaked during and after
training, without relying on a trusted third party. While LDP is often believed
to be too stringent to allow for satisfactory utility, our paper challenges
this belief. We consider a general setup with unbalanced, heterogeneous data,
disparate privacy needs across clients, and unreliable communication, where a
random number/subset of clients is available each round. We propose three LDP
algorithms for smooth (strongly) convex FL; each are noisy variations of
distributed minibatch SGD. One is accelerated and one involves novel
time-varying noise, which we use to obtain the first non-trivial LDP excess
risk bound for the fully general non-i.i.d. FL problem. Specializing to i.i.d.
clients, our risk bounds interpolate between the best known and/or optimal
bounds in the centralized setting and the cross-device setting, where each
client represents just one person&#x27;s data. Furthermore, we show that in certain
regimes, our convergence rate (nearly) matches the corresponding non-private
lower bound or outperforms state of the art non-private algorithms (&#x60;&#x60;privacy
for free&#x27;&#x27;). Finally, we validate our theoretical results and illustrate the
practical utility of our algorithm with numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Steerable Partial Differential Operators for Equivariant Neural Networks. (arXiv:2106.10163v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jenner_E/0/1/0/all/0/1">Erik Jenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1">Maurice Weiler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10163">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work in equivariant deep learning bears strong similarities to
physics. Fields over a base space are fundamental entities in both subjects, as
are equivariant maps between these fields. In deep learning, however, these
maps are usually defined by convolutions with a kernel, whereas they are
partial differential operators (PDOs) in physics. Developing the theory of
equivariant PDOs in the context of deep learning could bring these subjects
even closer together and lead to a stronger flow of ideas. In this work, we
derive a $G$-steerability constraint that completely characterizes when a PDO
between feature vector fields is equivariant, for arbitrary symmetry groups
$G$. We then fully solve this constraint for several important groups. We use
our solutions as equivariant drop-in replacements for convolutional layers and
benchmark them in that role. Finally, we develop a framework for equivariant
maps based on Schwartz distributions that unifies classical convolutions and
differential operators and gives insight about the relation between the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning Models Predict Visual Responses in the Brain: A Preliminary Result. (arXiv:2106.10112v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piriyajitakonkij_M/0/1/0/all/0/1">Maytus Piriyajitakonkij</a>, <a href="http://arxiv.org/find/cs/1/au:+Itthipuripat_S/0/1/0/all/0/1">Sirawaj Itthipuripat</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1">Theerawit Wilaiprasitporn</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilokthanakul_N/0/1/0/all/0/1">Nat Dilokthanakul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10112">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised deep convolutional neural networks (DCNNs) are currently one of
the best computational models that can explain how the primate ventral visual
stream solves object recognition. However, embodied cognition has not been
considered in the existing visual processing models. From the ecological
standpoint, humans learn to recognize objects by interacting with them,
allowing better classification, specialization, and generalization. Here, we
ask if computational models under the embodied learning framework can explain
mechanisms underlying object recognition in the primate visual system better
than the existing supervised models? To address this question, we use
reinforcement learning to train neural network models to play a 3D computer
game and we find that these reinforcement learning models achieve neural
response prediction accuracy scores in the early visual areas (e.g., V1 and V2)
in the levels that are comparable to those accomplished by the supervised
neural network model. In contrast, the supervised neural network models yield
better neural response predictions in the higher visual areas, compared to the
reinforcement learning models. Our preliminary results suggest the future
direction of visual neuroscience in which deep reinforcement learning should be
included to fill the missing embodiment concept.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smoothed Multi-View Subspace Clustering. (arXiv:2106.09875v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhengrui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09875">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, multi-view subspace clustering has achieved impressive
performance due to the exploitation of complementary imformation across
multiple views. However, multi-view data can be very complicated and are not
easy to cluster in real-world applications. Most existing methods operate on
raw data and may not obtain the optimal solution. In this work, we propose a
novel multi-view clustering method named smoothed multi-view subspace
clustering (SMVSC) by employing a novel technique, i.e., graph filtering, to
obtain a smooth representation for each view, in which similar data points have
similar feature values. Specifically, it retains the graph geometric features
through applying a low-pass filter. Consequently, it produces a
&#x60;&#x60;clustering-friendly&quot; representation and greatly facilitates the downstream
clustering task. Extensive experiments on benchmark datasets validate the
superiority of our approach. Analysis shows that graph filtering increases the
separability of classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ScoreGrad: Multivariate Probabilistic Time Series Forecasting with Continuous Energy-based Generative Models. (arXiv:2106.10121v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1">Tijin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1">Yufeng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yuanqing Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10121">
                                    <div class="article-summary-box-inner">
                                        <span>Multivariate time series prediction has attracted a lot of attention because
of its wide applications such as intelligence transportation, AIOps. Generative
models have achieved impressive results in time series modeling because they
can model data distribution and take noise into consideration. However, many
existing works can not be widely used because of the constraints of functional
form of generative models or the sensitivity to hyperparameters. In this paper,
we propose ScoreGrad, a multivariate probabilistic time series forecasting
framework based on continuous energy-based generative models. ScoreGrad is
composed of time series feature extraction module and conditional stochastic
differential equation based score matching module. The prediction can be
achieved by iteratively solving reverse-time SDE. To the best of our knowledge,
ScoreGrad is the first continuous energy based generative model used for time
series forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on
six real-world datasets. The impact of hyperparameters and sampler types on the
performance are also explored. Code is available at
https://github.com/yantijin/ScoreGradPred.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Effects of Compression with Hyperdimensional Computing in Distributed Randomized Neural Networks. (arXiv:2106.09831v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosato_A/0/1/0/all/0/1">Antonello Rosato</a>, <a href="http://arxiv.org/find/cs/1/au:+Panella_M/0/1/0/all/0/1">Massimo Panella</a>, <a href="http://arxiv.org/find/cs/1/au:+Osipov_E/0/1/0/all/0/1">Evgeny Osipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1">Denis Kleyko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09831">
                                    <div class="article-summary-box-inner">
                                        <span>A change of the prevalent supervised learning techniques is foreseeable in
the near future: from the complex, computational expensive algorithms to more
flexible and elementary training ones. The strong revitalization of randomized
algorithms can be framed in this prospect steering. We recently proposed a
model for distributed classification based on randomized neural networks and
hyperdimensional computing, which takes into account cost of information
exchange between agents using compression. The use of compression is important
as it addresses the issues related to the communication bottleneck, however,
the original approach is rigid in the way the compression is used. Therefore,
in this work, we propose a more flexible approach to compression and compare it
to conventional compression algorithms, dimensionality reduction, and
quantization techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented KRnet for density estimation and approximation. (arXiv:2105.12866v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1">Xiaoliang Wan</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_K/0/1/0/all/0/1">Kejun Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12866">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we have proposed augmented KRnets including both discrete and
continuous models. One difficulty in flow-based generative modeling is to
maintain the invertibility of the transport map, which is often a trade-off
between effectiveness and robustness. The exact invertibility has been achieved
in the real NVP using a specific pattern to exchange information between two
separated groups of dimensions. KRnet has been developed to enhance the
information exchange among data dimensions by incorporating the
Knothe-Rosenblatt rearrangement into the structure of the transport map. Due to
the maintenance of exact invertibility, a full nonlinear update of all data
dimensions needs three iterations in KRnet. To alleviate this issue, we will
add augmented dimensions that act as a channel for communications among the
data dimensions. In the augmented KRnet, a fully nonlinear update is achieved
in two iterations. We also show that the augmented KRnet can be reformulated as
the discretization of a neural ODE, where the exact invertibility is kept such
that the adjoint method can be formulated with respect to the discretized ODE
to obtain the exact gradient. Numerical experiments have been implemented to
demonstrate the effectiveness of our models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm via Langevin Monte Carlo within Gibbs. (arXiv:2106.06300v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1">Vincent Plassier</a>, <a href="http://arxiv.org/find/stat/1/au:+Vono_M/0/1/0/all/0/1">Maxime Vono</a>, <a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1">Eric Moulines</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06300">
                                    <div class="article-summary-box-inner">
                                        <span>Performing reliable Bayesian inference on a big data scale is becoming a
keystone in the modern era of machine learning. A workhorse class of methods to
achieve this task are Markov chain Monte Carlo (MCMC) algorithms and their
design to handle distributed datasets has been the subject of many works.
However, existing methods are not completely either reliable or computationally
efficient. In this paper, we propose to fill this gap in the case where the
dataset is partitioned and stored on computing nodes within a cluster under a
master/slaves architecture. We derive a user-friendly centralised distributed
MCMC algorithm with provable scaling in high-dimensional settings. We
illustrate the relevance of the proposed methodology on both synthetic and real
data experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Connections between Counterfactual Explanations and Adversarial Examples. (arXiv:2106.09992v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pawelczyk_M/0/1/0/all/0/1">Martin Pawelczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Shalmali Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1">Sohini Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09992">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactual explanations and adversarial examples have emerged as critical
research areas for addressing the explainability and robustness goals of
machine learning (ML). While counterfactual explanations were developed with
the goal of providing recourse to individuals adversely impacted by algorithmic
decisions, adversarial examples were designed to expose the vulnerabilities of
ML models. While prior research has hinted at the commonalities between these
frameworks, there has been little to no work on systematically exploring the
connections between the literature on counterfactual explanations and
adversarial examples. In this work, we make one of the first attempts at
formalizing the connections between counterfactual explanations and adversarial
examples. More specifically, we theoretically analyze salient counterfactual
explanation and adversarial example generation methods, and highlight the
conditions under which they behave similarly. Our analysis demonstrates that
several popular counterfactual explanation and adversarial example generation
methods such as the ones proposed by Wachter et. al. and Carlini and Wagner
(with mean squared error loss), and C-CHVAE and natural adversarial examples by
Zhao et. al. are equivalent. We also bound the distance between counterfactual
explanations and adversarial examples generated by Wachter et. al. and DeepFool
methods for linear models. Finally, we empirically validate our theoretical
findings using extensive experimentation with synthetic and real world
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SoK: Privacy-Preserving Collaborative Tree-based Model Learning. (arXiv:2103.08987v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatel_S/0/1/0/all/0/1">Sylvain Chatel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pyrgelis_A/0/1/0/all/0/1">Apostolos Pyrgelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Troncoso_Pastoriza_J/0/1/0/all/0/1">Juan Ramon Troncoso-Pastoriza</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubaux_J/0/1/0/all/0/1">Jean-Pierre Hubaux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08987">
                                    <div class="article-summary-box-inner">
                                        <span>Tree-based models are among the most efficient machine learning techniques
for data mining nowadays due to their accuracy, interpretability, and
simplicity. The recent orthogonal needs for more data and privacy protection
call for collaborative privacy-preserving solutions. In this work, we survey
the literature on distributed and privacy-preserving training of tree-based
models and we systematize its knowledge based on four axes: the learning
algorithm, the collaborative model, the protection mechanism, and the threat
model. We use this to identify the strengths and limitations of these works and
provide for the first time a framework analyzing the information leakage
occurring in distributed tree-based model learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fitting summary statistics of neural data with a differentiable spiking network simulator. (arXiv:2106.10064v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bellec_G/0/1/0/all/0/1">Guillaume Bellec</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Shuqi Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Modirshanechi_A/0/1/0/all/0/1">Alireza Modirshanechi</a>, <a href="http://arxiv.org/find/stat/1/au:+Brea_J/0/1/0/all/0/1">Johanni Brea</a>, <a href="http://arxiv.org/find/stat/1/au:+Gerstner_W/0/1/0/all/0/1">Wulfram Gerstner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10064">
                                    <div class="article-summary-box-inner">
                                        <span>Fitting network models to neural activity is becoming an important tool in
neuroscience. A popular approach is to model a brain area with a probabilistic
recurrent spiking network whose parameters maximize the likelihood of the
recorded activity. Although this is widely used, we show that the resulting
model does not produce realistic neural activity and wrongly estimates the
connectivity matrix when neurons that are not recorded have a substantial
impact on the recorded network. To correct for this, we suggest to augment the
log-likelihood with terms that measure the dissimilarity between simulated and
recorded activity. This dissimilarity is defined via summary statistics
commonly used in neuroscience, and the optimization is efficient because it
relies on back-propagation through the stochastically simulated spike trains.
We analyze this method theoretically and show empirically that it generates
more realistic activity statistics and recovers the connectivity matrix better
than other methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points and Convergence. (arXiv:2106.00198v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Runyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaolin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Na Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00198">
                                    <div class="article-summary-box-inner">
                                        <span>We study the performance of the gradient play algorithm for multi-agent
tabular Markov decision processes (MDPs), which are also known as stochastic
games (SGs), where each agent tries to maximize its own total discounted reward
by making decisions independently based on current state information which is
shared between agents. Policies are directly parameterized by the probability
of choosing a certain action at a given state. We show that Nash equilibria
(NEs) and first order stationary policies are equivalent in this setting, and
give a non-asymptotic global convergence rate analysis to an $\epsilon$-NE for
a subclass of multi-agent MDPs called Markov potential games, which includes
the cooperative setting with identical rewards among agents as an important
special case. Our result shows that the number of iterations to reach an
$\epsilon$-NE scales linearly, instead of exponentially, with the number of
agents. Local geometry and local stability are also considered. For Markov
potential games, we prove that strict NEs are local maxima of the total
potential function and fully-mixed NEs are saddle points. We also give a local
convergence rate around strict NEs for more general settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information criteria for non-normalized models. (arXiv:1905.05976v4 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Matsuda_T/0/1/0/all/0/1">Takeru Matsuda</a>, <a href="http://arxiv.org/find/math/1/au:+Uehara_M/0/1/0/all/0/1">Masatoshi Uehara</a>, <a href="http://arxiv.org/find/math/1/au:+Hyvarinen_A/0/1/0/all/0/1">Aapo Hyvarinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.05976">
                                    <div class="article-summary-box-inner">
                                        <span>Many statistical models are given in the form of non-normalized densities
with an intractable normalization constant. Since maximum likelihood estimation
is computationally intensive for these models, several estimation methods have
been developed which do not require explicit computation of the normalization
constant, such as noise contrastive estimation (NCE) and score matching.
However, model selection methods for general non-normalized models have not
been proposed so far. In this study, we develop information criteria for
non-normalized models estimated by NCE or score matching. They are
approximately unbiased estimators of discrepancy measures for non-normalized
models. Simulation results and applications to real data demonstrate that the
proposed criteria enable selection of the appropriate non-normalized model in a
data-driven manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Residual Contrastive Learning for Joint Demosaicking and Denoising. (arXiv:2106.10070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1">Nanqing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Maggioni_M/0/1/0/all/0/1">Matteo Maggioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Pellitero_E/0/1/0/all/0/1">Eduardo P&#xe9;rez-Pellitero</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1">Ales Leonardis</a>, <a href="http://arxiv.org/find/cs/1/au:+McDonagh_S/0/1/0/all/0/1">Steven McDonagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10070">
                                    <div class="article-summary-box-inner">
                                        <span>The breakthrough of contrastive learning (CL) has fueled the recent success
of self-supervised learning (SSL) in high-level vision tasks on RGB images.
However, CL is still ill-defined for low-level vision tasks, such as joint
demosaicking and denoising (JDD), in the RAW domain. To bridge this
methodological gap, we present a novel CL approach on RAW images, residual
contrastive learning (RCL), which aims to learn meaningful representations for
JDD. Our work is built on the assumption that noise contained in each RAW image
is signal-dependent, thus two crops from the same RAW image should have more
similar noise distribution than two crops from different RAW images. We use
residuals as a discriminative feature and the earth mover&#x27;s distance to measure
the distribution divergence for the contrastive loss. To evaluate the proposed
CL strategy, we simulate a series of unsupervised JDD experiments with
large-scale data corrupted by synthetic signal-dependent noise, where we set a
new benchmark for unsupervised JDD tasks with unknown (random) noise variance.
Our empirical study not only validates that CL can be applied on distributions
(c.f. features), but also exposes the lack of robustness of previous non-ML and
SSL JDD methods when the statistics of the noise are unknown, thus providing
some further insight into signal-dependent noise problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consensus Control for Decentralized Deep Learning. (arXiv:2102.04828v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1">Lingjing Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1">Anastasia Koloskova</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04828">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized training of deep learning models enables on-device learning
over networks, as well as efficient scaling to large compute clusters.
Experiments in earlier works reveal that, even in a data-center setup,
decentralized training often suffers from the degradation in the quality of the
model: the training and test performance of models trained in a decentralized
fashion is in general worse than that of models trained in a centralized
fashion, and this performance drop is impacted by parameters such as network
size, communication topology and data partitioning. We identify the changing
consensus distance between devices as a key parameter to explain the gap
between centralized and decentralized training.

We show in theory that when the training consensus distance is lower than a
critical quantity, decentralized training converges as fast as the centralized
counterpart. We empirically validate that the relation between generalization
performance and consensus distance is consistent with this theoretical
observation. Our empirical insights allow the principled design of better
decentralized training schemes that mitigate the performance drop. To this end,
we provide practical training guidelines and exemplify its effectiveness on the
data-center setup as the important first step.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting the Function Approximation Architecture in Online Reinforcement Learning. (arXiv:2106.09776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1">John D. Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Modayil_J/0/1/0/all/0/1">Joseph Modayil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09776">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of a reinforcement learning (RL) system depends on the
computational architecture used to approximate a value function. Deep learning
methods provide both optimization techniques and architectures for
approximating nonlinear functions from noisy, high-dimensional observations.
However, prevailing optimization techniques are not designed for
strictly-incremental online updates. Nor are standard architectures designed
for observations with an a priori unknown structure: for example, light sensors
randomly dispersed in space. This paper proposes an online RL prediction
algorithm with an adaptive architecture that efficiently finds useful nonlinear
features. The algorithm is evaluated in a spatial domain with high-dimensional,
stochastic observations. The algorithm outperforms non-adaptive baseline
architectures and approaches the performance of an architecture given
side-channel information. These results are a step towards scalable RL
algorithms for more general problems, where the observation structure is not
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Generalization in Deep Learning Applications for Land Cover Mapping. (arXiv:2008.10351v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lucas Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10351">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that deep learning models can be used to classify
land-use data from geospatial satellite imagery. We show that when these deep
learning models are trained on data from specific continents/seasons, there is
a high degree of variability in model performance on out-of-sample
continents/seasons. This suggests that just because a model accurately predicts
land-use classes in one continent or season does not mean that the model will
accurately predict land-use classes in a different continent or season. We then
use clustering techniques on satellite imagery from different continents to
visualize the differences in landscapes that make geospatial generalization
particularly difficult, and summarize our takeaways for future satellite
imagery-related applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Approximations for a Class of Sequential Testing Problems. (arXiv:2102.07030v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Araman_V/0/1/0/all/0/1">Victor F. Araman</a>, <a href="http://arxiv.org/find/stat/1/au:+Caldentey_R/0/1/0/all/0/1">Rene Caldentey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07030">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a decision maker who must choose an action in order to maximize a
reward function that depends also on an unknown parameter {\Theta}. The
decision maker can delay taking the action in order to experiment and gather
additional information on {\Theta}. We model the decision maker&#x27;s problem using
a Bayesian sequential experimentation framework and use dynamic programming and
diffusion-asymptotic analysis to solve it. For that, we scale our problem in a
way that both the average number of experiments that is conducted per unit of
time is large and the informativeness of each individual experiment is low.
Under such regime, we derive a diffusion approximation for the sequential
experimentation problem, which provides a number of important insights about
the nature of the problem and its solution. Our solution method also shows that
the complexity of the problem grows only quadratically with the cardinality of
the set of actions from which the decision maker can choose. We illustrate our
methodology and results using a concrete application in the context of
assortment selection and new product introduction. Specifically, we study the
problem of a seller who wants to select an optimal assortment of products to
launch into the marketplace and is uncertain about consumers&#x27; preferences.
Motivated by emerging practices in e-commerce, we assume that the seller is
able to use a crowdvoting system to learn these preferences before a final
assortment decision is made. In this context, we undertake an extensive
numerical analysis to assess the value of learning and demonstrate the
effectiveness and robustness of the heuristics derived from the diffusion
approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pseudo-healthy synthesis with pathology disentanglement and adversarial learning. (arXiv:2005.01607v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xia_T/0/1/0/all/0/1">Tian Xia</a>, <a href="http://arxiv.org/find/eess/1/au:+Chartsias_A/0/1/0/all/0/1">Agisilaos Chartsias</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsaftaris_S/0/1/0/all/0/1">Sotirios A. Tsaftaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01607">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-healthy synthesis is the task of creating a subject-specific &#x60;healthy&#x27;
image from a pathological one. Such images can be helpful in tasks such as
anomaly detection and understanding changes induced by pathology and disease.
In this paper, we present a model that is encouraged to disentangle the
information of pathology from what seems to be healthy. We disentangle what
appears to be healthy and where disease is as a segmentation map, which are
then recombined by a network to reconstruct the input disease image. We train
our models adversarially using either paired or unpaired settings, where we
pair disease images and maps when available. We quantitatively and
subjectively, with a human study, evaluate the quality of pseudo-healthy images
using several criteria. We show in a series of experiments, performed on ISLES,
BraTS and Cam-CAN datasets, that our method is better than several baselines
and methods from the literature. We also show that due to better training
processes we could recover deformations, on surrounding tissue, caused by
disease. Our implementation is publicly available at
https://github.com/xiat0616/pseudo-healthy-synthesis. This paper has been
accepted by Medical Image Analysis:
https://doi.org/10.1016/j.media.2020.101719.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving GANs: When Contradictions Turn into Compliance. (arXiv:2106.09946v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhar_S/0/1/0/all/0/1">Sauptik Dhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Heydari_J/0/1/0/all/0/1">Javad Heydari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Samarth Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurup_U/0/1/0/all/0/1">Unmesh Kurup</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mohak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09946">
                                    <div class="article-summary-box-inner">
                                        <span>Limited availability of labeled-data makes any supervised learning problem
challenging. Alternative learning settings like semi-supervised and universum
learning alleviate the dependency on labeled data, but still require a large
amount of unlabeled data, which may be unavailable or expensive to acquire.
GAN-based synthetic data generation methods have recently shown promise by
generating synthetic samples to improve task at hand. However, these samples
cannot be used for other purposes. In this paper, we propose a GAN game which
provides improved discriminator accuracy under limited data settings, while
generating realistic synthetic data. This provides the added advantage that now
the generated data can be used for other similar tasks. We provide the
theoretical guarantees and empirical results in support of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Message Passing in Graph Convolution Networks via Adaptive Filter Banks. (arXiv:2106.09910v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xing Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wenrui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Junni Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hongkai Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1">Pascal Frossard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09910">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolution networks, like message passing graph convolution networks
(MPGCNs), have been a powerful tool in representation learning of networked
data. However, when data is heterogeneous, most architectures are limited as
they employ a single strategy to handle multi-channel graph signals and they
typically focus on low-frequency information. In this paper, we present a novel
graph convolution operator, termed BankGCN, which keeps benefits of message
passing models, but extends their capabilities beyond &#x60;low-pass&#x27; features. It
decomposes multi-channel signals on graphs into subspaces and handles
particular information in each subspace with an adapted filter. The filters of
all subspaces have different frequency responses and together form a filter
bank. Furthermore, each filter in the spectral domain corresponds to a message
passing scheme, and diverse schemes are implemented via the filter bank.
Importantly, the filter bank and the signal decomposition are jointly learned
to adapt to the spectral characteristics of data and to target applications.
Furthermore, this is implemented almost without extra parameters in comparison
with most existing MPGCNs. Experimental results show that the proposed
convolution operator permits to achieve excellent performance in graph
classification on a collection of benchmark graph datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Armed Bandits for Minesweeper: Profiting from Exploration-Exploitation Synergy. (arXiv:2007.12824v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lordeiro_I/0/1/0/all/0/1">Igor Q. Lordeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddad_D/0/1/0/all/0/1">Diego B. Haddad</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardoso_D/0/1/0/all/0/1">Douglas O. Cardoso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12824">
                                    <div class="article-summary-box-inner">
                                        <span>A popular computer puzzle, the game of Minesweeper requires its human players
to have a mix of both luck and strategy to succeed. Analyzing these aspects
more formally, in our research we assessed the feasibility of a novel
methodology based on Reinforcement Learning as an adequate approach to tackle
the problem presented by this game. For this purpose we employed Multi-Armed
Bandit algorithms which were carefully adapted in order to enable their use to
define autonomous computational players, targeting to make the best use of some
game peculiarities. After experimental evaluation, results showed that this
approach was indeed successful, especially in smaller game boards, such as the
standard beginner level. Despite this fact the main contribution of this work
is a detailed examination of Minesweeper from a learning perspective, which led
to various original insights which are thoroughly discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the Gap Between Object Detection and User Intent via Query-Modulation. (arXiv:2106.10258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fornoni_M/0/1/0/all/0/1">Marco Fornoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chaochao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Liangchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilber_K/0/1/0/all/0/1">Kimberly Wilber</a>, <a href="http://arxiv.org/find/cs/1/au:+Stark_A/0/1/0/all/0/1">Alex Stark</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Howard_A/0/1/0/all/0/1">Andrew Howard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10258">
                                    <div class="article-summary-box-inner">
                                        <span>When interacting with objects through cameras, or pictures, users often have
a specific intent. For example, they may want to perform a visual search.
However, most object detection models ignore the user intent, relying on image
pixels as their only input. This often leads to incorrect results, such as lack
of a high-confidence detection on the object of interest, or detection with a
wrong class label. In this paper we investigate techniques to modulate standard
object detectors to explicitly account for the user intent, expressed as an
embedding of a simple query. Compared to standard object detectors,
query-modulated detectors show superior performance at detecting objects for a
given label of interest. Thanks to large-scale training data synthesized from
standard object detection annotations, query-modulated detectors can also
outperform specialized referring expression recognition systems. Furthermore,
they can be simultaneously trained to solve for both query-modulated detection
and standard object detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local AdaGrad-Type Algorithm for Stochastic Convex-Concave Minimax Problems. (arXiv:2106.10022v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1">Luofeng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jia Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolar_M/0/1/0/all/0/1">Mladen Kolar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10022">
                                    <div class="article-summary-box-inner">
                                        <span>Large scale convex-concave minimax problems arise in numerous applications,
including game theory, robust training, and training of generative adversarial
networks. Despite their wide applicability, solving such problems efficiently
and effectively is challenging in the presence of large amounts of data using
existing stochastic minimax methods. We study a class of stochastic minimax
methods and develop a communication-efficient distributed stochastic
extragradient algorithm, LocalAdaSEG, with an adaptive learning rate suitable
for solving convex-concave minimax problem in the Parameter-Server model.
LocalAdaSEG has three main features: (i) periodic communication strategy
reduces the communication cost between workers and the server; (ii) an adaptive
learning rate that is computed locally and allows for tuning-free
implementation; and (iii) theoretically, a nearly linear speed-up with respect
to the dominant variance term, arising from estimation of the stochastic
gradient, is proven in both the smooth and nonsmooth convex-concave settings.
LocalAdaSEG is used to solve a stochastic bilinear game, and train generative
adversarial network. We compare LocalAdaSEG against several existing optimizers
for minimax problems and demonstrate its efficacy through several experiments
in both the homogeneous and heterogeneous settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">It&#x27;s FLAN time! Summing feature-wise latent representations for interpretability. (arXiv:2106.10086v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An-phi Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_M/0/1/0/all/0/1">Maria Rodriguez Martinez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10086">
                                    <div class="article-summary-box-inner">
                                        <span>Interpretability has become a necessary feature for machine learning models
deployed in critical scenarios, e.g. legal systems, healthcare. In these
situations, algorithmic decisions may have (potentially negative) long-lasting
effects on the end-user affected by the decision. In many cases, the
representational power of deep learning models is not needed, therefore simple
and interpretable models (e.g. linear models) should be preferred. However, in
high-dimensional and/or complex domains (e.g. computer vision), the universal
approximation capabilities of neural networks is required. Inspired by linear
models and the Kolmogorov-Arnol representation theorem, we propose a novel
class of structurally-constrained neural networks, which we call FLANs
(Feature-wise Latent Additive Networks). Crucially, FLANs process each input
feature separately, computing for each of them a representation in a common
latent space. These feature-wise latent representations are then simply summed,
and the aggregated representation is used for prediction. These constraints
(which are at the core of the interpretability of linear models) allow an user
to estimate the effect of each individual feature independently from the
others, enhancing interpretability. In a set of experiments across different
domains, we show how without compromising excessively the test performance, the
structural constraints proposed in FLANs indeed increase the interpretability
of deep learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers. (arXiv:2106.10270v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1">Andreas Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wightman_R/0/1/0/all/0/1">Ross Wightman</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10270">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformers (ViT) have been shown to attain highly competitive
performance for a wide range of vision applications, such as image
classification, object detection and semantic image segmentation. In comparison
to convolutional neural networks, the Vision Transformer&#x27;s weaker inductive
bias is generally found to cause an increased reliance on model regularization
or data augmentation (&#x60;&#x60;AugReg&#x27;&#x27; for short) when training on smaller training
datasets. We conduct a systematic empirical study in order to better understand
the interplay between the amount of training data, AugReg, model size and
compute budget. As one result of this study we find that the combination of
increased compute and AugReg can yield models with the same performance as
models trained on an order of magnitude more training data: we train ViT models
of various sizes on the public ImageNet-21k dataset which either match or
outperform their counterparts trained on the larger, but not publicly available
JFT-300M dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting gender of Brazilian names using deep learning. (arXiv:2106.10156v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rego_R/0/1/0/all/0/1">Rosana C. B. Rego</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1">Ver&#xf4;nica M. L. Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10156">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting gender by the name is not a simple task. In many applications,
especially in the natural language processing (NLP) field, this task may be
necessary, mainly when considering foreign names. Some machine learning
algorithms can satisfactorily perform the prediction. In this paper, we
examined and implemented feedforward and recurrent deep neural network models,
such as MLP, RNN, GRU, CNN, and BiLSTM, to classify gender through the first
name. A dataset of Brazilian names is used to train and evaluate the models. We
analyzed the accuracy, recall, precision, and confusion matrix to measure the
models&#x27; performances. The results indicate that the gender prediction can be
performed from the feature extraction strategy looking at the names as a set of
strings. Some models accurately predict the gender in more than 90% of the
cases. The recurrent models overcome the feedforward models in this binary
classification problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python. (arXiv:2106.09756v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1">Robert Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_P/0/1/0/all/0/1">Peizhen Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo E Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chasmai_M/0/1/0/all/0/1">Mustafa Chasmai</a>, <a href="http://arxiv.org/find/cs/1/au:+Schobs_L/0/1/0/all/0/1">Lawrence Schobs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09756">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning is a general-purpose technology holding promises for many
interdisciplinary research problems. However, significant barriers exist in
crossing disciplinary boundaries when most machine learning tools are developed
in different areas separately. We present Pykale - a Python library for
knowledge-aware machine learning on graphs, images, texts, and videos to enable
and accelerate interdisciplinary research. We formulate new green machine
learning guidelines based on standard software engineering practices and
propose a novel pipeline-based application programming interface (API). PyKale
focuses on leveraging knowledge from multiple sources for accurate and
interpretable prediction, thus supporting multimodal learning and transfer
learning (particularly domain adaptation) with latest deep learning and
dimensionality reduction models. We build PyKale on PyTorch and leverage the
rich PyTorch ecosystem. Our pipeline-based API design enforces standardization
and minimalism, embracing green machine learning concepts via reducing
repetitions and redundancy, reusing existing resources, and recycling learning
models across areas. We demonstrate its interdisciplinary nature via examples
in bioinformatics, knowledge graph, image/video recognition, and medical
imaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bad Characters: Imperceptible NLP Attacks. (arXiv:2106.09898v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boucher_N/0/1/0/all/0/1">Nicholas Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1">Ross Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09898">
                                    <div class="article-summary-box-inner">
                                        <span>Several years of research have shown that machine-learning systems are
vulnerable to adversarial examples, both in theory and in practice. Until now,
such attacks have primarily targeted visual models, exploiting the gap between
human and machine perception. Although text-based models have also been
attacked with adversarial examples, such attacks struggled to preserve semantic
meaning and indistinguishability. In this paper, we explore a large class of
adversarial examples that can be used to attack text-based models in a
black-box setting without making any human-perceptible visual modification to
inputs. We use encoding-specific perturbations that are imperceptible to the
human eye to manipulate the outputs of a wide range of Natural Language
Processing (NLP) systems from neural machine-translation pipelines to web
search engines. We find that with a single imperceptible encoding injection --
representing one invisible character, homoglyph, reordering, or deletion -- an
attacker can significantly reduce the performance of vulnerable models, and
with three injections most models can be functionally broken. Our attacks work
against currently-deployed commercial systems, including those produced by
Microsoft and Google, in addition to open source models published by Facebook
and IBM. This novel series of attacks presents a significant threat to many
language processing systems: an attacker can affect systems in a targeted
manner without any assumptions about the underlying model. We conclude that
text-based NLP systems require careful input sanitization, just like
conventional applications, and that given such systems are now being deployed
rapidly at scale, the urgent attention of architects and operators is required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-Shot Federated Learning with New Classes for Audio Classification. (arXiv:2106.10019v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gudur_G/0/1/0/all/0/1">Gautham Krishna Gudur</a>, <a href="http://arxiv.org/find/cs/1/au:+Perepu_S/0/1/0/all/0/1">Satheesh K. Perepu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10019">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an effective way of extracting insights from different
user devices while preserving the privacy of users. However, new classes with
completely unseen data distributions can stream across any device in a
federated learning setting, whose data cannot be accessed by the global server
or other users. To this end, we propose a unified zero-shot framework to handle
these aforementioned challenges during federated learning. We simulate two
scenarios here -- 1) when the new class labels are not reported by the user,
the traditional FL setting is used; 2) when new class labels are reported by
the user, we synthesize Anonymized Data Impressions by calculating class
similarity matrices corresponding to each device&#x27;s new classes followed by
unsupervised clustering to distinguish between new classes across different
users. Moreover, our proposed framework can also handle statistical
heterogeneities in both labels and models across the participating users. We
empirically evaluate our framework on-device across different communication
rounds (FL iterations) with new classes in both local and global updates, along
with heterogeneous labels and models, on two widely used audio classification
applications -- keyword spotting and urban sound classification, and observe an
average deterministic accuracy increase of ~4.041% and ~4.258% respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Directed Planning by Reinforcement Learning and Active Inference. (arXiv:2106.09938v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongqi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Doya_K/0/1/0/all/0/1">Kenji Doya</a>, <a href="http://arxiv.org/find/cs/1/au:+Tani_J/0/1/0/all/0/1">Jun Tani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09938">
                                    <div class="article-summary-box-inner">
                                        <span>What is the difference between goal-directed and habitual behavior? We
propose a novel computational framework of decision making with Bayesian
inference, in which everything is integrated as an entire neural network model.
The model learns to predict environmental state transitions by self-exploration
and generating motor actions by sampling stochastic internal states $z$.
Habitual behavior, which is obtained from the prior distribution of $z$, is
acquired by reinforcement learning. Goal-directed behavior is determined from
the posterior distribution of $z$ by planning, using active inference, to
minimize the free energy for goal observation. We demonstrate the effectiveness
of the proposed framework by experiments in a sensorimotor navigation task with
camera observations and continuous motor actions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Bias Quantification for Continuous Treatment. (arXiv:2106.09762v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Detommaso_G/0/1/0/all/0/1">Gianluca Detommaso</a>, <a href="http://arxiv.org/find/stat/1/au:+Bruckner_M/0/1/0/all/0/1">Michael Br&#xfc;ckner</a>, <a href="http://arxiv.org/find/stat/1/au:+Schulz_P/0/1/0/all/0/1">Philip Schulz</a>, <a href="http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1">Victor Chernozhukov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09762">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we develop a novel characterization of marginal causal effect
and causal bias in the continuous treatment setting. We show they can be
expressed as an expectation with respect to a conditional probability
distribution, which can be estimated via standard statistical and probabilistic
methods. All terms in the expectations can be computed via automatic
differentiation, also for highly non-linear models. We further develop a new
complete criterion for identifiability of causal effects via covariate
adjustment, showing the bias equals zero if the criterion is met. We study the
effectiveness of our framework in three different scenarios: linear models
under confounding, overcontrol and endogenous selection bias; a non-linear
model where full identifiability cannot be achieved because of missing data; a
simulated medical study of statins and atherosclerotic cardiovascular disease.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping strict saddle points of the Moreau envelope in nonsmooth optimization. (arXiv:2106.09815v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Davis_D/0/1/0/all/0/1">Damek Davis</a>, <a href="http://arxiv.org/find/math/1/au:+Diaz_M/0/1/0/all/0/1">Mateo D&#xed;az</a>, <a href="http://arxiv.org/find/math/1/au:+Drusvyatskiy_D/0/1/0/all/0/1">Dmitriy Drusvyatskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09815">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that stochastically perturbed gradient methods can
efficiently escape strict saddle points of smooth functions. We extend this
body of work to nonsmooth optimization, by analyzing an inexact analogue of a
stochastically perturbed gradient method applied to the Moreau envelope. The
main conclusion is that a variety of algorithms for nonsmooth optimization can
escape strict saddle points of the Moreau envelope at a controlled rate. The
main technical insight is that typical algorithms applied to the proximal
subproblem yield directions that approximate the gradient of the Moreau
envelope in relative terms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boolean Matrix Factorization with SAT and MaxSAT. (arXiv:2106.10105v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Avellaneda_F/0/1/0/all/0/1">Florent Avellaneda</a>, <a href="http://arxiv.org/find/cs/1/au:+Villemaire_R/0/1/0/all/0/1">Roger Villemaire</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10105">
                                    <div class="article-summary-box-inner">
                                        <span>The Boolean matrix factorization problem consists in approximating a matrix
by the Boolean product of two smaller Boolean matrices. To obtain optimal
solutions when the matrices to be factorized are small, we propose SAT and
MaxSAT encoding; however, when the matrices to be factorized are large, we
propose a heuristic based on the search for maximal biclique edge cover. We
experimentally demonstrate that our approaches allow a better factorization
than existing approaches while keeping reasonable computation times. Our
methods also allow the handling of incomplete matrices with missing entries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accumulative Poisoning Attacks on Real-time Data. (arXiv:2106.09993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09993">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting training data from untrusted sources exposes machine learning
services to poisoning adversaries, who maliciously manipulate training data to
degrade the model accuracy. When trained on offline datasets, poisoning
adversaries have to inject the poisoned data in advance before training, and
the order of feeding these poisoned batches into the model is stochastic. In
contrast, practical systems are more usually trained/fine-tuned on sequentially
captured real-time data, in which case poisoning adversaries could dynamically
poison each data batch according to the current model state. In this paper, we
focus on the real-time settings and propose a new attacking strategy, which
affiliates an accumulative phase with poisoning attacks to secretly (i.e.,
without affecting accuracy) magnify the destructive effect of a (poisoned)
trigger batch. By mimicking online learning and federated learning on CIFAR-10,
we show that the model accuracy will significantly drop by a single update step
on the trigger batch after the accumulative phase. Our work validates that a
well-designed but straightforward attacking strategy can dramatically amplify
the poisoning effects, with no need to explore complex techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection in Dynamic Graphs via Transformer. (arXiv:2106.09876v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shirui Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Guang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1">Fei Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_V/0/1/0/all/0/1">Vincent CS Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09876">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting anomalies for dynamic graphs has drawn increasing attention due to
their wide applications in social networks, e-commerce, and cybersecurity. The
recent deep learning-based approaches have shown promising results over shallow
methods. However, they fail to address two core challenges of anomaly detection
in dynamic graphs: the lack of informative encoding for unattributed nodes and
the difficulty of learning discriminate knowledge from coupled spatial-temporal
dynamic graphs. To overcome these challenges, in this paper, we present a novel
Transformer-based Anomaly Detection framework for DYnamic graph (TADDY). Our
framework constructs a comprehensive node encoding strategy to better represent
each node&#x27;s structural and temporal roles in an evolving graphs stream.
Meanwhile, TADDY captures informative representation from dynamic graphs with
coupled spatial-temporal patterns via a dynamic graph transformer model. The
extensive experimental results demonstrate that our proposed TADDY framework
outperforms the state-of-the-art methods by a large margin on four real-world
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Being Properly Improper. (arXiv:2106.09920v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1">Richard Nock</a>, <a href="http://arxiv.org/find/cs/1/au:+Sypherd_T/0/1/0/all/0/1">Tyler Sypherd</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_L/0/1/0/all/0/1">Lalitha Sankar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09920">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s ML, data can be twisted (changed) in various ways, either for bad
or good intent. Such twisted data challenges the founding theory of properness
for supervised losses which form the basis for many popular losses for class
probability estimation. Unfortunately, at its core, properness ensures that the
optimal models also learn the twist. In this paper, we analyse such class
probability-based losses when they are stripped off the mandatory properness;
we define twist-proper losses as losses formally able to retrieve the optimum
(untwisted) estimate off the twists, and show that a natural extension of a
half-century old loss introduced by S. Arimoto is twist proper. We then turn to
a theory that has provided some of the best off-the-shelf algorithms for proper
losses, boosting. Boosting can require access to the derivative of the convex
conjugate of a loss to compute examples weights. Such a function can be hard to
get, for computational or mathematical reasons; this turns out to be the case
for Arimoto&#x27;s loss. We bypass this difficulty by inverting the problem as
follows: suppose a blueprint boosting algorithm is implemented with a general
weight update function. What are the losses for which boosting-compliant
minimisation happens? Our answer comes as a general boosting algorithm which
meets the optimal boosting dependence on the number of calls to the weak
learner; when applied to Arimoto&#x27;s loss, it leads to a simple optimisation
algorithm whose performances are showcased on several domains and twists.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Distance-based Separability Measure for Internal Cluster Validation. (arXiv:2106.09794v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Shuyue Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1">Murray Loew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09794">
                                    <div class="article-summary-box-inner">
                                        <span>To evaluate clustering results is a significant part of cluster analysis.
Since there are no true class labels for clustering in typical unsupervised
learning, many internal cluster validity indices (CVIs), which use predicted
labels and data, have been created. Without true labels, to design an effective
CVI is as difficult as to create a clustering method. And it is crucial to have
more CVIs because there are no universal CVIs that can be used to measure all
datasets and no specific methods of selecting a proper CVI for clusters without
true labels. Therefore, to apply a variety of CVIs to evaluate clustering
results is necessary. In this paper, we propose a novel internal CVI -- the
Distance-based Separability Index (DSI), based on a data separability measure.
We compared the DSI with eight internal CVIs including studies from early Dunn
(1974) to most recent CVDD (2019) and an external CVI as ground truth, by using
clustering results of five clustering algorithms on 12 real and 97 synthetic
datasets. Results show DSI is an effective, unique, and competitive CVI to
other compared CVIs. We also summarized the general process to evaluate CVIs
and created the rank-difference metric for comparison of CVIs&#x27; results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Self-supervised Vision Transformers for Representation Learning. (arXiv:2106.09785v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1">Mei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09785">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates two techniques for developing efficient
self-supervised vision transformers (EsViT) for visual representation learning.
First, we show through a comprehensive empirical study that multi-stage
architectures with sparse self-attentions can significantly reduce modeling
complexity but with a cost of losing the ability to capture fine-grained
correspondences between image regions. Second, we propose a new pre-training
task of region matching which allows the model to capture fine-grained region
dependencies and as a result significantly improves the quality of the learned
vision representations. Our results show that combining the two techniques,
EsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation,
outperforming prior arts with around an order magnitude of higher throughput.
When transferring to downstream linear classification tasks, EsViT outperforms
its supervised counterpart on 17 out of 18 datasets. The code and models will
be publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shuffle Private Stochastic Convex Optimization. (arXiv:2106.09805v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheu_A/0/1/0/all/0/1">Albert Cheu</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_M/0/1/0/all/0/1">Matthew Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jieming Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Binghui Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09805">
                                    <div class="article-summary-box-inner">
                                        <span>In shuffle privacy, each user sends a collection of randomized messages to a
trusted shuffler, the shuffler randomly permutes these messages, and the
resulting shuffled collection of messages must satisfy differential privacy.
Prior work in this model has largely focused on protocols that use a single
round of communication to compute algorithmic primitives like means,
histograms, and counts. In this work, we present interactive shuffle protocols
for stochastic convex optimization. Our optimization protocols rely on a new
noninteractive protocol for summing vectors of bounded $\ell_2$ norm. By
combining this sum subroutine with techniques including mini-batch stochastic
gradient descent, accelerated gradient descent, and Nesterov&#x27;s smoothing
method, we obtain loss guarantees for a variety of convex loss functions that
significantly improve on those of the local model and sometimes match those of
the central model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heuristic Stopping Rules For Technology-Assisted Review. (arXiv:2106.09871v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eugene Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_D/0/1/0/all/0/1">David D. Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Frieder_O/0/1/0/all/0/1">Ophir Frieder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09871">
                                    <div class="article-summary-box-inner">
                                        <span>Technology-assisted review (TAR) refers to human-in-the-loop active learning
workflows for finding relevant documents in large collections. These workflows
often must meet a target for the proportion of relevant documents found (i.e.
recall) while also holding down costs. A variety of heuristic stopping rules
have been suggested for striking this tradeoff in particular settings, but none
have been tested against a range of recall targets and tasks. We propose two
new heuristic stopping rules, Quant and QuantCI based on model-based estimation
techniques from survey research. We compare them against a range of proposed
heuristics and find they are accurate at hitting a range of recall targets
while substantially reducing review costs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AI-Enabled Ultra-Low-Dose CT Reconstruction. (arXiv:2106.09834v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1">Weiwen Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Niu_C/0/1/0/all/0/1">Chuang Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ebrahimian_S/0/1/0/all/0/1">Shadi Ebrahimian</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1">Hengyong Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kalra_M/0/1/0/all/0/1">Mannu Kalra</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09834">
                                    <div class="article-summary-box-inner">
                                        <span>By the ALARA (As Low As Reasonably Achievable) principle, ultra-low-dose CT
reconstruction is a holy grail to minimize cancer risks and genetic damages,
especially for children. With the development of medical CT technologies, the
iterative algorithms are widely used to reconstruct decent CT images from a
low-dose scan. Recently, artificial intelligence (AI) techniques have shown a
great promise in further reducing CT radiation dose to the next level. In this
paper, we demonstrate that AI-powered CT reconstruction offers diagnostic image
quality at an ultra-low-dose level comparable to that of radiography.
Specifically, here we develop a Split Unrolled Grid-like Alternative
Reconstruction (SUGAR) network, in which deep learning, physical modeling and
image prior are integrated. The reconstruction results from clinical datasets
show that excellent images can be reconstructed using SUGAR from 36
projections. This approach has a potential to change future healthcare.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Invariance Penalties for Risk Minimization. (arXiv:2106.09777v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khezeli_K/0/1/0/all/0/1">Kia Khezeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Blaas_A/0/1/0/all/0/1">Arno Blaas</a>, <a href="http://arxiv.org/find/cs/1/au:+Soboczenski_F/0/1/0/all/0/1">Frank Soboczenski</a>, <a href="http://arxiv.org/find/cs/1/au:+Chia_N/0/1/0/all/0/1">Nicholas Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalantari_J/0/1/0/all/0/1">John Kalantari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09777">
                                    <div class="article-summary-box-inner">
                                        <span>The Invariant Risk Minimization (IRM) principle was first proposed by
Arjovsky et al. [2019] to address the domain generalization problem by
leveraging data heterogeneity from differing experimental conditions.
Specifically, IRM seeks to find a data representation under which an optimal
classifier remains invariant across all domains. Despite the conceptual appeal
of IRM, the effectiveness of the originally proposed invariance penalty has
recently been brought into question. In particular, there exists
counterexamples for which that invariance penalty can be arbitrarily small for
non-invariant data representations. We propose an alternative invariance
penalty by revisiting the Gramian matrix of the data representation. We discuss
the role of its eigenvalues in the relationship between the risk and the
invariance penalty, and demonstrate that it is ill-conditioned for said
counterexamples. The proposed approach is guaranteed to recover an invariant
representation for linear settings under mild non-degeneracy conditions. Its
effectiveness is substantiated by experiments on DomainBed and
InvarianceUnitTest, two extensive test beds for domain generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topological Indoor Mapping through WiFi Signals. (arXiv:2106.09789v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaefermeier_B/0/1/0/all/0/1">Bastian Schaefermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1">Gerd Stumme</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1">Tom Hanika</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09789">
                                    <div class="article-summary-box-inner">
                                        <span>The ubiquitous presence of WiFi access points and mobile devices capable of
measuring WiFi signal strengths allow for real-world applications in indoor
localization and mapping. In particular, no additional infrastructure is
required. Previous approaches in this field were, however, often hindered by
problems such as effortful map-building processes, changing environments and
hardware differences. We tackle these problems focussing on topological maps.
These represent discrete locations, such as rooms, and their relations, e.g.,
distances and transition frequencies. In our unsupervised method, we employ
WiFi signal strength distributions, dimension reduction and clustering. It can
be used in settings where users carry mobile devices and follow their normal
routine. We aim for applications in short-lived indoor events such as
conferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Note on Optimizing Distributions using Kernel Mean Embeddings. (arXiv:2106.09994v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muzellec_B/0/1/0/all/0/1">Boris Muzellec</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09994">
                                    <div class="article-summary-box-inner">
                                        <span>Kernel mean embeddings are a popular tool that consists in representing
probability measures by their infinite-dimensional mean embeddings in a
reproducing kernel Hilbert space. When the kernel is characteristic, mean
embeddings can be used to define a distance between probability measures, known
as the maximum mean discrepancy (MMD). A well-known advantage of mean
embeddings and MMD is their low computational cost and low sample complexity.
However, kernel mean embeddings have had limited applications to problems that
consist in optimizing distributions, due to the difficulty of characterizing
which Hilbert space vectors correspond to a probability distribution. In this
note, we propose to leverage the kernel sums-of-squares parameterization of
positive functions of Marteau-Ferey et al. [2020] to fit distributions in the
MMD geometry. First, we show that when the kernel is characteristic,
distributions with a kernel sum-of-squares density are dense. Then, we provide
algorithms to optimize such distributions in the finite-sample setting, which
we illustrate in a density fitting numerical experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Generative Adversarial Network Training via Self-Labeling and Self-Attention. (arXiv:2106.09914v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1">Tomoki Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09914">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel GAN training scheme that can handle any level of labeling
in a unified manner. Our scheme introduces a form of artificial labeling that
can incorporate manually defined labels, when available, and induce an
alignment between them. To define the artificial labels, we exploit the
assumption that neural network generators can be trained more easily to map
nearby latent vectors to data with semantic similarities, than across separate
categories. We use generated data samples and their corresponding artificial
conditioning labels to train a classifier. The classifier is then used to
self-label real data. To boost the accuracy of the self-labeling, we also use
the exponential moving average of the classifier. However, because the
classifier might still make mistakes, especially at the beginning of the
training, we also refine the labels through self-attention, by using the
labeling of real data samples only when the classifier outputs a high
classification probability score. We evaluate our approach on CIFAR-10, STL-10
and SVHN, and show that both self-labeling and self-attention consistently
improve the quality of generated data. More surprisingly, we find that the
proposed scheme can even outperform class-conditional GANs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradual Domain Adaptation via Self-Training of Auxiliary Models. (arXiv:2106.09890v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yabin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Bin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09890">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation becomes more challenging with increasing gaps between
source and target domains. Motivated from an empirical analysis on the
reliability of labeled source data for the use of distancing target domains, we
propose self-training of auxiliary models (AuxSelfTrain) that learns models for
intermediate domains and gradually combats the distancing shifts across
domains. We introduce evolving intermediate domains as combinations of
decreasing proportion of source data and increasing proportion of target data,
which are sampled to minimize the domain distance between consecutive domains.
Then the source model could be gradually adapted for the use in the target
domain by self-training of auxiliary models on evolving intermediate domains.
We also introduce an enhanced indicator for sample selection via implicit
ensemble and extend the proposed method to semi-supervised domain adaptation.
Experiments on benchmark datasets of unsupervised and semi-supervised domain
adaptation verify its efficacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many Agent Reinforcement Learning Under Partial Observability. (arXiv:2106.09825v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Keyang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_P/0/1/0/all/0/1">Prashant Doshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Bikramjit Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09825">
                                    <div class="article-summary-box-inner">
                                        <span>Recent renewed interest in multi-agent reinforcement learning (MARL) has
generated an impressive array of techniques that leverage deep reinforcement
learning, primarily actor-critic architectures, and can be applied to a limited
range of settings in terms of observability and communication. However, a
continuing limitation of much of this work is the curse of dimensionality when
it comes to representations based on joint actions, which grow exponentially
with the number of agents. In this paper, we squarely focus on this challenge
of scalability. We apply the key insight of action anonymity, which leads to
permutation invariance of joint actions, to two recently presented deep MARL
algorithms, MADDPG and IA2C, and compare these instantiations to another recent
technique that leverages action anonymity, viz., mean-field MARL. We show that
our instantiations can learn the optimal behavior in a broader class of agent
networks than the mean-field method, using a recently introduced pragmatic
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic COVID-19 Chest X-ray Dataset for Computer-Aided Diagnosis. (arXiv:2106.09759v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zunair_H/0/1/0/all/0/1">Hasib Zunair</a>, <a href="http://arxiv.org/find/eess/1/au:+Hamza_A/0/1/0/all/0/1">A. Ben Hamza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09759">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new dataset called Synthetic COVID-19 Chest X-ray Dataset for
training machine learning models. The dataset consists of 21,295 synthetic
COVID-19 chest X-ray images to be used for computer-aided diagnosis. These
images, generated via an unsupervised domain adaptation approach, are of high
quality. We find that the synthetic images not only improve performance of
various deep learning architectures when used as additional training data under
heavy imbalance conditions, but also detect the target class with high
confidence. We also find that comparable performance can also be achieved when
trained only on synthetic images. Further, salient features of the synthetic
COVID-19 images indicate that the distribution is significantly different from
Non-COVID-19 classes, enabling a proper decision boundary. We hope the
availability of such high fidelity chest X-ray images of COVID-19 will
encourage advances in the development of diagnostic and/or management tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch Multi-Fidelity Bayesian Optimization with Deep Auto-Regressive Networks. (arXiv:2106.09884v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shibo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_R/0/1/0/all/0/1">Robert M. Kirby</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1">Shandian Zhe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09884">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is a powerful approach for optimizing black-box,
expensive-to-evaluate functions. To enable a flexible trade-off between the
cost and accuracy, many applications allow the function to be evaluated at
different fidelities. In order to reduce the optimization cost while maximizing
the benefit-cost ratio, in this paper, we propose Batch Multi-fidelity Bayesian
Optimization with Deep Auto-Regressive Networks (BMBO-DARN). We use a set of
Bayesian neural networks to construct a fully auto-regressive model, which is
expressive enough to capture strong yet complex relationships across all the
fidelities, so as to improve the surrogate learning and optimization
performance. Furthermore, to enhance the quality and diversity of queries, we
develop a simple yet efficient batch querying method, without any combinatorial
search over the fidelities. We propose a batch acquisition function based on
Max-value Entropy Search (MES) principle, which penalizes highly correlated
queries and encourages diversity. We use posterior samples and moment matching
to fulfill efficient computation of the acquisition function and conduct
alternating optimization over every fidelity-input pair, which guarantees an
improvement at each step. We demonstrate the advantage of our approach on four
real-world hyperparameter optimization applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LSEC: Large-scale spectral ensemble clustering. (arXiv:2106.09852v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongmin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiucai Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Imakura_A/0/1/0/all/0/1">Akira Imakura</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakurai_T/0/1/0/all/0/1">Tetsuya Sakurai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09852">
                                    <div class="article-summary-box-inner">
                                        <span>Ensemble clustering is a fundamental problem in the machine learning field,
combining multiple base clusterings into a better clustering result. However,
most of the existing methods are unsuitable for large-scale ensemble clustering
tasks due to the efficiency bottleneck. In this paper, we propose a large-scale
spectral ensemble clustering (LSEC) method to strike a good balance between
efficiency and effectiveness. In LSEC, a large-scale spectral clustering based
efficient ensemble generation framework is designed to generate various base
clusterings within a low computational complexity. Then all based clustering
are combined through a bipartite graph partition based consensus function into
a better consensus clustering result. The LSEC method achieves a lower
computational complexity than most existing ensemble clustering methods.
Experiments conducted on ten large-scale datasets show the efficiency and
effectiveness of the LSEC method. The MATLAB code of the proposed method and
experimental datasets are available at https://github.com/Li-
Hongmin/MyPaperWithCode.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machining Cycle Time Prediction: Data-driven Modelling of Machine Tool Feedrate Behavior with Neural Networks. (arXiv:2106.09719v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Dominguez_Caballero_J/0/1/0/all/0/1">Javier Dominguez-Caballero</a>, <a href="http://arxiv.org/find/cs/1/au:+Ward_R/0/1/0/all/0/1">Rob Ward</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayvar_Soberanis_S/0/1/0/all/0/1">Sabino Ayvar-Soberanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Curtis_D/0/1/0/all/0/1">David Curtis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09719">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate prediction of machining cycle times is important in the
manufacturing industry. Usually, Computer Aided Manufacturing (CAM) software
estimates the machining times using the commanded feedrate from the toolpath
file using basic kinematic settings. Typically, the methods do not account for
toolpath geometry or toolpath tolerance and therefore under estimate the
machining cycle times considerably. Removing the need for machine specific
knowledge, this paper presents a data-driven feedrate and machining cycle time
prediction method by building a neural network model for each machine tool
axis. In this study, datasets composed of the commanded feedrate, nominal
acceleration, toolpath geometry and the measured feedrate were used to train a
neural network model. Validation trials using a representative industrial thin
wall structure component on a commercial machining centre showed that this
method estimated the machining time with more than 90% accuracy. This method
showed that neural network models have the capability to learn the behavior of
a complex machine tool system and predict cycle times. Further integration of
the methods will be critical in the implantation of digital twins in Industry
4.0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC Prediction Sets Under Covariate Shift. (arXiv:2106.09848v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sangdon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobriban_E/0/1/0/all/0/1">Edgar Dobriban</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1">Osbert Bastani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09848">
                                    <div class="article-summary-box-inner">
                                        <span>An important challenge facing modern machine learning is how to rigorously
quantify the uncertainty of model predictions. Conveying uncertainty is
especially important when there are changes to the underlying data distribution
that might invalidate the predictive model. Yet, most existing uncertainty
quantification algorithms break down in the presence of such shifts. We propose
a novel approach that addresses this challenge by constructing \emph{probably
approximately correct (PAC)} prediction sets in the presence of covariate
shift. Our approach focuses on the setting where there is a covariate shift
from the source distribution (where we have labeled training examples) to the
target distribution (for which we want to quantify uncertainty). Our algorithm
assumes given importance weights that encode how the probabilities of the
training examples change under the covariate shift. In practice, importance
weights typically need to be estimated; thus, we extend our algorithm to the
setting where we are given confidence intervals for the importance weights
rather than their true value. We demonstrate the effectiveness of our approach
on various covariate shifts designed based on the DomainNet and ImageNet
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-free optimization of chaotic acoustics with reservoir computing. (arXiv:2106.09780v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Huhn_F/0/1/0/all/0/1">Francisco Huhn</a>, <a href="http://arxiv.org/find/physics/1/au:+Magri_L/0/1/0/all/0/1">Luca Magri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09780">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a versatile optimization method, which finds the design parameters
that minimize time-averaged acoustic cost functionals. The method is
gradient-free, model-informed, and data-driven with reservoir computing based
on echo state networks. First, we analyse the predictive capabilities of echo
state networks both in the short- and long-time prediction of the dynamics. We
find that both fully data-driven and model-informed architectures learn the
chaotic acoustic dynamics, both time-accurately and statistically. Informing
the training with a physical reduced-order model with one acoustic mode
markedly improves the accuracy and robustness of the echo state networks,
whilst keeping the computational cost low. Echo state networks offer accurate
predictions of the long-time dynamics, which would be otherwise expensive by
integrating the governing equations to evaluate the time-averaged quantity to
optimize. Second, we couple echo state networks with a Bayesian technique to
explore the design thermoacoustic parameter space. The computational method is
minimally intrusive. Third, we find the set of flame parameters that minimize
the time-averaged acoustic energy of chaotic oscillations, which are caused by
the positive feedback with a heat source, such as a flame in gas turbines or
rocket motors. These oscillations are known as thermoacoustic oscillations. The
optimal set of flame parameters is found with the same accuracy as brute-force
grid search, but with a convergence rate that is more than one order of
magnitude faster. This work opens up new possibilities for non-intrusive
(&#x60;&#x60;hands-off&#x27;&#x27;) optimization of chaotic systems, in which the cost of
generating data, for example from high-fidelity simulations and experiments, is
high.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Resource Allocation with Graph Neural Networks. (arXiv:2106.09761v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1">Miles Cranmer</a> (Princeton), <a href="http://arxiv.org/find/cs/1/au:+Melchior_P/0/1/0/all/0/1">Peter Melchior</a> (Princeton), <a href="http://arxiv.org/find/cs/1/au:+Nord_B/0/1/0/all/0/1">Brian Nord</a> (Fermilab)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09761">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for maximizing a global utility function by learning
how to allocate resources in an unsupervised way. We expect interactions
between allocation targets to be important and therefore propose to learn the
reward structure for near-optimal allocation policies with a GNN. By relaxing
the resource constraint, we can employ gradient-based optimization in contrast
to more standard evolutionary algorithms. Our algorithm is motivated by a
problem in modern astronomy, where one needs to select-based on limited initial
information-among $10^9$ galaxies those whose detailed measurement will lead to
optimal inference of the composition of the universe. Our technique presents a
way of flexibly learning an allocation strategy by only requiring forward
simulators for the physics of interest and the measurement process. We
anticipate that our technique will also find applications in a range of
resource allocation problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Iterative Feature Matching: Toward Provable Domain Generalization with Logarithmic Environments. (arXiv:2106.09913v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yining Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenfeld_E/0/1/0/all/0/1">Elan Rosenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09913">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization aims at performing well on unseen test environments
with data from a limited number of training environments. Despite a
proliferation of proposal algorithms for this task, assessing their
performance, both theoretically and empirically is still very challenging.
Moreover, recent approaches such as Invariant Risk Minimization (IRM) require a
prohibitively large number of training environments - linear in the dimension
of the spurious feature space $d_s$ - even on simple data models like the one
proposed by [Rosenfeld et al., 2021]. Under a variant of this model, we show
that both ERM and IRM cannot generalize with $o(d_s)$ environments. We then
present a new algorithm based on performing iterative feature matching that is
guaranteed with high probability to yield a predictor that generalizes after
seeing only $O(\log{d_s})$ environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Integrated Gradients: An Adaptive Path Method for Removing Noise. (arXiv:2106.09788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kapishnikov_A/0/1/0/all/0/1">Andrei Kapishnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopalan_S/0/1/0/all/0/1">Subhashini Venugopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Avci_B/0/1/0/all/0/1">Besim Avci</a>, <a href="http://arxiv.org/find/cs/1/au:+Wedin_B/0/1/0/all/0/1">Ben Wedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Terry_M/0/1/0/all/0/1">Michael Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolukbasi_T/0/1/0/all/0/1">Tolga Bolukbasi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09788">
                                    <div class="article-summary-box-inner">
                                        <span>Integrated Gradients (IG) is a commonly used feature attribution method for
deep neural networks. While IG has many desirable properties, the method often
produces spurious/noisy pixel attributions in regions that are not related to
the predicted class when applied to visual models. While this has been
previously noted, most existing solutions are aimed at addressing the symptoms
by explicitly reducing the noise in the resulting attributions. In this work,
we show that one of the causes of the problem is the accumulation of noise
along the IG path. To minimize the effect of this source of noise, we propose
adapting the attribution path itself -- conditioning the path not just on the
image but also on the model being explained. We introduce Adaptive Path Methods
(APMs) as a generalization of path methods, and Guided IG as a specific
instance of an APM. Empirically, Guided IG creates saliency maps better aligned
with the model&#x27;s prediction and the input image that is being explained. We
show through qualitative and quantitative experiments that Guided IG
outperforms other, related methods in nearly every experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autoencoder-based cleaning in probabilistic databases. (arXiv:2106.09764v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mauritz_R/0/1/0/all/0/1">R.R. Mauritz</a>, <a href="http://arxiv.org/find/cs/1/au:+Nijweide_F/0/1/0/all/0/1">F.P.J. Nijweide</a>, <a href="http://arxiv.org/find/cs/1/au:+Goseling_J/0/1/0/all/0/1">J. Goseling</a>, <a href="http://arxiv.org/find/cs/1/au:+Keulen_M/0/1/0/all/0/1">M. van Keulen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09764">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of data integration, data quality problems are often encountered
when extracting, combining, and merging data. The probabilistic data
integration approach represents information about such problems as
uncertainties in a probabilistic database. In this paper, we propose a
data-cleaning autoencoder capable of near-automatic data quality improvement.
It learns the structure and dependencies in the data to identify and correct
doubtful values. A theoretical framework is provided, and experiments show that
it can remove significant amounts of noise from categorical and numeric
probabilistic data. Our method does not require clean data. We do, however,
show that manually cleaning a small fraction of the data significantly improves
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GEM: A General Evaluation Benchmark for Multimodal Tasks. (arXiv:2106.09889v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Lin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_E/0/1/0/all/0/1">Edward Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Huaishao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1">Ming Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharti_T/0/1/0/all/0/1">Taroon Bharti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sacheti_A/0/1/0/all/0/1">Arun Sacheti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09889">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present GEM as a General Evaluation benchmark for
Multimodal tasks. Different from existing datasets such as GLUE, SuperGLUE,
XGLUE and XTREME that mainly focus on natural language tasks, GEM is a
large-scale vision-language benchmark, which consists of GEM-I for
image-language tasks and GEM-V for video-language tasks. Comparing with
existing multimodal datasets such as MSCOCO and Flicker30K for image-language
tasks, YouCook2 and MSR-VTT for video-language tasks, GEM is not only the
largest vision-language dataset covering image-language tasks and
video-language tasks at the same time, but also labeled in multiple languages.
We also provide two baseline models for this benchmark. We will release the
dataset, code and baseline models, aiming to advance the development of
multilingual multimodal research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Audio-Driven System For Real-Time Music Visualisation. (arXiv:2106.10134v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Graf_M/0/1/0/all/0/1">Max Graf</a>, <a href="http://arxiv.org/find/cs/1/au:+Opara_H/0/1/0/all/0/1">Harold Chijioke Opara</a>, <a href="http://arxiv.org/find/cs/1/au:+Barthet_M/0/1/0/all/0/1">Mathieu Barthet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10134">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-generated visualisations can accompany recorded or live music to
create novel audiovisual experiences for audiences. We present a system to
streamline the creation of audio-driven visualisations based on audio feature
extraction and mapping interfaces. Its architecture is based on three modular
software components: backend (audio plugin), frontend (3D game-like
environment), and middleware (visual mapping interface). We conducted a user
evaluation comprising two stages. Results from the first stage (34
participants) indicate that music visualisations generated with the system were
significantly better at complementing the music than a baseline visualisation.
Nine participants took part in the second stage involving interactive tasks.
Overall, the system yielded a Creativity Support Index above average (68.1) and
a System Usability Scale index (58.6) suggesting that ease of use can be
improved. Thematic analysis revealed that participants enjoyed the system&#x27;s
synchronicity and expressive capabilities, but found technical problems and
difficulties understanding the audio feature terminology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PixInWav: Residual Steganography for Hiding Pixels in Audio. (arXiv:2106.09814v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geleta_M/0/1/0/all/0/1">Margarita Geleta</a>, <a href="http://arxiv.org/find/cs/1/au:+Punti_C/0/1/0/all/0/1">Cristina Punti</a>, <a href="http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1">Kevin McGuinness</a>, <a href="http://arxiv.org/find/cs/1/au:+Pons_J/0/1/0/all/0/1">Jordi Pons</a>, <a href="http://arxiv.org/find/cs/1/au:+Canton_C/0/1/0/all/0/1">Cristian Canton</a>, <a href="http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1">Xavier Giro-i-Nieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09814">
                                    <div class="article-summary-box-inner">
                                        <span>Steganography comprises the mechanics of hiding data in a host media that may
be publicly available. While previous works focused on unimodal setups (e.g.,
hiding images in images, or hiding audio in audio), PixInWav targets the
multimodal case of hiding images in audio. To this end, we propose a novel
residual architecture operating on top of short-time discrete cosine transform
(STDCT) audio spectrograms. Among our results, we find that the residual audio
steganography setup we propose allows independent encoding of the hidden image
from the host audio without compromising quality. Accordingly, while previous
works require both host and hidden signals to hide a signal, PixInWav can
encode images offline -- which can be later hidden, in a residual fashion, into
any audio signal. Finally, we test our scheme in a lab setting to transmit
images over airwaves from a loudspeaker to a microphone verifying our
theoretical insights and obtaining promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-18">2021-06-18</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Volta at SemEval-2021 Task 9: Statement Verification and Evidence Finding with Tables using TAPAS and Transfer Learning. (arXiv:2106.00248v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gautam_D/0/1/0/all/0/1">Devansh Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Kshitij Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1">Manish Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00248">
                                    <div class="article-summary-box-inner">
                                        <span>Tables are widely used in various kinds of documents to present information
concisely. Understanding tables is a challenging problem that requires an
understanding of language and table structure, along with numerical and logical
reasoning. In this paper, we present our systems to solve Task 9 of
SemEval-2021: Statement Verification and Evidence Finding with Tables
(SEM-TAB-FACTS). The task consists of two subtasks: (A) Given a table and a
statement, predicting whether the table supports the statement and (B)
Predicting which cells in the table provide evidence for/against the statement.
We fine-tune TAPAS (a model which extends BERT&#x27;s architecture to capture
tabular structure) for both the subtasks as it has shown state-of-the-art
performance in various table understanding tasks. In subtask A, we evaluate how
transfer learning and standardizing tables to have a single header row improves
TAPAS&#x27; performance. In subtask B, we evaluate how different fine-tuning
strategies can improve TAPAS&#x27; performance. Our systems achieve an F1 score of
67.34 in subtask A three-way classification, 72.89 in subtask A two-way
classification, and 62.95 in subtask B.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Cross-Domain Text-to-SQL Semantic Parsing with Auxiliary Task. (arXiv:2106.09588v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1">Peng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1">Patrick Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiguo Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09588">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we focus on two crucial components in the cross-domain
text-to-SQL semantic parsing task: schema linking and value filling. To
encourage the model to learn better encoding ability, we propose a column
selection auxiliary task to empower the encoder with the relevance matching
capability by using explicit learning targets. Furthermore, we propose two
value filling methods to build the bridge from the existing zero-shot semantic
parsers to real-world applications, considering most of the existing parsers
ignore the values filling in the synthesized SQL. With experiments on Spider,
our proposed framework improves over the baselines on the execution accuracy
and exact set match accuracy when database contents are unavailable, and
detailed analysis sheds light on future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Sampling-Based Training Criteria for Neural Language Modeling. (arXiv:2104.10507v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yingbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Thulke_D/0/1/0/all/0/1">David Thulke</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerstenberger_A/0/1/0/all/0/1">Alexander Gerstenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1">Khoa Viet Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10507">
                                    <div class="article-summary-box-inner">
                                        <span>As the vocabulary size of modern word-based language models becomes ever
larger, many sampling-based training criteria are proposed and investigated.
The essence of these sampling methods is that the softmax-related traversal
over the entire vocabulary can be simplified, giving speedups compared to the
baseline. A problem we notice about the current landscape of such sampling
methods is the lack of a systematic comparison and some myths about preferring
one over another. In this work, we consider Monte Carlo sampling, importance
sampling, a novel method we call compensated partial summation, and noise
contrastive estimation. Linking back to the three traditional criteria, namely
mean squared error, binary cross-entropy, and cross-entropy, we derive the
theoretical solutions to the training problems. Contrary to some common belief,
we show that all these sampling methods can perform equally well, as long as we
correct for the intended class posterior probabilities. Experimental results in
language modeling and automatic speech recognition on Switchboard and
LibriSpeech support our claim, with all sampling-based methods showing similar
perplexities and word error rates while giving the expected speedups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scrambled Translation Problem: A Problem of Denoising UNMT. (arXiv:1911.01212v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1">Tamali Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1">Rudra Murthy V</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Pushpak Bhattacharyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01212">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we identify an interesting kind of error in the output of
Unsupervised Neural Machine Translation (UNMT) systems like
\textit{Undreamt}(footnote). We refer to this error type as \textit{Scrambled
Translation problem}. We observe that UNMT models which use \textit{word
shuffle} noise (as in case of Undreamt) can generate correct words, but fail to
stitch them together to form phrases. As a result, words of the translated
sentence look \textit{scrambled}, resulting in decreased BLEU. We hypothesise
that the reason behind \textit{scrambled translation problem} is &#x27;shuffling
noise&#x27; which is introduced in every input sentence as a denoising strategy. To
test our hypothesis, we experiment by retraining UNMT models with a simple
\textit{retraining} strategy. We stop the training of the Denoising UNMT model
after a pre-decided number of iterations and resume the training for the
remaining iterations -- which number is also pre-decided -- using original
sentence as input without adding any noise. Our proposed solution achieves
significant performance improvement UNMT models that train conventionally. We
demonstrate these performance gains on four language pairs, \textit{viz.},
English-French, English-German, English-Spanish, Hindi-Punjabi. Our qualitative
and quantitative analysis shows that the retraining strategy helps achieve
better alignment as observed by attention heatmap and better phrasal
translation, leading to statistically significant improvement in BLEU scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Detection of Alzheimer&#x27;s Disease from Speech and Text. (arXiv:2012.00096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1">Amish Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahoo_S/0/1/0/all/0/1">Sourav Sahoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Datar_A/0/1/0/all/0/1">Arnhav Datar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadiwala_J/0/1/0/all/0/1">Juned Kadiwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalu_H/0/1/0/all/0/1">Hrithwik Shalu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathew_J/0/1/0/all/0/1">Jimson Mathew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00096">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable detection of the prodromal stages of Alzheimer&#x27;s disease (AD)
remains difficult even today because, unlike other neurocognitive impairments,
there is no definitive diagnosis of AD in vivo. In this context, existing
research has shown that patients often develop language impairment even in mild
AD conditions. We propose a multimodal deep learning method that utilizes
speech and the corresponding transcript simultaneously to detect AD. For audio
signals, the proposed audio-based network, a convolutional neural network (CNN)
based model, predicts the diagnosis for multiple speech segments, which are
combined for the final prediction. Similarly, we use contextual embedding
extracted from BERT concatenated with a CNN-generated embedding for classifying
the transcript. The individual predictions of the two models are then combined
to make the final classification. We also perform experiments to analyze the
model performance when Automated Speech Recognition (ASR) system generated
transcripts are used instead of manual transcription in the text-based model.
The proposed method achieves 85.3% 10-fold cross-validation accuracy when
trained and evaluated on the Dementiabank Pitt corpus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Emotion Label Space Modelling for Affect Lexica. (arXiv:1911.08782v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bruyne_L/0/1/0/all/0/1">Luna De Bruyne</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanasova_P/0/1/0/all/0/1">Pepa Atanasova</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.08782">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion lexica are commonly used resources to combat data poverty in
automatic emotion detection. However, vocabulary coverage issues, differences
in construction method and discrepancies in emotion framework and
representation result in a heterogeneous landscape of emotion detection
resources, calling for a unified approach to utilising them. To combat this, we
present an extended emotion lexicon of 30,273 unique entries, which is a result
of merging eight existing emotion lexica by means of a multi-view variational
autoencoder (VAE). We showed that a VAE is a valid approach for combining
lexica with different label spaces into a joint emotion label space with a
chosen number of dimensions, and that these dimensions are still interpretable.
We tested the utility of the unified VAE lexicon by employing the lexicon
values as features in an emotion detection model. We found that the VAE lexicon
outperformed individual lexica, but contrary to our expectations, it did not
outperform a naive concatenation of lexica, although it did contribute to the
naive concatenation when added as an extra lexicon. Furthermore, using lexicon
information as additional features next to state-of-the-art language models
usually resulted in a better performance than when no lexicon information was
used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic Modeling and Progression of American Digital News Media During the Onset of the COVID-19 Pandemic. (arXiv:2106.09572v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiangpeng Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1">Michael C. Lucic</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazzai_H/0/1/0/all/0/1">Hakim Ghazzai</a>, <a href="http://arxiv.org/find/cs/1/au:+Massoud_Y/0/1/0/all/0/1">Yehia Massoud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09572">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, the world is in the midst of a severe global pandemic, which has
affected all aspects of people&#x27;s lives. As a result, there is a deluge of
COVID-related digital media articles published in the United States, due to the
disparate effects of the pandemic. This large volume of information is
difficult to consume by the audience in a reasonable amount of time. In this
paper, we develop a Natural Language Processing (NLP) pipeline that is capable
of automatically distilling various digital articles into manageable pieces of
information, while also modelling the progression topics discussed over time in
order to aid readers in rapidly gaining holistic perspectives on pressing
issues (i.e., the COVID-19 pandemic) from a diverse array of sources. We
achieve these goals by first collecting a large corpus of COVID-related
articles during the onset of the pandemic. After, we apply unsupervised and
semi-supervised learning procedures to summarize articles, then cluster them
based on their similarities using the community detection methods. Next, we
identify the topic of each cluster of articles using the BART algorithm.
Finally, we provide a detailed digital media analysis based on the NLP-pipeline
outputs and show how the conversation surrounding COVID-19 evolved over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study. (arXiv:2106.09700v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadkarni_R/0/1/0/all/0/1">Rahul Nadkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1">David Wadden</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1">Iz Beltagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09700">
                                    <div class="article-summary-box-inner">
                                        <span>Biomedical knowledge graphs (KGs) hold rich information on entities such as
diseases, drugs, and genes. Predicting missing links in these graphs can boost
many important applications, such as drug design and repurposing. Recent work
has shown that general-domain language models (LMs) can serve as &quot;soft&quot; KGs,
and that they can be fine-tuned for the task of KG completion. In this work, we
study scientific LMs for KG completion, exploring whether we can tap into their
latent knowledge to enhance biomedical link prediction. We evaluate several
domain-specific LMs, fine-tuning them on datasets centered on drugs and
diseases that we represent as KGs and enrich with textual entity descriptions.
We integrate the LM-based models with KG embedding models, using a router
method that learns to assign each input example to either type of model and
provides a substantial boost in performance. Finally, we demonstrate the
advantage of LM models in the inductive setting with novel scientific entities.
Our datasets and code are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classifying vaccine sentiment tweets by modelling domain-specific representation and commonsense knowledge into context-aware attentive GRU. (arXiv:2106.09589v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseem_U/0/1/0/all/0/1">Usman Naseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Khushi_M/0/1/0/all/0/1">Matloob Khushi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinman Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dunn_A/0/1/0/all/0/1">Adam G. Dunn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09589">
                                    <div class="article-summary-box-inner">
                                        <span>Vaccines are an important public health measure, but vaccine hesitancy and
refusal can create clusters of low vaccine coverage and reduce the
effectiveness of vaccination programs. Social media provides an opportunity to
estimate emerging risks to vaccine acceptance by including geographical
location and detailing vaccine-related concerns. Methods for classifying social
media posts, such as vaccine-related tweets, use language models (LMs) trained
on general domain text. However, challenges to measuring vaccine sentiment at
scale arise from the absence of tonal stress and gestural cues and may not
always have additional information about the user, e.g., past tweets or social
connections. Another challenge in LMs is the lack of commonsense knowledge that
are apparent in users metadata, i.e., emoticons, positive and negative words
etc. In this study, to classify vaccine sentiment tweets with limited
information, we present a novel end-to-end framework consisting of
interconnected components that use domain-specific LM trained on
vaccine-related tweets and models commonsense knowledge into a bidirectional
gated recurrent network (CK-BiGRU) with context-aware attention. We further
leverage syntactical, user metadata and sentiment information to capture the
sentiment of a tweet. We experimented using two popular vaccine-related Twitter
datasets and demonstrate that our proposed approach outperforms
state-of-the-art models in identifying pro-vaccine, anti-vaccine and neutral
tweets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Worlds in Text. (arXiv:2106.09578v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1">Prithviraj Ammanabrolu</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1">Mark O. Riedl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09578">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a dataset that enables the creation of learning agents that can
build knowledge graph-based world models of interactive narratives. Interactive
narratives -- or text-adventure games -- are partially observable environments
structured as long puzzles or quests in which an agent perceives and interacts
with the world purely through textual natural language. Each individual game
typically contains hundreds of locations, characters, and objects -- each with
their own unique descriptions -- providing an opportunity to study the problem
of giving language-based agents the structured memory necessary to operate in
such worlds. Our dataset provides 24198 mappings between rich natural language
observations and: (1) knowledge graphs that reflect the world state in the form
of a map; (2) natural language actions that are guaranteed to cause a change in
that particular world state. The training data is collected across 27 games in
multiple genres and contains a further 7836 heldout instances over 9 additional
games in the test set. We further provide baseline models using rules-based,
question-answering, and sequence learning approaches in addition to an analysis
of the data and corresponding learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Element Intervention for Open Relation Extraction. (arXiv:2106.09558v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fangchao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Lingyong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09558">
                                    <div class="article-summary-box-inner">
                                        <span>Open relation extraction aims to cluster relation instances referring to the
same underlying relation, which is a critical step for general relation
extraction. Current OpenRE models are commonly trained on the datasets
generated from distant supervision, which often results in instability and
makes the model easily collapsed. In this paper, we revisit the procedure of
OpenRE from a causal view. By formulating OpenRE using a structural causal
model, we identify that the above-mentioned problems stem from the spurious
correlations from entities and context to the relation type. To address this
issue, we conduct \emph{Element Intervention}, which intervenes on the context
and entities respectively to obtain the underlying causal effects of them. We
also provide two specific implementations of the interventions based on entity
ranking and context contrasting. Experimental results on unsupervised relation
extraction datasets show that our methods outperform previous state-of-the-art
methods and are robust across different datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidence-based Factual Error Correction. (arXiv:2106.01072v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01072">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the task of factual error correction: performing edits
to a claim so that the generated rewrite is better supported by evidence. This
extends the well-studied task of fact verification by providing a mechanism to
correct written texts that are refuted or only partially supported by evidence.
We demonstrate that it is feasible to train factual error correction systems
from existing fact checking datasets which only contain labeled claims
accompanied by evidence, but not the correction. We achieve this by employing a
two-stage distant supervision approach that incorporates evidence into masked
claims when generating corrections. Our approach, based on the T5 transformer
and using retrieved evidence, achieved better results than existing work which
used a pointer copy network and gold evidence, producing accurate factual error
corrections for 5x more instances in human evaluation and a .125 increase in
SARI score. The evaluation is conducted on a dataset of 65,000 instances based
on a recent fact verification shared task and we release it to enable further
work on the task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pushing the Limits of Non-Autoregressive Speech Recognition. (arXiv:2104.03416v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ng_E/0/1/0/all/0/1">Edwin G. Ng</a>, <a href="http://arxiv.org/find/eess/1/au:+Chiu_C/0/1/0/all/0/1">Chung-Cheng Chiu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03416">
                                    <div class="article-summary-box-inner">
                                        <span>We combine recent advancements in end-to-end speech recognition to
non-autoregressive automatic speech recognition. We push the limits of
non-autoregressive state-of-the-art results for multiple datasets: LibriSpeech,
Fisher+Switchboard and Wall Street Journal. Key to our recipe, we leverage CTC
on giant Conformer neural network architectures with SpecAugment and wav2vec2
pre-training. We achieve 1.8%/3.6% WER on LibriSpeech test/test-other sets,
5.1%/9.8% WER on Switchboard, and 3.4% on the Wall Street Journal, all without
a language model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-head or Single-head? An Empirical Comparison for Transformer Training. (arXiv:2106.09650v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09650">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-head attention plays a crucial role in the recent success of
Transformer models, which leads to consistent performance improvements over
conventional attention in various applications. The popular belief is that this
effectiveness stems from the ability of jointly attending multiple positions.
In this paper, we first demonstrate that jointly attending multiple positions
is not a unique feature of multi-head attention, as multi-layer single-head
attention also attends multiple positions and is more effective. Then, we
suggest the main advantage of the multi-head attention is the training
stability, since it has less number of layers than the single-head attention,
when attending the same number of positions. For example, 24-layer 16-head
Transformer (BERT-large) and 384-layer single-head Transformer has the same
total attention head number and roughly the same model size, while the
multi-head one is significantly shallower. Meanwhile, we show that, with recent
advances in deep learning, we can successfully stabilize the training of the
384-layer Transformer. As the training difficulty is no longer a bottleneck,
substantially deeper single-head Transformer achieves consistent performance
improvements without tuning hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGGGEN: Ordering and Aggregating while Generating. (arXiv:2106.05580v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinnuo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1">Ond&#x159;ej Du&#x161;ek</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1">Verena Rieser</a>, <a href="http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1">Ioannis Konstas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05580">
                                    <div class="article-summary-box-inner">
                                        <span>We present AGGGEN (pronounced &#x27;again&#x27;), a data-to-text model which
re-introduces two explicit sentence planning stages into neural data-to-text
systems: input ordering and input aggregation. In contrast to previous work
using sentence planning, our model is still end-to-end: AGGGEN performs
sentence planning at the same time as generating text by learning latent
alignments (via semantic facts) between input representation and target text.
Experiments on the WebNLG and E2E challenge data show that by using fact-based
alignments our approach is more interpretable, expressive, robust to noise, and
easier to control, while retaining the advantages of end-to-end systems in
terms of fluency. Our code is available at https://github.com/XinnuoXu/AggGen.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DESCGEN: A Distantly Supervised Dataset for Generating Abstractive Entity Descriptions. (arXiv:2106.05365v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Weijia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1">Mandar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05365">
                                    <div class="article-summary-box-inner">
                                        <span>Short textual descriptions of entities provide summaries of their key
attributes and have been shown to be useful sources of background knowledge for
tasks such as entity linking and question answering. However, generating entity
descriptions, especially for new and long-tail entities, can be challenging
since relevant information is often scattered across multiple sources with
varied content and style. We introduce DESCGEN: given mentions spread over
multiple documents, the goal is to generate an entity summary description.
DESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each
paired with nine evidence documents on average. The documents were collected
using a combination of entity linking and hyperlinks to the Wikipedia and
Fandom entity pages, which together provide high-quality distant supervision.
The resulting summaries are more abstractive than those found in existing
datasets and provide a better proxy for the challenge of describing new and
emerging entities. We also propose a two-stage extract-then-generate baseline
and show that there exists a large gap (19.9% in ROUGE-L) between
state-of-the-art models and human performance, suggesting that the data will
support significant future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DravidianCodeMix: Sentiment Analysis and Offensive Language Identification Dataset for Dravidian Languages in Code-Mixed Text. (arXiv:2106.09460v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1">Ruba Priyadharshini</a>, <a href="http://arxiv.org/find/cs/1/au:+Muralidaran_V/0/1/0/all/0/1">Vigneshwaran Muralidaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Jose_N/0/1/0/all/0/1">Navya Jose</a>, <a href="http://arxiv.org/find/cs/1/au:+Suryawanshi_S/0/1/0/all/0/1">Shardul Suryawanshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sherly_E/0/1/0/all/0/1">Elizabeth Sherly</a>, <a href="http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1">John P. McCrae</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09460">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the development of a multilingual, manually annotated
dataset for three under-resourced Dravidian languages generated from social
media comments. The dataset was annotated for sentiment analysis and offensive
language identification for a total of more than 60,000 YouTube comments. The
dataset consists of around 44,000 comments in Tamil-English, around 7,000
comments in Kannada-English, and around 20,000 comments in Malayalam-English.
The data was manually annotated by volunteer annotators and has a high
inter-annotator agreement in Krippendorff&#x27;s alpha. The dataset contains all
types of code-mixing phenomena since it comprises user-generated content from a
multilingual country. We also present baseline experiments to establish
benchmarks on the dataset using machine learning methods. The dataset is
available on Github
(https://github.com/bharathichezhiyan/DravidianCodeMix-Dataset) and Zenodo
(https://zenodo.org/record/4750858\#.YJtw0SYo\_0M).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LoRA: Low-Rank Adaptation of Large Language Models. (arXiv:2106.09685v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Edward J. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallis_P/0/1/0/all/0/1">Phillip Wallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shean Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09685">
                                    <div class="article-summary-box-inner">
                                        <span>The dominant paradigm of natural language processing consists of large-scale
pre-training on general domain data and adaptation to particular tasks or
domains. As we pre-train larger models, conventional fine-tuning, which
retrains all model parameters, becomes less feasible. Using GPT-3 175B as an
example, deploying many independent instances of fine-tuned models, each with
175B parameters, is extremely expensive. We propose Low-Rank Adaptation, or
LoRA, which freezes the pre-trained model weights and injects trainable rank
decomposition matrices into each layer of the Transformer architecture, greatly
reducing the number of trainable parameters for downstream tasks. For GPT-3,
LoRA can reduce the number of trainable parameters by 10,000 times and the
computation hardware requirement by 3 times compared to full fine-tuning. LoRA
performs on-par or better than fine-tuning in model quality on both GPT-3 and
GPT-2, despite having fewer trainable parameters, a higher training throughput,
and no additional inference latency. We also provide an empirical investigation
into rank-deficiency in language model adaptations, which sheds light on the
efficacy of LoRA. We release our implementation in GPT-2 at
https://github.com/microsoft/LoRA .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">STAN: A stuttering therapy analysis helper. (arXiv:2106.09545v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bayerl_S/0/1/0/all/0/1">Sebastian P. Bayerl</a>, <a href="http://arxiv.org/find/eess/1/au:+Wenninger_M/0/1/0/all/0/1">Marc Wenninger</a>, <a href="http://arxiv.org/find/eess/1/au:+Schmidt_J/0/1/0/all/0/1">Jochen Schmidt</a>, <a href="http://arxiv.org/find/eess/1/au:+Gudenberg_A/0/1/0/all/0/1">Alexander Wolff von Gudenberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Riedhammer_K/0/1/0/all/0/1">Korbinian Riedhammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09545">
                                    <div class="article-summary-box-inner">
                                        <span>Stuttering is a complex speech disorder identified by repeti-tions,
prolongations of sounds, syllables or words and blockswhile speaking. Specific
stuttering behaviour differs strongly,thus needing personalized therapy.
Therapy sessions requirea high level of concentration by the therapist. We
introduceSTAN, a system to aid speech therapists in stuttering therapysessions.
Such an automated feedback system can lower thecognitive load on the therapist
and thereby enable a more con-sistent therapy as well as allowing analysis of
stuttering overthe span of multiple therapy sessions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-supervised Method for Entity Alignment. (arXiv:2106.09395v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1">Haoyun Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinghao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09395">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment, aiming to identify equivalent entities across different
knowledge graphs (KGs), is a fundamental problem for constructing large-scale
KGs. Over the course of its development, supervision has been considered
necessary for accurate alignments. Inspired by the recent progress of
self-supervised learning, we explore the extent to which we can get rid of
supervision for entity alignment. Existing supervised methods for this task
focus on pulling each pair of positive (labeled) entities close to each other.
However, our analysis suggests that the learning of entity alignment can
actually benefit more from pushing sampled (unlabeled) negatives far away than
pulling positive aligned pairs close. We present SelfKG by leveraging this
discovery to design a contrastive learning strategy across two KGs. Extensive
experiments on benchmark datasets demonstrate that SelfKG without supervision
can match or achieve comparable results with state-of-the-art supervised
baselines. The performance of SelfKG demonstrates self-supervised learning
offers great potential for entity alignment in KGs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural semi-Markov CRF for Monolingual Word Alignment. (arXiv:2106.02569v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1">Wuwei Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02569">
                                    <div class="article-summary-box-inner">
                                        <span>Monolingual word alignment is important for studying fine-grained editing
operations (i.e., deletion, addition, and substitution) in text-to-text
generation tasks, such as paraphrase generation, text simplification,
neutralizing biased language, etc. In this paper, we present a novel neural
semi-Markov CRF alignment model, which unifies word and phrase alignments
through variable-length spans. We also create a new benchmark with human
annotations that cover four different text genres to evaluate monolingual word
alignment models in more realistic settings. Experimental results show that our
proposed model outperforms all previous approaches for monolingual word
alignment as well as a competitive QA-based baseline, which was previously only
applied to bilingual data. Our model demonstrates good generalizability to
three out-of-domain datasets and shows great utility in two downstream
applications: automatic text simplification and sentence pair classification
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetric Regularization based BERT for Pair-wise Semantic Reasoning. (arXiv:1909.03405v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weidi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xingyi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kunlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1">Bin Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1">Luo Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Taifeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03405">
                                    <div class="article-summary-box-inner">
                                        <span>The ability of semantic reasoning over the sentence pair is essential for
many natural language understanding tasks, e.g., natural language inference and
machine reading comprehension. A recent significant improvement in these tasks
comes from BERT. As reported, the next sentence prediction (NSP) in BERT, which
learns the contextual relationship between two sentences, is of great
significance for downstream problems with sentence-pair input. Despite the
effectiveness of NSP, we suggest that NSP still lacks the essential signal to
distinguish between entailment and shallow correlation. To remedy this, we
propose to augment the NSP task to a 3-class categorization task, which
includes a category for previous sentence prediction (PSP). The involvement of
PSP encourages the model to focus on the informative semantics to determine the
sentence order, thereby improves the ability of semantic understanding. This
simple modification yields remarkable improvement against vanilla BERT. To
further incorporate the document-level information, the scope of NSP and PSP is
expanded into a broader range, i.e., NSP and PSP also include close but
nonsuccessive sentences, the noise of which is mitigated by the label-smoothing
technique. Both qualitative and quantitative experimental results demonstrate
the effectiveness of the proposed method. Our method consistently improves the
performance on the NLI and MRC benchmarks, including the challenging HANS
dataset \cite{hans}, suggesting that the document-level task is still promising
for the pre-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-FACT: A New Benchmark Dataset for Multilingual Fact Checking. (arXiv:2106.09248v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ashim Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1">Vivek Srikumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09248">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce X-FACT: the largest publicly available
multilingual dataset for factual verification of naturally existing real-world
claims. The dataset contains short statements in 25 languages and is labeled
for veracity by expert fact-checkers. The dataset includes a multilingual
evaluation benchmark that measures both out-of-domain generalization, and
zero-shot capabilities of the multilingual models. Using state-of-the-art
multilingual transformer-based models, we develop several automated
fact-checking models that, along with textual claims, make use of additional
metadata and evidence from news stories retrieved using a search engine.
Empirically, our best model attains an F-score of around 40%, suggesting that
our dataset is a challenging benchmark for evaluation of multilingual
fact-checking models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Knowledge Graph-based World Models of Textual Environments. (arXiv:2106.09608v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1">Prithviraj Ammanabrolu</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1">Mark O. Riedl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09608">
                                    <div class="article-summary-box-inner">
                                        <span>World models improve a learning agent&#x27;s ability to efficiently operate in
interactive and situated environments. This work focuses on the task of
building world models of text-based game environments. Text-based games, or
interactive narratives, are reinforcement learning environments in which agents
perceive and interact with the world using textual natural language. These
environments contain long, multi-step puzzles or quests woven through a world
that is filled with hundreds of characters, locations, and objects. Our world
model learns to simultaneously: (1) predict changes in the world caused by an
agent&#x27;s actions when representing the world as a knowledge graph; and (2)
generate the set of contextually relevant natural language actions required to
operate in the world. We frame this task as a Set of Sequences generation
problem by exploiting the inherent structure of knowledge graphs and actions
and introduce both a transformer-based multi-task architecture and a loss
function to train it. A zero-shot ablation study on never-before-seen textual
worlds shows that our methodology significantly outperforms existing textual
world modeling techniques as well as the importance of each of our
contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can I Be of Further Assistance? Using Unstructured Knowledge Access to Improve Task-oriented Conversational Modeling. (arXiv:2106.09174v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Di Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seokhwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1">Dilek Hakkani-Tur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09174">
                                    <div class="article-summary-box-inner">
                                        <span>Most prior work on task-oriented dialogue systems are restricted to limited
coverage of domain APIs. However, users oftentimes have requests that are out
of the scope of these APIs. This work focuses on responding to these
beyond-API-coverage user turns by incorporating external, unstructured
knowledge sources. Our approach works in a pipelined manner with
knowledge-seeking turn detection, knowledge selection, and response generation
in sequence. We introduce novel data augmentation methods for the first two
steps and demonstrate that the use of information extracted from dialogue
context improves the knowledge selection and end-to-end performances. Through
experiments, we achieve state-of-the-art performance for both automatic and
human evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the
effectiveness of our contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Data Usage via Differentiable Rewards. (arXiv:1911.10088v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1">Paul Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1">Antonios Anastasopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Carbonell_J/0/1/0/all/0/1">Jaime Carbonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.10088">
                                    <div class="article-summary-box-inner">
                                        <span>To acquire a new skill, humans learn better and faster if a tutor, based on
their current knowledge level, informs them of how much attention they should
pay to particular content or practice problems. Similarly, a machine learning
model could potentially be trained better with a scorer that &quot;adapts&quot; to its
current learning state and estimates the importance of each training data
instance. Training such an adaptive scorer efficiently is a challenging
problem; in order to precisely quantify the effect of a data instance at a
given time during the training, it is typically necessary to first complete the
entire training process. To efficiently optimize data usage, we propose a
reinforcement learning approach called Differentiable Data Selection (DDS). In
DDS, we formulate a scorer network as a learnable function of the training
data, which can be efficiently updated along with the main model being trained.
Specifically, DDS updates the scorer with an intuitive reward signal: it should
up-weigh the data that has a similar gradient with a dev set upon which we
would finally like to perform well. Without significant computing overhead, DDS
delivers strong and consistent improvements over several strong baselines on
two very different tasks of machine translation and image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Approach for Normalizing E-commerce Text Attributes (SANTA). (arXiv:2106.09493v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1">Ravi Shankar Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_K/0/1/0/all/0/1">Kartik Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasiwasia_N/0/1/0/all/0/1">Nikhil Rasiwasia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09493">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present SANTA, a scalable framework to automatically
normalize E-commerce attribute values (e.g. &quot;Win 10 Pro&quot;) to a fixed set of
pre-defined canonical values (e.g. &quot;Windows 10&quot;). Earlier works on attribute
normalization focused on fuzzy string matching (also referred as syntactic
matching in this paper). In this work, we first perform an extensive study of
nine syntactic matching algorithms and establish that &#x27;cosine&#x27; similarity leads
to best results, showing 2.7% improvement over commonly used Jaccard index.
Next, we argue that string similarity alone is not sufficient for attribute
normalization as many surface forms require going beyond syntactic matching
(e.g. &quot;720p&quot; and &quot;HD&quot; are synonyms). While semantic techniques like
unsupervised embeddings (e.g. word2vec/fastText) have shown good results in
word similarity tasks, we observed that they perform poorly to distinguish
between close canonical forms, as these close forms often occur in similar
contexts. We propose to learn token embeddings using a twin network with
triplet loss. We propose an embedding learning task leveraging raw attribute
values and product titles to learn these embeddings in a self-supervised
fashion. We show that providing supervision using our proposed task improves
over both syntactic and unsupervised embeddings based techniques for attribute
normalization. Experiments on a real-world attribute normalization dataset of
50 attributes show that the embeddings trained using our proposed approach
obtain 2.3% improvement over best string matching and 19.3% improvement over
best unsupervised embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Biomedical Interpretable Entity Representations. (arXiv:2106.09502v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garcia_Olano_D/0/1/0/all/0/1">Diego Garcia-Olano</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1">Yasumasa Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1">Ioana Baldini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_J/0/1/0/all/0/1">Joydeep Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1">Kush R. Varshney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09502">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models induce dense entity representations that offer
strong performance on entity-centric NLP tasks, but such representations are
not immediately interpretable. This can be a barrier to model uptake in
important domains such as biomedicine. There has been recent work on general
interpretable representation learning (Onoe and Durrett, 2020), but these
domain-agnostic representations do not readily transfer to the important domain
of biomedicine. In this paper, we create a new entity type system and training
set from a large corpus of biomedical texts by mapping entities to concepts in
a medical ontology, and from these to Wikipedia pages whose categories are our
types. From this mapping we derive Biomedical Interpretable Entity
Representations(BIERs), in which dimensions correspond to fine-grained entity
types, and values are predicted probabilities that a given entity is of the
corresponding type. We propose a novel method that exploits BIER&#x27;s final sparse
and intermediate dense representations to facilitate model and entity type
debugging. We show that BIERs achieve strong performance in biomedical tasks
including named entity disambiguation and entity label classification, and we
provide error analysis to highlight the utility of their interpretability,
particularly in low-supervision settings. Finally, we provide our induced 68K
biomedical type system, the corresponding 37 million triples of derived data
used to train BIER models and our best performing model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DocNLI: A Large-scale Dataset for Document-level Natural Language Inference. (arXiv:2106.09449v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1">Wenpeng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1">Dragomir Radev</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09449">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language inference (NLI) is formulated as a unified framework for
solving various NLP problems such as relation extraction, question answering,
summarization, etc. It has been studied intensively in the past few years
thanks to the availability of large-scale labeled datasets. However, most
existing studies focus on merely sentence-level inference, which limits the
scope of NLI&#x27;s application in downstream NLP problems. This work presents
DocNLI -- a newly-constructed large-scale dataset for document-level NLI.
DocNLI is transformed from a broad range of NLP problems and covers multiple
genres of text. The premises always stay in the document granularity, whereas
the hypotheses vary in length from single sentences to passages with hundreds
of words. Additionally, DocNLI has pretty limited artifacts which unfortunately
widely exist in some popular sentence-level NLI datasets. Our experiments
demonstrate that, even without fine-tuning, a model pretrained on DocNLI shows
promising performance on popular sentence-level benchmarks, and generalizes
well to out-of-domain NLP tasks that rely on inference at document granularity.
Task-specific fine-tuning can bring further improvements. Data, code, and
pretrained models can be found at https://github.com/salesforce/DocNLI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">De-biasing Distantly Supervised Named Entity Recognition via Causal Intervention. (arXiv:2106.09233v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenkai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09233">
                                    <div class="article-summary-box-inner">
                                        <span>Distant supervision tackles the data bottleneck in NER by automatically
generating training instances via dictionary matching. Unfortunately, the
learning of DS-NER is severely dictionary-biased, which suffers from spurious
correlations and therefore undermines the effectiveness and the robustness of
the learned models. In this paper, we fundamentally explain the dictionary bias
via a Structural Causal Model (SCM), categorize the bias into intra-dictionary
and inter-dictionary biases, and identify their causes. Based on the SCM, we
learn de-biased DS-NER via causal interventions. For intra-dictionary bias, we
conduct backdoor adjustment to remove the spurious correlations introduced by
the dictionary confounder. For inter-dictionary bias, we propose a causal
invariance regularizer which will make DS-NER models more robust to the
perturbation of dictionaries. Experiments on four datasets and three DS-NER
models show that our method can significantly improve the performance of
DS-NER.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Laws for Acoustic Models. (arXiv:2106.09488v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Droppo_J/0/1/0/all/0/1">Jasha Droppo</a>, <a href="http://arxiv.org/find/eess/1/au:+Elibol_O/0/1/0/all/0/1">Oguz Elibol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09488">
                                    <div class="article-summary-box-inner">
                                        <span>There is a recent trend in machine learning to increase model quality by
growing models to sizes previously thought to be unreasonable. Recent work has
shown that autoregressive generative models with cross-entropy objective
functions exhibit smooth power-law relationships, or scaling laws, that predict
model quality from model size, training set size, and the available compute
budget. These scaling laws allow one to choose nearly optimal hyper-parameters
given constraints on available training data, model parameter count, or
training computation budget. In this paper, we demonstrate that acoustic models
trained with an auto-predictive coding loss behave as if they are subject to
similar scaling laws. We extend previous work to jointly predict loss due to
model size, to training set size, and to the inherent &quot;irreducible loss&quot; of the
task. We find that the scaling laws accurately match model performance over two
orders of magnitude in both model size and training set size, and make
predictions about the limits of model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">pysentimiento: A Python Toolkit for Sentiment Analysis and SocialNLP tasks. (arXiv:2106.09462v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1">Juan Manuel P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Giudici_J/0/1/0/all/0/1">Juan Carlos Giudici</a>, <a href="http://arxiv.org/find/cs/1/au:+Luque_F/0/1/0/all/0/1">Franco Luque</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09462">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting opinions from texts has gathered a lot of interest in the last
years, as we are experiencing an unprecedented volume of user-generated content
in social networks and other places. A problem that social researchers find in
using opinion mining tools is that they are usually behind commercial APIs and
unavailable for other languages than English. To address these issues, we
present pysentimiento, a multilingual Python toolkit for Sentiment Analysis and
other Social NLP tasks. This open-source library brings state-of-the-art models
for Spanish and English in a black-box fashion, allowing researchers to easily
access these techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition. (arXiv:2104.01989v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pelecanos_J/0/1/0/all/0/1">Jason Pelecanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_I/0/1/0/all/0/1">Ignacio Lopez Moreno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01989">
                                    <div class="article-summary-box-inner">
                                        <span>Many neural network speaker recognition systems model each speaker using a
fixed-dimensional embedding vector. These embeddings are generally compared
using either linear or 2nd-order scoring and, until recently, do not handle
utterance-specific uncertainty. In this work we propose scoring these
representations in a way that can capture uncertainty, enroll/test asymmetry
and additional non-linear information. This is achieved by incorporating a
2nd-stage neural network (known as a decision network) as part of an end-to-end
training regimen. In particular, we propose the concept of decision residual
networks which involves the use of a compact decision network to leverage
cosine scores and to model the residual signal that&#x27;s needed. Additionally, we
present a modification to the generalized end-to-end softmax loss function to
target the separation of same/different speaker scores. We observed significant
performance gains for the two techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Listen with Intent: Improving Speech Recognition with Audio-to-Intent Front-End. (arXiv:2105.07071v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ray_S/0/1/0/all/0/1">Swayambhu Nath Ray</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_M/0/1/0/all/0/1">Minhua Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Raju_A/0/1/0/all/0/1">Anirudh Raju</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghahremani_P/0/1/0/all/0/1">Pegah Ghahremani</a>, <a href="http://arxiv.org/find/eess/1/au:+Bilgi_R/0/1/0/all/0/1">Raghavendra Bilgi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rao_M/0/1/0/all/0/1">Milind Rao</a>, <a href="http://arxiv.org/find/eess/1/au:+Arsikere_H/0/1/0/all/0/1">Harish Arsikere</a>, <a href="http://arxiv.org/find/eess/1/au:+Rastrow_A/0/1/0/all/0/1">Ariya Rastrow</a>, <a href="http://arxiv.org/find/eess/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a>, <a href="http://arxiv.org/find/eess/1/au:+Droppo_J/0/1/0/all/0/1">Jasha Droppo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07071">
                                    <div class="article-summary-box-inner">
                                        <span>Comprehending the overall intent of an utterance helps a listener recognize
the individual words spoken. Inspired by this fact, we perform a novel study of
the impact of explicitly incorporating intent representations as additional
information to improve a recurrent neural network-transducer (RNN-T) based
automatic speech recognition (ASR) system. An audio-to-intent (A2I) model
encodes the intent of the utterance in the form of embeddings or posteriors,
and these are used as auxiliary inputs for RNN-T training and inference.
Experimenting with a 50k-hour far-field English speech corpus, this study shows
that when running the system in non-streaming mode, where intent representation
is extracted from the entire utterance and then used to bias streaming RNN-T
search from the start, it provides a 5.56% relative word error rate reduction
(WERR). On the other hand, a streaming system using per-frame intent posteriors
as extra inputs for the RNN-T ASR system yields a 3.33% relative WERR. A
further detailed analysis of the streaming system indicates that our proposed
method brings especially good gain on media-playing related intents (e.g. 9.12%
relative WERR on PlayMusicIntent).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Methods to Improve Language Model Integration for Attention-based Encoder-Decoder ASR Models. (arXiv:2104.05544v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1">Mohammad Zeineldeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Glushko_A/0/1/0/all/0/1">Aleksandr Glushko</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_W/0/1/0/all/0/1">Wilfried Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1">Albert Zeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05544">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based encoder-decoder (AED) models learn an implicit internal
language model (ILM) from the training transcriptions. The integration with an
external LM trained on much more unpaired text usually leads to better
performance. A Bayesian interpretation as in the hybrid autoregressive
transducer (HAT) suggests dividing by the prior of the discriminative acoustic
model, which corresponds to this implicit LM, similarly as in the hybrid hidden
Markov model approach. The implicit LM cannot be calculated efficiently in
general and it is yet unclear what are the best methods to estimate it. In this
work, we compare different approaches from the literature and propose several
novel methods to estimate the ILM directly from the AED model. Our proposed
methods outperform all previous approaches. We also investigate other methods
to suppress the ILM mainly by decreasing the capacity of the AED model,
limiting the label context, and also by training the AED model together with a
pre-existing LM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing past words: Testing the cross-modal capabilities of pretrained V&amp;L models on counting tasks. (arXiv:2012.12352v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1">Letitia Parcalabescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatt_A/0/1/0/all/0/1">Albert Gatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Calixto_I/0/1/0/all/0/1">Iacer Calixto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12352">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the reasoning ability of pretrained vision and language (V&amp;L)
models in two tasks that require multimodal integration: (1) discriminating a
correct image-sentence pair from an incorrect one, and (2) counting entities in
an image. We evaluate three pretrained V&amp;L models on these tasks: ViLBERT,
ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results
show that models solve task (1) very well, as expected, since all models are
pretrained on task (1). However, none of the pretrained V&amp;L models is able to
adequately solve task (2), our counting probe, and they cannot generalise to
out-of-distribution quantities. We propose a number of explanations for these
findings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of
catastrophic forgetting on task (1). Concerning our results on the counting
probe, we find evidence that all models are impacted by dataset bias, and also
fail to individuate entities in the visual input. While a selling point of
pretrained V&amp;L models is their ability to solve complex tasks, our findings
suggest that understanding their reasoning and grounding capabilities requires
more targeted investigations on specific phenomena.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model. (arXiv:2106.09234v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenkai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huidan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhicheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_N/0/1/0/all/0/1">Nicholas Jing Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09234">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising is the essential step for distant supervision based named entity
recognition. Previous denoising methods are mostly based on instance-level
confidence statistics, which ignore the variety of the underlying noise
distribution on different datasets and entity types. This makes them difficult
to be adapted to high noise rate settings. In this paper, we propose
Hypergeometric Learning (HGL), a denoising algorithm for distantly supervised
NER that takes both noise distribution and instance-level confidence into
consideration. Specifically, during neural network training, we naturally model
the noise samples in each batch following a hypergeometric distribution
parameterized by the noise-rate. Then each instance in the batch is regarded as
either correct or noisy one according to its label confidence derived from
previous training step, as well as the noise distribution in this sampled
batch. Experiments show that HGL can effectively denoise the weakly-labeled
data retrieved from distant supervision, and therefore results in significant
improvements on the trained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layer Pruning on Demand with Intermediate CTC. (arXiv:2106.09216v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1">Jaesong Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Kang_J/0/1/0/all/0/1">Jingu Kang</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09216">
                                    <div class="article-summary-box-inner">
                                        <span>Deploying an end-to-end automatic speech recognition (ASR) model on
mobile/embedded devices is a challenging task, since the device computational
power and energy consumption requirements are dynamically changed in practice.
To overcome the issue, we present a training and pruning method for ASR based
on the connectionist temporal classification (CTC) which allows reduction of
model depth at run-time without any extra fine-tuning. To achieve the goal, we
adopt two regularization methods, intermediate CTC and stochastic depth, to
train a model whose performance does not degrade much after pruning. We present
an in-depth analysis of layer behaviors using singular vector canonical
correlation analysis (SVCCA), and efficient strategies for finding layers which
are safe to prune. Using the proposed method, we show that a Transformer-CTC
model can be pruned in various depth on demand, improving real-time factor from
0.005 to 0.002 on GPU, while each pruned sub-model maintains the accuracy of
individually trained model of the same depth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging Navigation. (arXiv:2010.10811v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Puhai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heyan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xianling Mao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10811">
                                    <div class="article-summary-box-inner">
                                        <span>Scalability for handling unknown slot values is a important problem in
dialogue state tracking (DST). As far as we know, previous scalable DST
approaches generally rely on either the candidate generation from slot tagging
output or the span extraction in dialogue context. However, the candidate
generation based DST often suffers from error propagation due to its pipelined
two-stage process; meanwhile span extraction based DST has the risk of
generating invalid spans in the lack of semantic constraints between start and
end position pointers. To tackle the above drawbacks, in this paper, we propose
a novel scalable dialogue state tracking method based on slot tagging
navigation, which implements an end-to-end single-step pointer to locate and
extract slot value quickly and accurately by the joint learning of slot tagging
and slot value position prediction in the dialogue context, especially for
unknown slot values. Extensive experiments over several benchmark datasets show
that the proposed model performs better than state-of-the-art baselines
greatly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Large Scale Molecular Language Representations Capture Important Structural Information?. (arXiv:2106.09553v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1">Jerret Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Belgodere_B/0/1/0/all/0/1">Brian Belgodere</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenthamarakshan_V/0/1/0/all/0/1">Vijil Chenthamarakshan</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1">Inkit Padhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09553">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting chemical properties from the structure of a molecule is of great
importance in many applications including drug discovery and material design.
Machine learning based molecular property prediction holds the promise of
enabling accurate predictions at much less complexity, when compared to, for
example Density Functional Theory (DFT) calculations. Features extracted from
molecular graphs, using graph neural nets in a supervised manner, have emerged
as strong baselines for such tasks. However, the vast chemical space together
with the limited availability of labels makes supervised learning challenging,
calling for learning a general-purpose molecular representation. Recently,
pre-trained transformer-based language models (PTLMs) on large unlabeled corpus
have produced state-of-the-art results in many downstream natural language
processing tasks. Inspired by this development, here we present molecular
embeddings obtained by training an efficient transformer encoder model,
referred to as MoLFormer. This model was employed with a linear attention
mechanism and highly paralleized training on 1D SMILES sequences of 1.1 billion
unlabeled molecules from the PubChem and ZINC datasets. Experiments show that
the learned molecular representation performs competitively, when compared to
existing graph-based and fingerprint-based supervised learning baselines, on
the challenging tasks of predicting properties of QM8 and QM9 molecules.
Further task-specific fine-tuning of the MoLFormerr representation improves
performance on several of those property prediction benchmarks. These results
provide encouraging evidence that large-scale molecular language models can
capture sufficient structural information to be able to accurately predict
quantum chemical properties and beyond.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASR Adaptation for E-commerce Chatbots using Cross-Utterance Context and Multi-Task Language Modeling. (arXiv:2106.09532v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shenoy_A/0/1/0/all/0/1">Ashish Shenoy</a>, <a href="http://arxiv.org/find/eess/1/au:+Bodapati_S/0/1/0/all/0/1">Sravan Bodapati</a>, <a href="http://arxiv.org/find/eess/1/au:+Kirchhoff_K/0/1/0/all/0/1">Katrin Kirchhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09532">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic Speech Recognition (ASR) robustness toward slot entities are
critical in e-commerce voice assistants that involve monetary transactions and
purchases. Along with effective domain adaptation, it is intuitive that cross
utterance contextual cues play an important role in disambiguating domain
specific content words from speech. In this paper, we investigate various
techniques to improve contextualization, content word robustness and domain
adaptation of a Transformer-XL neural language model (NLM) to rescore ASR
N-best hypotheses. To improve contextualization, we utilize turn level dialogue
acts along with cross utterance context carry over. Additionally, to adapt our
domain-general NLM towards e-commerce on-the-fly, we use embeddings derived
from a finetuned masked LM on in-domain data. Finally, to improve robustness
towards in-domain content words, we propose a multi-task model that can jointly
perform content word detection and language modeling tasks. Compared to a
non-contextual LSTM LM baseline, our best performing NLM rescorer results in a
content WER reduction of 19.2% on e-commerce audio test set and a slot labeling
F1 improvement of 6.4%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text2Event: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction. (arXiv:2106.09232v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yaojie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jialong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Annan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Meng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shaoyi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09232">
                                    <div class="article-summary-box-inner">
                                        <span>Event extraction is challenging due to the complex structure of event records
and the semantic gap between text and event. Traditional methods usually
extract event records by decomposing the complex structure prediction task into
multiple subtasks. In this paper, we propose Text2Event, a
sequence-to-structure generation paradigm that can directly extract events from
the text in an end-to-end manner. Specifically, we design a
sequence-to-structure network for unified event extraction, a constrained
decoding algorithm for event knowledge injection during inference, and a
curriculum learning algorithm for efficient model learning. Experimental
results show that, by uniformly modeling all tasks in a single model and
universally predicting different labels, our method can achieve competitive
performance using only record-level annotations in both supervised learning and
transfer learning settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models. (arXiv:2106.09204v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xueqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09204">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of fine-tuning pre-trained language models largely depends on
the hyperparameter configuration. In this paper, we investigate the performance
of modern hyperparameter optimization methods (HPO) on fine-tuning pre-trained
language models. First, we study and report three HPO algorithms&#x27; performances
on fine-tuning two state-of-the-art language models on the GLUE dataset. We
find that using the same time budget, HPO often fails to outperform grid search
due to two reasons: insufficient time budget and overfitting. We propose two
general strategies and an experimental procedure to systematically troubleshoot
HPO&#x27;s failure cases. By applying the procedure, we observe that HPO can succeed
with more appropriate settings in the search space and time budget; however, in
certain cases overfitting remains. Finally, we make suggestions for future
work. Our implementation can be found in
https://github.com/microsoft/FLAML/tree/main/flaml/nlp/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence. (arXiv:2004.03974v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1">Federico Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Terragni_S/0/1/0/all/0/1">Silvia Terragni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1">Dirk Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03974">
                                    <div class="article-summary-box-inner">
                                        <span>Topic models extract groups of words from documents, whose interpretation as
a topic hopefully allows for a better understanding of the data. However, the
resulting word groups are often not coherent, making them harder to interpret.
Recently, neural topic models have shown improvements in overall coherence.
Concurrently, contextual embeddings have advanced the state of the art of
neural models in general. In this paper, we combine contextualized
representations with neural topic models. We find that our approach produces
more meaningful and coherent topics than traditional bag-of-words topic models
and recent neural models. Our results indicate that future improvements in
language models will translate into better topic models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lost in Interpreting: Speech Translation from Source or Interpreter?. (arXiv:2106.09343v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Machacek_D/0/1/0/all/0/1">Dominik Mach&#xe1;&#x10d;ek</a>, <a href="http://arxiv.org/find/cs/1/au:+Zilinec_M/0/1/0/all/0/1">Mat&#xfa;&#x161; &#x17d;ilinec</a>, <a href="http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1">Ond&#x159;ej Bojar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09343">
                                    <div class="article-summary-box-inner">
                                        <span>Interpreters facilitate multi-lingual meetings but the affordable set of
languages is often smaller than what is needed. Automatic simultaneous speech
translation can extend the set of provided languages. We investigate if such an
automatic system should rather follow the original speaker, or an interpreter
to achieve better translation quality at the cost of increased delay.

To answer the question, we release Europarl Simultaneous Interpreting Corpus
(ESIC), 10 hours of recordings and transcripts of European Parliament speeches
in English, with simultaneous interpreting into Czech and German. We evaluate
quality and latency of speaker-based and interpreter-based spoken translation
systems from English to Czech. We study the differences in implicit
simplification and summarization of the human interpreter compared to a machine
translation system trained to shorten the output to some extent. Finally, we
perform human evaluation to measure information loss of each of these
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases. (arXiv:2106.09231v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1">Boxi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Lingyong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Meng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1">Tong Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09231">
                                    <div class="article-summary-box-inner">
                                        <span>Previous literatures show that pre-trained masked language models (MLMs) such
as BERT can achieve competitive factual knowledge extraction performance on
some datasets, indicating that MLMs can potentially be a reliable knowledge
source. In this paper, we conduct a rigorous study to explore the underlying
predicting mechanisms of MLMs over different extraction paradigms. By
investigating the behaviors of MLMs, we find that previous decent performance
mainly owes to the biased prompts which overfit dataset artifacts. Furthermore,
incorporating illustrative cases and external contexts improve knowledge
prediction mainly due to entity type guidance and golden answer leakage. Our
findings shed light on the underlying predicting mechanisms of MLMs, and
strongly question the previous conclusion that current MLMs can potentially
serve as reliable factual knowledge bases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing Image-Language Transformers for Verb Understanding. (arXiv:2106.09141v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendricks_L/0/1/0/all/0/1">Lisa Anne Hendricks</a>, <a href="http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1">Aida Nematzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09141">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal image-language transformers have achieved impressive results on a
variety of tasks that rely on fine-tuning (e.g., visual question answering and
image retrieval). We are interested in shedding light on the quality of their
pretrained representations -- in particular, if these models can distinguish
different types of verbs or if they rely solely on nouns in a given sentence.
To do so, we collect a dataset of image-sentence pairs (in English) consisting
of 421 verbs that are either visual or commonly found in the pretraining data
(i.e., the Conceptual Captions dataset). We use this dataset to evaluate
pretrained image-language transformers and find that they fail more in
situations that require verb understanding compared to other parts of speech.
We also investigate what category of verbs are particularly challenging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Specializing Multilingual Language Models: An Empirical Study. (arXiv:2106.09063v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chau_E/0/1/0/all/0/1">Ethan C. Chau</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09063">
                                    <div class="article-summary-box-inner">
                                        <span>Contextualized word representations from pretrained multilingual language
models have become the de facto standard for addressing natural language tasks
in many different languages, but the success of this approach is far from
universal. For languages rarely or never seen by these models, directly using
such models often results in suboptimal representation or use of data,
motivating additional model adaptations to achieve reasonably strong
performance. In this work, we study the performance, extensibility, and
interaction of two such adaptations for this low-resource setting: vocabulary
augmentation and script transliteration. Our evaluations on a set of three
tasks in nine diverse low-resource languages yield a mixed result, upholding
the viability of these approaches while raising new questions around how to
optimally adapt multilingual models to low-resource settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Online Chats with DAG-Structured LSTMs. (arXiv:2106.09024v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pappadopulo_D/0/1/0/all/0/1">Duccio Pappadopulo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_L/0/1/0/all/0/1">Lisa Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Farina_M/0/1/0/all/0/1">Marco Farina</a>, <a href="http://arxiv.org/find/cs/1/au:+Irsoy_O/0/1/0/all/0/1">Ozan &#x130;rsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09024">
                                    <div class="article-summary-box-inner">
                                        <span>Many modern messaging systems allow fast and synchronous textual
communication among many users. The resulting sequence of messages hides a more
complicated structure in which independent sub-conversations are interwoven
with one another. This poses a challenge for any task aiming to understand the
content of the chat logs or gather information from them. The ability to
disentangle these conversations is then tantamount to the success of many
downstream tasks such as summarization and question answering. Structured
information accompanying the text such as user turn, user mentions, timestamps,
is used as a cue by the participants themselves who need to follow the
conversation and has been shown to be important for disentanglement. DAG-LSTMs,
a generalization of Tree-LSTMs that can handle directed acyclic dependencies,
are a natural way to incorporate such information and its non-sequential
nature. In this paper, we apply DAG-LSTMs to the conversation disentanglement
task. We perform our experiments on the Ubuntu IRC dataset. We show that the
novel model we propose achieves state of the art status on the task of
recovering reply-to relations and it is competitive on other disentanglement
metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Construction of Evaluation Suites for Natural Language Generation Datasets. (arXiv:2106.09069v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mille_S/0/1/0/all/0/1">Simon Mille</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1">Kaustubh D. Dhole</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahamood_S/0/1/0/all/0/1">Saad Mahamood</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Beltrachini_L/0/1/0/all/0/1">Laura Perez-Beltrachini</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Miltenburg_E/0/1/0/all/0/1">Emiel van Miltenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09069">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning approaches applied to NLP are often evaluated by summarizing
their performance in a single number, for example accuracy. Since most test
sets are constructed as an i.i.d. sample from the overall data, this approach
overly simplifies the complexity of language and encourages overfitting to the
head of the data distribution. As such, rare language phenomena or text about
underrepresented groups are not equally included in the evaluation. To
encourage more in-depth model analyses, researchers have proposed the use of
multiple test sets, also called challenge sets, that assess specific
capabilities of a model. In this paper, we develop a framework based on this
idea which is able to generate controlled perturbations and identify subsets in
text-to-scalar, text-to-text, or data-to-text settings. By applying this
framework to the GEM generation benchmark, we propose an evaluation suite made
of 80 challenge sets, demonstrate the kinds of analyses that it enables and
shed light onto the limits of current generation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autobots: Latent Variable Sequential Set Transformers. (arXiv:2104.00563v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girgis_R/0/1/0/all/0/1">Roger Girgis</a>, <a href="http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1">Florian Golemo</a>, <a href="http://arxiv.org/find/cs/1/au:+Codevilla_F/0/1/0/all/0/1">Felipe Codevilla</a>, <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jim Aldon D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_M/0/1/0/all/0/1">Martin Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1">Samira Ebrahimi Kahou</a>, <a href="http://arxiv.org/find/cs/1/au:+Heide_F/0/1/0/all/0/1">Felix Heide</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00563">
                                    <div class="article-summary-box-inner">
                                        <span>Robust multi-agent trajectory prediction is essential for the safe control of
robots and vehicles that interact with humans. Many existing methods treat
social and temporal information separately and therefore fall short of
modelling the joint future trajectories of all agents in a socially consistent
way. To address this, we propose a new class of Latent Variable Sequential Set
Transformers which autoregressively model multi-agent trajectories. We refer to
these architectures as &quot;AutoBots&quot;. AutoBots model the contents of sets (e.g.
representing the properties of agents in a scene) over time and employ
multi-head self-attention blocks over these sequences of sets to encode the
sociotemporal relationships between the different actors of a scene. This
produces either the trajectory of one ego-agent or a distribution over the
future trajectories for all agents under consideration. Our approach works for
general sequences of sets and we provide illustrative experiments modelling the
sequential structure of the multiple strokes that make up symbols in the
Omniglot data. For the single-agent prediction case, we validate our model on
the NuScenes motion prediction task and achieve competitive results on the
global leaderboard. In the multi-agent forecasting setting, we validate our
model on TrajNet. We find that our method outperforms physical extrapolation
and recurrent network baselines and generates scene-consistent trajectories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIFT Matching by Context Exposed. (arXiv:2106.09584v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bellavia_F/0/1/0/all/0/1">Fabio Bellavia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09584">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates how to step up local image descriptor matching by
exploiting matching context information. Two main contexts are identified,
originated respectively from the descriptor space and from the keypoint space.
The former is generally used to design the actual matching strategy while the
latter to filter matches according to the local spatial consistency. On this
basis, a new matching strategy and a novel local spatial filter, named
respectively blob matching and Delaunay Triangulation Matching (DTM) are
devised. Blob matching provides a general matching framework by merging
together several strategies, including pre-filtering as well as many-to-many
and symmetric matching, enabling to achieve a global improvement upon each
individual strategy. DTM alternates between Delaunay triangulation contractions
and expansions to figure out and adjust keypoint neighborhood consistency.
Experimental evaluation shows that DTM is comparable or better than the
state-of-the-art in terms of matching accuracy and robustness, especially for
non-planar scenes. Evaluation is carried out according to a new benchmark
devised for analyzing the matching pipeline in terms of correct correspondences
on both planar and non-planar scenes, including state-of-the-art methods as
well as the common SIFT matching approach for reference. This evaluation can be
of assistance for future research in this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Correlation-Based Multiview Learning and Self-Supervision: A Unifying Perspective. (arXiv:2106.07115v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qi Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Songtao Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07115">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple views of data, both naturally acquired (e.g., image and audio) and
artificially produced (e.g., via adding different noise to data samples), have
proven useful in enhancing representation learning. Natural views are often
handled by multiview analysis tools, e.g., (deep) canonical correlation
analysis [(D)CCA], while the artificial ones are frequently used in
self-supervised learning (SSL) paradigms, e.g., SimCLR and Barlow Twins. Both
types of approaches often involve learning neural feature extractors such that
the embeddings of data exhibit high cross-view correlations. Although
intuitive, the effectiveness of correlation-based neural embedding is only
empirically validated. This work puts forth a theory-backed framework for
unsupervised multiview learning. Our development starts with proposing a
multiview model, where each view is a nonlinear mixture of shared and private
components. Consequently, the learning problem boils down to shared/private
component identification and disentanglement. Under this model, latent
correlation maximization is shown to guarantee the extraction of the shared
components across views (up to certain ambiguities). In addition, the private
information in each view can be provably disentangled from the shared using
proper regularization design. The method is tested on a series of tasks, e.g.,
downstream clustering, which all show promising performance. Our development
also provides a unifying perspective for understanding various DCCA and SSL
schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning. (arXiv:2102.09559v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chen Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kihyuk Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Mellina_C/0/1/0/all/0/1">Clayton Mellina</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09559">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised learning on class-imbalanced data, although a realistic
problem, has been under studied. While existing semi-supervised learning (SSL)
methods are known to perform poorly on minority classes, we find that they
still generate high precision pseudo-labels on minority classes. By exploiting
this property, in this work, we propose Class-Rebalancing Self-Training
(CReST), a simple yet effective framework to improve existing SSL methods on
class-imbalanced data. CReST iteratively retrains a baseline SSL model with a
labeled set expanded by adding pseudo-labeled samples from an unlabeled set,
where pseudo-labeled samples from minority classes are selected more frequently
according to an estimated class distribution. We also propose a progressive
distribution alignment to adaptively adjust the rebalancing strength dubbed
CReST+. We show that CReST and CReST+ improve state-of-the-art SSL algorithms
on various class-imbalanced datasets and consistently outperform other popular
rebalancing methods. Code has been made available at
https://github.com/google-research/crest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMN4: Few-shot Learning via Discriminative Mutual Nearest Neighbor Neural Network. (arXiv:2103.08160v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofei He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08160">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to classify images under low-data regimes, where
the conventional pooled global representation is likely to lose useful local
characteristics. Recent work has achieved promising performances by using deep
descriptors. They generally take all deep descriptors from neural networks into
consideration while ignoring that some of them are useless in classification
due to their limited receptive field, e.g., task-irrelevant descriptors could
be misleading and multiple aggregative descriptors from background clutter
could even overwhelm the object&#x27;s presence. In this paper, we argue that a
Mutual Nearest Neighbor (MNN) relation should be established to explicitly
select the query descriptors that are most relevant to each task and discard
less relevant ones from aggregative clutters in FSL. Specifically, we propose
Discriminative Mutual Nearest Neighbor Neural Network (DMN4) for FSL. Extensive
experiments demonstrate that our method not only qualitatively selects
task-relevant descriptors but also quantitatively outperforms the existing
state-of-the-arts by a large margin of 1.8~4.9% on fine-grained CUB, a
considerable margin of 1.4~2.2% on both supervised and semi-supervised
miniImagenet, and ~1.4% on challenging tieredimagenet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Adversarial Transferability with Gradient Refining. (arXiv:2105.04834v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoqiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Huanqian Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Ying Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xingxing Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04834">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are vulnerable to adversarial examples, which are
crafted by adding human-imperceptible perturbations to original images. Most
existing adversarial attack methods achieve nearly 100% attack success rates
under the white-box setting, but only achieve relatively low attack success
rates under the black-box setting. To improve the transferability of
adversarial examples for the black-box setting, several methods have been
proposed, e.g., input diversity, translation-invariant attack, and
momentum-based attack. In this paper, we propose a method named Gradient
Refining, which can further improve the adversarial transferability by
correcting useless gradients introduced by input diversity through multiple
transformations. Our method is generally applicable to many gradient-based
attack methods combined with input diversity. Extensive experiments are
conducted on the ImageNet dataset and our method can achieve an average
transfer success rate of 82.07% for three different models under single-model
setting, which outperforms the other state-of-the-art methods by a large margin
of 6.0% averagely. And we have applied the proposed method to the competition
CVPR 2021 Unrestricted Adversarial Attacks on ImageNet organized by Alibaba and
won the second place in attack success rates among 1558 teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NPAS: A Compiler-aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-Time Mobile Acceleration. (arXiv:2012.00596v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuxuan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zheng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1">Zhenglun Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00596">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing demand to efficiently deploy DNNs on mobile edge devices,
it becomes much more important to reduce unnecessary computation and increase
the execution speed. Prior methods towards this goal, including model
compression and network architecture search (NAS), are largely performed
independently and do not fully consider compiler-level optimizations which is a
must-do for mobile acceleration. In this work, we first propose (i) a general
category of fine-grained structured pruning applicable to various DNN layers,
and (ii) a comprehensive, compiler automatic code generation framework
supporting different DNNs and different pruning schemes, which bridge the gap
of model compression and NAS. We further propose NPAS, a compiler-aware unified
network pruning, and architecture search. To deal with large search space, we
propose a meta-modeling procedure based on reinforcement learning with fast
evaluation and Bayesian optimization, ensuring the total number of training
epochs comparable with representative NAS frameworks. Our framework achieves
6.7ms, 5.9ms, 3.9ms ImageNet inference times with 78.2%, 75% (MobileNet-V3
level), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an
off-the-shelf mobile phone, consistently outperforming prior work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IFCNet: A Benchmark Dataset for IFC Entity Classification. (arXiv:2106.09712v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Emunds_C/0/1/0/all/0/1">Christoph Emunds</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauen_N/0/1/0/all/0/1">Nicolas Pauen</a>, <a href="http://arxiv.org/find/cs/1/au:+Richter_V/0/1/0/all/0/1">Veronika Richter</a>, <a href="http://arxiv.org/find/cs/1/au:+Frisch_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Frisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Treeck_C/0/1/0/all/0/1">Christoph van Treeck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09712">
                                    <div class="article-summary-box-inner">
                                        <span>Enhancing interoperability and information exchange between domain-specific
software products for BIM is an important aspect in the Architecture,
Engineering, Construction and Operations industry. Recent research started
investigating methods from the areas of machine and deep learning for semantic
enrichment of BIM models. However, training and evaluation of these machine
learning algorithms requires sufficiently large and comprehensive datasets.
This work presents IFCNet, a dataset of single-entity IFC files spanning a
broad range of IFC classes containing both geometric and semantic information.
Using only the geometric information of objects, the experiments show that
three different deep learning models are able to achieve good classification
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing past words: Testing the cross-modal capabilities of pretrained V&amp;L models on counting tasks. (arXiv:2012.12352v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1">Letitia Parcalabescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatt_A/0/1/0/all/0/1">Albert Gatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Calixto_I/0/1/0/all/0/1">Iacer Calixto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12352">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the reasoning ability of pretrained vision and language (V&amp;L)
models in two tasks that require multimodal integration: (1) discriminating a
correct image-sentence pair from an incorrect one, and (2) counting entities in
an image. We evaluate three pretrained V&amp;L models on these tasks: ViLBERT,
ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results
show that models solve task (1) very well, as expected, since all models are
pretrained on task (1). However, none of the pretrained V&amp;L models is able to
adequately solve task (2), our counting probe, and they cannot generalise to
out-of-distribution quantities. We propose a number of explanations for these
findings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of
catastrophic forgetting on task (1). Concerning our results on the counting
probe, we find evidence that all models are impacted by dataset bias, and also
fail to individuate entities in the visual input. While a selling point of
pretrained V&amp;L models is their ability to solve complex tasks, our findings
suggest that understanding their reasoning and grounding capabilities requires
more targeted investigations on specific phenomena.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Multimodal Domino: in Search of Biomarkers for Alzheimer&#x27;s Disease. (arXiv:2012.13623v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1">Alex Fedorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sylvain_T/0/1/0/all/0/1">Tristan Sylvain</a>, <a href="http://arxiv.org/find/cs/1/au:+Geenjaar_E/0/1/0/all/0/1">Eloy Geenjaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Luck_M/0/1/0/all/0/1">Margaux Luck</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+DeRamus_T/0/1/0/all/0/1">Thomas P. DeRamus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirilin_A/0/1/0/all/0/1">Alex Kirilin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleklov_D/0/1/0/all/0/1">Dmitry Bleklov</a>, <a href="http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1">Vince D. Calhoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1">Sergey M. Plis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13623">
                                    <div class="article-summary-box-inner">
                                        <span>Sensory input from multiple sources is crucial for robust and coherent human
perception. Different sources contribute complementary explanatory factors.
Similarly, research studies often collect multimodal imaging data, each of
which can provide shared and unique information. This observation motivated the
design of powerful multimodal self-supervised representation-learning
algorithms. In this paper, we unify recent work on multimodal self-supervised
learning under a single framework. Observing that most self-supervised methods
optimize similarity metrics between a set of model components, we propose a
taxonomy of all reasonable ways to organize this process. We first evaluate
models on toy multimodal MNIST datasets and then apply them to a multimodal
neuroimaging dataset with Alzheimer&#x27;s disease patients. We find that (1)
multimodal contrastive learning has significant benefits over its unimodal
counterpart, (2) the specific composition of multiple contrastive objectives is
critical to performance on a downstream task, (3) maximization of the
similarity between representations has a regularizing effect on a neural
network, which can sometimes lead to reduced downstream performance but still
reveal multimodal relations. Results show that the proposed approach
outperforms previous self-supervised encoder-decoder methods based on canonical
correlation analysis (CCA) or the mixture-of-experts multimodal variational
autoEncoder (MMVAE) on various datasets with a linear evaluation protocol.
Importantly, we find a promising solution to uncover connections between
modalities through a jointly shared subspace that can help advance work in our
search for neuroimaging biomarkers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Recommend Frame for Interactive Video Object Segmentation in the Wild. (arXiv:2103.10391v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1">Zhaoyuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jia Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Weixin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1">Shenhan Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanling Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shenghua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a framework for the interactive video object segmentation
(VOS) in the wild where users can choose some frames for annotations
iteratively. Then, based on the user annotations, a segmentation algorithm
refines the masks. The previous interactive VOS paradigm selects the frame with
some worst evaluation metric, and the ground truth is required for calculating
the evaluation metric, which is impractical in the testing phase. In contrast,
in this paper, we advocate that the frame with the worst evaluation metric may
not be exactly the most valuable frame that leads to the most performance
improvement across the video. Thus, we formulate the frame selection problem in
the interactive VOS as a Markov Decision Process, where an agent is learned to
recommend the frame under a deep reinforcement learning framework. The learned
agent can automatically determine the most valuable frame, making the
interactive setting more practical in the wild. Experimental results on the
public datasets show the effectiveness of our learned agent without any changes
to the underlying VOS algorithms. Our data, code, and models are available at
https://github.com/svip-lab/IVOS-W.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking and Designing a High-performing Automatic License Plate Recognition Approach. (arXiv:2011.14936v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1">Zhen-Peng Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yunhao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1">Lap-Pui Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14936">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a real-time and accurate automatic license plate
recognition (ALPR) approach. Our study illustrates the outstanding design of
ALPR with four insights: (1) the resampling-based cascaded framework is
beneficial to both speed and accuracy; (2) the highly efficient license plate
recognition should abundant additional character segmentation and recurrent
neural network (RNN), but adopt a plain convolutional neural network (CNN); (3)
in the case of CNN, taking advantage of vertex information on license plates
improves the recognition performance; and (4) the weight-sharing character
classifier addresses the lack of training images in small-scale datasets. Based
on these insights, we propose a novel ALPR approach, termed VSNet.
Specifically, VSNet includes two CNNs, i.e., VertexNet for license plate
detection and SCR-Net for license plate recognition, integrated in a
resampling-based cascaded manner. In VertexNet, we propose an efficient
integration block to extract the spatial features of license plates. With
vertex supervisory information, we propose a vertex-estimation branch in
VertexNet such that license plates can be rectified as the input images of
SCR-Net. In SCR-Net, we introduce a horizontal encoding technique for
left-to-right feature extraction and propose a weight-sharing classifier for
character recognition. Experimental results show that the proposed VSNet
outperforms state-of-the-art methods by more than 50% relative improvement on
error rate, achieving &gt; 99% recognition accuracy on CCPD and AOLP datasets with
149 FPS inference speed. Moreover, our method illustrates an outstanding
generalization capability when evaluated on the unseen PKUData and CLPD
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICON: Learning Regular Maps Through Inverse Consistency. (arXiv:2105.04459v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Greer_H/0/1/0/all/0/1">Hastings Greer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwitt_R/0/1/0/all/0/1">Roland Kwitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Vialard_F/0/1/0/all/0/1">Francois-Xavier Vialard</a>, <a href="http://arxiv.org/find/cs/1/au:+Niethammer_M/0/1/0/all/0/1">Marc Niethammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04459">
                                    <div class="article-summary-box-inner">
                                        <span>Learning maps between data samples is fundamental. Applications range from
representation learning, image translation and generative modeling, to the
estimation of spatial deformations. Such maps relate feature vectors, or map
between feature spaces. Well-behaved maps should be regular, which can be
imposed explicitly or may emanate from the data itself. We explore what induces
regularity for spatial transformations, e.g., when computing image
registrations. Classical optimization-based models compute maps between pairs
of samples and rely on an appropriate regularizer for well-posedness. Recent
deep learning approaches have attempted to avoid using such regularizers
altogether by relying on the sample population instead. We explore if it is
possible to obtain spatial regularity using an inverse consistency loss only
and elucidate what explains map regularity in such a context. We find that deep
networks combined with an inverse consistency loss and randomized off-grid
interpolation yield well behaved, approximately diffeomorphic, spatial
transformations. Despite the simplicity of this approach, our experiments
present compelling evidence, on both synthetic and real data, that regular maps
can be obtained without carefully tuned explicit regularizers, while achieving
competitive registration performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and Positioning Predictor on Edge Devices. (arXiv:2102.03456v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fasfous_N/0/1/0/all/0/1">Nael Fasfous</a>, <a href="http://arxiv.org/find/cs/1/au:+Vemparala_M/0/1/0/all/0/1">Manoj-Rohit Vemparala</a>, <a href="http://arxiv.org/find/cs/1/au:+Frickenstein_A/0/1/0/all/0/1">Alexander Frickenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Frickenstein_L/0/1/0/all/0/1">Lukas Frickenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Stechele_W/0/1/0/all/0/1">Walter Stechele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03456">
                                    <div class="article-summary-box-inner">
                                        <span>Face masks have long been used in many areas of everyday life to protect
against the inhalation of hazardous fumes and particles. They also offer an
effective solution in healthcare for bi-directional protection against
air-borne diseases. Wearing and positioning the mask correctly is essential for
its function. Convolutional neural networks (CNNs) offer an excellent solution
for face recognition and classification of correct mask wearing and
positioning. In the context of the ongoing COVID-19 pandemic, such algorithms
can be used at entrances to corporate buildings, airports, shopping areas, and
other indoor locations, to mitigate the spread of the virus. These application
scenarios impose major challenges to the underlying compute platform. The
inference hardware must be cheap, small and energy efficient, while providing
sufficient memory and compute power to execute accurate CNNs at a reasonably
low latency. To maintain data privacy of the public, all processing must remain
on the edge-device, without any communication with cloud servers. To address
these challenges, we present a low-power binary neural network classifier for
correct facial-mask wear and positioning. The classification task is
implemented on an embedded FPGA, performing high-throughput binary operations.
Classification can take place at up to ~6400 frames-per-second, easily enabling
multi-camera, speed-gate settings or statistics collection in crowd settings.
When deployed on a single entrance or gate, the idle power consumption is
reduced to 1.6W, improving the battery-life of the device. We achieve an
accuracy of up to 98% for four wearing positions of the MaskedFace-Net dataset.
To maintain equivalent classification accuracy for all face structures,
skin-tones, hair types, and mask types, the algorithms are tested for their
ability to generalize the relevant features over all subjects using the
Grad-CAM approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive for Remote Sensing Image Classification and Retrieval. (arXiv:2105.07921v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sumbul_G/0/1/0/all/0/1">Gencer Sumbul</a>, <a href="http://arxiv.org/find/cs/1/au:+Wall_A/0/1/0/all/0/1">Arne de Wall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreuziger_T/0/1/0/all/0/1">Tristan Kreuziger</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcelino_F/0/1/0/all/0/1">Filipe Marcelino</a>, <a href="http://arxiv.org/find/cs/1/au:+Costa_H/0/1/0/all/0/1">Hugo Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Benevides_P/0/1/0/all/0/1">Pedro Benevides</a>, <a href="http://arxiv.org/find/cs/1/au:+Caetano_M/0/1/0/all/0/1">M&#xe1;rio Caetano</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_B/0/1/0/all/0/1">Beg&#xfc;m Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Markl_V/0/1/0/all/0/1">Volker Markl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07921">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the multi-modal BigEarthNet (BigEarthNet-MM) benchmark
archive made up of 590,326 pairs of Sentinel-1 and Sentinel-2 image patches to
support the deep learning (DL) studies in multi-modal multi-label remote
sensing (RS) image retrieval and classification. Each pair of patches in
BigEarthNet-MM is annotated with multi-labels provided by the CORINE Land Cover
(CLC) map of 2018 based on its thematically most detailed Level-3 class
nomenclature. Our initial research demonstrates that some CLC classes are
challenging to be accurately described by only considering (single-date)
BigEarthNet-MM images. In this paper, we also introduce an alternative
class-nomenclature as an evolution of the original CLC labels to address this
problem. This is achieved by interpreting and arranging the CLC Level-3
nomenclature based on the properties of BigEarthNet-MM images in a new
nomenclature of 19 classes. In our experiments, we show the potential of
BigEarthNet-MM for multi-modal multi-label image retrieval and classification
problems by considering several state-of-the-art DL models. We also demonstrate
that the DL models trained from scratch on BigEarthNet-MM outperform those
pre-trained on ImageNet, especially in relation to some complex classes,
including agriculture and other vegetated and natural environments. We make all
the data and the DL models publicly available at https://bigearth.net, offering
an important resource to support studies on multi-modal image scene
classification and retrieval problems in RS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XCiT: Cross-Covariance Image Transformers. (arXiv:2106.09681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1">Alaaeldin El-Nouby</a>, <a href="http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1">Hugo Touvron</a>, <a href="http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1">Mathilde Caron</a>, <a href="http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1">Piotr Bojanowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1">Armand Joulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Neverova_N/0/1/0/all/0/1">Natalia Neverova</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegou_H/0/1/0/all/0/1">Herv&#xe9; Jegou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09681">
                                    <div class="article-summary-box-inner">
                                        <span>Following their success in natural language processing, transformers have
recently shown much promise for computer vision. The self-attention operation
underlying transformers yields global interactions between all tokens ,i.e.
words or image patches, and enables flexible modelling of image data beyond the
local interactions of convolutions. This flexibility, however, comes with a
quadratic complexity in time and memory, hindering application to long
sequences and high-resolution images. We propose a &quot;transposed&quot; version of
self-attention that operates across feature channels rather than tokens, where
the interactions are based on the cross-covariance matrix between keys and
queries. The resulting cross-covariance attention (XCA) has linear complexity
in the number of tokens, and allows efficient processing of high-resolution
images. Our cross-covariance image transformer (XCiT) is built upon XCA. It
combines the accuracy of conventional transformers with the scalability of
convolutional architectures. We validate the effectiveness and generality of
XCiT by reporting excellent results on multiple vision benchmarks, including
image classification and self-supervised feature learning on ImageNet-1k,
object detection and instance segmentation on COCO, and semantic segmentation
on ADE20k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Image-to-Video Synthesis using cINNs. (arXiv:2105.04551v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dorkenwald_M/0/1/0/all/0/1">Michael Dorkenwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1">Timo Milbich</a>, <a href="http://arxiv.org/find/cs/1/au:+Blattmann_A/0/1/0/all/0/1">Andreas Blattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rombach_R/0/1/0/all/0/1">Robin Rombach</a>, <a href="http://arxiv.org/find/cs/1/au:+Derpanis_K/0/1/0/all/0/1">Konstantinos G. Derpanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1">Bj&#xf6;rn Ommer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04551">
                                    <div class="article-summary-box-inner">
                                        <span>Video understanding calls for a model to learn the characteristic interplay
between static scene content and its dynamics: Given an image, the model must
be able to predict a future progression of the portrayed scene and, conversely,
a video should be explained in terms of its static image content and all the
remaining characteristics not present in the initial frame. This naturally
suggests a bijective mapping between the video domain and the static content as
well as residual information. In contrast to common stochastic image-to-video
synthesis, such a model does not merely generate arbitrary videos progressing
the initial image. Given this image, it rather provides a one-to-one mapping
between the residual vectors and the video with stochastic outcomes when
sampling. The approach is naturally implemented using a conditional invertible
neural network (cINN) that can explain videos by independently modelling static
and other video characteristics, thus laying the basis for controlled video
synthesis. Experiments on four diverse video datasets demonstrate the
effectiveness of our approach in terms of both the quality and diversity of the
synthesized results. Our project page is available at https://bit.ly/3t66bnU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FG-Net: Fast Large-Scale LiDAR Point Clouds Understanding Network Leveraging Correlated Feature Mining and Geometric-Aware Modelling. (arXiv:2012.09439v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kangcheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Feng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Ben M. Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09439">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents FG-Net, a general deep learning framework for large-scale
point clouds understanding without voxelizations, which achieves accurate and
real-time performance with a single NVIDIA GTX 1080 GPU. First, a novel noise
and outlier filtering method is designed to facilitate subsequent high-level
tasks. For effective understanding purpose, we propose a deep convolutional
neural network leveraging correlated feature mining and deformable convolution
based geometric-aware modelling, in which the local feature relationships and
geometric patterns can be fully exploited. For the efficiency issue, we put
forward an inverse density sampling operation and a feature pyramid based
residual learning strategy to save the computational cost and memory
consumption respectively. Extensive experiments on real-world challenging
datasets demonstrated that our approaches outperform state-of-the-art
approaches in terms of accuracy and efficiency. Moreover, weakly supervised
transfer learning is also conducted to demonstrate the generalization capacity
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMA-Net: A Cascaded Mutual Attention Network for Light Field Salient Object Detection. (arXiv:2105.00949v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1">Olivier Deforges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00949">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, numerous deep learning methods have been proposed to
address the task of segmenting salient objects from RGB images. However, these
approaches depending on single modality fail to achieve the state-of-the-art
performance on widely used light field salient object detection (SOD) datasets,
which collect large-scale natural images and provide multiple modalities such
as multi-view, micro-lens images and depth maps. Most recently proposed light
field SOD methods have acquired improving detecting accuracy, yet still predict
rough objects&#x27; structures and perform slow inference speed. To this end, we
propose CMA-Net, which consists of two novel cascaded mutual attention modules
aiming at fusing the high level features from the modalities of all-in-focus
and depth. Our proposed CMA-Net outperforms 30 SOD methods (by a large margin)
on two widely applied light field benchmark datasets. Besides, the proposed
CMA-Net can run at a speed of 53 fps, thus being four times faster than the
state-of-the-art multi-modal SOD methods. Extensive quantitative and
qualitative experiments illustrate both the effectiveness and efficiency of our
CMA-Net, inspiring future development of multi-modal learning for both the
RGB-D and light field SOD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Personal Style from Few Examples. (arXiv:2105.14457v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">David Chuan-En Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Martelaro_N/0/1/0/all/0/1">Nikolas Martelaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14457">
                                    <div class="article-summary-box-inner">
                                        <span>A key task in design work is grasping the client&#x27;s implicit tastes. Designers
often do this based on a set of examples from the client. However, recognizing
a common pattern among many intertwining variables such as color, texture, and
layout and synthesizing them into a composite preference can be challenging. In
this paper, we leverage the pattern recognition capability of computational
models to aid in this task. We offer a set of principles for computationally
learning personal style. The principles are manifested in PseudoClient, a deep
learning framework that learns a computational model for personal graphic
design style from only a handful of examples. In several experiments, we found
that PseudoClient achieves a 79.40% accuracy with only five positive and
negative examples, outperforming several alternative methods. Finally, we
discuss how PseudoClient can be utilized as a building block to support the
development of future design applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Attack Vulnerability of Medical Image Analysis Systems: Unexplored Factors. (arXiv:2006.06356v3 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bortsova_G/0/1/0/all/0/1">Gerda Bortsova</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Gonzalo_C/0/1/0/all/0/1">Cristina Gonz&#xe1;lez-Gonzalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wetstein_S/0/1/0/all/0/1">Suzanne C. Wetstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubost_F/0/1/0/all/0/1">Florian Dubost</a>, <a href="http://arxiv.org/find/cs/1/au:+Katramados_I/0/1/0/all/0/1">Ioannis Katramados</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogeweg_L/0/1/0/all/0/1">Laurens Hogeweg</a>, <a href="http://arxiv.org/find/cs/1/au:+Liefers_B/0/1/0/all/0/1">Bart Liefers</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1">Bram van Ginneken</a>, <a href="http://arxiv.org/find/cs/1/au:+Pluim_J/0/1/0/all/0/1">Josien P.W. Pluim</a>, <a href="http://arxiv.org/find/cs/1/au:+Veta_M/0/1/0/all/0/1">Mitko Veta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_C/0/1/0/all/0/1">Clara I. S&#xe1;nchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruijne_M/0/1/0/all/0/1">Marleen de Bruijne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06356">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks are considered a potentially serious security threat for
machine learning systems. Medical image analysis (MedIA) systems have recently
been argued to be vulnerable to adversarial attacks due to strong financial
incentives and the associated technological infrastructure.

In this paper, we study previously unexplored factors affecting adversarial
attack vulnerability of deep learning MedIA systems in three medical domains:
ophthalmology, radiology, and pathology. We focus on adversarial black-box
settings, in which the attacker does not have full access to the target model
and usually uses another model, commonly referred to as surrogate model, to
craft adversarial examples. We consider this to be the most realistic scenario
for MedIA systems.

Firstly, we study the effect of weight initialization (ImageNet vs. random)
on the transferability of adversarial attacks from the surrogate model to the
target model. Secondly, we study the influence of differences in development
data between target and surrogate models. We further study the interaction of
weight initialization and data differences with differences in model
architecture. All experiments were done with a perturbation degree tuned to
ensure maximal transferability at minimal visual perceptibility of the attacks.

Our experiments show that pre-training may dramatically increase the
transferability of adversarial examples, even when the target and surrogate&#x27;s
architectures are different: the larger the performance gain using
pre-training, the larger the transferability. Differences in the development
data between target and surrogate models considerably decrease the performance
of the attack; this decrease is further amplified by difference in the model
architecture. We believe these factors should be considered when developing
security-critical MedIA systems planned to be deployed in clinical practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine-learning enhanced dark soliton detection in Bose-Einstein condensates. (arXiv:2101.05404v2 [cond-mat.quant-gas] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Guo_S/0/1/0/all/0/1">Shangjie Guo</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fritsch_A/0/1/0/all/0/1">Amilson R. Fritsch</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Greenberg_C/0/1/0/all/0/1">Craig Greenberg</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Spielman_I/0/1/0/all/0/1">I. B. Spielman</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zwolak_J/0/1/0/all/0/1">Justyna P. Zwolak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05404">
                                    <div class="article-summary-box-inner">
                                        <span>Most data in cold-atom experiments comes from images, the analysis of which
is limited by our preconceptions of the patterns that could be present in the
data. We focus on the well-defined case of detecting dark solitons -- appearing
as local density depletions in a Bose-Einstein condensate (BEC) -- using a
methodology that is extensible to the general task of pattern recognition in
images of cold atoms. Studying soliton dynamics over a wide range of parameters
requires the analysis of large datasets, making the existing
human-inspection-based methodology a significant bottleneck. Here we describe
an automated classification and positioning system for identifying localized
excitations in atomic BECs utilizing deep convolutional neural networks to
eliminate the need for human image examination. Furthermore, we openly publish
our labeled dataset of dark solitons, the first of its kind, for further
machine learning research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalization of breast MRIs using Cycle-Consistent Generative Adversarial Networks. (arXiv:1912.08061v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Modanwal_G/0/1/0/all/0/1">Gourav Modanwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Vellal_A/0/1/0/all/0/1">Adithya Vellal</a>, <a href="http://arxiv.org/find/eess/1/au:+Mazurowski_M/0/1/0/all/0/1">Maciej A. Mazurowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.08061">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) is widely used
to complement ultrasound examinations and x-ray mammography during the early
detection and diagnosis of breast cancer. However, images generated by various
MRI scanners (e.g. GE Healthcare vs Siemens) differ both in intensity and noise
distribution, preventing algorithms trained on MRIs from one scanner to
generalize to data from other scanners successfully. We propose a method for
image normalization to solve this problem. MRI normalization is challenging
because it requires both normalizing intensity values and mapping between the
noise distributions of different scanners. We utilize a cycle-consistent
generative adversarial network to learn a bidirectional mapping between MRIs
produced by GE Healthcare and Siemens scanners. This allows us learning the
mapping between two different scanner types without matched data, which is not
commonly available. To ensure the preservation of breast shape and structures
within the breast, we propose two technical innovations. First, we incorporate
a mutual information loss with the CycleGAN architecture to ensure that the
structure of the breast is maintained. Second, we propose a modified
discriminator architecture which utilizes a smaller field-of-view to ensure the
preservation of finer details in the breast tissue. Quantitative and
qualitative evaluations show that the second proposed method was able to
consistently preserve a high level of detail in the breast structure while also
performing the proper intensity normalization and noise mapping. Our results
demonstrate that the proposed model can successfully learn a bidirectional
mapping between MRIs produced by different vendors, potentially enabling
improved accuracy of downstream computational algorithms for diagnosis and
detection of breast cancer. All the data used in this study are publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-guided Automatic Natural Image Matting with Light-weight Non-local Attention. (arXiv:2103.17020v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuhongze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Liguang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1">Tin Lun Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yangsheng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17020">
                                    <div class="article-summary-box-inner">
                                        <span>Natural image matting aims to precisely separate foreground objects from
background using alpha matte. Fully automatic natural image matting without
external annotation is quite challenging. Well-performed matting methods
usually require accurate labor-intensive handcrafted trimap as extra input,
while the performance of automatic trimap generation method of dilating
foreground segmentation fluctuates with segmentation quality. Therefore, we
argue that how to handle trade-off of additional information input is a major
issue in automatic matting. This paper presents a universal semantic-guided
automatic natural image matting pipeline with light-weight non-local attention
without trimap and background image as input. Specifically, guided by semantic
information of coarse foreground segmentation, Trimap Generation Network
estimates accurate trimap. With estimated trimap and RGB image as input, our
light-weight Non-local Matting Network with Refinement produces final alpha
matte, whose trimap-guided global aggregation attention block is equipped with
stride downsampling convolution, reducing computation complexity and promoting
performance. Experimental results show that our matting algorithm has
competitive performance with current state-of-the-art methods in both
trimap-free and trimap-needed aspects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Selfie Video Stabilization. (arXiv:2009.02007v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiyang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramamoorthi_R/0/1/0/all/0/1">Ravi Ramamoorthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Keli Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkis_M/0/1/0/all/0/1">Michel Sarkis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_N/0/1/0/all/0/1">Ning Bi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02007">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel real-time selfie video stabilization method. Our method is
completely automatic and runs at 26 fps. We use a 1D linear convolutional
network to directly infer the rigid moving least squares warping which
implicitly balances between the global rigidity and local flexibility. Our
network structure is specifically designed to stabilize the background and
foreground at the same time, while providing optional control of stabilization
focus (relative importance of foreground vs. background) to the users. To train
our network, we collect a selfie video dataset with 1005 videos, which is
significantly larger than previous selfie video datasets. We also propose a
grid approximation method to the rigid moving least squares warping that
enables the real-time frame warping. Our method is fully automatic and produces
visually and quantitatively better results than previous real-time general
video stabilization methods. Compared to previous offline selfie video methods,
our approach produces comparable quality with a speed improvement of orders of
magnitude.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions. (arXiv:2010.12852v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dua_R/0/1/0/all/0/1">Radhika Dua</a>, <a href="http://arxiv.org/find/cs/1/au:+Kancheti_S/0/1/0/all/0/1">Sai Srinivas Kancheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12852">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Question Answering is a multi-modal task that aims to measure
high-level visual understanding. Contemporary VQA models are restrictive in the
sense that answers are obtained via classification over a limited vocabulary
(in the case of open-ended VQA), or via classification over a set of
multiple-choice-type answers. In this work, we present a completely generative
formulation where a multi-word answer is generated for a visual query. To take
this a step forward, we introduce a new task: ViQAR (Visual Question Answering
and Reasoning), wherein a model must generate the complete answer and a
rationale that seeks to justify the generated answer. We propose an end-to-end
architecture to solve this task and describe how to evaluate it. We show that
our model generates strong answers and rationales through qualitative and
quantitative evaluation, as well as through a human Turing Test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning. (arXiv:2106.09701v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">James Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1">Yen-Chang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Balloch_J/0/1/0/all/0/1">Jonathan Balloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yilin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hongxia Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09701">
                                    <div class="article-summary-box-inner">
                                        <span>Modern computer vision applications suffer from catastrophic forgetting when
incrementally learning new concepts over time. The most successful approaches
to alleviate this forgetting require extensive replay of previously seen data,
which is problematic when memory constraints or data legality concerns exist.
In this work, we consider the high-impact problem of Data-Free
Class-Incremental Learning (DFCIL), where an incremental learning agent must
learn new concepts over time without storing generators or training data from
past tasks. One approach for DFCIL is to replay synthetic images produced by
inverting a frozen copy of the learner&#x27;s classification model, but we show this
approach fails for common class-incremental benchmarks when using standard
distillation strategies. We diagnose the cause of this failure and propose a
novel incremental distillation strategy for DFCIL, contributing a modified
cross-entropy training and importance-weighted feature distillation, and show
that our method results in up to a 25.1% increase in final task accuracy
(absolute difference) compared to SOTA DFCIL methods for common
class-incremental benchmarks. Our method even outperforms several standard
replay based methods which store a coreset of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Analytics with Zero-streaming Cameras. (arXiv:1904.12342v4 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tiantu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Felix Xiaozhu Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.12342">
                                    <div class="article-summary-box-inner">
                                        <span>Low-cost cameras enable powerful analytics. An unexploited opportunity is
that most captured videos remain &quot;cold&quot; without being queried. For efficiency,
we advocate for these cameras to be zero streaming: capturing videos to local
storage and communicating with the cloud only when analytics is requested. How
to query zero-streaming cameras efficiently? Our response is a camera/cloud
runtime system called DIVA. It addresses two key challenges: to best use
limited camera resource during video capture; to rapidly explore massive videos
during query execution. DIVA contributes two unconventional techniques. (1)
When capturing videos, a camera builds sparse yet accurate landmark frames,
from which it learns reliable knowledge for accelerating future queries. (2)
When executing a query, a camera processes frames in multiple passes with
increasingly more expensive operators. As such, DIVA presents and keeps
refining inexact query results throughout the query&#x27;s execution. On diverse
queries over 15 videos lasting 720 hours in total, DIVA runs at more than 100x
video realtime and outperforms competitive alternative designs. To our
knowledge, DIVA is the first system for querying large videos stored on
low-cost remote cameras.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors. (arXiv:2006.15417v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruihan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Madumal_P/0/1/0/all/0/1">Prashan Madumal</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1">Tim Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehinger_K/0/1/0/all/0/1">Krista A. Ehinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1">Benjamin I. P. Rubinstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15417">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural network (CNN) models for computer vision are powerful
but lack explainability in their most basic form. This deficiency remains a key
challenge when applying CNNs in important domains. Recent work on explanations
through feature importance of approximate linear models has moved from
input-level features (pixels or segments) to features from mid-layer feature
maps in the form of concept activation vectors (CAVs). CAVs contain
concept-level information and could be learned via clustering. In this work, we
rethink the ACE algorithm of Ghorbani et~al., proposing an alternative
invertible concept-based explanation (ICE) framework to overcome its
shortcomings. Based on the requirements of fidelity (approximate models to
target models) and interpretability (being meaningful to people), we design
measurements and evaluate a range of matrix factorization methods with our
framework. We find that non-negative concept activation vectors (NCAVs) from
non-negative matrix factorization provide superior performance in
interpretability and fidelity based on computational and human subject
experiments. Our framework provides both local and global concept-level
explanations for pre-trained CNN models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;What&#x27;s This?&quot; -- Learning to Segment Unknown Objects from Manipulation Sequences. (arXiv:2011.03279v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boerdijk_W/0/1/0/all/0/1">Wout Boerdijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundermeyer_M/0/1/0/all/0/1">Martin Sundermeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Durner_M/0/1/0/all/0/1">Maximilian Durner</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03279">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel framework for self-supervised grasped object segmentation
with a robotic manipulator. Our method successively learns an agnostic
foreground segmentation followed by a distinction between manipulator and
object solely by observing the motion between consecutive RGB frames. In
contrast to previous approaches, we propose a single, end-to-end trainable
architecture which jointly incorporates motion cues and semantic knowledge.
Furthermore, while the motion of the manipulator and the object are substantial
cues for our algorithm, we present means to robustly deal with distraction
objects moving in the background, as well as with completely static scenes. Our
method neither depends on any visual registration of a kinematic robot or 3D
object models, nor on precise hand-eye calibration or any additional sensor
data. By extensive experimental evaluation we demonstrate the superiority of
our framework and provide detailed insights on its capability of dealing with
the aforementioned extreme cases of motion. We also show that training a
semantic segmentation network with the automatically labeled data achieves
results on par with manually annotated training data. Code and pretrained model
are available at https://github.com/DLR-RM/DistinctNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BABEL: Bodies, Action and Behavior with English Labels. (arXiv:2106.09696v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Punnakkal_A/0/1/0/all/0/1">Abhinanda R. Punnakkal</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_A/0/1/0/all/0/1">Arjun Chandrasekaran</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Athanasiou_N/0/1/0/all/0/1">Nikos Athanasiou</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Quiros_Ramirez_A/0/1/0/all/0/1">Alejandra Quiros-Ramirez</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a> (1) ((1) Max Planck Institute for Intelligent Systems, (2) Universitat Konstanz)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09696">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the semantics of human movement -- the what, how and why of the
movement -- is an important problem that requires datasets of human actions
with semantic labels. Existing datasets take one of two approaches. Large-scale
video datasets contain many action labels but do not contain ground-truth 3D
human motion. Alternatively, motion-capture (mocap) datasets have precise body
motions but are limited to a small number of actions. To address this, we
present BABEL, a large dataset with language labels describing the actions
being performed in mocap sequences. BABEL consists of action labels for about
43 hours of mocap sequences from AMASS. Action labels are at two levels of
abstraction -- sequence labels describe the overall action in the sequence, and
frame labels describe all actions in every frame of the sequence. Each frame
label is precisely aligned with the duration of the corresponding action in the
mocap sequence, and multiple actions can overlap. There are over 28k sequence
labels, and 63k frame labels in BABEL, which belong to over 250 unique action
categories. Labels from BABEL can be leveraged for tasks like action
recognition, temporal action localization, motion synthesis, etc. To
demonstrate the value of BABEL as a benchmark, we evaluate the performance of
models on 3D action recognition. We demonstrate that BABEL poses interesting
learning challenges that are applicable to real-world scenarios, and can serve
as a useful benchmark of progress in 3D action recognition. The dataset,
baseline method, and evaluation code is made available, and supported for
academic research purposes at https://babel.is.tue.mpg.de/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Correspondence Hallucination: Towards Geometric Reasoning. (arXiv:2106.09711v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Germain_H/0/1/0/all/0/1">Hugo Germain</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1">Vincent Lepetit</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourmaud_G/0/1/0/all/0/1">Guillaume Bourmaud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09711">
                                    <div class="article-summary-box-inner">
                                        <span>Given a pair of partially overlapping source and target images and a keypoint
in the source image, the keypoint&#x27;s correspondent in the target image can be
either visible, occluded or outside the field of view. Local feature matching
methods are only able to identify the correspondent&#x27;s location when it is
visible, while humans can also hallucinate its location when it is occluded or
outside the field of view through geometric reasoning. In this paper, we bridge
this gap by training a network to output a peaked probability distribution over
the correspondent&#x27;s location, regardless of this correspondent being visible,
occluded, or outside the field of view. We experimentally demonstrate that this
network is indeed able to hallucinate correspondences on unseen pairs of
images. We also apply this network to a camera pose estimation problem and find
it is significantly more robust than state-of-the-art local feature
matching-based competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Label Learning from Single Positive Labels. (arXiv:2106.09708v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1">Elijah Cole</a>, <a href="http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1">Oisin Mac Aodha</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorieul_T/0/1/0/all/0/1">Titouan Lorieul</a>, <a href="http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1">Pietro Perona</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1">Dan Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Jojic_N/0/1/0/all/0/1">Nebojsa Jojic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09708">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting all applicable labels for a given image is known as multi-label
classification. Compared to the standard multi-class case (where each image has
only one label), it is considerably more challenging to annotate training data
for multi-label classification. When the number of potential labels is large,
human annotators find it difficult to mention all applicable labels for each
training image. Furthermore, in some settings detection is intrinsically
difficult e.g. finding small object instances in high resolution images. As a
result, multi-label training data is often plagued by false negatives. We
consider the hardest version of this problem, where annotators provide only one
relevant label for each image. As a result, training sets will have only one
positive label per image and no confirmed negatives. We explore this special
case of learning from missing labels across four different multi-label image
classification datasets for both linear classifiers and end-to-end fine-tuned
deep networks. We extend existing multi-label losses to this setting and
propose novel variants that constrain the number of expected positive labels
during training. Surprisingly, we show that in some cases it is possible to
approach the performance of fully labeled classifiers despite training with
significantly fewer confirmed labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Contextual Prediction for Learned Image Compression. (arXiv:2011.09704v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zongyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhizheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Runsen Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09704">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past several years, we have witnessed impressive progress in the
field of learned image compression. Recent learned image codecs are commonly
based on autoencoders, that first encode an image into low-dimensional latent
representations and then decode them for reconstruction purposes. To capture
spatial dependencies in the latent space, prior works exploit hyperprior and
spatial context model to build an entropy model, which estimates the bit-rate
for end-to-end rate-distortion optimization. However, such an entropy model is
suboptimal from two aspects: (1) It fails to capture spatially global
correlations among the latents. (2) Cross-channel relationships of the latents
are still underexplored. In this paper, we propose the concept of separate
entropy coding to leverage a serial decoding process for causal contextual
entropy prediction in the latent space. A causal context model is proposed that
separates the latents across channels and makes use of cross-channel
relationships to generate highly informative contexts. Furthermore, we propose
a causal global prediction model, which is able to find global reference points
for accurate predictions of unknown points. Both these two models facilitate
entropy estimation without the transmission of overhead. In addition, we
further adopt a new separate attention module to build more powerful transform
networks. Experimental results demonstrate that our full image compression
model outperforms standard VVC/H.266 codec on Kodak dataset in terms of both
PSNR and MS-SSIM, yielding the state-of-the-art rate-distortion performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks. (arXiv:2006.12557v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12557">
                                    <div class="article-summary-box-inner">
                                        <span>Data poisoning and backdoor attacks manipulate training data in order to
cause models to fail during inference. A recent survey of industry
practitioners found that data poisoning is the number one concern among threats
ranging from model stealing to adversarial attacks. However, it remains unclear
exactly how dangerous poisoning methods are and which ones are more effective
considering that these methods, even ones with identical objectives, have not
been tested in consistent or realistic settings. We observe that data poisoning
and backdoor attacks are highly sensitive to variations in the testing setup.
Moreover, we find that existing methods may not generalize to realistic
settings. While these existing works serve as valuable prototypes for data
poisoning, we apply rigorous tests to determine the extent to which we should
fear them. In order to promote fair comparison in future work, we develop
standardized benchmarks for data poisoning and backdoor attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Dexterous Grasping with Object-Centric Visual Affordances. (arXiv:2009.01439v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mandikal_P/0/1/0/all/0/1">Priyanka Mandikal</a>, <a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1">Kristen Grauman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.01439">
                                    <div class="article-summary-box-inner">
                                        <span>Dexterous robotic hands are appealing for their agility and human-like
morphology, yet their high degree of freedom makes learning to manipulate
challenging. We introduce an approach for learning dexterous grasping. Our key
idea is to embed an object-centric visual affordance model within a deep
reinforcement learning loop to learn grasping policies that favor the same
object regions favored by people. Unlike traditional approaches that learn from
human demonstration trajectories (e.g., hand joint sequences captured with a
glove), the proposed prior is object-centric and image-based, allowing the
agent to anticipate useful affordance regions for objects unseen during policy
learning. We demonstrate our idea with a 30-DoF five-fingered robotic hand
simulator on 40 objects from two datasets, where it successfully and
efficiently learns policies for stable functional grasps. Our affordance-guided
policies are significantly more effective, generalize better to novel objects,
train 3 X faster than the baselines, and are more robust to noisy sensor
readings and actuation. Our work offers a step towards manipulation agents that
learn by watching how people use objects, without requiring state and action
information about the human body. Project website:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks. (arXiv:2004.05937v7 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kuk-Jin Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.05937">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural models in recent years have been successful in almost every
field, including extremely complex problem statements. However, these models
are huge in size, with millions (and even billions) of parameters, thus
demanding more heavy computation power and failing to be deployed on edge
devices. Besides, the performance boost is highly dependent on redundant
labeled data. To achieve faster speeds and to handle the problems caused by the
lack of data, knowledge distillation (KD) has been proposed to transfer
information learned from one model to another. KD is often characterized by the
so-called &#x60;Student-Teacher&#x27; (S-T) learning framework and has been broadly
applied in model compression and knowledge transfer. This paper is about KD and
S-T learning, which are being actively studied in recent years. First, we aim
to provide explanations of what KD is and how/why it works. Then, we provide a
comprehensive survey on the recent progress of KD methods together with S-T
frameworks typically for vision tasks. In general, we consider some fundamental
questions that have been driving this research area and thoroughly generalize
the research progress and technical details. Additionally, we systematically
analyze the research status of KD in vision applications. Finally, we discuss
the potentials and open challenges of existing methods and prospect the future
directions of KD and S-T learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Indian Masked Faces in the Wild Dataset. (arXiv:2106.09670v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Shiksha Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_P/0/1/0/all/0/1">Puspita Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Richa Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatsa_M/0/1/0/all/0/1">Mayank Vatsa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09670">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the COVID-19 pandemic, wearing face masks has become a mandate in
public places worldwide. Face masks occlude a significant portion of the facial
region. Additionally, people wear different types of masks, from simple ones to
ones with graphics and prints. These pose new challenges to face recognition
algorithms. Researchers have recently proposed a few masked face datasets for
designing algorithms to overcome the challenges of masked face recognition.
However, existing datasets lack the cultural diversity and collection in the
unrestricted settings. Country like India with attire diversity, people are not
limited to wearing traditional masks but also clothing like a thin cotton
printed towel (locally called as &#x60;&#x60;gamcha&#x27;&#x27;), &#x60;&#x60;stoles&#x27;&#x27;, and &#x60;&#x60;handkerchiefs&#x27;&#x27;
to cover their faces. In this paper, we present a novel \textbf{Indian Masked
Faces in the Wild (IMFW)} dataset which contains images with variations in
pose, illumination, resolution, and the variety of masks worn by the subjects.
We have also benchmarked the performance of existing face recognition models on
the proposed IMFW dataset. Experimental results demonstrate the limitations of
existing algorithms in presence of diverse conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MoDist: Motion Distillation for Self-supervised Video Representation Learning. (arXiv:2106.09703v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1">Fanyi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tighe_J/0/1/0/all/0/1">Joseph Tighe</a>, <a href="http://arxiv.org/find/cs/1/au:+Modolo_D/0/1/0/all/0/1">Davide Modolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09703">
                                    <div class="article-summary-box-inner">
                                        <span>We present MoDist as a novel method to explicitly distill motion information
into self-supervised video representations. Compared to previous video
representation learning methods that mostly focus on learning motion cues
implicitly from RGB inputs, we show that the representation learned with our
MoDist method focus more on foreground motion regions and thus generalizes
better to downstream tasks. To achieve this, MoDist enriches standard
contrastive learning objectives for RGB video clips with a cross-modal learning
objective between a Motion pathway and a Visual pathway. We evaluate MoDist on
several datasets for both action recognition (UCF101/HMDB51/SSv2) as well as
action detection (AVA), and demonstrate state-of-the-art self-supervised
performance on all datasets. Furthermore, we show that MoDist representation
can be as effective as (in some cases even better than) representations learned
with full supervision. Given its simplicity, we hope MoDist could serve as a
strong baseline for future research in self-supervised video representation
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies. (arXiv:2106.09678v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Linxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">De-An Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09678">
                                    <div class="article-summary-box-inner">
                                        <span>Generalization has been a long-standing challenge for reinforcement learning
(RL). Visual RL, in particular, can be easily distracted by irrelevant factors
in high-dimensional observation space. In this work, we consider robust policy
learning which targets zero-shot generalization to unseen visual environments
with large distributional shift. We propose SECANT, a novel self-expert cloning
technique that leverages image augmentation in two stages to decouple robust
representation learning from policy optimization. Specifically, an expert
policy is first trained by RL from scratch with weak augmentations. A student
network then learns to mimic the expert policy by supervised learning with
strong augmentations, making its representation more robust against visual
variations compared to the expert. Extensive experiments demonstrate that
SECANT significantly advances the state of the art in zero-shot generalization
across 4 challenging domains. Our average reward improvements over prior SOTAs
are: DeepMind Control (+26.5%), robotic manipulation (+337.8%), vision-based
autonomous driving (+47.7%), and indoor object navigation (+15.8%). Code
release and video are available at https://linxifan.github.io/secant-site/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale-Consistent Fusion: from Heterogeneous Local Sampling to Global Immersive Rendering. (arXiv:2106.09548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_W/0/1/0/all/0/1">Wenpeng Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zaifeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09548">
                                    <div class="article-summary-box-inner">
                                        <span>Image-based geometric modeling and novel view synthesis based on sparse,
large-baseline samplings are challenging but important tasks for emerging
multimedia applications such as virtual reality and immersive telepresence.
Existing methods fail to produce satisfactory results due to the limitation on
inferring reliable depth information over such challenging reference
conditions. With the popularization of commercial light field (LF) cameras,
capturing LF images (LFIs) is as convenient as taking regular photos, and
geometry information can be reliably inferred. This inspires us to use a sparse
set of LF captures to render high-quality novel views globally. However, fusion
of LF captures from multiple angles is challenging due to the scale
inconsistency caused by various capture settings. To overcome this challenge,
we propose a novel scale-consistent volume rescaling algorithm that robustly
aligns the disparity probability volumes (DPV) among different captures for
scale-consistent global geometry fusion. Based on the fused DPV projected to
the target camera frustum, novel learning-based modules have been proposed
(i.e., the attention-guided multi-scale residual fusion module, and the
disparity field guided deep re-regularization module) which comprehensively
regularize noisy observations from heterogeneous captures for high-quality
rendering of novel LFIs. Both quantitative and qualitative experiments over the
Stanford Lytro Multi-view LF dataset show that the proposed method outperforms
state-of-the-art methods significantly under different experiment settings for
disparity inference and LF synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The 2021 Image Similarity Dataset and Challenge. (arXiv:2106.09672v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolias_G/0/1/0/all/0/1">Giorgos Tolias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pizzi_E/0/1/0/all/0/1">Ed Pizzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papakipos_Z/0/1/0/all/0/1">Zo&#xeb; Papakipos</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_L/0/1/0/all/0/1">Lowik Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Radenovic_F/0/1/0/all/0/1">Filip Radenovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenicek_T/0/1/0/all/0/1">Tomas Jenicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Maximov_M/0/1/0/all/0/1">Maxim Maximov</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1">Ismail Elezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chum_O/0/1/0/all/0/1">Ond&#x159;ej Chum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09672">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a new benchmark for large-scale image similarity
detection. This benchmark is used for the Image Similarity Challenge at
NeurIPS&#x27;21 (ISC2021). The goal is to determine whether a query image is a
modified copy of any image in a reference corpus of size 1~million. The
benchmark features a variety of image transformations such as automated
transformations, hand-crafted image edits and machine-learning based
manipulations. This mimics real-life cases appearing in social media, for
example for integrity-related problems dealing with misinformation and
objectionable content. The strength of the image manipulations, and therefore
the difficulty of the benchmark, is calibrated according to the performance of
a set of baseline approaches. Both the query and reference set contain a
majority of &#x60;&#x60;distractor&#x27;&#x27; images that do not match, which corresponds to a
real-life needle-in-haystack setting, and the evaluation metric reflects that.
We expect the DISC21 benchmark to promote image copy detection as an important
and challenging computer vision task and refresh the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Few-Shot Learning: Clustering is All You Need?. (arXiv:2106.09516v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziko_I/0/1/0/all/0/1">Imtiaz Masud Ziko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1">Malik Boudiaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09516">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate a general formulation for clustering and transductive few-shot
learning, which integrates prototype-based objectives, Laplacian regularization
and supervision constraints from a few labeled data points. We propose a
concave-convex relaxation of the problem, and derive a computationally
efficient block-coordinate bound optimizer, with convergence guarantee. At each
iteration,our optimizer computes independent (parallel) updates for each
point-to-cluster assignment. Therefore, it could be trivially distributed for
large-scale clustering and few-shot tasks. Furthermore, we provides a thorough
convergence analysis based on point-to-set maps. Were port comprehensive
clustering and few-shot learning experiments over various data sets, showing
that our method yields competitive performances, in term of accuracy and
optimization quality, while scaling up to large problems. Using standard
training on the base classes, without resorting to complex meta-learning and
episodic-training strategies, our approach outperforms state-of-the-art
few-shot methods by significant margins, across various models, settings and
data sets. Surprisingly, we found that even standard clustering procedures
(e.g., K-means), which correspond to particular, non-regularized cases of our
general model, already achieve competitive performances in comparison to the
state-of-the-art in few-shot learning. These surprising results point to the
limitations of the current few-shot benchmarks, and question the viability of a
large body of convoluted few-shot learning techniques in the recent literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Associate Every Segment for Video Panoptic Segmentation. (arXiv:2106.09453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sanghyun Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dahun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joon-Young Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09453">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal correspondence - linking pixels or objects across frames - is a
fundamental supervisory signal for the video models. For the panoptic
understanding of dynamic scenes, we further extend this concept to every
segment. Specifically, we aim to learn coarse segment-level matching and fine
pixel-level matching together. We implement this idea by designing two novel
learning objectives. To validate our proposals, we adopt a deep siamese model
and train the model to learn the temporal correspondence on two different
levels (i.e., segment and pixel) along with the target task. At inference time,
the model processes each frame independently without any extra computation and
post-processing. We show that our per-frame inference model can achieve new
state-of-the-art results on Cityscapes-VPS and VIPER datasets. Moreover, due to
its high efficiency, the model runs in a fraction of time (3x) compared to the
previous state-of-the-art approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving On-Screen Sound Separation for Open Domain Videos with Audio-Visual Self-attention. (arXiv:2106.09669v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1">Efthymios Tzinis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wisdom_S/0/1/0/all/0/1">Scott Wisdom</a>, <a href="http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1">Tal Remez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershey_J/0/1/0/all/0/1">John R. Hershey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09669">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a state-of-the-art audio-visual on-screen sound separation
system which is capable of learning to separate sounds and associate them with
on-screen objects by looking at in-the-wild videos. We identify limitations of
previous work on audiovisual on-screen sound separation, including the
simplicity and coarse resolution of spatio-temporal attention, and poor
convergence of the audio separation model. Our proposed model addresses these
issues using cross-modal and self-attention modules that capture audio-visual
dependencies at a finer resolution over time, and by unsupervised pre-training
of audio separation model. These improvements allow the model to generalize to
a much wider set of unseen videos. For evaluation and semi-supervised training,
we collected human annotations of on-screen audio from a large database of
in-the-wild videos (YFCC100M). Our results show marked improvements in
on-screen separation performance, in more general conditions than previous
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Segmentation of the Prostate on 3D Trans-rectal Ultrasound Images using Statistical Shape Models and Convolutional Neural Networks. (arXiv:2106.09662v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Samei_G/0/1/0/all/0/1">Golnoosh Samei</a>, <a href="http://arxiv.org/find/eess/1/au:+Karimi_D/0/1/0/all/0/1">Davood Karimi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kesch_C/0/1/0/all/0/1">Claudia Kesch</a>, <a href="http://arxiv.org/find/eess/1/au:+Salcudean_S/0/1/0/all/0/1">Septimiu Salcudean</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09662">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we propose to segment the prostate on a challenging dataset of
trans-rectal ultrasound (TRUS) images using convolutional neural networks
(CNNs) and statistical shape models (SSMs). TRUS is commonly used for a number
of image-guided interventions on the prostate. Fast and accurate segmentation
on the organ in these images is crucial to planning and fusion with other
modalities such as magnetic resonance images (MRIs) . However, TRUS has limited
soft tissue contrast and signal to noise ratio which makes the task of
segmenting the prostate challenging and subject to inter-observer and
intra-observer variability. This is especially problematic at the base and apex
where the gland boundary is hard to define. In this paper, we aim to tackle
this problem by taking advantage of shape priors learnt on an MR dataset which
has higher soft tissue contrast allowing the prostate to be contoured more
accurately. We use this shape prior in combination with a prostate tissue
probability map computed by a CNN for segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seesaw Loss for Long-Tailed Instance Segmentation. (arXiv:2008.10032v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1">Yuhang Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yuhang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_T/0/1/0/all/0/1">Tao Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10032">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation has witnessed a remarkable progress on class-balanced
benchmarks. However, they fail to perform as accurately in real-world
scenarios, where the category distribution of objects naturally comes with a
long tail. Instances of head classes dominate a long-tailed dataset and they
serve as negative samples of tail categories. The overwhelming gradients of
negative samples on tail classes lead to a biased learning process for
classifiers. Consequently, objects of tail categories are more likely to be
misclassified as backgrounds or head categories. To tackle this problem, we
propose Seesaw Loss to dynamically re-balance gradients of positive and
negative samples for each category, with two complementary factors, i.e.,
mitigation factor and compensation factor. The mitigation factor reduces
punishments to tail categories w.r.t. the ratio of cumulative training
instances between different categories. Meanwhile, the compensation factor
increases the penalty of misclassified instances to avoid false positives of
tail categories. We conduct extensive experiments on Seesaw Loss with
mainstream frameworks and different data sampling strategies. With a simple
end-to-end training pipeline, Seesaw Loss obtains significant gains over
Cross-Entropy Loss, and achieves state-of-the-art performance on LVIS dataset
without bells and whistles. Code is available at
https://github.com/open-mmlab/mmdetection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep HDR Hallucination for Inverse Tone Mapping. (arXiv:2106.09486v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marnerides_D/0/1/0/all/0/1">Demetris Marnerides</a>, <a href="http://arxiv.org/find/cs/1/au:+Bashford_Rogers_T/0/1/0/all/0/1">Thomas Bashford-Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Debattista_K/0/1/0/all/0/1">Kurt Debattista</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09486">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse Tone Mapping (ITM) methods attempt to reconstruct High Dynamic Range
(HDR) information from Low Dynamic Range (LDR) image content. The dynamic range
of well-exposed areas must be expanded and any missing information due to
over/under-exposure must be recovered (hallucinated). The majority of methods
focus on the former and are relatively successful, while most attempts on the
latter are not of sufficient quality, even ones based on Convolutional Neural
Networks (CNNs). A major factor for the reduced inpainting quality in some
works is the choice of loss function. Work based on Generative Adversarial
Networks (GANs) shows promising results for image synthesis and LDR inpainting,
suggesting that GAN losses can improve inverse tone mapping results. This work
presents a GAN-based method that hallucinates missing information from badly
exposed areas in LDR images and compares its efficacy with alternative
variations. The proposed method is quantitatively competitive with
state-of-the-art inverse tone mapping methods, providing good dynamic range
expansion for well-exposed areas and plausible hallucinations for saturated and
under-exposed areas. A density-based normalisation method, targeted for HDR
content, is also proposed, as well as an HDR data augmentation method targeted
for HDR hallucination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Predict Visual Attributes in the Wild. (arXiv:2106.09707v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pham_K/0/1/0/all/0/1">Khoi Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Kafle_K/0/1/0/all/0/1">Kushal Kafle</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhihong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Scott Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_Q/0/1/0/all/0/1">Quan Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Abhinav Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09707">
                                    <div class="article-summary-box-inner">
                                        <span>Visual attributes constitute a large portion of information contained in a
scene. Objects can be described using a wide variety of attributes which
portray their visual appearance (color, texture), geometry (shape, size,
posture), and other intrinsic properties (state, action). Existing work is
mostly limited to study of attribute prediction in specific domains. In this
paper, we introduce a large-scale in-the-wild visual attribute prediction
dataset consisting of over 927K attribute annotations for over 260K object
instances. Formally, object attribute prediction is a multi-label
classification problem where all attributes that apply to an object must be
predicted. Our dataset poses significant challenges to existing methods due to
large number of attributes, label sparsity, data imbalance, and object
occlusion. To this end, we propose several techniques that systematically
tackle these challenges, including a base model that utilizes both low- and
high-level CNN features with multi-hop attention, reweighting and resampling
techniques, a novel negative label expansion scheme, and a novel supervised
attribute-aware contrastive learning algorithm. Using these techniques, we
achieve near 3.7 mAP and 5.7 overall F1 points improvement over the current
state of the art. Further details about the VAW dataset can be found at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Anytime Learning at Macroscale. (arXiv:2106.09563v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ott_M/0/1/0/all/0/1">Myle Ott</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranzato_M/0/1/0/all/0/1">Marc&#x27;Aurelio Ranzato</a>, <a href="http://arxiv.org/find/cs/1/au:+Denoyer_L/0/1/0/all/0/1">Ludovic Denoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09563">
                                    <div class="article-summary-box-inner">
                                        <span>Classical machine learning frameworks assume access to a possibly large
dataset in order to train a predictive model. In many practical applications
however, data does not arrive all at once, but in batches over time. This
creates a natural trade-off between accuracy of a model and time to obtain such
a model. A greedy predictor could produce non-trivial predictions by
immediately training on batches as soon as these become available but, it may
also make sub-optimal use of future data. On the other hand, a tardy predictor
could wait for a long time to aggregate several batches into a larger dataset,
but ultimately deliver a much better performance. In this work, we consider
such a streaming learning setting, which we dub {\em anytime learning at
macroscale} (ALMA). It is an instance of anytime learning applied not at the
level of a single chunk of data, but at the level of the entire sequence of
large batches. We first formalize this learning setting, we then introduce
metrics to assess how well learners perform on the given task for a given
memory and compute budget, and finally we test several baseline approaches on
standard benchmarks repurposed for anytime learning at macroscale. The general
finding is that bigger models always generalize better. In particular, it is
important to grow model capacity over time if the initial model is relatively
small. Moreover, updating the model at an intermediate rate strikes the best
trade off between accuracy and time to obtain a useful predictor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Visual Robustness by Causal Intervention. (arXiv:2106.09534v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Kaihua Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1">Mingyuan Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanwang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09534">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is the de facto most promising defense against
adversarial examples. Yet, its passive nature inevitably prevents it from being
immune to unknown attackers. To achieve a proactive defense, we need a more
fundamental understanding of adversarial examples, beyond the popular bounded
threat model. In this paper, we provide a causal viewpoint of adversarial
vulnerability: the cause is the confounder ubiquitously existing in learning,
where attackers are precisely exploiting the confounding effect. Therefore, a
fundamental solution for adversarial robustness is causal intervention. As the
confounder is unobserved in general, we propose to use the instrumental
variable that achieves intervention without the need for confounder
observation. We term our robust training method as Causal intervention by
instrumental Variable (CiiV). It has a differentiable retinotopic sampling
layer and a consistency loss, which is stable and guaranteed not to suffer from
gradient obfuscation. Extensive experiments on a wide spectrum of attackers and
settings applied in MNIST, CIFAR-10, and mini-ImageNet datasets empirically
demonstrate that CiiV is robust to adaptive attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To fit or not to fit: Model-based Face Reconstruction and Occlusion Segmentation from Weak Supervision. (arXiv:2106.09614v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunlu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Morel_Forster_A/0/1/0/all/0/1">Andreas Morel-Forster</a>, <a href="http://arxiv.org/find/cs/1/au:+Vetter_T/0/1/0/all/0/1">Thomas Vetter</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_B/0/1/0/all/0/1">Bernhard Egger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kortylewski_A/0/1/0/all/0/1">Adam Kortylewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09614">
                                    <div class="article-summary-box-inner">
                                        <span>3D face reconstruction from a single image is challenging due to its
ill-posed nature. Model-based face autoencoders address this issue effectively
by fitting a face model to the target image in a weakly supervised manner.
However, in unconstrained environments occlusions distort the face
reconstruction because the model often erroneously tries to adapt to occluded
face regions. Supervised occlusion segmentation is a viable solution to avoid
the fitting of occluded face regions, but it requires a large amount of
annotated training data. In this work, we enable model-based face autoencoders
to segment occluders accurately without requiring any additional supervision
during training, and this separates regions where the model will be fitted from
those where it will not be fitted. To achieve this, we extend face autoencoders
with a segmentation network. The segmentation network decides which regions the
model should adapt to by reaching balances in a trade-off between including
pixels and adapting the model to them, and excluding pixels so that the model
fitting is not negatively affected and reaches higher overall reconstruction
accuracy on pixels showing the face. This leads to a synergistic effect, in
which the occlusion segmentation guides the training of the face autoencoder to
constrain the fitting in the non-occluded regions, while the improved fitting
enables the segmentation model to better predict the occluded face regions.
Qualitative and quantitative experiments on the CelebA-HQ database and the AR
database verify the effectiveness of our model in improving 3D face
reconstruction under occlusions and in enabling accurate occlusion segmentation
from weak supervision only. Code available at
https://github.com/unibas-gravis/Occlusion-Robust-MoFA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition. (arXiv:2106.09637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barros_T/0/1/0/all/0/1">Tiago Barros</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrote_L/0/1/0/all/0/1">Lu&#xed;s Garrote</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1">Ricardo Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Premebida_C/0/1/0/all/0/1">Cristiano Premebida</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunes_U/0/1/0/all/0/1">Urbano J. Nunes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09637">
                                    <div class="article-summary-box-inner">
                                        <span>Deep networks have been progressively adapted to new sensor modalities,
namely to 3D LiDAR, which led to unprecedented achievements in autonomous
vehicle-related applications such as place recognition. One of the main
challenges of deep models in place recognition is to extract efficient and
descriptive feature representations that relate places based on their
similarity. To address the problem of place recognition using LiDAR data, this
paper proposes a novel 3D LiDAR-based deep learning network (named AttDLNet)
that comprises an encoder network and exploits an attention mechanism to
selectively focus on long-range context and interfeature relationships. The
proposed network is trained and validated on the KITTI dataset, using the
cosine loss for training and a retrieval-based place recognition pipeline for
validation. Additionally, an ablation study is presented to assess the best
network configuration. Results show that the encoder network features are
already very descriptive, but adding attention to the network further improves
performance. From the ablation study, results indicate that the middle encoder
layers have the highest mean performance, while deeper layers are more robust
to orientation change. The code is publicly available on the project website:
https://github.com/Cybonic/ AttDLNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Knowledge Distillation with A Single Stream Structure for RGB-DSalient Object Detection. (arXiv:2106.09517v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1">Guangyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1">Tania Stathaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09517">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-D salient object detection(SOD) demonstrates its superiority on detecting
in complex environments due to the additional depth information introduced in
the data. Inevitably, an independent stream is introduced to extract features
from depth images, leading to extra computation and parameters. This
methodology which sacrifices the model size to improve the detection accuracy
may impede the practical application of SOD problems. To tackle this dilemma,
we propose a dynamic distillation method along with a lightweight framework,
which significantly reduces the parameters. This method considers the factors
of both teacher and student performance within the training stage and
dynamically assigns the distillation weight instead of applying a fixed weight
on the student model. Extensive experiments are conducted on five public
datasets to demonstrate that our method can achieve competitive performance
compared to 10 prior methods through a 78.2MB lightweight structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal-Pad\&#x27;e Activation Functions: Trainable Activation functions for smooth and faster convergence in deep networks. (arXiv:2106.09693v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_K/0/1/0/all/0/1">Koushik Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Shilpak Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ashish Kumar Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09693">
                                    <div class="article-summary-box-inner">
                                        <span>We have proposed orthogonal-Pad\&#x27;e activation functions, which are trainable
activation functions and show that they have faster learning capability and
improves the accuracy in standard deep learning datasets and models. Based on
our experiments, we have found two best candidates out of six orthogonal-Pad\&#x27;e
activations, which we call safe Hermite-Pade (HP) activation functions, namely
HP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1
accuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%
respectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset
top-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by
2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in
Efficientnet B0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge distillation from multi-modal to mono-modal segmentation networks. (arXiv:2106.09564v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Minhao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Maillard_M/0/1/0/all/0/1">Matthis Maillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciceri_T/0/1/0/all/0/1">Tommaso Ciceri</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbera_G/0/1/0/all/0/1">Giammarco La Barbera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09564">
                                    <div class="article-summary-box-inner">
                                        <span>The joint use of multiple imaging modalities for medical image segmentation
has been widely studied in recent years. The fusion of information from
different modalities has demonstrated to improve the segmentation accuracy,
with respect to mono-modal segmentations, in several applications. However,
acquiring multiple modalities is usually not possible in a clinical setting due
to a limited number of physicians and scanners, and to limit costs and scan
time. Most of the time, only one modality is acquired. In this paper, we
propose KD-Net, a framework to transfer knowledge from a trained multi-modal
network (teacher) to a mono-modal one (student). The proposed method is an
adaptation of the generalized distillation framework where the student network
is trained on a subset (1 modality) of the teacher&#x27;s inputs (n modalities). We
illustrate the effectiveness of the proposed framework in brain tumor
segmentation with the BraTS 2018 dataset. Using different architectures, we
show that the student network effectively learns from the teacher and always
outperforms the baseline mono-modal network in terms of segmentation accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JOKR: Joint Keypoint Representation for Unsupervised Cross-Domain Motion Retargeting. (arXiv:2106.09679v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mokady_R/0/1/0/all/0/1">Ron Mokady</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzaban_R/0/1/0/all/0/1">Rotem Tzaban</a>, <a href="http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1">Sagie Benaim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1">Amit H. Bermano</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09679">
                                    <div class="article-summary-box-inner">
                                        <span>The task of unsupervised motion retargeting in videos has seen substantial
advancements through the use of deep neural networks. While early works
concentrated on specific object priors such as a human face or body, recent
work considered the unsupervised case. When the source and target videos,
however, are of different shapes, current methods fail. To alleviate this
problem, we introduce JOKR - a JOint Keypoint Representation that captures the
motion common to both the source and target videos, without requiring any
object prior or data collection. By employing a domain confusion term, we
enforce the unsupervised keypoint representations of both videos to be
indistinguishable. This encourages disentanglement between the parts of the
motion that are common to the two domains, and their distinctive appearance and
motion, enabling the generation of videos that capture the motion of the one
while depicting the style of the other. To enable cases where the objects are
of different proportions or orientations, we apply a learned affine
transformation between the JOKRs. This augments the representation to be affine
invariant, and in practice broadens the variety of possible retargeting pairs.
This geometry-driven representation enables further intuitive control, such as
temporal coherence and manual editing. Through comprehensive experimentation,
we demonstrate the applicability of our method to different challenging
cross-domain video pairs. We evaluate our method both qualitatively and
quantitatively, and demonstrate that our method handles various cross-domain
scenarios, such as different animals, different flowers, and humans. We also
demonstrate superior temporal coherency and visual quality compared to
state-of-the-art alternatives, through statistical metrics and a user study.
Source code and videos can be found at https://rmokady.github.io/JOKR/ .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Eye-tracking Using Deep Learning. (arXiv:2106.09621v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seyedi_S/0/1/0/all/0/1">Salman Seyedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zifan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Levey_A/0/1/0/all/0/1">Allan Levey</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_G/0/1/0/all/0/1">Gari D. Clifford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09621">
                                    <div class="article-summary-box-inner">
                                        <span>The expanding usage of complex machine learning methods like deep learning
has led to an explosion in human activity recognition, particularly applied to
health. In particular, as part of a larger body sensor network system, face and
full-body analysis is becoming increasingly common for evaluating health
status. However, complex models which handle private and sometimes protected
data, raise concerns about the potential leak of identifiable data. In this
work, we focus on the case of a deep network model trained on images of
individual faces. Full-face video recordings taken from 493 individuals
undergoing an eye-tracking based evaluation of neurological function were used.
Outputs, gradients, intermediate layer outputs, loss, and labels were used as
inputs for a deep network with an added support vector machine emission layer
to recognize membership in the training data. The inference attack method and
associated mathematical analysis indicate that there is a low likelihood of
unintended memorization of facial features in the deep learning model. In this
study, it is showed that the named model preserves the integrity of training
data with reasonable confidence. The same process can be implemented in similar
conditions for different models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Autoregressive Transformer for Image Captioning. (arXiv:2106.09436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuanen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhenzhen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09436">
                                    <div class="article-summary-box-inner">
                                        <span>Current state-of-the-art image captioning models adopt autoregressive
decoders, \ie they generate each word by conditioning on previously generated
words, which leads to heavy latency during inference. To tackle this issue,
non-autoregressive image captioning models have recently been proposed to
significantly accelerate the speed of inference by generating all words in
parallel. However, these non-autoregressive models inevitably suffer from large
generation quality degradation since they remove words dependence excessively.
To make a better trade-off between speed and quality, we introduce a
semi-autoregressive model for image captioning~(dubbed as SATIC), which keeps
the autoregressive property in global but generates words parallelly in local.
Based on Transformer, there are only a few modifications needed to implement
SATIC. Extensive experiments on the MSCOCO image captioning benchmark show that
SATIC can achieve a better trade-off without bells and whistles. Code is
available at {\color{magenta}\url{https://github.com/YuanEZhou/satic}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One Go. (arXiv:2106.09431v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eisenberger_M/0/1/0/all/0/1">Marvin Eisenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Novotny_D/0/1/0/all/0/1">David Novotny</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerchenbaum_G/0/1/0/all/0/1">Gael Kerchenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Labatut_P/0/1/0/all/0/1">Patrick Labatut</a>, <a href="http://arxiv.org/find/cs/1/au:+Neverova_N/0/1/0/all/0/1">Natalia Neverova</a>, <a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1">Daniel Cremers</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1">Andrea Vedaldi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09431">
                                    <div class="article-summary-box-inner">
                                        <span>We present NeuroMorph, a new neural network architecture that takes as input
two 3D shapes and produces in one go, i.e. in a single feed forward pass, a
smooth interpolation and point-to-point correspondences between them. The
interpolation, expressed as a deformation field, changes the pose of the source
shape to resemble the target, but leaves the object identity unchanged.
NeuroMorph uses an elegant architecture combining graph convolutions with
global feature pooling to extract local features. During training, the model is
incentivized to create realistic deformations by approximating geodesics on the
underlying shape space manifold. This strong geometric prior allows to train
our model end-to-end and in a fully unsupervised manner without requiring any
manual correspondence annotations. NeuroMorph works well for a large variety of
input shapes, including non-isometric pairs from different object categories.
It obtains state-of-the-art results for both shape correspondence and
interpolation tasks, matching or surpassing the performance of recent
unsupervised and supervised methods on multiple benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class Balancing GAN with a Classifier in the Loop. (arXiv:2106.09402v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangwani_H/0/1/0/all/0/1">Harsh Rangwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1">R. Venkatesh Babu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09402">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have swiftly evolved to imitate
increasingly complex image distributions. However, majority of the developments
focus on performance of GANs on balanced datasets. We find that the existing
GANs and their training regimes which work well on balanced datasets fail to be
effective in case of imbalanced (i.e. long-tailed) datasets. In this work we
introduce a novel theoretically motivated Class Balancing regularizer for
training GANs. Our regularizer makes use of the knowledge from a pre-trained
classifier to ensure balanced learning of all the classes in the dataset. This
is achieved via modelling the effective class frequency based on the
exponential forgetting observed in neural networks and encouraging the GAN to
focus on underrepresented classes. We demonstrate the utility of our
regularizer in learning representations for long-tailed distributions via
achieving better performance than existing approaches over multiple datasets.
Specifically, when applied to an unconditional GAN, it improves the FID from
$13.03$ to $9.01$ on the long-tailed iNaturalist-$2019$ dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Perceptual Manifold of Fonts. (arXiv:2106.09198v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Haoran Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujita_Y/0/1/0/all/0/1">Yuki Fujita</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyata_K/0/1/0/all/0/1">Kazunori Miyata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09198">
                                    <div class="article-summary-box-inner">
                                        <span>Along the rapid development of deep learning techniques in generative models,
it is becoming an urgent issue to combine machine intelligence with human
intelligence to solve the practical applications. Motivated by this
methodology, this work aims to adjust the machine generated character fonts
with the effort of human workers in the perception study. Although numerous
fonts are available online for public usage, it is difficult and challenging to
generate and explore a font to meet the preferences for common users. To solve
the specific issue, we propose the perceptual manifold of fonts to visualize
the perceptual adjustment in the latent space of a generative model of fonts.
In our framework, we adopt the variational autoencoder network for the font
generation. Then, we conduct a perceptual study on the generated fonts from the
multi-dimensional latent space of the generative model. After we obtained the
distribution data of specific preferences, we utilize manifold learning
approach to visualize the font distribution. In contrast to the conventional
user interface in our user study, the proposed font-exploring user interface is
efficient and helpful in the designated user preference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Main Character Recognition for Photographic Studies. (arXiv:2106.09064v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1">Mert Seker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1">Anssi M&#xe4;nnist&#xf6;</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09064">
                                    <div class="article-summary-box-inner">
                                        <span>Main characters in images are the most important humans that catch the
viewer&#x27;s attention upon first look, and they are emphasized by properties such
as size, position, color saturation, and sharpness of focus. Identifying the
main character in images plays an important role in traditional photographic
studies and media analysis, but the task is performed manually and can be slow
and laborious. Furthermore, selection of main characters can be sometimes
subjective. In this paper, we analyze the feasibility of solving the main
character recognition needed for photographic studies automatically and propose
a method for identifying the main characters. The proposed method uses machine
learning based human pose estimation along with traditional computer vision
approaches for this task. We approach the task as a binary classification
problem where each detected human is classified either as a main character or
not. To evaluate both the subjectivity of the task and the performance of our
method, we collected a dataset of 300 varying images from multiple sources and
asked five people, a photographic researcher and four other persons, to
annotate the main characters. Our analysis showed a relatively high agreement
between different annotators. The proposed method achieved a promising F1 score
of 0.83 on the full image set and 0.96 on a subset evaluated as most clear and
important cases by the photographic researcher.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">using multiple losses for accurate facial age estimation. (arXiv:2106.09393v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huttunen_H/0/1/0/all/0/1">Heikki Huttunen</a>, <a href="http://arxiv.org/find/cs/1/au:+Elomaa_T/0/1/0/all/0/1">Tapio Elomaa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09393">
                                    <div class="article-summary-box-inner">
                                        <span>Age estimation is an essential challenge in computer vision. With the
advances of convolutional neural networks, the performance of age estimation
has been dramatically improved. Existing approaches usually treat age
estimation as a classification problem. However, the age labels are ambiguous,
thus make the classification task difficult. In this paper, we propose a simple
yet effective approach for age estimation, which improves the performance
compared to classification-based methods. The method combines four
classification losses and one regression loss representing different class
granularities together, and we name it as Age-Granularity-Net. We validate the
Age-Granularity-Net framework on the CVPR Chalearn 2016 dataset, and extensive
experiments show that the proposed approach can reduce the prediction error
compared to any individual loss. The source code link is
https://github.com/yipersevere/age-estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Training Data Generation of Handwritten Formulas using Generative Adversarial Networks with Self-Attention. (arXiv:2106.09432v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Springstein_M/0/1/0/all/0/1">Matthias Springstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1">Eric M&#xfc;ller-Budack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09432">
                                    <div class="article-summary-box-inner">
                                        <span>The recognition of handwritten mathematical expressions in images and video
frames is a difficult and unsolved problem yet. Deep convectional neural
networks are basically a promising approach, but typically require a large
amount of labeled training data. However, such a large training dataset does
not exist for the task of handwritten formula recognition. In this paper, we
introduce a system that creates a large set of synthesized training examples of
mathematical expressions which are derived from LaTeX documents. For this
purpose, we propose a novel attention-based generative adversarial network to
translate rendered equations to handwritten formulas. The datasets generated by
this approach contain hundreds of thousands of formulas, making it ideal for
pretraining or the design of more complex models. We evaluate our synthesized
dataset and the recognition approach on the CROHME 2014 benchmark dataset.
Experimental results demonstrate the feasibility of the approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Dark Side of Calibration for Modern Neural Networks. (arXiv:2106.09385v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Aditya Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bay_A/0/1/0/all/0/1">Alessandro Bay</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_B/0/1/0/all/0/1">Biswa Sengupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirabile_A/0/1/0/all/0/1">Andrea Mirabile</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09385">
                                    <div class="article-summary-box-inner">
                                        <span>Modern neural networks are highly uncalibrated. It poses a significant
challenge for safety-critical systems to utilise deep neural networks (DNNs),
reliably. Many recently proposed approaches have demonstrated substantial
progress in improving DNN calibration. However, they hardly touch upon
refinement, which historically has been an essential aspect of calibration.
Refinement indicates separability of a network&#x27;s correct and incorrect
predictions. This paper presents a theoretically and empirically supported
exposition for reviewing a model&#x27;s calibration and refinement. Firstly, we show
the breakdown of expected calibration error (ECE), into predicted confidence
and refinement. Connecting with this result, we highlight that regularisation
based calibration only focuses on naively reducing a model&#x27;s confidence. This
logically has a severe downside to a model&#x27;s refinement. We support our claims
through rigorous empirical evaluations of many state of the art calibration
approaches on standard datasets. We find that many calibration approaches with
the likes of label smoothing, mixup etc. lower the utility of a DNN by
degrading its refinement. Even under natural data shift, this
calibration-refinement trade-off holds for the majority of calibration methods.
These findings call for an urgent retrospective into some popular pathways
taken for modern DNN calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Subdomain Adaptation Network for Image Classification. (arXiv:2106.09388v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yongchun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1">Fuzhen Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1">Guolin Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingwu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qing He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09388">
                                    <div class="article-summary-box-inner">
                                        <span>For a target task where labeled data is unavailable, domain adaptation can
transfer a learner from a different source domain. Previous deep domain
adaptation methods mainly learn a global domain shift, i.e., align the global
source and target distributions without considering the relationships between
two subdomains within the same category of different domains, leading to
unsatisfying transfer learning performance without capturing the fine-grained
information. Recently, more and more researchers pay attention to Subdomain
Adaptation which focuses on accurately aligning the distributions of the
relevant subdomains. However, most of them are adversarial methods which
contain several loss functions and converge slowly. Based on this, we present
Deep Subdomain Adaptation Network (DSAN) which learns a transfer network by
aligning the relevant subdomain distributions of domain-specific layer
activations across different domains based on a local maximum mean discrepancy
(LMMD). Our DSAN is very simple but effective which does not need adversarial
training and converges fast. The adaptation can be achieved easily with most
feed-forward network models by extending them with LMMD loss, which can be
trained efficiently via back-propagation. Experiments demonstrate that DSAN can
achieve remarkable results on both object recognition tasks and digit
classification tasks. Our code will be available at:
https://github.com/easezyc/deep-transfer-learning</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Localized Uncertainty Attacks. (arXiv:2106.09222v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dia_O/0/1/0/all/0/1">Ousmane Amadou Dia</a>, <a href="http://arxiv.org/find/stat/1/au:+Karaletsos_T/0/1/0/all/0/1">Theofanis Karaletsos</a>, <a href="http://arxiv.org/find/stat/1/au:+Hazirbas_C/0/1/0/all/0/1">Caner Hazirbas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>, <a href="http://arxiv.org/find/stat/1/au:+Kabul_I/0/1/0/all/0/1">Ilknur Kaynar Kabul</a>, <a href="http://arxiv.org/find/stat/1/au:+Meijer_E/0/1/0/all/0/1">Erik Meijer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09222">
                                    <div class="article-summary-box-inner">
                                        <span>The susceptibility of deep learning models to adversarial perturbations has
stirred renewed attention in adversarial examples resulting in a number of
attacks. However, most of these attacks fail to encompass a large spectrum of
adversarial perturbations that are imperceptible to humans. In this paper, we
present localized uncertainty attacks, a novel class of threat models against
deterministic and stochastic classifiers. Under this threat model, we create
adversarial examples by perturbing only regions in the inputs where a
classifier is uncertain. To find such regions, we utilize the predictive
uncertainty of the classifier when the classifier is stochastic or, we learn a
surrogate model to amortize the uncertainty when it is deterministic. Unlike
$\ell_p$ ball or functional attacks which perturb inputs indiscriminately, our
targeted changes can be less perceptible. When considered under our threat
model, these attacks still produce strong adversarial examples; with the
examples retaining a greater degree of similarity with the inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Positional Contrastive Learning for VolumetricMedical Image Segmentation. (arXiv:2106.09157v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Dewen Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yawen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xinrong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaowei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Haiyun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Meiping Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jian Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jingtong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yiyu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09157">
                                    <div class="article-summary-box-inner">
                                        <span>The success of deep learning heavily depends on the availability of large
labeled training sets. However, it is hard to get large labeled datasets in
medical image domain because of the strict privacy concern and costly labeling
efforts. Contrastive learning, an unsupervised learning technique, has been
proved powerful in learning image-level representations from unlabeled data.
The learned encoder can then be transferred or fine-tuned to improve the
performance of downstream tasks with limited labels. A critical step in
contrastive learning is the generation of contrastive data pairs, which is
relatively simple for natural image classification but quite challenging for
medical image segmentation due to the existence of the same tissue or organ
across the dataset. As a result, when applied to medical image segmentation,
most state-of-the-art contrastive learning frameworks inevitably introduce a
lot of false-negative pairs and result in degraded segmentation quality. To
address this issue, we propose a novel positional contrastive learning (PCL)
framework to generate contrastive data pairs by leveraging the position
information in volumetric medical images. Experimental results on CT and MRI
datasets demonstrate that the proposed PCL method can substantially improve the
segmentation performance compared to existing methods in both semi-supervised
setting and transfer learning setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optical Mouse: 3D Mouse Pose From Single-View Video. (arXiv:2106.09251v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Seybold_B/0/1/0/all/0/1">Bryan Seybold</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1">David Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Sud_A/0/1/0/all/0/1">Avneesh Sud</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruby_G/0/1/0/all/0/1">Graham Ruby</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09251">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to infer the 3D pose of mice, including the limbs and
feet, from monocular videos. Many human clinical conditions and their
corresponding animal models result in abnormal motion, and accurately measuring
3D motion at scale offers insights into health. The 3D poses improve
classification of health-related attributes over 2D representations. The
inferred poses are accurate enough to estimate stride length even when the feet
are mostly occluded. This method could be applied as part of a continuous
monitoring system to non-invasively measure animal health.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wavelet-Packet Powered Deepfake Image Detection. (arXiv:2106.09369v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolter_M/0/1/0/all/0/1">Moritz Wolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanke_F/0/1/0/all/0/1">Felix Blanke</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoyt_C/0/1/0/all/0/1">Charles Tapley Hoyt</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcke_J/0/1/0/all/0/1">Jochen Garcke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09369">
                                    <div class="article-summary-box-inner">
                                        <span>As neural networks become more able to generate realistic artificial images,
they have the potential to improve movies, music, video games and make the
internet an even more creative and inspiring place. Yet, at the same time, the
latest technology potentially enables new digital ways to lie. In response, the
need for a diverse and reliable toolbox arises to identify artificial images
and other content. Previous work primarily relies on pixel-space CNN or the
Fourier transform. To the best of our knowledge, wavelet-based gan analysis and
detection methods have been absent thus far. This paper aims to fill this gap
and describes a wavelet-based approach to gan-generated image analysis and
detection. We evaluate our method on FFHQ, CelebA, and LSUN source
identification problems and find improved or competitive performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing Image-Language Transformers for Verb Understanding. (arXiv:2106.09141v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendricks_L/0/1/0/all/0/1">Lisa Anne Hendricks</a>, <a href="http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1">Aida Nematzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09141">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal image-language transformers have achieved impressive results on a
variety of tasks that rely on fine-tuning (e.g., visual question answering and
image retrieval). We are interested in shedding light on the quality of their
pretrained representations -- in particular, if these models can distinguish
different types of verbs or if they rely solely on nouns in a given sentence.
To do so, we collect a dataset of image-sentence pairs (in English) consisting
of 421 verbs that are either visual or commonly found in the pretraining data
(i.e., the Conceptual Captions dataset). We use this dataset to evaluate
pretrained image-language transformers and find that they fail more in
situations that require verb understanding compared to other parts of speech.
We also investigate what category of verbs are particularly challenging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Episode Adaptive Embedding Networks for Few-shot Learning. (arXiv:2106.09398v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fangbing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09398">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning aims to learn a classifier using a few labelled instances
for each class. Metric-learning approaches for few-shot learning embed
instances into a high-dimensional space and conduct classification based on
distances among instance embeddings. However, such instance embeddings are
usually shared across all episodes and thus lack the discriminative power to
generalize classifiers according to episode-specific features. In this paper,
we propose a novel approach, namely \emph{Episode Adaptive Embedding Network}
(EAEN), to learn episode-specific embeddings of instances. By leveraging the
probability distributions of all instances in an episode at each channel-pixel
embedding dimension, EAEN can not only alleviate the overfitting issue
encountered in few-shot learning tasks, but also capture discriminative
features specific to an episode. To empirically verify the effectiveness and
robustness of EAEN, we have conducted extensive experiments on three widely
used benchmark datasets, under various combinations of different generic
embedding backbones and different classifiers. The results show that EAEN
significantly improves classification accuracy about $10\%$ to $20\%$ in
different settings over the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Contrastive Graph Representation via Adaptive Homotopy Learning. (arXiv:2106.09244v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chengjun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1">Ziheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuelong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09244">
                                    <div class="article-summary-box-inner">
                                        <span>Homotopy model is an excellent tool exploited by diverse research works in
the field of machine learning. However, its flexibility is limited due to lack
of adaptiveness, i.e., manual fixing or tuning the appropriate homotopy
coefficients. To address the problem above, we propose a novel adaptive
homotopy framework (AH) in which the Maclaurin duality is employed, such that
the homotopy parameters can be adaptively obtained. Accordingly, the proposed
AH can be widely utilized to enhance the homotopy-based algorithm. In
particular, in this paper, we apply AH to contrastive learning (AHCL) such that
it can be effectively transferred from weak-supervised learning (given label
priori) to unsupervised learning, where soft labels of contrastive learning are
directly and adaptively learned. Accordingly, AHCL has the adaptive ability to
extract deep features without any sort of prior information. Consequently, the
affinity matrix formulated by the related adaptive labels can be constructed as
the deep Laplacian graph that incorporates the topology of deep representations
for the inputs. Eventually, extensive experiments on benchmark datasets
validate the superiority of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Robustness of Bayesian Neural Networks Against Different Types of Attacks. (arXiv:2106.09223v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yutian Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Sheng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jueming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09223">
                                    <div class="article-summary-box-inner">
                                        <span>To evaluate the robustness gain of Bayesian neural networks on image
classification tasks, we perform input perturbations, and adversarial attacks
to the state-of-the-art Bayesian neural networks, with a benchmark CNN model as
reference. The attacks are selected to simulate signal interference and
cyberattacks towards CNN-based machine learning systems. The result shows that
a Bayesian neural network achieves significantly higher robustness against
adversarial attacks generated against a deterministic neural network model,
without adversarial training. The Bayesian posterior can act as the safety
precursor of ongoing malicious activities. Furthermore, we show that the
stochastic classifier after the deterministic CNN extractor has sufficient
robustness enhancement rather than a stochastic feature extractor before the
stochastic classifier. This advises on utilizing stochastic layers in building
decision-making pipelines within a safety-critical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">THUNDR: Transformer-based 3D HUmaN Reconstruction with Markers. (arXiv:2106.09336v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zanfir_M/0/1/0/all/0/1">Mihai Zanfir</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanfir_A/0/1/0/all/0/1">Andrei Zanfir</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazavan_E/0/1/0/all/0/1">Eduard Gabriel Bazavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1">William T. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukthankar_R/0/1/0/all/0/1">Rahul Sukthankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sminchisescu_C/0/1/0/all/0/1">Cristian Sminchisescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09336">
                                    <div class="article-summary-box-inner">
                                        <span>We present THUNDR, a transformer-based deep neural network methodology to
reconstruct the 3d pose and shape of people, given monocular RGB images. Key to
our methodology is an intermediate 3d marker representation, where we aim to
combine the predictive power of model-free-output architectures and the
regularizing, anthropometrically-preserving properties of a statistical human
surface model like GHUM -- a recently introduced, expressive full body
statistical 3d human model, trained end-to-end. Our novel transformer-based
prediction pipeline can focus on image regions relevant to the task, supports
self-supervised regimes, and ensures that solutions are consistent with human
anthropometry. We show state-of-the-art results on Human3.6M and 3DPW, for both
the fully-supervised and the self-supervised models, for the task of inferring
3d human shape, joint positions, and global translation. Moreover, we observe
very solid 3d reconstruction performance for difficult human poses collected in
the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ShuffleBlock: Shuffle to Regularize Deep Convolutional Neural Networks. (arXiv:2106.09358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumawat_S/0/1/0/all/0/1">Sudhakar Kumawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanojia_G/0/1/0/all/0/1">Gagan Kanojia</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_S/0/1/0/all/0/1">Shanmuganathan Raman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09358">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have enormous representational power which leads them to
overfit on most datasets. Thus, regularizing them is important in order to
reduce overfitting and enhance their generalization capabilities. Recently,
channel shuffle operation has been introduced for mixing channels in group
convolutions in resource efficient networks in order to reduce memory and
computations. This paper studies the operation of channel shuffle as a
regularization technique in deep convolutional networks. We show that while
random shuffling of channels during training drastically reduce their
performance, however, randomly shuffling small patches between channels
significantly improves their performance. The patches to be shuffled are picked
from the same spatial locations in the feature maps such that a patch, when
transferred from one channel to another, acts as structured noise for the later
channel. We call this method &quot;ShuffleBlock&quot;. The proposed ShuffleBlock module
is easy to implement and improves the performance of several baseline networks
on the task of image classification on CIFAR and ImageNet datasets. It also
achieves comparable and in many cases better performance than many other
regularization methods. We provide several ablation studies on selecting
various hyperparameters of the ShuffleBlock module and propose a new scheduling
method that further enhances its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Evaluation of Self-Supervised Pre-Training for Skin-Lesion Analysis. (arXiv:2106.09229v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaves_L/0/1/0/all/0/1">Levy Chaves</a>, <a href="http://arxiv.org/find/cs/1/au:+Bissoto_A/0/1/0/all/0/1">Alceu Bissoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>, <a href="http://arxiv.org/find/cs/1/au:+Avila_S/0/1/0/all/0/1">Sandra Avila</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09229">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised pre-training appears as an advantageous alternative to
supervised pre-trained for transfer learning. By synthesizing annotations on
pretext tasks, self-supervision allows to pre-train models on large amounts of
pseudo-labels before fine-tuning them on the target task. In this work, we
assess self-supervision for the diagnosis of skin lesions, comparing three
self-supervised pipelines to a challenging supervised baseline, on five test
datasets comprising in- and out-of-distribution samples. Our results show that
self-supervision is competitive both in improving accuracies and in reducing
the variability of outcomes. Self-supervision proves particularly useful for
low training data scenarios ($&lt;1\,500$ and $&lt;150$ samples), where its ability
to stabilize the outcomes is essential to provide sound results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Insights into Data through Model Behaviour: An Explainability-driven Strategy for Data Auditing for Responsible Computer Vision Applications. (arXiv:2106.09177v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorfman_A/0/1/0/all/0/1">Adam Dorfman</a>, <a href="http://arxiv.org/find/cs/1/au:+McInnis_P/0/1/0/all/0/1">Paul McInnis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunraj_H/0/1/0/all/0/1">Hayden Gunraj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09177">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we take a departure and explore an explainability-driven
strategy to data auditing, where actionable insights into the data at hand are
discovered through the eyes of quantitative explainability on the behaviour of
a dummy model prototype when exposed to data. We demonstrate this strategy by
auditing two popular medical benchmark datasets, and discover hidden data
quality issues that lead deep learning models to make predictions for the wrong
reasons. The actionable insights gained from this explainability driven data
auditing strategy is then leveraged to address the discovered issues to enable
the creation of high-performing deep learning models with appropriate
prediction behaviour. The hope is that such an explainability-driven strategy
can be complimentary to data-driven strategies to facilitate for more
responsible development of machine learning algorithms for computer vision
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task convolutional neural network for blind stereoscopic image quality assessment using naturalness analysis. (arXiv:2106.09303v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bourbia_S/0/1/0/all/0/1">Salima Bourbia</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Karine_A/0/1/0/all/0/1">Ayoub Karine</a> (2), <a href="http://arxiv.org/find/eess/1/au:+Chetouani_A/0/1/0/all/0/1">Aladine Chetouani</a> (3), <a href="http://arxiv.org/find/eess/1/au:+Hassouni_M/0/1/0/all/0/1">Mohammed El Hassouni</a> (1 and 4) ((1) LRIT, Mohammed V University in Rabat, Rabat, Morocco, (2) L@bISEN, ISEN Yncrea Ouest, 33 Quater Chemin du Champ de Manoeuvre, 44470 Carquefou, France, (3) Laboratoire PRISME, Universite d&#x27;Orl&#xe9;ans, France, (4) FLSH, Mohammed V University in Rabat, Rabat, Morocco)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09303">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of blind stereoscopic image quality
assessment (NR-SIQA) using a new multi-task deep learning based-method. In the
field of stereoscopic vision, the information is fairly distributed between the
left and right views as well as the binocular phenomenon. In this work, we
propose to integrate these characteristics to estimate the quality of
stereoscopic images without reference through a convolutional neural network.
Our method is based on two main tasks: the first task predicts naturalness
analysis based features adapted to stereo images, while the second task
predicts the quality of such images. The former, so-called auxiliary task, aims
to find more robust and relevant features to improve the quality prediction. To
do this, we compute naturalness-based features using a Natural Scene Statistics
(NSS) model in the complex wavelet domain. It allows to capture the statistical
dependency between pairs of the stereoscopic images. Experiments are conducted
on the well known LIVE PHASE I and LIVE PHASE II databases. The results
obtained show the relevance of our method when comparing with those of the
state-of-the-art. Our code is available online on
\url{https://github.com/Bourbia-Salima/multitask-cnn-nrsiqa_2021}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Confidence-Based Image Denoising. (arXiv:2106.09311v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Owsianko_H/0/1/0/all/0/1">Haley Owsianko</a>, <a href="http://arxiv.org/find/eess/1/au:+Cassayre_F/0/1/0/all/0/1">Florian Cassayre</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1">Qiyuan Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09311">
                                    <div class="article-summary-box-inner">
                                        <span>Image denoising is a classic restoration problem. Yet, current deep learning
methods are subject to the problems of generalization and interpretability. To
mitigate these problems, in this project, we present a framework that is
capable of controllable, confidence-based noise removal. The framework is based
on the fusion between two different denoised images, both derived from the same
noisy input. One of the two is denoised using generic algorithms (e.g.
Gaussian), which make few assumptions on the input images, therefore,
generalize in all scenarios. The other is denoised using deep learning,
performing well on seen datasets. We introduce a set of techniques to fuse the
two components smoothly in the frequency domain. Beyond that, we estimate the
confidence of a deep learning denoiser to allow users to interpret the output,
and provide a fusion strategy that safeguards them against out-of-distribution
inputs. Through experiments, we demonstrate the effectiveness of the proposed
framework in different use cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layer Folding: Neural Network Depth Reduction using Activation Linearization. (arXiv:2106.09309v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dror_A/0/1/0/all/0/1">Amir Ben Dror</a>, <a href="http://arxiv.org/find/cs/1/au:+Zehngut_N/0/1/0/all/0/1">Niv Zehngut</a>, <a href="http://arxiv.org/find/cs/1/au:+Raviv_A/0/1/0/all/0/1">Avraham Raviv</a>, <a href="http://arxiv.org/find/cs/1/au:+Artyomov_E/0/1/0/all/0/1">Evgeny Artyomov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vitek_R/0/1/0/all/0/1">Ran Vitek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jevnisek_R/0/1/0/all/0/1">Roy Jevnisek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09309">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the increasing prevalence of deep neural networks, their
applicability in resource-constrained devices is limited due to their
computational load. While modern devices exhibit a high level of parallelism,
real-time latency is still highly dependent on networks&#x27; depth. Although recent
works show that below a certain depth, the width of shallower networks must
grow exponentially, we presume that neural networks typically exceed this
minimal depth to accelerate convergence and incrementally increase accuracy.
This motivates us to transform pre-trained deep networks that already exploit
such advantages into shallower forms. We propose a method that learns whether
non-linear activations can be removed, allowing to fold consecutive linear
layers into one. We apply our method to networks pre-trained on CIFAR-10 and
CIFAR-100 and find that they can all be transformed into shallower forms that
share a similar depth. Finally, we use our method to provide more efficient
alternatives to MobileNetV2 and EfficientNet-Lite architectures on the ImageNet
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks. (arXiv:2106.09249v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao%2A_Y/0/1/0/all/0/1">Yulong Cao*</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang%2A_N/0/1/0/all/0/1">Ningfei Wang*</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao%2A_C/0/1/0/all/0/1">Chaowei Xiao*</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang%2A_D/0/1/0/all/0/1">Dawei Yang*</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruigang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qi Alfred Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingyan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a> (*co-first authors)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09249">
                                    <div class="article-summary-box-inner">
                                        <span>In Autonomous Driving (AD) systems, perception is both security and safety
critical. Despite various prior studies on its security issues, all of them
only consider attacks on camera- or LiDAR-based AD perception alone. However,
production AD systems today predominantly adopt a Multi-Sensor Fusion (MSF)
based design, which in principle can be more robust against these attacks under
the assumption that not all fusion sources are (or can be) attacked at the same
time. In this paper, we present the first study of security issues of MSF-based
perception in AD systems. We directly challenge the basic MSF design assumption
above by exploring the possibility of attacking all fusion sources
simultaneously. This allows us for the first time to understand how much
security guarantee MSF can fundamentally provide as a general defense strategy
for AD perception.

We formulate the attack as an optimization problem to generate a
physically-realizable, adversarial 3D-printed object that misleads an AD system
to fail in detecting it and thus crash into it. We propose a novel attack
pipeline that addresses two main design challenges: (1) non-differentiable
target camera and LiDAR sensing systems, and (2) non-differentiable cell-level
aggregated features popularly used in LiDAR-based AD perception. We evaluate
our attack on MSF included in representative open-source industry-grade AD
systems in real-world driving scenarios. Our results show that the attack
achieves over 90% success rate across different object types and MSF. Our
attack is also found stealthy, robust to victim positions, transferable across
MSF algorithms, and physical-world realizable after being 3D-printed and
captured by LiDAR and camera devices. To concretely assess the end-to-end
safety impact, we further perform simulation evaluation and show that it can
cause a 100% vehicle collision rate for an industry-grade AD system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How can we learn (more) from challenges? A statistical approach to driving future algorithm development. (arXiv:2106.09302v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ross_T/0/1/0/all/0/1">Tobias Ro&#xdf;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruno_P/0/1/0/all/0/1">Pierangela Bruno</a>, <a href="http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1">Annika Reinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1">Manuel Wiesenfarth</a>, <a href="http://arxiv.org/find/cs/1/au:+Koeppel_L/0/1/0/all/0/1">Lisa Koeppel</a>, <a href="http://arxiv.org/find/cs/1/au:+Full_P/0/1/0/all/0/1">Peter M. Full</a>, <a href="http://arxiv.org/find/cs/1/au:+Pekdemir_B/0/1/0/all/0/1">B&#xfc;nyamin Pekdemir</a>, <a href="http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1">Patrick Godau</a>, <a href="http://arxiv.org/find/cs/1/au:+Trofimova_D/0/1/0/all/0/1">Darya Trofimova</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1">Sara Moccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Calimeri_F/0/1/0/all/0/1">Francesco Calimeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Stich_B/0/1/0/all/0/1">Beat P. M&#xfc;ller-Stich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopp_Schneider_A/0/1/0/all/0/1">Annette Kopp-Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1">Lena Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09302">
                                    <div class="article-summary-box-inner">
                                        <span>Challenges have become the state-of-the-art approach to benchmark image
analysis algorithms in a comparative manner. While the validation on identical
data sets was a great step forward, results analysis is often restricted to
pure ranking tables, leaving relevant questions unanswered. Specifically,
little effort has been put into the systematic investigation on what
characterizes images in which state-of-the-art algorithms fail. To address this
gap in the literature, we (1) present a statistical framework for learning from
challenges and (2) instantiate it for the specific task of instrument instance
segmentation in laparoscopic videos. Our framework relies on the semantic meta
data annotation of images, which serves as foundation for a General Linear
Mixed Models (GLMM) analysis. Based on 51,542 meta data annotations performed
on 2,728 images, we applied our approach to the results of the Robust Medical
Instrument Segmentation Challenge (ROBUST-MIS) challenge 2019 and revealed
underexposure, motion and occlusion of instruments as well as the presence of
smoke or other objects in the background as major sources of algorithm failure.
Our subsequent method development, tailored to the specific remaining issues,
yielded a deep learning model with state-of-the-art overall performance and
specific strengths in the processing of images in which previous methods tended
to fail. Due to the objectivity and generic applicability of our approach, it
could become a valuable tool for validation in the field of medical image
analysis and beyond. and segmentation of small, crossing, moving and
transparent instrument(s) (parts).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deformation Driven Seq2Seq Longitudinal Tumor and Organs-at-Risk Prediction for Radiotherapy. (arXiv:2106.09076v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Donghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1">Sadegh R Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jue Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengpeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_S/0/1/0/all/0/1">Saad Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yu-Chi Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09076">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: Radiotherapy presents unique challenges and clinical requirements
for longitudinal tumor and organ-at-risk (OAR) prediction during treatment. The
challenges include tumor inflammation/edema and radiation-induced changes in
organ geometry, whereas the clinical requirements demand flexibility in
input/output sequence timepoints to update the predictions on rolling basis and
the grounding of all predictions in relationship to the pre-treatment imaging
information for response and toxicity assessment in adaptive radiotherapy.
Methods: To deal with the aforementioned challenges and to comply with the
clinical requirements, we present a novel 3D sequence-to-sequence model based
on Convolution Long Short Term Memory (ConvLSTM) that makes use of series of
deformation vector fields (DVF) between individual timepoints and reference
pre-treatment/planning CTs to predict future anatomical deformations and
changes in gross tumor volume as well as critical OARs. High-quality DVF
training data is created by employing hyper-parameter optimization on the
subset of the training data with DICE coefficient and mutual information
metric. We validated our model on two radiotherapy datasets: a publicly
available head-and-neck dataset (28 patients with manually contoured pre-,
mid-, and post-treatment CTs), and an internal non-small cell lung cancer
dataset (63 patients with manually contoured planning CT and 6 weekly CBCTs).
Results: The use of DVF representation and skip connections overcomes the
blurring issue of ConvLSTM prediction with the traditional image
representation. The mean and standard deviation of DICE for predictions of lung
GTV at week 4, 5, and 6 were 0.83$\pm$0.09, 0.82$\pm$0.08, and 0.81$\pm$0.10,
respectively, and for post-treatment ipsilateral and contralateral parotids,
were 0.81$\pm$0.06 and 0.85$\pm$0.02.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-level Motion Attention for Human Motion Prediction. (arXiv:2106.09300v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_W/0/1/0/all/0/1">Wei Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Miaomiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1">Mathieu Salzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongdong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09300">
                                    <div class="article-summary-box-inner">
                                        <span>Human motion prediction aims to forecast future human poses given a
historical motion. Whether based on recurrent or feed-forward neural networks,
existing learning based methods fail to model the observation that human motion
tends to repeat itself, even for complex sports actions and cooking activities.
Here, we introduce an attention based feed-forward network that explicitly
leverages this observation. In particular, instead of modeling frame-wise
attention via pose similarity, we propose to extract motion attention to
capture the similarity between the current motion context and the historical
motion sub-sequences. In this context, we study the use of different types of
attention, computed at joint, body part, and full pose levels. Aggregating the
relevant past motions and processing the result with a graph convolutional
network allows us to effectively exploit motion patterns from the long-term
history to predict the future poses. Our experiments on Human3.6M, AMASS and
3DPW validate the benefits of our approach for both periodical and
non-periodical actions. Thanks to our attention model, it yields
state-of-the-art results on all three datasets. Our code is available at
https://github.com/wei-mao-2019/HisRepItself.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Two-stage Multi-modal Affect Analysis Framework for Children with Autism Spectrum Disorder. (arXiv:2106.09199v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jicheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_A/0/1/0/all/0/1">Anjana Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Barmaki_R/0/1/0/all/0/1">Roghayeh Barmaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09199">
                                    <div class="article-summary-box-inner">
                                        <span>Autism spectrum disorder (ASD) is a developmental disorder that influences
the communication and social behavior of a person in a way that those in the
spectrum have difficulty in perceiving other people&#x27;s facial expressions, as
well as presenting and communicating emotions and affect via their own faces
and bodies. Some efforts have been made to predict and improve children with
ASD&#x27;s affect states in play therapy, a common method to improve children&#x27;s
social skills via play and games. However, many previous works only used
pre-trained models on benchmark emotion datasets and failed to consider the
distinction in emotion between typically developing children and children with
autism. In this paper, we present an open-source two-stage multi-modal approach
leveraging acoustic and visual cues to predict three main affect states of
children with ASD&#x27;s affect states (positive, negative, and neutral) in
real-world play therapy scenarios, and achieved an overall accuracy of 72:40%.
This work presents a novel way to combine human expertise and machine
intelligence for ASD affect recognition by proposing a two-stage schema.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated CycleGAN for Privacy-Preserving Image-to-Image Translation. (arXiv:2106.09246v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Joonyoung Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09246">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised image-to-image translation methods such as CycleGAN learn to
convert images from one domain to another using unpaired training data sets
from different domains. Unfortunately, these approaches still require centrally
collected unpaired records, potentially violating privacy and security issues.
Although the recent federated learning (FL) allows a neural network to be
trained without data exchange, the basic assumption of the FL is that all
clients have their own training data from a similar domain, which is different
from our image-to-image translation scenario in which each client has images
from its unique domain and the goal is to learn image translation between
different domains without accessing the target domain data. To address this,
here we propose a novel federated CycleGAN architecture that can learn image
translation in an unsupervised manner while maintaining the data privacy.
Specifically, our approach arises from a novel observation that CycleGAN loss
can be decomposed into the sum of client specific local objectives that can be
evaluated using only their data. This local objective decomposition allows
multiple clients to participate in federated CycleGAN training without
sacrificing performance. Furthermore, our method employs novel switchable
generator and discriminator architecture using Adaptive Instance Normalization
(AdaIN) that significantly reduces the band-width requirement of the federated
learning. Our experimental results on various unsupervised image translation
tasks show that our federated CycleGAN provides comparable performance compared
to the non-federated counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Random CNN Sees Objects: One Inductive Bias of CNN and Its Applications. (arXiv:2106.09259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yun-Hao Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianxin Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09259">
                                    <div class="article-summary-box-inner">
                                        <span>This paper starts by revealing a surprising finding: without any learning, a
randomly initialized CNN can localize objects surprisingly well. That is, a CNN
has an inductive bias to naturally focus on objects, named as Tobias (&#x60;&#x60;The
object is at sight&#x27;&#x27;) in this paper. This empirical inductive bias is further
analyzed and successfully applied to self-supervised learning. A CNN is
encouraged to learn representations that focus on the foreground object, by
transforming every image into various versions with different backgrounds,
where the foreground and background separation is guided by Tobias.
Experimental results show that the proposed Tobias significantly improves
downstream tasks, especially for object detection. This paper also shows that
Tobias has consistent improvements on training sets of different sizes, and is
more resilient to changes in image augmentations. Our codes will be available
at https://github.com/CupidJay/Tobias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trilateral Attention Network for Real-time Medical Image Segmentation. (arXiv:2106.09201v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachdev_V/0/1/0/all/0/1">Vandana Sachdev</a>, <a href="http://arxiv.org/find/cs/1/au:+Antani_S/0/1/0/all/0/1">Sameer Antani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09201">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate segmentation of medical images into anatomically meaningful regions
is critical for the extraction of quantitative indices or biomarkers. The
common pipeline for segmentation comprises regions of interest detection stage
and segmentation stage, which are independent of each other and typically
performed using separate deep learning networks. The performance of the
segmentation stage highly relies on the extracted set of spatial features and
the receptive fields. In this work, we propose an end-to-end network, called
Trilateral Attention Network (TaNet), for real-time detection and segmentation
in medical images. TaNet has a module for region localization, and three
segmentation pathways: 1) handcrafted pathway with hand-designed convolutional
kernels, 2) detail pathway with regular convolutional kernels, and 3) a global
pathway to enlarge the receptive field. The first two pathways encode rich
handcrafted and low-level features extracted by hand-designed and regular
kernels while the global pathway encodes high-level context information. By
jointly training the network for localization and segmentation using different
sets of features, TaNet achieved superior performance, in terms of accuracy and
speed, when evaluated on an echocardiography dataset for cardiac segmentation.
The code and models will be made publicly available in TaNet Github page.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework. (arXiv:2106.09121v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jiahao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Byeon_W/0/1/0/all/0/1">Wonmin Byeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09121">
                                    <div class="article-summary-box-inner">
                                        <span>Enforcing orthogonality in neural networks is an antidote for gradient
vanishing/exploding problems, sensitivity by adversarial perturbation, and
bounding generalization errors. However, many previous approaches are
heuristic, and the orthogonality of convolutional layers is not systematically
studied: some of these designs are not exactly orthogonal, while others only
consider standard convolutional layers and propose specific classes of their
realizations. To address this problem, we propose a theoretical framework for
orthogonal convolutional layers, which establishes the equivalence between
various orthogonal convolutional layers in the spatial domain and the
paraunitary systems in the spectral domain. Since there exists a complete
spectral factorization of paraunitary systems, any orthogonal convolution layer
can be parameterized as convolutions of spatial filters. Our framework endows
high expressive power to various convolutional layers while maintaining their
exact orthogonality. Furthermore, our layers are memory and computationally
efficient for deep networks compared to previous designs. Our versatile
framework, for the first time, enables the study of architecture designs for
deep orthogonal networks, such as choices of skip connection, initialization,
stride, and dilation. Consequently, we scale up orthogonal networks to deep
architectures, including ResNet, WideResNet, and ShuffleNet, substantially
increasing the performance over the traditional shallow orthogonal networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPeCiaL: Self-Supervised Pretraining for Continual Learning. (arXiv:2106.09065v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09065">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents SPeCiaL: a method for unsupervised pretraining of
representations tailored for continual learning. Our approach devises a
meta-learning objective that differentiates through a sequential learning
process. Specifically, we train a linear model over the representations to
match different augmented views of the same image together, each view presented
sequentially. The linear model is then evaluated on both its ability to
classify images it just saw, and also on images from previous iterations. This
gives rise to representations that favor quick knowledge retention with minimal
forgetting. We evaluate SPeCiaL in the Continual Few-Shot Learning setting, and
show that it can match or outperform other supervised pretraining approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Video Prediction from a Single Frame by Estimating 3D Dynamic Scene Structure. (arXiv:2106.09051v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Paul Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1">Christoph H. Lampert</a>, <a href="http://arxiv.org/find/cs/1/au:+Bickel_B/0/1/0/all/0/1">Bernd Bickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09051">
                                    <div class="article-summary-box-inner">
                                        <span>Our goal in this work is to generate realistic videos given just one initial
frame as input. Existing unsupervised approaches to this task do not consider
the fact that a video typically shows a 3D environment, and that this should
remain coherent from frame to frame even as the camera and objects move. We
address this by developing a model that first estimates the latent 3D structure
of the scene, including the segmentation of any moving objects. It then
predicts future frames by simulating the object and camera dynamics, and
rendering the resulting views. Importantly, it is trained end-to-end using only
the unsupervised objective of predicting future frames, without any 3D
information nor segmentation annotations. Experiments on two challenging
datasets of natural videos show that our model can estimate 3D structure and
motion segmentation from a single frame, and hence generate plausible and
varied predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Temporal Contrastive Learning of Video Transformers. (arXiv:2106.09212v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1">Gedas Bertasius</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1">Du Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1">Lorenzo Torresani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09212">
                                    <div class="article-summary-box-inner">
                                        <span>Video transformers have recently emerged as a competitive alternative to 3D
CNNs for video understanding. However, due to their large number of parameters
and reduced inductive biases, these models require supervised pretraining on
large-scale image datasets to achieve top performance. In this paper, we
empirically demonstrate that self-supervised pretraining of video transformers
on video-only datasets can lead to action recognition results that are on par
or better than those obtained with supervised pretraining on large-scale image
datasets, even massive ones such as ImageNet-21K. Since transformer-based
models are effective at capturing dependencies over extended temporal spans, we
propose a simple learning procedure that forces the model to match a long-term
view to a short-term view of the same video. Our approach, named Long-Short
Temporal Contrastive Learning (LSTCL), enables video transformers to learn an
effective clip-level representation by predicting temporal context captured
from a longer temporal extent. To demonstrate the generality of our findings,
we implement and validate our approach under three different self-supervised
contrastive learning frameworks (MoCo v3, BYOL, SimSiam) using two distinct
video-transformer architectures, including an improved variant of the Swin
Transformer augmented with space-time attention. We conduct a thorough ablation
study and show that LSTCL achieves competitive performance on multiple video
benchmarks and represents a convincing alternative to supervised image-based
pretraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularization of Mixture Models for Robust Principal Graph Learning. (arXiv:2106.09035v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bonnaire_T/0/1/0/all/0/1">Tony Bonnaire</a>, <a href="http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1">Aur&#xe9;lien Decelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghanim_N/0/1/0/all/0/1">Nabila Aghanim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09035">
                                    <div class="article-summary-box-inner">
                                        <span>A regularized version of Mixture Models is proposed to learn a principal
graph from a distribution of $D$-dimensional data points. In the particular
case of manifold learning for ridge detection, we assume that the underlying
manifold can be modeled as a graph structure acting like a topological prior
for the Gaussian clusters turning the problem into a maximum a posteriori
estimation. Parameters of the model are iteratively estimated through an
Expectation-Maximization procedure making the learning of the structure
computationally efficient with guaranteed convergence for any graph prior in a
polynomial time. We also embed in the formalism a natural way to make the
algorithm robust to outliers of the pattern and heteroscedasticity of the
manifold sampling coherently with the graph structure. The method uses a graph
prior given by the minimum spanning tree that we extend using random
sub-samplings of the dataset to take into account cycles that can be observed
in the spatial distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LiRA: Learning Visual Speech Representations from Audio through Self-supervision. (arXiv:2106.09171v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Pingchuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mira_R/0/1/0/all/0/1">Rodrigo Mira</a>, <a href="http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1">Stavros Petridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09171">
                                    <div class="article-summary-box-inner">
                                        <span>The large amount of audiovisual content being shared online today has drawn
substantial attention to the prospect of audiovisual self-supervised learning.
Recent works have focused on each of these modalities separately, while others
have attempted to model both simultaneously in a cross-modal fashion. However,
comparatively little attention has been given to leveraging one modality as a
training objective to learn from the other. In this work, we propose Learning
visual speech Representations from Audio via self-supervision (LiRA).
Specifically, we train a ResNet+Conformer model to predict acoustic features
from unlabelled visual speech. We find that this pre-trained model can be
leveraged towards word-level and sentence-level lip-reading through feature
extraction and fine-tuning experiments. We show that our approach significantly
outperforms other self-supervised methods on the Lip Reading in the Wild (LRW)
dataset and achieves state-of-the-art performance on Lip Reading Sentences 2
(LRS2) using only a fraction of the total labelled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Fishnet Open Images Database: A Dataset for Fish Detection and Fine-Grained Categorization in Fisheries. (arXiv:2106.09178v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kay_J/0/1/0/all/0/1">Justin Kay</a>, <a href="http://arxiv.org/find/cs/1/au:+Merrifield_M/0/1/0/all/0/1">Matt Merrifield</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09178">
                                    <div class="article-summary-box-inner">
                                        <span>Camera-based electronic monitoring (EM) systems are increasingly being
deployed onboard commercial fishing vessels to collect essential data for
fisheries management and regulation. These systems generate large quantities of
video data which must be reviewed on land by human experts. Computer vision can
assist this process by automatically detecting and classifying fish species,
however the lack of existing public data in this domain has hindered progress.
To address this, we present the Fishnet Open Images Database, a large dataset
of EM imagery for fish detection and fine-grained categorization onboard
commercial fishing vessels. The dataset consists of 86,029 images containing 34
object classes, making it the largest and most diverse public dataset of
fisheries EM imagery to-date. It includes many of the characteristic challenges
of EM data: visual similarity between species, skewed class distributions,
harsh weather conditions, and chaotic crew activity. We evaluate the
performance of existing detection and classification algorithms and demonstrate
that the dataset can serve as a challenging benchmark for development of
computer vision algorithms in fisheries. The dataset is available at
https://www.fishnet.ai/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Position-wise Interaction Network for CTR Prediction. (arXiv:2106.05482v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1">Qingtao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingjian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jia Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jun Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05482">
                                    <div class="article-summary-box-inner">
                                        <span>Click-through rate (CTR) prediction plays an important role in online
advertising and recommender systems. In practice, the training of CTR models
depends on click data which is intrinsically biased towards higher positions
since higher position has higher CTR by nature. Existing methods such as actual
position training with fixed position inference and inverse propensity weighted
training with no position inference alleviate the bias problem to some extend.
However, the different treatment of position information between training and
inference will inevitably lead to inconsistency and sub-optimal online
performance. Meanwhile, the basic assumption of these methods, i.e., the click
probability is the product of examination probability and relevance
probability, is oversimplified and insufficient to model the rich interaction
between position and other information. In this paper, we propose a Deep
Position-wise Interaction Network (DPIN) to efficiently combine all candidate
items and positions for estimating CTR at each position, achieving consistency
between offline and online as well as modeling the deep non-linear interaction
among position, user, context and item under the limit of serving performance.
Following our new treatment to the position bias in CTR prediction, we propose
a new evaluation metrics named PAUC (position-wise AUC) that is suitable for
measuring the ranking quality at a given position. Through extensive
experiments on a real world dataset, we show empirically that our method is
both effective and efficient in solving position bias problem. We have also
deployed our method in production and observed statistically significant
improvement over a highly optimized baseline in a rigorous A/B test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Popularity of Reddit Posts with AI. (arXiv:2106.07380v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juno Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07380">
                                    <div class="article-summary-box-inner">
                                        <span>Social media creates crucial mass changes, as popular posts and opinions cast
a significant influence on users&#x27; decisions and thought processes. For example,
the recent Reddit uprising inspired by r/wallstreetbets which had remarkable
economic impact was started with a series of posts on the thread. The
prediction of posts that may have a notable impact will allow for the
preparation of possible following trends. This study aims to develop a machine
learning model capable of accurately predicting the popularity of a Reddit
post. Specifically, the model is predicting the number of upvotes a post will
receive based on its textual content. I experimented with three different
models: a baseline linear regression model, a random forest regression model,
and a neural network. I collected Reddit post data from an online data set and
analyzed the model&#x27;s performance when trained on a single subreddit and a
collection of subreddits. The results showed that the neural network model
performed the best when the loss of the models were compared. With the use of a
machine learning model to predict social trends through the reaction users have
to post, a better picture of the near future can be envisioned.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open Data and the Status Quo -- A Fine-Grained Evaluation Framework for Open Data Quality and an Analysis of Open Data portals in Germany. (arXiv:2106.09590v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wenige_L/0/1/0/all/0/1">Lisa Wenige</a>, <a href="http://arxiv.org/find/cs/1/au:+Stadler_C/0/1/0/all/0/1">Claus Stadler</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_M/0/1/0/all/0/1">Michael Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Figura_R/0/1/0/all/0/1">Richard Figura</a>, <a href="http://arxiv.org/find/cs/1/au:+Sauter_R/0/1/0/all/0/1">Robert Sauter</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_C/0/1/0/all/0/1">Christopher W. Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09590">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a framework for assessing data and metadata quality
within Open Data portals. Although a few benchmark frameworks already exist for
this purpose, they are not yet detailed enough in both breadth and depth to
make valid statements about the actual discoverability and accessibility of
publicly available data collections. To address this research gap, we have
designed a quality framework that is able to evaluate data quality in Open Data
portals on dedicated and fine-grained dimensions, such as interoperability,
findability, uniqueness or completeness. Additionally, we propose quality
measures that allow for valid assessments regarding cross-portal findability
and uniqueness of dataset descriptions. We have validated our novel quality
framework for the German Open Data landscape and found out that metadata often
still lacks meaningful descriptions and is not yet extensively connected to the
Semantic Web.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-supervised Method for Entity Alignment. (arXiv:2106.09395v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1">Haoyun Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinghao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09395">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment, aiming to identify equivalent entities across different
knowledge graphs (KGs), is a fundamental problem for constructing large-scale
KGs. Over the course of its development, supervision has been considered
necessary for accurate alignments. Inspired by the recent progress of
self-supervised learning, we explore the extent to which we can get rid of
supervision for entity alignment. Existing supervised methods for this task
focus on pulling each pair of positive (labeled) entities close to each other.
However, our analysis suggests that the learning of entity alignment can
actually benefit more from pushing sampled (unlabeled) negatives far away than
pulling positive aligned pairs close. We present SelfKG by leveraging this
discovery to design a contrastive learning strategy across two KGs. Extensive
experiments on benchmark datasets demonstrate that SelfKG without supervision
can match or achieve comparable results with state-of-the-art supervised
baselines. The performance of SelfKG demonstrates self-supervised learning
offers great potential for entity alignment in KGs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PEN4Rec: Preference Evolution Networks for Session-based Recommendation. (arXiv:2106.09306v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1">Xiaoyong Huai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhiqi Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songlin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09306">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation aims to predict user the next action based on
historical behaviors in an anonymous session. For better recommendations, it is
vital to capture user preferences as well as their dynamics. Besides, user
preferences evolve over time dynamically and each preference has its own
evolving track. However, most previous works neglect the evolving trend of
preferences and can be easily disturbed by the effect of preference drifting.
In this paper, we propose a novel Preference Evolution Networks for
session-based Recommendation (PEN4Rec) to model preference evolving process by
a two-stage retrieval from historical contexts. Specifically, the first-stage
process integrates relevant behaviors according to recent items. Then, the
second-stage process models the preference evolving trajectory over time
dynamically and infer rich preferences. The process can strengthen the effect
of relevant sequential behaviors during the preference evolution and weaken the
disturbance from preference drifting. Extensive experiments on three public
datasets demonstrate the effectiveness and superiority of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Author Clustering and Topic Estimation for Short Texts. (arXiv:2106.09533v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tierney_G/0/1/0/all/0/1">Graham Tierney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bail_C/0/1/0/all/0/1">Christopher Bail</a>, <a href="http://arxiv.org/find/cs/1/au:+Volfovsky_A/0/1/0/all/0/1">Alexander Volfovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09533">
                                    <div class="article-summary-box-inner">
                                        <span>Analysis of short text, such as social media posts, is extremely difficult
because it relies on observing many document-level word co-occurrence pairs.
Beyond topic distributions, a common downstream task of the modeling is
grouping the authors of these documents for subsequent analyses. Traditional
models estimate the document groupings and identify user clusters with an
independent procedure. We propose a novel model that expands on the Latent
Dirichlet Allocation by modeling strong dependence among the words in the same
document, with user-level topic distributions. We also simultaneously cluster
users, removing the need for post-hoc cluster estimation and improving topic
estimation by shrinking noisy user-level topic distributions towards typical
values. Our method performs as well as -- or better -- than traditional
approaches to problems arising in short text, and we demonstrate its usefulness
on a dataset of tweets from United States Senators, recovering both meaningful
topics and clusters that reflect partisan ideology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XDM: Improving Sequential Deep Matching with Unclicked User Behaviors for Recommender System. (arXiv:2010.12837v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fuyu Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mengxue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1">Tonglei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Changlong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1">Taiwei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_W/0/1/0/all/0/1">Wilfred Ng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12837">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based sequential recommender systems have recently attracted
increasing attention from both academia and industry. Most of industrial
Embedding-Based Retrieval (EBR) system for recommendation share the similar
ideas with sequential recommenders. Among them, how to comprehensively capture
sequential user interest is a fundamental problem. However, most existing
sequential recommendation models take as input clicked or purchased behavior
sequences from user-item interactions. This leads to incomprehensive user
representation and sub-optimal model performance, since they ignore the
complete user behavior exposure data, i.e., items impressed yet unclicked by
users. In this work, we attempt to incorporate and model those unclicked item
sequences using a new learning approach in order to explore better sequential
recommendation technique. An efficient triplet metric learning algorithm is
proposed to appropriately learn the representation of unclicked items. Our
method can be simply integrated with existing sequential recommendation models
by a confidence fusion network and further gain better user representation. The
offline experimental results based on real-world E-commerce data demonstrate
the effectiveness and verify the importance of unclicked items in sequential
recommendation. Moreover we deploy our new model (named XDM) into EBR of
recommender system at Taobao, outperforming the deployed previous generation
SDM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Current Challenges and Future Directions in Podcast Information Access. (arXiv:2106.09227v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1">Rosie Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1">Hamed Zamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Schedl_M/0/1/0/all/0/1">Markus Schedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Ching-Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Sravana Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_A/0/1/0/all/0/1">Ann Clifton</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlgren_J/0/1/0/all/0/1">Jussi Karlgren</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_H/0/1/0/all/0/1">Helia Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappu_A/0/1/0/all/0/1">Aasish Pappu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazari_Z/0/1/0/all/0/1">Zahra Nazari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Longqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Semerci_O/0/1/0/all/0/1">Oguz Semerci</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchard_H/0/1/0/all/0/1">Hugues Bouchard</a>, <a href="http://arxiv.org/find/cs/1/au:+Carterette_B/0/1/0/all/0/1">Ben Carterette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09227">
                                    <div class="article-summary-box-inner">
                                        <span>Podcasts are spoken documents across a wide-range of genres and styles, with
growing listenership across the world, and a rapidly lowering barrier to entry
for both listeners and creators. The great strides in search and recommendation
in research and industry have yet to see impact in the podcast space, where
recommendations are still largely driven by word of mouth. In this perspective
paper, we highlight the many differences between podcasts and other media, and
discuss our perspective on challenges and future research directions in the
domain of podcast information access.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedding-based Product Retrieval in Taobao Search. (arXiv:2106.09297v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fuyu Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1">Taiwei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaoyi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiao-Ming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1">Qianli Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09297">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, the product search service of e-commerce platforms has become a
vital shopping channel in people&#x27;s life. The retrieval phase of products
determines the search system&#x27;s quality and gradually attracts researchers&#x27;
attention. Retrieving the most relevant products from a large-scale corpus
while preserving personalized user characteristics remains an open question.
Recent approaches in this domain have mainly focused on embedding-based
retrieval (EBR) systems. However, after a long period of practice on Taobao, we
find that the performance of the EBR system is dramatically degraded due to
its: (1) low relevance with a given query and (2) discrepancy between the
training and inference phases. Therefore, we propose a novel and practical
embedding-based product retrieval model, named Multi-Grained Deep Semantic
Product Retrieval (MGDSPR). Specifically, we first identify the inconsistency
between the training and inference stages, and then use the softmax
cross-entropy loss as the training objective, which achieves better performance
and faster convergence. Two efficient methods are further proposed to improve
retrieval relevance, including smoothing noisy training data and generating
relevance-improving hard negative samples without requiring extra knowledge and
training procedures. We evaluate MGDSPR on Taobao Product Search with
significant metrics gains observed in offline experiments and online A/B tests.
MGDSPR has been successfully deployed to the existing multi-channel retrieval
system in Taobao Search. We also introduce the online deployment scheme and
share practical lessons of our retrieval system to contribute to the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recovery under Side Constraints. (arXiv:2106.09375v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ardah_K/0/1/0/all/0/1">Khaled Ardah</a>, <a href="http://arxiv.org/find/cs/1/au:+Haardt_M/0/1/0/all/0/1">Martin Haardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Matter_F/0/1/0/all/0/1">Frederic Matter</a>, <a href="http://arxiv.org/find/cs/1/au:+Pesavento_M/0/1/0/all/0/1">Marius Pesavento</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfetsch_M/0/1/0/all/0/1">Marc E. Pfetsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09375">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses sparse signal reconstruction under various types of
structural side constraints with applications in multi-antenna systems. Side
constraints may result from prior information on the measurement system and the
sparse signal structure. They may involve the structure of the sensing matrix,
the structure of the non-zero support values, the temporal structure of the
sparse representationvector, and the nonlinear measurement structure. First, we
demonstrate how a priori information in form of structural side constraints
influence recovery guarantees (null space properties) using L1-minimization.
Furthermore, for constant modulus signals, signals with row-, block- and
rank-sparsity, as well as non-circular signals, we illustrate how structural
prior information can be used to devise efficient algorithms with improved
recovery performance and reduced computational complexity. Finally, we address
the measurement system design for linear and nonlinear measurements of sparse
signals. Moreover, we discuss the linear mixing matrix design based on
coherence minimization. Then we extend our focus to nonlinear measurement
systems where we design parallel optimization algorithms to efficiently compute
stationary points in the sparse phase retrieval problem with and without
dictionary learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Effectiveness of Reviews in E-commerce Top-N Recommendation. (arXiv:2106.09665v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhichao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Hansi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09665">
                                    <div class="article-summary-box-inner">
                                        <span>Modern E-commerce websites contain heterogeneous sources of information, such
as numerical ratings, textual reviews and images. These information can be
utilized to assist recommendation. Through textual reviews, a user explicitly
express her affinity towards the item. Previous researchers found that by using
the information extracted from these reviews, we can better profile the users&#x27;
explicit preferences as well as the item features, leading to the improvement
of recommendation performance. However, most of the previous algorithms were
only utilizing the review information for explicit-feedback problem i.e. rating
prediction, and when it comes to implicit-feedback ranking problem such as
top-N recommendation, the usage of review information has not been fully
explored. Seeing this gap, in this work, we investigate the effectiveness of
textual review information for top-N recommendation under E-commerce settings.
We adapt several SOTA review-based rating prediction models for top-N
recommendation tasks and compare them to existing top-N recommendation models
from both performance and efficiency. We find that models utilizing only review
information can not achieve better performances than vanilla implicit-feedback
matrix factorization method. When utilizing review information as a regularizer
or auxiliary information, the performance of implicit-feedback matrix
factorization method can be further improved. However, the optimal model
structure to utilize textual reviews for E-commerce top-N recommendation is yet
to be determined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Unified Framework for Fair and Stable Graph Representation Learning. (arXiv:2102.13186v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1">Marinka Zitnik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13186">
                                    <div class="article-summary-box-inner">
                                        <span>As the representations output by Graph Neural Networks (GNNs) are
increasingly employed in real-world applications, it becomes important to
ensure that these representations are fair and stable. In this work, we
establish a key connection between counterfactual fairness and stability and
leverage it to propose a novel framework, NIFTY (uNIfying Fairness and
stabiliTY), which can be used with any GNN to learn fair and stable
representations. We introduce a novel objective function that simultaneously
accounts for fairness and stability and develop a layer-wise weight
normalization using the Lipschitz constant to enhance neural message passing in
GNNs. In doing so, we enforce fairness and stability both in the objective
function as well as in the GNN architecture. Further, we show theoretically
that our layer-wise weight normalization promotes counterfactual fairness and
stability in the resulting representations. We introduce three new graph
datasets comprising of high-stakes decisions in criminal justice and financial
lending domains. Extensive experimentation with the above datasets demonstrates
the efficacy of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Backward Gradient Normalization in Deep Neural Networks. (arXiv:2106.09475v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cabana_A/0/1/0/all/0/1">Alejandro Cabana</a>, <a href="http://arxiv.org/find/cs/1/au:+Lago_Fernandez_L/0/1/0/all/0/1">Luis F. Lago-Fern&#xe1;ndez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09475">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new technique for gradient normalization during neural network
training. The gradients are rescaled during the backward pass using
normalization layers introduced at certain points within the network
architecture. These normalization nodes do not affect forward activity
propagation, but modify backpropagation equations to permit a well-scaled
gradient flow that reaches the deepest network layers without experimenting
vanishing or explosion. Results on tests with very deep neural networks show
that the new technique can do an effective control of the gradient norm,
allowing the update of weights in the deepest layers and improving network
accuracy on several experimental conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BF++: a language for general-purpose program synthesis. (arXiv:2101.09571v4 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liventsev_V/0/1/0/all/0/1">Vadim Liventsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Harma_A/0/1/0/all/0/1">Aki H&#xe4;rm&#xe4;</a>, <a href="http://arxiv.org/find/cs/1/au:+Petkovic_M/0/1/0/all/0/1">Milan Petkovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09571">
                                    <div class="article-summary-box-inner">
                                        <span>Most state of the art decision systems based on Reinforcement Learning (RL)
are data-driven black-box neural models, where it is often difficult to
incorporate expert knowledge into the models or let experts review and validate
the learned decision mechanisms. Knowledge-insertion and model review are
important requirements in many applications involving human health and safety.
One way to bridge the gap between data and knowledge driven systems is program
synthesis: replacing a neural network that outputs decisions with a symbolic
program generated by a neural network or by means of genetic programming. We
propose a new programming language, BF++, designed specifically for automatic
programming of agents in a Partially Observable Markov Decision Process (POMDP)
setting and apply neural program synthesis to solve standard OpenAI Gym
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Error Convergence in Data Classification with Optimized Random Features: Acceleration by Quantum Machine Learning. (arXiv:2106.09028v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Yamasaki_H/0/1/0/all/0/1">Hayata Yamasaki</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sonoda_S/0/1/0/all/0/1">Sho Sonoda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09028">
                                    <div class="article-summary-box-inner">
                                        <span>Random features are a central technique for scalable learning algorithms
based on kernel methods. A recent work has shown that an algorithm for machine
learning by quantum computer, quantum machine learning (QML), can exponentially
speed up sampling of optimized random features, even without imposing
restrictive assumptions on sparsity and low-rankness of matrices that had
limited applicability of conventional QML algorithms; this QML algorithm makes
it possible to significantly reduce and provably minimize the required number
of features for regression tasks. However, a major interest in the field of QML
is how widely the advantages of quantum computation can be exploited, not only
in the regression tasks. We here construct a QML algorithm for a classification
task accelerated by the optimized random features. We prove that the QML
algorithm for sampling optimized random features, combined with stochastic
gradient descent (SGD), can achieve state-of-the-art exponential convergence
speed of reducing classification error in a classification task under a
low-noise condition; at the same time, our algorithm with optimized random
features can take advantage of the significant reduction of the required number
of features so as to accelerate each iteration in the SGD and evaluation of the
classifier obtained from our algorithm. These results discover a promising
application of QML to significant acceleration of the leading classification
algorithm based on kernel methods, without ruining its applicability to a
practical class of data sets and the exponential error-convergence speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modelling resource allocation in uncertain system environment through deep reinforcement learning. (arXiv:2106.09461v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gandhi_N/0/1/0/all/0/1">Neel Gandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Shakti Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09461">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement Learning has applications in field of mechatronics, robotics,
and other resource-constrained control system. Problem of resource allocation
is primarily solved using traditional predefined techniques and modern deep
learning methods. The drawback of predefined and most deep learning methods for
resource allocation is failing to meet the requirements in cases of uncertain
system environment. We can approach problem of resource allocation in uncertain
system environment alongside following certain criteria using deep
reinforcement learning. Also, reinforcement learning has ability for adapting
to new uncertain environment for prolonged period of time. The paper provides a
detailed comparative analysis on various deep reinforcement learning methods by
applying different components to modify architecture of reinforcement learning
with use of noisy layers, prioritized replay, bagging, duelling networks, and
other related combination to obtain improvement in terms of performance and
reduction of computational cost. The paper identifies problem of resource
allocation in uncertain environment could be effectively solved using Noisy
Bagging duelling double deep Q network achieving efficiency of 97.7% by
maximizing reward with significant exploration in given simulated environment
for resource allocation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VFL: A Vertical Federated Learning System for Multiple Data and Label Owners. (arXiv:2106.05468v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mugunthan_V/0/1/0/all/0/1">Vaikkunth Mugunthan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1">Lalana Kagal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05468">
                                    <div class="article-summary-box-inner">
                                        <span>Vertical Federated Learning (VFL) refers to the collaborative training of a
model on a dataset where the features of the dataset are split among multiple
data owners, while label information is owned by a single data owner. In this
paper, we propose a novel method, Multi Vertical Federated Learning
(Multi-VFL), to train VFL models when there are multiple data and label owners.
Our approach is the first to consider the setting where $D$-data owners (across
which features are distributed) and $K$-label owners (across which labels are
distributed) exist. This proposed configuration allows different entities to
train and learn optimal models without having to share their data. Our
framework makes use of split learning and adaptive federated optimizers to
solve this problem. For empirical evaluation, we run experiments on the MNIST
and FashionMNIST datasets. Our results show that using adaptive optimizers for
model aggregation fastens convergence and improves accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1">Jie Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02835">
                                    <div class="article-summary-box-inner">
                                        <span>Causal discovery from observational data is an important but challenging task
in many scientific fields. Recently, NOTEARS [Zheng et al., 2018] formulates
the causal structure learning problem as a continuous optimization problem
using least-square loss with an acyclicity constraint. Though the least-square
loss function is well justified under the standard Gaussian noise assumption,
it is limited if the assumption does not hold. In this work, we theoretically
show that the violation of the Gaussian noise assumption will hinder the causal
direction identification, making the causal orientation fully determined by the
causal strength as well as the variances of noises in the linear case and the
noises of strong non-Gaussianity in the nonlinear case. Consequently, we
propose a more general entropy-based loss that is theoretically consistent with
the likelihood score under any noise distribution. We run extensive empirical
evaluations on both synthetic data and real-world data to validate the
effectiveness of the proposed method and show that our method achieves the best
in Structure Hamming Distance, False Discovery Rate, and True Positive Rate
matrices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Multi-Function Computation with Private Remote Sources. (arXiv:2106.09485v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunlu_O/0/1/0/all/0/1">Onur G&#xfc;nl&#xfc;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_M/0/1/0/all/0/1">Matthieu Bloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaefer_R/0/1/0/all/0/1">Rafael F. Schaefer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09485">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a distributed function computation problem in which parties
observing noisy versions of a remote source facilitate the computation of a
function of their observations at a fusion center through public communication.
The distributed function computation is subject to constraints, including not
only reliability and storage but also privacy and secrecy. Specifically, 1) the
remote source should remain private from an eavesdropper and the fusion center,
measured in terms of the information leaked about the remote source; 2) the
function computed should remain secret from the eavesdropper, measured in terms
of the information leaked about the arguments of the function, to ensure
secrecy regardless of the exact function used. We derive the exact rate regions
for lossless and lossy single-function computation and illustrate the lossy
single-function computation rate region for an information bottleneck example,
in which the optimal auxiliary random variables are characterized for
binary-input symmetric-output channels. We extend the approach to lossless and
lossy asynchronous multiple-function computations with joint secrecy and
privacy constraints, in which case inner and outer bounds for the rate regions
differing only in the Markov chain conditions imposed are characterized.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex Envelopes. (arXiv:2002.00874v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zaiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00874">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic Approximation (SA) is a popular approach for solving fixed-point
equations where the information is corrupted by noise. In this paper, we
consider an SA involving a contraction mapping with respect to an arbitrary
norm, and show its finite-sample error bounds while using different stepsizes.
The idea is to construct a smooth Lyapunov function using the generalized
Moreau envelope, and show that the iterates of SA have negative drift with
respect to that Lyapunov function. Our result is applicable in Reinforcement
Learning (RL). In particular, we use it to establish the first-known
convergence rate of the V-trace algorithm for off-policy TD-learning. Moreover,
we also use it to study TD-learning in the on-policy setting, and recover the
existing state-of-the-art results for $Q$-learning. Importantly, our
construction results in only a logarithmic dependence of the convergence bound
on the size of the state-space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discond-VAE: Disentangling Continuous Factors from the Discrete. (arXiv:2009.08039v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jaewoong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_G/0/1/0/all/0/1">Geonho Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Myungjoo Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08039">
                                    <div class="article-summary-box-inner">
                                        <span>In the real-world data, there are common variations shared by all classes
(e.g. category label) and exclusive variations of each class. We propose a
variant of VAE capable of disentangling both of these variations. To represent
these generative factors of data, we introduce two sets of continuous latent
variables, private variable and public variable. Our proposed framework models
the private variable as a Mixture of Gaussian and the public variable as a
Gaussian, respectively. Each mode of the private variable is responsible for a
class of the discrete variable.

Most of the previous attempts to integrate the discrete generative factors to
disentanglement assume statistical independence between the continuous and
discrete variables. Our proposed model, which we call Discond-VAE, DISentangles
the class-dependent CONtinuous factors from the Discrete factors by introducing
the private variables. The experiments show that Discond-VAE can discover the
private and public factors from data. Moreover, even under the dataset with
only public factors, Discond-VAE does not fail and adapts the private variables
to represent the public factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-exponentially weighted aggregation: regret bounds for unbounded loss functions. (arXiv:2009.03017v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Alquier_P/0/1/0/all/0/1">Pierre Alquier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03017">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the problem of online optimization with a general, possibly
unbounded, loss function. It is well known that when the loss is bounded, the
exponentially weighted aggregation strategy (EWA) leads to a regret in
$\sqrt{T}$ after $T$ steps. In this paper, we study a generalized aggregation
strategy, where the weights no longer depend exponentially on the losses. Our
strategy is based on Follow The Regularized Leader (FTRL): we minimize the
expected losses plus a regularizer, that is here a $\phi$-divergence. When the
regularizer is the Kullback-Leibler divergence, we obtain EWA as a special
case. Using alternative divergences enables unbounded losses, at the cost of a
worst regret bound in some cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Graph Neural Networks with 1000 Layers. (arXiv:2106.07476v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guohao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1">Matthias M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1">Vladlen Koltun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07476">
                                    <div class="article-summary-box-inner">
                                        <span>Deep graph neural networks (GNNs) have achieved excellent results on various
tasks on increasingly large graph datasets with millions of nodes and edges.
However, memory complexity has become a major obstacle when training deep GNNs
for practical applications due to the immense number of nodes, edges, and
intermediate activations. To improve the scalability of GNNs, prior works
propose smart graph sampling or partitioning strategies to train GNNs with a
smaller set of nodes or sub-graphs. In this work, we study reversible
connections, group convolutions, weight tying, and equilibrium models to
advance the memory and parameter efficiency of GNNs. We find that reversible
connections in combination with deep network architectures enable the training
of overparameterized GNNs that significantly outperform existing methods on
multiple datasets. Our models RevGNN-Deep (1001 layers with 80 channels each)
and RevGNN-Wide (448 layers with 224 channels each) were both trained on a
single commodity GPU and achieve an ROC-AUC of $87.74 \pm 0.13$ and $88.24 \pm
0.15$ on the ogbn-proteins dataset. To the best of our knowledge, RevGNN-Deep
is the deepest GNN in the literature by one order of magnitude. Please visit
our project website https://www.deepgcns.org/arch/gnn1000 for more information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Variance Reduction in Online Experiments. (arXiv:2106.07263v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guo_Y/0/1/0/all/0/1">Yongyi Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Coey_D/0/1/0/all/0/1">Dominic Coey</a>, <a href="http://arxiv.org/find/stat/1/au:+Konutgan_M/0/1/0/all/0/1">Mikael Konutgan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_W/0/1/0/all/0/1">Wenting Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Schoener_C/0/1/0/all/0/1">Chris Schoener</a>, <a href="http://arxiv.org/find/stat/1/au:+Goldman_M/0/1/0/all/0/1">Matt Goldman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07263">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of variance reduction in randomized controlled
trials, through the use of covariates correlated with the outcome but
independent of the treatment. We propose a machine learning regression-adjusted
treatment effect estimator, which we call MLRATE. MLRATE uses machine learning
predictors of the outcome to reduce estimator variance. It employs
cross-fitting to avoid overfitting biases, and we prove consistency and
asymptotic normality under general conditions. MLRATE is robust to poor
predictions from the machine learning step: if the predictions are uncorrelated
with the outcomes, the estimator performs asymptotically no worse than the
standard difference-in-means estimator, while if predictions are highly
correlated with outcomes, the efficiency gains are large. In A/A tests, for a
set of 48 outcome metrics commonly monitored in Facebook experiments the
estimator has over 70% lower variance than the simple difference-in-means
estimator, and about 19% lower variance than the common univariate procedure
which adjusts only for pre-experiment values of the outcome.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Correlation-Based Multiview Learning and Self-Supervision: A Unifying Perspective. (arXiv:2106.07115v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qi Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Songtao Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07115">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple views of data, both naturally acquired (e.g., image and audio) and
artificially produced (e.g., via adding different noise to data samples), have
proven useful in enhancing representation learning. Natural views are often
handled by multiview analysis tools, e.g., (deep) canonical correlation
analysis [(D)CCA], while the artificial ones are frequently used in
self-supervised learning (SSL) paradigms, e.g., SimCLR and Barlow Twins. Both
types of approaches often involve learning neural feature extractors such that
the embeddings of data exhibit high cross-view correlations. Although
intuitive, the effectiveness of correlation-based neural embedding is only
empirically validated. This work puts forth a theory-backed framework for
unsupervised multiview learning. Our development starts with proposing a
multiview model, where each view is a nonlinear mixture of shared and private
components. Consequently, the learning problem boils down to shared/private
component identification and disentanglement. Under this model, latent
correlation maximization is shown to guarantee the extraction of the shared
components across views (up to certain ambiguities). In addition, the private
information in each view can be provably disentangled from the shared using
proper regularization design. The method is tested on a series of tasks, e.g.,
downstream clustering, which all show promising performance. Our development
also provides a unifying perspective for understanding various DCCA and SSL
schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression. (arXiv:2106.02875v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhaozhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1">William R. Zame</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleuren_L/0/1/0/all/0/1">Lucas M. Fleuren</a>, <a href="http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1">Paul Elbers</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02875">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling a system&#x27;s temporal behaviour in reaction to external stimuli is a
fundamental problem in many areas. Pure Machine Learning (ML) approaches often
fail in the small sample regime and cannot provide actionable insights beyond
predictions. A promising modification has been to incorporate expert domain
knowledge into ML models. The application we consider is predicting the
progression of disease under medications, where a plethora of domain knowledge
is available from pharmacology. Pharmacological models describe the dynamics of
carefully-chosen medically meaningful variables in terms of systems of Ordinary
Differential Equations (ODEs). However, these models only describe a limited
collection of variables, and these variables are often not observable in
clinical environments. To close this gap, we propose the latent hybridisation
model (LHM) that integrates a system of expert-designed ODEs with
machine-learned Neural ODEs to fully describe the dynamics of the system and to
link the expert and latent variables to observable quantities. We evaluated LHM
on synthetic data as well as real-world intensive care data of COVID-19
patients. LHM consistently outperforms previous works, especially when few
training samples are available such as at the beginning of the pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Metrizing Weak Convergence with Maximum Mean Discrepancies. (arXiv:2006.09268v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simon_Gabriel_C/0/1/0/all/0/1">Carl-Johann Simon-Gabriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Barp_A/0/1/0/all/0/1">Alessandro Barp</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09268">
                                    <div class="article-summary-box-inner">
                                        <span>This paper characterizes the maximum mean discrepancies (MMD) that metrize
the weak convergence of probability measures for a wide class of kernels. More
precisely, we prove that, on a locally compact, non-compact, Hausdorff space,
the MMD of a bounded continuous Borel measurable kernel k, whose reproducing
kernel Hilbert space (RKHS) functions vanish at infinity, metrizes the weak
convergence of probability measures if and only if k is continuous and
integrally strictly positive definite (i.s.p.d.) over all signed, finite,
regular Borel measures. We also correct a prior result of Simon-Gabriel &amp;
Sch\&quot;olkopf (JMLR, 2018, Thm.12) by showing that there exist both bounded
continuous i.s.p.d. kernels that do not metrize weak convergence and bounded
continuous non-i.s.p.d. kernels that do metrize it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Protecting gender and identity with disentangled speech representations. (arXiv:2104.11051v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stoidis_D/0/1/0/all/0/1">Dimitrios Stoidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11051">
                                    <div class="article-summary-box-inner">
                                        <span>Besides its linguistic content, our speech is rich in biometric information
that can be inferred by classifiers. Learning privacy-preserving
representations for speech signals enables downstream tasks without sharing
unnecessary, private information about an individual. In this paper, we show
that protecting gender information in speech is more effective than modelling
speaker-identity information only when generating a non-sensitive
representation of speech. Our method relies on reconstructing speech by
decoding linguistic content along with gender information using a variational
autoencoder. Specifically, we exploit disentangled representation learning to
encode information about different attributes into separate subspaces that can
be factorised independently. We present a novel way to encode gender
information and disentangle two sensitive biometric identifiers, namely gender
and identity, in a privacy-protecting setting. Experiments on the LibriSpeech
dataset show that gender recognition and speaker verification can be reduced to
a random guess, protecting against classification-based attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empowerment-based Solution to Robotic Manipulation Tasks with Sparse Rewards. (arXiv:2010.07986v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Siyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_A/0/1/0/all/0/1">Andreas Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1">Brian Williams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07986">
                                    <div class="article-summary-box-inner">
                                        <span>In order to provide adaptive and user-friendly solutions to robotic
manipulation, it is important that the agent can learn to accomplish tasks even
if they are only provided with very sparse instruction signals. To address the
issues reinforcement learning algorithms face when task rewards are sparse,
this paper proposes an intrinsic motivation approach that can be easily
integrated into any standard reinforcement learning algorithm and can allow
robotic manipulators to learn useful manipulation skills with only sparse
extrinsic rewards. Through integrating and balancing empowerment and curiosity,
this approach shows superior performance compared to other state-of-the-art
intrinsic exploration approaches during extensive empirical testing.
Qualitative analysis also shows that when combined with diversity-driven
intrinsic motivations, this approach can help manipulators learn a set of
diverse skills which could potentially be applied to other more complicated
manipulation tasks and accelerate their learning process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Query Lower Bounds for List-Decodable Linear Regression. (arXiv:2106.09689v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Pensia_A/0/1/0/all/0/1">Ankit Pensia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pittas_T/0/1/0/all/0/1">Thanasis Pittas</a>, <a href="http://arxiv.org/find/cs/1/au:+Stewart_A/0/1/0/all/0/1">Alistair Stewart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09689">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of list-decodable linear regression, where an adversary
can corrupt a majority of the examples. Specifically, we are given a set $T$ of
labeled examples $(x, y) \in \mathbb{R}^d \times \mathbb{R}$ and a parameter
$0&lt; \alpha &lt;1/2$ such that an $\alpha$-fraction of the points in $T$ are i.i.d.
samples from a linear regression model with Gaussian covariates, and the
remaining $(1-\alpha)$-fraction of the points are drawn from an arbitrary noise
distribution. The goal is to output a small list of hypothesis vectors such
that at least one of them is close to the target regression vector. Our main
result is a Statistical Query (SQ) lower bound of $d^{\mathrm{poly}(1/\alpha)}$
for this problem. Our SQ lower bound qualitatively matches the performance of
previously developed algorithms, providing evidence that current upper bounds
for this task are nearly best possible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visualising Deep Network&#x27;s Time-Series Representations. (arXiv:2103.07176v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leporowski_B/0/1/0/all/0/1">B&#x142;a&#x17c;ej Leporowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07176">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the popularisation of machine learning models, more often than not,
they still operate as black boxes with no insight into what is happening inside
the model. There exist a few methods that allow to visualise and explain why a
model has made a certain prediction. Those methods, however, allow
visualisation of the link between the input and output of the model without
presenting how the model learns to represent the data used to train the model
as whole. In this paper, a method that addresses that issue is proposed, with a
focus on visualising multi-dimensional time-series data. Experiments on a
high-frequency stock market dataset show that the method provides fast and
discernible visualisations. Large datasets can be visualised quickly and on one
plot, which makes it easy for a user to compare the learned representations of
the data. The developed method successfully combines known techniques to
provide an insight into the inner workings of time-series classification
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidence-based Factual Error Correction. (arXiv:2106.01072v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01072">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the task of factual error correction: performing edits
to a claim so that the generated rewrite is better supported by evidence. This
extends the well-studied task of fact verification by providing a mechanism to
correct written texts that are refuted or only partially supported by evidence.
We demonstrate that it is feasible to train factual error correction systems
from existing fact checking datasets which only contain labeled claims
accompanied by evidence, but not the correction. We achieve this by employing a
two-stage distant supervision approach that incorporates evidence into masked
claims when generating corrections. Our approach, based on the T5 transformer
and using retrieved evidence, achieved better results than existing work which
used a pointer copy network and gold evidence, producing accurate factual error
corrections for 5x more instances in human evaluation and a .125 increase in
SARI score. The evaluation is conducted on a dataset of 65,000 instances based
on a recent fact verification shared task and we release it to enable further
work on the task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Randomized Value Functions via Posterior State-Abstraction Sampling. (arXiv:2010.02383v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arumugam_D/0/1/0/all/0/1">Dilip Arumugam</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02383">
                                    <div class="article-summary-box-inner">
                                        <span>State abstraction has been an essential tool for dramatically improving the
sample efficiency of reinforcement-learning algorithms. Indeed, by exposing and
accentuating various types of latent structure within the environment,
different classes of state abstraction have enabled improved theoretical
guarantees and empirical performance. When dealing with state abstractions that
capture structure in the value function, however, a standard assumption is that
the true abstraction has been supplied or unrealistically computed a priori,
leaving open the question of how to efficiently uncover such latent structure
while jointly seeking out optimal behavior. Taking inspiration from the bandit
literature, we propose that an agent seeking out latent task structure must
explicitly represent and maintain its uncertainty over that structure as part
of its overall uncertainty about the environment. We introduce a practical
algorithm for doing this using two posterior distributions over state
abstractions and abstract-state values. In empirically validating our approach,
we find that substantial performance gains lie in the multi-task setting where
tasks share a common, low-dimensional representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperparameter Optimization via Sequential Uniform Designs. (arXiv:2009.03586v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zebin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03586">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperparameter optimization (HPO) plays a central role in the automated
machine learning (AutoML). It is a challenging task as the response surfaces of
hyperparameters are generally unknown, hence essentially a global optimization
problem. This paper reformulates HPO as a computer experiment and proposes a
novel sequential uniform design (SeqUD) strategy with three-fold advantages: a)
the hyperparameter space is adaptively explored with evenly spread design
points, without the need of expensive meta-modeling and acquisition
optimization; b) the batch-by-batch design points are sequentially generated
with parallel processing support; c) a new augmented uniform design algorithm
is developed for the efficient real-time generation of follow-up design points.
Extensive experiments are conducted on both global optimization tasks and HPO
applications. The numerical results show that the proposed SeqUD strategy
outperforms benchmark HPO methods, and it can be therefore a promising and
competitive alternative to existing AutoML tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling. (arXiv:2104.02321v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1">Junhyeok Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_S/0/1/0/all/0/1">Seungu Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02321">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce NU-Wave, the first neural audio upsampling model
to produce waveforms of sampling rate 48kHz from coarse 16kHz or 24kHz inputs,
while prior works could generate only up to 16kHz. NU-Wave is the first
diffusion probabilistic model for audio super-resolution which is engineered
based on neural vocoders. NU-Wave generates high-quality audio that achieves
high performance in terms of signal-to-noise ratio (SNR), log-spectral distance
(LSD), and accuracy of the ABX test. In all cases, NU-Wave outperforms the
baseline models despite the substantially smaller model capacity (3.0M
parameters) than baselines (5.4-21%). The audio samples of our model are
available at https://mindslab-ai.github.io/nuwave, and the code will be made
available soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Merging versus Ensembling in Multi-Study Prediction: Theoretical Insight from Random Effects. (arXiv:1905.07382v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guan_Z/0/1/0/all/0/1">Zoe Guan</a>, <a href="http://arxiv.org/find/stat/1/au:+Parmigiani_G/0/1/0/all/0/1">Giovanni Parmigiani</a>, <a href="http://arxiv.org/find/stat/1/au:+Patil_P/0/1/0/all/0/1">Prasad Patil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.07382">
                                    <div class="article-summary-box-inner">
                                        <span>A critical decision point when training predictors using multiple studies is
whether these studies should be combined or treated separately. We compare two
multi-study learning approaches in the presence of potential heterogeneity in
predictor-outcome relationships across datasets. We consider 1) merging all of
the datasets and training a single learner, and 2) multi-study ensembling,
which involves training a separate learner on each dataset and combining the
predictions resulting from each learner. In a linear regression setting, we
show analytically and confirm via simulation that merging yields lower
prediction error than ensembling when the predictor-outcome relationships are
relatively homogeneous across studies. However, as cross-study heterogeneity
increases, there exists a transition point beyond which ensembling outperforms
merging. We provide analytic expressions for the transition point in various
scenarios, study asymptotic properties, and illustrate how transition point
theory can be used for deciding when studies should be combined with an
application from metabolomics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On a Sparse Shortcut Topology of Artificial Neural Networks. (arXiv:1811.09003v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1">Fenglei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dayang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hengtao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qikui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1">Pingkun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hengyong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.09003">
                                    <div class="article-summary-box-inner">
                                        <span>Over recent years, deep learning has become the mainstream data-driven
approach to solve many important real-world problems. In the successful network
architectures, shortcut connections are well established to take the outputs of
earlier layers as additional inputs to later layers, which have produced
excellent results. Despite the extraordinary effectiveness of shortcuts, there
remain important questions on the underlying mechanism and associated
functionalities. For example, why are shortcuts powerful? Why shortcuts
generalize well? To address these questions, we investigate the representation
and generalization ability of a sparse shortcut topology. Specifically, we
first demonstrate that this topology can empower a one-neuron-wide deep network
to approximate any univariate continuous function. Then, we present a novel
width-bounded universal approximator in contrast to depth-bounded universal
approximators, and also extend the approximation result to a family of networks
such that in the view of approximation ability, these networks are equally
competent. Furthermore, we use the generalization bound theory to show that the
investigated shortcut topology enjoys an excellent generalizability. Finally,
we corroborate our theoretical analyses with experiments on some well-known
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incremental Without Replacement Sampling in Nonconvex Optimization. (arXiv:2007.07557v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1">Edouard Pauwels</a> (IRIT-ADRIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07557">
                                    <div class="article-summary-box-inner">
                                        <span>Minibatch decomposition methods for empirical risk minimization are commonly
analysed in a stochastic approximation setting, also known as sampling with
replacement. On the other hands modern implementations of such techniques are
incremental: they rely on sampling without replacement, for which available
analysis are much scarcer. We provide convergence guaranties for the latter
variant by analysing a versatile incremental gradient scheme. For this scheme,
we consider constant, decreasing or adaptive step sizes. In the smooth setting
we obtain explicit complexity estimates in terms of epoch counter. In the
nonsmooth setting we prove that the sequence is attracted by solutions of
optimality conditions of the problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedV: Privacy-Preserving Federated Learning over Vertically Partitioned Data. (arXiv:2103.03918v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Runhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1">Nathalie Baracaldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Ali Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_J/0/1/0/all/0/1">James Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ludwig_H/0/1/0/all/0/1">Heiko Ludwig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03918">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) has been proposed to allow collaborative training of
machine learning (ML) models among multiple parties where each party can keep
its data private. In this paradigm, only model updates, such as model weights
or gradients, are shared. Many existing approaches have focused on horizontal
FL, where each party has the entire feature set and labels in the training data
set. However, many real scenarios follow a vertically-partitioned FL setup,
where a complete feature set is formed only when all the datasets from the
parties are combined, and the labels are only available to a single party.
Privacy-preserving vertical FL is challenging because complete sets of labels
and features are not owned by one entity. Existing approaches for vertical FL
require multiple peer-to-peer communications among parties, leading to lengthy
training times, and are restricted to (approximated) linear models and just two
parties. To close this gap, we propose FedV, a framework for secure gradient
computation in vertical settings for several widely used ML models such as
linear models, logistic regression, and support vector machines. FedV removes
the need for peer-to-peer communication among parties by using functional
encryption schemes; this allows FedV to achieve faster training times. It also
works for larger and changing sets of parties. We empirically demonstrate the
applicability for multiple types of ML models and show a reduction of 10%-70%
of training time and 80% to 90% in data transfer with respect to the
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NPAS: A Compiler-aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-Time Mobile Acceleration. (arXiv:2012.00596v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuxuan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zheng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1">Zhenglun Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00596">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing demand to efficiently deploy DNNs on mobile edge devices,
it becomes much more important to reduce unnecessary computation and increase
the execution speed. Prior methods towards this goal, including model
compression and network architecture search (NAS), are largely performed
independently and do not fully consider compiler-level optimizations which is a
must-do for mobile acceleration. In this work, we first propose (i) a general
category of fine-grained structured pruning applicable to various DNN layers,
and (ii) a comprehensive, compiler automatic code generation framework
supporting different DNNs and different pruning schemes, which bridge the gap
of model compression and NAS. We further propose NPAS, a compiler-aware unified
network pruning, and architecture search. To deal with large search space, we
propose a meta-modeling procedure based on reinforcement learning with fast
evaluation and Bayesian optimization, ensuring the total number of training
epochs comparable with representative NAS frameworks. Our framework achieves
6.7ms, 5.9ms, 3.9ms ImageNet inference times with 78.2%, 75% (MobileNet-V3
level), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an
off-the-shelf mobile phone, consistently outperforming prior work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A General Framework For Detecting Anomalous Inputs to DNN Classifiers. (arXiv:2007.15147v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raghuram_J/0/1/0/all/0/1">Jayaram Raghuram</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1">Varun Chandrasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Somesh Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Suman Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15147">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting anomalous inputs, such as adversarial and out-of-distribution (OOD)
inputs, is critical for classifiers (including deep neural networks or DNNs)
deployed in real-world applications. While prior works have proposed various
methods to detect such anomalous samples using information from the internal
layer representations of a DNN, there is a lack of consensus on a principled
approach for the different components of such a detection method. As a result,
often heuristic and one-off methods are applied for different aspects of this
problem. We propose an unsupervised anomaly detection framework based on the
internal DNN layer representations in the form of a meta-algorithm with
configurable components. We proceed to propose specific instantiations for each
component of the meta-algorithm based on ideas grounded in statistical testing
and anomaly detection. We evaluate the proposed methods on well-known image
classification datasets with strong adversarial attacks and OOD inputs,
including an adaptive attack that uses the internal layer representations of
the DNN (often not considered in prior work). Comparisons with five
recently-proposed competing detection methods demonstrates the effectiveness of
our method in detecting adversarial and OOD inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors. (arXiv:2006.15417v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruihan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Madumal_P/0/1/0/all/0/1">Prashan Madumal</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1">Tim Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehinger_K/0/1/0/all/0/1">Krista A. Ehinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1">Benjamin I. P. Rubinstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15417">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural network (CNN) models for computer vision are powerful
but lack explainability in their most basic form. This deficiency remains a key
challenge when applying CNNs in important domains. Recent work on explanations
through feature importance of approximate linear models has moved from
input-level features (pixels or segments) to features from mid-layer feature
maps in the form of concept activation vectors (CAVs). CAVs contain
concept-level information and could be learned via clustering. In this work, we
rethink the ACE algorithm of Ghorbani et~al., proposing an alternative
invertible concept-based explanation (ICE) framework to overcome its
shortcomings. Based on the requirements of fidelity (approximate models to
target models) and interpretability (being meaningful to people), we design
measurements and evaluate a range of matrix factorization methods with our
framework. We find that non-negative concept activation vectors (NCAVs) from
non-negative matrix factorization provide superior performance in
interpretability and fidelity based on computational and human subject
experiments. Our framework provides both local and global concept-level
explanations for pre-trained CNN models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can convolutional ResNets approximately preserve input distances? A frequency analysis perspective. (arXiv:2106.02469v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Lewis Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1">Joost van Amersfoort</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haiwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02469">
                                    <div class="article-summary-box-inner">
                                        <span>ResNets constrained to be bi-Lipschitz, that is, approximately distance
preserving, have been a crucial component of recently proposed techniques for
deterministic uncertainty quantification in neural models. We show that
theoretical justifications for recent regularisation schemes trying to enforce
such a constraint suffer from a crucial flaw -- the theoretical link between
the regularisation scheme used and bi-Lipschitzness is only valid under
conditions which do not hold in practice, rendering existing theory of limited
use, despite the strong empirical performance of these models. We provide a
theoretical explanation for the effectiveness of these regularisation schemes
using a frequency analysis perspective, showing that under mild conditions
these schemes will enforce a lower Lipschitz bound on the low-frequency
projection of images. We then provide empirical evidence supporting our
theoretical claims, and perform further experiments which demonstrate that our
broader conclusions appear to hold when some of the mathematical assumptions of
our proof are relaxed, corresponding to the setup used in prior work. In
addition, we present a simple constructive algorithm to search for counter
examples to the distance preservation condition, and discuss possible
implications of our theory for future model design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Boolean Function Learnability on Deep Neural Networks. (arXiv:2009.05908v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tavares_A/0/1/0/all/0/1">Anderson R. Tavares</a>, <a href="http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1">Pedro Avelar</a>, <a href="http://arxiv.org/find/cs/1/au:+Flach_J/0/1/0/all/0/1">Jo&#xe3;o M. Flach</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolau_M/0/1/0/all/0/1">Marcio Nicolau</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1">Luis C. Lamb</a>, <a href="http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1">Moshe Vardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05908">
                                    <div class="article-summary-box-inner">
                                        <span>Computational learning theory states that many classes of boolean formulas
are learnable in polynomial time. This paper addresses the understudied subject
of how, in practice, such formulas can be learned by deep neural networks.
Specifically, we analyse boolean formulas associated with the decision version
of combinatorial optimisation problems, model sampling benchmarks, and random
3-CNFs with varying degrees of constrainedness. Our extensive experiments
indicate that: (i) regardless of the combinatorial optimisation problem,
relatively small and shallow neural networks are very good approximators of the
associated formulas; (ii) smaller formulas seem harder to learn, possibly due
to the fewer positive (satisfying) examples available; and (iii) interestingly,
underconstrained 3-CNF formulas are more challenging to learn than
overconstrained ones. Source code and relevant datasets are publicly available
(https://github.com/machine-reasoning-ufrgs/mlbf).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Transformers Really Perform Bad for Graph Representation?. (arXiv:2106.05234v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1">Chengxuan Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shengjie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuxin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1">Guolin Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yanming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05234">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer architecture has become a dominant choice in many domains,
such as natural language processing and computer vision. Yet, it has not
achieved competitive performance on popular leaderboards of graph-level
prediction compared to mainstream GNN variants. Therefore, it remains a mystery
how Transformers could perform well for graph representation learning. In this
paper, we solve this mystery by presenting Graphormer, which is built upon the
standard Transformer architecture, and could attain excellent results on a
broad range of graph representation learning tasks, especially on the recent
OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the
graph is the necessity of effectively encoding the structural information of a
graph into the model. To this end, we propose several simple yet effective
structural encoding methods to help Graphormer better model graph-structured
data. Besides, we mathematically characterize the expressive power of
Graphormer and exhibit that with our ways of encoding the structural
information of graphs, many popular GNN variants could be covered as the
special cases of Graphormer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autobots: Latent Variable Sequential Set Transformers. (arXiv:2104.00563v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girgis_R/0/1/0/all/0/1">Roger Girgis</a>, <a href="http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1">Florian Golemo</a>, <a href="http://arxiv.org/find/cs/1/au:+Codevilla_F/0/1/0/all/0/1">Felipe Codevilla</a>, <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jim Aldon D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_M/0/1/0/all/0/1">Martin Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1">Samira Ebrahimi Kahou</a>, <a href="http://arxiv.org/find/cs/1/au:+Heide_F/0/1/0/all/0/1">Felix Heide</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00563">
                                    <div class="article-summary-box-inner">
                                        <span>Robust multi-agent trajectory prediction is essential for the safe control of
robots and vehicles that interact with humans. Many existing methods treat
social and temporal information separately and therefore fall short of
modelling the joint future trajectories of all agents in a socially consistent
way. To address this, we propose a new class of Latent Variable Sequential Set
Transformers which autoregressively model multi-agent trajectories. We refer to
these architectures as &quot;AutoBots&quot;. AutoBots model the contents of sets (e.g.
representing the properties of agents in a scene) over time and employ
multi-head self-attention blocks over these sequences of sets to encode the
sociotemporal relationships between the different actors of a scene. This
produces either the trajectory of one ego-agent or a distribution over the
future trajectories for all agents under consideration. Our approach works for
general sequences of sets and we provide illustrative experiments modelling the
sequential structure of the multiple strokes that make up symbols in the
Omniglot data. For the single-agent prediction case, we validate our model on
the NuScenes motion prediction task and achieve competitive results on the
global leaderboard. In the multi-agent forecasting setting, we validate our
model on TrajNet. We find that our method outperforms physical extrapolation
and recurrent network baselines and generates scene-consistent trajectories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BELT: Block-wise Missing Embedding Learning Transformer. (arXiv:2105.10360v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1">Doudou Zhou</a>, <a href="http://arxiv.org/find/stat/1/au:+Cai_T/0/1/0/all/0/1">Tianxi Cai</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1">Junwei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10360">
                                    <div class="article-summary-box-inner">
                                        <span>Matrix completion has attracted attention in many fields, including
statistics, applied mathematics, and electrical engineering. Most of the works
focus on the independent sampling models under which the observed entries are
sampled independently. Motivated by applications in the integration of multiple
Electronic Health Record (EHR) datasets, we propose the method {\bf B}lock-wise
missing {\bf E}mbedding {\bf L}earning {\bf T}ransformer (BELT) to treat
row-wise/column-wise missingness. Specifically, BELT can recover block-wise
missing matrices efficiently when every pair of matrices has an overlap. Our
idea is to exploit the orthogonal Procrustes problem to align the eigenspace of
the two sub-matrices using their overlap, then complete the missing blocks by
the inner product of the two low-rank components. Besides, we prove the
statistical rate for the eigenspace of the underlying matrix, which is
comparable to the rate under the independently missing assumption. Simulation
studies show that the method performs well under a variety of configurations.
In the real data analysis, the method is applied to two tasks: (i) the
integrating of several point-wise mutual information matrices built by English
EHR and Chinese medical text data, and (ii) the machine translation between
English and Chinese medical concepts. Our method shows an advantage over
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Schr\&quot;odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1">Francisco Vargas</a>, <a href="http://arxiv.org/find/stat/1/au:+Thodoroff_P/0/1/0/all/0/1">Pierre Thodoroff</a>, <a href="http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1">Neil D. Lawrence</a>, <a href="http://arxiv.org/find/stat/1/au:+Lamacraft_A/0/1/0/all/0/1">Austen Lamacraft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02081">
                                    <div class="article-summary-box-inner">
                                        <span>The Schr\&quot;odinger bridge problem (SBP) finds the most likely stochastic
evolution between two probability distributions given a prior stochastic
evolution. As well as applications in the natural sciences, problems of this
kind have important applications in machine learning such as dataset alignment
and hypothesis testing. Whilst the theory behind this problem is relatively
mature, scalable numerical recipes to estimate the Schr\&quot;odinger bridge remain
an active area of research. We prove an equivalence between the SBP and maximum
likelihood estimation enabling direct application of successful machine
learning techniques. We propose a numerical procedure to estimate SBPs using
Gaussian process and demonstrate the practical usage of our approach in
numerical simulations and experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time Series Domain Adaptation via Sparse Associative Structure Alignment. (arXiv:2012.11797v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Keli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjian Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhuozhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenjie Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11797">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation on time series data is an important but challenging task.
Most of the existing works in this area are based on the learning of the
domain-invariant representation of the data with the help of restrictions like
MMD. However, such extraction of the domain-invariant representation is a
non-trivial task for time series data, due to the complex dependence among the
timestamps. In detail, in the fully dependent time series, a small change of
the time lags or the offsets may lead to difficulty in the domain invariant
extraction. Fortunately, the stability of the causality inspired us to explore
the domain invariant structure of the data. To reduce the difficulty in the
discovery of causal structure, we relax it to the sparse associative structure
and propose a novel sparse associative structure alignment model for domain
adaptation. First, we generate the segment set to exclude the obstacle of
offsets. Second, the intra-variables and inter-variables sparse attention
mechanisms are devised to extract associative structure time-series data with
considering time lags. Finally, the associative structure alignment is used to
guide the transfer of knowledge from the source domain to the target one.
Experimental studies not only verify the good performance of our methods on
three real-world datasets but also provide some insightful discoveries on the
transferred knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants. (arXiv:2102.01567v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zaiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01567">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops an unified framework to study finite-sample convergence
guarantees of a large class of value-based asynchronous reinforcement learning
(RL) algorithms. We do this by first reformulating the RL algorithms as
\textit{Markovian Stochastic Approximation} (SA) algorithms to solve
fixed-point equations. We then develop a Lyapunov analysis and derive
mean-square error bounds on the convergence of the Markovian SA. Based on this
result, we establish finite-sample mean-square convergence bounds for
asynchronous RL algorithms such as $Q$-learning, $n$-step TD, TD$(\lambda)$,
and off-policy TD algorithms including V-trace. As a by-product, by analyzing
the convergence bounds of $n$-step TD and TD$(\lambda)$, we provide theoretical
insights into the bias-variance trade-off, i.e., efficiency of bootstrapping in
RL. This was first posed as an open problem in (Sutton, 1999).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pushing the Limits of Non-Autoregressive Speech Recognition. (arXiv:2104.03416v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ng_E/0/1/0/all/0/1">Edwin G. Ng</a>, <a href="http://arxiv.org/find/eess/1/au:+Chiu_C/0/1/0/all/0/1">Chung-Cheng Chiu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03416">
                                    <div class="article-summary-box-inner">
                                        <span>We combine recent advancements in end-to-end speech recognition to
non-autoregressive automatic speech recognition. We push the limits of
non-autoregressive state-of-the-art results for multiple datasets: LibriSpeech,
Fisher+Switchboard and Wall Street Journal. Key to our recipe, we leverage CTC
on giant Conformer neural network architectures with SpecAugment and wav2vec2
pre-training. We achieve 1.8%/3.6% WER on LibriSpeech test/test-other sets,
5.1%/9.8% WER on Switchboard, and 3.4% on the Wall Street Journal, all without
a language model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Identifiable Features from Noisy Data with Structured Nonlinear ICA. (arXiv:2106.09620v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Halva_H/0/1/0/all/0/1">Hermanni H&#xe4;lv&#xe4;</a>, <a href="http://arxiv.org/find/stat/1/au:+Corff_S/0/1/0/all/0/1">Sylvain Le Corff</a>, <a href="http://arxiv.org/find/stat/1/au:+Lehericy_L/0/1/0/all/0/1">Luc Leh&#xe9;ricy</a>, <a href="http://arxiv.org/find/stat/1/au:+So_J/0/1/0/all/0/1">Jonathan So</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yongjie Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Gassiat_E/0/1/0/all/0/1">Elisabeth Gassiat</a>, <a href="http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1">Aapo Hyvarinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09620">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new general identifiable framework for principled
disentanglement referred to as Structured Nonlinear Independent Component
Analysis (SNICA). Our contribution is to extend the identifiability theory of
deep generative models for a very broad class of structured models. While
previous works have shown identifiability for specific classes of time-series
models, our theorems extend this to more general temporal structures as well as
to models with more complex structures such as spatial dependencies. In
particular, we establish the major result that identifiability for this
framework holds even in the presence of noise of unknown distribution. The
SNICA setting therefore subsumes all the existing nonlinear ICA models for
time-series and also allows for new much richer identifiable models. Finally,
as an example of our framework&#x27;s flexibility, we introduce the first nonlinear
ICA model for time-series that combines the following very useful properties:
it accounts for both nonstationarity and autocorrelation in a fully
unsupervised setting; performs dimensionality reduction; models hidden states;
and enables principled estimation and inference by variational
maximum-likelihood.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks. (arXiv:2006.12557v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12557">
                                    <div class="article-summary-box-inner">
                                        <span>Data poisoning and backdoor attacks manipulate training data in order to
cause models to fail during inference. A recent survey of industry
practitioners found that data poisoning is the number one concern among threats
ranging from model stealing to adversarial attacks. However, it remains unclear
exactly how dangerous poisoning methods are and which ones are more effective
considering that these methods, even ones with identical objectives, have not
been tested in consistent or realistic settings. We observe that data poisoning
and backdoor attacks are highly sensitive to variations in the testing setup.
Moreover, we find that existing methods may not generalize to realistic
settings. While these existing works serve as valuable prototypes for data
poisoning, we apply rigorous tests to determine the extent to which we should
fear them. In order to promote fair comparison in future work, we develop
standardized benchmarks for data poisoning and backdoor attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">There is no data like more data -- current status of machine learning datasets in remote sensing. (arXiv:2105.11726v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmitt_M/0/1/0/all/0/1">Michael Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmadi_S/0/1/0/all/0/1">Seyed Ali Ahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansch_R/0/1/0/all/0/1">Ronny H&#xe4;nsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11726">
                                    <div class="article-summary-box-inner">
                                        <span>Annotated datasets have become one of the most crucial preconditions for the
development and evaluation of machine learning-based methods designed for the
automated interpretation of remote sensing data. In this paper, we review the
historic development of such datasets, discuss their features based on a few
selected examples, and address open issues for future developments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch Value-function Approximation with Only Realizability. (arXiv:2008.04990v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04990">
                                    <div class="article-summary-box-inner">
                                        <span>We make progress in a long-standing problem of batch reinforcement learning
(RL): learning $Q^\star$ from an exploratory and polynomial-sized dataset,
using a realizable and otherwise arbitrary function class. In fact, all
existing algorithms demand function-approximation assumptions stronger than
realizability, and the mounting negative evidence has led to a conjecture that
sample-efficient learning is impossible in this setting (Chen and Jiang, 2019).
Our algorithm, BVFT, breaks the hardness conjecture (albeit under a stronger
notion of exploratory data) via a tournament procedure that reduces the
learning problem to pairwise comparison, and solves the latter with the help of
a state-action partition constructed from the compared functions. We also
discuss how BVFT can be applied to model selection among other extensions and
open problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Proposals for Probabilistic Programs with Inference Combinators. (arXiv:2103.00668v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Stites_S/0/1/0/all/0/1">Sam Stites</a>, <a href="http://arxiv.org/find/stat/1/au:+Zimmermann_H/0/1/0/all/0/1">Heiko Zimmermann</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Sennesh_E/0/1/0/all/0/1">Eli Sennesh</a>, <a href="http://arxiv.org/find/stat/1/au:+Meent_J/0/1/0/all/0/1">Jan-Willem van de Meent</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00668">
                                    <div class="article-summary-box-inner">
                                        <span>We develop operators for construction of proposals in probabilistic programs,
which we refer to as inference combinators. Inference combinators define a
grammar over importance samplers that compose primitive operations such as
application of a transition kernel and importance resampling. Proposals in
these samplers can be parameterized using neural networks, which in turn can be
trained by optimizing variational objectives. The result is a framework for
user-programmable variational methods that are correct by construction and can
be tailored to specific models. We demonstrate the flexibility of this
framework by implementing advanced variational methods based on amortized Gibbs
sampling and annealing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and Positioning Predictor on Edge Devices. (arXiv:2102.03456v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fasfous_N/0/1/0/all/0/1">Nael Fasfous</a>, <a href="http://arxiv.org/find/cs/1/au:+Vemparala_M/0/1/0/all/0/1">Manoj-Rohit Vemparala</a>, <a href="http://arxiv.org/find/cs/1/au:+Frickenstein_A/0/1/0/all/0/1">Alexander Frickenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Frickenstein_L/0/1/0/all/0/1">Lukas Frickenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Stechele_W/0/1/0/all/0/1">Walter Stechele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03456">
                                    <div class="article-summary-box-inner">
                                        <span>Face masks have long been used in many areas of everyday life to protect
against the inhalation of hazardous fumes and particles. They also offer an
effective solution in healthcare for bi-directional protection against
air-borne diseases. Wearing and positioning the mask correctly is essential for
its function. Convolutional neural networks (CNNs) offer an excellent solution
for face recognition and classification of correct mask wearing and
positioning. In the context of the ongoing COVID-19 pandemic, such algorithms
can be used at entrances to corporate buildings, airports, shopping areas, and
other indoor locations, to mitigate the spread of the virus. These application
scenarios impose major challenges to the underlying compute platform. The
inference hardware must be cheap, small and energy efficient, while providing
sufficient memory and compute power to execute accurate CNNs at a reasonably
low latency. To maintain data privacy of the public, all processing must remain
on the edge-device, without any communication with cloud servers. To address
these challenges, we present a low-power binary neural network classifier for
correct facial-mask wear and positioning. The classification task is
implemented on an embedded FPGA, performing high-throughput binary operations.
Classification can take place at up to ~6400 frames-per-second, easily enabling
multi-camera, speed-gate settings or statistics collection in crowd settings.
When deployed on a single entrance or gate, the idle power consumption is
reduced to 1.6W, improving the battery-life of the device. We achieve an
accuracy of up to 98% for four wearing positions of the MaskedFace-Net dataset.
To maintain equivalent classification accuracy for all face structures,
skin-tones, hair types, and mask types, the algorithms are tested for their
ability to generalize the relevant features over all subjects using the
Grad-CAM approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Learning Guarantees for Compressive Clustering and Compressive Mixture Modeling. (arXiv:2004.08085v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1">R&#xe9;mi Gribonval</a> (PANAMA, DANTE), <a href="http://arxiv.org/find/cs/1/au:+Blanchard_G/0/1/0/all/0/1">Gilles Blanchard</a> (LMO), <a href="http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1">Nicolas Keriven</a> (GIPSA-GAIA), <a href="http://arxiv.org/find/cs/1/au:+Traonmilin_Y/0/1/0/all/0/1">Yann Traonmilin</a> (IMB)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08085">
                                    <div class="article-summary-box-inner">
                                        <span>We provide statistical learning guarantees for two unsupervised learning
tasks in the context of compressive statistical learning, a general framework
for resource-efficient large-scale learning that we introduced in a companion
paper. The principle of compressive statistical learning is to compress a
training collection, in one pass, into a low-dimensional sketch (a vector of
random empirical generalized moments) that captures the information relevant to
the considered learning task. We explicit random feature functions which
empirical averages preserve the needed information for compressive clustering
and compressive Gaussian mixture modeling with fixed known variance, and
establish sufficient sketch sizes given the problem dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Label Learning from Single Positive Labels. (arXiv:2106.09708v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1">Elijah Cole</a>, <a href="http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1">Oisin Mac Aodha</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorieul_T/0/1/0/all/0/1">Titouan Lorieul</a>, <a href="http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1">Pietro Perona</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1">Dan Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Jojic_N/0/1/0/all/0/1">Nebojsa Jojic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09708">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting all applicable labels for a given image is known as multi-label
classification. Compared to the standard multi-class case (where each image has
only one label), it is considerably more challenging to annotate training data
for multi-label classification. When the number of potential labels is large,
human annotators find it difficult to mention all applicable labels for each
training image. Furthermore, in some settings detection is intrinsically
difficult e.g. finding small object instances in high resolution images. As a
result, multi-label training data is often plagued by false negatives. We
consider the hardest version of this problem, where annotators provide only one
relevant label for each image. As a result, training sets will have only one
positive label per image and no confirmed negatives. We explore this special
case of learning from missing labels across four different multi-label image
classification datasets for both linear classifiers and end-to-end fine-tuned
deep networks. We extend existing multi-label losses to this setting and
propose novel variants that constrain the number of expected positive labels
during training. Surprisingly, we show that in some cases it is possible to
approach the performance of fully labeled classifiers despite training with
significantly fewer confirmed labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AN-GCN: An Anonymous Graph Convolutional Network Defense Against Edge-Perturbing Attack. (arXiv:2005.03482v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Ao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+wang_R/0/1/0/all/0/1">Rui wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03482">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have revealed the vulnerability of graph convolutional
networks (GCNs) to edge-perturbing attacks, such as maliciously inserting or
deleting graph edges. However, a theoretical proof of such vulnerability
remains a big challenge, and effective defense schemes are still open issues.
In this paper, we first generalize the formulation of edge-perturbing attacks
and strictly prove the vulnerability of GCNs to such attacks in node
classification tasks. Following this, an anonymous graph convolutional network,
named AN-GCN, is proposed to counter against edge-perturbing attacks.
Specifically, we present a node localization theorem to demonstrate how the GCN
locates nodes during its training phase. In addition, we design a staggered
Gaussian noise based node position generator, and devise a spectral graph
convolution based discriminator in detecting the generated node positions.
Further, we give the optimization of the above generator and discriminator.
AN-GCN can classify nodes without taking their position as input. It is
demonstrated that the AN-GCN is secure against edge-perturbing attacks in node
classification tasks, as AN-GCN classifies nodes without the edge information
and thus makes it impossible for attackers to perturb edges anymore. Extensive
evaluations demonstrated the effectiveness of the general edge-perturbing
attack model in manipulating the classification results of the target nodes.
More importantly, the proposed AN-GCN can achieve 82.7% in node classification
accuracy without the edge-reading permission, which outperforms the
state-of-the-art GCN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning. (arXiv:2102.09756v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minchao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Norrish_M/0/1/0/all/0/1">Michael Norrish</a>, <a href="http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1">Christian Walder</a>, <a href="http://arxiv.org/find/cs/1/au:+Dezfouli_A/0/1/0/all/0/1">Amir Dezfouli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09756">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel approach to interactive theorem-proving (ITP) using deep
reinforcement learning. The proposed framework is able to learn proof search
strategies as well as tactic and arguments prediction in an end-to-end manner.
We formulate the process of ITP as a Markov decision process (MDP) in which
each state represents a set of potential derivation paths. This structure
allows us to introduce a novel backtracking mechanism which enables the agent
to efficiently discard (predicted) dead-end derivations and restart from
promising alternatives. We implement the framework in the HOL4 theorem prover.
Experimental results show that the framework outperforms existing automated
theorem provers (i.e., hammers) available in HOL4 when evaluated on unseen
problems. We further elaborate the role of key components of the framework
using ablation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Short Note of PAGE: Optimal Convergence Rates for Nonconvex Optimization. (arXiv:2106.09663v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1">Zhize Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09663">
                                    <div class="article-summary-box-inner">
                                        <span>In this note, we first recall the nonconvex problem setting and introduce the
optimal PAGE algorithm (Li et al., ICML&#x27;21). Then we provide a simple and clean
convergence analysis of PAGE for achieving optimal convergence rates. Moreover,
PAGE and its analysis can be easily adopted and generalized to other works. We
hope that this note provides the insights and is helpful for future works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Robust Batch Contextual Bandits. (arXiv:2006.05630v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1">Nian Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1">Jose Blanchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05630">
                                    <div class="article-summary-box-inner">
                                        <span>Policy learning using historical observational data is an important problem
that has found widespread applications. Examples include selecting offers,
prices, advertisements to send to customers, as well as selecting which
medication to prescribe to a patient. However, existing literature rests on the
crucial assumption that the future environment where the learned policy will be
deployed is the same as the past environment that has generated the data--an
assumption that is often false or too coarse an approximation. In this paper,
we lift this assumption and aim to learn a distributional robust policy with
incomplete (bandit) observational data. We propose a novel learning algorithm
that is able to learn a robust policy to adversarial perturbations and unknown
covariate shifts. We first present a policy evaluation procedure in the
ambiguous environment and then give a performance guarantee based on the theory
of uniform convergence. Additionally, we also give a heuristic algorithm to
solve the distributional robust policy learning problems efficiently. Finally,
we demonstrate the robustness of our methods in the synthetic and real-world
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAR-U-Net: a Residual Encoder to Attention Decoder by Residual Connections Framework for Spine Segmentation under Noisy Labels. (arXiv:2009.12873v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1">Ziyang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengdong Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Voiculescu_I/0/1/0/all/0/1">Irina Voiculescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12873">
                                    <div class="article-summary-box-inner">
                                        <span>Segmentation algorithms for medical images are widely studied for various
clinical and research purposes. In this paper, we propose a new and efficient
method for medical image segmentation under noisy labels. The method operates
under a deep learning paradigm, incorporating four novel contributions.
Firstly, a residual interconnection is explored in different scale encoders to
transfer gradient information efficiently. Secondly, four copy-and-crop
connections are replaced by residual-block-based concatenation to alleviate the
disparity between encoders and decoders. Thirdly, convolutional attention
modules for feature refinement are studied on all scale decoders. Finally, an
adaptive denoising learning strategy (ADL) is introduced into the training
process to avoid too much influence from the noisy labels. Experimental results
are illustrated on a publicly available benchmark database of spine CTs. Our
proposed method achieves competitive performance against other state-of-the-art
methods over a variety of different evaluation measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks. (arXiv:2004.05937v7 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kuk-Jin Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.05937">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural models in recent years have been successful in almost every
field, including extremely complex problem statements. However, these models
are huge in size, with millions (and even billions) of parameters, thus
demanding more heavy computation power and failing to be deployed on edge
devices. Besides, the performance boost is highly dependent on redundant
labeled data. To achieve faster speeds and to handle the problems caused by the
lack of data, knowledge distillation (KD) has been proposed to transfer
information learned from one model to another. KD is often characterized by the
so-called &#x60;Student-Teacher&#x27; (S-T) learning framework and has been broadly
applied in model compression and knowledge transfer. This paper is about KD and
S-T learning, which are being actively studied in recent years. First, we aim
to provide explanations of what KD is and how/why it works. Then, we provide a
comprehensive survey on the recent progress of KD methods together with S-T
frameworks typically for vision tasks. In general, we consider some fundamental
questions that have been driving this research area and thoroughly generalize
the research progress and technical details. Additionally, we systematically
analyze the research status of KD in vision applications. Finally, we discuss
the potentials and open challenges of existing methods and prospect the future
directions of KD and S-T learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving adversarial robustness of deep neural networks by using semantic information. (arXiv:2008.07838v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Rui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yawei Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xuemei Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.07838">
                                    <div class="article-summary-box-inner">
                                        <span>The vulnerability of deep neural networks (DNNs) to adversarial attack, which
is an attack that can mislead state-of-the-art classifiers into making an
incorrect classification with high confidence by deliberately perturbing the
original inputs, raises concerns about the robustness of DNNs to such attacks.
Adversarial training, which is the main heuristic method for improving
adversarial robustness and the first line of defense against adversarial
attacks, requires many sample-by-sample calculations to increase training size
and is usually insufficiently strong for an entire network. This paper provides
a new perspective on the issue of adversarial robustness, one that shifts the
focus from the network as a whole to the critical part of the region close to
the decision boundary corresponding to a given class. From this perspective, we
propose a method to generate a single but image-agnostic adversarial
perturbation that carries the semantic information implying the directions to
the fragile parts on the decision boundary and causes inputs to be
misclassified as a specified target. We call the adversarial training based on
such perturbations &quot;region adversarial training&quot; (RAT), which resembles
classical adversarial training but is distinguished in that it reinforces the
semantic information missing in the relevant regions. Experimental results on
the MNIST and CIFAR-10 datasets show that this approach greatly improves
adversarial robustness even using a very small dataset from the training data;
moreover, it can defend against FGSM adversarial attacks that have a completely
different pattern from the model seen during retraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine-learning enhanced dark soliton detection in Bose-Einstein condensates. (arXiv:2101.05404v2 [cond-mat.quant-gas] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Guo_S/0/1/0/all/0/1">Shangjie Guo</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fritsch_A/0/1/0/all/0/1">Amilson R. Fritsch</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Greenberg_C/0/1/0/all/0/1">Craig Greenberg</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Spielman_I/0/1/0/all/0/1">I. B. Spielman</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zwolak_J/0/1/0/all/0/1">Justyna P. Zwolak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05404">
                                    <div class="article-summary-box-inner">
                                        <span>Most data in cold-atom experiments comes from images, the analysis of which
is limited by our preconceptions of the patterns that could be present in the
data. We focus on the well-defined case of detecting dark solitons -- appearing
as local density depletions in a Bose-Einstein condensate (BEC) -- using a
methodology that is extensible to the general task of pattern recognition in
images of cold atoms. Studying soliton dynamics over a wide range of parameters
requires the analysis of large datasets, making the existing
human-inspection-based methodology a significant bottleneck. Here we describe
an automated classification and positioning system for identifying localized
excitations in atomic BECs utilizing deep convolutional neural networks to
eliminate the need for human image examination. Furthermore, we openly publish
our labeled dataset of dark solitons, the first of its kind, for further
machine learning research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse bottleneck neural networks for exploratory non-linear visualization of Patch-seq data. (arXiv:2006.10411v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bernaerts_Y/0/1/0/all/0/1">Yves Bernaerts</a>, <a href="http://arxiv.org/find/cs/1/au:+Berens_P/0/1/0/all/0/1">Philipp Berens</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobak_D/0/1/0/all/0/1">Dmitry Kobak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10411">
                                    <div class="article-summary-box-inner">
                                        <span>Patch-seq, a recently developed experimental technique, allows
neuroscientists to obtain transcriptomic and electrophysiological information
from the same neurons. Efficiently analyzing and visualizing such paired
multivariate data in order to extract biologically meaningful interpretations
has, however, remained a challenge. Here, we use sparse deep neural networks
with a two-dimensional bottleneck and group lasso penalty to predict
electrophysiological features from the transcriptomic ones, yielding concise
and biologically interpretable two-dimensional visualizations. In two large
example data sets, this visualization reveals known neural classes and their
marker genes without biological prior knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient reconstruction of depth three circuits with top fan-in two. (arXiv:2103.07445v2 [cs.CC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_G/0/1/0/all/0/1">Gaurav Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07445">
                                    <div class="article-summary-box-inner">
                                        <span>We develop efficient randomized algorithms to solve the black-box
reconstruction problem for polynomials over finite fields, computable by depth
three arithmetic circuits with alternating addition/multiplication gates, such
that output gate is an addition gate with in-degree two. These circuits compute
polynomials of form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of
affine forms, and polynomials $T_1,T_2$ have no common factors. Rank of such a
circuit is defined as dimension of vector space spanned by all affine factors
of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit,
$rank(f)$ is defined to be the minimum rank of any such circuit computing it.
Our work develops randomized reconstruction algorithms which take as input
black-box access to a polynomial $f$ (over finite field $\mathbb{F}$),
computable by such a circuit. Here are the results.

1 [Low rank]: When $5\leq rank(f) &#x3D; O(\log^3 d)$, it runs in time
$(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a
depth three circuit computing $f$, with top addition gate having in-degree
$\leq d^{rank(f)}$.

2 [High rank]: When $rank(f) &#x3D; \Omega(\log^3 d)$, it runs in time $(nd\log
|\mathbb{F}|)^{O(1)}$, and, with high probability, outputs a depth three
circuit computing $f$, with top addition gate having in-degree two.

Ours is the first blackbox reconstruction algorithm for this circuit class,
that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been
mentioned as an open problem in [GKL12] (STOC 2012)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distribution Free Uncertainty for the Minimum Norm Solution of Over-parameterized Linear Regression. (arXiv:2102.07181v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bibas_K/0/1/0/all/0/1">Koby Bibas</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_M/0/1/0/all/0/1">Meir Feder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07181">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental principle of learning theory is that there is a trade-off
between the complexity of a prediction rule and its ability to generalize.
Modern machine learning models do not obey this paradigm: They produce an
accurate prediction even with a perfect fit to the training set. We investigate
over-parameterized linear regression models focusing on the minimum norm
solution: This is the solution with the minimal norm that attains a perfect fit
to the training set. We utilize the recently proposed predictive normalized
maximum likelihood (pNML) learner which is the min-max regret solution for the
distribution-free setting. We derive an upper bound of this min-max regret
which is associated with the prediction uncertainty. We show that if the test
sample lies mostly in a subspace spanned by the eigenvectors associated with
the large eigenvalues of the empirical correlation matrix of the training data,
the model generalizes despite its over-parameterized nature. We demonstrate the
use of the pNML regret as a point-wise learnability measure on synthetic data
and successfully observe the double-decent phenomenon of the over-parameterized
models on UCI datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss. (arXiv:2106.04156v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1">Jeff Z. HaoChen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04156">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works in self-supervised learning have advanced the state-of-the-art
by relying on the contrastive learning paradigm, which learns representations
by pushing positive pairs, or similar examples from the same class, closer
together while keeping negative pairs far apart. Despite the empirical
successes, theoretical foundations are limited -- prior analyses assume
conditional independence of the positive pairs given the same class label, but
recent empirical applications use heavily correlated positive pairs (i.e., data
augmentations of the same image). Our work analyzes contrastive learning
without assuming conditional independence of positive pairs using a novel
concept of the augmentation graph on data. Edges in this graph connect
augmentations of the same data, and ground-truth classes naturally form
connected sub-graphs. We propose a loss that performs spectral decomposition on
the population augmentation graph and can be succinctly written as a
contrastive learning objective on neural net representations. Minimizing this
objective leads to features with provable accuracy guarantees under linear
probe evaluation. By standard generalization bounds, these accuracy guarantees
also hold when minimizing the training contrastive loss. Empirically, the
features learned by our objective can match or outperform several strong
baselines on benchmark vision datasets. In all, this work provides the first
provable analysis for contrastive learning where guarantees for linear probe
evaluation can apply to realistic empirical settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMN4: Few-shot Learning via Discriminative Mutual Nearest Neighbor Neural Network. (arXiv:2103.08160v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofei He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08160">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to classify images under low-data regimes, where
the conventional pooled global representation is likely to lose useful local
characteristics. Recent work has achieved promising performances by using deep
descriptors. They generally take all deep descriptors from neural networks into
consideration while ignoring that some of them are useless in classification
due to their limited receptive field, e.g., task-irrelevant descriptors could
be misleading and multiple aggregative descriptors from background clutter
could even overwhelm the object&#x27;s presence. In this paper, we argue that a
Mutual Nearest Neighbor (MNN) relation should be established to explicitly
select the query descriptors that are most relevant to each task and discard
less relevant ones from aggregative clutters in FSL. Specifically, we propose
Discriminative Mutual Nearest Neighbor Neural Network (DMN4) for FSL. Extensive
experiments demonstrate that our method not only qualitatively selects
task-relevant descriptors but also quantitatively outperforms the existing
state-of-the-arts by a large margin of 1.8~4.9% on fine-grained CUB, a
considerable margin of 1.4~2.2% on both supervised and semi-supervised
miniImagenet, and ~1.4% on challenging tieredimagenet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Source Identification on Networks with Statistical Confidence. (arXiv:2106.04800v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dawkins_Q/0/1/0/all/0/1">Quinlan Dawkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haifeng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04800">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion source identification on networks is a problem of fundamental
importance in a broad class of applications, including rumor controlling and
virus identification. Though this problem has received significant recent
attention, most studies have focused only on very restrictive settings and lack
theoretical guarantees for more realistic networks. We introduce a statistical
framework for the study of diffusion source identification and develop a
confidence set inference approach inspired by hypothesis testing. Our method
efficiently produces a small subset of nodes, which provably covers the source
node with any pre-specified confidence level without restrictive assumptions on
network structures. Moreover, we propose multiple Monte Carlo strategies for
the inference procedure based on network topology and the probabilistic
properties that significantly improve the scalability. To our knowledge, this
is the first diffusion source identification method with a practically useful
theoretical guarantee on general networks. We demonstrate our approach via
extensive synthetic experiments on well-known random network models and a
mobility network between cities concerning the COVID-19 spreading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Data Usage via Differentiable Rewards. (arXiv:1911.10088v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1">Paul Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1">Antonios Anastasopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Carbonell_J/0/1/0/all/0/1">Jaime Carbonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.10088">
                                    <div class="article-summary-box-inner">
                                        <span>To acquire a new skill, humans learn better and faster if a tutor, based on
their current knowledge level, informs them of how much attention they should
pay to particular content or practice problems. Similarly, a machine learning
model could potentially be trained better with a scorer that &quot;adapts&quot; to its
current learning state and estimates the importance of each training data
instance. Training such an adaptive scorer efficiently is a challenging
problem; in order to precisely quantify the effect of a data instance at a
given time during the training, it is typically necessary to first complete the
entire training process. To efficiently optimize data usage, we propose a
reinforcement learning approach called Differentiable Data Selection (DDS). In
DDS, we formulate a scorer network as a learnable function of the training
data, which can be efficiently updated along with the main model being trained.
Specifically, DDS updates the scorer with an intuitive reward signal: it should
up-weigh the data that has a similar gradient with a dev set upon which we
would finally like to perform well. Without significant computing overhead, DDS
delivers strong and consistent improvements over several strong baselines on
two very different tasks of machine translation and image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent Asymmetric Embedding for Cascade Prediction on Social Networks. (arXiv:2105.08291v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Wenjin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaomeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_T/0/1/0/all/0/1">Tao Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08291">
                                    <div class="article-summary-box-inner">
                                        <span>The prediction for information diffusion on social networks has great
practical significance in marketing and public opinion control. Cascade
prediction aims to predict the individuals who will potentially repost the
message on the social network. One kind of methods either exploit
demographical, structural, and temporal features for prediction, or explicitly
rely on particular information diffusion models. The other kind of models are
fully data-driven and do not require a global network structure. Thus massive
diffusion prediction models based on network embedding are proposed. These
models embed the users into the latent space using their cascade information,
but are lack of consideration for the intervene among users when embedding. In
this paper, we propose an independent asymmetric embedding method to learn
social embedding for cascade prediction. Different from existing methods, our
method embeds each individual into one latent influence space and multiple
latent susceptibility spaces. Furthermore, our method captures the
co-occurrence regulation of user combination in cascades to improve the
calculating effectiveness. The results of extensive experiments conducted on
real-world datasets verify both the predictive accuracy and cost-effectiveness
of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Detection of Alzheimer&#x27;s Disease from Speech and Text. (arXiv:2012.00096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1">Amish Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahoo_S/0/1/0/all/0/1">Sourav Sahoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Datar_A/0/1/0/all/0/1">Arnhav Datar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadiwala_J/0/1/0/all/0/1">Juned Kadiwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalu_H/0/1/0/all/0/1">Hrithwik Shalu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathew_J/0/1/0/all/0/1">Jimson Mathew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00096">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable detection of the prodromal stages of Alzheimer&#x27;s disease (AD)
remains difficult even today because, unlike other neurocognitive impairments,
there is no definitive diagnosis of AD in vivo. In this context, existing
research has shown that patients often develop language impairment even in mild
AD conditions. We propose a multimodal deep learning method that utilizes
speech and the corresponding transcript simultaneously to detect AD. For audio
signals, the proposed audio-based network, a convolutional neural network (CNN)
based model, predicts the diagnosis for multiple speech segments, which are
combined for the final prediction. Similarly, we use contextual embedding
extracted from BERT concatenated with a CNN-generated embedding for classifying
the transcript. The individual predictions of the two models are then combined
to make the final classification. We also perform experiments to analyze the
model performance when Automated Speech Recognition (ASR) system generated
transcripts are used instead of manual transcription in the text-based model.
The proposed method achieves 85.3% 10-fold cross-validation accuracy when
trained and evaluated on the Dementiabank Pitt corpus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Low-Rank Regularization with Damping Sequences to Restrict Lazy Weights in Deep Networks. (arXiv:2106.09677v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bejani_M/0/1/0/all/0/1">Mohammad Mahdi Bejani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghatee_M/0/1/0/all/0/1">Mehdi Ghatee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09677">
                                    <div class="article-summary-box-inner">
                                        <span>Overfitting is one of the critical problems in deep neural networks. Many
regularization schemes try to prevent overfitting blindly. However, they
decrease the convergence speed of training algorithms. Adaptive regularization
schemes can solve overfitting more intelligently. They usually do not affect
the entire network weights. This paper detects a subset of the weighting layers
that cause overfitting. The overfitting recognizes by matrix and tensor
condition numbers. An adaptive regularization scheme entitled Adaptive Low-Rank
(ALR) is proposed that converges a subset of the weighting layers to their
Low-Rank Factorization (LRF). It happens by minimizing a new Tikhonov-based
loss function. ALR also encourages lazy weights to contribute to the
regularization when epochs grow up. It uses a damping sequence to increment
layer selection likelihood in the last generations. Thus before falling the
training accuracy, ALR reduces the lazy weights and regularizes the network
substantially. The experimental results show that ALR regularizes the deep
networks well with high training speed and low resource usage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Dimension Reduction for Supervised Representation Learning. (arXiv:2006.05865v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05865">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of supervised representation learning is to construct effective data
representations for prediction. Among all the characteristics of an ideal
nonparametric representation of high-dimensional complex data, sufficiency, low
dimensionality and disentanglement are some of the most essential ones. We
propose a deep dimension reduction approach to learning representations with
these characteristics. The proposed approach is a nonparametric generalization
of the sufficient dimension reduction method. We formulate the ideal
representation learning task as that of finding a nonparametric representation
that minimizes an objective function characterizing conditional independence
and promoting disentanglement at the population level. We then estimate the
target representation at the sample level nonparametrically using deep neural
networks. We show that the estimated deep nonparametric representation is
consistent in the sense that its excess risk converges to zero. Our extensive
numerical experiments using simulated and real benchmark data demonstrate that
the proposed methods have better performance than several existing dimension
reduction methods and the standard deep learning models in the context of
classification and regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scrambled Translation Problem: A Problem of Denoising UNMT. (arXiv:1911.01212v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1">Tamali Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1">Rudra Murthy V</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Pushpak Bhattacharyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01212">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we identify an interesting kind of error in the output of
Unsupervised Neural Machine Translation (UNMT) systems like
\textit{Undreamt}(footnote). We refer to this error type as \textit{Scrambled
Translation problem}. We observe that UNMT models which use \textit{word
shuffle} noise (as in case of Undreamt) can generate correct words, but fail to
stitch them together to form phrases. As a result, words of the translated
sentence look \textit{scrambled}, resulting in decreased BLEU. We hypothesise
that the reason behind \textit{scrambled translation problem} is &#x27;shuffling
noise&#x27; which is introduced in every input sentence as a denoising strategy. To
test our hypothesis, we experiment by retraining UNMT models with a simple
\textit{retraining} strategy. We stop the training of the Denoising UNMT model
after a pre-decided number of iterations and resume the training for the
remaining iterations -- which number is also pre-decided -- using original
sentence as input without adding any noise. Our proposed solution achieves
significant performance improvement UNMT models that train conventionally. We
demonstrate these performance gains on four language pairs, \textit{viz.},
English-French, English-German, English-Spanish, Hindi-Punjabi. Our qualitative
and quantitative analysis shows that the retraining strategy helps achieve
better alignment as observed by attention heatmap and better phrasal
translation, leading to statistically significant improvement in BLEU scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BABEL: Bodies, Action and Behavior with English Labels. (arXiv:2106.09696v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Punnakkal_A/0/1/0/all/0/1">Abhinanda R. Punnakkal</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_A/0/1/0/all/0/1">Arjun Chandrasekaran</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Athanasiou_N/0/1/0/all/0/1">Nikos Athanasiou</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Quiros_Ramirez_A/0/1/0/all/0/1">Alejandra Quiros-Ramirez</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a> (1) ((1) Max Planck Institute for Intelligent Systems, (2) Universitat Konstanz)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09696">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the semantics of human movement -- the what, how and why of the
movement -- is an important problem that requires datasets of human actions
with semantic labels. Existing datasets take one of two approaches. Large-scale
video datasets contain many action labels but do not contain ground-truth 3D
human motion. Alternatively, motion-capture (mocap) datasets have precise body
motions but are limited to a small number of actions. To address this, we
present BABEL, a large dataset with language labels describing the actions
being performed in mocap sequences. BABEL consists of action labels for about
43 hours of mocap sequences from AMASS. Action labels are at two levels of
abstraction -- sequence labels describe the overall action in the sequence, and
frame labels describe all actions in every frame of the sequence. Each frame
label is precisely aligned with the duration of the corresponding action in the
mocap sequence, and multiple actions can overlap. There are over 28k sequence
labels, and 63k frame labels in BABEL, which belong to over 250 unique action
categories. Labels from BABEL can be leveraged for tasks like action
recognition, temporal action localization, motion synthesis, etc. To
demonstrate the value of BABEL as a benchmark, we evaluate the performance of
models on 3D action recognition. We demonstrate that BABEL poses interesting
learning challenges that are applicable to real-world scenarios, and can serve
as a useful benchmark of progress in 3D action recognition. The dataset,
baseline method, and evaluation code is made available, and supported for
academic research purposes at https://babel.is.tue.mpg.de/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral goodness-of-fit tests for complete and partial network data. (arXiv:2106.09702v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lubold_S/0/1/0/all/0/1">Shane Lubold</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_B/0/1/0/all/0/1">Bolun Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1">Tyler H. McCormick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09702">
                                    <div class="article-summary-box-inner">
                                        <span>Networks describe the, often complex, relationships between individual
actors. In this work, we address the question of how to determine whether a
parametric model, such as a stochastic block model or latent space model, fits
a dataset well and will extrapolate to similar data. We use recent results in
random matrix theory to derive a general goodness-of-fit test for dyadic data.
We show that our method, when applied to a specific model of interest, provides
an straightforward, computationally fast way of selecting parameters in a
number of commonly used network models. For example, we show how to select the
dimension of the latent space in latent space models. Unlike other network
goodness-of-fit methods, our general approach does not require simulating from
a candidate parametric model, which can be cumbersome with large graphs, and
eliminates the need to choose a particular set of statistics on the graph for
comparison. It also allows us to perform goodness-of-fit tests on partial
network data, such as Aggregated Relational Data. We show with simulations that
our method performs well in many situations of interest. We analyze several
empirically relevant networks and show that our method leads to improved
community detection algorithms. R code to implement our method is available on
Github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Multimodal Domino: in Search of Biomarkers for Alzheimer&#x27;s Disease. (arXiv:2012.13623v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fedorov_A/0/1/0/all/0/1">Alex Fedorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sylvain_T/0/1/0/all/0/1">Tristan Sylvain</a>, <a href="http://arxiv.org/find/cs/1/au:+Geenjaar_E/0/1/0/all/0/1">Eloy Geenjaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Luck_M/0/1/0/all/0/1">Margaux Luck</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+DeRamus_T/0/1/0/all/0/1">Thomas P. DeRamus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirilin_A/0/1/0/all/0/1">Alex Kirilin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleklov_D/0/1/0/all/0/1">Dmitry Bleklov</a>, <a href="http://arxiv.org/find/cs/1/au:+Calhoun_V/0/1/0/all/0/1">Vince D. Calhoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1">Sergey M. Plis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13623">
                                    <div class="article-summary-box-inner">
                                        <span>Sensory input from multiple sources is crucial for robust and coherent human
perception. Different sources contribute complementary explanatory factors.
Similarly, research studies often collect multimodal imaging data, each of
which can provide shared and unique information. This observation motivated the
design of powerful multimodal self-supervised representation-learning
algorithms. In this paper, we unify recent work on multimodal self-supervised
learning under a single framework. Observing that most self-supervised methods
optimize similarity metrics between a set of model components, we propose a
taxonomy of all reasonable ways to organize this process. We first evaluate
models on toy multimodal MNIST datasets and then apply them to a multimodal
neuroimaging dataset with Alzheimer&#x27;s disease patients. We find that (1)
multimodal contrastive learning has significant benefits over its unimodal
counterpart, (2) the specific composition of multiple contrastive objectives is
critical to performance on a downstream task, (3) maximization of the
similarity between representations has a regularizing effect on a neural
network, which can sometimes lead to reduced downstream performance but still
reveal multimodal relations. Results show that the proposed approach
outperforms previous self-supervised encoder-decoder methods based on canonical
correlation analysis (CCA) or the mixture-of-experts multimodal variational
autoEncoder (MMVAE) on various datasets with a linear evaluation protocol.
Importantly, we find a promising solution to uncover connections between
modalities through a jointly shared subspace that can help advance work in our
search for neuroimaging biomarkers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels. (arXiv:2006.07831v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Songhua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xiaobo Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingming Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Nannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haifeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07831">
                                    <div class="article-summary-box-inner">
                                        <span>Learning with noisy labels has attracted a lot of attention in recent years,
where the mainstream approaches are in pointwise manners. Meanwhile, pairwise
manners have shown great potential in supervised metric learning and
unsupervised contrastive learning. Thus, a natural question is raised: does
learning in a pairwise manner mitigate label noise? To give an affirmative
answer, in this paper, we propose a framework called Class2Simi: it transforms
data points with noisy class labels to data pairs with noisy similarity labels,
where a similarity label denotes whether a pair shares the class label or not.
Through this transformation, the reduction of the noise rate is theoretically
guaranteed, and hence it is in principle easier to handle noisy similarity
labels. Amazingly, DNNs that predict the clean class labels can be trained from
noisy data pairs if they are first pretrained from noisy data points.
Class2Simi is computationally efficient because not only this transformation is
on-the-fly in mini-batches, but also it just changes loss computation on top of
model prediction into a pairwise manner. Its effectiveness is verified by
extensive experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent Neural Networks for Stochastic Control Problems with Delay. (arXiv:2101.01385v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1">Jiequn Han</a>, <a href="http://arxiv.org/find/math/1/au:+Hu_R/0/1/0/all/0/1">Ruimeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01385">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic control problems with delay are challenging due to the
path-dependent feature of the system and thus its intrinsic high dimensions. In
this paper, we propose and systematically study deep neural networks-based
algorithms to solve stochastic control problems with delay features.
Specifically, we employ neural networks for sequence modeling (\emph{e.g.},
recurrent neural networks such as long short-term memory) to parameterize the
policy and optimize the objective function. The proposed algorithms are tested
on three benchmark examples: a linear-quadratic problem, optimal consumption
with fixed finite delay, and portfolio optimization with complete memory.
Particularly, we notice that the architecture of recurrent neural networks
naturally captures the path-dependent feature with much flexibility and yields
better performance with more efficient and stable training of the network
compared to feedforward networks. The superiority is even evident in the case
of portfolio optimization with complete memory, which features infinite delay.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Postprocessing Ensemble Streamflow Forecasts. (arXiv:2106.09547v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Sanjib Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghimire_G/0/1/0/all/0/1">Ganesh Raj Ghimire</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddique_R/0/1/0/all/0/1">Ridwan Siddique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09547">
                                    <div class="article-summary-box-inner">
                                        <span>Skillful streamflow forecasting informs decisions in various areas of water
policy and management. We integrate dynamical modeling with machine learning to
demonstrate the enhanced quality of streamflow forecasts at short-to
medium-range timescales (1 - 7 days). Dynamical modeling generates ensemble
streamflow forecasts by forcing a hydrological model with numerical weather
prediction model outputs. We employ a Long Short-Term Memory (LSTM) neural
network to correct forecast biases in raw ensemble streamflow forecasts
obtained from dynamical modeling. For forecast verification, we use different
metrics such as skill score and reliability diagram conditioned upon the lead
time, flow threshold, and season. The verification results show that the LSTM
can improve streamflow forecasts relative to climatological, temporal
persistence, deterministic, and raw ensemble forecasts. The LSTM demonstrates
improvement across all lead times, flow thresholds, and seasons. As compared to
the raw ensembles, relative gain in forecast skill from LSTM is generally
higher at medium-range timescales compared to initial lead time; high flows
compared to low-moderate flows; and warm-season compared to the cool ones.
Overall, our results highlight the benefits of LSTM for improving both the
skill and reliability of streamflow forecasts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit. (arXiv:2106.09539v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Vaaras_E/0/1/0/all/0/1">Einari Vaaras</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahlqvist_Bjorkroth_S/0/1/0/all/0/1">Sari Ahlqvist-Bj&#xf6;rkroth</a>, <a href="http://arxiv.org/find/eess/1/au:+Drossos_K/0/1/0/all/0/1">Konstantinos Drossos</a>, <a href="http://arxiv.org/find/eess/1/au:+Rasanen_O/0/1/0/all/0/1">Okko R&#xe4;s&#xe4;nen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09539">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers have recently started to study how the emotional speech heard by
young infants can affect their developmental outcomes. As a part of this
research, hundreds of hours of daylong recordings from preterm infants&#x27; audio
environments were collected from two hospitals in Finland and Estonia in the
context of so-called APPLE study. In order to analyze the emotional content of
speech in such a massive dataset, an automatic speech emotion recognition (SER)
system is required. However, there are no emotion labels or existing indomain
SER systems to be used for this purpose. In this paper, we introduce this
initially unannotated large-scale real-world audio dataset and describe the
development of a functional SER system for the Finnish subset of the data. We
explore the effectiveness of alternative state-of-the-art techniques to deploy
a SER system to a new domain, comparing cross-corpus generalization, WGAN-based
domain adaptation, and active learning in the task. As a result, we show that
the best-performing models are able to achieve a classification performance of
73.4% unweighted average recall (UAR) and 73.2% UAR for a binary classification
for valence and arousal, respectively. The results also show that active
learning achieves the most consistent performance compared to the two
alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Author Clustering and Topic Estimation for Short Texts. (arXiv:2106.09533v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tierney_G/0/1/0/all/0/1">Graham Tierney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bail_C/0/1/0/all/0/1">Christopher Bail</a>, <a href="http://arxiv.org/find/cs/1/au:+Volfovsky_A/0/1/0/all/0/1">Alexander Volfovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09533">
                                    <div class="article-summary-box-inner">
                                        <span>Analysis of short text, such as social media posts, is extremely difficult
because it relies on observing many document-level word co-occurrence pairs.
Beyond topic distributions, a common downstream task of the modeling is
grouping the authors of these documents for subsequent analyses. Traditional
models estimate the document groupings and identify user clusters with an
independent procedure. We propose a novel model that expands on the Latent
Dirichlet Allocation by modeling strong dependence among the words in the same
document, with user-level topic distributions. We also simultaneously cluster
users, removing the need for post-hoc cluster estimation and improving topic
estimation by shrinking noisy user-level topic distributions towards typical
values. Our method performs as well as -- or better -- than traditional
approaches to problems arising in short text, and we demonstrate its usefulness
on a dataset of tweets from United States Senators, recovering both meaningful
topics and clusters that reflect partisan ideology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium Meta-Solvers. (arXiv:2106.09435v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marris_L/0/1/0/all/0/1">Luke Marris</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_P/0/1/0/all/0/1">Paul Muller</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanctot_M/0/1/0/all/0/1">Marc Lanctot</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1">Karl Tuyls</a>, <a href="http://arxiv.org/find/cs/1/au:+Grapael_T/0/1/0/all/0/1">Thore Grapael</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09435">
                                    <div class="article-summary-box-inner">
                                        <span>Two-player, constant-sum games are well studied in the literature, but there
has been limited progress outside of this setting. We propose Joint
Policy-Space Response Oracles (JPSRO), an algorithm for training agents in
n-player, general-sum extensive form games, which provably converges to an
equilibrium. We further suggest correlated equilibria (CE) as promising
meta-solvers, and propose a novel solution concept Maximum Gini Correlated
Equilibrium (MGCE), a principled and computationally efficient family of
solutions for solving the correlated equilibrium selection problem. We conduct
several experiments using CE meta-solvers for JPSRO and demonstrate convergence
on n-player, general-sum games.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-head or Single-head? An Empirical Comparison for Transformer Training. (arXiv:2106.09650v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09650">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-head attention plays a crucial role in the recent success of
Transformer models, which leads to consistent performance improvements over
conventional attention in various applications. The popular belief is that this
effectiveness stems from the ability of jointly attending multiple positions.
In this paper, we first demonstrate that jointly attending multiple positions
is not a unique feature of multi-head attention, as multi-layer single-head
attention also attends multiple positions and is more effective. Then, we
suggest the main advantage of the multi-head attention is the training
stability, since it has less number of layers than the single-head attention,
when attending the same number of positions. For example, 24-layer 16-head
Transformer (BERT-large) and 384-layer single-head Transformer has the same
total attention head number and roughly the same model size, while the
multi-head one is significantly shallower. Meanwhile, we show that, with recent
advances in deep learning, we can successfully stabilize the training of the
384-layer Transformer. As the training difficulty is no longer a bottleneck,
substantially deeper single-head Transformer achieves consistent performance
improvements without tuning hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalization of breast MRIs using Cycle-Consistent Generative Adversarial Networks. (arXiv:1912.08061v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Modanwal_G/0/1/0/all/0/1">Gourav Modanwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Vellal_A/0/1/0/all/0/1">Adithya Vellal</a>, <a href="http://arxiv.org/find/eess/1/au:+Mazurowski_M/0/1/0/all/0/1">Maciej A. Mazurowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.08061">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) is widely used
to complement ultrasound examinations and x-ray mammography during the early
detection and diagnosis of breast cancer. However, images generated by various
MRI scanners (e.g. GE Healthcare vs Siemens) differ both in intensity and noise
distribution, preventing algorithms trained on MRIs from one scanner to
generalize to data from other scanners successfully. We propose a method for
image normalization to solve this problem. MRI normalization is challenging
because it requires both normalizing intensity values and mapping between the
noise distributions of different scanners. We utilize a cycle-consistent
generative adversarial network to learn a bidirectional mapping between MRIs
produced by GE Healthcare and Siemens scanners. This allows us learning the
mapping between two different scanner types without matched data, which is not
commonly available. To ensure the preservation of breast shape and structures
within the breast, we propose two technical innovations. First, we incorporate
a mutual information loss with the CycleGAN architecture to ensure that the
structure of the breast is maintained. Second, we propose a modified
discriminator architecture which utilizes a smaller field-of-view to ensure the
preservation of finer details in the breast tissue. Quantitative and
qualitative evaluations show that the second proposed method was able to
consistently preserve a high level of detail in the breast structure while also
performing the proper intensity normalization and noise mapping. Our results
demonstrate that the proposed model can successfully learn a bidirectional
mapping between MRIs produced by different vendors, potentially enabling
improved accuracy of downstream computational algorithms for diagnosis and
detection of breast cancer. All the data used in this study are publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study. (arXiv:2106.09700v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadkarni_R/0/1/0/all/0/1">Rahul Nadkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1">David Wadden</a>, <a href="http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1">Iz Beltagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09700">
                                    <div class="article-summary-box-inner">
                                        <span>Biomedical knowledge graphs (KGs) hold rich information on entities such as
diseases, drugs, and genes. Predicting missing links in these graphs can boost
many important applications, such as drug design and repurposing. Recent work
has shown that general-domain language models (LMs) can serve as &quot;soft&quot; KGs,
and that they can be fine-tuned for the task of KG completion. In this work, we
study scientific LMs for KG completion, exploring whether we can tap into their
latent knowledge to enhance biomedical link prediction. We evaluate several
domain-specific LMs, fine-tuning them on datasets centered on drugs and
diseases that we represent as KGs and enrich with textual entity descriptions.
We integrate the LM-based models with KG embedding models, using a router
method that learns to assign each input example to either type of model and
provides a substantial boost in performance. Finally, we demonstrate the
advantage of LM models in the inductive setting with novel scientific entities.
Our datasets and code are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XCiT: Cross-Covariance Image Transformers. (arXiv:2106.09681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1">Alaaeldin El-Nouby</a>, <a href="http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1">Hugo Touvron</a>, <a href="http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1">Mathilde Caron</a>, <a href="http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1">Piotr Bojanowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1">Armand Joulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Neverova_N/0/1/0/all/0/1">Natalia Neverova</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegou_H/0/1/0/all/0/1">Herv&#xe9; Jegou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09681">
                                    <div class="article-summary-box-inner">
                                        <span>Following their success in natural language processing, transformers have
recently shown much promise for computer vision. The self-attention operation
underlying transformers yields global interactions between all tokens ,i.e.
words or image patches, and enables flexible modelling of image data beyond the
local interactions of convolutions. This flexibility, however, comes with a
quadratic complexity in time and memory, hindering application to long
sequences and high-resolution images. We propose a &quot;transposed&quot; version of
self-attention that operates across feature channels rather than tokens, where
the interactions are based on the cross-covariance matrix between keys and
queries. The resulting cross-covariance attention (XCA) has linear complexity
in the number of tokens, and allows efficient processing of high-resolution
images. Our cross-covariance image transformer (XCiT) is built upon XCA. It
combines the accuracy of conventional transformers with the scalability of
convolutional architectures. We validate the effectiveness and generality of
XCiT by reporting excellent results on multiple vision benchmarks, including
image classification and self-supervised feature learning on ImageNet-1k,
object detection and instance segmentation on COCO, and semantic segmentation
on ADE20k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Through the Lens of Example Difficulty. (arXiv:2106.09647v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baldock_R/0/1/0/all/0/1">Robert J. N. Baldock</a>, <a href="http://arxiv.org/find/cs/1/au:+Maennel_H/0/1/0/all/0/1">Hartmut Maennel</a>, <a href="http://arxiv.org/find/cs/1/au:+Neyshabur_B/0/1/0/all/0/1">Behnam Neyshabur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09647">
                                    <div class="article-summary-box-inner">
                                        <span>Existing work on understanding deep learning often employs measures that
compress all data-dependent information into a few numbers. In this work, we
adopt a perspective based on the role of individual examples. We introduce a
measure of the computational difficulty of making a prediction for a given
input: the (effective) prediction depth. Our extensive investigation reveals
surprising yet simple relationships between the prediction depth of a given
input and the model&#x27;s uncertainty, confidence, accuracy and speed of learning
for that data point. We further categorize difficult examples into three
interpretable groups, demonstrate how these groups are processed differently
inside deep models and showcase how this understanding allows us to improve
prediction accuracy. Insights from our study lead to a coherent view of a
number of separately reported phenomena in the literature: early layers
generalize while later layers memorize; early layers converge faster and
networks learn easy data and simple functions first.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accuracy, Interpretability, and Differential Privacy via Explainable Boosting. (arXiv:2106.09680v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nori_H/0/1/0/all/0/1">Harsha Nori</a>, <a href="http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1">Rich Caruana</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_Z/0/1/0/all/0/1">Zhiqi Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Judy Hanwen Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1">Janardhan Kulkarni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09680">
                                    <div class="article-summary-box-inner">
                                        <span>We show that adding differential privacy to Explainable Boosting Machines
(EBMs), a recent method for training interpretable ML models, yields
state-of-the-art accuracy while protecting privacy. Our experiments on multiple
classification and regression datasets show that DP-EBM models suffer
surprisingly little accuracy loss even with strong differential privacy
guarantees. In addition to high accuracy, two other benefits of applying DP to
EBMs are: a) trained models provide exact global and local interpretability,
which is often important in settings where differential privacy is needed; and
b) the models can be edited after training without loss of privacy to correct
errors which DP noise may have introduced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Low Can We Go: Trading Memory for Error in Low-Precision Training. (arXiv:2106.09686v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chengrun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chee_J/0/1/0/all/0/1">Jerry Chee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>, <a href="http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1">Madeleine Udell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09686">
                                    <div class="article-summary-box-inner">
                                        <span>Low-precision arithmetic trains deep learning models using less energy, less
memory and less time. However, we pay a price for the savings: lower precision
may yield larger round-off error and hence larger prediction error. As
applications proliferate, users must choose which precision to use to train a
new model, and chip manufacturers must decide which precisions to manufacture.
We view these precision choices as a hyperparameter tuning problem, and borrow
ideas from meta-learning to learn the tradeoff between memory and error. In
this paper, we introduce Pareto Estimation to Pick the Perfect Precision
(PEPPP). We use matrix factorization to find non-dominated configurations (the
Pareto frontier) with a limited number of network evaluations. For any given
memory budget, the precision that minimizes error is a point on this frontier.
Practitioners can use the frontier to trade memory for error and choose the
best precision for their goals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Reinforcement Learning Approach towards Pendulum Swing-up Problem based on TF-Agents. (arXiv:2106.09556v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bi_Y/0/1/0/all/0/1">Yifei Bi</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1">Xinyi Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Xiao_C/0/1/0/all/0/1">Caihui Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09556">
                                    <div class="article-summary-box-inner">
                                        <span>Adapting the idea of training CartPole with Deep Q-learning agent, we are
able to find a promising result that prevent the pole from falling down. The
capacity of reinforcement learning (RL) to learn from the interaction between
the environment and agent provides an optimal control strategy. In this paper,
we aim to solve the classic pendulum swing-up problem that making the learned
pendulum to be in upright position and balanced. Deep Deterministic Policy
Gradient algorithm is introduced to operate over continuous action domain in
this problem. Salient results of optimal pendulum are proved with increasing
average return, decreasing loss, and live video in the code part.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving On-Screen Sound Separation for Open Domain Videos with Audio-Visual Self-attention. (arXiv:2106.09669v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1">Efthymios Tzinis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wisdom_S/0/1/0/all/0/1">Scott Wisdom</a>, <a href="http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1">Tal Remez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershey_J/0/1/0/all/0/1">John R. Hershey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09669">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a state-of-the-art audio-visual on-screen sound separation
system which is capable of learning to separate sounds and associate them with
on-screen objects by looking at in-the-wild videos. We identify limitations of
previous work on audiovisual on-screen sound separation, including the
simplicity and coarse resolution of spatio-temporal attention, and poor
convergence of the audio separation model. Our proposed model addresses these
issues using cross-modal and self-attention modules that capture audio-visual
dependencies at a finer resolution over time, and by unsupervised pre-training
of audio separation model. These improvements allow the model to generalize to
a much wider set of unseen videos. For evaluation and semi-supervised training,
we collected human annotations of on-screen audio from a large database of
in-the-wild videos (YFCC100M). Our results show marked improvements in
on-screen separation performance, in more general conditions than previous
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LoRA: Low-Rank Adaptation of Large Language Models. (arXiv:2106.09685v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Edward J. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallis_P/0/1/0/all/0/1">Phillip Wallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shean Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09685">
                                    <div class="article-summary-box-inner">
                                        <span>The dominant paradigm of natural language processing consists of large-scale
pre-training on general domain data and adaptation to particular tasks or
domains. As we pre-train larger models, conventional fine-tuning, which
retrains all model parameters, becomes less feasible. Using GPT-3 175B as an
example, deploying many independent instances of fine-tuned models, each with
175B parameters, is extremely expensive. We propose Low-Rank Adaptation, or
LoRA, which freezes the pre-trained model weights and injects trainable rank
decomposition matrices into each layer of the Transformer architecture, greatly
reducing the number of trainable parameters for downstream tasks. For GPT-3,
LoRA can reduce the number of trainable parameters by 10,000 times and the
computation hardware requirement by 3 times compared to full fine-tuning. LoRA
performs on-par or better than fine-tuning in model quality on both GPT-3 and
GPT-2, despite having fewer trainable parameters, a higher training throughput,
and no additional inference latency. We also provide an empirical investigation
into rank-deficiency in language model adaptations, which sheds light on the
efficacy of LoRA. We release our implementation in GPT-2 at
https://github.com/microsoft/LoRA .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning. (arXiv:2106.09701v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">James Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1">Yen-Chang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Balloch_J/0/1/0/all/0/1">Jonathan Balloch</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yilin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hongxia Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09701">
                                    <div class="article-summary-box-inner">
                                        <span>Modern computer vision applications suffer from catastrophic forgetting when
incrementally learning new concepts over time. The most successful approaches
to alleviate this forgetting require extensive replay of previously seen data,
which is problematic when memory constraints or data legality concerns exist.
In this work, we consider the high-impact problem of Data-Free
Class-Incremental Learning (DFCIL), where an incremental learning agent must
learn new concepts over time without storing generators or training data from
past tasks. One approach for DFCIL is to replay synthetic images produced by
inverting a frozen copy of the learner&#x27;s classification model, but we show this
approach fails for common class-incremental benchmarks when using standard
distillation strategies. We diagnose the cause of this failure and propose a
novel incremental distillation strategy for DFCIL, contributing a modified
cross-entropy training and importance-weighted feature distillation, and show
that our method results in up to a 25.1% increase in final task accuracy
(absolute difference) compared to SOTA DFCIL methods for common
class-incremental benchmarks. Our method even outperforms several standard
replay based methods which store a coreset of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Visual Robustness by Causal Intervention. (arXiv:2106.09534v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Kaihua Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1">Mingyuan Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanwang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09534">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is the de facto most promising defense against
adversarial examples. Yet, its passive nature inevitably prevents it from being
immune to unknown attackers. To achieve a proactive defense, we need a more
fundamental understanding of adversarial examples, beyond the popular bounded
threat model. In this paper, we provide a causal viewpoint of adversarial
vulnerability: the cause is the confounder ubiquitously existing in learning,
where attackers are precisely exploiting the confounding effect. Therefore, a
fundamental solution for adversarial robustness is causal intervention. As the
confounder is unobserved in general, we propose to use the instrumental
variable that achieves intervention without the need for confounder
observation. We term our robust training method as Causal intervention by
instrumental Variable (CiiV). It has a differentiable retinotopic sampling
layer and a consistency loss, which is stable and guaranteed not to suffer from
gradient obfuscation. Extensive experiments on a wide spectrum of attackers and
settings applied in MNIST, CIFAR-10, and mini-ImageNet datasets empirically
demonstrate that CiiV is robust to adaptive attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Calibration: Meta-Learning of Model Calibration Using Differentiable Expected Calibration Error. (arXiv:2106.09613v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1">Ondrej Bohdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Timothy Hospedales</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09613">
                                    <div class="article-summary-box-inner">
                                        <span>Calibration of neural networks is a topical problem that is becoming
increasingly important for real-world use of neural networks. The problem is
especially noticeable when using modern neural networks, for which there is
significant difference between the model confidence and the confidence it
should have. Various strategies have been successfully proposed, yet there is
more space for improvements. We propose a novel approach that introduces a
differentiable metric for expected calibration error and successfully uses it
as an objective for meta-learning, achieving competitive results with
state-of-the-art approaches. Our approach presents a new direction of using
meta-learning to directly optimize model calibration, which we believe will
inspire further work in this promising and new direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design and Analysis of Robust Deep Learning Models for Stock Price Prediction. (arXiv:2106.09664v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Sen_J/0/1/0/all/0/1">Jaydip Sen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mehtab_S/0/1/0/all/0/1">Sidra Mehtab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09664">
                                    <div class="article-summary-box-inner">
                                        <span>Building predictive models for robust and accurate prediction of stock prices
and stock price movement is a challenging research problem to solve. The
well-known efficient market hypothesis believes in the impossibility of
accurate prediction of future stock prices in an efficient stock market as the
stock prices are assumed to be purely stochastic. However, numerous works
proposed by researchers have demonstrated that it is possible to predict future
stock prices with a high level of precision using sophisticated algorithms,
model architectures, and the selection of appropriate variables in the models.
This chapter proposes a collection of predictive regression models built on
deep learning architecture for robust and precise prediction of the future
prices of a stock listed in the diversified sectors in the National Stock
Exchange (NSE) of India. The Metastock tool is used to download the historical
stock prices over a period of two years (2013- 2014) at 5 minutes intervals.
While the records for the first year are used to train the models, the testing
is carried out using the remaining records. The design approaches of all the
models and their performance results are presented in detail. The models are
also compared based on their execution time and accuracy of prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hi-Phy: A Benchmark for Hierarchical Physical Reasoning. (arXiv:2106.09692v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1">Cheng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_V/0/1/0/all/0/1">Vimukthini Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Gamage_C/0/1/0/all/0/1">Chathura Gamage</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Renz_J/0/1/0/all/0/1">Jochen Renz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09692">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning about the behaviour of physical objects is a key capability of
agents operating in physical worlds. Humans are very experienced in physical
reasoning while it remains a major challenge for AI. To facilitate research
addressing this problem, several benchmarks have been proposed recently.
However, these benchmarks do not enable us to measure an agent&#x27;s granular
physical reasoning capabilities when solving a complex reasoning task. In this
paper, we propose a new benchmark for physical reasoning that allows us to test
individual physical reasoning capabilities. Inspired by how humans acquire
these capabilities, we propose a general hierarchy of physical reasoning
capabilities with increasing complexity. Our benchmark tests capabilities
according to this hierarchy through generated physical reasoning tasks in the
video game Angry Birds. This benchmark enables us to conduct a comprehensive
agent evaluation by measuring the agent&#x27;s granular physical reasoning
capabilities. We conduct an evaluation with human players, learning agents, and
heuristic agents and determine their capabilities. Our evaluation shows that
learning agents, with good local generalization ability, still struggle to
learn the underlying physical reasoning capabilities and perform worse than
current state-of-the-art heuristic agents and humans. We believe that this
benchmark will encourage researchers to develop intelligent agents with
advanced, human-like physical reasoning capabilities. URL:
https://github.com/Cheng-Xue/Hi-Phy</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Knowledge Graph-based World Models of Textual Environments. (arXiv:2106.09608v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1">Prithviraj Ammanabrolu</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1">Mark O. Riedl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09608">
                                    <div class="article-summary-box-inner">
                                        <span>World models improve a learning agent&#x27;s ability to efficiently operate in
interactive and situated environments. This work focuses on the task of
building world models of text-based game environments. Text-based games, or
interactive narratives, are reinforcement learning environments in which agents
perceive and interact with the world using textual natural language. These
environments contain long, multi-step puzzles or quests woven through a world
that is filled with hundreds of characters, locations, and objects. Our world
model learns to simultaneously: (1) predict changes in the world caused by an
agent&#x27;s actions when representing the world as a knowledge graph; and (2)
generate the set of contextually relevant natural language actions required to
operate in the world. We frame this task as a Set of Sequences generation
problem by exploiting the inherent structure of knowledge graphs and actions
and introduce both a transformer-based multi-task architecture and a loss
function to train it. A zero-shot ablation study on never-before-seen textual
worlds shows that our methodology significantly outperforms existing textual
world modeling techniques as well as the importance of each of our
contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Anytime Learning at Macroscale. (arXiv:2106.09563v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ott_M/0/1/0/all/0/1">Myle Ott</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranzato_M/0/1/0/all/0/1">Marc&#x27;Aurelio Ranzato</a>, <a href="http://arxiv.org/find/cs/1/au:+Denoyer_L/0/1/0/all/0/1">Ludovic Denoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09563">
                                    <div class="article-summary-box-inner">
                                        <span>Classical machine learning frameworks assume access to a possibly large
dataset in order to train a predictive model. In many practical applications
however, data does not arrive all at once, but in batches over time. This
creates a natural trade-off between accuracy of a model and time to obtain such
a model. A greedy predictor could produce non-trivial predictions by
immediately training on batches as soon as these become available but, it may
also make sub-optimal use of future data. On the other hand, a tardy predictor
could wait for a long time to aggregate several batches into a larger dataset,
but ultimately deliver a much better performance. In this work, we consider
such a streaming learning setting, which we dub {\em anytime learning at
macroscale} (ALMA). It is an instance of anytime learning applied not at the
level of a single chunk of data, but at the level of the entire sequence of
large batches. We first formalize this learning setting, we then introduce
metrics to assess how well learners perform on the given task for a given
memory and compute budget, and finally we test several baseline approaches on
standard benchmarks repurposed for anytime learning at macroscale. The general
finding is that bigger models always generalize better. In particular, it is
important to grow model capacity over time if the initial model is relatively
small. Moreover, updating the model at an intermediate rate strikes the best
trade off between accuracy and time to obtain a useful predictor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix Recovery. (arXiv:2106.09211v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junhui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jingkai Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">John Wright</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09211">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework -- Square Root Principal Component Pursuit -- for
low-rank matrix recovery from observations corrupted with noise and outliers.
Inspired by the square root Lasso, this new formulation does not require prior
knowledge of the noise level. We show that a single, universal choice of the
regularization parameter suffices to achieve reconstruction error proportional
to the (a priori unknown) noise level. In comparison, previous formulations
such as stable PCP rely on noise-dependent parameters to achieve similar
performance, and are therefore challenging to deploy in applications where the
noise level is unknown. We validate the effectiveness of our new method through
experiments on simulated and real datasets. Our simulations corroborate the
claim that a universal choice of the regularization parameter yields near
optimal performance across a range of noise levels, indicating that the
proposed method outperforms the (somewhat loose) bound proved here.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimality and Stability in Federated Learning: A Game-theoretic Approach. (arXiv:2106.09580v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Donahue_K/0/1/0/all/0/1">Kate Donahue</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09580">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is a distributed learning paradigm where multiple agents,
each only with access to local data, jointly learn a global model. There has
recently been an explosion of research aiming not only to improve the accuracy
rates of federated learning, but also provide certain guarantees around social
good properties such as total error. One branch of this research has taken a
game-theoretic approach, and in particular, prior work has viewed federated
learning as a hedonic game, where error-minimizing players arrange themselves
into federating coalitions. This past work proves the existence of stable
coalition partitions, but leaves open a wide range of questions, including how
far from optimal these stable solutions are. In this work, we motivate and
define a notion of optimality given by the average error rates among federating
agents (players). First, we provide and prove the correctness of an efficient
algorithm to calculate an optimal (error minimizing) arrangement of players.
Next, we analyze the relationship between the stability and optimality of an
arrangement. First, we show that for some regions of parameter space, all
stable arrangements are optimal (Price of Anarchy equal to 1). However, we show
this is not true for all settings: there exist examples of stable arrangements
with higher cost than optimal (Price of Anarchy greater than 1). Finally, we
give the first constant-factor bound on the performance gap between stability
and optimality, proving that the total error of the worst stable solution can
be no higher than 9 times the total error of an optimal solution (Price of
Anarchy bound of 9).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Work in Progress: Mobile or FPGA? A Comprehensive Evaluation on Energy Efficiency and a Unified Optimization Framework. (arXiv:2106.09166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1">Peiyan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mengshu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuxuan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xulong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09166">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient deployment of Deep Neural Networks (DNNs) on edge devices (i.e.,
FPGAs and mobile platforms) is very challenging, especially under a recent
witness of the increasing DNN model size and complexity. Although various
optimization approaches have been proven to be effective in many DNNs on edge
devices, most state-of-the-art work focuses on ad-hoc optimizations, and there
lacks a thorough study to comprehensively reveal the potentials and constraints
of different edge devices when considering different optimizations. In this
paper, we qualitatively and quantitatively compare the energy-efficiency of
FPGA-based and mobile-based DNN executions, and provide detailed analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mungojerrie: Reinforcement Learning of Linear-Time Objectives. (arXiv:2106.09161v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hahn_E/0/1/0/all/0/1">Ernst Moritz Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1">Mateo Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1">Sven Schewe</a>, <a href="http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1">Fabio Somenzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Ashutosh Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1">Dominik Wojtczak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09161">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning synthesizes controllers without prior knowledge of the
system. At each timestep, a reward is given. The controllers optimize the
discounted sum of these rewards. Applying this class of algorithms requires
designing a reward scheme, which is typically done manually. The designer must
ensure that their intent is accurately captured. This may not be trivial, and
is prone to error. An alternative to this manual programming, akin to
programming directly in assembly, is to specify the objective in a formal
language and have it &quot;compiled&quot; to a reward scheme. Mungojerrie
($\href{https://plv.colorado.edu/mungojerrie/}{plv.colorado.edu/mungojerrie}$)
is a tool for testing reward schemes for $\omega$-regular objectives on finite
models. The tool contains reinforcement learning algorithms and a probabilistic
model checker. Mungojerrie supports models specified in PRISM and
$\omega$-automata specified in HOA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Power of Preconditioning in Sparse Linear Regression. (arXiv:2106.09207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kelner_J/0/1/0/all/0/1">Jonathan Kelner</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1">Frederic Koehler</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1">Raghu Meka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohatgi_D/0/1/0/all/0/1">Dhruv Rohatgi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09207">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse linear regression is a fundamental problem in high-dimensional
statistics, but strikingly little is known about how to efficiently solve it
without restrictive conditions on the design matrix. We consider the
(correlated) random design setting, where the covariates are independently
drawn from a multivariate Gaussian $N(0,\Sigma)$ with $\Sigma : n \times n$,
and seek estimators $\hat{w}$ minimizing $(\hat{w}-w^*)^T\Sigma(\hat{w}-w^*)$,
where $w^*$ is the $k$-sparse ground truth. Information theoretically, one can
achieve strong error bounds with $O(k \log n)$ samples for arbitrary $\Sigma$
and $w^*$; however, no efficient algorithms are known to match these guarantees
even with $o(n)$ samples, without further assumptions on $\Sigma$ or $w^*$. As
far as hardness, computational lower bounds are only known with worst-case
design matrices. Random-design instances are known which are hard for the
Lasso, but these instances can generally be solved by Lasso after a simple
change-of-basis (i.e. preconditioning).

In this work, we give upper and lower bounds clarifying the power of
preconditioning in sparse linear regression. First, we show that the
preconditioned Lasso can solve a large class of sparse linear regression
problems nearly optimally: it succeeds whenever the dependency structure of the
covariates, in the sense of the Markov property, has low treewidth -- even if
$\Sigma$ is highly ill-conditioned. Second, we construct (for the first time)
random-design instances which are provably hard for an optimally preconditioned
Lasso. In fact, we complete our treewidth classification by proving that for
any treewidth-$t$ graph, there exists a Gaussian Markov Random Field on this
graph such that the preconditioned Lasso, with any choice of preconditioner,
requires $\Omega(t^{1/20})$ samples to recover $O(\log n)$-sparse signals when
covariates are drawn from this model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-supervised Method for Entity Alignment. (arXiv:2106.09395v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1">Haoyun Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinghao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1">Evgeny Kharlamov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09395">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment, aiming to identify equivalent entities across different
knowledge graphs (KGs), is a fundamental problem for constructing large-scale
KGs. Over the course of its development, supervision has been considered
necessary for accurate alignments. Inspired by the recent progress of
self-supervised learning, we explore the extent to which we can get rid of
supervision for entity alignment. Existing supervised methods for this task
focus on pulling each pair of positive (labeled) entities close to each other.
However, our analysis suggests that the learning of entity alignment can
actually benefit more from pushing sampled (unlabeled) negatives far away than
pulling positive aligned pairs close. We present SelfKG by leveraging this
discovery to design a contrastive learning strategy across two KGs. Extensive
experiments on benchmark datasets demonstrate that SelfKG without supervision
can match or achieve comparable results with state-of-the-art supervised
baselines. The performance of SelfKG demonstrates self-supervised learning
offers great potential for entity alignment in KGs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gone Fishing: Neural Active Learning with Fisher Embeddings. (arXiv:2106.09675v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ash_J/0/1/0/all/0/1">Jordan T. Ash</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Surbhi Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham Kakade</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09675">
                                    <div class="article-summary-box-inner">
                                        <span>There is an increasing need for effective active learning algorithms that are
compatible with deep neural networks. While there are many classic,
well-studied sample selection methods, the non-convexity and varying internal
representation of neural models make it unclear how to extend these approaches.
This article introduces BAIT, a practical, tractable, and high-performing
active learning algorithm for neural networks that addresses these concerns.
BAIT draws inspiration from the theoretical analysis of maximum likelihood
estimators (MLE) for parametric models. It selects batches of samples by
optimizing a bound on the MLE error in terms of the Fisher information, which
we show can be implemented efficiently at scale by exploiting linear-algebraic
structure especially amenable to execution on modern hardware. Our experiments
show that BAIT outperforms the previous state of the art on both classification
and regression problems, and is flexible enough to be used with a variety of
model architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-intrusive Nonlinear Model Reduction via Machine Learning Approximations to Low-dimensional Operators. (arXiv:2106.09658v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1">Zhe Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1">Liqian Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09658">
                                    <div class="article-summary-box-inner">
                                        <span>Although projection-based reduced-order models (ROMs) for parameterized
nonlinear dynamical systems have demonstrated exciting results across a range
of applications, their broad adoption has been limited by their intrusivity:
implementing such a reduced-order model typically requires significant
modifications to the underlying simulation code. To address this, we propose a
method that enables traditionally intrusive reduced-order models to be
accurately approximated in a non-intrusive manner. Specifically, the approach
approximates the low-dimensional operators associated with projection-based
reduced-order models (ROMs) using modern machine-learning regression
techniques. The only requirement of the simulation code is the ability to
export the velocity given the state and parameters as this functionality is
used to train the approximated low-dimensional operators. In addition to
enabling nonintrusivity, we demonstrate that the approach also leads to very
low computational complexity, achieving up to $1000\times$ reduction in run
time. We demonstrate the effectiveness of the proposed technique on two types
of PDEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rotation Invariant Graph Neural Networks using Spin Convolutions. (arXiv:2106.09575v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shuaibi_M/0/1/0/all/0/1">Muhammed Shuaibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolluru_A/0/1/0/all/0/1">Adeesh Kolluru</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1">Abhishek Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>, <a href="http://arxiv.org/find/cs/1/au:+Sriram_A/0/1/0/all/0/1">Anuroop Sriram</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulissi_Z/0/1/0/all/0/1">Zachary Ulissi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09575">
                                    <div class="article-summary-box-inner">
                                        <span>Progress towards the energy breakthroughs needed to combat climate change can
be significantly accelerated through the efficient simulation of atomic
systems. Simulation techniques based on first principles, such as Density
Functional Theory (DFT), are limited in their practical use due to their high
computational expense. Machine learning approaches have the potential to
approximate DFT in a computationally efficient manner, which could dramatically
increase the impact of computational simulations on real-world problems.
Approximating DFT poses several challenges. These include accurately modeling
the subtle changes in the relative positions and angles between atoms, and
enforcing constraints such as rotation invariance or energy conservation. We
introduce a novel approach to modeling angular information between sets of
neighboring atoms in a graph neural network. Rotation invariance is achieved
for the network&#x27;s edge messages through the use of a per-edge local coordinate
frame and a novel spin convolution over the remaining degree of freedom. Two
model variants are proposed for the applications of structure relaxation and
molecular dynamics. State-of-the-art results are demonstrated on the
large-scale Open Catalyst 2020 dataset. Comparisons are also performed on the
MD17 and QM9 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Eye-tracking Using Deep Learning. (arXiv:2106.09621v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seyedi_S/0/1/0/all/0/1">Salman Seyedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zifan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Levey_A/0/1/0/all/0/1">Allan Levey</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_G/0/1/0/all/0/1">Gari D. Clifford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09621">
                                    <div class="article-summary-box-inner">
                                        <span>The expanding usage of complex machine learning methods like deep learning
has led to an explosion in human activity recognition, particularly applied to
health. In particular, as part of a larger body sensor network system, face and
full-body analysis is becoming increasingly common for evaluating health
status. However, complex models which handle private and sometimes protected
data, raise concerns about the potential leak of identifiable data. In this
work, we focus on the case of a deep network model trained on images of
individual faces. Full-face video recordings taken from 493 individuals
undergoing an eye-tracking based evaluation of neurological function were used.
Outputs, gradients, intermediate layer outputs, loss, and labels were used as
inputs for a deep network with an added support vector machine emission layer
to recognize membership in the training data. The inference attack method and
associated mathematical analysis indicate that there is a low likelihood of
unintended memorization of facial features in the deep learning model. In this
study, it is showed that the named model preserves the integrity of training
data with reasonable confidence. The same process can be implemented in similar
conditions for different models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prototypical Graph Contrastive Learning. (arXiv:2106.09645v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zi-Yuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuojia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruihui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09645">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-level representations are critical in various real-world applications,
such as predicting the properties of molecules. But in practice, precise graph
annotations are generally very expensive and time-consuming. To address this
issue, graph contrastive learning constructs instance discrimination task which
pulls together positive pairs (augmentation pairs of the same graph) and pushes
away negative pairs (augmentation pairs of different graphs) for unsupervised
representation learning. However, since for a query, its negatives are
uniformly sampled from all graphs, existing methods suffer from the critical
sampling bias issue, i.e., the negatives likely having the same semantic
structure with the query, leading to performance degradation. To mitigate this
sampling bias issue, in this paper, we propose a Prototypical Graph Contrastive
Learning (PGCL) approach. Specifically, PGCL models the underlying semantic
structure of the graph data via clustering semantically similar graphs into the
same group, and simultaneously encourages the clustering consistency for
different augmentations of the same graph. Then given a query, it performs
negative sampling via drawing the graphs from those clusters that differ from
the cluster of query, which ensures the semantic difference between query and
its negative samples. Moreover, for a query, PGCL further reweights its
negative samples based on the distance between their prototypes (cluster
centroids) and the query prototype such that those negatives having moderate
prototype distance enjoy relatively large weights. This reweighting strategy is
proved to be more effective than uniform sampling. Experimental results on
various graph benchmarks testify the advantages of our PGCL over
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Explainable Student Group Collaboration Assessment Models Using Temporal Representations of Individual Student Roles. (arXiv:2106.09623v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1">Anirudh Som</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sujeong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Prado_B/0/1/0/all/0/1">Bladimir Lopez-Prado</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamija_S/0/1/0/all/0/1">Svati Dhamija</a>, <a href="http://arxiv.org/find/cs/1/au:+Alozie_N/0/1/0/all/0/1">Nonye Alozie</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamrakar_A/0/1/0/all/0/1">Amir Tamrakar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09623">
                                    <div class="article-summary-box-inner">
                                        <span>Collaboration is identified as a required and necessary skill for students to
be successful in the fields of Science, Technology, Engineering and Mathematics
(STEM). However, due to growing student population and limited teaching staff
it is difficult for teachers to provide constructive feedback and instill
collaborative skills using instructional methods. Development of simple and
easily explainable machine-learning-based automated systems can help address
this problem. Improving upon our previous work, in this paper we propose using
simple temporal-CNN deep-learning models to assess student group collaboration
that take in temporal representations of individual student roles as input. We
check the applicability of dynamically changing feature representations for
student group collaboration assessment and how they impact the overall
performance. We also use Grad-CAM visualizations to better understand and
interpret the important temporal indices that led to the deep-learning model&#x27;s
decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poisoning and Backdooring Contrastive Learning. (arXiv:2106.09667v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Terzis_A/0/1/0/all/0/1">Andreas Terzis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09667">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning methods like CLIP train on noisy and uncurated training
datasets. This is cheaper than labeling datasets manually, and even improves
out-of-distribution robustness. We show that this practice makes backdoor and
poisoning attacks a significant threat. By poisoning just 0.005% of a dataset
(e.g., just 150 images of the 3 million-example Conceptual Captions dataset),
we can cause the model to misclassify test images by overlaying a small patch.
Targeted poisoning attacks, whereby the model misclassifies a particular test
input with an adversarially-desired label, are even easier requiring control of
less than 0.0001% of the dataset (e.g., just two out of the 3 million images).
Our attacks call into question whether training on noisy and uncurated Internet
scrapes is desirable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Large Scale Molecular Language Representations Capture Important Structural Information?. (arXiv:2106.09553v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1">Jerret Ross</a>, <a href="http://arxiv.org/find/cs/1/au:+Belgodere_B/0/1/0/all/0/1">Brian Belgodere</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenthamarakshan_V/0/1/0/all/0/1">Vijil Chenthamarakshan</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1">Inkit Padhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09553">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting chemical properties from the structure of a molecule is of great
importance in many applications including drug discovery and material design.
Machine learning based molecular property prediction holds the promise of
enabling accurate predictions at much less complexity, when compared to, for
example Density Functional Theory (DFT) calculations. Features extracted from
molecular graphs, using graph neural nets in a supervised manner, have emerged
as strong baselines for such tasks. However, the vast chemical space together
with the limited availability of labels makes supervised learning challenging,
calling for learning a general-purpose molecular representation. Recently,
pre-trained transformer-based language models (PTLMs) on large unlabeled corpus
have produced state-of-the-art results in many downstream natural language
processing tasks. Inspired by this development, here we present molecular
embeddings obtained by training an efficient transformer encoder model,
referred to as MoLFormer. This model was employed with a linear attention
mechanism and highly paralleized training on 1D SMILES sequences of 1.1 billion
unlabeled molecules from the PubChem and ZINC datasets. Experiments show that
the learned molecular representation performs competitively, when compared to
existing graph-based and fingerprint-based supervised learning baselines, on
the challenging tasks of predicting properties of QM8 and QM9 molecules.
Further task-specific fine-tuning of the MoLFormerr representation improves
performance on several of those property prediction benchmarks. These results
provide encouraging evidence that large-scale molecular language models can
capture sufficient structural information to be able to accurately predict
quantum chemical properties and beyond.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Semi-Supervised Learning for Delayed Partially Labelled Data Streams. (arXiv:2106.09170v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomes_H/0/1/0/all/0/1">Heitor Murilo Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzenda_M/0/1/0/all/0/1">Maciej Grzenda</a>, <a href="http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1">Rodrigo Mello</a>, <a href="http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1">Jesse Read</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh Huong Le Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bifet_A/0/1/0/all/0/1">Albert Bifet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09170">
                                    <div class="article-summary-box-inner">
                                        <span>Unlabelled data appear in many domains and are particularly relevant to
streaming applications, where even though data is abundant, labelled data is
rare. To address the learning problems associated with such data, one can
ignore the unlabelled data and focus only on the labelled data (supervised
learning); use the labelled data and attempt to leverage the unlabelled data
(semi-supervised learning); or assume some labels will be available on request
(active learning). The first approach is the simplest, yet the amount of
labelled data available will limit the predictive performance. The second
relies on finding and exploiting the underlying characteristics of the data
distribution. The third depends on an external agent to provide the required
labels in a timely fashion. This survey pays special attention to methods that
leverage unlabelled data in a semi-supervised setting. We also discuss the
delayed labelling issue, which impacts both fully supervised and
semi-supervised methods. We propose a unified problem setting, discuss the
learning guarantees and existing methods, explain the differences between
related problem settings. Finally, we review the current benchmarking practices
and propose adaptations to enhance them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Localized Uncertainty Attacks. (arXiv:2106.09222v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dia_O/0/1/0/all/0/1">Ousmane Amadou Dia</a>, <a href="http://arxiv.org/find/stat/1/au:+Karaletsos_T/0/1/0/all/0/1">Theofanis Karaletsos</a>, <a href="http://arxiv.org/find/stat/1/au:+Hazirbas_C/0/1/0/all/0/1">Caner Hazirbas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>, <a href="http://arxiv.org/find/stat/1/au:+Kabul_I/0/1/0/all/0/1">Ilknur Kaynar Kabul</a>, <a href="http://arxiv.org/find/stat/1/au:+Meijer_E/0/1/0/all/0/1">Erik Meijer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09222">
                                    <div class="article-summary-box-inner">
                                        <span>The susceptibility of deep learning models to adversarial perturbations has
stirred renewed attention in adversarial examples resulting in a number of
attacks. However, most of these attacks fail to encompass a large spectrum of
adversarial perturbations that are imperceptible to humans. In this paper, we
present localized uncertainty attacks, a novel class of threat models against
deterministic and stochastic classifiers. Under this threat model, we create
adversarial examples by perturbing only regions in the inputs where a
classifier is uncertain. To find such regions, we utilize the predictive
uncertainty of the classifier when the classifier is stochastic or, we learn a
surrogate model to amortize the uncertainty when it is deterministic. Unlike
$\ell_p$ ball or functional attacks which perturb inputs indiscriminately, our
targeted changes can be less perceptible. When considered under our threat
model, these attacks still produce strong adversarial examples; with the
examples retaining a greater degree of similarity with the inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis. (arXiv:2106.09660v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1">Nanxin Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zen_H/0/1/0/all/0/1">Heiga Zen</a>, <a href="http://arxiv.org/find/eess/1/au:+Weiss_R/0/1/0/all/0/1">Ron J. Weiss</a>, <a href="http://arxiv.org/find/eess/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1">Najim Dehak</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09660">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces WaveGrad 2, a non-autoregressive generative model for
text-to-speech synthesis. WaveGrad 2 is trained to estimate the gradient of the
log conditional density of the waveform given a phoneme sequence. The model
takes an input phoneme sequence, and through an iterative refinement process,
generates an audio waveform. This contrasts to the original WaveGrad vocoder
which conditions on mel-spectrogram features, generated by a separate model.
The iterative refinement process starts from Gaussian noise, and through a
series of refinement steps (e.g., 50 steps), progressively recovers the audio
sequence. WaveGrad 2 offers a natural way to trade-off between inference speed
and sample quality, through adjusting the number of refinement steps.
Experiments show that the model can generate high fidelity audio, approaching
the performance of a state-of-the-art neural TTS system. We also report various
ablation studies over different model configurations. Audio samples are
available at https://wavegrad.github.io/v2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Importance measures derived from random forests: characterisation and extension. (arXiv:2106.09473v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sutera_A/0/1/0/all/0/1">Antonio Sutera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09473">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays new technologies, and especially artificial intelligence, are more
and more established in our society. Big data analysis and machine learning,
two sub-fields of artificial intelligence, are at the core of many recent
breakthroughs in many application fields (e.g., medicine, communication,
finance, ...), including some that are strongly related to our day-to-day life
(e.g., social networks, computers, smartphones, ...). In machine learning,
significant improvements are usually achieved at the price of an increasing
computational complexity and thanks to bigger datasets. Currently, cutting-edge
models built by the most advanced machine learning algorithms typically became
simultaneously very efficient and profitable but also extremely complex. Their
complexity is to such an extent that these models are commonly seen as
black-boxes providing a prediction or a decision which can not be interpreted
or justified. Nevertheless, whether these models are used autonomously or as a
simple decision-making support tool, they are already being used in machine
learning applications where health and human life are at stake. Therefore, it
appears to be an obvious necessity not to blindly believe everything coming out
of those models without a detailed understanding of their predictions or
decisions. Accordingly, this thesis aims at improving the interpretability of
models built by a specific family of machine learning algorithms, the so-called
tree-based methods. Several mechanisms have been proposed to interpret these
models and we aim along this thesis to improve their understanding, study their
properties, and define their limitations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class Balancing GAN with a Classifier in the Loop. (arXiv:2106.09402v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangwani_H/0/1/0/all/0/1">Harsh Rangwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1">R. Venkatesh Babu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09402">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have swiftly evolved to imitate
increasingly complex image distributions. However, majority of the developments
focus on performance of GANs on balanced datasets. We find that the existing
GANs and their training regimes which work well on balanced datasets fail to be
effective in case of imbalanced (i.e. long-tailed) datasets. In this work we
introduce a novel theoretically motivated Class Balancing regularizer for
training GANs. Our regularizer makes use of the knowledge from a pre-trained
classifier to ensure balanced learning of all the classes in the dataset. This
is achieved via modelling the effective class frequency based on the
exponential forgetting observed in neural networks and encouraging the GAN to
focus on underrepresented classes. We demonstrate the utility of our
regularizer in learning representations for long-tailed distributions via
achieving better performance than existing approaches over multiple datasets.
Specifically, when applied to an unconditional GAN, it improves the FID from
$13.03$ to $9.01$ on the long-tailed iNaturalist-$2019$ dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning methods for postprocessing ensemble forecasts of wind gusts: A systematic comparison. (arXiv:2106.09512v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Schulz_B/0/1/0/all/0/1">Benedikt Schulz</a>, <a href="http://arxiv.org/find/stat/1/au:+Lerch_S/0/1/0/all/0/1">Sebastian Lerch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09512">
                                    <div class="article-summary-box-inner">
                                        <span>Postprocessing ensemble weather predictions to correct systematic errors has
become a standard practice in research and operations. However, only few recent
studies have focused on ensemble postprocessing of wind gust forecasts, despite
its importance for severe weather warnings. Here, we provide a comprehensive
review and systematic comparison of eight statistical and machine learning
methods for probabilistic wind gust forecasting via ensemble postprocessing,
that can be divided in three groups: State of the art postprocessing techniques
from statistics (ensemble model output statistics (EMOS), member-by-member
postprocessing, isotonic distributional regression), established machine
learning methods (gradient-boosting extended EMOS, quantile regression forests)
and neural network-based approaches (distributional regression network,
Bernstein quantile network, histogram estimation network). The methods are
systematically compared using six years of data from a high-resolution,
convection-permitting ensemble prediction system that was run operationally at
the German weather service, and hourly observations at 175 surface weather
stations in Germany. While all postprocessing methods yield calibrated
forecasts and are able to correct the systematic errors of the raw ensemble
predictions, incorporating information from additional meteorological predictor
variables beyond wind gusts leads to significant improvements in forecast
skill. In particular, we propose a flexible framework of locally adaptive
neural networks with different probabilistic forecast types as output, which
not only significantly outperform all benchmark postprocessing methods but also
learn physically consistent relations associated with the diurnal cycle,
especially the evening transition of the planetary boundary layer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algorithmic Bias and Data Bias: Understanding the Relation between Distributionally Robust Optimization and Data Curation. (arXiv:2106.09467v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Slowik_A/0/1/0/all/0/1">Agnieszka S&#x142;owik</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1">L&#xe9;on Bottou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09467">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning systems based on minimizing average error have been shown to
perform inconsistently across notable subsets of the data, which is not exposed
by a low average error for the entire dataset. In consequential social and
economic applications, where data represent people, this can lead to
discrimination of underrepresented gender and ethnic groups. Given the
importance of bias mitigation in machine learning, the topic leads to
contentious debates on how to ensure fairness in practice (data bias versus
algorithmic bias). Distributionally Robust Optimization (DRO) seemingly
addresses this problem by minimizing the worst expected risk across
subpopulations. We establish theoretical results that clarify the relation
between DRO and the optimization of the same loss averaged on an adequately
weighted training dataset. The results cover finite and infinite number of
training distributions, as well as convex and non-convex loss functions. We
show that neither DRO nor curating the training set should be construed as a
complete solution for bias mitigation: in the same way that there is no
universally robust training set, there is no universal way to setup a DRO
problem and ensure a socially acceptable set of results. We then leverage these
insights to provide a mininal set of practical recommendations for addressing
bias with DRO. Finally, we discuss ramifications of our results in other
related applications of DRO, using an example of adversarial robustness. Our
results show that there is merit to both the algorithm-focused and the
data-focused side of the bias debate, as long as arguments in favor of these
positions are precisely qualified and backed by relevant mathematics known
today.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Approach for Normalizing E-commerce Text Attributes (SANTA). (arXiv:2106.09493v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1">Ravi Shankar Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_K/0/1/0/all/0/1">Kartik Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasiwasia_N/0/1/0/all/0/1">Nikhil Rasiwasia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09493">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present SANTA, a scalable framework to automatically
normalize E-commerce attribute values (e.g. &quot;Win 10 Pro&quot;) to a fixed set of
pre-defined canonical values (e.g. &quot;Windows 10&quot;). Earlier works on attribute
normalization focused on fuzzy string matching (also referred as syntactic
matching in this paper). In this work, we first perform an extensive study of
nine syntactic matching algorithms and establish that &#x27;cosine&#x27; similarity leads
to best results, showing 2.7% improvement over commonly used Jaccard index.
Next, we argue that string similarity alone is not sufficient for attribute
normalization as many surface forms require going beyond syntactic matching
(e.g. &quot;720p&quot; and &quot;HD&quot; are synonyms). While semantic techniques like
unsupervised embeddings (e.g. word2vec/fastText) have shown good results in
word similarity tasks, we observed that they perform poorly to distinguish
between close canonical forms, as these close forms often occur in similar
contexts. We propose to learn token embeddings using a twin network with
triplet loss. We propose an embedding learning task leveraging raw attribute
values and product titles to learn these embeddings in a self-supervised
fashion. We show that providing supervision using our proposed task improves
over both syntactic and unsupervised embeddings based techniques for attribute
normalization. Experiments on a real-world attribute normalization dataset of
50 attributes show that the embeddings trained using our proposed approach
obtain 2.3% improvement over best string matching and 19.3% improvement over
best unsupervised embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASR Adaptation for E-commerce Chatbots using Cross-Utterance Context and Multi-Task Language Modeling. (arXiv:2106.09532v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shenoy_A/0/1/0/all/0/1">Ashish Shenoy</a>, <a href="http://arxiv.org/find/eess/1/au:+Bodapati_S/0/1/0/all/0/1">Sravan Bodapati</a>, <a href="http://arxiv.org/find/eess/1/au:+Kirchhoff_K/0/1/0/all/0/1">Katrin Kirchhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09532">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic Speech Recognition (ASR) robustness toward slot entities are
critical in e-commerce voice assistants that involve monetary transactions and
purchases. Along with effective domain adaptation, it is intuitive that cross
utterance contextual cues play an important role in disambiguating domain
specific content words from speech. In this paper, we investigate various
techniques to improve contextualization, content word robustness and domain
adaptation of a Transformer-XL neural language model (NLM) to rescore ASR
N-best hypotheses. To improve contextualization, we utilize turn level dialogue
acts along with cross utterance context carry over. Additionally, to adapt our
domain-general NLM towards e-commerce on-the-fly, we use embeddings derived
from a finetuned masked LM on in-domain data. Finally, to improve robustness
towards in-domain content words, we propose a multi-task model that can jointly
perform content word detection and language modeling tasks. Compared to a
non-contextual LSTM LM baseline, our best performing NLM rescorer results in a
content WER reduction of 19.2% on e-commerce audio test set and a slot labeling
F1 improvement of 6.4%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Laws for Acoustic Models. (arXiv:2106.09488v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Droppo_J/0/1/0/all/0/1">Jasha Droppo</a>, <a href="http://arxiv.org/find/eess/1/au:+Elibol_O/0/1/0/all/0/1">Oguz Elibol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09488">
                                    <div class="article-summary-box-inner">
                                        <span>There is a recent trend in machine learning to increase model quality by
growing models to sizes previously thought to be unreasonable. Recent work has
shown that autoregressive generative models with cross-entropy objective
functions exhibit smooth power-law relationships, or scaling laws, that predict
model quality from model size, training set size, and the available compute
budget. These scaling laws allow one to choose nearly optimal hyper-parameters
given constraints on available training data, model parameter count, or
training computation budget. In this paper, we demonstrate that acoustic models
trained with an auto-predictive coding loss behave as if they are subject to
similar scaling laws. We extend previous work to jointly predict loss due to
model size, to training set size, and to the inherent &quot;irreducible loss&quot; of the
task. We find that the scaling laws accurately match model performance over two
orders of magnitude in both model size and training set size, and make
predictions about the limits of model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coded Federated Learning Framework for AI-Based Mobile Application Services with Privacy-Awareness. (arXiv:2106.09261v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saputra_Y/0/1/0/all/0/1">Yuris Mulya Saputra</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Diep N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1">Dinh Thai Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1">Eryk Dutkiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09261">
                                    <div class="article-summary-box-inner">
                                        <span>By encoding computing tasks, coded computing can not only mitigate straggling
problems in federated learning (FL), but also preserve privacy of sensitive
data uploaded/contributed by participating mobile users (MUs) to the
centralized server, owned by a mobile application provider (MAP). However,
these advantages come with extra coding cost/complexity and communication
overhead (referred to as \emph{privacy cost}) that must be considered given the
limited computing/communications resources at MUs/MAP, the rationality and
incentive competition among MUs in contributing data to the MAP. This article
proposes a novel coded FL-based framework for a privacy-aware mobile
application service to address these challenges. In particular, the MAP first
determines a set of the best MUs for the FL process based on MUs&#x27; provided
information/features. Then, each selected MU can propose a contract to the MAP
according to its expected trainable local data and privacy-protected coded
data. To find the optimal contracts that can maximize utilities of the MAP and
all the participating MUs while maintaining high learning quality of the whole
system, we first develop a multi-principal one-agent contract-based problem
leveraging coded FL-based multiple utility functions under the MUs&#x27; privacy
cost, the MAP&#x27;s limited computing resource, and asymmetric information between
the MAP and MUs. Then, we transform the problem into an equivalent
low-complexity problem and develop an iterative algorithm to solve it.
Experiments with a real-world dataset show that our framework can speed up
training time up to 49% and improve prediction accuracy up to 4.6 times while
enhancing network&#x27;s social welfare, i.e., total utility of all participating
entities, up to 114% under the privacy cost consideration compared with those
of baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoANE: Modeling Context Co-occurrence for Attributed Network Embedding. (arXiv:2106.09241v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsieh_I/0/1/0/all/0/1">I-Chung Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Cheng-Te Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09241">
                                    <div class="article-summary-box-inner">
                                        <span>Attributed network embedding (ANE) is to learn low-dimensional vectors so
that not only the network structure but also node attributes can be preserved
in the embedding space. Existing ANE models do not consider the specific
combination between graph structure and attributes. While each node has its
structural characteristics, such as highly-interconnected neighbors along with
their certain patterns of attribute distribution, each node&#x27;s neighborhood
should be not only depicted by multi-hop nodes, but consider certain clusters
or social circles. To model such information, in this paper, we propose a novel
ANE model, Context Co-occurrence-aware Attributed Network Embedding (CoANE).
The basic idea of CoANE is to model the context attributes that each node&#x27;s
involved diverse patterns, and apply the convolutional mechanism to encode
positional information by treating each attribute as a channel. The learning of
context co-occurrence can capture the latent social circles of each node. To
better encode structural and semantic knowledge of nodes, we devise a three-way
objective function, consisting of positive graph likelihood, contextual
negative sampling, and attribute reconstruction. We conduct experiments on five
real datasets in the tasks of link prediction, node label classification, and
node clustering. The results exhibit that CoANE can significantly outperform
state-of-the-art ANE models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEG-GNN: Graph Neural Networks for Classification of Electroencephalogram (EEG) Signals. (arXiv:2106.09135v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_A/0/1/0/all/0/1">Andac Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Koike_Akino_T/0/1/0/all/0/1">Toshiaki Koike-Akino</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Ye Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Haruna_M/0/1/0/all/0/1">Masaki Haruna</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1">Deniz Erdogmus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09135">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNN) have been frequently used to extract
subject-invariant features from electroencephalogram (EEG) for classification
tasks. This approach holds the underlying assumption that electrodes are
equidistant analogous to pixels of an image and hence fails to explore/exploit
the complex functional neural connectivity between different electrode sites.
We overcome this limitation by tailoring the concepts of convolution and
pooling applied to 2D grid-like inputs for the functional network of electrode
sites. Furthermore, we develop various graph neural network (GNN) models that
project electrodes onto the nodes of a graph, where the node features are
represented as EEG channel samples collected over a trial, and nodes can be
connected by weighted/unweighted edges according to a flexible policy
formulated by a neuroscientist. The empirical evaluations show that our
proposed GNN-based framework outperforms standard CNN classifiers across ErrP,
and RSVP datasets, as well as allowing neuroscientific interpretability and
explainability to deep learning methods tailored to EEG related classification
problems. Another practical advantage of our GNN-based framework is that it can
be used in EEG channel selection, which is critical for reducing computational
cost, and designing portable EEG headsets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Rigorous Theoretical Analysis and Evaluation of GNN Explanations. (arXiv:2106.09078v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1">Marinka Zitnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09078">
                                    <div class="article-summary-box-inner">
                                        <span>As Graph Neural Networks (GNNs) are increasingly employed in real-world
applications, it becomes critical to ensure that the stakeholders understand
the rationale behind their predictions. While several GNN explanation methods
have been proposed recently, there has been little to no work on theoretically
analyzing the behavior of these methods or systematically evaluating their
effectiveness. Here, we introduce the first axiomatic framework for
theoretically analyzing, evaluating, and comparing state-of-the-art GNN
explanation methods. We outline and formalize the key desirable properties that
all GNN explanation methods should satisfy in order to generate reliable
explanations, namely, faithfulness, stability, and fairness. We leverage these
properties to present the first ever theoretical analysis of the effectiveness
of state-of-the-art GNN explanation methods. Our analysis establishes upper
bounds on all the aforementioned properties for popular GNN explanation
methods. We also leverage our framework to empirically evaluate these methods
on multiple real-world datasets from diverse domains. Our empirical results
demonstrate that some popular GNN explanation methods (e.g., gradient-based
methods) perform no better than a random baseline and that methods which
leverage the graph structure are more effective than those that solely rely on
the node features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FORMS: Fine-grained Polarized ReRAM-based In-situ Computation for Mixed-signal DNN Accelerator. (arXiv:2106.09144v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnam_P/0/1/0/all/0/1">Payman Behnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_A/0/1/0/all/0/1">Ali Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Sheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xuehai Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Bojnordi_M/0/1/0/all/0/1">Mahdi Nazm Bojnordi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09144">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works demonstrated the promise of using resistive random access memory
(ReRAM) as an emerging technology to perform inherently parallel analog domain
in-situ matrix-vector multiplication -- the intensive and key computation in
DNNs. With weights stored in the ReRAM crossbar cells as conductance, when the
input vector is applied to word lines, the matrix-vector multiplication results
can be generated as the current in bit lines. A key problem is that the weight
can be either positive or negative, but the in-situ computation assumes all
cells on each crossbar column with the same sign. The current architectures
either use two ReRAM crossbars for positive and negative weights, or add an
offset to weights so that all values become positive. Neither solution is
ideal: they either double the cost of crossbars, or incur extra offset
circuity. To better solve this problem, this paper proposes FORMS, a
fine-grained ReRAM-based DNN accelerator with polarized weights. Instead of
trying to represent the positive/negative weights, our key design principle is
to enforce exactly what is assumed in the in-situ computation -- ensuring that
all weights in the same column of a crossbar have the same sign. It naturally
avoids the cost of an additional crossbar. Such weights can be nicely generated
using alternating direction method of multipliers (ADMM) regularized
optimization, which can exactly enforce certain patterns in DNN weights. To
achieve high accuracy, we propose to use fine-grained sub-array columns, which
provide a unique opportunity for input zero-skipping, significantly avoiding
unnecessary computations. It also makes the hardware much easier to implement.
Putting all together, with the same optimized models, FORMS achieves
significant throughput improvement and speed up in frame per second over ISAAC
with similar area cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Sang Michael Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09226">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained language models have achieved state-of-the-art performance when
adapted to a downstream NLP task. However, theoretical analysis of these models
is scarce and challenging since the pretraining and downstream tasks can be
very different. We propose an analysis framework that links the pretraining and
downstream tasks with an underlying latent variable generative model of text --
the downstream classifier must recover a function of the posterior distribution
over the latent variables. We analyze head tuning (learning a classifier on top
of the frozen pretrained model) and prompt tuning in this setting. The
generative model in our analysis is either a Hidden Markov Model (HMM) or an
HMM augmented with a latent memory component, motivated by long-term
dependencies in natural language. We show that 1) under certain non-degeneracy
conditions on the HMM, simple classification heads can solve the downstream
task, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy
conditions, and 3) our recovery guarantees for the memory-augmented HMM are
stronger than for the vanilla HMM because task-relevant information is easier
to recover from the long-term memory. Experiments on synthetically generated
data from HMMs back our theoretical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LiRA: Learning Visual Speech Representations from Audio through Self-supervision. (arXiv:2106.09171v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Pingchuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mira_R/0/1/0/all/0/1">Rodrigo Mira</a>, <a href="http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1">Stavros Petridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09171">
                                    <div class="article-summary-box-inner">
                                        <span>The large amount of audiovisual content being shared online today has drawn
substantial attention to the prospect of audiovisual self-supervised learning.
Recent works have focused on each of these modalities separately, while others
have attempted to model both simultaneously in a cross-modal fashion. However,
comparatively little attention has been given to leveraging one modality as a
training objective to learn from the other. In this work, we propose Learning
visual speech Representations from Audio via self-supervision (LiRA).
Specifically, we train a ResNet+Conformer model to predict acoustic features
from unlabelled visual speech. We find that this pre-trained model can be
leveraged towards word-level and sentence-level lip-reading through feature
extraction and fine-tuning experiments. We show that our approach significantly
outperforms other self-supervised methods on the Lip Reading in the Wild (LRW)
dataset and achieves state-of-the-art performance on Lip Reading Sentences 2
(LRS2) using only a fraction of the total labelled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Bias-Reduced Gradient Methods. (arXiv:2106.09481v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Asi_H/0/1/0/all/0/1">Hilal Asi</a>, <a href="http://arxiv.org/find/math/1/au:+Carmon_Y/0/1/0/all/0/1">Yair Carmon</a>, <a href="http://arxiv.org/find/math/1/au:+Jambulapati_A/0/1/0/all/0/1">Arun Jambulapati</a>, <a href="http://arxiv.org/find/math/1/au:+Jin_Y/0/1/0/all/0/1">Yujia Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Sidford_A/0/1/0/all/0/1">Aaron Sidford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09481">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a new primitive for stochastic optimization: a low-bias, low-cost
estimator of the minimizer $x_\star$ of any Lipschitz strongly-convex function.
In particular, we use a multilevel Monte-Carlo approach due to Blanchet and
Glynn to turn any optimal stochastic gradient method into an estimator of
$x_\star$ with bias $\delta$, variance $O(\log(1/\delta))$, and an expected
sampling cost of $O(\log(1/\delta))$ stochastic gradient evaluations. As an
immediate consequence, we obtain cheap and nearly unbiased gradient estimators
for the Moreau-Yoshida envelope of any Lipschitz convex function, allowing us
to perform dimension-free randomized smoothing.

We demonstrate the potential of our estimator through four applications.
First, we develop a method for minimizing the maximum of $N$ functions,
improving on recent results and matching a lower bound up logarithmic factors.
Second and third, we recover state-of-the-art rates for projection-efficient
and gradient-efficient optimization using simple algorithms with a transparent
analysis. Finally, we show that an improved version of our estimator would
yield a nearly linear-time, optimal-utility, differentially-private non-smooth
stochastic optimization method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Voice2Series: Reprogramming Acoustic Models for Time Series Classification. (arXiv:2106.09296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yun-Yun Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09296">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to classify time series with limited data is a practical yet
challenging problem. Current methods are primarily based on hand-designed
feature extraction rules or domain-specific data augmentation. Motivated by the
advances in deep speech processing models and the fact that voice data are
univariate temporal signals, in this paper, we propose Voice2Series (V2S), a
novel end-to-end approach that reprograms acoustic models for time series
classification, through input transformation learning and output label mapping.
Leveraging the representation learning power of a large-scale pre-trained
speech processing model, on 30 different time series tasks we show that V2S
either outperforms or is tied with state-of-the-art methods on 20 tasks, and
improves their average accuracy by 1.84%. We further provide a theoretical
justification of V2S by proving its population risk is upper bounded by the
source risk and a Wasserstein distance accounting for feature alignment via
reprogramming. Our results offer new and effective means to time series
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning Randomly Initialized Neural Networks with Iterative Randomization. (arXiv:2106.09269v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chijiwa_D/0/1/0/all/0/1">Daiki Chijiwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ida_Y/0/1/0/all/0/1">Yasutoshi Ida</a>, <a href="http://arxiv.org/find/cs/1/au:+Umakoshi_K/0/1/0/all/0/1">Kenji Umakoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Inoue_T/0/1/0/all/0/1">Tomohiro Inoue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09269">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning the weights of randomly initialized neural networks plays an
important role in the context of lottery ticket hypothesis. Ramanujan et al.
(2020) empirically showed that only pruning the weights can achieve remarkable
performance instead of optimizing the weight values. However, to achieve the
same level of performance as the weight optimization, the pruning approach
requires more parameters in the networks before pruning and thus more memory
space. To overcome this parameter inefficiency, we introduce a novel framework
to prune randomly initialized neural networks with iteratively randomizing
weight values (IteRand). Theoretically, we prove an approximation theorem in
our framework, which indicates that the randomizing operations are provably
effective to reduce the required number of the parameters. We also empirically
demonstrate the parameter efficiency in multiple experiments on CIFAR-10 and
ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Robustness of Bayesian Neural Networks Against Different Types of Attacks. (arXiv:2106.09223v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yutian Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Sheng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jueming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09223">
                                    <div class="article-summary-box-inner">
                                        <span>To evaluate the robustness gain of Bayesian neural networks on image
classification tasks, we perform input perturbations, and adversarial attacks
to the state-of-the-art Bayesian neural networks, with a benchmark CNN model as
reference. The attacks are selected to simulate signal interference and
cyberattacks towards CNN-based machine learning systems. The result shows that
a Bayesian neural network achieves significantly higher robustness against
adversarial attacks generated against a deterministic neural network model,
without adversarial training. The Bayesian posterior can act as the safety
precursor of ongoing malicious activities. Furthermore, we show that the
stochastic classifier after the deterministic CNN extractor has sufficient
robustness enhancement rather than a stochastic feature extractor before the
stochastic classifier. This advises on utilizing stochastic layers in building
decision-making pipelines within a safety-critical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning for complete intersection Calabi-Yau manifolds: a methodological study. (arXiv:2007.15706v2 [hep-th] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-th/1/au:+Erbin_H/0/1/0/all/0/1">Harold Erbin</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Finotello_R/0/1/0/all/0/1">Riccardo Finotello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15706">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the question of predicting both Hodge numbers $h^{1,1}$ and
$h^{2,1}$ of complete intersection Calabi-Yau (CICY) 3-folds using machine
learning (ML), considering both the old and new datasets built respectively by
Candelas-Dale-Lutken-Schimmrigk / Green-H\&quot;ubsch-Lutken and by
Anderson-Gao-Gray-Lee. In real world applications, implementing a ML system
rarely reduces to feed the brute data to the algorithm. Instead, the typical
workflow starts with an exploratory data analysis (EDA) which aims at
understanding better the input data and finding an optimal representation. It
is followed by the design of a validation procedure and a baseline model.
Finally, several ML models are compared and combined, often involving neural
networks with a topology more complicated than the sequential models typically
used in physics. By following this procedure, we improve the accuracy of ML
computations for Hodge numbers with respect to the existing literature. First,
we obtain 97% (resp. 99%) accuracy for $h^{1,1}$ using a neural network
inspired by the Inception model for the old dataset, using only 30% (resp. 70%)
of the data for training. For the new one, a simple linear regression leads to
almost 100% accuracy with 30% of the data for training. The computation of
$h^{2,1}$ is less successful as we manage to reach only 50% accuracy for both
datasets, but this is still better than the 16% obtained with a simple neural
network (SVM with Gaussian kernel and feature engineering and sequential
convolutional network reach at best 36%). This serves as a proof of concept
that neural networks can be valuable to study the properties of geometries
appearing in string theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal fusion with gating using audio, lexical and disfluency features for Alzheimer&#x27;s Dementia recognition from spontaneous speech. (arXiv:2106.09668v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rohanian_M/0/1/0/all/0/1">Morteza Rohanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hough_J/0/1/0/all/0/1">Julian Hough</a>, <a href="http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1">Matthew Purver</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09668">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is a submission to the Alzheimer&#x27;s Dementia Recognition through
Spontaneous Speech (ADReSS) challenge, which aims to develop methods that can
assist in the automated prediction of severity of Alzheimer&#x27;s Disease from
speech data. We focus on acoustic and natural language features for cognitive
impairment detection in spontaneous speech in the context of Alzheimer&#x27;s
Disease Diagnosis and the mini-mental state examination (MMSE) score
prediction. We proposed a model that obtains unimodal decisions from different
LSTMs, one for each modality of text and audio, and then combines them using a
gating mechanism for the final prediction. We focused on sequential modelling
of text and audio and investigated whether the disfluencies present in
individuals&#x27; speech relate to the extent of their cognitive impairment. Our
results show that the proposed classification and regression schemes obtain
very promising results on both development and test sets. This suggests
Alzheimer&#x27;s Disease can be detected successfully with sequence modeling of the
speech data of medical sessions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Prototype Learning for Interpretable Multivariable Time Series Classification. (arXiv:2106.09636v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosal_G/0/1/0/all/0/1">Gaurav R. Ghosal</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasi_Asl_R/0/1/0/all/0/1">Reza Abbasi-Asl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09636">
                                    <div class="article-summary-box-inner">
                                        <span>Multivariable time series classification problems are increasing in
prevalence and complexity in a variety of domains, such as biology and finance.
While deep learning methods are an effective tool for these problems, they
often lack interpretability. In this work, we propose a novel modular prototype
learning framework for multivariable time series classification. In the first
stage of our framework, encoders extract features from each variable
independently. Prototype layers identify single-variable prototypes in the
resulting feature spaces. The next stage of our framework represents the
multivariable time series sample points in terms of their similarity to these
single-variable prototypes. This results in an inherently interpretable
representation of multivariable patterns, on which prototype learning is
applied to extract representative examples i.e. multivariable prototypes. Our
framework is thus able to explicitly identify both informative patterns in the
individual variables, as well as the relationships between the variables. We
validate our framework on a simulated dataset with embedded patterns, as well
as a real human activity recognition problem. Our framework attains comparable
or superior classification performance to existing time series classification
methods on these tasks. On the simulated dataset, we find that our model
returns interpretations consistent with the embedded patterns. Moreover, the
interpretations learned on the activity recognition dataset align with domain
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distance Metric Learning for Graph Structured Data. (arXiv:2002.00727v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yoshida_T/0/1/0/all/0/1">Tomoki Yoshida</a>, <a href="http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1">Ichiro Takeuchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karasuyama_M/0/1/0/all/0/1">Masayuki Karasuyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00727">
                                    <div class="article-summary-box-inner">
                                        <span>Graphs are versatile tools for representing structured data. As a result, a
variety of machine learning methods have been studied for graph data analysis.
Although many such learning methods depend on the measurement of differences
between input graphs, defining an appropriate distance metric for graphs
remains a controversial issue. Hence, we propose a supervised distance metric
learning method for the graph classification problem. Our method, named
interpretable graph metric learning (IGML), learns discriminative metrics in a
subgraph-based feature space, which has a strong graph representation
capability. By introducing a sparsity-inducing penalty on the weight of each
subgraph, IGML can identify a small number of important subgraphs that can
provide insight into the given classification task. Because our formulation has
a large number of optimization variables, an efficient algorithm that uses
pruning techniques based on safe screening and working set selection methods is
also proposed. An important property of IGML is that solution optimality is
guaranteed because the problem is formulated as a convex problem and our
pruning strategies only discard unnecessary subgraphs. Furthermore, we show
that IGML is also applicable to other structured data such as itemset and
sequence data, and that it can incorporate vertex-label similarity by using a
transportation-based subgraph feature. We empirically evaluate the
computational efficiency and classification performance of IGML on several
benchmark datasets and provide some illustrative examples of how IGML
identifies important subgraphs from a given graph dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Reinforcement Learning of Symbolic Reasoning Domains. (arXiv:2106.09146v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poesia_G/0/1/0/all/0/1">Gabriel Poesia</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">WenXin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09146">
                                    <div class="article-summary-box-inner">
                                        <span>Abstract symbolic reasoning, as required in domains such as mathematics and
logic, is a key component of human intelligence. Solvers for these domains have
important applications, especially to computer-assisted education. But learning
to solve symbolic problems is challenging for machine learning algorithms.
Existing models either learn from human solutions or use hand-engineered
features, making them expensive to apply in new domains. In this paper, we
instead consider symbolic domains as simple environments where states and
actions are given as unstructured text, and binary rewards indicate whether a
problem is solved. This flexible setup makes it easy to specify new domains,
but search and planning become challenging. We introduce four environments
inspired by the Mathematics Common Core Curriculum, and observe that existing
Reinforcement Learning baselines perform poorly. We then present a novel
learning algorithm, Contrastive Policy Learning (ConPoLe) that explicitly
optimizes the InfoNCE loss, which lower bounds the mutual information between
the current state and next states that continue on a path to the solution.
ConPoLe successfully solves all four domains. Moreover, problem representations
learned by ConPoLe enable accurate prediction of the categories of problems in
a real mathematics curriculum. Our results suggest new directions for
reinforcement learning in symbolic domains, as well as applications to
mathematics education.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smart Contract Vulnerability Detection: From Pure Neural Network to Interpretable Graph Feature and Expert Pattern Fusion. (arXiv:2106.09282v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenguang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1">Peng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qinming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shouling Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09282">
                                    <div class="article-summary-box-inner">
                                        <span>Smart contracts hold digital coins worth billions of dollars, their security
issues have drawn extensive attention in the past years. Towards smart contract
vulnerability detection, conventional methods heavily rely on fixed expert
rules, leading to low accuracy and poor scalability. Recent deep learning
approaches alleviate this issue but fail to encode useful expert knowledge. In
this paper, we explore combining deep learning with expert patterns in an
explainable fashion. Specifically, we develop automatic tools to extract expert
patterns from the source code. We then cast the code into a semantic graph to
extract deep graph features. Thereafter, the global graph feature and local
expert patterns are fused to cooperate and approach the final prediction, while
yielding their interpretable weights. Experiments are conducted on all
available smart contracts with source code in two platforms, Ethereum and VNT
Chain. Empirically, our system significantly outperforms state-of-the-art
methods. Our code is released.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Dark Side of Calibration for Modern Neural Networks. (arXiv:2106.09385v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Aditya Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bay_A/0/1/0/all/0/1">Alessandro Bay</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_B/0/1/0/all/0/1">Biswa Sengupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirabile_A/0/1/0/all/0/1">Andrea Mirabile</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09385">
                                    <div class="article-summary-box-inner">
                                        <span>Modern neural networks are highly uncalibrated. It poses a significant
challenge for safety-critical systems to utilise deep neural networks (DNNs),
reliably. Many recently proposed approaches have demonstrated substantial
progress in improving DNN calibration. However, they hardly touch upon
refinement, which historically has been an essential aspect of calibration.
Refinement indicates separability of a network&#x27;s correct and incorrect
predictions. This paper presents a theoretically and empirically supported
exposition for reviewing a model&#x27;s calibration and refinement. Firstly, we show
the breakdown of expected calibration error (ECE), into predicted confidence
and refinement. Connecting with this result, we highlight that regularisation
based calibration only focuses on naively reducing a model&#x27;s confidence. This
logically has a severe downside to a model&#x27;s refinement. We support our claims
through rigorous empirical evaluations of many state of the art calibration
approaches on standard datasets. We find that many calibration approaches with
the likes of label smoothing, mixup etc. lower the utility of a DNN by
degrading its refinement. Even under natural data shift, this
calibration-refinement trade-off holds for the majority of calibration methods.
These findings call for an urgent retrospective into some popular pathways
taken for modern DNN calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Heterogeneous Clients with Elastic Federated Learning. (arXiv:2106.09433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zichen Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zihan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenye Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1">Jinfeng Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09433">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning involves training machine learning models over devices or
data silos, such as edge processors or data warehouses, while keeping the data
local. Training in heterogeneous and potentially massive networks introduces
bias into the system, which is originated from the non-IID data and the low
participation rate in reality. In this paper, we propose Elastic Federated
Learning (EFL), an unbiased algorithm to tackle the heterogeneity in the
system, which makes the most informative parameters less volatile during
training, and utilizes the incomplete local updates. It is an efficient and
effective algorithm that compresses both upstream and downstream
communications. Theoretically, the algorithm has convergence guarantee when
training on the non-IID data at the low participation rate. Empirical
experiments corroborate the competitive performance of EFL framework on the
robustness and the efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Biomedical Interpretable Entity Representations. (arXiv:2106.09502v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garcia_Olano_D/0/1/0/all/0/1">Diego Garcia-Olano</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1">Yasumasa Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1">Ioana Baldini</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_J/0/1/0/all/0/1">Joydeep Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1">Kush R. Varshney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09502">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models induce dense entity representations that offer
strong performance on entity-centric NLP tasks, but such representations are
not immediately interpretable. This can be a barrier to model uptake in
important domains such as biomedicine. There has been recent work on general
interpretable representation learning (Onoe and Durrett, 2020), but these
domain-agnostic representations do not readily transfer to the important domain
of biomedicine. In this paper, we create a new entity type system and training
set from a large corpus of biomedical texts by mapping entities to concepts in
a medical ontology, and from these to Wikipedia pages whose categories are our
types. From this mapping we derive Biomedical Interpretable Entity
Representations(BIERs), in which dimensions correspond to fine-grained entity
types, and values are predicted probabilities that a given entity is of the
corresponding type. We propose a novel method that exploits BIER&#x27;s final sparse
and intermediate dense representations to facilitate model and entity type
debugging. We show that BIERs achieve strong performance in biomedical tasks
including named entity disambiguation and entity label classification, and we
provide error analysis to highlight the utility of their interpretability,
particularly in low-supervision settings. Finally, we provide our induced 68K
biomedical type system, the corresponding 37 million triples of derived data
used to train BIER models and our best performing model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Path Representation Learning with Curriculum Negative Sampling. (arXiv:2106.09373v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sean Bin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chenjuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jilin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09373">
                                    <div class="article-summary-box-inner">
                                        <span>Path representations are critical in a variety of transportation
applications, such as estimating path ranking in path recommendation systems
and estimating path travel time in navigation systems. Existing studies often
learn task-specific path representations in a supervised manner, which require
a large amount of labeled training data and generalize poorly to other tasks.
We propose an unsupervised learning framework Path InfoMax (PIM) to learn
generic path representations that work for different downstream tasks. We first
propose a curriculum negative sampling method, for each input path, to generate
a small amount of negative paths, by following the principles of curriculum
learning. Next, \emph{PIM} employs mutual information maximization to learn
path representations from both a global and a local view. In the global view,
PIM distinguishes the representations of the input paths from those of the
negative paths. In the local view, \emph{PIM} distinguishes the input path
representations from the representations of the nodes that appear only in the
negative paths. This enables the learned path representations to encode both
global and local information at different scales. Extensive experiments on two
downstream tasks, ranking score estimation and travel time estimation, using
two road network datasets suggest that PIM significantly outperforms other
unsupervised methods and is also able to be used as a pre-training method to
enhance supervised path representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC-Bayes, MAC-Bayes and Conditional Mutual Information: Fast rate bounds that handle general VC classes. (arXiv:2106.09683v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grunwald_P/0/1/0/all/0/1">Peter Gr&#xfc;nwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Zakynthinou_L/0/1/0/all/0/1">Lydia Zakynthinou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09683">
                                    <div class="article-summary-box-inner">
                                        <span>We give a novel, unified derivation of conditional PAC-Bayesian and mutual
information (MI) generalization bounds. We derive conditional MI bounds as an
instance, with special choice of prior, of conditional MAC-Bayesian (Mean
Approximately Correct) bounds, itself derived from conditional PAC-Bayesian
bounds, where &#x60;conditional&#x27; means that one can use priors conditioned on a
joint training and ghost sample. This allows us to get nontrivial PAC-Bayes and
MI-style bounds for general VC classes, something recently shown to be
impossible with standard PAC-Bayesian/MI bounds. Second, it allows us to get
faster rates of order $O \left(({\text{KL}}/n)^{\gamma}\right)$ for $\gamma &gt;
1/2$ if a Bernstein condition holds and for exp-concave losses (with
$\gamma&#x3D;1$), which is impossible with both standard PAC-Bayes generalization
and MI bounds. Our work extends the recent work by Steinke and Zakynthinou
[2020] who handle MI with VC but neither PAC-Bayes nor fast rates, the recent
work of Hellstr\&quot;om and Durisi [2020] who extend the latter to the PAC-Bayes
setting via a unifying exponential inequality, and Mhammedi et al. [2019] who
initiated fast rate PAC-Bayes generalization error bounds but handle neither MI
nor general VC classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">mPyPl: Python Monadic Pipeline Library for Complex Functional Data Processing. (arXiv:2106.09164v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soshnikov_D/0/1/0/all/0/1">Dmitry Soshnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Valieva_Y/0/1/0/all/0/1">Yana Valieva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09164">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a new Python library called mPyPl, which is
intended to simplify complex data processing tasks using functional approach.
This library defines operations on lazy data streams of named dictionaries
represented as generators (so-called multi-field datastreams), and allows
enriching those data streams with more &#x27;fields&#x27; in the process of data
preparation and feature extraction. Thus, most data preparation tasks can be
expressed in the form of neat linear &#x27;pipeline&#x27;, similar in syntax to UNIX
pipes, or |&gt; functional composition operator in F#.

We define basic operations on multi-field data streams, which resemble
classical monadic operations, and show similarity of the proposed approach to
monads in functional programming. We also show how the library was used in
complex deep learning tasks of event detection in video, and discuss different
evaluation strategies that allow for different compromises in terms of memory
and performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joining datasets via data augmentation in the label space for neural networks. (arXiv:2106.09260v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jake Zhao</a> (Junbo), <a href="http://arxiv.org/find/cs/1/au:+Ou_M/0/1/0/all/0/1">Mingfeng Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1">Linji Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yunkai Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Sai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09260">
                                    <div class="article-summary-box-inner">
                                        <span>Most, if not all, modern deep learning systems restrict themselves to a
single dataset for neural network training and inference. In this article, we
are interested in systematic ways to join datasets that are made of similar
purposes. Unlike previous published works that ubiquitously conduct the dataset
joining in the uninterpretable latent vectorial space, the core to our method
is an augmentation procedure in the label space. The primary challenge to
address the label space for dataset joining is the discrepancy between labels:
non-overlapping label annotation sets, different labeling granularity or
hierarchy and etc. Notably we propose a new technique leveraging artificially
created knowledge graph, recurrent neural networks and policy gradient that
successfully achieve the dataset joining in the label space. Empirical results
on both image and text classification justify the validity of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting. (arXiv:2106.09276v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Koehler_F/0/1/0/all/0/1">Frederic Koehler</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1">Lijia Zhou</a>, <a href="http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1">Danica J. Sutherland</a>, <a href="http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09276">
                                    <div class="article-summary-box-inner">
                                        <span>We consider interpolation learning in high-dimensional linear regression with
Gaussian data, and prove a generic uniform convergence guarantee on the
generalization error of interpolators in an arbitrary hypothesis class in terms
of the class&#x27;s Gaussian width. Applying the generic bound to Euclidean norm
balls recovers the consistency result of Bartlett et al. (2020) for
minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for
near-minimal-norm interpolators in the special case of Gaussian data. We
demonstrate the generality of the bound by applying it to the simplex,
obtaining a novel consistency result for minimum l1-norm interpolators (basis
pursuit). Our results show how norm-based generalization bounds can explain and
be used to analyze benign overfitting, at least in some settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can I Be of Further Assistance? Using Unstructured Knowledge Access to Improve Task-oriented Conversational Modeling. (arXiv:2106.09174v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1">Di Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seokhwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1">Dilek Hakkani-Tur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09174">
                                    <div class="article-summary-box-inner">
                                        <span>Most prior work on task-oriented dialogue systems are restricted to limited
coverage of domain APIs. However, users oftentimes have requests that are out
of the scope of these APIs. This work focuses on responding to these
beyond-API-coverage user turns by incorporating external, unstructured
knowledge sources. Our approach works in a pipelined manner with
knowledge-seeking turn detection, knowledge selection, and response generation
in sequence. We introduce novel data augmentation methods for the first two
steps and demonstrate that the use of information extracted from dialogue
context improves the knowledge selection and end-to-end performances. Through
experiments, we achieve state-of-the-art performance for both automatic and
human evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the
effectiveness of our contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Generative Network. (arXiv:2106.09330v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nissani_D/0/1/0/all/0/1">Daniel N. Nissani</a> (Nissensohn)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09330">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural networks are able to mimic intricate probability
distributions such as those of handwritten text, natural images, etc. Since
their inception several models were proposed. The most successful of these were
based on adversarial (GAN), auto-encoding (VAE) and maximum mean discrepancy
(MMD) relatively complex architectures and schemes. Surprisingly, a very simple
architecture (a single feed-forward neural network) in conjunction with an
obvious optimization goal (Kullback_Leibler divergence) was apparently
overlooked. This paper demonstrates that such a model (denoted SGN for its
simplicity) is able to generate samples visually and quantitatively competitive
as compared with the fore-mentioned state of the art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-informed CoKriging model of a redox flow battery. (arXiv:2106.09188v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Howard_A/0/1/0/all/0/1">Amanda A. Howard</a>, <a href="http://arxiv.org/find/physics/1/au:+Tartakovsky_A/0/1/0/all/0/1">Alexandre M. Tartakovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09188">
                                    <div class="article-summary-box-inner">
                                        <span>Redox flow batteries (RFBs) offer the capability to store large amounts of
energy cheaply and efficiently, however, there is a need for fast and accurate
models of the charge-discharge curve of a RFB to potentially improve the
battery capacity and performance. We develop a multifidelity model for
predicting the charge-discharge curve of a RFB. In the multifidelity model, we
use the Physics-informed CoKriging (CoPhIK) machine learning method that is
trained on experimental data and constrained by the so-called
&quot;zero-dimensional&quot; physics-based model. Here we demonstrate that the model
shows good agreement with experimental results and significant improvements
over existing zero-dimensional models. We show that the proposed model is
robust as it is not sensitive to the input parameters in the zero-dimensional
model. We also show that only a small amount of high-fidelity experimental
datasets are needed for accurate predictions for the range of considered input
parameters, which include current density, flow rate, and initial
concentrations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing. (arXiv:2106.09292v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zijian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1">Yevgeniy Vorobeychik</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09292">
                                    <div class="article-summary-box-inner">
                                        <span>We present the first framework of Certifying Robust Policies for
reinforcement learning (CROP) against adversarial state perturbations. We
propose two particular types of robustness certification criteria: robustness
of per-state actions and lower bound of cumulative rewards. Specifically, we
develop a local smoothing algorithm which uses a policy derived from
Q-functions smoothed with Gaussian noise over each encountered state to
guarantee the robustness of actions taken along this trajectory. Next, we
develop a global smoothing algorithm for certifying the robustness of a
finite-horizon cumulative reward under adversarial state perturbations.
Finally, we propose a local smoothing approach which makes use of adaptive
search in order to obtain tight certification bounds for reward. We use the
proposed RL robustness certification framework to evaluate six methods that
have previously been shown to yield empirically robust RL, including
adversarial training and several forms of regularization, on two representative
Atari games. We show that RegPGD, RegCVX, and RadialRL achieve high certified
robustness among these. Furthermore, we demonstrate that our certifications are
often tight by evaluating these algorithms against adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepSplit: Scalable Verification of Deep Neural Networks via Operator Splitting. (arXiv:2106.09117v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shaoru Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1">Eric Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazlyab_M/0/1/0/all/0/1">Mahyar Fazlyab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09117">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing the worst-case performance of deep neural networks against input
perturbations amounts to solving a large-scale non-convex optimization problem,
for which several past works have proposed convex relaxations as a promising
alternative. However, even for reasonably-sized neural networks, these
relaxations are not tractable, and so must be replaced by even weaker
relaxations in practice. In this work, we propose a novel operator splitting
method that can directly solve a convex relaxation of the problem to high
accuracy, by splitting it into smaller sub-problems that often have analytical
solutions. The method is modular and scales to problem instances that were
previously impossible to solve exactly due to their size. Furthermore, the
solver operations are amenable to fast parallelization with GPU acceleration.
We demonstrate our method in obtaining tighter bounds on the worst-case
performance of large convolutional networks in image classification and
reinforcement learning settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Fishnet Open Images Database: A Dataset for Fish Detection and Fine-Grained Categorization in Fisheries. (arXiv:2106.09178v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kay_J/0/1/0/all/0/1">Justin Kay</a>, <a href="http://arxiv.org/find/cs/1/au:+Merrifield_M/0/1/0/all/0/1">Matt Merrifield</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09178">
                                    <div class="article-summary-box-inner">
                                        <span>Camera-based electronic monitoring (EM) systems are increasingly being
deployed onboard commercial fishing vessels to collect essential data for
fisheries management and regulation. These systems generate large quantities of
video data which must be reviewed on land by human experts. Computer vision can
assist this process by automatically detecting and classifying fish species,
however the lack of existing public data in this domain has hindered progress.
To address this, we present the Fishnet Open Images Database, a large dataset
of EM imagery for fish detection and fine-grained categorization onboard
commercial fishing vessels. The dataset consists of 86,029 images containing 34
object classes, making it the largest and most diverse public dataset of
fisheries EM imagery to-date. It includes many of the characteristic challenges
of EM data: visual similarity between species, skewed class distributions,
harsh weather conditions, and chaotic crew activity. We evaluate the
performance of existing detection and classification algorithms and demonstrate
that the dataset can serve as a challenging benchmark for development of
computer vision algorithms in fisheries. The dataset is available at
https://www.fishnet.ai/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amortized Auto-Tuning: Cost-Efficient Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yuxin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric P. Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1">Willie Neiswanger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09179">
                                    <div class="article-summary-box-inner">
                                        <span>With the surge in the number of hyperparameters and training times of modern
machine learning models, hyperparameter tuning is becoming increasingly
expensive. Although methods have been proposed to speed up tuning via knowledge
transfer, they typically require the final performance of hyperparameters and
do not focus on low-fidelity information. Nevertheless, this common practice is
suboptimal and can incur an unnecessary use of resources. It is more
cost-efficient to instead leverage the low-fidelity tuning observations to
measure inter-task similarity and transfer knowledge from existing to new tasks
accordingly. However, performing multi-fidelity tuning comes with its own
challenges in the transfer setting: the noise in the additional observations
and the need for performance forecasting. Therefore, we conduct a thorough
analysis of the multi-task multi-fidelity Bayesian optimization framework,
which leads to the best instantiation--amortized auto-tuning (AT2). We further
present an offline-computed 27-task hyperparameter recommendation (HyperRec)
database to serve the community. Extensive experiments on HyperRec and other
real-world databases illustrate the effectiveness of our AT2 method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition. (arXiv:2104.01989v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pelecanos_J/0/1/0/all/0/1">Jason Pelecanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_I/0/1/0/all/0/1">Ignacio Lopez Moreno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01989">
                                    <div class="article-summary-box-inner">
                                        <span>Many neural network speaker recognition systems model each speaker using a
fixed-dimensional embedding vector. These embeddings are generally compared
using either linear or 2nd-order scoring and, until recently, do not handle
utterance-specific uncertainty. In this work we propose scoring these
representations in a way that can capture uncertainty, enroll/test asymmetry
and additional non-linear information. This is achieved by incorporating a
2nd-stage neural network (known as a decision network) as part of an end-to-end
training regimen. In particular, we propose the concept of decision residual
networks which involves the use of a compact decision network to leverage
cosine scores and to model the residual signal that&#x27;s needed. Additionally, we
present a modification to the generalized end-to-end softmax loss function to
target the separation of same/different speaker scores. We observed significant
performance gains for the two techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven control of room temperature and bidirectional EV charging using deep reinforcement learning: simulations and experiments. (arXiv:2103.01886v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1">B. Svetozarevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumann_C/0/1/0/all/0/1">C.Baumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Muntwiler_S/0/1/0/all/0/1">S. Muntwiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Natale_L/0/1/0/all/0/1">L. Di Natale</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeilinger_M/0/1/0/all/0/1">M. Zeilinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Heer_P/0/1/0/all/0/1">P. Heer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01886">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a fully data-driven, black-box pipeline to obtain an
optimal control policy for a multi-loop building control problem based on
historical building and weather data, thus without the need for complex
physics-based modelling. We demonstrate the method for joint control of room
temperature and bidirectional EV charging to maximize the occupant thermal
comfort and energy savings while leaving enough energy in the EV battery for
the next trip. We modelled the room temperature with a recurrent neural network
and EV charging with a piece-wise linear function. Using these models as a
simulation environment, we applied a deep reinforcement learning (DRL)
algorithm to obtain an optimal control policy. The learnt policy achieves on
average 17% energy savings over the heating season and 19% better comfort
satisfaction than a standard RB room temperature controller. When a
bidirectional EV is additionally connected and a two-tariff electricity pricing
is applied, the MIMO DRL policy successfully leverages the battery and
decreases the overall cost of electricity compared to two standard RB
controllers, one controlling the room temperature and another controlling the
bidirectional EV (dis-)charging. Finally, we demonstrate a successful transfer
of the learnt DRL policy from simulation onto a real building, the DFAB HOUSE
at Empa Duebendorf in Switzerland, achieving up to 30% energy savings while
maintaining similar comfort levels compared to a conventional RB room
temperature controller over three weeks during the heating season.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantized Federated Learning under Transmission Delay and Outage Constraints. (arXiv:2106.09397v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanmeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanqing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1">Qingjiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1">Tsung-Hui Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09397">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) has been recognized as a viable distributed learning
paradigm which trains a machine learning model collaboratively with massive
mobile devices in the wireless edge while protecting user privacy. Although
various communication schemes have been proposed to expedite the FL process,
most of them have assumed ideal wireless channels which provide reliable and
lossless communication links between the server and mobile clients.
Unfortunately, in practical systems with limited radio resources such as
constraint on the training latency and constraints on the transmission power
and bandwidth, transmission of a large number of model parameters inevitably
suffers from quantization errors (QE) and transmission outage (TO). In this
paper, we consider such non-ideal wireless channels, and carry out the first
analysis showing that the FL convergence can be severely jeopardized by TO and
QE, but intriguingly can be alleviated if the clients have uniform outage
probabilities. These insightful results motivate us to propose a robust FL
scheme, named FedTOE, which performs joint allocation of wireless resources and
quantization bits across the clients to minimize the QE while making the
clients have the same TO probability. Extensive experimental results are
presented to show the superior performance of FedTOE for a deep learning-based
classification task with transmission latency constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Validity of Modeling SGD with Stochastic Differential Equations (SDEs). (arXiv:2102.12470v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Malladi_S/0/1/0/all/0/1">Sadhika Malladi</a>, <a href="http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1">Sanjeev Arora</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12470">
                                    <div class="article-summary-box-inner">
                                        <span>It is generally recognized that finite learning rate (LR), in contrast to
infinitesimal LR, is important for good generalization in real-life deep nets.
Most attempted explanations propose approximating finite-LR SGD with Ito
Stochastic Differential Equations (SDEs), but formal justification for this
approximation (e.g., (Li et al., 2019)) only applies to SGD with tiny LR.
Experimental verification of the approximation appears computationally
infeasible. The current paper clarifies the picture with the following
contributions: (a) An efficient simulation algorithm SVAG that provably
converges to the conventionally used Ito SDE approximation. (b) A theoretically
motivated testable necessary condition for the SDE approximation and its most
famous implication, the linear scaling rule (Goyal et al., 2017), to hold. (c)
Experiments using this simulation to demonstrate that the previously proposed
SDE approximation can meaningfully capture the training and generalization
properties of common deep nets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Training Data Generation of Handwritten Formulas using Generative Adversarial Networks with Self-Attention. (arXiv:2106.09432v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Springstein_M/0/1/0/all/0/1">Matthias Springstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1">Eric M&#xfc;ller-Budack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09432">
                                    <div class="article-summary-box-inner">
                                        <span>The recognition of handwritten mathematical expressions in images and video
frames is a difficult and unsolved problem yet. Deep convectional neural
networks are basically a promising approach, but typically require a large
amount of labeled training data. However, such a large training dataset does
not exist for the task of handwritten formula recognition. In this paper, we
introduce a system that creates a large set of synthesized training examples of
mathematical expressions which are derived from LaTeX documents. For this
purpose, we propose a novel attention-based generative adversarial network to
translate rendered equations to handwritten formulas. The datasets generated by
this approach contain hundreds of thousands of formulas, making it ideal for
pretraining or the design of more complex models. We evaluate our synthesized
dataset and the recognition approach on the CROHME 2014 benchmark dataset.
Experimental results demonstrate the feasibility of the approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Machine Learning Classifiers for Brain Tumour Survival Prediction. (arXiv:2106.09424v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Charlton_C/0/1/0/all/0/1">Colleen E. Charlton</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_M/0/1/0/all/0/1">Michael Tin Chung Poon</a>, <a href="http://arxiv.org/find/cs/1/au:+Brennan_P/0/1/0/all/0/1">Paul M. Brennan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleuriot_J/0/1/0/all/0/1">Jacques D. Fleuriot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09424">
                                    <div class="article-summary-box-inner">
                                        <span>Prediction of survival in patients diagnosed with a brain tumour is
challenging because of heterogeneous tumour behaviours and responses to
treatment. Better estimations of prognosis would support treatment planning and
patient support. Advances in machine learning have informed development of
clinical predictive models, but their integration into clinical practice is
almost non-existent. One reasons for this is the lack of interpretability of
models. In this paper, we use a novel brain tumour dataset to compare two
interpretable rule list models against popular machine learning approaches for
brain tumour survival prediction. All models are quantitatively evaluated using
standard performance metrics. The rule lists are also qualitatively assessed
for their interpretability and clinical utility. The interpretability of the
black box machine learning models is evaluated using two post-hoc explanation
techniques, LIME and SHAP. Our results show that the rule lists were only
slightly outperformed by the black box models. We demonstrate that rule list
algorithms produced simple decision lists that align with clinical expertise.
By comparison, post-hoc interpretability methods applied to black box models
may produce unreliable explanations of local model predictions. Model
interpretability is essential for understanding differences in predictive
performance and for integration into clinical practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing Differently, Acting Similarly: Imitation Learning with Heterogeneous Observations. (arXiv:2106.09256v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xin-Qiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yao-Xiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zi-Xuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09256">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world imitation learning tasks, the demonstrator and the learner
have to act in different but full observation spaces. This situation generates
significant obstacles for existing imitation learning approaches to work, even
when they are combined with traditional space adaptation techniques. The main
challenge lies in bridging expert&#x27;s occupancy measures to learner&#x27;s dynamically
changing occupancy measures under the different observation spaces. In this
work, we model the above learning problem as Heterogeneous Observations
Imitation Learning (HOIL). We propose the Importance Weighting with REjection
(IWRE) algorithm based on the techniques of importance-weighting, learning with
rejection, and active querying to solve the key challenge of occupancy measure
matching. Experimental results show that IWRE can successfully solve HOIL
tasks, including the challenging task of transforming the vision-based
demonstrations to random access memory (RAM)-based policies under the Atari
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Imprecise SHAP as a Tool for Explaining the Class Probability Distributions under Limited Training Data. (arXiv:2106.09111v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Utkin_L/0/1/0/all/0/1">Lev V. Utkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Konstantinov_A/0/1/0/all/0/1">Andrei V. Konstantinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vishniakov_K/0/1/0/all/0/1">Kirill A. Vishniakov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09111">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most popular methods of the machine learning prediction
explanation is the SHapley Additive exPlanations method (SHAP). An imprecise
SHAP as a modification of the original SHAP is proposed for cases when the
class probability distributions are imprecise and represented by sets of
distributions. The first idea behind the imprecise SHAP is a new approach for
computing the marginal contribution of a feature, which fulfils the important
efficiency property of Shapley values. The second idea is an attempt to
consider a general approach to calculating and reducing interval-valued Shapley
values, which is similar to the idea of reachable probability intervals in the
imprecise probability theory. A simple special implementation of the general
approach in the form of linear optimization problems is proposed, which is
based on using the Kolmogorov-Smirnov distance and imprecise contamination
models. Numerical examples with synthetic and real data illustrate the
imprecise SHAP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Insights into Data through Model Behaviour: An Explainability-driven Strategy for Data Auditing for Responsible Computer Vision Applications. (arXiv:2106.09177v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorfman_A/0/1/0/all/0/1">Adam Dorfman</a>, <a href="http://arxiv.org/find/cs/1/au:+McInnis_P/0/1/0/all/0/1">Paul McInnis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunraj_H/0/1/0/all/0/1">Hayden Gunraj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09177">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we take a departure and explore an explainability-driven
strategy to data auditing, where actionable insights into the data at hand are
discovered through the eyes of quantitative explainability on the behaviour of
a dummy model prototype when exposed to data. We demonstrate this strategy by
auditing two popular medical benchmark datasets, and discover hidden data
quality issues that lead deep learning models to make predictions for the wrong
reasons. The actionable insights gained from this explainability driven data
auditing strategy is then leveraged to address the discovered issues to enable
the creation of high-performing deep learning models with appropriate
prediction behaviour. The hope is that such an explainability-driven strategy
can be complimentary to data-driven strategies to facilitate for more
responsible development of machine learning algorithms for computer vision
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Popularity of Reddit Posts with AI. (arXiv:2106.07380v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Juno Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07380">
                                    <div class="article-summary-box-inner">
                                        <span>Social media creates crucial mass changes, as popular posts and opinions cast
a significant influence on users&#x27; decisions and thought processes. For example,
the recent Reddit uprising inspired by r/wallstreetbets which had remarkable
economic impact was started with a series of posts on the thread. The
prediction of posts that may have a notable impact will allow for the
preparation of possible following trends. This study aims to develop a machine
learning model capable of accurately predicting the popularity of a Reddit
post. Specifically, the model is predicting the number of upvotes a post will
receive based on its textual content. I experimented with three different
models: a baseline linear regression model, a random forest regression model,
and a neural network. I collected Reddit post data from an online data set and
analyzed the model&#x27;s performance when trained on a single subreddit and a
collection of subreddits. The results showed that the neural network model
performed the best when the loss of the models were compared. With the use of a
machine learning model to predict social trends through the reaction users have
to post, a better picture of the near future can be envisioned.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Shape Rewards using a Game of Switching Controls. (arXiv:2103.09159v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mguni_D/0/1/0/all/0/1">David Mguni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jafferjee_T/0/1/0/all/0/1">Taher Jafferjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Nieves_N/0/1/0/all/0/1">Nicolas Perez-Nieves</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wenbin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_F/0/1/0/all/0/1">Feifei Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiangcheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09159">
                                    <div class="article-summary-box-inner">
                                        <span>Reward shaping (RS) is a powerful method in reinforcement learning (RL) for
overcoming the problem of sparse or uninformative rewards. However, RS
typically relies on manually engineered shaping-reward functions whose
construction is time-consuming and error-prone. It also requires domain
knowledge which runs contrary to the goal of autonomous learning. We introduce
Reinforcement Learning Optimal Shaping Algorithm (ROSA), an automated RS
framework in which the shaping-reward function is constructed in a novel Markov
game between two agents. A reward-shaping agent (Shaper) uses switching
controls to determine which states to add shaping rewards and their optimal
values while the other agent (Controller) learns the optimal policy for the
task using these shaped rewards. We prove that ROSA, which easily adopts
existing RL algorithms, learns to construct a shaping-reward function that is
tailored to the task thus ensuring efficient convergence to high performance
policies. We demonstrate ROSA&#x27;s congenial properties in three carefully
designed experiments and show its superior performance against state-of-the-art
RS algorithms in challenging sparse reward environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated CycleGAN for Privacy-Preserving Image-to-Image Translation. (arXiv:2106.09246v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Joonyoung Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09246">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised image-to-image translation methods such as CycleGAN learn to
convert images from one domain to another using unpaired training data sets
from different domains. Unfortunately, these approaches still require centrally
collected unpaired records, potentially violating privacy and security issues.
Although the recent federated learning (FL) allows a neural network to be
trained without data exchange, the basic assumption of the FL is that all
clients have their own training data from a similar domain, which is different
from our image-to-image translation scenario in which each client has images
from its unique domain and the goal is to learn image translation between
different domains without accessing the target domain data. To address this,
here we propose a novel federated CycleGAN architecture that can learn image
translation in an unsupervised manner while maintaining the data privacy.
Specifically, our approach arises from a novel observation that CycleGAN loss
can be decomposed into the sum of client specific local objectives that can be
evaluated using only their data. This local objective decomposition allows
multiple clients to participate in federated CycleGAN training without
sacrificing performance. Furthermore, our method employs novel switchable
generator and discriminator architecture using Adaptive Instance Normalization
(AdaIN) that significantly reduces the band-width requirement of the federated
learning. Our experimental results on various unsupervised image translation
tasks show that our federated CycleGAN provides comparable performance compared
to the non-federated counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies. (arXiv:2106.09678v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Linxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">De-An Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09678">
                                    <div class="article-summary-box-inner">
                                        <span>Generalization has been a long-standing challenge for reinforcement learning
(RL). Visual RL, in particular, can be easily distracted by irrelevant factors
in high-dimensional observation space. In this work, we consider robust policy
learning which targets zero-shot generalization to unseen visual environments
with large distributional shift. We propose SECANT, a novel self-expert cloning
technique that leverages image augmentation in two stages to decouple robust
representation learning from policy optimization. Specifically, an expert
policy is first trained by RL from scratch with weak augmentations. A student
network then learns to mimic the expert policy by supervised learning with
strong augmentations, making its representation more robust against visual
variations compared to the expert. Extensive experiments demonstrate that
SECANT significantly advances the state of the art in zero-shot generalization
across 4 challenging domains. Our average reward improvements over prior SOTAs
are: DeepMind Control (+26.5%), robotic manipulation (+337.8%), vision-based
autonomous driving (+47.7%), and indoor object navigation (+15.8%). Code
release and video are available at https://linxifan.github.io/secant-site/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MHNF: Multi-hop Heterogeneous Neighborhood information Fusion graph representation learning. (arXiv:2106.09289v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dongjie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yundong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1">Haiwen Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhaoshuo Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09289">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism enables the Graph Neural Networks(GNNs) to learn the
attention weights between the target node and its one-hop neighbors, the
performance is further improved. However, the most existing GNNs are oriented
to homogeneous graphs and each layer can only aggregate the information of
one-hop neighbors. Stacking multi-layer networks will introduce a lot of noise
and easily lead to over smoothing. We propose a Multi-hop Heterogeneous
Neighborhood information Fusion graph representation learning method (MHNF).
Specifically, we first propose a hybrid metapath autonomous extraction model to
efficiently extract multi-hop hybrid neighbors. Then, we propose a hop-level
heterogeneous Information aggregation model, which selectively aggregates
different-hop neighborhood information within the same hybrid metapath.
Finally, a hierarchical semantic attention fusion model (HSAF) is proposed,
which can efficiently integrate different-hop and different-path neighborhood
information respectively. This paper can solve the problem of aggregating the
multi-hop neighborhood information and can learn hybrid metapaths for target
task, reducing the limitation of manually specifying metapaths. In addition,
HSAF can extract the internal node information of the metapaths and better
integrate the semantic information of different levels. Experimental results on
real datasets show that MHNF is superior to state-of-the-art methods in node
classification and clustering tasks (10.94% - 69.09% and 11.58% - 394.93%
relative improvement on average, respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Languages in the Limit from Positive Information with Finitely Many Memory Changes. (arXiv:2010.04782v3 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotzing_T/0/1/0/all/0/1">Timo K&#xf6;tzing</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_K/0/1/0/all/0/1">Karen Seidel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04782">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate learning collections of languages from texts by an inductive
inference machine with access to the current datum and a bounded memory in form
of states. Such a bounded memory states (BMS) learner is considered successful
in case it eventually settles on a correct hypothesis while exploiting only
finitely many different states.

We give the complete map of all pairwise relations for an established
collection of criteria of successfull learning. Most prominently, we show that
non-U-shapedness is not restrictive, while conservativeness and (strong)
monotonicity are. Some results carry over from iterative learning by a general
lemma showing that, for a wealth of restrictions (the semantic restrictions),
iterative and bounded memory states learning are equivalent. We also give an
example of a non-semantic restriction (strongly non-U-shapedness) where the two
settings differ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Behavioral Priors and Dynamics Models: Improving Performance and Domain Transfer in Offline RL. (arXiv:2106.09119v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cang_C/0/1/0/all/0/1">Catherine Cang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1">Aravind Rajeswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1">Michael Laskin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09119">
                                    <div class="article-summary-box-inner">
                                        <span>Offline Reinforcement Learning (RL) aims to extract near-optimal policies
from imperfect offline data without additional environment interactions.
Extracting policies from diverse offline datasets has the potential to expand
the range of applicability of RL by making the training process safer, faster,
and more streamlined. We investigate how to improve the performance of offline
RL algorithms, its robustness to the quality of offline data, as well as its
generalization capabilities. To this end, we introduce Offline Model-based RL
with Adaptive Behavioral Priors (MABE). Our algorithm is based on the finding
that dynamics models, which support within-domain generalization, and
behavioral priors, which support cross-domain generalization, are
complementary. When combined together, they substantially improve the
performance and generalization of offline RL policies. In the widely studied
D4RL offline RL benchmark, we find that MABE achieves higher average
performance compared to prior model-free and model-based algorithms. In
experiments that require cross-domain generalization, we find that MABE
outperforms prior methods. Our website is available at
https://sites.google.com/berkeley.edu/mabe .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Properties and Evolution of Neural Network Eigenspaces during Training. (arXiv:2106.09526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krumnack_M/0/1/0/all/0/1">Mats L. Richter Leila Malihi Anne-Kathrin Patricia Windler Ulf Krumnack</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09526">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we explore the information processing inside neural networks
using logistic regression probes \cite{probes} and the saturation metric
\cite{featurespace_saturation}. We show that problem difficulty and neural
network capacity affect the predictive performance in an antagonistic manner,
opening the possibility of detecting over- and under-parameterization of neural
networks for a given task. We further show that the observed effects are
independent from previously reported pathological patterns like the &#x60;&#x60;tail
pattern&#x27;&#x27; described in \cite{featurespace_saturation}. Finally we are able to
show that saturation patterns converge early during training, allowing for a
quicker cycle time during analysis</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Winning Hand: Compressing Deep Networks Can Improve Out-Of-Distribution Robustness. (arXiv:2106.09129v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diffenderfer_J/0/1/0/all/0/1">James Diffenderfer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartoldson_B/0/1/0/all/0/1">Brian R. Bartoldson</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaganti_S/0/1/0/all/0/1">Shreya Chaganti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jize Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09129">
                                    <div class="article-summary-box-inner">
                                        <span>Two crucial requirements for a successful adoption of deep learning (DL) in
the wild are: (1) robustness to distributional shifts, and (2) model
compactness for achieving efficiency. Unfortunately, efforts towards
simultaneously achieving Out-of-Distribution (OOD) robustness and extreme model
compactness without sacrificing accuracy have mostly been unsuccessful. This
raises an important question: &quot;Is the inability to create compact, accurate,
and robust deep neural networks (CARDs) fundamental?&quot; To answer this question,
we perform a large-scale analysis for a range of popular model compression
techniques which uncovers several intriguing patterns. Notably, in contrast to
traditional pruning approaches (e.g., fine tuning and gradual magnitude
pruning), we find that &quot;lottery ticket-style&quot; pruning approaches can
surprisingly be used to create high performing CARDs. Specifically, we are able
to create extremely compact CARDs that are dramatically more robust than their
significantly larger and full-precision counterparts while matching (or
beating) their test accuracy, simply by pruning and/or quantizing. To better
understand these differences, we perform sensitivity analysis in the Fourier
domain for CARDs trained using different data augmentation methods. Motivated
by our analysis, we develop a simple domain-adaptive test-time ensembling
approach (CARD-Deck) that uses a gating module to dynamically select an
appropriate CARD from the CARD-Deck based on their spectral-similarity with
test samples. By leveraging complementary frequency biases of different
compressed models, the proposed approach builds a &quot;winning hand&quot; of CARDs that
establishes a new state-of-the-art on CIFAR-10-C accuracies (i.e., 96.8% clean
and 92.75% robust) with dramatically better memory usage than their
non-compressed counterparts. We also present some theoretical evidences
supporting our empirical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trainable Discrete Feature Embeddings for Variational Quantum Classifier. (arXiv:2106.09415v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Thumwanit_N/0/1/0/all/0/1">Napat Thumwanit</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Lortararprasert_C/0/1/0/all/0/1">Chayaphol Lortararprasert</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yano_H/0/1/0/all/0/1">Hiroshi Yano</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Raymond_R/0/1/0/all/0/1">Rudy Raymond</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09415">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum classifiers provide sophisticated embeddings of input data in Hilbert
space promising quantum advantage. The advantage stems from quantum feature
maps encoding the inputs into quantum states with variational quantum circuits.
A recent work shows how to map discrete features with fewer quantum bits using
Quantum Random Access Coding (QRAC), an important primitive to encode binary
strings into quantum states. We propose a new method to embed discrete features
with trainable quantum circuits by combining QRAC and a recently proposed
strategy for training quantum feature map called quantum metric learning. We
show that the proposed trainable embedding requires not only as few qubits as
QRAC but also overcomes the limitations of QRAC to classify inputs whose
classes are based on hard Boolean functions. We numerically demonstrate its use
in variational quantum classifiers to achieve better performances in
classifying real-world datasets, and thus its possibility to leverage near-term
quantum computers for quantum machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal-Pad\&#x27;e Activation Functions: Trainable Activation functions for smooth and faster convergence in deep networks. (arXiv:2106.09693v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_K/0/1/0/all/0/1">Koushik Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Shilpak Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ashish Kumar Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09693">
                                    <div class="article-summary-box-inner">
                                        <span>We have proposed orthogonal-Pad\&#x27;e activation functions, which are trainable
activation functions and show that they have faster learning capability and
improves the accuracy in standard deep learning datasets and models. Based on
our experiments, we have found two best candidates out of six orthogonal-Pad\&#x27;e
activations, which we call safe Hermite-Pade (HP) activation functions, namely
HP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1
accuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%
respectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset
top-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by
2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in
Efficientnet B0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time Series is a Special Sequence: Forecasting with Sample Convolution and Interaction. (arXiv:2106.09305v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Q/0/1/0/all/0/1">Qiuxia Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09305">
                                    <div class="article-summary-box-inner">
                                        <span>Time series is a special type of sequence data, a set of observations
collected at even intervals of time and ordered chronologically. Existing deep
learning techniques use generic sequence models (e.g., recurrent neural
network, Transformer model, or temporal convolutional network) for time series
analysis, which ignore some of its unique properties. For example, the
downsampling of time series data often preserves most of the information in the
data, while this is not true for general sequence data such as text sequence
and DNA sequence. Motivated by the above, in this paper, we propose a novel
neural network architecture and apply it for the time series forecasting
problem, wherein we conduct sample convolution and interaction at multiple
resolutions for temporal modeling. The proposed architecture, namelySCINet,
facilitates extracting features with enhanced predictability. Experimental
results show that SCINet achieves significant prediction accuracy improvement
over existing solutions across various real-world time series forecasting
datasets. In particular, it can achieve high fore-casting accuracy for those
temporal-spatial datasets without using sophisticated spatial modeling
techniques. Our codes and data are presented in the supplemental material.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Scale Private Learning via Low-rank Reparametrization. (arXiv:2106.09352v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Da Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huishuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jian Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09352">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a reparametrization scheme to address the challenges of applying
differentially private SGD on large neural networks, which are 1) the huge
memory cost of storing individual gradients, 2) the added noise suffering
notorious dimensional dependence. Specifically, we reparametrize each weight
matrix with two \emph{gradient-carrier} matrices of small dimension and a
\emph{residual weight} matrix. We argue that such reparametrization keeps the
forward/backward process unchanged while enabling us to compute the projected
gradient without computing the gradient itself. To learn with differential
privacy, we design \emph{reparametrized gradient perturbation (RGP)} that
perturbs the gradients on gradient-carrier matrices and reconstructs an update
for the original weight from the noisy gradients. Importantly, we use
historical updates to find the gradient-carrier matrices, whose optimality is
rigorously justified under linear regression and empirically verified with deep
learning tasks. RGP significantly reduces the memory cost and improves the
utility. For example, we are the first able to apply differential privacy on
the BERT model and achieve an average accuracy of $83.9\%$ on four downstream
tasks with $\epsilon&#x3D;8$, which is within $5\%$ loss compared to the non-private
baseline but enjoys much lower privacy leakage risk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimum-statistical collaboration towards efficient black-box optimization. (arXiv:2106.09215v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_W/0/1/0/all/0/1">Wenjie Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1">Chihua Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1">Guang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09215">
                                    <div class="article-summary-box-inner">
                                        <span>With increasingly more hyperparameters involved in their training, machine
learning systems demand a better understanding of hyperparameter tuning
automation. This has raised interest in studies of provably black-box
optimization, which is made more practical by better exploration mechanism
implemented in algorithm design, managing the flux of both optimization and
statistical errors. Prior efforts focus on delineating optimization errors, but
this is deficient: black-box optimization algorithms can be inefficient without
considering heterogeneity among reward samples. In this paper, we make the key
delineation on the role of statistical uncertainty in black-box optimization,
guiding a more efficient algorithm design. We introduce
\textit{optimum-statistical collaboration}, a framework of managing the
interaction between optimization error flux and statistical error flux evolving
in the optimization process. Inspired by this framework, we propose the
\texttt{VHCT} algorithms for objective functions with only local-smoothness
assumptions. In theory, we prove our algorithm enjoys rate-optimal regret
bounds; in experiments, we show the algorithm outperforms prior efforts in
extensive settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks. (arXiv:2106.09249v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao%2A_Y/0/1/0/all/0/1">Yulong Cao*</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang%2A_N/0/1/0/all/0/1">Ningfei Wang*</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao%2A_C/0/1/0/all/0/1">Chaowei Xiao*</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang%2A_D/0/1/0/all/0/1">Dawei Yang*</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruigang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qi Alfred Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingyan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a> (*co-first authors)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09249">
                                    <div class="article-summary-box-inner">
                                        <span>In Autonomous Driving (AD) systems, perception is both security and safety
critical. Despite various prior studies on its security issues, all of them
only consider attacks on camera- or LiDAR-based AD perception alone. However,
production AD systems today predominantly adopt a Multi-Sensor Fusion (MSF)
based design, which in principle can be more robust against these attacks under
the assumption that not all fusion sources are (or can be) attacked at the same
time. In this paper, we present the first study of security issues of MSF-based
perception in AD systems. We directly challenge the basic MSF design assumption
above by exploring the possibility of attacking all fusion sources
simultaneously. This allows us for the first time to understand how much
security guarantee MSF can fundamentally provide as a general defense strategy
for AD perception.

We formulate the attack as an optimization problem to generate a
physically-realizable, adversarial 3D-printed object that misleads an AD system
to fail in detecting it and thus crash into it. We propose a novel attack
pipeline that addresses two main design challenges: (1) non-differentiable
target camera and LiDAR sensing systems, and (2) non-differentiable cell-level
aggregated features popularly used in LiDAR-based AD perception. We evaluate
our attack on MSF included in representative open-source industry-grade AD
systems in real-world driving scenarios. Our results show that the attack
achieves over 90% success rate across different object types and MSF. Our
attack is also found stealthy, robust to victim positions, transferable across
MSF algorithms, and physical-world realizable after being 3D-printed and
captured by LiDAR and camera devices. To concretely assess the end-to-end
safety impact, we further perform simulation evaluation and show that it can
cause a 100% vehicle collision rate for an industry-grade AD system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity. (arXiv:2106.09524v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pesme_S/0/1/0/all/0/1">Scott Pesme</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1">Loucas Pillaud-Vivien</a>, <a href="http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1">Nicolas Flammarion</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09524">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the implicit bias of training algorithms is of crucial
importance in order to explain the success of overparametrised neural networks.
In this paper, we study the dynamics of stochastic gradient descent over
diagonal linear networks through its continuous time version, namely stochastic
gradient flow. We explicitly characterise the solution chosen by the stochastic
flow and prove that it always enjoys better generalisation properties than that
of gradient flow. Quite surprisingly, we show that the convergence speed of the
training loss controls the magnitude of the biasing effect: the slower the
convergence, the better the bias. To fully complete our analysis, we provide
convergence guarantees for the dynamics. We also give experimental results
which support our theoretical claims. Our findings highlight the fact that
structured noise can induce better generalisation and they help explain the
greater performances observed in practice of stochastic gradient descent over
gradient descent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Few-Shot Learning: Clustering is All You Need?. (arXiv:2106.09516v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziko_I/0/1/0/all/0/1">Imtiaz Masud Ziko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1">Malik Boudiaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09516">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate a general formulation for clustering and transductive few-shot
learning, which integrates prototype-based objectives, Laplacian regularization
and supervision constraints from a few labeled data points. We propose a
concave-convex relaxation of the problem, and derive a computationally
efficient block-coordinate bound optimizer, with convergence guarantee. At each
iteration,our optimizer computes independent (parallel) updates for each
point-to-cluster assignment. Therefore, it could be trivially distributed for
large-scale clustering and few-shot tasks. Furthermore, we provides a thorough
convergence analysis based on point-to-set maps. Were port comprehensive
clustering and few-shot learning experiments over various data sets, showing
that our method yields competitive performances, in term of accuracy and
optimization quality, while scaling up to large problems. Using standard
training on the base classes, without resorting to complex meta-learning and
episodic-training strategies, our approach outperforms state-of-the-art
few-shot methods by significant margins, across various models, settings and
data sets. Surprisingly, we found that even standard clustering procedures
(e.g., K-means), which correspond to particular, non-regularized cases of our
general model, already achieve competitive performances in comparison to the
state-of-the-art in few-shot learning. These surprising results point to the
limitations of the current few-shot benchmarks, and question the viability of a
large body of convoluted few-shot learning techniques in the recent literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Frustratingly Easy Transferability Estimation. (arXiv:2106.09362v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Long-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Ying Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09362">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability estimation has been an essential tool in selecting a
pre-trained model and the layers of it to transfer, so as to maximize the
performance on a target task and prevent negative transfer. Existing estimation
algorithms either require intensive training on target tasks or have
difficulties in evaluating the transferability between layers. We propose a
simple, efficient, and effective transferability measure named TransRate. With
single pass through the target data, TransRate measures the transferability as
the mutual information between the features of target examples extracted by a
pre-trained model and labels of them. We overcome the challenge of efficient
mutual information estimation by resorting to coding rate that serves as an
effective alternative to entropy. TransRate is theoretically analyzed to be
closely related to the performance after transfer learning. Despite its
extraordinary simplicity in 10 lines of codes, TransRate performs remarkably
well in extensive evaluations on 22 pre-trained models and 16 downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Reinforcement Learning Using Advantage-Based Intervention. (arXiv:2106.09110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wagener_N/0/1/0/all/0/1">Nolan Wagener</a>, <a href="http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1">Byron Boots</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09110">
                                    <div class="article-summary-box-inner">
                                        <span>Many sequential decision problems involve finding a policy that maximizes
total reward while obeying safety constraints. Although much recent research
has focused on the development of safe reinforcement learning (RL) algorithms
that produce a safe policy after training, ensuring safety during training as
well remains an open problem. A fundamental challenge is performing exploration
while still satisfying constraints in an unknown Markov decision process (MDP).
In this work, we address this problem for the chance-constrained setting. We
propose a new algorithm, SAILR, that uses an intervention mechanism based on
advantage functions to keep the agent safe throughout training and optimizes
the agent&#x27;s policy using off-the-shelf RL algorithms designed for unconstrained
MDPs. Our method comes with strong guarantees on safety during both training
and deployment (i.e., after training and without the intervention mechanism)
and policy performance compared to the optimal safety-constrained policy. In
our experiments, we show that SAILR violates constraints far less during
training than standard safe RL and constrained MDP approaches and converges to
a well-performing policy that can be deployed safely without intervention. Our
code is available at https://github.com/nolanwagener/safe_rl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifiability-Guaranteed Simplex-Structured Post-Nonlinear Mixture Learning via Autoencoder. (arXiv:2106.09070v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qi Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiao Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09070">
                                    <div class="article-summary-box-inner">
                                        <span>This work focuses on the problem of unraveling nonlinearly mixed latent
components in an unsupervised manner. The latent components are assumed to
reside in the probability simplex, and are transformed by an unknown
post-nonlinear mixing system. This problem finds various applications in signal
and data analytics, e.g., nonlinear hyperspectral unmixing, image embedding,
and nonlinear clustering. Linear mixture learning problems are already
ill-posed, as identifiability of the target latent components is hard to
establish in general. With unknown nonlinearity involved, the problem is even
more challenging. Prior work offered a function equation-based formulation for
provable latent component identification. However, the identifiability
conditions are somewhat stringent and unrealistic. In addition, the
identifiability analysis is based on the infinite sample (i.e., population)
case, while the understanding for practical finite sample cases has been
elusive. Moreover, the algorithm in the prior work trades model expressiveness
with computational convenience, which often hinders the learning performance.
Our contribution is threefold. First, new identifiability conditions are
derived under largely relaxed assumptions. Second, comprehensive sample
complexity results are presented -- which are the first of the kind. Third, a
constrained autoencoder-based algorithmic framework is proposed for
implementation, which effectively circumvents the challenges in the existing
algorithm. Synthetic and real experiments corroborate our theoretical analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning for Intrusion Detection System: Concepts, Challenges and Future Directions. (arXiv:2106.09527v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Shaashwat Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1">Sagnik Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Aouedi_O/0/1/0/all/0/1">Ons Aouedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yenduri_G/0/1/0/all/0/1">Gokul Yenduri</a>, <a href="http://arxiv.org/find/cs/1/au:+Piamrat_K/0/1/0/all/0/1">Kandaraj Piamrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Sweta Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddikunta_P/0/1/0/all/0/1">Praveen Kumar Reddy Maddikunta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadekallu_T/0/1/0/all/0/1">Thippa Reddy Gadekallu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09527">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid development of the Internet and smart devices trigger surge in
network traffic making its infrastructure more complex and heterogeneous. The
predominated usage of mobile phones, wearable devices and autonomous vehicles
are examples of distributed networks which generate huge amount of data each
and every day. The computational power of these devices have also seen steady
progression which has created the need to transmit information, store data
locally and drive network computations towards edge devices. Intrusion
detection systems play a significant role in ensuring security and privacy of
such devices. Machine Learning and Deep Learning with Intrusion Detection
Systems have gained great momentum due to their achievement of high
classification accuracy. However the privacy and security aspects potentially
gets jeopardised due to the need of storing and communicating data to
centralized server. On the contrary, federated learning (FL) fits in
appropriately as a privacy-preserving decentralized learning technique that
does not transfer data but trains models locally and transfers the parameters
to the centralized server. The present paper aims to present an extensive and
exhaustive review on the use of FL in intrusion detection system. In order to
establish the need for FL, various types of IDS, relevant ML approaches and its
associated issues are discussed. The paper presents detailed overview of the
implementation of FL in various aspects of anomaly detection. The allied
challenges of FL implementations are also identified which provides idea on the
scope of future direction of research. The paper finally presents the plausible
solutions associated with the identified challenges in FL based intrusion
detection system implementation acting as a baseline for prospective research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding Deep Learning from Noisy Labels with Small-Loss Criterion. (arXiv:2106.09291v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gui_X/0/1/0/all/0/1">Xian-Jin Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhang-Hao Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09291">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks need large amounts of labeled data to achieve good
performance. In real-world applications, labels are usually collected from
non-experts such as crowdsourcing to save cost and thus are noisy. In the past
few years, deep learning methods for dealing with noisy labels have been
developed, many of which are based on the small-loss criterion. However, there
are few theoretical analyses to explain why these methods could learn well from
noisy labels. In this paper, we theoretically explain why the widely-used
small-loss criterion works. Based on the explanation, we reformalize the
vanilla small-loss criterion to better tackle noisy labels. The experimental
results verify our theoretical explanation and also demonstrate the
effectiveness of the reformalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Demonstration without Demonstrations. (arXiv:2106.09203v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blau_T/0/1/0/all/0/1">Tom Blau</a>, <a href="http://arxiv.org/find/cs/1/au:+Francis_G/0/1/0/all/0/1">Gilad Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Morere_P/0/1/0/all/0/1">Philippe Morere</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09203">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art reinforcement learning (RL) algorithms suffer from high
sample complexity, particularly in the sparse reward case. A popular strategy
for mitigating this problem is to learn control policies by imitating a set of
expert demonstrations. The drawback of such approaches is that an expert needs
to produce demonstrations, which may be costly in practice. To address this
shortcoming, we propose Probabilistic Planning for Demonstration Discovery
(P2D2), a technique for automatically discovering demonstrations without access
to an expert. We formulate discovering demonstrations as a search problem and
leverage widely-used planning algorithms such as Rapidly-exploring Random Tree
to find demonstration trajectories. These demonstrations are used to initialize
a policy, then refined by a generic RL algorithm. We provide theoretical
guarantees of P2D2 finding successful trajectories, as well as bounds for its
sampling complexity. We experimentally demonstrate the method outperforms
classic and intrinsic exploration RL techniques in a range of classic control
and robotics tasks, requiring only a fraction of exploration samples and
achieving better asymptotic performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Online Chats with DAG-Structured LSTMs. (arXiv:2106.09024v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pappadopulo_D/0/1/0/all/0/1">Duccio Pappadopulo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_L/0/1/0/all/0/1">Lisa Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Farina_M/0/1/0/all/0/1">Marco Farina</a>, <a href="http://arxiv.org/find/cs/1/au:+Irsoy_O/0/1/0/all/0/1">Ozan &#x130;rsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09024">
                                    <div class="article-summary-box-inner">
                                        <span>Many modern messaging systems allow fast and synchronous textual
communication among many users. The resulting sequence of messages hides a more
complicated structure in which independent sub-conversations are interwoven
with one another. This poses a challenge for any task aiming to understand the
content of the chat logs or gather information from them. The ability to
disentangle these conversations is then tantamount to the success of many
downstream tasks such as summarization and question answering. Structured
information accompanying the text such as user turn, user mentions, timestamps,
is used as a cue by the participants themselves who need to follow the
conversation and has been shown to be important for disentanglement. DAG-LSTMs,
a generalization of Tree-LSTMs that can handle directed acyclic dependencies,
are a natural way to incorporate such information and its non-sequential
nature. In this paper, we apply DAG-LSTMs to the conversation disentanglement
task. We perform our experiments on the Ubuntu IRC dataset. We show that the
novel model we propose achieves state of the art status on the task of
recovering reply-to relations and it is competitive on other disentanglement
metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Curricula via Expert Demonstrations. (arXiv:2106.09159v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Siyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_A/0/1/0/all/0/1">Andreas Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1">Brian Williams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09159">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Automatic Curricula via Expert Demonstrations (ACED), a
reinforcement learning (RL) approach that combines the ideas of imitation
learning and curriculum learning in order to solve challenging robotic
manipulation tasks with sparse reward functions. Curriculum learning solves
complicated RL tasks by introducing a sequence of auxiliary tasks with
increasing difficulty, yet how to automatically design effective and
generalizable curricula remains a challenging research problem. ACED extracts
curricula from a small amount of expert demonstration trajectories by dividing
demonstrations into sections and initializing training episodes to states
sampled from different sections of demonstrations. Through moving the reset
states from the end to the beginning of demonstrations as the learning agent
improves its performance, ACED not only learns challenging manipulation tasks
with unseen initializations and goals, but also discovers novel solutions that
are distinct from the demonstrations. In addition, ACED can be naturally
combined with other imitation learning methods to utilize expert demonstrations
in a more efficient manner, and we show that a combination of ACED with
behavior cloning allows pick-and-place tasks to be learned with as few as 1
demonstration and block stacking tasks to be learned with 20 demonstrations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep generative modeling for probabilistic forecasting in power systems. (arXiv:2106.09370v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanaspeze_A/0/1/0/all/0/1">Antoine Wehenkel Damien Lanaspeze</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornelusse_B/0/1/0/all/0/1">Bertrand Corn&#xe9;lusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutera_A/0/1/0/all/0/1">Antonio Sutera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09370">
                                    <div class="article-summary-box-inner">
                                        <span>Greater direct electrification of end-use sectors with a higher share of
renewables is one of the pillars to power a carbon-neutral society by 2050.
This study uses a recent deep learning technique, the normalizing flows, to
produce accurate probabilistic forecasts that are crucial for decision-makers
to face the new challenges in power systems applications. Through comprehensive
empirical evaluations using the open data of the Global Energy Forecasting
Competition 2014, we demonstrate that our methodology is competitive with other
state-of-the-art deep learning generative models: generative adversarial
networks and variational autoencoders. The models producing weather-based wind,
solar power, and load scenarios are properly compared both in terms of forecast
value, by considering the case study of an energy retailer, and quality using
several complementary metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting cognitive scores with graph neural networks through sample selection learning. (arXiv:2106.09408v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hanik_M/0/1/0/all/0/1">Martin Hanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Demirtas_M/0/1/0/all/0/1">Mehmet Arif Demirta&#x15f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharsallaoui_M/0/1/0/all/0/1">Mohammed Amine Gharsallaoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekik_I/0/1/0/all/0/1">Islem Rekik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09408">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing the relation between intelligence and neural activity is of the
utmost importance in understanding the working principles of the human brain in
health and disease. In existing literature, functional brain connectomes have
been used successfully to predict cognitive measures such as intelligence
quotient (IQ) scores in both healthy and disordered cohorts using machine
learning models. However, existing methods resort to flattening the brain
connectome (i.e., graph) through vectorization which overlooks its topological
properties. To address this limitation and inspired from the emerging graph
neural networks (GNNs), we design a novel regression GNN model (namely RegGNN)
for predicting IQ scores from brain connectivity. On top of that, we introduce
a novel, fully modular sample selection method to select the best samples to
learn from for our target prediction task. However, since such deep learning
architectures are computationally expensive to train, we further propose a
\emph{learning-based sample selection} method that learns how to choose the
training samples with the highest expected predictive power on unseen samples.
For this, we capitalize on the fact that connectomes (i.e., their adjacency
matrices) lie in the symmetric positive definite (SPD) matrix cone. Our results
on full-scale and verbal IQ prediction outperforms comparison methods in autism
spectrum disorder cohorts and achieves a competitive performance for
neurotypical subjects using 3-fold cross-validation. Furthermore, we show that
our sample selection approach generalizes to other learning-based methods,
which shows its usefulness beyond our GNN architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework. (arXiv:2106.09121v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jiahao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Byeon_W/0/1/0/all/0/1">Wonmin Byeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09121">
                                    <div class="article-summary-box-inner">
                                        <span>Enforcing orthogonality in neural networks is an antidote for gradient
vanishing/exploding problems, sensitivity by adversarial perturbation, and
bounding generalization errors. However, many previous approaches are
heuristic, and the orthogonality of convolutional layers is not systematically
studied: some of these designs are not exactly orthogonal, while others only
consider standard convolutional layers and propose specific classes of their
realizations. To address this problem, we propose a theoretical framework for
orthogonal convolutional layers, which establishes the equivalence between
various orthogonal convolutional layers in the spatial domain and the
paraunitary systems in the spectral domain. Since there exists a complete
spectral factorization of paraunitary systems, any orthogonal convolution layer
can be parameterized as convolutions of spatial filters. Our framework endows
high expressive power to various convolutional layers while maintaining their
exact orthogonality. Furthermore, our layers are memory and computationally
efficient for deep networks compared to previous designs. Our versatile
framework, for the first time, enables the study of architecture designs for
deep orthogonal networks, such as choices of skip connection, initialization,
stride, and dilation. Consequently, we scale up orthogonal networks to deep
architectures, including ResNet, WideResNet, and ShuffleNet, substantially
increasing the performance over the traditional shallow orthogonal networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Main Character Recognition for Photographic Studies. (arXiv:2106.09064v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1">Mert Seker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1">Anssi M&#xe4;nnist&#xf6;</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09064">
                                    <div class="article-summary-box-inner">
                                        <span>Main characters in images are the most important humans that catch the
viewer&#x27;s attention upon first look, and they are emphasized by properties such
as size, position, color saturation, and sharpness of focus. Identifying the
main character in images plays an important role in traditional photographic
studies and media analysis, but the task is performed manually and can be slow
and laborious. Furthermore, selection of main characters can be sometimes
subjective. In this paper, we analyze the feasibility of solving the main
character recognition needed for photographic studies automatically and propose
a method for identifying the main characters. The proposed method uses machine
learning based human pose estimation along with traditional computer vision
approaches for this task. We approach the task as a binary classification
problem where each detected human is classified either as a main character or
not. To evaluate both the subjectivity of the task and the performance of our
method, we collected a dataset of 300 varying images from multiple sources and
asked five people, a photographic researcher and four other persons, to
annotate the main characters. Our analysis showed a relatively high agreement
between different annotators. The proposed method achieved a promising F1 score
of 0.83 on the full image set and 0.96 on a subset evaluated as most clear and
important cases by the photographic researcher.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPeCiaL: Self-Supervised Pretraining for Continual Learning. (arXiv:2106.09065v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09065">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents SPeCiaL: a method for unsupervised pretraining of
representations tailored for continual learning. Our approach devises a
meta-learning objective that differentiates through a sequential learning
process. Specifically, we train a linear model over the representations to
match different augmented views of the same image together, each view presented
sequentially. The linear model is then evaluated on both its ability to
classify images it just saw, and also on images from previous iterations. This
gives rise to representations that favor quick knowledge retention with minimal
forgetting. We evaluate SPeCiaL in the Continual Few-Shot Learning setting, and
show that it can match or outperform other supervised pretraining approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the training of sparse and dense deep neural networks: less parameters, same performance. (arXiv:2106.09021v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1">Lorenzo Chicchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1">Lorenzo Giambagli</a>, <a href="http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1">Lorenzo Buffoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Carletti_T/0/1/0/all/0/1">Timoteo Carletti</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciavarella_M/0/1/0/all/0/1">Marco Ciavarella</a>, <a href="http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1">Duccio Fanelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09021">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks can be trained in reciprocal space, by acting on the
eigenvalues and eigenvectors of suitable transfer operators in direct space.
Adjusting the eigenvalues, while freezing the eigenvectors, yields a
substantial compression of the parameter space. This latter scales by
definition with the number of computing neurons. The classification scores, as
measured by the displayed accuracy, are however inferior to those attained when
the learning is carried in direct space, for an identical architecture and by
employing the full set of trainable parameters (with a quadratic dependence on
the size of neighbor layers). In this Letter, we propose a variant of the
spectral learning method as appeared in Giambagli et al {Nat. Comm.} 2021,
which leverages on two sets of eigenvalues, for each mapping between adjacent
layers. The eigenvalues act as veritable knobs which can be freely tuned so as
to (i) enhance, or alternatively silence, the contribution of the input nodes,
(ii) modulate the excitability of the receiving nodes with a mechanism which we
interpret as the artificial analogue of the homeostatic plasticity. The number
of trainable parameters is still a linear function of the network size, but the
performances of the trained device gets much closer to those obtained via
conventional algorithms, these latter requiring however a considerably heavier
computational cost. The residual gap between conventional and spectral
trainings can be eventually filled by employing a suitable decomposition for
the non trivial block of the eigenvectors matrix. Each spectral parameter
reflects back on the whole set of inter-nodes weights, an attribute which we
shall effectively exploit to yield sparse networks with stunning classification
abilities, as compared to their homologues trained with conventional means.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Construction of Evaluation Suites for Natural Language Generation Datasets. (arXiv:2106.09069v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mille_S/0/1/0/all/0/1">Simon Mille</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1">Kaustubh D. Dhole</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahamood_S/0/1/0/all/0/1">Saad Mahamood</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Beltrachini_L/0/1/0/all/0/1">Laura Perez-Beltrachini</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Miltenburg_E/0/1/0/all/0/1">Emiel van Miltenburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09069">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning approaches applied to NLP are often evaluated by summarizing
their performance in a single number, for example accuracy. Since most test
sets are constructed as an i.i.d. sample from the overall data, this approach
overly simplifies the complexity of language and encourages overfitting to the
head of the data distribution. As such, rare language phenomena or text about
underrepresented groups are not equally included in the evaluation. To
encourage more in-depth model analyses, researchers have proposed the use of
multiple test sets, also called challenge sets, that assess specific
capabilities of a model. In this paper, we develop a framework based on this
idea which is able to generate controlled perturbations and identify subsets in
text-to-scalar, text-to-text, or data-to-text settings. By applying this
framework to the GEM generation benchmark, we propose an evaluation suite made
of 80 challenge sets, demonstrate the kinds of analyses that it enables and
shed light onto the limits of current generation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zeroth-Order Methods for Convex-Concave Minmax Problems: Applications to Decision-Dependent Risk Minimization. (arXiv:2106.09082v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Maheshwari_C/0/1/0/all/0/1">Chinmay Maheshwari</a>, <a href="http://arxiv.org/find/math/1/au:+Chiu_C/0/1/0/all/0/1">Chih-Yuan Chiu</a>, <a href="http://arxiv.org/find/math/1/au:+Mazumdar_E/0/1/0/all/0/1">Eric Mazumdar</a>, <a href="http://arxiv.org/find/math/1/au:+Sastry_S/0/1/0/all/0/1">S. Shankar Sastry</a>, <a href="http://arxiv.org/find/math/1/au:+Ratliff_L/0/1/0/all/0/1">Lillian J. Ratliff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09082">
                                    <div class="article-summary-box-inner">
                                        <span>Min-max optimization is emerging as a key framework for analyzing problems of
robustness to strategically and adversarially generated data. We propose a
random reshuffling-based gradient free Optimistic Gradient Descent-Ascent
algorithm for solving convex-concave min-max problems with finite sum
structure. We prove that the algorithm enjoys the same convergence rate as that
of zeroth-order algorithms for convex minimization problems. We further
specialize the algorithm to solve distributionally robust, decision-dependent
learning problems, where gradient information is not readily available. Through
illustrative simulations, we observe that our proposed approach learns models
that are simultaneously robust against adversarial distribution shifts and
strategic decisions from the data sources, and outperforms existing methods
from the strategic classification literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RHNAS: Realizable Hardware and Neural Architecture Search. (arXiv:2106.09180v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhauri_Y/0/1/0/all/0/1">Yash Akhauri</a>, <a href="http://arxiv.org/find/cs/1/au:+Niranjan_A/0/1/0/all/0/1">Adithya Niranjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Munoz_J/0/1/0/all/0/1">J. Pablo Mu&#xf1;oz</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1">Suvadeep Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Davare_A/0/1/0/all/0/1">Abhijit Davare</a>, <a href="http://arxiv.org/find/cs/1/au:+Cocchini_P/0/1/0/all/0/1">Pasquale Cocchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorokin_A/0/1/0/all/0/1">Anton A. Sorokin</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Ravi Iyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1">Nilesh Jain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09180">
                                    <div class="article-summary-box-inner">
                                        <span>The rapidly evolving field of Artificial Intelligence necessitates automated
approaches to co-design neural network architecture and neural accelerators to
maximize system efficiency and address productivity challenges. To enable joint
optimization of this vast space, there has been growing interest in
differentiable NN-HW co-design. Fully differentiable co-design has reduced the
resource requirements for discovering optimized NN-HW configurations, but fail
to adapt to general hardware accelerator search spaces. This is due to the
existence of non-synthesizable (invalid) designs in the search space of many
hardware accelerators. To enable efficient and realizable co-design of
configurable hardware accelerators with arbitrary neural network search spaces,
we introduce RHNAS. RHNAS is a method that combines reinforcement learning for
hardware optimization with differentiable neural architecture search. RHNAS
discovers realizable NN-HW designs with 1.84x lower latency and 1.86x lower
energy-delay product (EDP) on ImageNet and 2.81x lower latency and 3.30x lower
EDP on CIFAR-10 over the default hardware accelerator design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularization of Mixture Models for Robust Principal Graph Learning. (arXiv:2106.09035v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bonnaire_T/0/1/0/all/0/1">Tony Bonnaire</a>, <a href="http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1">Aur&#xe9;lien Decelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Aghanim_N/0/1/0/all/0/1">Nabila Aghanim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09035">
                                    <div class="article-summary-box-inner">
                                        <span>A regularized version of Mixture Models is proposed to learn a principal
graph from a distribution of $D$-dimensional data points. In the particular
case of manifold learning for ridge detection, we assume that the underlying
manifold can be modeled as a graph structure acting like a topological prior
for the Gaussian clusters turning the problem into a maximum a posteriori
estimation. Parameters of the model are iteratively estimated through an
Expectation-Maximization procedure making the learning of the structure
computationally efficient with guaranteed convergence for any graph prior in a
polynomial time. We also embed in the formalism a natural way to make the
algorithm robust to outliers of the pattern and heteroscedasticity of the
manifold sampling coherently with the graph structure. The method uses a graph
prior given by the minimum spanning tree that we extend using random
sub-samplings of the dataset to take into account cycles that can be observed
in the spatial distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection. (arXiv:2106.09022v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Fort_S/0/1/0/all/0/1">Stanislav Fort</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jeremiah Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Abhijit Guha Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhy_S/0/1/0/all/0/1">Shreyas Padhy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1">Balaji Lakshminarayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09022">
                                    <div class="article-summary-box-inner">
                                        <span>Mahalanobis distance (MD) is a simple and popular post-processing method for
detecting out-of-distribution (OOD) inputs in neural networks. We analyze its
failure modes for near-OOD detection and propose a simple fix called relative
Mahalanobis distance (RMD) which improves performance and is more robust to
hyperparameter choice. On a wide selection of challenging vision, language, and
biology OOD benchmarks (CIFAR-100 vs CIFAR-10, CLINC OOD intent detection,
Genomics OOD), we show that RMD meaningfully improves upon MD performance (by
up to 15% AUROC on genomics OOD).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QuantumFed: A Federated Learning Framework for Collaborative Quantum Training. (arXiv:2106.09109v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1">Qun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qun Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09109">
                                    <div class="article-summary-box-inner">
                                        <span>With the fast development of quantum computing and deep learning, quantum
neural networks have attracted great attention recently. By leveraging the
power of quantum computing, deep neural networks can potentially overcome
computational power limitations in classic machine learning. However, when
multiple quantum machines wish to train a global model using the local data on
each machine, it may be very difficult to copy the data into one machine and
train the model. Therefore, a collaborative quantum neural network framework is
necessary. In this article, we borrow the core idea of federated learning to
propose QuantumFed, a quantum federated learning framework to have multiple
quantum nodes with local quantum data train a mode together. Our experiments
show the feasibility and robustness of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Video Prediction from a Single Frame by Estimating 3D Dynamic Scene Structure. (arXiv:2106.09051v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Paul Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1">Christoph H. Lampert</a>, <a href="http://arxiv.org/find/cs/1/au:+Bickel_B/0/1/0/all/0/1">Bernd Bickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09051">
                                    <div class="article-summary-box-inner">
                                        <span>Our goal in this work is to generate realistic videos given just one initial
frame as input. Existing unsupervised approaches to this task do not consider
the fact that a video typically shows a 3D environment, and that this should
remain coherent from frame to frame even as the camera and objects move. We
address this by developing a model that first estimates the latent 3D structure
of the scene, including the segmentation of any moving objects. It then
predicts future frames by simulating the object and camera dynamics, and
rendering the resulting views. Importantly, it is trained end-to-end using only
the unsupervised objective of predicting future frames, without any 3D
information nor segmentation annotations. Experiments on two challenging
datasets of natural videos show that our model can estimate 3D structure and
motion segmentation from a single frame, and hence generate plausible and
varied predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model. (arXiv:2106.09317v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Chenye Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Feiyang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1">Rongjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_M/0/1/0/all/0/1">Ming Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09317">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing interest in neural speech synthesis.
While the deep neural network achieves the state-of-the-art result in
text-to-speech (TTS) tasks, how to generate a more emotional and more
expressive speech is becoming a new challenge to researchers due to the
scarcity of high-quality emotion speech dataset and the lack of advanced
emotional TTS model. In this paper, we first briefly introduce and publicly
release a Mandarin emotion speech dataset including 9,724 samples with audio
files and its emotion human-labeled annotation. After that, we propose a simple
but efficient architecture for emotional speech synthesis called EMSpeech.
Unlike those models which need additional reference audio as input, our model
could predict emotion labels just from the input text and generate more
expressive speech conditioned on the emotion embedding. In the experiment
phase, we first validate the effectiveness of our dataset by an emotion
classification task. Then we train our model on the proposed dataset and
conduct a series of subjective evaluations. Finally, by showing a comparable
performance in the emotional speech synthesis task, we successfully demonstrate
the ability of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Two-stage Multi-modal Affect Analysis Framework for Children with Autism Spectrum Disorder. (arXiv:2106.09199v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jicheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_A/0/1/0/all/0/1">Anjana Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Barmaki_R/0/1/0/all/0/1">Roghayeh Barmaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09199">
                                    <div class="article-summary-box-inner">
                                        <span>Autism spectrum disorder (ASD) is a developmental disorder that influences
the communication and social behavior of a person in a way that those in the
spectrum have difficulty in perceiving other people&#x27;s facial expressions, as
well as presenting and communicating emotions and affect via their own faces
and bodies. Some efforts have been made to predict and improve children with
ASD&#x27;s affect states in play therapy, a common method to improve children&#x27;s
social skills via play and games. However, many previous works only used
pre-trained models on benchmark emotion datasets and failed to consider the
distinction in emotion between typically developing children and children with
autism. In this paper, we present an open-source two-stage multi-modal approach
leveraging acoustic and visual cues to predict three main affect states of
children with ASD&#x27;s affect states (positive, negative, and neutral) in
real-world play therapy scenarios, and achieved an overall accuracy of 72:40%.
This work presents a novel way to combine human expertise and machine
intelligence for ASD affect recognition by proposing a two-stage schema.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-17">2021-06-17</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1">Richard Antonello</a>, <a href="http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1">Javier Turek</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1">Vy Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1">Alexander Huth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05426">
                                    <div class="article-summary-box-inner">
                                        <span>How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain&#x27;s
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain&#x27;s natural language representation structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hash Layers For Large Sparse Models. (arXiv:2106.04426v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1">Arthur Szlam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04426">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the training of sparse layers that use different parameters
for different inputs based on hashing in large Transformer models.
Specifically, we modify the feedforward layer to hash to different sets of
weights depending on the current token, over all tokens in the sequence. We
show that this procedure either outperforms or is competitive with
learning-to-route mixture-of-expert methods such as Switch Transformers and
BASE Layers, while requiring no routing parameters or extra terms in the
objective function such as a load balancing loss, and no sophisticated
assignment algorithm. We study the performance of different hashing techniques,
hash sizes and input features, and show that balanced and random hashes focused
on the most local features work best, compared to either learning clusters or
using longer-range context. We show our approach works well both on large
language modeling and dialogue tasks, and on downstream fine-tuning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods. (arXiv:2106.08829v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheema_G/0/1/0/all/0/1">Gullal S. Cheema</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1">Sherzod Hakimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1">Eric M&#xfc;ller-Budack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08829">
                                    <div class="article-summary-box-inner">
                                        <span>Opinion and sentiment analysis is a vital task to characterize subjective
information in social media posts. In this paper, we present a comprehensive
experimental evaluation and comparison with six state-of-the-art methods, from
which we have re-implemented one of them. In addition, we investigate different
textual and visual feature embeddings that cover different aspects of the
content, as well as the recently introduced multimodal CLIP embeddings.
Experimental results are presented for two different publicly available
benchmark datasets of tweets and corresponding images. In contrast to the
evaluation methodology of previous work, we introduce a reproducible and fair
evaluation scheme to make results comparable. Finally, we conduct an error
analysis to outline the limitations of the methods and possibilities for the
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidence-based Factual Error Correction. (arXiv:2012.15788v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15788">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the task of factual error correction: performing edits
to a claim so that the generated rewrite is better supported by evidence. This
extends the well-studied task of fact verification by providing a mechanism to
correct written texts that are refuted or only partially supported by evidence.
We demonstrate that it is feasible to train factual error correction systems
from existing fact checking datasets which only contain labeled claims
accompanied by evidence, but not the correction. We achieve this by employing a
two-stage distant supervision approach that incorporates evidence into masked
claims when generating corrections. Our approach, based on the T5 transformer
and using retrieved evidence, achieved better results than existing work which
used a pointer copy network and gold evidence, producing accurate factual error
corrections for 5x more instances in human evaluation and a .125 increase in
SARI score. The evaluation is conducted on a dataset of 65,000 instances based
on a recent fact verification shared task and we release it to enable further
work on the task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hipson_W/0/1/0/all/0/1">Will E. Hipson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1">Saif M. Mohammad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01345">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion dynamics is a framework for measuring how an individual&#x27;s emotions
change over time. It is a powerful tool for understanding how we behave and
interact with the world. In this paper, we introduce a framework to track
emotion dynamics through one&#x27;s utterances. Specifically we introduce a number
of utterance emotion dynamics (UED) metrics inspired by work in Psychology. We
use this approach to trace emotional arcs of movie characters. We analyze
thousands of such character arcs to test hypotheses that inform our broader
understanding of stories. Notably, we show that there is a tendency for
characters to use increasingly more negative words and become increasingly
emotionally discordant with each other until about 90 percent of the narrative
length. UED also has applications in behavior studies, social sciences, and
public health.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the long-term learning ability of LSTM LMs. (arXiv:2106.08927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boes_W/0/1/0/all/0/1">Wim Boes</a>, <a href="http://arxiv.org/find/cs/1/au:+Rompaey_R/0/1/0/all/0/1">Robbe Van Rompaey</a>, <a href="http://arxiv.org/find/cs/1/au:+Verwimp_L/0/1/0/all/0/1">Lyan Verwimp</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelemans_J/0/1/0/all/0/1">Joris Pelemans</a>, <a href="http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1">Hugo Van hamme</a>, <a href="http://arxiv.org/find/cs/1/au:+Wambacq_P/0/1/0/all/0/1">Patrick Wambacq</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08927">
                                    <div class="article-summary-box-inner">
                                        <span>We inspect the long-term learning ability of Long Short-Term Memory language
models (LSTM LMs) by evaluating a contextual extension based on the Continuous
Bag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and
by analyzing its performance. We evaluate on text and speech. Sentence-level
models using the long-term contextual module perform comparably to vanilla
discourse-level LSTM LMs. On the other hand, the extension does not provide
gains for discourse-level models. These findings indicate that discourse-level
LSTM LMs already rely on contextual information to perform long-term learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SEOVER: Sentence-level Emotion Orientation Vector based Conversation Emotion Recognition Model. (arXiv:2106.08785v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zaijing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1">Fengxiao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tieyu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yusen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Ming Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08785">
                                    <div class="article-summary-box-inner">
                                        <span>For the task of conversation emotion recognition, recent works focus on
speaker relationship modeling but ignore the role of utterance&#x27;s emotional
tendency.In this paper, we propose a new expression paradigm of sentence-level
emotion orientation vector to model the potential correlation of emotions
between sentence vectors. Based on it, we design an emotion recognition model,
which extracts the sentence-level emotion orientation vectors from the language
model and jointly learns from the dialogue sentiment analysis model and
extracted sentence-level emotion orientation vectors to identify the speaker&#x27;s
emotional orientation during the conversation. We conduct experiments on two
benchmark datasets and compare them with the five baseline models.The
experimental results show that our model has better performance on all data
sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathological voice adaptation with autoencoder-based voice conversion. (arXiv:2106.08427v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Illa_M/0/1/0/all/0/1">Marc Illa</a>, <a href="http://arxiv.org/find/cs/1/au:+Halpern_B/0/1/0/all/0/1">Bence Mark Halpern</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_R/0/1/0/all/0/1">Rob van Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Moro_Velazquez_L/0/1/0/all/0/1">Laureano Moro-Velazquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharenborg_O/0/1/0/all/0/1">Odette Scharenborg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08427">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a new approach to pathological speech synthesis.
Instead of using healthy speech as a source, we customise an existing
pathological speech sample to a new speaker&#x27;s voice characteristics. This
approach alleviates the evaluation problem one normally has when converting
typical speech to pathological speech, as in our approach, the voice conversion
(VC) model does not need to be optimised for speech degradation but only for
the speaker change. This change in the optimisation ensures that any
degradation found in naturalness is due to the conversion process and not due
to the model exaggerating characteristics of a speech pathology. To show a
proof of concept of this method, we convert dysarthric speech using the
UASpeech database and an autoencoder-based VC technique. Subjective evaluation
results show reasonable naturalness for high intelligibility dysarthric
speakers, though lower intelligibility seems to introduce a marginal
degradation in naturalness scores for mid and low intelligibility speakers
compared to ground truth. Conversion of speaker characteristics for low and
high intelligibility speakers is successful, but not for mid. Whether the
differences in the results for the different intelligibility levels is due to
the intelligibility levels or due to the speakers needs to be further
investigated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-independent User Simulation with Transformers for Task-oriented Dialogue Systems. (arXiv:2106.08838v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hsien-chin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lubis_N/0/1/0/all/0/1">Nurul Lubis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songbo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekerk_C/0/1/0/all/0/1">Carel van Niekerk</a>, <a href="http://arxiv.org/find/cs/1/au:+Geishauser_C/0/1/0/all/0/1">Christian Geishauser</a>, <a href="http://arxiv.org/find/cs/1/au:+Heck_M/0/1/0/all/0/1">Michael Heck</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shutong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1">Milica Ga&#x161;i&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08838">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue policy optimisation via reinforcement learning requires a large
number of training interactions, which makes learning with real users time
consuming and expensive. Many set-ups therefore rely on a user simulator
instead of humans. These user simulators have their own problems. While
hand-coded, rule-based user simulators have been shown to be sufficient in
small, simple domains, for complex domains the number of rules quickly becomes
intractable. State-of-the-art data-driven user simulators, on the other hand,
are still domain-dependent. This means that adaptation to each new domain
requires redesigning and retraining. In this work, we propose a
domain-independent transformer-based user simulator (TUS). The structure of our
TUS is not tied to a specific domain, enabling domain generalisation and
learning of cross-domain user behaviour from data. We compare TUS with the
state of the art using automatic as well as human evaluations. TUS can compete
with rule-based user simulators on pre-defined domains and is able to
generalise to unseen domains in a zero-shot fashion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the proper role of linguistically-oriented deep net analysis in linguistic theorizing. (arXiv:2106.08694v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1">Marco Baroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08694">
                                    <div class="article-summary-box-inner">
                                        <span>A lively research field has recently emerged that uses experimental methods
to probe the linguistic behavior of modern deep networks. While work in this
tradition often reports intriguing results about the grammatical skills of deep
nets, it is not clear what their implications for linguistic theorizing should
be. As a consequence, linguistically-oriented deep net analysis has had very
little impact on linguistics at large. In this chapter, I suggest that deep
networks should be treated as theories making explicit predictions about the
acceptability of linguistic utterances. I argue that, if we overcome some
obstacles standing in the way of seriously pursuing this idea, we will gain a
powerful new theoretical tool, complementary to mainstream algebraic
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmenting Part-of-speech Tagging with Syntactic Information for Vietnamese and Chinese. (arXiv:2102.12136v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Duc-Vu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12136">
                                    <div class="article-summary-box-inner">
                                        <span>Word segmentation and part-of-speech tagging are two critical preliminary
steps for downstream tasks in Vietnamese natural language processing. In
reality, people tend to consider also the phrase boundary when performing word
segmentation and part of speech tagging rather than solely process word by word
from left to right. In this paper, we implement this idea to improve word
segmentation and part of speech tagging the Vietnamese language by employing a
simplified constituency parser. Our neural model for joint word segmentation
and part-of-speech tagging has the architecture of the syllable-based CRF
constituency parser. To reduce the complexity of parsing, we replace all
constituent labels with a single label indicating for phrases. This model can
be augmented with predicted word boundary and part-of-speech tags by other
tools. Because Vietnamese and Chinese have some similar linguistic phenomena,
we evaluated the proposed model and its augmented versions on three Vietnamese
benchmark datasets and six Chinese benchmark datasets. Our experimental results
show that the proposed model achieves higher performances than previous works
for both languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BANG: Bridging Autoregressive and Non-autoregressive Generation with Large Scale Pretraining. (arXiv:2012.15525v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1">Weizhen Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yeyun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jian Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dayiheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Kewen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiusheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruofei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Ming Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15525">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose BANG, a new pretraining model to Bridge the gap
between Autoregressive (AR) and Non-autoregressive (NAR) Generation. AR and NAR
generation can be uniformly regarded as to what extent previous tokens can be
attended, and BANG bridges AR and NAR generation by designing a novel model
structure for large-scale pretraining. The pretrained BANG model can
simultaneously support AR, NAR and semi-NAR generation to meet different
requirements. Experiments on question generation (SQuAD 1.1), summarization
(XSum) and dialogue generation (PersonaChat) show that BANG improves NAR and
semi-NAR performance significantly as well as attaining comparable performance
with strong AR pretrained models. Compared with the semi-NAR strong baselines,
BANG achieves absolute improvements of 14.01 and 5.24 in the overall scores of
SQuAD 1.1 and XSum, respectively. In addition, BANG achieves absolute
improvements of 10.73, 6.39 and 5.90 in the overall scores of SQuAD, XSUM and
PersonaChat respectively compared with the strong NAR baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DialogSum: A Real-Life Scenario Dialogue Summarization Dataset. (arXiv:2105.06762v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yulong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06762">
                                    <div class="article-summary-box-inner">
                                        <span>Proposal of large-scale datasets has facilitated research on deep neural
models for news summarization. Deep learning can also be potentially useful for
spoken dialogue summarization, which can benefit a range of real-life scenarios
including customer service management and medication tracking. To this end, we
propose DialogSum, a large-scale labeled dialogue summarization dataset. We
conduct empirical analysis on DialogSum using state-of-the-art neural
summarizers. Experimental results show unique challenges in dialogue
summarization, such as spoken terms, special discourse structures, coreferences
and ellipsis, pragmatics and social common sense, which require specific
representation learning technologies to better deal with.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion. (arXiv:2105.09002v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Haipeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuxue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zakari_R/0/1/0/all/0/1">Rufai Yusuf Zakari</a>, <a href="http://arxiv.org/find/cs/1/au:+Owusu_J/0/1/0/all/0/1">Jim Wilson Owusu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_K/0/1/0/all/0/1">Ke Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09002">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge graph embedding has been an active research topic for knowledge
base completion (KGC), with progressive improvement from the initial TransE,
TransH, RotatE et al to the current state-of-the-art QuatE. However, QuatE
ignores the multi-faceted nature of the entity and the complexity of the
relation, only using rigorous operation on quaternion space to capture the
interaction between entitiy pair and relation, leaving opportunities for better
knowledge representation which will finally help KGC. In this paper, we propose
a novel model, QuatDE, with a dynamic mapping strategy to explicitly capture
the variety of relational patterns and separate different semantic information
of the entity, using transition vectors to adjust the point position of the
entity embedding vectors in the quaternion space via Hamilton product,
enhancing the feature interaction capability between elements of the triplet.
Experiment results show QuatDE achieves state-of-the-art performance on three
well-established knowledge graph completion benchmarks. In particular, the MR
evaluation has relatively increased by 26% on WN18 and 15% on WN18RR, which
proves the generalization of QuatDE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset. (arXiv:2104.08459v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mussakhojayeva_S/0/1/0/all/0/1">Saida Mussakhojayeva</a>, <a href="http://arxiv.org/find/eess/1/au:+Janaliyeva_A/0/1/0/all/0/1">Aigerim Janaliyeva</a>, <a href="http://arxiv.org/find/eess/1/au:+Mirzakhmetov_A/0/1/0/all/0/1">Almas Mirzakhmetov</a>, <a href="http://arxiv.org/find/eess/1/au:+Khassanov_Y/0/1/0/all/0/1">Yerbolat Khassanov</a>, <a href="http://arxiv.org/find/eess/1/au:+Varol_H/0/1/0/all/0/1">Huseyin Atakan Varol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08459">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a high-quality open-source speech synthesis dataset for
Kazakh, a low-resource language spoken by over 13 million people worldwide. The
dataset consists of about 93 hours of transcribed audio recordings spoken by
two professional speakers (female and male). It is the first publicly available
large-scale dataset developed to promote Kazakh text-to-speech (TTS)
applications in both academia and industry. In this paper, we share our
experience by describing the dataset development procedures and faced
challenges, and discuss important future directions. To demonstrate the
reliability of our dataset, we built baseline end-to-end TTS models and
evaluated them using the subjective mean opinion score (MOS) measure.
Evaluation results show that the best TTS models trained on our dataset achieve
MOS above 4 for both speakers, which makes them applicable for practical use.
The dataset, training recipe, and pretrained TTS models are freely available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information Divergence Measure Between Neural Text and Human Text. (arXiv:2102.01454v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1">Krishna Pillutla</a>, <a href="http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1">Swabha Swayamdipta</a>, <a href="http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1">Rowan Zellers</a>, <a href="http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1">John Thickstun</a>, <a href="http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1">Sean Welleck</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Harchaoui_Z/0/1/0/all/0/1">Zaid Harchaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01454">
                                    <div class="article-summary-box-inner">
                                        <span>As major progress is made in open-ended text generation, measuring how close
machine-generated text is to human language remains a critical open problem. We
propose Mauve, a comparison measure for open-ended text generation, which
directly compares a generation model&#x27;s distribution to that of human-written
text. Mauve measures the mean area under a divergence curve for the two
distributions, exploring the trade-off between two types of errors: those
arising from parts of the human distribution that the model distribution
approximates well, and those it does not. Mauve extends a family of information
divergence metrics, introducing a tractable approximation based on computing
the KL divergence in a quantized embedding space. This yields an efficient
implementation that scales up to modern text generation models. Through an
extensive empirical study on three open-ended generation tasks, we find that
Mauve identifies known properties of generated text, scales naturally with
model size, and correlates with human judgments, with fewer restrictions than
existing distributional evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1">Damir Koren&#x10d;i&#x107;</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1">Strahil Ristov</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1">Jelena Repar</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06274">
                                    <div class="article-summary-box-inner">
                                        <span>Topic models are widely used unsupervised models of text capable of learning
topics - weighted lists of words and documents - from large collections of text
documents. When topic models are used for discovery of topics in text
collections, a question that arises naturally is how well the model-induced
topics correspond to topics of interest to the analyst. In this paper we
revisit and extend a so far neglected approach to topic model evaluation based
on measuring topic coverage - computationally matching model topics with a set
of reference topics that models are expected to uncover. The approach is well
suited for analyzing models&#x27; performance in topic discovery and for large-scale
analysis of both topic models and measures of model quality. We propose new
measures of coverage and evaluate, in a series of experiments, different types
of topic models on two distinct text domains for which interest for topic
discovery exists. The experiments include evaluation of model quality, analysis
of coverage of distinct topic categories, and the analysis of the relationship
between coverage and other methods of topic model evaluation. The contributions
of the paper include new measures of coverage, insights into both topic models
and other methods of model evaluation, and the datasets and code for
facilitating future research of both topic coverage and other approaches to
topic model evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech. (arXiv:2104.08529v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1">Elma Kerz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08529">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, automated approaches to assessing linguistic complexity in
second language (L2) writing have made significant progress in gauging learner
performance, predicting human ratings of the quality of learner productions,
and benchmarking L2 development. In contrast, there is comparatively little
work in the area of speaking, particularly with respect to fully automated
approaches to assessing L2 spontaneous speech. While the importance of a
well-performing ASR system is widely recognized, little research has been
conducted to investigate the impact of its performance on subsequent automatic
text analysis. In this paper, we focus on this issue and examine the impact of
using a state-of-the-art ASR system for subsequent automatic analysis of
linguistic complexity in spontaneously produced L2 speech. A set of 30 selected
measures were considered, falling into four categories: syntactic, lexical,
n-gram frequency, and information-theoretic measures. The agreement between the
scores for these measures obtained on the basis of ASR-generated vs. manual
transcriptions was determined through correlation analysis. A more differential
effect of ASR performance on specific types of complexity measures when
controlling for task type effects is also presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining Language Models with Compositional Explanations. (arXiv:2103.10415v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Huihan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Ying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qinyuan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xisen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10415">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models have been successful on text classification
tasks, but are prone to learning spurious correlations from biased datasets,
and are thus vulnerable when making inferences in a new domain. Prior works
reveal such spurious patterns via post-hoc explanation algorithms which compute
the importance of input features. Further, the model is regularized to align
the importance scores with human knowledge, so that the unintended model
behaviors are eliminated. However, such a regularization technique lacks
flexibility and coverage, since only importance scores towards a pre-defined
list of features are adjusted, while more complex human knowledge such as
feature interaction and pattern generalization can hardly be incorporated. In
this work, we propose to refine a learned language model for a target domain by
collecting human-provided compositional explanations regarding observed biases.
By parsing these explanations into executable logic rules, the human-specified
refinement advice from a small set of explanations can be generalized to more
training examples. We additionally introduce a regularization term allowing
adjustments for both importance and interaction of features to better rectify
model behavior. We demonstrate the effectiveness of the proposed approach on
two text classification tasks by showing improved performance in target domain
as well as improved model fairness after refinement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Earnings-21: A Practical Benchmark for ASR in the Wild. (arXiv:2104.11348v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rio_M/0/1/0/all/0/1">Miguel Del Rio</a>, <a href="http://arxiv.org/find/cs/1/au:+Delworth_N/0/1/0/all/0/1">Natalie Delworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Westerman_R/0/1/0/all/0/1">Ryan Westerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Michelle Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1">Nishchal Bhandari</a>, <a href="http://arxiv.org/find/cs/1/au:+Palakapilly_J/0/1/0/all/0/1">Joseph Palakapilly</a>, <a href="http://arxiv.org/find/cs/1/au:+McNamara_Q/0/1/0/all/0/1">Quinten McNamara</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Joshua Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr Zelasko</a>, <a href="http://arxiv.org/find/cs/1/au:+Jette_M/0/1/0/all/0/1">Miguel Jette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11348">
                                    <div class="article-summary-box-inner">
                                        <span>Commonly used speech corpora inadequately challenge academic and commercial
ASR systems. In particular, speech corpora lack metadata needed for detailed
analysis and WER measurement. In response, we present Earnings-21, a 39-hour
corpus of earnings calls containing entity-dense speech from nine different
financial sectors. This corpus is intended to benchmark ASR systems in the wild
with special attention towards named entity recognition. We benchmark four
commercial ASR models, two internal models built with open-source tools, and an
open-source LibriSpeech model and discuss their differences in performance on
Earnings-21. Using our recently released fstalign tool, we provide a candid
analysis of each model&#x27;s recognition capabilities under different partitions.
Our analysis finds that ASR accuracy for certain NER categories is poor,
presenting a significant impediment to transcript comprehension and usage.
Earnings-21 bridges academic and commercial ASR system evaluation and enables
further research on entity modeling and WER on real world audio.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Variational Attention Models for Language Generation. (arXiv:2004.09764v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09764">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders have been widely applied for natural language
generation, however, there are two long-standing problems: information
under-representation and posterior collapse. The former arises from the fact
that only the last hidden state from the encoder is transformed to the latent
space, which is insufficient to summarize data. The latter comes as a result of
the imbalanced scale between the reconstruction loss and the KL divergence in
the objective function. To tackle these issues, in this paper we propose the
discrete variational attention model with categorical distribution over the
attention mechanism owing to the discrete nature in languages. Our approach is
combined with an auto-regressive prior to capture the sequential dependency
from observations, which can enhance the latent space for language generation.
Moreover, thanks to the property of discreteness, the training of our proposed
approach does not suffer from posterior collapse. Furthermore, we carefully
analyze the superiority of discrete latent space over the continuous space with
the common Gaussian distribution. Extensive experiments on language generation
demonstrate superior advantages of our proposed approach in comparison with the
state-of-the-art counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subword Sampling for Low Resource Word Alignment. (arXiv:2012.11657v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asgari_E/0/1/0/all/0/1">Ehsaneddin Asgari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabet_M/0/1/0/all/0/1">Masoud Jalili Sabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Dufter_P/0/1/0/all/0/1">Philipp Dufter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ringlstetter_C/0/1/0/all/0/1">Christopher Ringlstetter</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11657">
                                    <div class="article-summary-box-inner">
                                        <span>Annotation projection is an important area in NLP that can greatly contribute
to creating language resources for low-resource languages. Word alignment plays
a key role in this setting. However, most of the existing word alignment
methods are designed for a high resource setting in machine translation where
millions of parallel sentences are available. This amount reduces to a few
thousands of sentences when dealing with low-resource languages failing the
existing established IBM models. In this paper, we propose subword
sampling-based alignment of text units. This method&#x27;s hypothesis is that the
aggregation of different granularities of text for certain language pairs can
help word-level alignment. For certain languages for which gold-standard
alignments exist, we propose an iterative Bayesian optimization framework to
optimize selecting possible subwords from the space of possible subword
representations of the source and target sentences. We show that the subword
sampling method consistently outperforms word-level alignment on six language
pairs: English-German, English-French, English-Romanian, English-Persian,
English-Hindi, and English-Inuktitut. In addition, we show that the
hyperparameters learned for certain language pairs can be applied to other
languages at no supervision and consistently improve the alignment results. We
observe that using $5K$ parallel sentences together with our proposed subword
sampling approach, we obtain similar F1 scores to the use of $100K$&#x27;s of
parallel sentences in existing word-level fast-align/eflomal alignment methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Phoneme-BERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript. (arXiv:2102.00804v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sundararaman_M/0/1/0/all/0/1">Mukuntha Narayanan Sundararaman</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Ayush Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Vepa_J/0/1/0/all/0/1">Jithendra Vepa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00804">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed significant improvement in ASR systems to
recognize spoken utterances. However, it is still a challenging task for noisy
and out-of-domain data, where substitution and deletion errors are prevalent in
the transcribed text. These errors significantly degrade the performance of
downstream tasks. In this work, we propose a BERT-style language model,
referred to as PhonemeBERT, that learns a joint language model with phoneme
sequence and ASR transcript to learn phonetic-aware representations that are
robust to ASR errors. We show that PhonemeBERT can be used on downstream tasks
using phoneme sequences as additional features, and also in low-resource setup
where we only have ASR-transcripts for the downstream tasks with no phoneme
information available. We evaluate our approach extensively by generating noisy
data for three benchmark datasets - Stanford Sentiment Treebank, TREC and ATIS
for sentiment, question and intent classification tasks respectively. The
results of the proposed approach beats the state-of-the-art baselines
comprehensively on each dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf Language Models. (arXiv:2010.08566v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1">Peter West</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Ximing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1">Ari Holtzman</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1">Chandra Bhagavatula</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jena Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08566">
                                    <div class="article-summary-box-inner">
                                        <span>Publicly available, large pretrained LanguageModels (LMs) generate text with
remarkable quality, but only sequentially from left to right. As a result, they
are not immediately applicable to generation tasks that break the
unidirectional assumption, such as paraphrasing or text-infilling,
necessitating task-specific supervision.

In this paper, we present Reflective Decoding, a novel unsupervised algorithm
that allows for direct application of unidirectional LMs to non-sequential
tasks. Our 2-step approach requires no supervision or even parallel corpora,
only two off-the-shelf pretrained LMs in opposite directions: forward and
backward. First, in the contextualization step, we use LMs to generate
ensembles of past and future contexts which collectively capture the input
(e.g. the source sentence for paraphrasing). Second, in the reflection step, we
condition on these &quot;context ensembles&quot;, generating outputs that are compatible
with them. Comprehensive empirical results demonstrate that Reflective Decoding
outperforms strong unsupervised baselines on both paraphrasing and abductive
text infilling, significantly narrowing the gap between unsupervised and
supervised methods. Reflective Decoding surpasses multiple supervised baselines
on various metrics including human evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions. (arXiv:2012.04293v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ates_T/0/1/0/all/0/1">Tayfun Ates</a>, <a href="http://arxiv.org/find/cs/1/au:+Atesoglu_M/0/1/0/all/0/1">Muhammed Samil Atesoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yigit_C/0/1/0/all/0/1">Cagatay Yigit</a>, <a href="http://arxiv.org/find/cs/1/au:+Kesen_I/0/1/0/all/0/1">Ilker Kesen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobas_M/0/1/0/all/0/1">Mert Kobas</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdem_E/0/1/0/all/0/1">Erkut Erdem</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdem_A/0/1/0/all/0/1">Aykut Erdem</a>, <a href="http://arxiv.org/find/cs/1/au:+Goksun_T/0/1/0/all/0/1">Tilbe Goksun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuret_D/0/1/0/all/0/1">Deniz Yuret</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04293">
                                    <div class="article-summary-box-inner">
                                        <span>Humans are able to perceive, understand and reason about physical events.
Developing models with similar physical understanding capabilities is a
long-standing goal of artificial intelligence. As a step towards this goal, in
this work, we introduce CRAFT, a new visual question answering dataset that
requires causal reasoning about physical forces and object interactions. It
contains 58K video and question pairs that are generated from 10K videos from
20 different virtual environments, containing various objects in motion that
interact with each other and the scene. Two question categories from CRAFT
include previously studied descriptive and counterfactual questions. Besides,
inspired by the theories of force dynamics in cognitive linguistics, we
introduce new question categories that involve understanding the interactions
of objects through the notions of cause, enable, and prevent. Our results
demonstrate that even though these tasks seem to be simple and intuitive for
humans, the evaluated baseline models, including existing state-of-the-art
methods, do not yet deal with the challenges posed in our benchmark dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Automated Website Classification by Deep Learning. (arXiv:1910.09991v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fausti_F/0/1/0/all/0/1">Fabrizio De Fausti</a>, <a href="http://arxiv.org/find/cs/1/au:+Pugliese_F/0/1/0/all/0/1">Francesco Pugliese</a>, <a href="http://arxiv.org/find/cs/1/au:+Zardetto_D/0/1/0/all/0/1">Diego Zardetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.09991">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the interest in Big Data sources has been steadily growing
within the Official Statistic community. The Italian National Institute of
Statistics (Istat) is currently carrying out several Big Data pilot studies.
One of these studies, the ICT Big Data pilot, aims at exploiting massive
amounts of textual data automatically scraped from the websites of Italian
enterprises in order to predict a set of target variables (e.g. e-commerce)
that are routinely observed by the traditional ICT Survey. In this paper, we
show that Deep Learning techniques can successfully address this problem.
Essentially, we tackle a text classification task: an algorithm must learn to
infer whether an Italian enterprise performs e-commerce from the textual
content of its website. To reach this goal, we developed a sophisticated
processing pipeline and evaluated its performance through extensive
experiments. Our pipeline uses Convolutional Neural Networks and relies on Word
Embeddings to encode raw texts into grayscale images (i.e. normalized numeric
matrices). Web-scraped texts are huge and have very low signal to noise ratio:
to overcome these issues, we adopted a framework known as False Positive
Reduction, which has seldom (if ever) been applied before to text
classification tasks. Several original contributions enable our processing
pipeline to reach good classification results. Empirical evidence shows that
our proposal outperforms all the alternative Machine Learning solutions already
tested in Istat for the same task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1">Steven C.H. Hoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08914">
                                    <div class="article-summary-box-inner">
                                        <span>Video-grounded dialogue systems aim to integrate video understanding and
dialogue understanding to generate responses that are relevant to both the
dialogue and video context. Most existing approaches employ deep learning
models and have achieved remarkable performance, given the relatively small
datasets available. However, the results are partly accomplished by exploiting
biases in the datasets rather than developing multimodal reasoning, resulting
in limited generalization. In this paper, we propose a novel approach of
Compositional Counterfactual Contrastive Learning ($C^3$) to develop
contrastive training between factual and counterfactual samples in
video-grounded dialogues. Specifically, we design factual/counterfactual
sampling based on the temporal steps in videos and tokens in dialogues and
propose contrastive loss functions that exploit object-level or action-level
variance. Different from prior approaches, we focus on contrastive hidden state
representations among compositional output tokens to optimize the
representation space in a generation setting. We achieved promising performance
gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the
benefits of our approach in grounding video and dialogue context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Training of Acoustic Encoders for Speech Recognition. (arXiv:2106.08960v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagaraja_V/0/1/0/all/0/1">Varun Nagaraja</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yangyang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_G/0/1/0/all/0/1">Ganesh Venkatesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1">Ozlem Kalinli</a>, <a href="http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1">Michael L. Seltzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1">Vikas Chandra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08960">
                                    <div class="article-summary-box-inner">
                                        <span>On-device speech recognition requires training models of different sizes for
deploying on devices with various computational budgets. When building such
different models, we can benefit from training them jointly to take advantage
of the knowledge shared between them. Joint training is also efficient since it
reduces the redundancy in the training procedure&#x27;s data handling operations. We
propose a method for collaboratively training acoustic encoders of different
sizes for speech recognition. We use a sequence transducer setup where
different acoustic encoders share a common predictor and joiner modules. The
acoustic encoders are also trained using co-distillation through an auxiliary
task for frame level chenone prediction, along with the transducer loss. We
perform experiments using the LibriSpeech corpus and demonstrate that the
collaboratively trained acoustic encoders can provide up to a 11% relative
improvement in the word error rate on both the test partitions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RefBERT: Compressing BERT by Referencing to Pre-computed Representations. (arXiv:2106.08898v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haiqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1">Yang Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jianping Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08898">
                                    <div class="article-summary-box-inner">
                                        <span>Recently developed large pre-trained language models, e.g., BERT, have
achieved remarkable performance in many downstream natural language processing
applications. These pre-trained language models often contain hundreds of
millions of parameters and suffer from high computation and latency in
real-world applications. It is desirable to reduce the computation overhead of
the models for fast training and inference while keeping the model performance
in downstream applications. Several lines of work utilize knowledge
distillation to compress the teacher model to a smaller student model. However,
they usually discard the teacher&#x27;s knowledge when in inference. Differently, in
this paper, we propose RefBERT to leverage the knowledge learned from the
teacher, i.e., facilitating the pre-computed BERT representation on the
reference sample and compressing BERT into a smaller student model. To
guarantee our proposal, we provide theoretical justification on the loss
function and the usage of reference samples. Significantly, the theoretical
result shows that including the pre-computed teacher&#x27;s representations on the
reference samples indeed increases the mutual information in learning the
student model. Finally, we conduct the empirical evaluation and show that our
RefBERT can beat the vanilla TinyBERT over 8.1\% and achieves more than 94\% of
the performance of $\BERTBASE$ on the GLUE benchmark. Meanwhile, RefBERT is
7.4x smaller and 9.5x faster on inference than BERT$_{\rm BASE}$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Spoken Language Understanding for Generalized Voice Assistants. (arXiv:2106.09009v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1">Michael Saxon</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1">Samridhi Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+McKenna_J/0/1/0/all/0/1">Joseph P. McKenna</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1">Athanasios Mouchtaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09009">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end (E2E) spoken language understanding (SLU) systems predict
utterance semantics directly from speech using a single model. Previous work in
this area has focused on targeted tasks in fixed domains, where the output
semantic structure is assumed a priori and the input speech is of limited
complexity. In this work we present our approach to developing an E2E model for
generalized SLU in commercial voice assistants (VAs). We propose a fully
differentiable, transformer-based, hierarchical system that can be pretrained
at both the ASR and NLU levels. This is then fine-tuned on both transcription
and semantic classification losses to handle a diverse set of intent and
argument combinations. This leads to an SLU system that achieves significant
improvements over baselines on a complex internal generalized VA dataset with a
43% improvement in accuracy, while still meeting the 99% accuracy benchmark on
the popular Fluent Speech Commands dataset. We further evaluate our model on a
hard test set, exclusively containing slot arguments unseen in training, and
demonstrate a nearly 20% improvement, showing the efficacy of our approach in
truly demanding VA scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data. (arXiv:2106.08977v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haoming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Danqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tianyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1">Bing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08977">
                                    <div class="article-summary-box-inner">
                                        <span>Weak supervision has shown promising results in many natural language
processing tasks, such as Named Entity Recognition (NER). Existing work mainly
focuses on learning deep NER models only with weak supervision, i.e., without
any human annotation, and shows that by merely using weakly labeled data, one
can achieve good performance, though still underperforms fully supervised NER
with manually/strongly labeled data. In this paper, we consider a more
practical scenario, where we have both a small amount of strongly labeled data
and a large amount of weakly labeled data. Unfortunately, we observe that
weakly labeled data does not necessarily improve, or even deteriorate the model
performance (due to the extensive noise in the weak labels) when we train deep
NER models over a simple or weighted combination of the strongly labeled and
weakly labeled data. To address this issue, we propose a new multi-stage
computational framework -- NEEDLE with three essential ingredients: (1) weak
label completion, (2) noise-aware loss function, and (3) final fine-tuning over
the strongly labeled data. Through experiments on E-commerce query NER and
Biomedical NER, we demonstrate that NEEDLE can effectively suppress the noise
of the weak labels and outperforms existing methods. In particular, we achieve
new SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,
BC5CDR-disease 90.69, NCBI-disease 92.28.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Discourse to Narrative: Knowledge Projection for Event Relation Extraction. (arXiv:2106.08629v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jialong Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Meng Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yaojie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weijian Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08629">
                                    <div class="article-summary-box-inner">
                                        <span>Current event-centric knowledge graphs highly rely on explicit connectives to
mine relations between events. Unfortunately, due to the sparsity of
connectives, these methods severely undermine the coverage of EventKGs. The
lack of high-quality labelled corpora further exacerbates that problem. In this
paper, we propose a knowledge projection paradigm for event relation
extraction: projecting discourse knowledge to narratives by exploiting the
commonalities between them. Specifically, we propose Multi-tier Knowledge
Projection Network (MKPNet), which can leverage multi-tier discourse knowledge
effectively for event relation extraction. In this way, the labelled data
requirement is significantly reduced, and implicit event relations can be
effectively extracted. Intrinsic experimental results show that MKPNet achieves
the new state-of-the-art performance, and extrinsic experimental results verify
the value of the extracted event relations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding Spatio-Temporal Language with Transformers. (arXiv:2106.08858v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karch_T/0/1/0/all/0/1">Tristan Karch</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1">Laetitia Teodorescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1">Cl&#xe9;ment Moulin-Frier</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08858">
                                    <div class="article-summary-box-inner">
                                        <span>Language is an interface to the outside world. In order for embodied agents
to use it, language must be grounded in other, sensorimotor modalities. While
there is an extended literature studying how machines can learn grounded
language, the topic of how to learn spatio-temporal linguistic concepts is
still largely uncharted. To make progress in this direction, we here introduce
a novel spatio-temporal language grounding task where the goal is to learn the
meaning of spatio-temporal descriptions of behavioral traces of an embodied
agent. This is achieved by training a truth function that predicts if a
description matches a given history of observations. The descriptions involve
time-extended predicates in past and present tense as well as spatio-temporal
references to objects in the scene. To study the role of architectural biases
in this task, we train several models including multimodal Transformer
architectures; the latter implement different attention computations between
words and objects across space and time. We test models on two classes of
generalization: 1) generalization to randomly held-out sentences; 2)
generalization to grammar primitives. We observe that maintaining object
identity in the attention computation of our Transformers is instrumental to
achieving good performance on generalization overall, and that summarizing
object traces in a single token has little influence on performance. We then
discuss how this opens new perspectives for language-guided autonomous embodied
agents. We also release our code under open-source license as well as
pretrained models and datasets to encourage the wider community to build upon
and extend our work in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Disease Detection from Spontaneous Speech through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models. (arXiv:2106.08689v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xuefeng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiechmann_D/0/1/0/all/0/1">Daniel Wiechmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1">Elma Kerz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08689">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we combined linguistic complexity and (dis)fluency features
with pretrained language models for the task of Alzheimer&#x27;s disease detection
of the 2021 ADReSSo (Alzheimer&#x27;s Dementia Recognition through Spontaneous
Speech) challenge. An accuracy of 83.1% was achieved on the test set, which
amounts to an improvement of 4.23% over the baseline model. Our best-performing
model that integrated component models using a stacking ensemble technique
performed equally well on cross-validation and test data, indicating that it is
robust against overfitting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking. (arXiv:2106.08723v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Ting Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chongxuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08723">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue State Tracking (DST), which is the process of inferring user goals
by estimating belief states given the dialogue history, plays a critical role
in task-oriented dialogue systems. A coreference phenomenon observed in
multi-turn conversations is not addressed by existing DST models, leading to
sub-optimal performances. In this paper, we propose Coreference Dialogue State
Tracker (CDST) that explicitly models the coreference feature. In particular,
at each turn, the proposed model jointly predicts the coreferred domain-slot
pair and extracts the coreference values from the dialogue context.
Experimental results on MultiWOZ 2.1 dataset show that the proposed model
achieves the state-of-the-art joint goal accuracy of 56.47%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-Based Keyword Localisation in Speech using Visual Grounding. (arXiv:2106.08859v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Olaleye_K/0/1/0/all/0/1">Kayode Olaleye</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1">Herman Kamper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08859">
                                    <div class="article-summary-box-inner">
                                        <span>Visually grounded speech models learn from images paired with spoken
captions. By tagging images with soft text labels using a trained visual
classifier with a fixed vocabulary, previous work has shown that it is possible
to train a model that can detect whether a particular text keyword occurs in
speech utterances or not. Here we investigate whether visually grounded speech
models can also do keyword localisation: predicting where, within an utterance,
a given textual keyword occurs without any explicit text-based or alignment
supervision. We specifically consider whether incorporating attention into a
convolutional model is beneficial for localisation. Although absolute
localisation performance with visually supervised models is still modest
(compared to using unordered bag-of-word text labels for supervision), we show
that attention provides a large gain in performance over previous visually
grounded models. As in many other speech-image studies, we find that many of
the incorrect localisations are due to semantic confusions, e.g. locating the
word &#x27;backstroke&#x27; for the query keyword &#x27;swimming&#x27;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation. (arXiv:2106.08942v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kiegeland_S/0/1/0/all/0/1">Samuel Kiegeland</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1">Julia Kreutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08942">
                                    <div class="article-summary-box-inner">
                                        <span>Policy gradient algorithms have found wide adoption in NLP, but have recently
become subject to criticism, doubting their suitability for NMT. Choshen et al.
(2020) identify multiple weaknesses and suspect that their success is
determined by the shape of output distributions rather than the reward. In this
paper, we revisit these claims and study them under a wider range of
configurations. Our experiments on in-domain and cross-domain adaptation reveal
the importance of exploration and reward scaling, and provide empirical
counter-evidence to these claims.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the expressiveness of neural vocoding with non-affine Normalizing Flows. (arXiv:2106.08649v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gabrys_A/0/1/0/all/0/1">Adam Gabry&#x15b;</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiao_Y/0/1/0/all/0/1">Yunlong Jiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Klimkov_V/0/1/0/all/0/1">Viacheslav Klimkov</a>, <a href="http://arxiv.org/find/eess/1/au:+Korzekwa_D/0/1/0/all/0/1">Daniel Korzekwa</a>, <a href="http://arxiv.org/find/eess/1/au:+Barra_Chicote_R/0/1/0/all/0/1">Roberto Barra-Chicote</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08649">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a general enhancement to the Normalizing Flows (NF) used
in neural vocoding. As a case study, we improve expressive speech vocoding with
a revamped Parallel Wavenet (PW). Specifically, we propose to extend the affine
transformation of PW to the more expressive invertible non-affine function. The
greater expressiveness of the improved PW leads to better-perceived signal
quality and naturalness in the waveform reconstruction and text-to-speech (TTS)
tasks. We evaluate the model across different speaking styles on a
multi-speaker, multi-lingual dataset. In the waveform reconstruction task, the
proposed model closes the naturalness and signal quality gap from the original
PW to recordings by $10\%$, and from other state-of-the-art neural vocoding
systems by more than $60\%$. We also demonstrate improvements in objective
metrics on the evaluation test set with L2 Spectral Distance and Cross-Entropy
reduced by $3\%$ and $6\unicode{x2030}$ comparing to the affine PW.
Furthermore, we extend the probability density distillation procedure proposed
by the original PW paper, so that it works with any non-affine invertible and
differentiable function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algorithm to Compilation Codesign: An Integrated View of Neural Network Sparsity. (arXiv:2106.08846v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1">Fu-Ming Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Austin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08846">
                                    <div class="article-summary-box-inner">
                                        <span>Reducing computation cost, inference latency, and memory footprint of neural
networks are frequently cited as research motivations for pruning and sparsity.
However, operationalizing those benefits and understanding the end-to-end
effect of algorithm design and regularization on the runtime execution is not
often examined in depth.

Here we apply structured and unstructured pruning to attention weights of
transformer blocks of the BERT language model, while also expanding block
sparse representation (BSR) operations in the TVM compiler. Integration of BSR
operations enables the TVM runtime execution to leverage structured pattern
sparsity induced by model regularization.

This integrated view of pruning algorithms enables us to study relationships
between modeling decisions and their direct impact on sparsity-enhanced
execution. Our main findings are: 1) we validate that performance benefits of
structured sparsity block regularization must be enabled by the BSR
augmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x
speedup relative to standard TVM compilation (without expanded BSR support). 2)
for BERT attention weights, the end-to-end optimal block sparsity shape in this
CPU inference context is not a square block (as in \cite{gray2017gpu}) but
rather a linear 32x1 block 3) the relationship between performance and block
size / shape is is suggestive of how model regularization parameters interact
with task scheduler optimizations resulting in the observed end-to-end
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic sentence similarity: size does not always matter. (arXiv:2106.08648v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Merkx_D/0/1/0/all/0/1">Danny Merkx</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_S/0/1/0/all/0/1">Stefan L. Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernestus_M/0/1/0/all/0/1">Mirjam Ernestus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08648">
                                    <div class="article-summary-box-inner">
                                        <span>This study addresses the question whether visually grounded speech
recognition (VGS) models learn to capture sentence semantics without access to
any prior linguistic knowledge. We produce synthetic and natural spoken
versions of a well known semantic textual similarity database and show that our
VGS model produces embeddings that correlate well with human semantic
similarity judgements. Our results show that a model trained on a small
image-caption database outperforms two models trained on much larger databases,
indicating that database size is not all that matters. We also investigate the
importance of having multiple captions per image and find that this is indeed
helpful even if the total number of images is lower, suggesting that
paraphrasing is a valuable learning signal. While the general trend in the
field is to create ever larger datasets to train models on, our findings
indicate other characteristics of the database can just as important important.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Gender Bias in Hindi-English Machine Translation. (arXiv:2106.08680v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1">Gauri Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1">Krithika Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sanjay Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08680">
                                    <div class="article-summary-box-inner">
                                        <span>With language models being deployed increasingly in the real world, it is
essential to address the issue of the fairness of their outputs. The word
embedding representations of these language models often implicitly draw
unwanted associations that form a social bias within the model. The nature of
gendered languages like Hindi, poses an additional problem to the
quantification and mitigation of bias, owing to the change in the form of the
words in the sentence, based on the gender of the subject. Additionally, there
is sparse work done in the realm of measuring and debiasing systems for Indic
languages. In our work, we attempt to evaluate and quantify the gender bias
within a Hindi-English machine translation system. We implement a modified
version of the existing TGBI metric based on the grammatical considerations for
Hindi. We also compare and contrast the resulting bias measurements across
multiple metrics for pre-trained embeddings and the ones learned by our machine
translation model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alternated Training with Synthetic and Authentic Data for Neural Machine Translation. (arXiv:2106.08582v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1">Rui Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zonghan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08582">
                                    <div class="article-summary-box-inner">
                                        <span>While synthetic bilingual corpora have demonstrated their effectiveness in
low-resource neural machine translation (NMT), adding more synthetic data often
deteriorates translation performance. In this work, we propose alternated
training with synthetic and authentic data for NMT. The basic idea is to
alternate synthetic and authentic corpora iteratively during training. Compared
with previous work, we introduce authentic data as guidance to prevent the
training of NMT models from being disturbed by noisy synthetic data.
Experiments on Chinese-English and German-English translation tasks show that
our approach improves the performance over several strong baselines. We
visualize the BLEU landscape to further investigate the role of authentic and
synthetic data during alternated training. From the visualization, we find that
authentic data helps to direct the NMT model parameters towards points with
higher BLEU scores and leads to consistent translation performance improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coreference-Aware Dialogue Summarization. (arXiv:2106.08556v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Ke Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08556">
                                    <div class="article-summary-box-inner">
                                        <span>Summarizing conversations via neural approaches has been gaining research
traction lately, yet it is still challenging to obtain practical solutions.
Examples of such challenges include unstructured information exchange in
dialogues, informal interactions between speakers, and dynamic role changes of
speakers as the dialogue evolves. Many of such challenges result in complex
coreference links. Therefore, in this work, we investigate different approaches
to explicitly incorporate coreference information in neural abstractive
dialogue summarization models to tackle the aforementioned challenges.
Experimental results show that the proposed approaches achieve state-of-the-art
performance, implying it is useful to utilize coreference information in
dialogue summarization. Evaluation results on factual correctness suggest such
coreference-aware models are better at tracing the information flow among
interlocutors and associating accurate status/actions with the corresponding
interlocutors and person mentions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System. (arXiv:2106.08801v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhiyuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08801">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) alignment aims at finding equivalent entities and
relations (i.e., mappings) between two KGs. The existing approaches utilize
either reasoning-based or semantic embedding-based techniques, but few studies
explore their combination. In this demonstration, we present PRASEMap, an
unsupervised KG alignment system that iteratively computes the Mappings with
both Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.
PRASEMap can support various embedding-based KG alignment approaches as the SE
module, and enables easy human computer interaction that additionally provides
an option for users to feed the mapping annotations back to the system for
better results. The demonstration showcases these features via a stand-alone
Web application with user friendly interfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Context Features Can Transformer Language Models Use?. (arXiv:2106.08367v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+OConnor_J/0/1/0/all/0/1">Joe O&#x27;Connor</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08367">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based language models benefit from conditioning on contexts of
hundreds to thousands of previous tokens. What aspects of these contexts
contribute to accurate model prediction? We describe a series of experiments
that measure usable information by selectively ablating lexical and structural
information in transformer language models trained on English Wikipedia. In
both mid- and long-range contexts, we find that several extremely destructive
context manipulations -- including shuffling word order within sentences and
deleting all words other than nouns -- remove less than 15% of the usable
information. Our results suggest that long contexts, but not their detailed
syntactic and propositional content, are important for the low perplexity of
current transformer language models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Enrichment of Persona-grounded Dialog with Background Stories. (arXiv:2106.08364v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Majumder_B/0/1/0/all/0/1">Bodhisattwa Prasad Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1">Taylor Berg-Kirkpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>, <a href="http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1">Harsh Jhamtani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08364">
                                    <div class="article-summary-box-inner">
                                        <span>Humans often refer to personal narratives, life experiences, and events to
make a conversation more engaging and rich. While persona-grounded dialog
models are able to generate responses that follow a given persona, they often
miss out on stating detailed experiences or events related to a persona, often
leaving conversations shallow and dull. In this work, we equip dialog models
with &#x27;background stories&#x27; related to a persona by leveraging fictional
narratives from existing story datasets (e.g. ROCStories). Since current dialog
datasets do not contain such narratives as responses, we perform an
unsupervised adaptation of a retrieved story for generating a dialog response
using a gradient-based rewriting technique. Our proposed method encourages the
generated response to be fluent (i.e., highly likely) with the dialog history,
minimally different from the retrieved story to preserve event ordering and
consistent with the original persona. We demonstrate that our method can
generate responses that are more diverse, and are rated more engaging and
human-like by human evaluators, compared to outputs from existing dialog
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Entity Linking through Semantic Reinforced Entity Embeddings. (arXiv:2106.08495v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_F/0/1/0/all/0/1">Feng Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruili Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08495">
                                    <div class="article-summary-box-inner">
                                        <span>Entity embeddings, which represent different aspects of each entity with a
single vector like word embeddings, are a key component of neural entity
linking models. Existing entity embeddings are learned from canonical Wikipedia
articles and local contexts surrounding target entities. Such entity embeddings
are effective, but too distinctive for linking models to learn contextual
commonality. We propose a simple yet effective method, FGS2EE, to inject
fine-grained semantic information into entity embeddings to reduce the
distinctiveness and facilitate the learning of contextual commonality. FGS2EE
first uses the embeddings of semantic type words to generate semantic
embeddings, and then combines them with existing entity embeddings through
linear aggregation. Extensive experiments show the effectiveness of such
embeddings. Based on our entity embeddings, we achieved new sate-of-the-art
performance on entity linking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2106.08571v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08571">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code to Comment Translation: A Comparative Study on Model Effectiveness &amp; Errors. (arXiv:2106.08415v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1">Junayed Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1">Fahim Faisal</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnob_R/0/1/0/all/0/1">Raihan Islam Arnob</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1">Antonios Anastasopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_K/0/1/0/all/0/1">Kevin Moran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08415">
                                    <div class="article-summary-box-inner">
                                        <span>Automated source code summarization is a popular software engineering
research topic wherein machine translation models are employed to &quot;translate&quot;
code snippets into relevant natural language descriptions. Most evaluations of
such models are conducted using automatic reference-based metrics. However,
given the relatively large semantic gap between programming languages and
natural language, we argue that this line of research would benefit from a
qualitative investigation into the various error modes of current
state-of-the-art models. Therefore, in this work, we perform both a
quantitative and qualitative comparison of three recently proposed source code
summarization models. In our quantitative evaluation, we compare the models
based on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,
and in our qualitative evaluation, we perform a manual open-coding of the most
common errors committed by the models when compared to ground truth captions.
Our investigation reveals new insights into the relationship between
metric-based performance and model prediction errors grounded in an empirically
derived error taxonomy that can be used to drive future research efforts</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Eider: Evidence-enhanced Document-level Relation Extraction. (arXiv:2106.08657v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yiqing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jiaming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sha Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08657">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level relation extraction (DocRE) aims at extracting the semantic
relations among entity pairs in a document. In DocRE, a subset of the sentences
in a document, called the evidence sentences, might be sufficient for
predicting the relation between a specific entity pair. To make better use of
the evidence sentences, in this paper, we propose a three-stage
evidence-enhanced DocRE framework consisting of joint relation and evidence
extraction, evidence-centered relation extraction (RE), and fusion of
extraction results. We first jointly train an RE model with a simple and
memory-efficient evidence extraction model. Then, we construct pseudo documents
based on the extracted evidence sentences and run the RE model again. Finally,
we fuse the extraction results of the first two stages using a blending layer
and make a final prediction. Extensive experiments show that our proposed
framework achieves state-of-the-art performance on the DocRED dataset,
outperforming the second-best method by 0.76/0.82 Ign F1/F1. In particular, our
method significantly improves the performance on inter-sentence relations by
1.23 Inter F1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Conversational Networks. (arXiv:2106.08484v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1">Alexandros Papangelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1">Karthik Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Padmakumar_A/0/1/0/all/0/1">Aishwarya Padmakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seokhwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tur_G/0/1/0/all/0/1">Gokhan Tur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1">Dilek Hakkani-Tur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08484">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by recent work in meta-learning and generative teaching networks, we
propose a framework called Generative Conversational Networks, in which
conversational agents learn to generate their own labelled training data (given
some seed data) and then train themselves from that data to perform a given
task. We use reinforcement learning to optimize the data generation process
where the reward signal is the agent&#x27;s performance on the task. The task can be
any language-related task, from intent detection to full task-oriented
conversations. In this work, we show that our approach is able to generalise
from seed data and performs well in limited data and limited computation
settings, with significant gains for intent detection and slot tagging across
multiple datasets: ATIS, TOD, SNIPS, and Restaurants8k. We show an average
improvement of 35% in intent detection and 21% in slot tagging over a baseline
model trained from the seed data. We also conduct an analysis of the novelty of
the generated data and provide generated examples for intent detection, slot
tagging, and non-goal oriented conversations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis. (arXiv:2106.08468v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zandie_R/0/1/0/all/0/1">Rohola Zandie</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoor_M/0/1/0/all/0/1">Mohammad H. Mahoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Madsen_J/0/1/0/all/0/1">Julia Madsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Emamian_E/0/1/0/all/0/1">Eshrat S. Emamian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08468">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces RyanSpeech, a new speech corpus for research on
automated text-to-speech (TTS) systems. Publicly available TTS corpora are
often noisy, recorded with multiple speakers, or lack quality male speech data.
In order to meet the need for a high quality, publicly available male speech
corpus within the field of speech recognition, we have designed and created
RyanSpeech which contains textual materials from real-world conversational
settings. These materials contain over 10 hours of a professional male voice
actor&#x27;s speech recorded at 44.1 kHz. This corpus&#x27;s design and pipeline make
RyanSpeech ideal for developing TTS systems in real-world applications. To
provide a baseline for future research, protocols, and benchmarks, we trained 4
state-of-the-art speech models and a vocoder on RyanSpeech. The results show
3.36 in mean opinion scores (MOS) in our best model. We have made both the
corpus and trained models for public use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out-of-Scope Intent Detection with Self-Supervision and Discriminative Training. (arXiv:2106.08616v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Li-Ming Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haowen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lu Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiao-Ming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1">Albert Y.S. Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08616">
                                    <div class="article-summary-box-inner">
                                        <span>Out-of-scope intent detection is of practical importance in task-oriented
dialogue systems. Since the distribution of outlier utterances is arbitrary and
unknown in the training stage, existing methods commonly rely on strong
assumptions on data distribution such as mixture of Gaussians to make
inference, resulting in either complex multi-step training procedures or
hand-crafted rules such as confidence threshold selection for outlier
detection. In this paper, we propose a simple yet effective method to train an
out-of-scope intent classifier in a fully end-to-end manner by simulating the
test scenario in training, which requires no assumption on data distribution
and no additional post-processing or threshold setting. Specifically, we
construct a set of pseudo outliers in the training stage, by generating
synthetic outliers using inliner features via self-supervision and sampling
out-of-scope sentences from easily available open-domain datasets. The pseudo
outliers are used to train a discriminative classifier that can be directly
applied to and generalize well on the test task. We evaluate our method
extensively on four benchmark dialogue datasets and observe significant
improvements over state-of-the-art approaches. Our code has been released at
https://github.com/liam0949/DCLOOS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study. (arXiv:2106.08686v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1">Badr M. Abdullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosbach_M/0/1/0/all/0/1">Marius Mosbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaitova_I/0/1/0/all/0/1">Iuliia Zaitova</a>, <a href="http://arxiv.org/find/cs/1/au:+Mobius_B/0/1/0/all/0/1">Bernd M&#xf6;bius</a>, <a href="http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1">Dietrich Klakow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08686">
                                    <div class="article-summary-box-inner">
                                        <span>Several variants of deep neural networks have been successfully employed for
building parametric models that project variable-duration spoken word segments
onto fixed-size vector representations, or acoustic word embeddings (AWEs).
However, it remains unclear to what degree we can rely on the distance in the
emerging AWE space as an estimate of word-form similarity. In this paper, we
ask: does the distance in the acoustic embedding space correlate with
phonological dissimilarity? To answer this question, we empirically investigate
the performance of supervised approaches for AWEs with different neural
architectures and learning objectives. We train AWE models in controlled
settings for two languages (German and Czech) and evaluate the embeddings on
two tasks: word discrimination and phonological similarity. Our experiments
show that (1) the distance in the embedding space in the best cases only
moderately correlates with phonological distance, and (2) improving the
performance on the word discrimination task does not necessarily yield models
that better reflect word phonological similarity. Our findings highlight the
necessity to rethink the current intrinsic evaluations for AWEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised GANs with Label Augmentation. (arXiv:2106.08601v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Liang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huawei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08601">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, transformation-based self-supervised learning has been applied to
generative adversarial networks (GANs) to mitigate the catastrophic forgetting
problem of discriminator by learning stable representations. However, the
separate self-supervised tasks in existing self-supervised GANs cause an
inconsistent goal with generative modeling due to the learning of the generator
from their generator distribution-agnostic classifiers. To address this issue,
we propose a novel self-supervised GANs framework with label augmentation,
i.e., augmenting the GAN labels (real or fake) with the self-supervised
pseudo-labels. In particular, the discriminator and the self-supervised
classifier are unified to learn a single task that predicts the augmented label
such that the discriminator/classifier is aware of the generator distribution,
while the generator tries to confuse the discriminator/classifier by optimizing
the discrepancy between the transformed real and generated distributions.
Theoretically, we prove that the generator, at the equilibrium point, converges
to replicate the data distribution. Empirically, we demonstrate that the
proposed method significantly outperforms competitive baselines on both
generative modeling and representation learning across benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaomeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1">Michael Potter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gaurav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yun-Chan Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1">V. Ratna Saripalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08756">
                                    <div class="article-summary-box-inner">
                                        <span>It is no secret amongst deep learning researchers that finding the right data
augmentation strategy during training can mean the difference between a
state-of-the-art result and a run-of-the-mill ranking. To that end, the
community has seen many efforts to automate the process of finding the perfect
augmentation procedure for any task at hand. Unfortunately, even recent
cutting-edge methods bring massive computational overhead, requiring as many as
100 full model trainings to settle on an ideal configuration. We show how to
achieve even better performance in just 7: with Random Unidimensional
Augmentation. Source code is available at https://github.com/fastestimator/RUA</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1">Sophia Bano</a>, <a href="http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1">Alessandro Casella</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1">Francisco Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1">Sara Moccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1">George Attilakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1">Ruwan Wimalasundera</a>, <a href="http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1">Dario Paladini</a>, <a href="http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1">Jan Deprest</a>, <a href="http://arxiv.org/find/cs/1/au:+Momi_E/0/1/0/all/0/1">Elena De Momi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1">Leonardo S. Mattos</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05923">
                                    <div class="article-summary-box-inner">
                                        <span>Fetoscopy laser photocoagulation is a widely used procedure for the treatment
of Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic
multiple pregnancies due to placental vascular anastomoses. This procedure is
particularly challenging due to limited field of view, poor manoeuvrability of
the fetoscope, poor visibility due to fluid turbidity, variability in light
source, and unusual position of the placenta. This may lead to increased
procedural time and incomplete ablation, resulting in persistent TTTS.
Computer-assisted intervention may help overcome these challenges by expanding
the fetoscopic field of view through video mosaicking and providing better
visualization of the vessel network. However, the research and development in
this domain remain limited due to unavailability of high-quality data to encode
the intra- and inter-procedure variability. Through the \textit{Fetoscopic
Placental Vessel Segmentation and Registration (FetReg)} challenge, we present
a large-scale multi-centre dataset for the development of generalized and
robust semantic segmentation and video mosaicking algorithms for the fetal
environment with a focus on creating drift-free mosaics from long duration
fetoscopy videos. In this paper, we provide an overview of the FetReg dataset,
challenge tasks, evaluation metrics and baseline methods for both segmentation
and registration. Baseline methods results on the FetReg dataset shows that our
dataset poses interesting challenges, offering large opportunity for the
creation of novel methods and models through a community effort initiative
guided by the FetReg challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Min-Fong Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao-Yun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yu-Syuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1">Hsien-Kai Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yi-Min Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hung-Jen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1">Kevin Jou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11014">
                                    <div class="article-summary-box-inner">
                                        <span>Network spaces have been known as a critical factor in both handcrafted
network designs or defining search spaces for Neural Architecture Search (NAS).
However, an effective space involves tremendous prior knowledge and/or manual
effort, and additional constraints are required to discover efficiency-aware
architectures. In this paper, we define a new problem, Network Space Search
(NSS), as searching for favorable network spaces instead of a single
architecture. We propose an NSS method to directly search for efficient-aware
network spaces automatically, reducing the manual effort and immense cost in
discovering satisfactory ones. The resultant network spaces, named Elite
Spaces, are discovered from Expanded Search Space with minimal human expertise
imposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front
under various complexity constraints and can be further served as NAS search
spaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an
averagely 2.3% lower error rate and 3.7% closer to target constraint than the
baseline with around 90% fewer samples required to find satisfactory networks).
Moreover, our NSS approach is capable of searching for superior spaces in
future unexplored spaces, revealing great potential in searching for network
spaces automatically. Website:
https://minhungchen.netlify.app/publication/nss/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SVMA: A GAN-based model for Monocular 3D Human Pose Estimation. (arXiv:2106.05616v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05616">
                                    <div class="article-summary-box-inner">
                                        <span>Recovering 3D human pose from 2D joints is a highly unconstrained problem,
especially without any video or multi-view information. We present an
unsupervised GAN-based model to recover 3D human pose from 2D joint locations
extracted from a single image. Our model uses a GAN to learn the mapping of
distribution from 2D poses to 3D poses, not the simple 2D-3D correspondence.
Considering the reprojection constraint, our model can estimate the camera so
that we can reproject the estimated 3D pose to the original 2D pose. Based on
this reprojection method, we can rotate and reproject the generated pose to get
our &quot;new&quot; 2D pose and then use a weight sharing generator to estimate the &quot;new&quot;
3D pose and a &quot;new&quot; camera. Through the above estimation process, we can define
the single-view-multi-angle consistency loss during training to simulate
multi-view consistency, which means the 3D poses and cameras estimated from two
angles of a single view should be able to be mixed to generate rich 2D
reprojections, and the 2D reprojections reprojected from the same 3D pose
should be consistent. The experimental results on Human3.6M show that our
method outperforms all the state-of-the-art methods, and results on
MPI-INF-3DHP show that our method outperforms state-of-the-art by approximately
15.0%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascading Modular Network (CAM-Net) for Multimodal Image Synthesis. (arXiv:2106.09015v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Moazeni_A/0/1/0/all/0/1">Alireza Moazeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09015">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models such as GANs have driven impressive advances in
conditional image synthesis in recent years. A persistent challenge has been to
generate diverse versions of output images from the same input image, due to
the problem of mode collapse: because only one ground truth output image is
given per input image, only one mode of the conditional distribution is
modelled. In this paper, we focus on this problem of multimodal conditional
image synthesis and build on the recently proposed technique of Implicit
Maximum Likelihood Estimation (IMLE). Prior IMLE-based methods required
different architectures for different tasks, which limit their applicability,
and were lacking in fine details in the generated images. We propose CAM-Net, a
unified architecture that can be applied to a broad range of tasks.
Additionally, it is capable of generating convincing high frequency details,
achieving a reduction of the Frechet Inception Distance (FID) by up to 45.3%
compared to the baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Affective XAI: Facial Affect Analysis for Understanding Explainable Human-AI Interactions. (arXiv:2106.08761v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guerdan_L/0/1/0/all/0/1">Luke Guerdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Raymond_A/0/1/0/all/0/1">Alex Raymond</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunes_H/0/1/0/all/0/1">Hatice Gunes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08761">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning approaches are increasingly used to augment human
decision-making, eXplainable Artificial Intelligence (XAI) research has
explored methods for communicating system behavior to humans. However, these
approaches often fail to account for the emotional responses of humans as they
interact with explanations. Facial affect analysis, which examines human facial
expressions of emotions, is one promising lens for understanding how users
engage with explanations. Therefore, in this work, we aim to (1) identify which
facial affect features are pronounced when people interact with XAI interfaces,
and (2) develop a multitask feature embedding for linking facial affect signals
with participants&#x27; use of explanations. Our analyses and results show that the
occurrence and values of facial AU1 and AU4, and Arousal are heightened when
participants fail to use explanations effectively. This suggests that facial
affect analysis should be incorporated into XAI to personalize explanations to
individuals&#x27; interaction styles and to adapt explanations based on the
difficulty of the task performed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1">Joni Korpihalkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1">Tuomo Sipola</a>, <a href="http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1">Samir Puuska</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1">Tero Kokkonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00517">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT&#x27;s MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of Morphed Face Images Using Discriminative Wavelet Sub-bands. (arXiv:2106.08565v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aghdaie_P/0/1/0/all/0/1">Poorya Aghdaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_B/0/1/0/all/0/1">Baaria Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08565">
                                    <div class="article-summary-box-inner">
                                        <span>This work investigates the well-known problem of morphing attacks, which has
drawn considerable attention in the biometrics community. Morphed images have
exposed face recognition systems&#x27; susceptibility to false acceptance, resulting
in dire consequences, especially for national security applications. To detect
morphing attacks, we propose a method which is based on a discriminative 2D
Discrete Wavelet Transform (2D-DWT). A discriminative wavelet sub-band can
highlight inconsistencies between a real and a morphed image. We observe that
there is a salient discrepancy between the entropy of a given sub-band in a
bona fide image, and the same sub-band&#x27;s entropy in a morphed sample.
Considering this dissimilarity between these two entropy values, we find the
Kullback-Leibler divergence between the two distributions, namely the entropy
of the bona fide and the corresponding morphed images. The most discriminative
wavelet sub-bands are those with the highest corresponding KL-divergence
values. Accordingly, 22 sub-bands are selected as the most discriminative ones
in terms of morph detection. We show that a Deep Neural Network (DNN) trained
on the 22 discriminative sub-bands can detect morphed samples precisely. Most
importantly, the effectiveness of our algorithm is validated through
experiments on three datasets: VISAPP17, LMA, and MorGAN. We also performed an
ablation study on the sub-band selection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness of Object Detectors in Degrading Weather Conditions. (arXiv:2106.08795v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirza_M/0/1/0/all/0/1">Muhammad Jehanzeb Mirza</a>, <a href="http://arxiv.org/find/cs/1/au:+Buerkle_C/0/1/0/all/0/1">Cornelius Buerkle</a>, <a href="http://arxiv.org/find/cs/1/au:+Jarquin_J/0/1/0/all/0/1">Julio Jarquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Opitz_M/0/1/0/all/0/1">Michael Opitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Oboril_F/0/1/0/all/0/1">Fabian Oboril</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholl_K/0/1/0/all/0/1">Kay-Ulrich Scholl</a>, <a href="http://arxiv.org/find/cs/1/au:+Bischof_H/0/1/0/all/0/1">Horst Bischof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08795">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art object detection systems for autonomous driving achieve
promising results in clear weather conditions. However, such autonomous safety
critical systems also need to work in degrading weather conditions, such as
rain, fog and snow. Unfortunately, most approaches evaluate only on the KITTI
dataset, which consists only of clear weather scenes. In this paper we address
this issue and perform one of the most detailed evaluation on single and dual
modality architectures on data captured in real weather conditions. We analyse
the performance degradation of these architectures in degrading weather
conditions. We demonstrate that an object detection architecture performing
good in clear weather might not be able to handle degrading weather conditions.
We also perform ablation studies on the dual modality architectures and show
their limitations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure First Detail Next: Image Inpainting with Pyramid Generator. (arXiv:2106.08905v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1">Shuyi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Protter_M/0/1/0/all/0/1">Matan Protter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimerman_G/0/1/0/all/0/1">Gadi Zimerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08905">
                                    <div class="article-summary-box-inner">
                                        <span>Recent deep generative models have achieved promising performance in image
inpainting. However, it is still very challenging for a neural network to
generate realistic image details and textures, due to its inherent spectral
bias. By our understanding of how artists work, we suggest to adopt a
&#x60;structure first detail next&#x27; workflow for image inpainting. To this end, we
propose to build a Pyramid Generator by stacking several sub-generators, where
lower-layer sub-generators focus on restoring image structures while the
higher-layer sub-generators emphasize image details. Given an input image, it
will be gradually restored by going through the entire pyramid in a bottom-up
fashion. Particularly, our approach has a learning scheme of progressively
increasing hole size, which allows it to restore large-hole images. In
addition, our method could fully exploit the benefits of learning with
high-resolution images, and hence is suitable for high-resolution image
inpainting. Extensive experimental results on benchmark datasets have validated
the effectiveness of our approach compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EdgeConv with Attention Module for Monocular Depth Estimation. (arXiv:2106.08615v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Minhyeok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sangwon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1">Chaewon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangyoun Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08615">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular depth estimation is an especially important task in robotics and
autonomous driving, where 3D structural information is essential. However,
extreme lighting conditions and complex surface objects make it difficult to
predict depth in a single image. Therefore, to generate accurate depth maps, it
is important for the model to learn structural information about the scene. We
propose a novel Patch-Wise EdgeConv Module (PEM) and EdgeConv Attention Module
(EAM) to solve the difficulty of monocular depth estimation. The proposed
modules extract structural information by learning the relationship between
image patches close to each other in space using edge convolution. Our method
is evaluated on two popular datasets, the NYU Depth V2 and the KITTI Eigen
split, achieving state-of-the-art performance. We prove that the proposed model
predicts depth robustly in challenging scenes through various comparative
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation. (arXiv:2106.09017v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09017">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-task learning (MTL) aims to improve the generalization of several
related tasks by learning them jointly. As a comparison, in addition to the
joint training scheme, modern meta-learning allows unseen tasks with limited
labels during the test phase, in the hope of fast adaptation over them. Despite
the subtle difference between MTL and meta-learning in the problem formulation,
both learning paradigms share the same insight that the shared structure
between existing training tasks could lead to better generalization and
adaptation. In this paper, we take one important step further to understand the
close connection between these two learning paradigms, through both theoretical
analysis and empirical investigation. Theoretically, we first demonstrate that
MTL shares the same optimization formulation with a class of gradient-based
meta-learning (GBML) algorithms. We then prove that for over-parameterized
neural networks with sufficient depth, the learned predictive functions of MTL
and GBML are close. In particular, this result implies that the predictions
given by these two models are similar over the same unseen task. Empirically,
we corroborate our theoretical findings by showing that, with proper
implementation, MTL is competitive against state-of-the-art GBML algorithms on
a set of few-shot image classification benchmarks. Since existing GBML
algorithms often involve costly second-order bi-level optimization, our
first-order MTL method is an order of magnitude faster on large-scale datasets
such as mini-ImageNet. We believe this work could help bridge the gap between
these two learning paradigms, and provide a computationally efficient
alternative to GBML that also supports fast task adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint detection and matching of feature points in multimodal images. (arXiv:1810.12941v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baruch_E/0/1/0/all/0/1">Elad Ben Baruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1">Yosi Keller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1810.12941">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a novel Convolutional Neural Network (CNN)
architecture for the joint detection and matching of feature points in images
acquired by different sensors using a single forward pass. The resulting
feature detector is tightly coupled with the feature descriptor, in contrast to
classical approaches (SIFT, etc.), where the detection phase precedes and
differs from computing the descriptor. Our approach utilizes two CNN
subnetworks, the first being a Siamese CNN and the second, consisting of dual
non-weight-sharing CNNs. This allows simultaneous processing and fusion of the
joint and disjoint cues in the multimodal image patches. The proposed approach
is experimentally shown to outperform contemporary state-of-the-art schemes
when applied to multiple datasets of multimodal images. It is also shown to
provide repeatable feature points detections across multisensor images,
outperforming state-of-the-art detectors. To the best of our knowledge, it is
the first unified approach for the detection and matching of such images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamically Grown Generative Adversarial Networks. (arXiv:2106.08505v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lanlan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuting Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jia Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08505">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work introduced progressive network growing as a promising way to ease
the training for large GANs, but the model design and architecture-growing
strategy still remain under-explored and needs manual design for different
image data. In this paper, we propose a method to dynamically grow a GAN during
training, optimizing the network architecture and its parameters together with
automation. The method embeds architecture search techniques as an interleaving
step with gradient-based training to periodically seek the optimal
architecture-growing strategy for the generator and discriminator. It enjoys
the benefits of both eased training because of progressive growing and improved
performance because of broader architecture design space. Experimental results
demonstrate new state-of-the-art of image generation. Observations in the
search procedure also provide constructive insights into the GAN model design
such as generator-discriminator balance and convolutional layer choices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Synchronized Reprojection-based Model for 3D Human Pose Estimation. (arXiv:2106.04274v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Cheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04274">
                                    <div class="article-summary-box-inner">
                                        <span>3D human pose estimation is still a challenging problem despite the large
amount of work that has been done in this field. Generally, most methods
directly use neural networks and ignore certain constraints (e.g., reprojection
constraints and joint angle and bone length constraints). This paper proposes a
weakly supervised GAN-based model for 3D human pose estimation that considers
3D information along with 2D information simultaneously, in which a
reprojection network is employed to learn the mapping of the distribution from
3D poses to 2D poses. In particular, we train the reprojection network and the
generative adversarial network synchronously. Furthermore, inspired by the
typical kinematic chain space (KCS) matrix, we propose a weighted KCS matrix,
which is added into the discriminator&#x27;s input to impose joint angle and bone
length constraints. The experimental results on Human3.6M show that our method
outperforms state-of-the-art methods by approximately 5.1\%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks. (arXiv:2106.07141v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozbulak_U/0/1/0/all/0/1">Utku Ozbulak</a>, <a href="http://arxiv.org/find/cs/1/au:+Anzaku_E/0/1/0/all/0/1">Esla Timothy Anzaku</a>, <a href="http://arxiv.org/find/cs/1/au:+Neve_W/0/1/0/all/0/1">Wesley De Neve</a>, <a href="http://arxiv.org/find/cs/1/au:+Messem_A/0/1/0/all/0/1">Arnout Van Messem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07141">
                                    <div class="article-summary-box-inner">
                                        <span>Although the adoption rate of deep neural networks (DNNs) has tremendously
increased in recent years, a solution for their vulnerability against
adversarial examples has not yet been found. As a result, substantial research
efforts are dedicated to fix this weakness, with many studies typically using a
subset of source images to generate adversarial examples, treating every image
in this subset as equal. We demonstrate that, in fact, not every source image
is equally suited for this kind of assessment. To do so, we devise a
large-scale model-to-model transferability scenario for which we meticulously
analyze the properties of adversarial examples, generated from every suitable
source image in ImageNet by making use of two of the most frequently deployed
attacks. In this transferability scenario, which involves seven distinct DNN
models, including the recently proposed vision transformers, we reveal that it
is possible to have a difference of up to $12.5\%$ in model-to-model
transferability success, $1.01$ in average $L_2$ perturbation, and $0.03$
($8/225$) in average $L_{\infty}$ perturbation when $1,000$ source images are
sampled randomly among all suitable candidates. We then take one of the first
steps in evaluating the robustness of images used to create adversarial
examples, proposing a number of simple but effective methods to identify
unsuitable source images, thus making it possible to mitigate extreme cases in
experimentation and support high-quality benchmarking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation. (arXiv:2106.09016v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yahui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1">Enver Sangineto</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yajing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoxian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1">Bruno Lepri</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadai_M/0/1/0/all/0/1">Marco De Nadai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09016">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-Image (I2I) multi-domain translation models are usually evaluated
also using the quality of their semantic interpolation results. However,
state-of-the-art models frequently show abrupt changes in the image appearance
during interpolation, and usually perform poorly in interpolations across
domains. In this paper, we propose a new training protocol based on three
specific losses which help a translation network to learn a smooth and
disentangled latent style space in which: 1) Both intra- and inter-domain
interpolations correspond to gradual changes in the generated images and 2) The
content of the source image is better preserved during the translation.
Moreover, we propose a novel evaluation metric to properly measure the
smoothness of latent style space of I2I translation models. The proposed method
can be plugged into existing translation approaches, and our extensive
experiments on different datasets show that it can significantly boost the
quality of the generated images and the graduality of the interpolations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TextStyleBrush: Transfer of Text Aesthetics from a Single Example. (arXiv:2106.08385v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishnan_P/0/1/0/all/0/1">Praveen Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovvuri_R/0/1/0/all/0/1">Rama Kovvuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guan Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilev_B/0/1/0/all/0/1">Boris Vassilev</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassner_T/0/1/0/all/0/1">Tal Hassner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08385">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach for disentangling the content of a text image
from all aspects of its appearance. The appearance representation we derive can
then be applied to new content, for one-shot transfer of the source style to
new content. We learn this disentanglement in a self-supervised manner. Our
method processes entire word boxes, without requiring segmentation of text from
background, per-character processing, or making assumptions on string lengths.
We show results in different text domains which were previously handled by
specialized methods, e.g., scene text, handwritten text. To these ends, we make
a number of technical contributions: (1) We disentangle the style and content
of a textual image into a non-parametric, fixed-dimensional vector. (2) We
propose a novel approach inspired by StyleGAN but conditioned over the example
style at different resolution and content. (3) We present novel self-supervised
training criteria which preserve both source style and target content using a
pre-trained font classifier and text recognizer. Finally, (4) we also introduce
Imgur5K, a new challenging dataset for handwritten word images. We offer
numerous qualitative photo-realistic results of our method. We further show
that our method surpasses previous work in quantitative tests on scene text and
handwriting datasets, as well as in a user study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Evaluating and Training Verifiably Robust Neural Networks. (arXiv:2104.00447v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zhaoyang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Minghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guodong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kehuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00447">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have shown that interval bound propagation (IBP) can be used to
train verifiably robust neural networks. Reseachers observe an intriguing
phenomenon on these IBP trained networks: CROWN, a bounding method based on
tight linear relaxation, often gives very loose bounds on these networks. We
also observe that most neurons become dead during the IBP training process,
which could hurt the representation capability of the network. In this paper,
we study the relationship between IBP and CROWN, and prove that CROWN is always
tighter than IBP when choosing appropriate bounding lines. We further propose a
relaxed version of CROWN, linear bound propagation (LBP), that can be used to
verify large networks to obtain lower verified errors than IBP. We also design
a new activation function, parameterized ramp function (ParamRamp), which has
more diversity of neuron status than ReLU. We conduct extensive experiments on
MNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve
state-of-the-art verified robustness. Code and the appendix are available at
https://github.com/ZhaoyangLyu/VerifiablyRobustNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Metamorphic image registration using a semi-Lagrangian scheme. (arXiv:2106.08817v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Francois_A/0/1/0/all/0/1">Anton Fran&#xe7;ois</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Glaunes_J/0/1/0/all/0/1">Joan Glaun&#xe8;s</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08817">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an implementation of both Large Deformation
Diffeomorphic Metric Mapping (LDDMM) and Metamorphosis image registration using
a semi-Lagrangian scheme for geodesic shooting. We propose to solve both
problems as an inexact matching providing a single and unifying cost function.
We demonstrate that for image registration the use of a semi-Lagrangian scheme
is more stable than a standard Eulerian scheme. Our GPU implementation is based
on PyTorch, which greatly simplifies and accelerates the computations thanks to
its powerful automatic differentiation engine. It will be freely available at
https://github.com/antonfrancois/Demeter_metamorphosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphset:Augmenting categorical emotion datasets with dimensional affect labels using face morphing. (arXiv:2103.02854v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vonikakis_V/0/1/0/all/0/1">Vassilios Vonikakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Neo_D/0/1/0/all/0/1">Dexter Neo</a>, <a href="http://arxiv.org/find/cs/1/au:+Winkler_S/0/1/0/all/0/1">Stefan Winkler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02854">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion recognition and understanding is a vital component in human-machine
interaction. Dimensional models of affect such as those using valence and
arousal have advantages over traditional categorical ones due to the complexity
of emotional states in humans. However, dimensional emotion annotations are
difficult and expensive to collect, therefore they are not as prevalent in the
affective computing community. To address these issues, we propose a method to
generate synthetic images from existing categorical emotion datasets using face
morphing as well as dimensional labels in the circumplex space with full
control over the resulting sample distribution, while achieving augmentation
factors of at least 20x or more.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation Using Physics-Based Data Augmentation. (arXiv:2103.05690v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dahiya_N/0/1/0/all/0/1">Navdeep Dahiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1">Sadegh R Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengpeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Si-Yuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yezzi_A/0/1/0/all/0/1">Anthony Yezzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_S/0/1/0/all/0/1">Saad Nadeem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05690">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: In current clinical practice, noisy and artifact-ridden weekly
cone-beam computed tomography (CBCT) images are only used for patient setup
during radiotherapy. Treatment planning is done once at the beginning of the
treatment using high-quality planning CT (pCT) images and manual contours for
organs-at-risk (OARs) structures. If the quality of the weekly CBCT images can
be improved while simultaneously segmenting OAR structures, this can provide
critical information for adapting radiotherapy mid-treatment as well as for
deriving biomarkers for treatment response. Methods: Using a novel
physics-based data augmentation strategy, we synthesize a large dataset of
perfectly/inherently registered planning CT and synthetic-CBCT pairs for
locally advanced lung cancer patient cohort, which are then used in a multitask
3D deep learning framework to simultaneously segment and translate real weekly
CBCT images to high-quality planning CT-like images. Results: We compared the
synthetic CT and OAR segmentations generated by the model to real planning CT
and manual OAR segmentations and showed promising results. The real week 1
(baseline) CBCT images which had an average MAE of 162.77 HU compared to pCT
images are translated to synthetic CT images that exhibit a drastically
improved average MAE of 29.31 HU and average structural similarity of 92% with
the pCT images. The average DICE scores of the 3D organs-at-risk segmentations
are: lungs 0.96, heart 0.88, spinal cord 0.83 and esophagus 0.66. Conclusions:
We demonstrate an approach to translate artifact-ridden CBCT images to high
quality synthetic CT images while simultaneously generating good quality
segmentation masks for different organs-at-risk. This approach could allow
clinicians to adjust treatment plans using only the routine low-quality CBCT
images, potentially improving patient outcomes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainers in the Wild: Making Surrogate Explainers Robust to Distortions through Perception. (arXiv:2102.10951v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1">Alexander Hepburn</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Raul Santos-Rodriguez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10951">
                                    <div class="article-summary-box-inner">
                                        <span>Explaining the decisions of models is becoming pervasive in the image
processing domain, whether it is by using post-hoc methods or by creating
inherently interpretable models. While the widespread use of surrogate
explainers is a welcome addition to inspect and understand black-box models,
assessing the robustness and reliability of the explanations is key for their
success. Additionally, whilst existing work in the explainability field
proposes various strategies to address this problem, the challenges of working
with data in the wild is often overlooked. For instance, in image
classification, distortions to images can not only affect the predictions
assigned by the model, but also the explanation. Given a clean and a distorted
version of an image, even if the prediction probabilities are similar, the
explanation may still be different. In this paper we propose a methodology to
evaluate the effect of distortions in explanations by embedding perceptual
distances that tailor the neighbourhoods used to training surrogate explainers.
We also show that by operating in this way, we can make the explanations more
robust to distortions. We generate explanations for images in the Imagenet-C
dataset and demonstrate how using a perceptual distances in the surrogate
explainer creates more coherent explanations for the distorted and reference
images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imperfect ImaGANation: Implications of GANs Exacerbating Biases on Facial Data Augmentation and Snapchat Selfie Lenses. (arXiv:2001.09528v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1">Niharika Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Olmo_A/0/1/0/all/0/1">Alberto Olmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1">Sailik Sengupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Manikonda_L/0/1/0/all/0/1">Lydia Manikonda</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1">Subbarao Kambhampati</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09528">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we show that popular Generative Adversarial Networks (GANs)
exacerbate biases along the axes of gender and skin tone when given a skewed
distribution of face-shots. While practitioners celebrate synthetic data
generation using GANs as an economical way to augment data for training
data-hungry machine learning models, it is unclear whether they recognize the
perils of such techniques when applied to real world datasets biased along
latent dimensions. Specifically, we show that (1) traditional GANs further skew
the distribution of a dataset consisting of engineering faculty headshots,
generating minority modes less often and of worse quality and (2)
image-to-image translation (conditional) GANs also exacerbate biases by
lightening skin color of non-white faces and transforming female facial
features to be masculine when generating faces of engineering professors. Thus,
our study is meant to serve as a cautionary tale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding and Evaluating Racial Biases in Image Captioning. (arXiv:2106.08503v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dora Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Angelina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1">Olga Russakovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08503">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning is an important task for benchmarking visual reasoning and
for enabling accessibility for people with vision impairments. However, as in
many machine learning settings, social biases can influence image captioning in
undesirable ways. In this work, we study bias propagation pathways within image
captioning, focusing specifically on the COCO dataset. Prior work has analyzed
gender bias in captions using automatically-derived gender labels; here we
examine racial and intersectional biases using manual annotations. Our first
contribution is in annotating the perceived gender and skin color of 28,315 of
the depicted people after obtaining IRB approval. Using these annotations, we
compare racial biases present in both manual and automatically-generated image
captions. We demonstrate differences in caption performance, sentiment, and
word choice between images of lighter versus darker-skinned people. Further, we
find the magnitude of these differences to be greater in modern captioning
systems compared to older ones, thus leading to concerns that without proper
consideration and mitigation these differences will only become increasingly
prevalent. Code and data is available at
https://princetonvisualai.github.io/imagecaptioning-bias .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LaneAF: Robust Multi-Lane Detection with Affinity Fields. (arXiv:2103.12040v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abualsaud_H/0/1/0/all/0/1">Hala Abualsaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sean Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">David Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Situ_K/0/1/0/all/0/1">Kenny Situ</a>, <a href="http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1">Akshay Rangesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1">Mohan M. Trivedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12040">
                                    <div class="article-summary-box-inner">
                                        <span>This study presents an approach to lane detection involving the prediction of
binary segmentation masks and per-pixel affinity fields. These affinity fields,
along with the binary masks, can then be used to cluster lane pixels
horizontally and vertically into corresponding lane instances in a
post-processing step. This clustering is achieved through a simple row-by-row
decoding process with little overhead; such an approach allows LaneAF to detect
a variable number of lanes without assuming a fixed or maximum number of lanes.
Moreover, this form of clustering is more interpretable in comparison to
previous visual clustering approaches, and can be analyzed to identify and
correct sources of error. Qualitative and quantitative results obtained on
popular lane detection datasets demonstrate the model&#x27;s ability to detect and
cluster lanes effectively and robustly. Our proposed approach sets a new
state-of-the-art on the challenging CULane dataset and the recently introduced
Unsupervised LLAMAS dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing Attack. (arXiv:2105.00623v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yongjian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00623">
                                    <div class="article-summary-box-inner">
                                        <span>Previous studies have verified that the functionality of black-box models can
be stolen with full probability outputs. However, under the more practical
hard-label setting, we observe that existing methods suffer from catastrophic
performance degradation. We argue this is due to the lack of rich information
in the probability prediction and the overfitting caused by hard labels. To
this end, we propose a novel hard-label model stealing method termed
\emph{black-box dissector}, which consists of two erasing-based modules. One is
a CAM-driven erasing strategy that is designed to increase the information
capacity hidden in hard labels from the victim model. The other is a
random-erasing-based self-knowledge distillation module that utilizes soft
labels from the substitute model to mitigate overfitting. Extensive experiments
on four widely-used datasets consistently demonstrate that our method
outperforms state-of-the-art methods, with an improvement of at most $8.27\%$.
We also validate the effectiveness and practical potential of our method on
real-world APIs and defense methods. Furthermore, our method promotes other
downstream tasks, \emph{i.e.}, transfer adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaze Preserving CycleGANs for Eyeglass Removal &amp; Persistent Gaze Estimation. (arXiv:2002.02077v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1">Akshay Rangesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bowen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1">Mohan M. Trivedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02077">
                                    <div class="article-summary-box-inner">
                                        <span>A driver&#x27;s gaze is critical for determining their attention, state,
situational awareness, and readiness to take over control from partially
automated vehicles. Estimating the gaze direction is the most obvious way to
gauge a driver&#x27;s state under ideal conditions when limited to using
non-intrusive imaging sensors. Unfortunately, the vehicular environment
introduces a variety of challenges that are usually unaccounted for - harsh
illumination, nighttime conditions, and reflective eyeglasses. Relying on head
pose alone under such conditions can prove to be unreliable and erroneous. In
this study, we offer solutions to address these problems encountered in the
real world. To solve issues with lighting, we demonstrate that using an
infrared camera with suitable equalization and normalization suffices. To
handle eyeglasses and their corresponding artifacts, we adopt image-to-image
translation using generative adversarial networks to pre-process images prior
to gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is
trained to preserve the driver&#x27;s gaze while removing potential eyeglasses from
face images. GPCycleGAN is based on the well-known CycleGAN approach - with the
addition of a gaze classifier and a gaze consistency loss for additional
supervision. Our approach exhibits improved performance, interpretability,
robustness and superior qualitative results on challenging real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LARNet: Lie Algebra Residual Network for Face Recognition. (arXiv:2103.08147v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaolong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaohong Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1">Dihong Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1">Dong-Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08147">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition is an important yet challenging problem in computer vision.
A major challenge in practical face recognition applications lies in
significant variations between profile and frontal faces. Traditional
techniques address this challenge either by synthesizing frontal faces or by
pose invariant learning. In this paper, we propose a novel method with Lie
algebra theory to explore how face rotation in the 3D space affects the deep
feature generation process of convolutional neural networks (CNNs). We prove
that face rotation in the image space is equivalent to an additive residual
component in the feature space of CNNs, which is determined solely by the
rotation. Based on this theoretical finding, we further design a Lie Algebraic
Residual Network (LARNet) for tackling pose robust face recognition. Our LARNet
consists of a residual subnet for decoding rotation information from input face
images, and a gating subnet to learn rotation magnitude for controlling the
strength of the residual component contributing to the feature learning
process. Comprehensive experimental evaluations on both frontal-profile face
datasets and general face recognition datasets convincingly demonstrate that
our method consistently outperforms the state-of-the-art ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Feature Alignment for Adversarial Training. (arXiv:2105.15157v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruixin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuge Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaoxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15157">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies reveal that Convolutional Neural Networks (CNNs) are typically
vulnerable to adversarial attacks, which pose a threat to security-sensitive
applications. Many adversarial defense methods improve robustness at the cost
of accuracy, raising the contradiction between standard and adversarial
accuracies. In this paper, we observe an interesting phenomenon that feature
statistics change monotonically and smoothly w.r.t the rising of attacking
strength. Based on this observation, we propose the adaptive feature alignment
(AFA) to generate features of arbitrary attacking strengths. Our method is
trained to automatically align features of arbitrary attacking strength. This
is done by predicting a fusing weight in a dual-BN architecture. Unlike
previous works that need to either retrain the model or manually tune a
hyper-parameters for different attacking strengths, our method can deal with
arbitrary attacking strengths with a single model without introducing any
hyper-parameter. Importantly, our method improves the model robustness against
adversarial samples without incurring much loss in standard accuracy.
Experiments on CIFAR-10, SVHN, and tiny-ImageNet datasets demonstrate that our
method outperforms the state-of-the-art under a wide range of attacking
strengths.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Social Distance Estimation From Images: Performance Evaluation, Test Benchmark, and Algorithm. (arXiv:2103.06759v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1">Mert Seker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1">Anssi M&#xe4;nnist&#xf6;</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06759">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 virus has caused a global pandemic since March 2020. The World
Health Organization (WHO) has provided guidelines on how to reduce the spread
of the virus and one of the most important measures is social distancing.
Maintaining a minimum of one meter distance from other people is strongly
suggested to reduce the risk of infection. This has created a strong interest
in monitoring the social distances either as a safety measure or to study how
the measures have affected human behavior and country-wise differences in this.
The need for automatic social distance estimation algorithms is evident, but
there is no suitable test benchmark for such algorithms. Collecting images with
measured ground-truth pair-wise distances between all the people using
different camera settings is cumbersome. Furthermore, performance evaluation
for social distance estimation algorithms is not straightforward and there is
no widely accepted evaluation protocol. In this paper, we provide a dataset of
varying images with measured pair-wise social distances under different camera
positionings and focal length values. We suggest a performance evaluation
protocol and provide a benchmark to easily evaluate social distance estimation
algorithms. We also propose a method for automatic social distance estimation.
Our method takes advantage of object detection and human pose estimation. It
can be applied on any single image as long as focal length and sensor size
information are known. The results on our benchmark are encouraging with 92%
human detection rate and only 28.9% average error in distance estimation among
the detected people.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-MAN: Explaining multiple sources of anomalies in video. (arXiv:2106.08856v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szymanowicz_S/0/1/0/all/0/1">Stanislaw Szymanowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Charles_J/0/1/0/all/0/1">James Charles</a>, <a href="http://arxiv.org/find/cs/1/au:+Cipolla_R/0/1/0/all/0/1">Roberto Cipolla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08856">
                                    <div class="article-summary-box-inner">
                                        <span>Our objective is to detect anomalies in video while also automatically
explaining the reason behind the detector&#x27;s response. In a practical sense,
explainability is crucial for this task as the required response to an anomaly
depends on its nature and severity. However, most leading methods (based on
deep neural networks) are not interpretable and hide the decision making
process in uninterpretable feature representations. In an effort to tackle this
problem we make the following contributions: (1) we show how to build
interpretable feature representations suitable for detecting anomalies with
state of the art performance, (2) we propose an interpretable probabilistic
anomaly detector which can describe the reason behind it&#x27;s response using high
level concepts, (3) we are the first to directly consider object interactions
for anomaly detection and (4) we propose a new task of explaining anomalies and
release a large dataset for evaluating methods on this task. Our method
competes well with the state of the art on public datasets while also providing
anomaly explanation based on objects and their interactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Person Re-identification via Multi-Label Prediction and Classification based on Graph-Structural Insight. (arXiv:2106.08798v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jongmin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_H/0/1/0/all/0/1">Hyeontaek Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08798">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses unsupervised person re-identification (Re-ID) using
multi-label prediction and classification based on graph-structural insight.
Our method extracts features from person images and produces a graph that
consists of the features and a pairwise similarity of them as nodes and edges,
respectively. Based on the graph, the proposed graph structure based
multi-label prediction (GSMLP) method predicts multi-labels by considering the
pairwise similarity and the adjacency node distribution of each node. The
multi-labels created by GSMLP are applied to the proposed selective multi-label
classification (SMLC) loss. SMLC integrates a hard-sample mining scheme and a
multi-label classification. The proposed GSMLP and SMLC boost the performance
of unsupervised person Re-ID without any pre-labelled dataset. Experimental
results justify the superiority of the proposed method in unsupervised person
Re-ID by producing state-of-the-art performance. The source code for this paper
is publicly available on &#x27;https://github.com/uknownpioneer/GSMLP-SMLC.git&#x27;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Disentangle GAN Fingerprint for Fake Image Attribution. (arXiv:2106.08749v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianyun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Juan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Qiang Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jiaqi Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xirong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Sheng Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08749">
                                    <div class="article-summary-box-inner">
                                        <span>Rapid pace of generative models has brought about new threats to visual
forensics such as malicious personation and digital copyright infringement,
which promotes works on fake image attribution. Existing works on fake image
attribution mainly rely on a direct classification framework. Without
additional supervision, the extracted features could include many
content-relevant components and generalize poorly. Meanwhile, how to obtain an
interpretable GAN fingerprint to explain the decision remains an open question.
Adopting a multi-task framework, we propose a GAN Fingerprint Disentangling
Network (GFD-Net) to simultaneously disentangle the fingerprint from
GAN-generated images and produce a content-irrelevant representation for fake
image attribution. A series of constraints are provided to guarantee the
stability and discriminability of the fingerprint, which in turn helps
content-irrelevant feature extraction. Further, we perform comprehensive
analysis on GAN fingerprint, providing some clues about the properties of GAN
fingerprint and which factors dominate the fingerprint in GAN architecture.
Experiments show that our GFD-Net achieves superior fake image attribution
performance in both closed-world and open-world testing. We also apply our
method in binary fake image detection and exhibit a significant generalization
ability on unseen generators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PGMAN: An Unsupervised Generative Multi-adversarial Network for Pan-sharpening. (arXiv:2012.09054v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1">Huanyu Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1">Qingjie Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09054">
                                    <div class="article-summary-box-inner">
                                        <span>Pan-sharpening aims at fusing a low-resolution (LR) multi-spectral (MS) image
and a high-resolution (HR) panchromatic (PAN) image acquired by a satellite to
generate an HR MS image. Many deep learning based methods have been developed
in the past few years. However, since there are no intended HR MS images as
references for learning, almost all of the existing methods down-sample the MS
and PAN images and regard the original MS images as targets to form a
supervised setting for training. These methods may perform well on the
down-scaled images, however, they generalize poorly to the full-resolution
images. To conquer this problem, we design an unsupervised framework that is
able to learn directly from the full-resolution images without any
preprocessing. The model is built based on a novel generative multi-adversarial
network. We use a two-stream generator to extract the modality-specific
features from the PAN and MS images, respectively, and develop a
dual-discriminator to preserve the spectral and spatial information of the
inputs when performing fusion. Furthermore, a novel loss function is introduced
to facilitate training under the unsupervised setting. Experiments and
comparisons with other state-of-the-art methods on GaoFen-2 and QuickBird
images demonstrate that the proposed method can obtain much better fusion
results on the full-resolution images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic Segmentation. (arXiv:2009.13342v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1">Naiyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Yanhu Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaiqi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13342">
                                    <div class="article-summary-box-inner">
                                        <span>Panoptic segmentation (PS) is a complex scene understanding task that
requires providing high-quality segmentation for both thing objects and stuff
regions. Previous methods handle these two classes with semantic and instance
segmentation modules separately, following with heuristic fusion or additional
modules to resolve the conflicts between the two outputs. This work simplifies
this pipeline of PS by consistently modeling the two classes with a novel PS
framework, which extends a detection model with an extra module to predict
category- and instance-aware pixel embedding (CIAE). CIAE is a novel pixel-wise
embedding feature that encodes both semantic-classification and
instance-distinction information. At the inference process, PS results are
simply derived by assigning each pixel to a detected instance or a stuff class
according to the learned embedding. Our method not only demonstrates fast
inference speed but also the first one-stage method to achieve comparable
performance to two-stage methods on the challenging COCO benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods. (arXiv:2106.08829v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheema_G/0/1/0/all/0/1">Gullal S. Cheema</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1">Sherzod Hakimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1">Eric M&#xfc;ller-Budack</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08829">
                                    <div class="article-summary-box-inner">
                                        <span>Opinion and sentiment analysis is a vital task to characterize subjective
information in social media posts. In this paper, we present a comprehensive
experimental evaluation and comparison with six state-of-the-art methods, from
which we have re-implemented one of them. In addition, we investigate different
textual and visual feature embeddings that cover different aspects of the
content, as well as the recently introduced multimodal CLIP embeddings.
Experimental results are presented for two different publicly available
benchmark datasets of tweets and corresponding images. In contrast to the
evaluation methodology of previous work, we introduce a reproducible and fair
evaluation scheme to make results comparable. Finally, we conduct an error
analysis to outline the limitations of the methods and possibilities for the
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions. (arXiv:2012.04293v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ates_T/0/1/0/all/0/1">Tayfun Ates</a>, <a href="http://arxiv.org/find/cs/1/au:+Atesoglu_M/0/1/0/all/0/1">Muhammed Samil Atesoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yigit_C/0/1/0/all/0/1">Cagatay Yigit</a>, <a href="http://arxiv.org/find/cs/1/au:+Kesen_I/0/1/0/all/0/1">Ilker Kesen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobas_M/0/1/0/all/0/1">Mert Kobas</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdem_E/0/1/0/all/0/1">Erkut Erdem</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdem_A/0/1/0/all/0/1">Aykut Erdem</a>, <a href="http://arxiv.org/find/cs/1/au:+Goksun_T/0/1/0/all/0/1">Tilbe Goksun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuret_D/0/1/0/all/0/1">Deniz Yuret</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04293">
                                    <div class="article-summary-box-inner">
                                        <span>Humans are able to perceive, understand and reason about physical events.
Developing models with similar physical understanding capabilities is a
long-standing goal of artificial intelligence. As a step towards this goal, in
this work, we introduce CRAFT, a new visual question answering dataset that
requires causal reasoning about physical forces and object interactions. It
contains 58K video and question pairs that are generated from 10K videos from
20 different virtual environments, containing various objects in motion that
interact with each other and the scene. Two question categories from CRAFT
include previously studied descriptive and counterfactual questions. Besides,
inspired by the theories of force dynamics in cognitive linguistics, we
introduce new question categories that involve understanding the interactions
of objects through the notions of cause, enable, and prevent. Our results
demonstrate that even though these tasks seem to be simple and intuitive for
humans, the evaluated baseline models, including existing state-of-the-art
methods, do not yet deal with the challenges posed in our benchmark dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured DropConnect for Uncertainty Inference in Image Classification. (arXiv:2106.08624v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wenqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weidong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhanyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08624">
                                    <div class="article-summary-box-inner">
                                        <span>With the complexity of the network structure, uncertainty inference has
become an important task to improve the classification accuracy for artificial
intelligence systems. For image classification tasks, we propose a structured
DropConnect (SDC) framework to model the output of a deep neural network by a
Dirichlet distribution. We introduce a DropConnect strategy on weights in the
fully connected layers during training. In test, we split the network into
several sub-networks, and then model the Dirichlet distribution by match its
moments with the mean and variance of the outputs of these sub-networks. The
entropy of the estimated Dirichlet distribution is finally utilized for
uncertainty inference. In this paper, this framework is implemented on LeNet$5$
and VGG$16$ models for misclassification detection and out-of-distribution
detection on MNIST and CIFAR-$10$ datasets. Experimental results show that the
performance of the proposed SDC can be comparable to other uncertainty
inference methods. Furthermore, the SDC is adapted well to different network
structures with certain generalization capabilities and research prospects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking. (arXiv:2106.08816v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Ziang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Changhong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjie Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiming Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08816">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the Siamese-based method has stood out from multitudinous tracking
methods owing to its state-of-the-art (SOTA) performance. Nevertheless, due to
various special challenges in UAV tracking, \textit{e.g.}, severe occlusion,
and fast motion, most existing Siamese-based trackers hardly combine superior
performance with high efficiency. To this concern, in this paper, a novel
attentional Siamese tracker (SiamAPN++) is proposed for real-time UAV tracking.
By virtue of the attention mechanism, the attentional aggregation network (AAN)
is conducted with self-AAN and cross-AAN, raising the expression ability of
features eventually. The former AAN aggregates and models the self-semantic
interdependencies of the single feature map via spatial and channel dimensions.
The latter aims to aggregate the cross-interdependencies of different semantic
features including the location information of anchors. In addition, the dual
features version of the anchor proposal network is proposed to raise the
robustness of proposing anchors, increasing the perception ability to objects
with various scales. Experiments on two well-known authoritative benchmarks are
conducted, where SiamAPN++ outperforms its baseline SiamAPN and other SOTA
trackers. Besides, real-world tests onboard a typical embedded platform
demonstrate that SiamAPN++ achieves promising tracking results with real-time
speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM. (arXiv:2103.05056v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1">Daniele Cattaneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1">Matteo Vaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05056">
                                    <div class="article-summary-box-inner">
                                        <span>Loop closure detection is an essential component of Simultaneous Localization
and Mapping (SLAM) systems, which reduces the drift accumulated over time. Over
the years, several deep learning approaches have been proposed to address this
task, however their performance has been subpar compared to handcrafted
techniques, especially while dealing with reverse loops. In this paper, we
introduce the novel LCDNet that effectively detects loop closures in LiDAR
point clouds by simultaneously identifying previously visited places and
estimating the 6-DoF relative transformation between the current scan and the
map. LCDNet is composed of a shared encoder, a place recognition head that
extracts global descriptors, and a relative pose head that estimates the
transformation between two point clouds. We introduce a novel relative pose
head based on the unbalanced optimal transport theory that we implement in a
differentiable manner to allow for end-to-end training. Extensive evaluations
of LCDNet on multiple real-world autonomous driving datasets show that our
approach outperforms state-of-the-art loop closure detection and point cloud
registration techniques by a large margin, especially while dealing with
reverse loops. Moreover, we integrate our proposed loop closure detection
approach into a LiDAR SLAM library to provide a complete mapping system and
demonstrate the generalization ability using different sensor setup in an
unseen city.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSRN: an Efficient Deep Network for Image Relighting. (arXiv:2102.09242v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sourya Dipta Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nisarg A. Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Saikat Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1">Himanshu Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09242">
                                    <div class="article-summary-box-inner">
                                        <span>Custom and natural lighting conditions can be emulated in images of the scene
during post-editing. Extraordinary capabilities of the deep learning framework
can be utilized for such purpose. Deep image relighting allows automatic photo
enhancement by illumination-specific retouching. Most of the state-of-the-art
methods for relighting are run-time intensive and memory inefficient. In this
paper, we propose an efficient, real-time framework Deep Stacked Relighting
Network (DSRN) for image relighting by utilizing the aggregated features from
input image at different scales. Our model is very lightweight with total size
of about 42 MB and has an average inference time of about 0.0116s for image of
resolution $1024 \times 1024$ which is faster as compared to other multi-scale
models. Our solution is quite robust for translating image color temperature
from input image to target image and also performs moderately for light
gradient generation with respect to the target image. Additionally, we show
that if images illuminated from opposite directions are used as input, the
qualitative results improve over using a single input image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy Suppression for Anomalous Event Detection. (arXiv:2011.12077v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Muhammad Zaigham Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">Arif Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Astrid_M/0/1/0/all/0/1">Marcella Astrid</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seung-Ik Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12077">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to detect real-world anomalous events through video-level labels is
a challenging task due to the rare occurrence of anomalies as well as noise in
the labels. In this work, we propose a weakly supervised anomaly detection
method which has manifold contributions including1) a random batch based
training procedure to reduce inter-batch correlation, 2) a normalcy suppression
mechanism to minimize anomaly scores of the normal regions of a video by taking
into account the overall information available in one training batch, and 3) a
clustering distance based loss to contribute towards mitigating the label noise
and to produce better anomaly representations by encouraging our model to
generate distinct normal and anomalous clusters. The proposed method
obtains83.03% and 89.67% frame-level AUC performance on the UCF Crime and
ShanghaiTech datasets respectively, demonstrating its superiority over the
existing state-of-the-art algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Diffusion for Dense Depth Estimation from Multi-view Images. (arXiv:2106.08917v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Numair Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min H. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompkin_J/0/1/0/all/0/1">James Tompkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08917">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to estimate dense depth by optimizing a sparse set of
points such that their diffusion into a depth map minimizes a multi-view
reprojection error from RGB supervision. We optimize point positions, depths,
and weights with respect to the loss by differential splatting that models
points as Gaussians with analytic transmittance. Further, we develop an
efficient optimization routine that can simultaneously optimize the 50k+ points
required for complex scene reconstruction. We validate our routine using ground
truth data and show high reconstruction quality. Then, we apply this to light
field and wider baseline images via self supervision, and show improvements in
both average and outlier error for depth maps diffused from inaccurate sparse
points. Finally, we compare qualitative and quantitative results to image
processing and deep learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point and Ask: Incorporating Pointing into Visual Question Answering. (arXiv:2011.13681v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mani_A/0/1/0/all/0/1">Arjun Mani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hinthorn_W/0/1/0/all/0/1">Will Hinthorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_N/0/1/0/all/0/1">Nobline Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1">Olga Russakovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13681">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Question Answering (VQA) has become one of the key benchmarks of
visual recognition progress. Multiple VQA extensions have been explored to
better simulate real-world settings: different question formulations, changing
training and test distributions, conversational consistency in dialogues, and
explanation-based answering. In this work, we further expand this space by
considering visual questions that include a spatial point of reference.
Pointing is a nearly universal gesture among humans, and real-world VQA is
likely to involve a gesture towards the target region.

Concretely, we (1) introduce and motivate point-input questions as an
extension of VQA, (2) define three novel classes of questions within this
space, and (3) for each class, introduce both a benchmark dataset and a series
of baseline models to handle its unique challenges. There are two key
distinctions from prior work. First, we explicitly design the benchmarks to
require the point input, i.e., we ensure that the visual question cannot be
answered accurately without the spatial reference. Second, we explicitly
explore the more realistic point spatial input rather than the standard but
unnatural bounding box input. Through our exploration we uncover and address
several visual recognition challenges, including the ability to infer human
intent, reason both locally and globally about the image, and effectively
combine visual, language and spatial inputs. Code is available at:
https://github.com/princetonvisualai/pointingqa .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation with Variational Approximation for Cardiac Segmentation. (arXiv:2106.08752v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fuping Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08752">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation is useful in medical image segmentation.
Particularly, when ground truths of the target images are not available, domain
adaptation can train a target-specific model by utilizing the existing labeled
images from other modalities. Most of the reported works mapped images of both
the source and target domains into a common latent feature space, and then
reduced their discrepancy either implicitly with adversarial training or
explicitly by directly minimizing a discrepancy metric. In this work, we
propose a new framework, where the latent features of both domains are driven
towards a common and parameterized variational form, whose conditional
distribution given the image is Gaussian. This is achieved by two networks
based on variational auto-encoders (VAEs) and a regularization for this
variational approximation. Both of the VAEs, each for one domain, contain a
segmentation module, where the source segmentation is trained in a supervised
manner, while the target one is trained unsupervisedly. We validated the
proposed domain adaptation method using two cardiac segmentation tasks, i.e.,
the cross-modality (CT and MR) whole heart segmentation and the cross-sequence
cardiac MR segmentation. Results show that the proposed method achieved better
accuracies compared to two state-of-the-art approaches and demonstrated good
potential for cardiac segmentation. Furthermore, the proposed explicit
regularization was shown to be effective and efficient in narrowing down the
distribution gap between domains, which is useful for unsupervised domain
adaptation. Our code and data has been released via
https://zmiclab.github.io/projects.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Semi-Supervised Object Detection with Soft Teacher. (arXiv:2106.09018v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengde Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09018">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an end-to-end semi-supervised object detection approach,
in contrast to previous more complex multi-stage methods. The end-to-end
training gradually improves pseudo label qualities during the curriculum, and
the more and more accurate pseudo labels in turn benefit object detection
training. We also propose two simple yet effective techniques within this
framework: a soft teacher mechanism where the classification loss of each
unlabeled bounding box is weighed by the classification score produced by the
teacher network; a box jittering approach to select reliable pseudo boxes for
the learning of box regression. On COCO benchmark, the proposed approach
outperforms previous methods by a large margin under various labeling ratios,
i.e. 1\%, 5\% and 10\%. Moreover, our approach proves to perform also well when
the amount of labeled data is relatively large. For example, it can improve a
40.9 mAP baseline detector trained using the full COCO training set by +3.6
mAP, reaching 44.5 mAP, by leveraging the 123K unlabeled images of COCO. On the
state-of-the-art Swin Transformer-based object detector (58.9 mAP on test-dev),
it can still significantly improve the detection accuracy by +1.5 mAP, reaching
60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching
52.4 mAP, pushing the new state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AtrialGeneral: Domain Generalization for Left Atrial Segmentation of Multi-Center LGE MRIs. (arXiv:2106.08727v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmer_V/0/1/0/all/0/1">Veronika A. Zimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08727">
                                    <div class="article-summary-box-inner">
                                        <span>Left atrial (LA) segmentation from late gadolinium enhanced magnetic
resonance imaging (LGE MRI) is a crucial step needed for planning the treatment
of atrial fibrillation. However, automatic LA segmentation from LGE MRI is
still challenging, due to the poor image quality, high variability in LA
shapes, and unclear LA boundary. Though deep learning-based methods can provide
promising LA segmentation results, they often generalize poorly to unseen
domains, such as data from different scanners and/or sites. In this work, we
collect 210 LGE MRIs from different centers with different levels of image
quality. To evaluate the domain generalization ability of models on the LA
segmentation task, we employ four commonly used semantic segmentation networks
for the LA segmentation from multi-center LGE MRIs. Besides, we investigate
three domain generalization strategies, i.e., histogram matching, mutual
information based disentangled representation, and random style transfer, where
a simple histogram matching is proved to be most effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1">Steven C.H. Hoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08914">
                                    <div class="article-summary-box-inner">
                                        <span>Video-grounded dialogue systems aim to integrate video understanding and
dialogue understanding to generate responses that are relevant to both the
dialogue and video context. Most existing approaches employ deep learning
models and have achieved remarkable performance, given the relatively small
datasets available. However, the results are partly accomplished by exploiting
biases in the datasets rather than developing multimodal reasoning, resulting
in limited generalization. In this paper, we propose a novel approach of
Compositional Counterfactual Contrastive Learning ($C^3$) to develop
contrastive training between factual and counterfactual samples in
video-grounded dialogues. Specifically, we design factual/counterfactual
sampling based on the temporal steps in videos and tokens in dialogues and
propose contrastive loss functions that exploit object-level or action-level
variance. Different from prior approaches, we focus on contrastive hidden state
representations among compositional output tokens to optimize the
representation space in a generation setting. We achieved promising performance
gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the
benefits of our approach in grounding video and dialogue context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds. (arXiv:2007.07978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nielsen_A/0/1/0/all/0/1">A. H. Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">A. Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Karstoft_H/0/1/0/all/0/1">H. Karstoft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07978">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the formation and development of clouds is a central element of
modern weather forecasting systems. Incorrect clouds forecasts can lead to
major uncertainty in the overall accuracy of weather forecasts due to their
intrinsic role in the Earth&#x27;s climate system. Few studies have tackled this
challenging problem from a machine learning point-of-view due to a shortage of
high-resolution datasets with many historical observations globally. In this
paper, we present a novel satellite-based dataset called &#x60;&#x60;CloudCast&#x27;&#x27;. It
consists of 70,080 images with 10 different cloud types for multiple layers of
the atmosphere annotated on a pixel level. The spatial resolution of the
dataset is 928 x 1530 pixels (3x3 km per pixel) with 15-min intervals between
frames for the period 2017-01-01 to 2018-12-31. All frames are centered and
projected over Europe. To supplement the dataset, we conduct an evaluation
study with current state-of-the-art video prediction methods such as
convolutional long short-term memory networks, generative adversarial networks,
and optical flow-based extrapolation methods. As the evaluation of video
prediction is difficult in practice, we aim for a thorough evaluation in the
spatial and temporal domain. Our benchmark models show promising results but
with ample room for improvement. This is the first publicly available
global-scale dataset with high-resolution cloud types on a high temporal
granularity to the authors&#x27; best knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Generative Adversarial Networks in One Stage. (arXiv:2103.00430v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chengchao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Youtan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinchao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xubin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00430">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have demonstrated unprecedented
success in various image generation tasks. The encouraging results, however,
come at the price of a cumbersome training process, during which the generator
and discriminator are alternately updated in two stages. In this paper, we
investigate a general training scheme that enables training GANs efficiently in
only one stage. Based on the adversarial losses of the generator and
discriminator, we categorize GANs into two classes, Symmetric GANs and
Asymmetric GANs, and introduce a novel gradient decomposition method to unify
the two, allowing us to train both classes in one stage and hence alleviate the
training effort. We also computationally analyze the efficiency of the proposed
method, and empirically demonstrate that, the proposed method yields a solid
$1.5\times$ acceleration across various datasets and network architectures.
Furthermore, we show that the proposed method is readily applicable to other
adversarial-training scenarios, such as data-free knowledge distillation. The
code is available at https://github.com/zju-vipa/OSGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Naturalness Evaluation Database for Video Prediction Models. (arXiv:2005.00356v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Somraj_N/0/1/0/all/0/1">Nagabhushan Somraj</a>, <a href="http://arxiv.org/find/eess/1/au:+Kashi_M/0/1/0/all/0/1">Manoj Surya Kashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Arun_S/0/1/0/all/0/1">S. P. Arun</a>, <a href="http://arxiv.org/find/eess/1/au:+Soundararajan_R/0/1/0/all/0/1">Rajiv Soundararajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00356">
                                    <div class="article-summary-box-inner">
                                        <span>The study of video prediction models is believed to be a fundamental approach
to representation learning for videos. While a plethora of generative models
for predicting the future frame pixel values given the past few frames exist,
the quantitative evaluation of the predicted frames has been found to be
extremely challenging. In this context, we introduce the problem of naturalness
evaluation, which refers to how natural or realistic a predicted video looks.
We create the Indian Institute of Science VIdeo Naturalness Evaluation (IISc
VINE) Database consisting of 300 videos, obtained by applying different
prediction models on different datasets, and accompanying human opinion scores.
We collected subjective ratings of naturalness from 50 human participants for
these videos. Our subjective study reveals that human observers were highly
consistent in their judgments of naturalness. We benchmark several popularly
used measures for evaluating video prediction and show that they do not
adequately correlate with these subjective scores. We introduce two new
features to effectively capture naturalness, motion-compensated cosine
similarities of deep features of predicted frames with past frames, and deep
features extracted from rescaled frame differences. We show that our feature
design leads to state of the art naturalness prediction in accordance with
human judgments on our IISc VINE Database. The database and code are publicly
available on our project website:
https://nagabhushansn95.github.io/publications/2020/vine</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JRDB-Act: A Large-scale Multi-modal Dataset for Spatio-temporal Action, Social Group and Activity Detection. (arXiv:2106.08827v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ehsanpour_M/0/1/0/all/0/1">Mahsa Ehsanpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleh_F/0/1/0/all/0/1">Fatemeh Saleh</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1">Ian Reid</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezatofighi_H/0/1/0/all/0/1">Hamid Rezatofighi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08827">
                                    <div class="article-summary-box-inner">
                                        <span>The availability of large-scale video action understanding datasets has
facilitated advances in the interpretation of visual scenes containing people.
However, learning to recognize human activities in an unconstrained real-world
environment, with potentially highly unbalanced and long-tailed distributed
data remains a significant challenge, not least owing to the lack of a
reflective large-scale dataset. Most existing large-scale datasets are either
collected from a specific or constrained environment, e.g. kitchens or rooms,
or video sharing platforms such as YouTube. In this paper, we introduce
JRDB-Act, a multi-modal dataset, as an extension of the existing JRDB, which is
captured by asocial mobile manipulator and reflects a real distribution of
human daily life actions in a university campus environment. JRDB-Act has been
densely annotated with atomic actions, comprises over 2.8M action labels,
constituting a large-scale spatio-temporal action detection dataset. Each human
bounding box is labelled with one pose-based action label and multiple
(optional) interaction-based action labels. Moreover JRDB-Act comes with social
group identification annotations conducive to the task of grouping individuals
based on their interactions in the scene to infer their social activities
(common activities in each social group).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive coding feedback results in perceived illusory contours in a recurrent neural network. (arXiv:2102.01955v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_Z/0/1/0/all/0/1">Zhaoyang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+OMay_C/0/1/0/all/0/1">Callum Biggs O&#x27;May</a>, <a href="http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1">Bhavin Choksi</a>, <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01955">
                                    <div class="article-summary-box-inner">
                                        <span>Modern feedforward convolutional neural networks (CNNs) can now solve some
computer vision tasks at super-human levels. However, these networks only
roughly mimic human visual perception. One difference from human vision is that
they do not appear to perceive illusory contours (e.g. Kanizsa squares) in the
same way humans do. Physiological evidence from visual cortex suggests that the
perception of illusory contours could involve feedback connections. Would
recurrent feedback neural networks perceive illusory contours like humans? In
this work we equip a deep feedforward convolutional network with brain-inspired
recurrent dynamics. The network was first pretrained with an unsupervised
reconstruction objective on a natural image dataset, to expose it to natural
object contour statistics. Then, a classification decision layer was added and
the model was finetuned on a form discrimination task: squares vs. randomly
oriented inducer shapes (no illusory contour). Finally, the model was tested
with the unfamiliar &#x27;&#x27;illusory contour&#x27;&#x27; configuration: inducer shapes oriented
to form an illusory square. Compared with feedforward baselines, the iterative
&#x27;&#x27;predictive coding&#x27;&#x27; feedback resulted in more illusory contours being
classified as physical squares. The perception of the illusory contour was
measurable in the luminance profile of the image reconstructions produced by
the model, demonstrating that the model really &#x27;&#x27;sees&#x27;&#x27; the illusion. Ablation
studies revealed that natural image pretraining and feedback error correction
are both critical to the perception of the illusion. Finally we validated our
conclusions in a deeper network (VGG): adding the same predictive coding
feedback dynamics again leads to the perception of illusory contours.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1">Luka Murn</a>, <a href="http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1">Saverio Blasi</a>, <a href="http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1">Alan F. Smeaton</a>, <a href="http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1">Marta Mrak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08936">
                                    <div class="article-summary-box-inner">
                                        <span>The versatility of recent machine learning approaches makes them ideal for
improvement of next generation video compression solutions. Unfortunately,
these approaches typically bring significant increases in computational
complexity and are difficult to interpret into explainable models, affecting
their potential for implementation within practical video coding applications.
This paper introduces a novel explainable neural network-based inter-prediction
scheme, to improve the interpolation of reference samples needed for fractional
precision motion compensation. The approach requires a single neural network to
be trained from which a full quarter-pixel interpolation filter set is derived,
as the network is easily interpretable due to its linear structure. A novel
training framework enables each network branch to resemble a specific
fractional shift. This practical solution makes it very efficient to use
alongside conventional video coding schemes. When implemented in the context of
the state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and
2.25% BD-rate savings can be achieved on average for lower resolution sequences
under the random access, low-delay B and low-delay P configurations,
respectively, while the complexity of the learned interpolation schemes is
significantly reduced compared to the interpolation with full CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Over-and-Under Complete Convolutional RNN for MRI Reconstruction. (arXiv:2106.08886v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1">Pengfei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Puyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jinyuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shanshan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08886">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing magnetic resonance (MR) images from undersampled data is a
challenging problem due to various artifacts introduced by the under-sampling
operation. Recent deep learning-based methods for MR image reconstruction
usually leverage a generic auto-encoder architecture which captures low-level
features at the initial layers and high?level features at the deeper layers.
Such networks focus much on global features which may not be optimal to
reconstruct the fully-sampled image. In this paper, we propose an
Over-and-Under Complete Convolu?tional Recurrent Neural Network (OUCR), which
consists of an overcomplete and an undercomplete Convolutional Recurrent Neural
Network(CRNN). The overcomplete branch gives special attention in learning
local structures by restraining the receptive field of the network. Combining
it with the undercomplete branch leads to a network which focuses more on
low-level features without losing out on the global structures. Extensive
experiments on two datasets demonstrate that the proposed method achieves
significant improvements over the compressed sensing and popular deep
learning-based methods with less number of trainable parameters. Our code is
available at https://github.com/guopengf/OUCR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided interactive image segmentation using machine learning and color based data set clustering. (arXiv:2005.07662v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Friebel_A/0/1/0/all/0/1">Adrian Friebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Johann_T/0/1/0/all/0/1">Tim Johann</a>, <a href="http://arxiv.org/find/cs/1/au:+Drasdo_D/0/1/0/all/0/1">Dirk Drasdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoehme_S/0/1/0/all/0/1">Stefan Hoehme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07662">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach that combines machine learning based interactive
image segmentation with a two-stage clustering method to identify similarly
colored images for efficient batch image segmentation by guided reuse of
classifiers. The segmentation task is formulated as a supervised machine
learning problem working on homogeneous groups of voxels termed supervoxels.
Classifiers are interactively trained from sparse annotations in an iterative
process of annotation refinement. Resulting models can be used for batch
processing of previously unseen images. By clustering images into subsets of
similar colorization, we identify a minimal set of prototype images and
demonstrate that using only classifiers trained on these prototype images for
their color-cluster significantly improves the average segmentation performance
of batch processing. The presented methods are applicable for almost any image
type and therefore represent a useful tool for image analysis tasks in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_H/0/1/0/all/0/1">Hossein Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1">Liam Fowl</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08970">
                                    <div class="article-summary-box-inner">
                                        <span>As the curation of data for machine learning becomes increasingly automated,
dataset tampering is a mounting threat. Backdoor attackers tamper with training
data to embed a vulnerability in models that are trained on that data. This
vulnerability is then activated at inference time by placing a &quot;trigger&quot; into
the model&#x27;s input. Typical backdoor attacks insert the trigger directly into
the training data, although the presence of such an attack may be visible upon
inspection. In contrast, the Hidden Trigger Backdoor Attack achieves poisoning
without placing a trigger into the training data at all. However, this hidden
trigger attack is ineffective at poisoning neural networks trained from
scratch. We develop a new hidden trigger attack, Sleeper Agent, which employs
gradient matching, data selection, and target model re-training during the
crafting process. Sleeper Agent is the first hidden trigger backdoor attack to
be effective against neural networks trained from scratch. We demonstrate its
effectiveness on ImageNet and in black-box settings. Our implementation code
can be found at https://github.com/hsouri/Sleeper-Agent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving filling level classification with adversarial training. (arXiv:2102.04057v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Modas_A/0/1/0/all/0/1">Apostolos Modas</a>, <a href="http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1">Alessio Xompero</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_Matilla_R/0/1/0/all/0/1">Ricardo Sanchez-Matilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1">Pascal Frossard</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04057">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem of classifying - from a single image - the level
of content in a cup or a drinking glass. This problem is made challenging by
several ambiguities caused by transparencies, shape variations and partial
occlusions, and by the availability of only small training datasets. In this
paper, we tackle this problem with an appropriate strategy for transfer
learning. Specifically, we use adversarial training in a generic source dataset
and then refine the training with a task-specific dataset. We also discuss and
experimentally evaluate several training strategies and their combination on a
range of container types of the CORSMAL Containers Manipulation dataset. We
show that transfer learning with adversarial training in the source domain
consistently improves the classification accuracy on the test set and limits
the overfitting of the classifier to specific features of the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GelSight Wedge: Measuring High-Resolution 3D Contact Geometry with a Compact Robot Finger. (arXiv:2106.08851v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shaoxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Y/0/1/0/all/0/1">Yu She</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_B/0/1/0/all/0/1">Branden Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Adelson_E/0/1/0/all/0/1">Edward Adelson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08851">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-based tactile sensors have the potential to provide important contact
geometry to localize the objective with visual occlusion. However, it is
challenging to measure high-resolution 3D contact geometry for a compact robot
finger, to simultaneously meet optical and mechanical constraints. In this
work, we present the GelSight Wedge sensor, which is optimized to have a
compact shape for robot fingers, while achieving high-resolution 3D
reconstruction. We evaluate the 3D reconstruction under different lighting
configurations, and extend the method from 3 lights to 1 or 2 lights. We
demonstrate the flexibility of the design by shrinking the sensor to the size
of a human finger for fine manipulation tasks. We also show the effectiveness
and potential of the reconstructed 3D geometry for pose tracking in the 3D
space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lanfredi_R/0/1/0/all/0/1">Ricardo Bigolin Lanfredi</a>, <a href="http://arxiv.org/find/stat/1/au:+Schroeder_J/0/1/0/all/0/1">Joyce D. Schroeder</a>, <a href="http://arxiv.org/find/stat/1/au:+Tasdizen_T/0/1/0/all/0/1">Tolga Tasdizen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04709">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training, especially projected gradient descent (PGD), has been a
successful approach for improving robustness against adversarial attacks. After
adversarial training, gradients of models with respect to their inputs have a
preferential direction. However, the direction of alignment is not
mathematically well established, making it difficult to evaluate
quantitatively. We propose a novel definition of this direction as the
direction of the vector pointing toward the closest point of the support of the
closest inaccurate class in decision space. To evaluate the alignment with this
direction after adversarial training, we apply a metric that uses generative
adversarial networks to produce the smallest residual needed to change the
class present in the image. We show that PGD-trained models have a higher
alignment than the baseline according to our definition, that our metric
presents higher alignment values than a competing metric formulation, and that
enforcing this alignment increases the robustness of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI Classification. (arXiv:2106.08808v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1">Benoit Dufumier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1">Julie Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1">Antoine Grigis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wessa_M/0/1/0/all/0/1">Michel Wessa</a>, <a href="http://arxiv.org/find/cs/1/au:+Brambilla_P/0/1/0/all/0/1">Paolo Brambilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Favre_P/0/1/0/all/0/1">Pauline Favre</a>, <a href="http://arxiv.org/find/cs/1/au:+Polosan_M/0/1/0/all/0/1">Mircea Polosan</a>, <a href="http://arxiv.org/find/cs/1/au:+McDonald_C/0/1/0/all/0/1">Colm McDonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Piguet_C/0/1/0/all/0/1">Camille Marie Piguet</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1">Edouard Duchesnay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08808">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional supervised learning with deep neural networks requires a
tremendous amount of labelled data to converge to a good solution. For 3D
medical images, it is often impractical to build a large homogeneous annotated
dataset for a specific pathology. Self-supervised methods offer a new way to
learn a representation of the images in an unsupervised manner with a neural
network. In particular, contrastive learning has shown great promises by
(almost) matching the performance of fully-supervised CNN on vision tasks.
Nonetheless, this method does not take advantage of available meta-data, such
as participant&#x27;s age, viewed as prior knowledge. Here, we propose to leverage
continuous proxy metadata, in the contrastive learning framework, by
introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve
the positive sampling during pre-training by adding more positive examples with
similar proxy meta-data with the anchor, assuming they share similar
discriminative semantic features.With our method, a 3D CNN model pre-trained on
$10^4$ multi-site healthy brain MRI scans can extract relevant features for
three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer&#x27;s
detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on
these tasks, as well as state-of-the-art self-supervised methods. Our code is
made publicly available here.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An unifying point of view on expressive power of GNNs. (arXiv:2106.08992v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1">Giuseppe Alessio D&#x27;Inverno</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1">Monica Bianchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sampoli_M/0/1/0/all/0/1">Maria Lucia Sampoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1">Franco Scarselli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08992">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) are a wide class of connectionist models for
graph processing. They perform an iterative message passing operation on each
node and its neighbors, to solve classification/ clustering tasks --- on some
nodes or on the whole graph --- collecting all such messages, regardless of
their order. Despite the differences among the various models belonging to this
class, most of them adopt the same computation scheme, based on a local
aggregation mechanism and, intuitively, the local computation framework is
mainly responsible for the expressive power of GNNs. In this paper, we prove
that the Weisfeiler--Lehman test induces an equivalence relationship on the
graph nodes that exactly corresponds to the unfolding equivalence, defined on
the original GNN model. Therefore, the results on the expressive power of the
original GNNs can be extended to general GNNs which, under mild conditions, can
be proved capable of approximating, in probability and up to any precision, any
function on graphs that respects the unfolding equivalence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ruihao Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1">Mingzhu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fengwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shaoqing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shi Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09899">
                                    <div class="article-summary-box-inner">
                                        <span>User data confidentiality protection is becoming a rising challenge in the
present deep learning research. Without access to data, conventional
data-driven model compression faces a higher risk of performance degradation.
Recently, some works propose to generate images from a specific pretrained
model to serve as training data. However, the inversion process only utilizes
biased feature statistics stored in one model and is from low-dimension to
high-dimension. As a consequence, it inevitably encounters the difficulties of
generalizability and inexact inversion, which leads to unsatisfactory
performance. To address these problems, we propose MixMix based on two simple
yet effective techniques: (1) Feature Mixing: utilizes various models to
construct a universal feature space for generalized inversion; (2) Data Mixing:
mixes the synthesized images and labels to generate exact label information. We
prove the effectiveness of MixMix from both theoretical and empirical
perspectives. Extensive experiments show that MixMix outperforms existing
methods on the mainstream compression tasks, including quantization, knowledge
distillation, and pruning. Specifically, MixMix achieves up to 4% and 20%
accuracy uplift on quantization and pruning, respectively, compared to existing
data-free compression work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local plasticity rules can learn deep representations using self-supervised contrastive predictions. (arXiv:2010.08262v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Illing_B/0/1/0/all/0/1">Bernd Illing</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventura_J/0/1/0/all/0/1">Jean Ventura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1">Guillaume Bellec</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1">Wulfram Gerstner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08262">
                                    <div class="article-summary-box-inner">
                                        <span>Learning in the brain is poorly understood and learning rules that respect
biological constraints, yet yield deep hierarchical representations, are still
unknown. Here, we propose a learning rule that takes inspiration from
neuroscience and recent advances in self-supervised deep learning. Learning
minimizes a simple layer-specific loss function and does not need to
back-propagate error signals within or between layers. Instead, weight updates
follow a local, Hebbian, learning rule that only depends on pre- and
post-synaptic neuronal activity, predictive dendritic input and widely
broadcasted modulation factors which are identical for large groups of neurons.
The learning rule applies contrastive predictive learning to a causal,
biological setting using saccades (i.e. rapid shifts in gaze direction). We
find that networks trained with this self-supervised and local rule build deep
hierarchical representations of images, speech and video.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Image Compositions for Feature Representation Learning. (arXiv:2106.09011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cascante_Bonilla_P/0/1/0/all/0/1">Paola Cascante-Bonilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1">Arshdeep Sekhon</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yanjun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1">Vicente Ordonez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09011">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks for visual recognition require large amounts of
training samples and usually benefit from data augmentation. This paper
proposes PatchMix, a data augmentation method that creates new samples by
composing patches from pairs of images in a grid-like pattern. These new
samples&#x27; ground truth labels are set as proportional to the number of patches
from each image. We then add a set of additional losses at the patch-level to
regularize and to encourage good representations at both the patch and image
levels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior
transfer learning capabilities across a wide array of benchmarks. Although
PatchMix can rely on random pairings and random grid-like patterns for mixing,
we explore evolutionary search as a guiding strategy to discover optimal
grid-like patterns and image pairing jointly. For this purpose, we conceive a
fitness function that bypasses the need to re-train a model to evaluate each
choice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),
CIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant
margins, also outperforming previous state-of-the-art pairwise augmentation
strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects. (arXiv:2106.08762v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1">Denys Rozumnyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1">Martin R. Oswald</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1">Vittorio Ferrari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08762">
                                    <div class="article-summary-box-inner">
                                        <span>We address the novel task of jointly reconstructing the 3D shape, texture,
and motion of an object from a single motion-blurred image. While previous
approaches address the deblurring problem only in the 2D image domain, our
proposed rigorous modeling of all object properties in the 3D domain enables
the correct description of arbitrary object motion. This leads to significantly
better image decomposition and sharper deblurring results. We model the
observed appearance of a motion-blurred object as a combination of the
background and a 3D object with constant translation and rotation. Our method
minimizes a loss on reconstructing the input image via differentiable rendering
with suitable regularizers. This enables estimating the textured 3D mesh of the
blurred object with high fidelity. Our method substantially outperforms
competing approaches on several benchmarks for fast moving objects deblurring.
Qualitative results show that the reconstructed 3D mesh generates high-quality
temporal super-resolution and novel views of the deblurred object.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Robotic Weed Control: Detection of Nutsedge Weed in Bermudagrass Turf Using Inaccurate and Insufficient Training Data. (arXiv:2106.08897v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shuangyu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Chengsong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagavathiannan_M/0/1/0/all/0/1">Muthukumar Bagavathiannan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dezhen Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08897">
                                    <div class="article-summary-box-inner">
                                        <span>To enable robotic weed control, we develop algorithms to detect nutsedge weed
from bermudagrass turf. Due to the similarity between the weed and the
background turf, manual data labeling is expensive and error-prone.
Consequently, directly applying deep learning methods for object detection
cannot generate satisfactory results. Building on an instance detection
approach (i.e. Mask R-CNN), we combine synthetic data with raw data to train
the network. We propose an algorithm to generate high fidelity synthetic data,
adopting different levels of annotations to reduce labeling cost. Moreover, we
construct a nutsedge skeleton-based probabilistic map (NSPM) as the neural
network input to reduce the reliance on pixel-wise precise labeling. We also
modify loss function from cross entropy to Kullback-Leibler divergence which
accommodates uncertainty in the labeling process. We implement the proposed
algorithm and compare it with both Faster R-CNN and Mask R-CNN. The results
show that our design can effectively overcome the impact of imprecise and
insufficient training sample issues and significantly outperform the Faster
R-CNN counterpart with a false negative rate of only 0.4%. In particular, our
approach also reduces labeling time by 95% while achieving better performance
if comparing with the original Mask R-CNN approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence. (arXiv:2106.08710v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jacky Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1">Kit-Yung Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1">Lik-Hang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1">Pan Hui</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1">Xiang Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08710">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Augmented Reality (MAR) integrates computer-generated virtual objects
with physical environments for mobile devices. MAR systems enable users to
interact with MAR devices, such as smartphones and head-worn wearables, and
performs seamless transitions from the physical world to a mixed world with
digital entities. These MAR systems support user experiences by using MAR
devices to provide universal accessibility to digital contents. Over the past
20 years, a number of MAR systems have been developed, however, the studies and
design of MAR frameworks have not yet been systematically reviewed from the
perspective of user-centric design. This article presents the first effort of
surveying existing MAR frameworks (count: 37) and further discusses the latest
studies on MAR through a top-down approach: 1) MAR applications; 2) MAR
visualisation techniques adaptive to user mobility and contexts; 3) systematic
evaluation of MAR frameworks including supported platforms and corresponding
features such as tracking, feature extraction plus sensing capabilities; and 4)
underlying machine learning approaches supporting intelligent operations within
MAR systems. Finally, we summarise the development of emerging research fields,
current state-of-the-art, and discuss the important open challenges and
possible theoretical and technical directions. This survey aims to benefit both
researchers and MAR system developers alike.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimality of short-term synaptic plasticity in modelling certain dynamic environments. (arXiv:2009.06808v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1">Timoleon Moraitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1">Abu Sebastian</a>, <a href="http://arxiv.org/find/cs/1/au:+Eleftheriou_E/0/1/0/all/0/1">Evangelos Eleftheriou</a> (IBM Research - Zurich)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06808">
                                    <div class="article-summary-box-inner">
                                        <span>Biological neurons and their in-silico emulations for neuromorphic artificial
intelligence (AI) use extraordinarily energy-efficient mechanisms, such as
spike-based communication and local synaptic plasticity. It remains unclear
whether these neuronal mechanisms only offer efficiency or also underlie the
superiority of biological intelligence. Here, we prove rigorously that, indeed,
the Bayes-optimal prediction and inference of randomly but continuously
transforming environments, a common natural setting, relies on short-term
spike-timing-dependent plasticity, a hallmark of biological synapses. Further,
this dynamic Bayesian inference through plasticity enables circuits of the
cerebral cortex in simulations to recognize previously unseen, highly distorted
dynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,
the first to overcome multiple limitations of deep learning and outperform
artificial neural networks in a visual task. The cortical-like network is
spiking and event-based, trained only with unsupervised and local plasticity,
on a small, narrow, and static training dataset, but achieves recognition of
unseen, transformed, and dynamic data better than deep neural networks with
continuous activations, trained with supervised backpropagation on the
transforming data. These results link short-term plasticity to high-level
cortical function, suggest optimality of natural intelligence for natural
environments, and repurpose neuromorphic AI from mere efficiency to
computational supremacy altogether.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Oxford Road Boundaries Dataset. (arXiv:2106.08983v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suleymanov_T/0/1/0/all/0/1">Tarlan Suleymanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadd_M/0/1/0/all/0/1">Matthew Gadd</a>, <a href="http://arxiv.org/find/cs/1/au:+Martini_D/0/1/0/all/0/1">Daniele De Martini</a>, <a href="http://arxiv.org/find/cs/1/au:+Newman_P/0/1/0/all/0/1">Paul Newman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08983">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present the Oxford Road Boundaries Dataset, designed for
training and testing machine-learning-based road-boundary detection and
inference approaches. We have hand-annotated two of the 10 km-long forays from
the Oxford Robotcar Dataset and generated from other forays several thousand
further examples with semi-annotated road-boundary masks. To boost the number
of training samples in this way, we used a vision-based localiser to project
labels from the annotated datasets to other traversals at different times and
weather conditions. As a result, we release 62605 labelled samples, of which
47639 samples are curated. Each of these samples contains both raw and
classified masks for left and right lenses. Our data contains images from a
diverse set of scenarios such as straight roads, parked cars, junctions, etc.
Files for download and tools for manipulating the labelled data are available
at: oxford-robotics-institute.github.io/road-boundaries-dataset</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peijie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09373">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training has been the topic of dozens of studies and a leading
method for defending against adversarial attacks. Yet, it remains largely
unknown (a) how adversarially-robust ImageNet classifiers (R classifiers)
generalize to out-of-distribution examples; and (b) how their generalization
capability relates to their hidden representations. In this paper, we perform a
thorough, systematic study to answer these two questions across AlexNet,
GoogLeNet, and ResNet-50 architectures. We found that while standard ImageNet
classifiers have a strong texture bias, their R counterparts rely heavily on
shapes. Remarkably, adversarial training induces three simplicity biases into
hidden neurons in the process of &#x27;robustifying&#x27; the network. That is, each
convolutional neuron in R networks often changes to detecting (1) pixel-wise
smoother patterns i.e. a mechanism that blocks high-frequency noise from
passing through the network; (2) more lower-level features i.e. textures and
colors (instead of objects); and (3) fewer types of inputs. Our findings reveal
the interesting mechanisms that made networks more adversarially robust and
also explain some recent findings. Our findings reveal the interesting
mechanisms that made networks more adversarially robust and also explain some
recent findings e.g. why R networks benefit from much larger capacity (Xie and
Yuille, 2020) and can act as a strong image prior in image synthesis (Santurkar
et al., 2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invertible Attention. (arXiv:2106.09003v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_J/0/1/0/all/0/1">Jiajun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yiran Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartley_R/0/1/0/all/0/1">Richard Hartley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09003">
                                    <div class="article-summary-box-inner">
                                        <span>Attention has been proved to be an efficient mechanism to capture long-range
dependencies. However, so far it has not been deployed in invertible networks.
This is due to the fact that in order to make a network invertible, every
component within the network needs to be a bijective transformation, but a
normal attention block is not. In this paper, we propose invertible attention
that can be plugged into existing invertible models. We mathematically and
experimentally prove that the invertibility of an attention model can be
achieved by carefully constraining its Lipschitz constant. We validate the
invertibility of our invertible attention on image reconstruction task with 3
popular datasets: CIFAR-10, SVHN, and CelebA. We also show that our invertible
attention achieves similar performance in comparison with normal non-invertible
attention on dense prediction tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foo_L/0/1/0/all/0/1">Lin Geng Foo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiamei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Binder_A/0/1/0/all/0/1">Alexander Binder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10817">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of segmenting cell nuclei instances from Hematoxylin
and Eosin (H&amp;E) stains with dot annotations only. While most recent works focus
on improving the segmentation quality, this is usually insufficient for
instance segmentation of cell instances clustered together or with a small
size. In this work, we propose a simple two-step post-processing procedure,
Split and Expand, that directly improves the conversion of segmentation maps to
instances. In the splitting step, we generate fine-grained cell instances from
the segmentation map with the guidance of cell-center predictions. For the
expansion step, we utilize Layer-wise Relevance Propagation (LRP) explanation
results to add small cells that are not captured in the segmentation map.
Although we additionally train an output head to predict cell-centers, the
post-processing procedure itself is not explicitly trained and is executed at
inference-time only. A feature re-weighting loss based on LRP is proposed to
improve our method even further. We test our procedure on the MoNuSeg and TNBC
datasets and show quantitatively and qualitatively that our proposed method
improves object-level metrics substantially.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ParticleAugment: Sampling-Based Data Augmentation. (arXiv:2106.08693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsaregorodtsev_A/0/1/0/all/0/1">Alexander Tsaregorodtsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1">Vasileios Belagiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08693">
                                    <div class="article-summary-box-inner">
                                        <span>We present an automated data augmentation approach for image classification.
We formulate the problem as Monte Carlo sampling where our goal is to
approximate the optimal augmentation policies. We propose a particle filtering
formulation to find optimal augmentation policies and their schedules during
model training. Our performance measurement procedure relies on a validation
subset of our training set, while the policy transition model depends on a
Gaussian prior and an optional augmentation velocity parameter. In our
experiments, we show that our formulation for automated augmentation reaches
promising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the
standard network architectures for this problem. By comparing with the related
work, we also show that our method reaches a balance between the computational
cost of policy search and the model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polynomial Trajectory Predictions for Improved Learning Performance. (arXiv:2101.12616v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Freeman_I/0/1/0/all/0/1">Ido Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kummert_A/0/1/0/all/0/1">Anton Kummert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12616">
                                    <div class="article-summary-box-inner">
                                        <span>The rising demand for Active Safety systems in automotive applications
stresses the need for a reliable short to mid-term trajectory prediction.
Anticipating the unfolding path of road users, one can act to increase the
overall safety. In this work, we propose to train artificial neural networks
for movement understanding by predicting trajectories in their natural form, as
a function of time. Predicting polynomial coefficients allows us to increased
accuracy and improve generalisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization. (arXiv:2102.01670v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1">Kale-ab Tessera</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1">Benjamin Rosman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01670">
                                    <div class="article-summary-box-inner">
                                        <span>Training sparse networks to converge to the same performance as dense neural
architectures has proven to be elusive. Recent work suggests that
initialization is the key. However, while this direction of research has had
some success, focusing on initialization alone appears to be inadequate. In
this paper, we take a broader view of training sparse networks and consider the
role of regularization, optimization, and architecture choices on sparse
models. We propose a simple experimental framework, Same Capacity Sparse vs
Dense Comparison (SC-SDC), that allows for a fair comparison of sparse and
dense networks. Furthermore, we propose a new measure of gradient flow,
Effective Gradient Flow (EGF), that better correlates to performance in sparse
networks. Using top-line metrics, SC-SDC and EGF, we show that default choices
of optimizers, activation functions and regularizers used for dense networks
can disadvantage sparse networks. Based upon these findings, we show that
gradient flow in sparse networks can be improved by reconsidering aspects of
the architecture design and the training regime. Our work suggests that
initialization is only one piece of the puzzle and taking a wider view of
tailoring optimization to sparse networks yields promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Semantic-to-visual Confusion for Zero-shot Learning. (arXiv:2106.08605v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zihan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1">Fuyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_F/0/1/0/all/0/1">Fan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08605">
                                    <div class="article-summary-box-inner">
                                        <span>Using generative models to synthesize visual features from semantic
distribution is one of the most popular solutions to ZSL image classification
in recent years. The triplet loss (TL) is popularly used to generate realistic
visual distributions from semantics by automatically searching discriminative
representations. However, the traditional TL cannot search reliable unseen
disentangled representations due to the unavailability of unseen classes in
ZSL. To alleviate this drawback, we propose in this work a multi-modal triplet
loss (MMTL) which utilizes multimodal information to search a disentangled
representation space. As such, all classes can interplay which can benefit
learning disentangled class representations in the searched space. Furthermore,
we develop a novel model called Disentangling Class Representation Generative
Adversarial Network (DCR-GAN) focusing on exploiting the disentangled
representations in training, feature synthesis, and final recognition stages.
Benefiting from the disentangled representations, DCR-GAN could fit a more
realistic distribution over both seen and unseen features. Extensive
experiments show that our proposed model can lead to superior performance to
the state-of-the-arts on four benchmark datasets. Our code is available at
https://github.com/FouriYe/DCRGAN-TMM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI. (arXiv:2106.08706v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pandey_L/0/1/0/all/0/1">Laxmi Pandey</a>, <a href="http://arxiv.org/find/eess/1/au:+Arif_A/0/1/0/all/0/1">Ahmed Sabbir Arif</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08706">
                                    <div class="article-summary-box-inner">
                                        <span>Speech sounds of spoken language are obtained by varying configuration of the
articulators surrounding the vocal tract. They contain abundant information
that can be utilized to better understand the underlying mechanism of human
speech production. We propose a novel deep neural network-based learning
framework that understands acoustic information in the variable-length sequence
of vocal tract shaping during speech production, captured by real-time magnetic
resonance imaging (rtMRI), and translate it into text. The proposed framework
comprises of spatiotemporal convolutions, a recurrent network, and the
connectionist temporal classification loss, trained entirely end-to-end. On the
USC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better
compared to the existing models. To the best of our knowledge, this is the
first study that demonstrates the recognition of entire spoken sentence based
on an individual&#x27;s articulatory motions captured by rtMRI video. We also
performed an analysis of variations in the geometry of articulation in each
sub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard
palate, labial constriction region) with respect to different emotions and
genders. Results suggest that each sub-regions distortion is affected by both
emotion and gender.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shuffle Transformer with Feature Alignment for Video Face Parsing. (arXiv:2106.08650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zilong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Pei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guozhong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1">Gang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1">Bin Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08650">
                                    <div class="article-summary-box-inner">
                                        <span>This is a short technical report introducing the solution of the Team
TCParser for Short-video Face Parsing Track of The 3rd Person in Context (PIC)
Workshop and Challenge at CVPR 2021. In this paper, we introduce a strong
backbone which is cross-window based Shuffle Transformer for presenting
accurate face parsing representation. To further obtain the finer segmentation
results, especially on the edges, we introduce a Feature Alignment Aggregation
(FAA) module. It can effectively relieve the feature misalignment issue caused
by multi-resolution feature aggregation. Benefiting from the stronger backbone
and better feature aggregation, the proposed method achieves 86.9519% score in
the Short-video Face Parsing track of the 3rd Person in Context (PIC) Workshop
and Challenge, ranked the first place.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMF: Cascaded Multi-model Fusion for Referring Image Segmentation. (arXiv:2106.08617v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianhua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhanyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08617">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the task of referring image segmentation (RIS),
which aims at predicting a segmentation mask for the object described by a
natural language expression. Most existing methods focus on establishing
unidirectional or directional relationships between visual and linguistic
features to associate two modalities together, while the multi-scale context is
ignored or insufficiently modeled. Multi-scale context is crucial to localize
and segment those objects that have large scale variations during the
multi-modal fusion process. To solve this problem, we propose a simple yet
effective Cascaded Multi-modal Fusion (CMF) module, which stacks multiple
atrous convolutional layers in parallel and further introduces a cascaded
branch to fuse visual and linguistic features. The cascaded branch can
progressively integrate multi-scale contextual information and facilitate the
alignment of two modalities during the multi-modal fusion process. Experimental
results on four benchmark datasets demonstrate that our method outperforms most
state-of-the-art methods. Code is available at
https://github.com/jianhua2022/CMF-Refseg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">2nd Place Solution for Waymo Open Dataset Challenge - Real-time 2D Object Detection. (arXiv:2106.08713v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yueming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xiaolin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1">Bing Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_T/0/1/0/all/0/1">Tengfei Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yawei Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1">Haojin Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guoshan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pengfei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08713">
                                    <div class="article-summary-box-inner">
                                        <span>In an autonomous driving system, it is essential to recognize vehicles,
pedestrians and cyclists from images. Besides the high accuracy of the
prediction, the requirement of real-time running brings new challenges for
convolutional network models. In this report, we introduce a real-time method
to detect the 2D objects from images. We aggregate several popular one-stage
object detectors and train the models of variety input strategies
independently, to yield better performance for accurate multi-scale detection
of each category, especially for small objects. For model acceleration, we
leverage TensorRT to optimize the inference time of our detection pipeline. As
shown in the leaderboard, our proposed detection framework ranks the 2nd place
with 75.00% L1 mAP and 69.72% L2 mAP in the real-time 2D detection track of the
Waymo Open Dataset Challenges, while our framework achieves the latency of
45.8ms/frame on an Nvidia Tesla V100 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Semi-supervised Medical Image Classification via Inter-client Relation Matching. (arXiv:2106.08600v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Quande Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongzheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08600">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) has emerged with increasing popularity to collaborate
distributed medical institutions for training deep networks. However, despite
existing FL algorithms only allow the supervised training setting, most
hospitals in realistic usually cannot afford the intricate data labeling due to
absence of budget or expertise. This paper studies a practical yet challenging
FL problem, named \textit{Federated Semi-supervised Learning} (FSSL), which
aims to learn a federated model by jointly utilizing the data from both labeled
and unlabeled clients (i.e., hospitals). We present a novel approach for this
problem, which improves over traditional consistency regularization mechanism
with a new inter-client relation matching scheme. The proposed learning scheme
explicitly connects the learning across labeled and unlabeled clients by
aligning their extracted disease relationships, thereby mitigating the
deficiency of task knowledge at unlabeled clients and promoting discriminative
information from unlabeled samples. We validate our method on two large-scale
medical image classification datasets. The effectiveness of our method has been
demonstrated with the clear improvements over state-of-the-arts as well as the
thorough ablation analysis on both tasks\footnote{Code will be made available
at \url{https://github.com/liuquande/FedIRM}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection in Video Sequences: A Benchmark and Computational Model. (arXiv:2106.08570v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_B/0/1/0/all/0/1">Boyang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenhui Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuming Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhiyuan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guanqun Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08570">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection has attracted considerable search attention. However,
existing anomaly detection databases encounter two major problems. Firstly,
they are limited in scale. Secondly, training sets contain only video-level
labels indicating the existence of an abnormal event during the full video
while lacking annotations of precise time durations. To tackle these problems,
we contribute a new Large-scale Anomaly Detection (LAD) database as the
benchmark for anomaly detection in video sequences, which is featured in two
aspects. 1) It contains 2000 video sequences including normal and abnormal
video clips with 14 anomaly categories including crash, fire, violence, etc.
with large scene varieties, making it the largest anomaly analysis database to
date. 2) It provides the annotation data, including video-level labels
(abnormal/normal video, anomaly type) and frame-level labels (abnormal/normal
video frame) to facilitate anomaly detection. Leveraging the above benefits
from the LAD database, we further formulate anomaly detection as a
fully-supervised learning problem and propose a multi-task deep neural network
to solve it. We first obtain the local spatiotemporal contextual feature by
using an Inflated 3D convolutional (I3D) network. Then we construct a recurrent
convolutional neural network fed the local spatiotemporal contextual feature to
extract the spatiotemporal contextual feature. With the global spatiotemporal
contextual feature, the anomaly type and score can be computed simultaneously
by a multi-task neural network. Experimental results show that the proposed
method outperforms the state-of-the-art anomaly detection methods on our
database and other public databases of anomaly detection. Codes are available
at https://github.com/wanboyang/anomaly_detection_LAD2000.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compound Frechet Inception Distance for Quality Assessment of GAN Created Images. (arXiv:2106.08575v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nunn_E/0/1/0/all/0/1">Eric J. Nunn</a>, <a href="http://arxiv.org/find/cs/1/au:+Khadivi_P/0/1/0/all/0/1">Pejman Khadivi</a>, <a href="http://arxiv.org/find/cs/1/au:+Samavi_S/0/1/0/all/0/1">Shadrokh Samavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08575">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks or GANs are a type of generative modeling
framework. GANs involve a pair of neural networks engaged in a competition in
iteratively creating fake data, indistinguishable from the real data. One
notable application of GANs is developing fake human faces, also known as &quot;deep
fakes,&quot; due to the deep learning algorithms at the core of the GAN framework.
Measuring the quality of the generated images is inherently subjective but
attempts to objectify quality using standardized metrics have been made. One
example of objective metrics is the Frechet Inception Distance (FID), which
measures the difference between distributions of feature vectors for two
separate datasets of images. There are situations that images with low
perceptual qualities are not assigned appropriate FID scores. We propose to
improve the robustness of the evaluation process by integrating lower-level
features to cover a wider array of visual defects. Our proposed method
integrates three levels of feature abstractions to evaluate the quality of
generated images. Experimental evaluations show better performance of the
proposed method for distorted images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PatchNet: Unsupervised Object Discovery based on Patch Embedding. (arXiv:2106.08599v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moon_H/0/1/0/all/0/1">Hankyu Moon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1">Heng Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Didari_S/0/1/0/all/0/1">Sima Didari</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jae Oh Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bangert_P/0/1/0/all/0/1">Patrick Bangert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08599">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate that frequently appearing objects can be discovered by
training randomly sampled patches from a small number of images (100 to 200) by
self-supervision. Key to this approach is the pattern space, a latent space of
patterns that represents all possible sub-images of the given image data. The
distance structure in the pattern space captures the co-occurrence of patterns
due to the frequent objects. The pattern space embedding is learned by
minimizing the contrastive loss between randomly generated adjacent patches. To
prevent the embedding from learning the background, we modulate the contrastive
loss by color-based object saliency and background dissimilarity. The learned
distance structure serves as object memory, and the frequent objects are simply
discovered by clustering the pattern vectors from the random patches sampled
for inference. Our image representation based on image patches naturally
handles the position and scale invariance property that is crucial to
multi-object discovery. The method has been proven surprisingly effective, and
successfully applied to finding multiple human faces and bodies from natural
images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation. (arXiv:2106.08613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1">Chaewon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1">MyeongAh Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Minhyeok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangyoun Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08613">
                                    <div class="article-summary-box-inner">
                                        <span>Video anomaly detection has gained significant attention due to the
increasing requirements of automatic monitoring for surveillance videos.
Especially, the prediction based approach is one of the most studied methods to
detect anomalies by predicting frames that include abnormal events in the test
set after learning with the normal frames of the training set. However, a lot
of prediction networks are computationally expensive owing to the use of
pre-trained optical flow networks, or fail to detect abnormal situations
because of their strong generative ability to predict even the anomalies. To
address these shortcomings, we propose spatial rotation transformation (SRT)
and temporal mixing transformation (TMT) to generate irregular patch cuboids
within normal frame cuboids in order to enhance the learning of normal
features. Additionally, the proposed patch transformation is used only during
the training phase, allowing our model to detect abnormal frames at fast speed
during inference. Our model is evaluated on three anomaly detection benchmarks,
achieving competitive accuracy and surpassing all the previous works in terms
of speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Consistency Regularization for Unsupervised Multi-source Domain Adaptive Classification. (arXiv:2106.08590v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhipeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaobing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08590">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based multi-source unsupervised domain adaptation (MUDA) has
been actively studied in recent years. Compared with single-source unsupervised
domain adaptation (SUDA), domain shift in MUDA exists not only between the
source and target domains but also among multiple source domains. Most existing
MUDA algorithms focus on extracting domain-invariant representations among all
domains whereas the task-specific decision boundaries among classes are largely
neglected. In this paper, we propose an end-to-end trainable network that
exploits domain Consistency Regularization for unsupervised Multi-source domain
Adaptive classification (CRMA). CRMA aligns not only the distributions of each
pair of source and target domains but also that of all domains. For each pair
of source and target domains, we employ an intra-domain consistency to
regularize a pair of domain-specific classifiers to achieve intra-domain
alignment. In addition, we design an inter-domain consistency that targets
joint inter-domain alignment among all domains. To address different
similarities between multiple source domains and the target domain, we design
an authorization strategy that assigns different authorities to domain-specific
classifiers adaptively for optimal pseudo label prediction and self-training.
Extensive experiments show that CRMA tackles unsupervised domain adaptation
effectively under a multi-source setup and achieves superior adaptation
consistently across multiple MUDA datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisit Visual Representation in Analytics Taxonomy: A Compression Perspective. (arXiv:2106.08512v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yueyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenhan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haofeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaying Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08512">
                                    <div class="article-summary-box-inner">
                                        <span>Visual analytics have played an increasingly critical role in the Internet of
Things, where massive visual signals have to be compressed and fed into
machines. But facing such big data and constrained bandwidth capacity, existing
image/video compression methods lead to very low-quality representations, while
existing feature compression techniques fail to support diversified visual
analytics applications/tasks with low-bit-rate representations. In this paper,
we raise and study the novel problem of supporting multiple machine vision
analytics tasks with the compressed visual representation, namely, the
information compression problem in analytics taxonomy. By utilizing the
intrinsic transferability among different tasks, our framework successfully
constructs compact and expressive representations at low bit-rates to support a
diversified set of machine vision tasks, including both high-level
semantic-related tasks and mid-level geometry analytic tasks. In order to
impose compactness in the representations, we propose a codebook-based
hyperprior, which helps map the representation into a low-dimensional manifold.
As it well fits the signal structure of the deep visual feature, it facilitates
more accurate entropy estimation, and results in higher compression efficiency.
With the proposed framework and the codebook-based hyperprior, we further
investigate the relationship of different task features owning different levels
of abstraction granularity. Experimental results demonstrate that with the
proposed scheme, a set of diversified tasks can be supported at a significantly
lower bit-rate, compared with existing compression schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised-learning-based method for chest MRI-CT transformation using structure constrained unsupervised generative attention networks. (arXiv:2106.08557v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matsuo_H/0/1/0/all/0/1">Hidetoshi Matsuo</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Nishio_M/0/1/0/all/0/1">Mizuho Nishio</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Nogami_M/0/1/0/all/0/1">Munenobu Nogami</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1">Feibi Zeng</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Kurimoto_T/0/1/0/all/0/1">Takako Kurimoto</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Kaushik_S/0/1/0/all/0/1">Sandeep Kaushik</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Wiesinger_F/0/1/0/all/0/1">Florian Wiesinger</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Kono_A/0/1/0/all/0/1">Atsushi K Kono</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1">Takamichi Murakami</a> (1) ((1) Department of Radiology, Kobe University Graduate School of Medicine, Kobe, Japan, (2) GE Healthcare, Hino, Japan and (3) GE Healthcare, Munich, Germany)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08557">
                                    <div class="article-summary-box-inner">
                                        <span>The integrated positron emission tomography/magnetic resonance imaging
(PET/MRI) scanner facilitates the simultaneous acquisition of metabolic
information via PET and morphological information with high soft-tissue
contrast using MRI. Although PET/MRI facilitates the capture of high-accuracy
fusion images, its major drawback can be attributed to the difficulty
encountered when performing attenuation correction, which is necessary for
quantitative PET evaluation. The combined PET/MRI scanning requires the
generation of attenuation-correction maps from MRI owing to no direct
relationship between the gamma-ray attenuation information and MRIs. While
MRI-based bone-tissue segmentation can be readily performed for the head and
pelvis regions, the realization of accurate bone segmentation via chest CT
generation remains a challenging task. This can be attributed to the
respiratory and cardiac motions occurring in the chest as well as its
anatomically complicated structure and relatively thin bone cortex. This paper
presents a means to minimise the anatomical structural changes without human
annotation by adding structural constraints using a modality-independent
neighbourhood descriptor (MIND) to a generative adversarial network (GAN) that
can transform unpaired images. The results obtained in this study revealed the
proposed U-GAT-IT + MIND approach to outperform all other competing approaches.
The findings of this study hint towards possibility of synthesising clinically
acceptable CT images from chest MRI without human annotation, thereby
minimising the changes in the anatomical structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Watching Too Much Television is Good: Self-Supervised Audio-Visual Representation Learning from Movies and TV Shows. (arXiv:2106.08513v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalayeh_M/0/1/0/all/0/1">Mahdi M. Kalayeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_N/0/1/0/all/0/1">Nagendra Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandrashekar_A/0/1/0/all/0/1">Ashok Chandrashekar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08513">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance and ease of utilizing sound, along with the fact that auditory
clues reveal so much about what happens in the scene, make the audio-visual
space a perfectly intuitive choice for self-supervised representation learning.
However, the current literature suggests that training on \textit{uncurated}
data yields considerably poorer representations compared to the
\textit{curated} alternatives collected in supervised manner, and the gap only
narrows when the volume of data significantly increases. Furthermore, the
quality of learned representations is known to be heavily influenced by the
size and taxonomy of the curated datasets used for self-supervised training.
This begs the question of whether we are celebrating too early on catching up
with supervised learning when our self-supervised efforts still rely almost
exclusively on curated data. In this paper, we study the efficacy of learning
from Movies and TV Shows as forms of uncurated data for audio-visual
self-supervised learning. We demonstrate that a simple model based on
contrastive learning, trained on a collection of movies and TV shows, not only
dramatically outperforms more complex methods which are trained on orders of
magnitude larger uncurated datasets, but also performs very competitively with
the state-of-the-art that learns from large-scale curated data. We identify
that audiovisual patterns like the appearance of the main character or
prominent scenes and mise-en-sc\&#x60;ene which frequently occur through the whole
duration of a movie, lead to an overabundance of easy negative instances in the
contrastive learning formulation. Capitalizing on such observation, we propose
a hierarchical sampling policy, which despite its simplicity, effectively
improves the performance, particularly when learning from TV shows which
naturally face less semantic diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning-based analysis of hyperspectral images for automated sepsis diagnosis. (arXiv:2106.08445v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_M/0/1/0/all/0/1">Maximilian Dietrich</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Seidlitz_S/0/1/0/all/0/1">Silvia Seidlitz</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Schreck_N/0/1/0/all/0/1">Nicholas Schreck</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1">Manuel Wiesenfarth</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1">Patrick Godau</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Tizabi_M/0/1/0/all/0/1">Minu Tizabi</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Sellner_J/0/1/0/all/0/1">Jan Sellner</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Marx_S/0/1/0/all/0/1">Sebastian Marx</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Knodler_S/0/1/0/all/0/1">Samuel Kn&#xf6;dler</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Allers_M/0/1/0/all/0/1">Michael M. Allers</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Ayala_L/0/1/0/all/0/1">Leonardo Ayala</a> (2, 7), <a href="http://arxiv.org/find/cs/1/au:+Schmidt_K/0/1/0/all/0/1">Karsten Schmidt</a> (8), <a href="http://arxiv.org/find/cs/1/au:+Brenner_T/0/1/0/all/0/1">Thorsten Brenner</a> (8), <a href="http://arxiv.org/find/cs/1/au:+Studier_Fischer_A/0/1/0/all/0/1">Alexander Studier-Fischer</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Nickel_F/0/1/0/all/0/1">Felix Nickel</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Muller_Stich_B/0/1/0/all/0/1">Beat P. M&#xfc;ller-Stich</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Kopp_Schneider_A/0/1/0/all/0/1">Annette Kopp-Schneider</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Weigand_M/0/1/0/all/0/1">Markus A. Weigand</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1">Lena Maier-Hein</a> (2, 6, 7) ((1) Department of Anesthesiology, Heidelberg University Hospital, Heidelberg, Germany, (2) Division of Computer Assisted Medical Interventions, German Cancer Research Center (DKFZ), Heidelberg, Germany, (3) HIDSS4Health - Helmholtz Information and Data Science School for Health, Karlsruhe/Heidelberg, Germany (4) Division of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, Germany, (5) Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany, (6) Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany, (7) Medical Faculty, Heidelberg University, Heidelberg, Germany, (8) Department of Anesthesiology and Intensive Care Medicine, University Hospital Essen, University Duisburg-Essen, Essen, Germany)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08445">
                                    <div class="article-summary-box-inner">
                                        <span>Sepsis is a leading cause of mortality and critical illness worldwide. While
robust biomarkers for early diagnosis are still missing, recent work indicates
that hyperspectral imaging (HSI) has the potential to overcome this bottleneck
by monitoring microcirculatory alterations. Automated machine learning-based
diagnosis of sepsis based on HSI data, however, has not been explored to date.
Given this gap in the literature, we leveraged an existing data set to (1)
investigate whether HSI-based automated diagnosis of sepsis is possible and (2)
put forth a list of possible confounders relevant for HSI-based tissue
classification. While we were able to classify sepsis with an accuracy of over
$98\,\%$ using the existing data, our research also revealed several subject-,
therapy- and imaging-related confounders that may lead to an overestimation of
algorithm performance when not balanced across the patient groups. We conclude
that further prospective studies, carefully designed with respect to these
confounders, are necessary to confirm the preliminary results obtained in this
study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Achieving Domain Robustness in Stereo Matching Networks by Removing Shortcut Learning. (arXiv:2106.08486v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chuah_W/0/1/0/all/0/1">WeiQin Chuah</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennakoon_R/0/1/0/all/0/1">Ruwan Tennakoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bab_Hadiashar_A/0/1/0/all/0/1">Alireza Bab-Hadiashar</a>, <a href="http://arxiv.org/find/cs/1/au:+Suter_D/0/1/0/all/0/1">David Suter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08486">
                                    <div class="article-summary-box-inner">
                                        <span>Learning-based stereo matching and depth estimation networks currently excel
on public benchmarks with impressive results. However, state-of-the-art
networks often fail to generalize from synthetic imagery to more challenging
real data domains. This paper is an attempt to uncover hidden secrets of
achieving domain robustness and in particular, discovering the important
ingredients of generalization success of stereo matching networks by analyzing
the effect of synthetic image learning on real data performance. We provide
evidence that demonstrates that learning of features in the synthetic domain by
a stereo matching network is heavily influenced by two &quot;shortcuts&quot; presented in
the synthetic data: (1) identical local statistics (RGB colour features)
between matching pixels in the synthetic stereo images and (2) lack of realism
in synthetic textures on 3D objects simulated in game engines. We will show
that by removing such shortcuts, we can achieve domain robustness in the
state-of-the-art stereo matching frameworks and produce a remarkable
performance on multiple realistic datasets, despite the fact that the networks
were trained on synthetic data, only. Our experimental results point to the
fact that eliminating shortcuts from the synthetic data is key to achieve
domain-invariant generalization between synthetic and real data domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Implicit Glyph Shape Representation. (arXiv:2106.08573v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ying-Tian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuan-Chen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi-Xiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Song-Hai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08573">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel implicit glyph shape representation, which
models glyphs as shape primitives enclosed by quadratic curves, and naturally
enables generating glyph images at arbitrary high resolutions. Experiments on
font reconstruction and interpolation tasks verified that this structured
implicit representation is suitable for describing both structure and style
features of glyphs. Furthermore, based on the proposed representation, we
design a simple yet effective disentangled network for the challenging one-shot
font style transfer problem, and achieve the best results comparing to
state-of-the-art alternatives in both quantitative and qualitative comparisons.
Benefit from this representation, our generated glyphs have the potential to be
converted to vector fonts through post-processing, reducing the gap between
rasterized images and vector graphics. We hope this work can provide a powerful
tool for 2D shape analysis and synthesis, and inspire further exploitation in
implicit representations for 2D shape modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Convolution Networks with Positional Encoding for Evoked Expression Estimation. (arXiv:2106.08596v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huynh_V/0/1/0/all/0/1">VanThong Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Guee-Sang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hyung-Jeong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soo-Huyng Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08596">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an approach for Evoked Expressions from Videos (EEV)
challenge, which aims to predict evoked facial expressions from video. We take
advantage of pre-trained models on large-scale datasets in computer vision and
audio signals to extract the deep representation of timestamps in the video. A
temporal convolution network, rather than an RNN like architecture, is used to
explore temporal relationships due to its advantage in memory consumption and
parallelism. Furthermore, to address the missing annotations of some
timestamps, positional encoding is employed to ensure continuity of input data
when discarding these timestamps during training. We achieved state-of-the-art
results on the EEV challenge with a Pearson correlation coefficient of 0.05477,
the first ranked performance in the EEV 2021 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Resolution Continuous Normalizing Flows. (arXiv:2106.08462v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Finlay_C/0/1/0/all/0/1">Chris Finlay</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08462">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that Neural Ordinary Differential Equations (ODEs) can
serve as generative models of images using the perspective of Continuous
Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and
invertible generation/density estimation. In this work we introduce a
Multi-Resolution variant of such models (MRCNF), by characterizing the
conditional distribution over the additional information required to generate a
fine image that is consistent with the coarse image. We introduce a
transformation between resolutions that allows for no change in the log
likelihood. We show that this approach yields comparable likelihood values for
various image datasets, with improved performance at higher resolutions, with
fewer parameters, using only 1 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tackling the Challenges in Scene Graph Generation with Local-to-Global Interactions. (arXiv:2106.08543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sangmin Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Noh_J/0/1/0/all/0/1">Junhyug Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kangil Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08543">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we seek new insights into the underlying challenges of the
Scene Graph Generation (SGG) task. Quantitative and qualitative analysis of the
Visual Genome dataset implies -- 1) Ambiguity: even if inter-object
relationship contains the same object (or predicate), they may not be visually
or semantically similar, 2) Asymmetry: despite the nature of the relationship
that embodied the direction, it was not well addressed in previous studies, and
3) Higher-order contexts: leveraging the identities of certain graph elements
can help to generate accurate scene graphs. Motivated by the analysis, we
design a novel SGG framework, Local-to-Global Interaction Networks (LOGIN).
Locally, interactions extract the essence between three instances - subject,
object, and background - while baking direction awareness into the network by
constraining the input order. Globally, interactions encode the contexts
between every graph components -- nodes and edges. Also we introduce Attract &amp;
Repel loss which finely adjusts predicate embeddings. Our framework enables
predicting the scene graph in a local-to-global manner by design, leveraging
the possible complementariness. To quantify how much LOGIN is aware of
relational direction, we propose a new diagnostic task called Bidirectional
Relationship Classification (BRC). We see that LOGIN can successfully
distinguish relational direction than existing methods (in BRC task) while
showing state-of-the-art results on the Visual Genome benchmark (in SGG task).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1">Celso A. M. Lopes Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1">Ricardo B. das Neves Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1">Byron L. D. Bezerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1">Alejandro H. Toselli</a>, <a href="http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1">Donato Impedovo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the short-term competition on Components Segmentation
Task of Document Photos that was prepared in the context of the 16th
International Conference on Document Analysis and Recognition (ICDAR 2021).
This competition aims to bring together researchers working on the filed of
identification document image processing and provides them a suitable benchmark
to compare their techniques on the component segmentation task of document
images. Three challenge tasks were proposed entailing different segmentation
assignments to be performed on a provided dataset. The collected data are from
several types of Brazilian ID documents, whose personal information was
conveniently replaced. There were 16 participants whose results obtained for
some or all the three tasks show different rates for the adopted metrics, like
Dice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning
models were applied by the entrants with diverse strategies to achieve the best
results in each of the tasks. Obtained results show that the current applied
methods for solving one of the proposed tasks (document boundary detection) are
already well stablished. However, for the other two challenge tasks (text zone
and handwritten sign detection) research and development of more robust
approaches are still required to achieve acceptable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-shot Learning. (arXiv:2106.08523v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaofan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoshan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Changsheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuhui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhe Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08523">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the transductive graph-based methods have achieved great success in
the few-shot classification task. However, most existing methods ignore
exploring the class-level knowledge that can be easily learned by humans from
just a handful of samples. In this paper, we propose an Explicit Class
Knowledge Propagation Network (ECKPN), which is composed of the comparison,
squeeze and calibration modules, to address this problem. Specifically, we
first employ the comparison module to explore the pairwise sample relations to
learn rich sample representations in the instance-level graph. Then, we squeeze
the instance-level graph to generate the class-level graph, which can help
obtain the class-level visual knowledge and facilitate modeling the relations
of different classes. Next, the calibration module is adopted to characterize
the relations of the classes explicitly to obtain the more discriminative
class-level knowledge representations. Finally, we combine the class-level
knowledge with the instance-level sample representations to guide the inference
of the query samples. We conduct extensive experiments on four few-shot
classification benchmarks, and the experimental results show that the proposed
ECKPN significantly outperforms the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scene Transformer: A unified multi-task model for behavior prediction and planning. (arXiv:2106.08417v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngiam_J/0/1/0/all/0/1">Jiquan Ngiam</a>, <a href="http://arxiv.org/find/cs/1/au:+Caine_B/0/1/0/all/0/1">Benjamin Caine</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1">Vijay Vasudevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hao-Tien Lewis Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1">Jeffrey Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1">Alex Bewley</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chenxi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1">Ashish Venugopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_D/0/1/0/all/0/1">David Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1">Ben Sapp</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1">Jonathon Shlens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08417">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the future motion of multiple agents is necessary for planning in
dynamic environments. This task is challenging for autonomous driving since
agents (e.g., vehicles and pedestrians) and their associated behaviors may be
diverse and influence each other. Most prior work has focused on first
predicting independent futures for each agent based on all past motion, and
then planning against these independent predictions. However, planning against
fixed predictions can suffer from the inability to represent the future
interaction possibilities between different agents, leading to sub-optimal
planning. In this work, we formulate a model for predicting the behavior of all
agents jointly in real-world driving environments in a unified manner. Inspired
by recent language modeling approaches, we use a masking strategy as the query
to our model, enabling one to invoke a single model to predict agent behavior
in many ways, such as potentially conditioned on the goal or full future
trajectory of the autonomous vehicle or the behavior of other agents in the
environment. Our model architecture fuses heterogeneous world state in a
unified Transformer architecture by employing attention across road elements,
agent interactions and time steps. We evaluate our approach on autonomous
driving datasets for behavior prediction, and achieve state-of-the-art
performance. Our work demonstrates that formulating the problem of behavior
prediction in a unified architecture with a masking strategy may allow us to
have a single model that can perform multiple motion prediction and planning
related tasks effectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing Through Clouds in Satellite Images. (arXiv:2106.08408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mingmin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Olsen_P/0/1/0/all/0/1">Peder A. Olsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Ranveer Chandra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08408">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a neural-network-based solution to recover pixels
occluded by clouds in satellite images. We leverage radio frequency (RF)
signals in the ultra/super-high frequency band that penetrate clouds to help
reconstruct the occluded regions in multispectral images. We introduce the
first multi-modal multi-temporal cloud removal model. Our model uses publicly
available satellite observations and produces daily cloud-free images.
Experimental results show that our system significantly outperforms baselines
by 8dB in PSNR. We also demonstrate use cases of our system in digital
agriculture, flood monitoring, and wildfire detection. We will release the
processed dataset to facilitate future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-scale Neural ODEs for 3D Medical Image Registration. (arXiv:2106.08493v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Junshen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Eric Z. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Terrence Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Shanhui Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08493">
                                    <div class="article-summary-box-inner">
                                        <span>Image registration plays an important role in medical image analysis.
Conventional optimization based methods provide an accurate estimation due to
the iterative process at the cost of expensive computation. Deep learning
methods such as learn-to-map are much faster but either iterative or
coarse-to-fine approach is required to improve accuracy for handling large
motions. In this work, we proposed to learn a registration optimizer via a
multi-scale neural ODE model. The inference consists of iterative gradient
updates similar to a conventional gradient descent optimizer but in a much
faster way, because the neural ODE learns from the training data to adapt the
gradient efficiently at each iteration. Furthermore, we proposed to learn a
modal-independent similarity metric to address image appearance variations
across different image contrasts. We performed evaluations through extensive
experiments in the context of multi-contrast 3D MR images from both public and
private data sources and demonstrate the superior performance of our proposed
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GKNet: grasp keypoint network for grasp candidates detection. (arXiv:2106.08497v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruinian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_F/0/1/0/all/0/1">Fu-Jen Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vela_P/0/1/0/all/0/1">Patricio A. Vela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08497">
                                    <div class="article-summary-box-inner">
                                        <span>Contemporary grasp detection approaches employ deep learning to achieve
robustness to sensor and object model uncertainty. The two dominant approaches
design either grasp-quality scoring or anchor-based grasp recognition networks.
This paper presents a different approach to grasp detection by treating it as
keypoint detection. The deep network detects each grasp candidate as a pair of
keypoints, convertible to the grasp representation g &#x3D; {x, y, w, {\theta}}^T,
rather than a triplet or quartet of corner points. Decreasing the detection
difficulty by grouping keypoints into pairs boosts performance. To further
promote dependencies between keypoints, the general non-local module is
incorporated into the proposed learning framework. A final filtering strategy
based on discrete and continuous orientation prediction removes false
correspondences and further improves grasp detection performance. GKNet, the
approach presented here, achieves the best balance of accuracy and speed on the
Cornell and the abridged Jacquard dataset (96.9% and 98.39% at 41.67 and 23.26
fps). Follow-up experiments on a manipulator evaluate GKNet using 4 types of
grasping experiments reflecting different nuisance sources: static grasping,
dynamic grasping, grasping at varied camera angles, and bin picking. GKNet
outperforms reference baselines in static and dynamic grasping experiments
while showing robustness to varied camera viewpoints and bin picking
experiments. The results confirm the hypothesis that grasp keypoints are an
effective output representation for deep grasp networks that provide robustness
to expected nuisance factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving. (arXiv:2106.08372v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_A/0/1/0/all/0/1">Anthony Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Max Paul Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Resch_M/0/1/0/all/0/1">Michael Resch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08372">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing safety validation requirements for the release of a
self-driving car, alternative approaches, such as simulation-based testing, are
emerging in addition to conventional real-world testing. In order to rely on
virtual tests the employed sensor models have to be validated. For this reason,
it is necessary to quantify the discrepancy between simulation and reality in
order to determine whether a certain fidelity is sufficient for a desired
intended use. There exists no sound method to measure this
simulation-to-reality gap of radar perception for autonomous driving. We
address this problem by introducing a multi-layered evaluation approach, which
consists of a combination of an explicit and an implicit sensor model
evaluation. The former directly evaluates the realism of the synthetically
generated sensor data, while the latter refers to an evaluation of a downstream
target application. In order to demonstrate the method, we evaluated the
fidelity of three typical radar model types (ideal, data-driven, ray
tracing-based) and their applicability for virtually testing radar-based
multi-object tracking. We have shown the effectiveness of the proposed approach
in terms of providing an in-depth sensor model assessment that renders existing
disparities visible and enables a realistic estimation of the overall model
fidelity across different scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining decision of model from its prediction. (arXiv:2106.08366v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tamboli_D/0/1/0/all/0/1">Dipesh Tamboli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08366">
                                    <div class="article-summary-box-inner">
                                        <span>This document summarizes different visual explanations methods such as CAM,
Grad-CAM, Localization using Multiple Instance Learning - Saliency-based
methods, Saliency-driven Class-Impressions, Muting pixels in input image -
Adversarial methods and Activation visualization, Convolution filter
visualization - Feature-based methods. We have also shown the results produced
by different methods and a comparison between CAM, GradCAM, and Guided
Backpropagation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08382">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism of late has been quite popular in the computer vision
community. A lot of work has been done to improve the performance of the
network, although almost always it results in increased computational
complexity. In this paper, we propose a new attention module that not only
achieves the best performance but also has lesser parameters compared to most
existing models. Our attention module can easily be integrated with other
convolutional neural networks because of its lightweight nature. The proposed
network named Dual Multi Scale Attention Network (DMSANet) is comprised of two
parts: the first part is used to extract features at various scales and
aggregate them, the second part uses spatial and channel attention modules in
parallel to adaptively integrate local features with their global dependencies.
We benchmark our network performance for Image Classification on ImageNet
dataset, Object Detection and Instance Segmentation both on MS COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Better Understanding of Linear Models for Recommendation. (arXiv:2105.12937v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Ruoming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jing Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12937">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, linear regression models, such as EASE and SLIM, have shown to
often produce rather competitive results against more sophisticated deep
learning models. On the other side, the (weighted) matrix factorization
approaches have been popular choices for recommendation in the past and widely
adopted in the industry. In this work, we aim to theoretically understand the
relationship between these two approaches, which are the cornerstones of
model-based recommendations. Through the derivation and analysis of the
closed-form solutions for two basic regression and matrix factorization
approaches, we found these two approaches are indeed inherently related but
also diverge in how they &quot;scale-down&quot; the singular values of the original
user-item interaction matrix. This analysis also helps resolve the questions
related to the regularization parameter range and model complexities. We
further introduce a new learning algorithm in searching (hyper)parameters for
the closed-form solution and utilize it to discover the nearby models of the
existing solutions. The experimental results demonstrate that the basic models
and their closed-form solutions are indeed quite competitive against the
state-of-the-art models, thus, confirming the validity of studying the basic
models. The effectiveness of exploring the nearby models are also
experimentally validated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1">Damir Koren&#x10d;i&#x107;</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1">Strahil Ristov</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1">Jelena Repar</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06274">
                                    <div class="article-summary-box-inner">
                                        <span>Topic models are widely used unsupervised models of text capable of learning
topics - weighted lists of words and documents - from large collections of text
documents. When topic models are used for discovery of topics in text
collections, a question that arises naturally is how well the model-induced
topics correspond to topics of interest to the analyst. In this paper we
revisit and extend a so far neglected approach to topic model evaluation based
on measuring topic coverage - computationally matching model topics with a set
of reference topics that models are expected to uncover. The approach is well
suited for analyzing models&#x27; performance in topic discovery and for large-scale
analysis of both topic models and measures of model quality. We propose new
measures of coverage and evaluate, in a series of experiments, different types
of topic models on two distinct text domains for which interest for topic
discovery exists. The experiments include evaluation of model quality, analysis
of coverage of distinct topic categories, and the analysis of the relationship
between coverage and other methods of topic model evaluation. The contributions
of the paper include new measures of coverage, insights into both topic models
and other methods of model evaluation, and the datasets and code for
facilitating future research of both topic coverage and other approaches to
topic model evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal and specific features of Ukrainian economic research: publication analysis based on Crossref data. (arXiv:2106.08701v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mryglod_O/0/1/0/all/0/1">O. Mryglod</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazarovets_S/0/1/0/all/0/1">S. Nazarovets</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozmenko_S/0/1/0/all/0/1">S. Kozmenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08701">
                                    <div class="article-summary-box-inner">
                                        <span>Our study is one of the first examples of multidimensional and longitudinal
disciplinary analysis at the national level based on Crossref data. We present
a large-scale quantitative analysis of Ukrainian economics. This study is not
yet another example of research aimed at ranking of local journals, authors or
institutions, but rather exploring general tendencies that can be compared to
other countries or regions. We study different aspects of Ukrainian economics
output. In particular, the collaborative nature, geographic landscape and some
peculiarities of citation statistics are investigated. We have found that
Ukrainian economics is characterized by a comparably small share of co-authored
publications, however, it demonstrates the tendency towards more collaborative
output. Based on our analysis, we discuss specific and universal features of
Ukrainian economic research. The importance of supporting various initiatives
aimed at enriching open scholarly metadata is considered. A comprehensive and
high-quality meta description of publications is probably the shortest path to
a better understanding of national trends, especially for non-English speaking
countries. The results of our analysis can be used to better understand
Ukrainian economic research and support research policy decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSSuBERT: Tweet Stream Summarization Using BERT. (arXiv:2106.08770v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dusart_A/0/1/0/all/0/1">Alexis Dusart</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinel_Sauvagnat_K/0/1/0/all/0/1">Karen Pinel-Sauvagnat</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubert_G/0/1/0/all/0/1">Gilles Hubert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08770">
                                    <div class="article-summary-box-inner">
                                        <span>The development of deep neural networks and the emergence of pre-trained
language models such as BERT allow to increase performance on many NLP tasks.
However, these models do not meet the same popularity for tweet summarization,
which can probably be explained by the lack of existing collections for
training and evaluation. Our contribution in this paper is twofold : (1) we
introduce a large dataset for Twitter event summarization, and (2) we propose a
neural model to automatically summarize huge tweet streams. This extractive
model combines in an original way pre-trained language models and vocabulary
frequency-based representations to predict tweet salience. An additional
advantage of the model is that it automatically adapts the size of the output
summary according to the input tweet stream. We conducted experiments using two
different Twitter collections, and promising results are observed in comparison
with state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized News Recommendation: A Survey. (arXiv:2106.08934v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08934">
                                    <div class="article-summary-box-inner">
                                        <span>Personalized news recommendation is an important technique to help users find
their interested news information and alleviate their information overload. It
has been extensively studied over decades and has achieved notable success in
improving users&#x27; news reading experience. However, there are still many
unsolved problems and challenges that need to be further studied. To help
researchers master the advances in personalized news recommendation over the
past years, in this paper we present a comprehensive overview of personalized
news recommendation. Instead of following the conventional taxonomy of news
recommendation methods, in this paper we propose a novel perspective to
understand personalized news recommendation based on its core problems and the
associated techniques and challenges. We first review the techniques for
tackling each core problem in a personalized news recommender system and the
challenges they face. Next, we introduce the public datasets and evaluation
metrics used for personalized news recommendation. We then discuss the key
points on improving the responsibility of personalized news recommender
systems. Finally, we raise several research directions that are worth
investigating in future. This paper can provide up-to-date and comprehensive
views to help readers understand the personalized news recommendation field. We
hope this paper can facilitate research on personalized news recommendation and
as well as related fields in natural language processing and data mining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TUTA: Tree-based Transformers for Generally Structured Table Pre-training. (arXiv:2010.12537v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiruo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Haoyu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiyi Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12537">
                                    <div class="article-summary-box-inner">
                                        <span>Tables are widely used with various structures to organize and present data.
Recent attempts on table understanding mainly focus on relational tables, yet
overlook to other common table structures. In this paper, we propose TUTA, a
unified pre-training architecture for understanding generally structured
tables. Noticing that understanding a table requires spatial, hierarchical, and
semantic information, we enhance transformers with three novel structure-aware
mechanisms. First, we devise a unified tree-based structure, called a
bi-dimensional coordinate tree, to describe both the spatial and hierarchical
information of generally structured tables. Upon this, we propose tree-based
attention and position embedding to better capture the spatial and hierarchical
information. Moreover, we devise three progressive pre-training objectives to
enable representations at the token, cell, and table levels. We pre-train TUTA
on a wide range of unlabeled web and spreadsheet tables and fine-tune it on two
critical tasks in the field of table structure understanding: cell type
classification and table type classification. Experiments show that TUTA is
highly effective, achieving state-of-the-art on five widely-studied datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topology Distillation for Recommender System. (arXiv:2106.08700v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">SeongKu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Junyoung Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1">Wonbin Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08700">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender Systems (RS) have employed knowledge distillation which is a
model compression technique training a compact student model with the knowledge
transferred from a pre-trained large teacher model. Recent work has shown that
transferring knowledge from the teacher&#x27;s intermediate layer significantly
improves the recommendation quality of the student. However, they transfer the
knowledge of individual representation point-wise and thus have a limitation in
that primary information of RS lies in the relations in the representation
space. This paper proposes a new topology distillation approach that guides the
student by transferring the topological structure built upon the relations in
the teacher space. We first observe that simply making the student learn the
whole topological structure is not always effective and even degrades the
student&#x27;s performance. We demonstrate that because the capacity of the student
is highly limited compared to that of the teacher, learning the whole
topological structure is daunting for the student. To address this issue, we
propose a novel method named Hierarchical Topology Distillation (HTD) which
distills the topology hierarchically to cope with the large capacity gap. Our
extensive experiments on real-world datasets show that the proposed method
significantly outperforms the state-of-the-art competitors. We also provide
in-depth analyses to ascertain the benefit of distilling the topology for RS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FAIR: Fairness-Aware Information Retrieval Evaluation. (arXiv:2106.08527v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Ruoyuan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yingqiang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1">Chirag Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08527">
                                    <div class="article-summary-box-inner">
                                        <span>With the emerging needs of creating fairness-aware solutions for search and
recommendation systems, a daunting challenge exists of evaluating such
solutions. While many of the traditional information retrieval (IR) metrics can
capture the relevance, diversity and novelty for the utility with respect to
users, they are not suitable for inferring whether the presented results are
fair from the perspective of responsible information exposure. On the other
hand, various fairness metrics have been proposed but they do not account for
the user utility or do not measure it adequately. To address this problem, we
propose a new metric called Fairness-Aware IR (FAIR). By unifying standard IR
metrics and fairness measures into an integrated metric, this metric offers a
new perspective for evaluating fairness-aware ranking results. Based on this
metric, we developed an effective ranking algorithm that jointly optimized user
utility and fairness. The experimental results showed that our FAIR metric
could highlight results with good user utility and fair information exposure.
We showed how FAIR related to existing metrics and demonstrated the
effectiveness of our FAIR-based algorithm. We believe our work opens up a new
direction of pursuing a computationally feasible metric for evaluating and
implementing the fairness-aware IR systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysing Dense Passage Retrieval for Multi-hop Question Answering. (arXiv:2106.08433v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sidiropoulos_G/0/1/0/all/0/1">Georgios Sidiropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Voskarides_N/0/1/0/all/0/1">Nikos Voskarides</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1">Svitlana Vakulenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1">Evangelos Kanoulas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08433">
                                    <div class="article-summary-box-inner">
                                        <span>We analyse the performance of passage retrieval models in the presence of
complex (multi-hop) questions to provide a better understanding of how
retrieval systems behave when multiple hops of reasoning are needed. In simple
open-domain question answering (QA), dense passage retrieval has become one of
the standard approaches for retrieving the relevant passages to infer an
answer. Recently, dense passage retrieval also achieved state-of-the-art
results in multi-hop QA, where aggregating information from multiple documents
and reasoning over them is required. However, so far, the dense retrieval
models are not evaluated properly concerning the multi-hop nature of the
problem: models are typically evaluated by the end result of the retrieval
pipeline, which leaves unclear where their success lies. In this work, we
provide an in-depth evaluation of such models not only unveiling the reasons
behind their success but also their limitations. Moreover, we introduce a
hybrid (lexical and dense) retrieval approach that is highly competitive with
the state-of-the-art dense retrieval model, while requiring substantially less
computational resources. Furthermore, we also perform qualitative analysis to
better understand the challenges behind passage retrieval for multi-hop QA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections. (arXiv:2106.08908v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pappas_D/0/1/0/all/0/1">Dimitris Pappas</a>, <a href="http://arxiv.org/find/cs/1/au:+Androutsopoulos_I/0/1/0/all/0/1">Ion Androutsopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08908">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) systems for large document collections typically use
pipelines that (i) retrieve possibly relevant documents, (ii) re-rank them,
(iii) rank paragraphs or other snippets of the top-ranked documents, and (iv)
select spans of the top-ranked snippets as exact answers. Pipelines are
conceptually simple, but errors propagate from one component to the next,
without later components being able to revise earlier decisions. We present an
architecture for joint document and snippet ranking, the two middle stages,
which leverages the intuition that relevant documents have good snippets and
good snippets come from relevant documents. The architecture is general and can
be used with any neural text relevance ranker. We experiment with two main
instantiations of the architecture, based on POSIT-DRMM (PDRMM) and a
BERT-based ranker. Experiments on biomedical data from BIOASQ show that our
joint models vastly outperform the pipelines in snippet retrieval, the main
goal for QA, with fewer trainable parameters, also remaining competitive in
document retrieval. Furthermore, our joint PDRMM-based model is competitive
with BERT-based models, despite using orders of magnitude fewer parameters.
These claims are also supported by human evaluation on two test batches of
BIOASQ. To test our key findings on another dataset, we modified the Natural
Questions dataset so that it can also be used for document and snippet
retrieval. Our joint PDRMM-based model again outperforms the corresponding
pipeline in snippet retrieval on the modified Natural Questions dataset, even
though it performs worse than the pipeline in document retrieval. We make our
code and the modified Natural Questions dataset publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Predictive Coding Account for Chaotic Itinerancy. (arXiv:2106.08937v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Annabi_L/0/1/0/all/0/1">Louis Annabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitti_A/0/1/0/all/0/1">Alexandre Pitti</a>, <a href="http://arxiv.org/find/cs/1/au:+Quoy_M/0/1/0/all/0/1">Mathias Quoy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08937">
                                    <div class="article-summary-box-inner">
                                        <span>As a phenomenon in dynamical systems allowing autonomous switching between
stable behaviors, chaotic itinerancy has gained interest in neurorobotics
research. In this study, we draw a connection between this phenomenon and the
predictive coding theory by showing how a recurrent neural network implementing
predictive coding can generate neural trajectories similar to chaotic
itinerancy in the presence of input noise. We propose two scenarios generating
random and past-independent attractor switching trajectories using our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Min-Fong Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao-Yun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yu-Syuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1">Hsien-Kai Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yi-Min Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hung-Jen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1">Kevin Jou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11014">
                                    <div class="article-summary-box-inner">
                                        <span>Network spaces have been known as a critical factor in both handcrafted
network designs or defining search spaces for Neural Architecture Search (NAS).
However, an effective space involves tremendous prior knowledge and/or manual
effort, and additional constraints are required to discover efficiency-aware
architectures. In this paper, we define a new problem, Network Space Search
(NSS), as searching for favorable network spaces instead of a single
architecture. We propose an NSS method to directly search for efficient-aware
network spaces automatically, reducing the manual effort and immense cost in
discovering satisfactory ones. The resultant network spaces, named Elite
Spaces, are discovered from Expanded Search Space with minimal human expertise
imposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front
under various complexity constraints and can be further served as NAS search
spaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an
averagely 2.3% lower error rate and 3.7% closer to target constraint than the
baseline with around 90% fewer samples required to find satisfactory networks).
Moreover, our NSS approach is capable of searching for superior spaces in
future unexplored spaces, revealing great potential in searching for network
spaces automatically. Website:
https://minhungchen.netlify.app/publication/nss/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1">Sophia Bano</a>, <a href="http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1">Alessandro Casella</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1">Francisco Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1">Sara Moccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1">George Attilakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1">Ruwan Wimalasundera</a>, <a href="http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1">Dario Paladini</a>, <a href="http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1">Jan Deprest</a>, <a href="http://arxiv.org/find/cs/1/au:+Momi_E/0/1/0/all/0/1">Elena De Momi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1">Leonardo S. Mattos</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05923">
                                    <div class="article-summary-box-inner">
                                        <span>Fetoscopy laser photocoagulation is a widely used procedure for the treatment
of Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic
multiple pregnancies due to placental vascular anastomoses. This procedure is
particularly challenging due to limited field of view, poor manoeuvrability of
the fetoscope, poor visibility due to fluid turbidity, variability in light
source, and unusual position of the placenta. This may lead to increased
procedural time and incomplete ablation, resulting in persistent TTTS.
Computer-assisted intervention may help overcome these challenges by expanding
the fetoscopic field of view through video mosaicking and providing better
visualization of the vessel network. However, the research and development in
this domain remain limited due to unavailability of high-quality data to encode
the intra- and inter-procedure variability. Through the \textit{Fetoscopic
Placental Vessel Segmentation and Registration (FetReg)} challenge, we present
a large-scale multi-centre dataset for the development of generalized and
robust semantic segmentation and video mosaicking algorithms for the fetal
environment with a focus on creating drift-free mosaics from long duration
fetoscopy videos. In this paper, we provide an overview of the FetReg dataset,
challenge tasks, evaluation metrics and baseline methods for both segmentation
and registration. Baseline methods results on the FetReg dataset shows that our
dataset poses interesting challenges, offering large opportunity for the
creation of novel methods and models through a community effort initiative
guided by the FetReg challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1">Carles Domingo-Enrich</a>, <a href="http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05739">
                                    <div class="article-summary-box-inner">
                                        <span>Several works in implicit and explicit generative modeling empirically
observed that feature-learning discriminators outperform fixed-kernel
discriminators in terms of the sample quality of the models. We provide
separation results between probability metrics with fixed-kernel and
feature-learning discriminators using the function classes $\mathcal{F}_2$ and
$\mathcal{F}_1$ respectively, which were developed to study overparametrized
two-layer neural networks. In particular, we construct pairs of distributions
over hyper-spheres that can not be discriminated by fixed kernel
$(\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)
in high dimensions, but that can be discriminated by their feature learning
($\mathcal{F}_1$) counterparts. To further study the separation we provide
links between the $\mathcal{F}_1$ and $\mathcal{F}_2$ IPMs with sliced
Wasserstein distances. Our work suggests that fixed-kernel discriminators
perform worse than their feature learning counterparts because their
corresponding metrics are weaker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1">Richard Antonello</a>, <a href="http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1">Javier Turek</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1">Vy Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1">Alexander Huth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05426">
                                    <div class="article-summary-box-inner">
                                        <span>How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain&#x27;s
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain&#x27;s natural language representation structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Predictive Control with and without Terminal Weight: Stability and Algorithms. (arXiv:2011.14193v2 [eess.SY] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1">Wen-Hua Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14193">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents stability analysis tools for model predictive control
(MPC) with and without terminal weight. Stability analysis of MPC with a
limited horizon but without terminal weight is a long-standing open problem. By
using a modified value function as an Lyapunov function candidate and the
principle of optimality, this paper establishes stability conditions for this
type of widely spread MPC algorithms. A new stability guaranteed MPC algorithm
without terminal weight (MPCS) is presented. With the help of designing a new
sublevel set defined by the value function of one-step ahead stage cost,
conditions for checking its recursive feasibility and stability of the proposed
MPC algorithm are presented. The new stability condition and the derived MPCS
overcome the difficulties arising in the existing terminal weight based MPC
framework, including the need of searching a suitable terminal weight and
possible poor performance caused by an inappropriate terminal weight. This work
is further extended to MPC with a terminal weight for the completeness.
Numerical examples are presented to demonstrate the effectiveness of the
proposed tool, whereas the existing stability analysis tools are either not
applicable or lead to quite conservative results. It shows that the proposed
tools offer a number of mechanisms to achieve stability: adjusting state and/or
control weights, extending the length of horizon, and adding a simple extra
constraint on the first or second state in the optimisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-Aware Deep Clustering: Maximizing Angles between Embedding Vectors Based on Regular Simplex. (arXiv:2106.02331v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tanaka_K/0/1/0/all/0/1">Keitaro Tanaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Sawata_R/0/1/0/all/0/1">Ryosuke Sawata</a>, <a href="http://arxiv.org/find/eess/1/au:+Takahashi_S/0/1/0/all/0/1">Shusuke Takahashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02331">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new deep clustering (DC) method called manifold-aware
DC (M-DC) that can enhance hyperspace utilization more effectively than the
original DC. The original DC has a limitation in that a pair of two speakers
has to be embedded having an orthogonal relationship due to its use of the
one-hot vector-based loss function, while our method derives a unique loss
function aimed at maximizing the target angle in the hyperspace based on the
nature of a regular simplex. Our proposed loss imposes a higher penalty than
the original DC when the speaker is assigned incorrectly. The change from DC to
M-DC can be easily achieved by rewriting just one term in the loss function of
DC, without any other modifications to the network architecture or model
parameters. As such, our method has high practicability because it does not
affect the original inference part. The experimental results show that the
proposed method improves the performances of the original DC and its expansion
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Less is More: A privacy-respecting Android malware classifier using Federated Learning. (arXiv:2007.08319v3 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galvez_R/0/1/0/all/0/1">Rafa G&#xe1;lvez</a>, <a href="http://arxiv.org/find/cs/1/au:+Moonsamy_V/0/1/0/all/0/1">Veelasha Moonsamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_C/0/1/0/all/0/1">Claudia Diaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08319">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present LiM (&quot;Less is More&quot;), a malware classification
framework that leverages Federated Learning to detect and classify malicious
apps in a privacy-respecting manner. Information about newly installed apps is
kept locally on users&#x27; devices, so that the provider cannot infer which apps
were installed by users. At the same time, input from all users is taken into
account in the federated learning process and they all benefit from better
classification performance. A key challenge of this setting is that users do
not have access to the ground truth (i.e. they cannot correctly identify
whether an app is malicious). To tackle this, LiM uses a safe semi-supervised
ensemble that maximizes classification accuracy with respect to a baseline
classifier trained by the service provider (i.e. the cloud). We implement LiM
and show that the cloud server has F1 score of 95%, while clients have perfect
recall with only 1 false positive in &gt;100 apps, using a dataset of 25K clean
apps and 25K malicious apps, 200 users and 50 rounds of federation.
Furthermore, we conduct a security analysis and demonstrate that LiM is robust
against both poisoning attacks by adversaries who control half of the clients,
and inference attacks performed by an honest-but-curious cloud server. Further
experiments with MaMaDroid&#x27;s dataset confirm resistance against poisoning
attacks and a performance improvement due to the federation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1">Damir Koren&#x10d;i&#x107;</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1">Strahil Ristov</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1">Jelena Repar</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06274">
                                    <div class="article-summary-box-inner">
                                        <span>Topic models are widely used unsupervised models of text capable of learning
topics - weighted lists of words and documents - from large collections of text
documents. When topic models are used for discovery of topics in text
collections, a question that arises naturally is how well the model-induced
topics correspond to topics of interest to the analyst. In this paper we
revisit and extend a so far neglected approach to topic model evaluation based
on measuring topic coverage - computationally matching model topics with a set
of reference topics that models are expected to uncover. The approach is well
suited for analyzing models&#x27; performance in topic discovery and for large-scale
analysis of both topic models and measures of model quality. We propose new
measures of coverage and evaluate, in a series of experiments, different types
of topic models on two distinct text domains for which interest for topic
discovery exists. The experiments include evaluation of model quality, analysis
of coverage of distinct topic categories, and the analysis of the relationship
between coverage and other methods of topic model evaluation. The contributions
of the paper include new measures of coverage, insights into both topic models
and other methods of model evaluation, and the datasets and code for
facilitating future research of both topic coverage and other approaches to
topic model evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deriving Autism Spectrum Disorder Functional Networks from RS-FMRI Data using Group ICA and Dictionary Learning. (arXiv:2106.09000v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1">Ning Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_D/0/1/0/all/0/1">Donglin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09000">
                                    <div class="article-summary-box-inner">
                                        <span>The objective of this study is to derive functional networks for the autism
spectrum disorder (ASD) population using the group ICA and dictionary learning
model together and to classify ASD and typically developing (TD) participants
using the functional connectivity calculated from the derived functional
networks. In our experiments, the ASD functional networks were derived from
resting-state functional magnetic resonance imaging (rs-fMRI) data. We
downloaded a total of 120 training samples, including 58 ASD and 62 TD
participants, which were obtained from the public repository: Autism Brain
Imaging Data Exchange I (ABIDE I). Our methodology and results have five main
parts. First, we utilize a group ICA model to extract functional networks from
the ASD group and rank the top 20 regions of interest (ROIs). Second, we
utilize a dictionary learning model to extract functional networks from the ASD
group and rank the top 20 ROIs. Third, we merged the 40 selected ROIs from the
two models together as the ASD functional networks. Fourth, we generate three
corresponding masks based on the 20 selected ROIs from group ICA, the 20 ROIs
selected from dictionary learning, and the 40 combined ROIs selected from both.
Finally, we extract ROIs for all training samples using the above three masks,
and the calculated functional connectivity was used as features for ASD and TD
classification. The classification results showed that the functional networks
derived from ICA and dictionary learning together outperform those derived from
a single ICA model or a single dictionary learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Outside the Echo Chamber: Optimizing the Performative Risk. (arXiv:2102.08570v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1">John Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdomo_J/0/1/0/all/0/1">Juan C. Perdomo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zrnic_T/0/1/0/all/0/1">Tijana Zrnic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08570">
                                    <div class="article-summary-box-inner">
                                        <span>In performative prediction, predictions guide decision-making and hence can
influence the distribution of future data. To date, work on performative
prediction has focused on finding performatively stable models, which are the
fixed points of repeated retraining. However, stable solutions can be far from
optimal when evaluated in terms of the performative risk, the loss experienced
by the decision maker when deploying a model. In this paper, we shift attention
beyond performative stability and focus on optimizing the performative risk
directly. We identify a natural set of properties of the loss function and
model-induced distribution shift under which the performative risk is convex, a
property which does not follow from convexity of the loss alone. Furthermore,
we develop algorithms that leverage our structural assumptions to optimize the
performative risk with better sample efficiency than generic methods for
derivative-free convex optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1">Kendrick Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yining Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03622">
                                    <div class="article-summary-box-inner">
                                        <span>Self-training algorithms, which train a model to fit pseudolabels predicted
by another previously-learned model, have been very successful for learning
with unlabeled data using neural networks. However, the current theoretical
understanding of self-training only applies to linear models. This work
provides a unified theoretical analysis of self-training with deep networks for
semi-supervised learning, unsupervised domain adaptation, and unsupervised
learning. At the core of our analysis is a simple but realistic &quot;expansion&quot;
assumption, which states that a low probability subset of the data must expand
to a neighborhood with large probability relative to the subset. We also assume
that neighborhoods of examples in different classes have minimal overlap. We
prove that under these assumptions, the minimizers of population objectives
based on self-training and input-consistency regularization will achieve high
accuracy with respect to ground-truth labels. By using off-the-shelf
generalization bounds, we immediately convert this result to sample complexity
guarantees for neural nets that are polynomial in the margin and Lipschitzness.
Our results help explain the empirical successes of recently proposed
self-training algorithms which use input consistency regularization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1">Luka Murn</a>, <a href="http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1">Saverio Blasi</a>, <a href="http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1">Alan F. Smeaton</a>, <a href="http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1">Marta Mrak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08936">
                                    <div class="article-summary-box-inner">
                                        <span>The versatility of recent machine learning approaches makes them ideal for
improvement of next generation video compression solutions. Unfortunately,
these approaches typically bring significant increases in computational
complexity and are difficult to interpret into explainable models, affecting
their potential for implementation within practical video coding applications.
This paper introduces a novel explainable neural network-based inter-prediction
scheme, to improve the interpolation of reference samples needed for fractional
precision motion compensation. The approach requires a single neural network to
be trained from which a full quarter-pixel interpolation filter set is derived,
as the network is easily interpretable due to its linear structure. A novel
training framework enables each network branch to resemble a specific
fractional shift. This practical solution makes it very efficient to use
alongside conventional video coding schemes. When implemented in the context of
the state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and
2.25% BD-rate savings can be achieved on average for lower resolution sequences
under the random access, low-delay B and low-delay P configurations,
respectively, while the complexity of the learned interpolation schemes is
significantly reduced compared to the interpolation with full CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users. (arXiv:2106.08946v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaopeng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobson_G/0/1/0/all/0/1">Guy Jacobson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jana_R/0/1/0/all/0/1">Rittwik Jana</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Wen-Ling Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Talasila_M/0/1/0/all/0/1">Manoop Talasila</a>, <a href="http://arxiv.org/find/cs/1/au:+Aftab_S/0/1/0/all/0/1">Syed Anwar Aftab</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Borcea_C/0/1/0/all/0/1">Cristian Borcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08946">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained location prediction on smart phones can be used to improve
app/system performance. Application scenarios include video quality adaptation
as a function of the 5G network quality at predicted user locations, and
augmented reality apps that speed up content rendering based on predicted user
locations. Such use cases require prediction error in the same range as the GPS
error, and no existing works on location prediction can achieve this level of
accuracy. We present a system for fine-grained location prediction (FGLP) of
mobile users, based on GPS traces collected on the phones. FGLP has two
components: a federated learning framework and a prediction model. The
framework runs on the phones of the users and also on a server that coordinates
learning from all users in the system. FGLP represents the user location data
as relative points in an abstract 2D space, which enables learning across
different physical spaces. The model merges Bidirectional Long Short-Term
Memory (BiLSTM) and Convolutional Neural Networks (CNN), where BiLSTM learns
the speed and direction of the mobile users, and CNN learns information such as
user movement preferences. FGLP uses federated learning to protect user privacy
and reduce bandwidth consumption. Our experimental results, using a dataset
with over 600,000 users, demonstrate that FGLP outperforms baseline models in
terms of prediction accuracy. We also demonstrate that FGLP works well in
conjunction with transfer learning, which enables model reusability. Finally,
benchmark results on several types of Android phones demonstrate FGLP&#x27;s
feasibility in real life.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RefBERT: Compressing BERT by Referencing to Pre-computed Representations. (arXiv:2106.08898v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haiqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1">Yang Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jianping Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08898">
                                    <div class="article-summary-box-inner">
                                        <span>Recently developed large pre-trained language models, e.g., BERT, have
achieved remarkable performance in many downstream natural language processing
applications. These pre-trained language models often contain hundreds of
millions of parameters and suffer from high computation and latency in
real-world applications. It is desirable to reduce the computation overhead of
the models for fast training and inference while keeping the model performance
in downstream applications. Several lines of work utilize knowledge
distillation to compress the teacher model to a smaller student model. However,
they usually discard the teacher&#x27;s knowledge when in inference. Differently, in
this paper, we propose RefBERT to leverage the knowledge learned from the
teacher, i.e., facilitating the pre-computed BERT representation on the
reference sample and compressing BERT into a smaller student model. To
guarantee our proposal, we provide theoretical justification on the loss
function and the usage of reference samples. Significantly, the theoretical
result shows that including the pre-computed teacher&#x27;s representations on the
reference samples indeed increases the mutual information in learning the
student model. Finally, we conduct the empirical evaluation and show that our
RefBERT can beat the vanilla TinyBERT over 8.1\% and achieves more than 94\% of
the performance of $\BERTBASE$ on the GLUE benchmark. Meanwhile, RefBERT is
7.4x smaller and 9.5x faster on inference than BERT$_{\rm BASE}$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning. (arXiv:2012.11662v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gillen_S/0/1/0/all/0/1">Sean Gillen</a>, <a href="http://arxiv.org/find/cs/1/au:+Byl_K/0/1/0/all/0/1">Katie Byl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11662">
                                    <div class="article-summary-box-inner">
                                        <span>A key limitation in using various modern methods of machine learning in
developing feedback control policies is the lack of appropriate methodologies
to analyze their long-term dynamics, in terms of making any sort of guarantees
(even statistically) about robustness. The central reasons for this are largely
due to the so-called curse of dimensionality, combined with the black-box
nature of the resulting control policies themselves. This paper aims at the
first of these issues. Although the full state space of a system may be quite
large in dimensionality, it is a common feature of most model-based control
methods that the resulting closed-loop systems demonstrate dominant dynamics
that are rapidly driven to some lower-dimensional sub-space within. In this
work we argue that the dimensionality of this subspace is captured by tools
from fractal geometry, namely various notions of a fractional dimension. We
then show that the dimensionality of trajectories induced by model free
reinforcement learning agents can be influenced adding a post processing
function to the agents reward signal. We verify that the dimensionality
reduction is robust to noise being added to the system and show that that the
modified agents are more actually more robust to noise and push disturbances in
general for the systems we examined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuefeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02400">
                                    <div class="article-summary-box-inner">
                                        <span>In label-noise learning, the transition matrix plays a key role in building
statistically consistent classifiers. Existing consistent estimators for the
transition matrix have been developed by exploiting anchor points. However, the
anchor-point assumption is not always satisfied in real scenarios. In this
paper, we propose an end-to-end framework for solving label-noise learning
without anchor points, in which we simultaneously optimize two objectives: the
cross entropy loss between the noisy label and the predicted probability by the
neural network, and the volume of the simplex formed by the columns of the
transition matrix. Our proposed framework can identify the transition matrix if
the clean class-posterior probabilities are sufficiently scattered. This is by
far the mildest assumption under which the transition matrix is provably
identifiable and the learned classifier is statistically consistent.
Experimental results on benchmark datasets demonstrate the effectiveness and
robustness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning effective stochastic differential equations from microscopic simulations: combining stochastic numerics and deep learning. (arXiv:2106.09004v1 [physics.comp-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Dietrich_F/0/1/0/all/0/1">Felix Dietrich</a>, <a href="http://arxiv.org/find/physics/1/au:+Makeev_A/0/1/0/all/0/1">Alexei Makeev</a>, <a href="http://arxiv.org/find/physics/1/au:+Kevrekidis_G/0/1/0/all/0/1">George Kevrekidis</a>, <a href="http://arxiv.org/find/physics/1/au:+Evangelou_N/0/1/0/all/0/1">Nikolaos Evangelou</a>, <a href="http://arxiv.org/find/physics/1/au:+Bertalan_T/0/1/0/all/0/1">Tom Bertalan</a>, <a href="http://arxiv.org/find/physics/1/au:+Reich_S/0/1/0/all/0/1">Sebastian Reich</a>, <a href="http://arxiv.org/find/physics/1/au:+Kevrekidis_I/0/1/0/all/0/1">Ioannis G. Kevrekidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09004">
                                    <div class="article-summary-box-inner">
                                        <span>We identify effective stochastic differential equations (SDE) for coarse
observables of fine-grained particle- or agent-based simulations; these SDE
then provide coarse surrogate models of the fine scale dynamics. We approximate
the drift and diffusivity functions in these effective SDE through neural
networks, which can be thought of as effective stochastic ResNets. The loss
function is inspired by, and embodies, the structure of established stochastic
numerical integrators (here, Euler-Maruyama and Milstein); our approximations
can thus benefit from error analysis of these underlying numerical schemes.
They also lend themselves naturally to &quot;physics-informed&quot; gray-box
identification when approximate coarse models, such as mean field equations,
are available. Our approach does not require long trajectories, works on
scattered snapshot data, and is designed to naturally handle different time
steps per snapshot. We consider both the case where the coarse collective
observables are known in advance, as well as the case where they must be found
in a data-driven manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonparametric Empirical Bayes Estimation and Testing for Sparse and Heteroscedastic Signals. (arXiv:2106.08881v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Junhui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritov_Y/0/1/0/all/0/1">Ya&#x27;acov Ritov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Linda Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08881">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale modern data often involves estimation and testing for
high-dimensional unknown parameters. It is desirable to identify the sparse
signals, &#x60;&#x60;the needles in the haystack&#x27;&#x27;, with accuracy and false discovery
control. However, the unprecedented complexity and heterogeneity in modern data
structure require new machine learning tools to effectively exploit
commonalities and to robustly adjust for both sparsity and heterogeneity. In
addition, estimates for high-dimensional parameters often lack uncertainty
quantification. In this paper, we propose a novel Spike-and-Nonparametric
mixture prior (SNP) -- a spike to promote the sparsity and a nonparametric
structure to capture signals. In contrast to the state-of-the-art methods, the
proposed methods solve the estimation and testing problem at once with several
merits: 1) an accurate sparsity estimation; 2) point estimates with
shrinkage/soft-thresholding property; 3) credible intervals for uncertainty
quantification; 4) an optimal multiple testing procedure that controls false
discovery rate. Our method exhibits promising empirical performance on both
simulated data and a gene expression case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time Attacks Against Deep Reinforcement Learning Policies. (arXiv:2106.08746v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1">Buse G.A. Tekgul</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shelly Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchal_S/0/1/0/all/0/1">Samuel Marchal</a>, <a href="http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1">N. Asokan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08746">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has discovered that deep reinforcement learning (DRL) policies
are vulnerable to adversarial examples. These attacks mislead the policy of DRL
agents by perturbing the state of the environment observed by agents. They are
feasible in principle but too slow to fool DRL policies in real time. We
propose a new attack to fool DRL policies that is both effective and efficient
enough to be mounted in real time. We utilize the Universal Adversarial
Perturbation (UAP) method to compute effective perturbations independent of the
individual inputs to which they are applied. Via an extensive evaluation using
Atari 2600 games, we show that our technique is effective, as it fully degrades
the performance of both deterministic and stochastic policies (up to 100%, even
when the $l_\infty$ bound on the perturbation is as small as 0.005). We also
show that our attack is efficient, incurring an online computational cost of
0.027ms on average. It is faster compared to the response time (0.6ms on
average) of agents with different DRL policies, and considerably faster than
prior attacks (2.7ms on average). Furthermore, we demonstrate that known
defenses are ineffective against universal perturbations. We propose an
effective detection technique which can form the basis for robust defenses
against attacks based on universal perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Based Counterfactual Synthesizer for Interpretation. (arXiv:2106.08971v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Alva_S/0/1/0/all/0/1">Sahan Suresh Alva</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08971">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactuals, serving as one of the emerging type of model
interpretations, have recently received attention from both researchers and
practitioners. Counterfactual explanations formalize the exploration of
&#x60;&#x60;what-if&#x27;&#x27; scenarios, and are an instance of example-based reasoning using a
set of hypothetical data samples. Counterfactuals essentially show how the
model decision alters with input perturbations. Existing methods for generating
counterfactuals are mainly algorithm-based, which are time-inefficient and
assume the same counterfactual universe for different queries. To address these
limitations, we propose a Model-based Counterfactual Synthesizer (MCS)
framework for interpreting machine learning models. We first analyze the
model-based counterfactual process and construct a base synthesizer using a
conditional generative adversarial net (CGAN). To better approximate the
counterfactual universe for those rare queries, we novelly employ the umbrella
sampling technique to conduct the MCS framework training. Besides, we also
enhance the MCS framework by incorporating the causal dependence among
attributes with model inductive bias, and validate its design correctness from
the causality identification perspective. Experimental results on several
datasets demonstrate the effectiveness as well as efficiency of our proposed
MCS framework, and verify the advantages compared with other alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Belief Learning. (arXiv:2103.04000v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hengyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1">Adam Lerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Brandon Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">David Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1">Luis Pineda</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1">Noam Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04000">
                                    <div class="article-summary-box-inner">
                                        <span>The standard problem setting in Dec-POMDPs is self-play, where the goal is to
find a set of policies that play optimally together. Policies learned through
self-play may adopt arbitrary conventions and implicitly rely on multi-step
reasoning based on fragile assumptions about other agents&#x27; actions and thus
fail when paired with humans or independently trained agents at test time. To
address this, we present off-belief learning (OBL). At each timestep OBL agents
follow a policy $\pi_1$ that is optimized assuming past actions were taken by a
given, fixed policy ($\pi_0$), but assuming that future actions will be taken
by $\pi_1$. When $\pi_0$ is uniform random, OBL converges to an optimal policy
that does not rely on inferences based on other agents&#x27; behavior (an optimal
grounded policy). OBL can be iterated in a hierarchy, where the optimal policy
from one level becomes the input to the next, thereby introducing multi-level
cognitive reasoning in a controlled manner. Unlike existing approaches, which
may converge to any equilibrium policy, OBL converges to a unique policy,
making it suitable for zero-shot coordination (ZSC). OBL can be scaled to
high-dimensional settings with a fictitious transition mechanism and shows
strong performance in both a toy-setting and the benchmark human-AI &amp; ZSC
problem Hanabi.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimized ensemble deep learning framework for scalable forecasting of dynamics containing extreme events. (arXiv:2106.08968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Arnob Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1">Tanujit Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1">Dibakar Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08968">
                                    <div class="article-summary-box-inner">
                                        <span>The remarkable flexibility and adaptability of both deep learning models and
ensemble methods have led to the proliferation for their application in
understanding many physical phenomena. Traditionally, these two techniques have
largely been treated as independent methodologies in practical applications.
This study develops an optimized ensemble deep learning (OEDL) framework
wherein these two machine learning techniques are jointly used to achieve
synergistic improvements in model accuracy, stability, scalability, and
reproducibility prompting a new wave of applications in the forecasting of
dynamics. Unpredictability is considered as one of the key features of chaotic
dynamics, so forecasting such dynamics of nonlinear systems is a relevant issue
in the scientific community. It becomes more challenging when the prediction of
extreme events is the focus issue for us. In this circumstance, the proposed
OEDL model based on a best convex combination of feed-forward neural networks,
reservoir computing, and long short-term memory can play a key role in
advancing predictions of dynamics consisting of extreme events. The combined
framework can generate the best out-of-sample performance than the individual
deep learners and standard ensemble framework for both numerically simulated
and real world data sets. We exhibit the outstanding performance of the OEDL
framework for forecasting extreme events generated from Lienard-type system,
prediction of COVID-19 cases in Brazil, dengue cases in San Juan, and sea
surface temperature in Nino 3.4 region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning. (arXiv:2012.09421v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1">Matthieu Zimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1">Claire Glanois</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddique_U/0/1/0/all/0/1">Umer Siddique</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_P/0/1/0/all/0/1">Paul Weng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09421">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning fair policies in (deep) cooperative
multi-agent reinforcement learning (MARL). We formalize it in a principled way
as the problem of optimizing a welfare function that explicitly encodes two
important aspects of fairness: efficiency and equity. As a solution method, we
propose a novel neural network architecture, which is composed of two
sub-networks specifically designed for taking into account the two aspects of
fairness. In experiments, we demonstrate the importance of the two sub-networks
for fair optimization. Our overall approach is general as it can accommodate
any (sub)differentiable welfare function. Therefore, it is compatible with
various notions of fairness that have been proposed in the literature (e.g.,
lexicographic maximin, generalized Gini social welfare function, proportional
fairness). Our solution method is generic and can be implemented in various
MARL settings: centralized training and decentralized execution, or fully
decentralized. Finally, we experimentally validate our approach in various
domains and show that it can perform much better than previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursive Construction of Stable Assemblies of Recurrent Neural Networks. (arXiv:2106.08928v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ennis_M/0/1/0/all/0/1">Michaela Ennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozachkov_L/0/1/0/all/0/1">Leo Kozachkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1">Jean-Jacques Slotine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08928">
                                    <div class="article-summary-box-inner">
                                        <span>Advanced applications of modern machine learning will likely involve
combinations of trained networks, as are already used in spectacular systems
such as DeepMind&#x27;s AlphaGo. Recursively building such combinations in an
effective and stable fashion while also allowing for continual refinement of
the individual networks - as nature does for biological networks - will require
new analysis tools. This paper takes a step in this direction by establishing
contraction properties of broad classes of nonlinear recurrent networks and
neural ODEs, and showing how these quantified properties allow in turn to
recursively construct stable networks of networks in a systematic fashion. The
results can also be used to stably combine recurrent networks and physical
systems with quantified contraction properties. Similarly, they may be applied
to modular computational models of cognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1">Steven C.H. Hoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08914">
                                    <div class="article-summary-box-inner">
                                        <span>Video-grounded dialogue systems aim to integrate video understanding and
dialogue understanding to generate responses that are relevant to both the
dialogue and video context. Most existing approaches employ deep learning
models and have achieved remarkable performance, given the relatively small
datasets available. However, the results are partly accomplished by exploiting
biases in the datasets rather than developing multimodal reasoning, resulting
in limited generalization. In this paper, we propose a novel approach of
Compositional Counterfactual Contrastive Learning ($C^3$) to develop
contrastive training between factual and counterfactual samples in
video-grounded dialogues. Specifically, we design factual/counterfactual
sampling based on the temporal steps in videos and tokens in dialogues and
propose contrastive loss functions that exploit object-level or action-level
variance. Different from prior approaches, we focus on contrastive hidden state
representations among compositional output tokens to optimize the
representation space in a generation setting. We achieved promising performance
gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the
benefits of our approach in grounding video and dialogue context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intelligent Tire-Based Slip Ratio Estimation Using Different Machine Learning Algorithms. (arXiv:2106.08961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1">Nan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zepeng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jianfeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Askari_H/0/1/0/all/0/1">Hassan Askari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08961">
                                    <div class="article-summary-box-inner">
                                        <span>Estimation of the longitudinal slip ratio of tires is important in boosting
the control performance of the vehicle under driving and braking conditions. In
this paper, the slip ratio is estimated using four machine learning algorithms
(Neural Network, Gradient Boosting Machine, Random Forest and Support Vector
Machine) based on the acceleration signals from the tri-axial MEMS
accelerometers utilized in the intelligent tire system. The experimental data
are collected through the MTS experimental platform. The corresponding
acceleration signals within the tire contact patch are extracted after
filtering to be used for the training the aforesaid machine learning
algorithms. A comparison is provided between the implemented ML algorithms
using a 10-fold CV. NRMS errors in the CV results indicate that NN has the
highest accuracy in comparison with other techniques. The NRSM errors of NN,
GBM, RF, and SVM are 2.59\%, 3.30\%, 4.21\%, and 5.34\%, respectively. Among
these techniques, GBM has a more stable results as it has the smallest output
variance. The present study with the fusion of intelligent tire system and
machine learning algorithms paves the way for the accurate estimation of tire
slip ratio, which is critical for the development of reliable vehicle control
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Tikhonov: Faster Learning with Self-Concordant Losses via Iterative Regularization. (arXiv:2106.08855v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beugnot_G/0/1/0/all/0/1">Gaspard Beugnot</a>, <a href="http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1">Julien Mairal</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08855">
                                    <div class="article-summary-box-inner">
                                        <span>The theory of spectral filtering is a remarkable tool to understand the
statistical properties of learning with kernels. For least squares, it allows
to derive various regularization schemes that yield faster convergence rates of
the excess risk than with Tikhonov regularization. This is typically achieved
by leveraging classical assumptions called source and capacity conditions,
which characterize the difficulty of the learning task. In order to understand
estimators derived from other loss functions, Marteau-Ferey et al. have
extended the theory of Tikhonov regularization to generalized self concordant
loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we
go a step further and show that fast and optimal rates can be achieved for GSC
by using the iterated Tikhonov regularization scheme, which is intrinsically
related to the proximal point method in optimization, and overcomes the
limitation of the classical Tikhonov regularization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Economic Nowcasting with Long Short-Term Memory Artificial Neural Networks (LSTM). (arXiv:2106.08901v1 [econ.EM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Hopp_D/0/1/0/all/0/1">Daniel Hopp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08901">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial neural networks (ANNs) have been the catalyst to numerous advances
in a variety of fields and disciplines in recent years. Their impact on
economics, however, has been comparatively muted. One type of ANN, the long
short-term memory network (LSTM), is particularly wellsuited to deal with
economic time-series. Here, the architecture&#x27;s performance and characteristics
are evaluated in comparison with the dynamic factor model (DFM), currently a
popular choice in the field of economic nowcasting. LSTMs are found to produce
superior results to DFMs in the nowcasting of three separate variables; global
merchandise export values and volumes, and global services exports. Further
advantages include their ability to handle large numbers of input features in a
variety of time frequencies. A disadvantage is the inability to ascribe
contributions of input features to model outputs, common to all ANNs. In order
to facilitate continued applied research of the methodology by avoiding the
need for any knowledge of deep-learning libraries, an accompanying Python
library was developed using PyTorch, https://pypi.org/project/nowcast-lstm/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bandit Modeling of Map Selection in Counter-Strike: Global Offensive. (arXiv:2106.08888v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petri_G/0/1/0/all/0/1">Guido Petri</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanley_M/0/1/0/all/0/1">Michael H. Stanley</a>, <a href="http://arxiv.org/find/cs/1/au:+Hon_A/0/1/0/all/0/1">Alec B. Hon</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1">Alexander Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xenopoulos_P/0/1/0/all/0/1">Peter Xenopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_C/0/1/0/all/0/1">Cl&#xe1;udio Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08888">
                                    <div class="article-summary-box-inner">
                                        <span>Many esports use a pick and ban process to define the parameters of a match
before it starts. In Counter-Strike: Global Offensive (CSGO) matches, two teams
first pick and ban maps, or virtual worlds, to play. Teams typically ban and
pick maps based on a variety of factors, such as banning maps which they do not
practice, or choosing maps based on the team&#x27;s recent performance. We introduce
a contextual bandit framework to tackle the problem of map selection in CSGO
and to investigate teams&#x27; pick and ban decision-making. Using a data set of
over 3,500 CSGO matches and over 25,000 map selection decisions, we consider
different framings for the problem, different contexts, and different reward
metrics. We find that teams have suboptimal map choice policies with respect to
both picking and banning. We also define an approach for rewarding bans, which
has not been explored in the bandit setting, and find that incorporating ban
rewards improves model performance. Finally, we determine that usage of our
model could improve teams&#x27; predicted map win probability by up to 11% and raise
overall match win probabilities by 19.8% for evenly-matched teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical and Private (Deep) Learning without Sampling or Shuffling. (arXiv:2103.00039v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1">Peter Kairouz</a>, <a href="http://arxiv.org/find/cs/1/au:+McMahan_B/0/1/0/all/0/1">Brendan McMahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Thakkar_O/0/1/0/all/0/1">Om Thakkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Thakurta_A/0/1/0/all/0/1">Abhradeep Thakurta</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zheng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00039">
                                    <div class="article-summary-box-inner">
                                        <span>We consider training models with differential privacy (DP) using mini-batch
gradients. The existing state-of-the-art, Differentially Private Stochastic
Gradient Descent (DP-SGD), requires privacy amplification by sampling or
shuffling to obtain the best privacy/accuracy/computation trade-offs.
Unfortunately, the precise requirements on exact sampling and shuffling can be
hard to obtain in important practical scenarios, particularly federated
learning (FL). We design and analyze a DP variant of
Follow-The-Regularized-Leader (DP-FTRL) that compares favorably (both
theoretically and empirically) to amplified DP-SGD, while allowing for much
more flexible data access patterns. DP-FTRL does not use any form of privacy
amplification.

The code is available at
https://github.com/google-research/federated/tree/master/dp_ftrl and
https://github.com/google-research/DP-FTRL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_H/0/1/0/all/0/1">Hossein Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1">Liam Fowl</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08970">
                                    <div class="article-summary-box-inner">
                                        <span>As the curation of data for machine learning becomes increasingly automated,
dataset tampering is a mounting threat. Backdoor attackers tamper with training
data to embed a vulnerability in models that are trained on that data. This
vulnerability is then activated at inference time by placing a &quot;trigger&quot; into
the model&#x27;s input. Typical backdoor attacks insert the trigger directly into
the training data, although the presence of such an attack may be visible upon
inspection. In contrast, the Hidden Trigger Backdoor Attack achieves poisoning
without placing a trigger into the training data at all. However, this hidden
trigger attack is ineffective at poisoning neural networks trained from
scratch. We develop a new hidden trigger attack, Sleeper Agent, which employs
gradient matching, data selection, and target model re-training during the
crafting process. Sleeper Agent is the first hidden trigger backdoor attack to
be effective against neural networks trained from scratch. We demonstrate its
effectiveness on ImageNet and in black-box settings. Our implementation code
can be found at https://github.com/hsouri/Sleeper-Agent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-k: A Piecewise Linear Classifier Based on Voronoi Tessellations. (arXiv:2012.15492v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zengin_R/0/1/0/all/0/1">Rahman Salim Zengin</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Sezer_V/0/1/0/all/0/1">Volkan Sezer</a> (1) ((1) Istanbul Technical University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15492">
                                    <div class="article-summary-box-inner">
                                        <span>Voronoi tessellations are used to partition the Euclidean space into
polyhedral regions, which are called Voronoi cells. Labeling the Voronoi cells
with the class information, we can map any classification problem into a
Voronoi tessellation. In this way, the classification problem changes into a
query of just finding the enclosing Voronoi cell. In order to accomplish this
task, we have developed a new algorithm which generates a labeled Voronoi
tessellation that partitions the training data into polyhedral regions and
obtains interclass boundaries as an indirect result. It is called Supervised
k-Voxels or in short Super-k. We are introducing Super-k as a foundational new
algorithm and opening the possibility of a new family of algorithms. In this
paper, it is shown via comparisons on certain datasets that the Super-k
algorithm has the potential of providing comparable performance of the
well-known SVM family of algorithms with less complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-Efficient Federated Learning with Compensated Overlap-FedAvg. (arXiv:2012.06706v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuhao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qing_Y/0/1/0/all/0/1">Ye Qing</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jiancheng Lv</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06706">
                                    <div class="article-summary-box-inner">
                                        <span>Petabytes of data are generated each day by emerging Internet of Things
(IoT), but only few of them can be finally collected and used for Machine
Learning (ML) purposes due to the apprehension of data &amp; privacy leakage, which
seriously retarding ML&#x27;s growth. To alleviate this problem, Federated learning
is proposed to perform model training by multiple clients&#x27; combined data
without the dataset sharing within the cluster. Nevertheless, federated
learning introduces massive communication overhead as the synchronized data in
each epoch is of the same size as the model, and thereby leading to a low
communication efficiency. Consequently, variant methods mainly focusing on the
communication rounds reduction and data compression are proposed to reduce the
communication overhead of federated learning. In this paper, we propose
Overlap-FedAvg, a framework that parallels the model training phase with model
uploading &amp; downloading phase, so that the latter phase can be totally covered
by the former phase. Compared to vanilla FedAvg, Overlap-FedAvg is further
developed with a hierarchical computing strategy, a data compensation mechanism
and a nesterov accelerated gradients~(NAG) algorithm. Besides, Overlap-FedAvg
is orthogonal to many other compression methods so that they can be applied
together to maximize the utilization of the cluster. Furthermore, the
theoretical analysis is provided to prove the convergence of the proposed
Overlap-FedAvg framework. Extensive experiments on both conventional and
recurrent tasks with multiple models and datasets also demonstrate that the
proposed Overlap-FedAvg framework substantially boosts the federated learning
process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ruihao Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1">Mingzhu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fengwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shaoqing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shi Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09899">
                                    <div class="article-summary-box-inner">
                                        <span>User data confidentiality protection is becoming a rising challenge in the
present deep learning research. Without access to data, conventional
data-driven model compression faces a higher risk of performance degradation.
Recently, some works propose to generate images from a specific pretrained
model to serve as training data. However, the inversion process only utilizes
biased feature statistics stored in one model and is from low-dimension to
high-dimension. As a consequence, it inevitably encounters the difficulties of
generalizability and inexact inversion, which leads to unsatisfactory
performance. To address these problems, we propose MixMix based on two simple
yet effective techniques: (1) Feature Mixing: utilizes various models to
construct a universal feature space for generalized inversion; (2) Data Mixing:
mixes the synthesized images and labels to generate exact label information. We
prove the effectiveness of MixMix from both theoretical and empirical
perspectives. Extensive experiments show that MixMix outperforms existing
methods on the mainstream compression tasks, including quantization, knowledge
distillation, and pruning. Specifically, MixMix achieves up to 4% and 20%
accuracy uplift on quantization and pruning, respectively, compared to existing
data-free compression work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Dimensional Bayesian Optimisation with Variational Autoencoders and Deep Metric Learning. (arXiv:2106.03609v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grosnit_A/0/1/0/all/0/1">Antoine Grosnit</a>, <a href="http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1">Rasul Tutunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Maraval_A/0/1/0/all/0/1">Alexandre Max Maraval</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1">Ryan-Rhys Griffiths</a>, <a href="http://arxiv.org/find/cs/1/au:+Cowen_Rivers_A/0/1/0/all/0/1">Alexander I. Cowen-Rivers</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1">Wenlong Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhitang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1">Haitham Bou-Ammar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03609">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method based on deep metric learning to perform Bayesian
optimisation over high-dimensional, structured input spaces using variational
autoencoders (VAEs). By extending ideas from supervised deep metric learning,
we address a longstanding problem in high-dimensional VAE Bayesian
optimisation, namely how to enforce a discriminative latent space as an
inductive bias. Importantly, we achieve such an inductive bias using just 1% of
the available labelled data relative to previous work, highlighting the sample
efficiency of our approach. As a theoretical contribution, we present a proof
of vanishing regret for our method. As an empirical contribution, we present
state-of-the-art results on real-world high-dimensional black-box optimisation
problems including property-guided molecule generation. It is the hope that the
results presented in this paper can act as a guiding principle for realising
effective high-dimensional Bayesian optimisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated scoring of pre-REM sleep in mice with deep learning. (arXiv:2105.01933v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Grieger_N/0/1/0/all/0/1">Niklas Grieger</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Schwabedal_J/0/1/0/all/0/1">Justus T. C. Schwabedal</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wendel_S/0/1/0/all/0/1">Stefanie Wendel</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ritze_Y/0/1/0/all/0/1">Yvonne Ritze</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bialonski_S/0/1/0/all/0/1">Stephan Bialonski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01933">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable automation of the labor-intensive manual task of scoring animal
sleep can facilitate the analysis of long-term sleep studies. In recent years,
deep-learning-based systems, which learn optimal features from the data,
increased scoring accuracies for the classical sleep stages of Wake, REM, and
Non-REM. Meanwhile, it has been recognized that the statistics of transitional
stages such as pre-REM, found between Non-REM and REM, may hold additional
insight into the physiology of sleep and are now under vivid investigation. We
propose a classification system based on a simple neural network architecture
that scores the classical stages as well as pre-REM sleep in mice. When
restricted to the classical stages, the optimized network showed
state-of-the-art classification performance with an out-of-sample F1 score of
0.95 in male C57BL/6J mice. When unrestricted, the network showed lower F1
scores on pre-REM (0.5) compared to the classical stages. The result is
comparable to previous attempts to score transitional stages in other species
such as transition sleep in rats or N1 sleep in humans. Nevertheless, we
observed that the sequence of predictions including pre-REM typically
transitioned from Non-REM to REM reflecting sleep dynamics observed by human
scorers. Our findings provide further evidence for the difficulty of scoring
transitional sleep stages, likely because such stages of sleep are
under-represented in typical data sets or show large inter-scorer variability.
We further provide our source code and an online platform to run predictions
with our trained network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local plasticity rules can learn deep representations using self-supervised contrastive predictions. (arXiv:2010.08262v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Illing_B/0/1/0/all/0/1">Bernd Illing</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventura_J/0/1/0/all/0/1">Jean Ventura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1">Guillaume Bellec</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1">Wulfram Gerstner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08262">
                                    <div class="article-summary-box-inner">
                                        <span>Learning in the brain is poorly understood and learning rules that respect
biological constraints, yet yield deep hierarchical representations, are still
unknown. Here, we propose a learning rule that takes inspiration from
neuroscience and recent advances in self-supervised deep learning. Learning
minimizes a simple layer-specific loss function and does not need to
back-propagate error signals within or between layers. Instead, weight updates
follow a local, Hebbian, learning rule that only depends on pre- and
post-synaptic neuronal activity, predictive dendritic input and widely
broadcasted modulation factors which are identical for large groups of neurons.
The learning rule applies contrastive predictive learning to a causal,
biological setting using saccades (i.e. rapid shifts in gaze direction). We
find that networks trained with this self-supervised and local rule build deep
hierarchical representations of images, speech and video.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-memory stochastic backpropagation with multi-channel randomized trace estimation. (arXiv:2106.06998v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Louboutin_M/0/1/0/all/0/1">Mathias Louboutin</a>, <a href="http://arxiv.org/find/cs/1/au:+Siahkoohi_A/0/1/0/all/0/1">Ali Siahkoohi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rongrong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrmann_F/0/1/0/all/0/1">Felix J. Herrmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06998">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to the combination of state-of-the-art accelerators and highly
optimized open software frameworks, there has been tremendous progress in the
performance of deep neural networks. While these developments have been
responsible for many breakthroughs, progress towards solving large-scale
problems, such as video encoding and semantic segmentation in 3D, is hampered
because access to on-premise memory is often limited. Instead of relying on
(optimal) checkpointing or invertibility of the network layers -- to recover
the activations during backpropagation -- we propose to approximate the
gradient of convolutional layers in neural networks with a multi-channel
randomized trace estimation technique. Compared to other methods, this approach
is simple, amenable to analyses, and leads to a greatly reduced memory
footprint. Even though the randomized trace estimation introduces stochasticity
during training, we argue that this is of little consequence as long as the
induced errors are of the same order as errors in the gradient due to the use
of stochastic gradient descent. We discuss the performance of networks trained
with stochastic backpropagation and how the error can be controlled while
maximizing memory usage and minimizing computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Automated Website Classification by Deep Learning. (arXiv:1910.09991v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fausti_F/0/1/0/all/0/1">Fabrizio De Fausti</a>, <a href="http://arxiv.org/find/cs/1/au:+Pugliese_F/0/1/0/all/0/1">Francesco Pugliese</a>, <a href="http://arxiv.org/find/cs/1/au:+Zardetto_D/0/1/0/all/0/1">Diego Zardetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.09991">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the interest in Big Data sources has been steadily growing
within the Official Statistic community. The Italian National Institute of
Statistics (Istat) is currently carrying out several Big Data pilot studies.
One of these studies, the ICT Big Data pilot, aims at exploiting massive
amounts of textual data automatically scraped from the websites of Italian
enterprises in order to predict a set of target variables (e.g. e-commerce)
that are routinely observed by the traditional ICT Survey. In this paper, we
show that Deep Learning techniques can successfully address this problem.
Essentially, we tackle a text classification task: an algorithm must learn to
infer whether an Italian enterprise performs e-commerce from the textual
content of its website. To reach this goal, we developed a sophisticated
processing pipeline and evaluated its performance through extensive
experiments. Our pipeline uses Convolutional Neural Networks and relies on Word
Embeddings to encode raw texts into grayscale images (i.e. normalized numeric
matrices). Web-scraped texts are huge and have very low signal to noise ratio:
to overcome these issues, we adopted a framework known as False Positive
Reduction, which has seldom (if ever) been applied before to text
classification tasks. Several original contributions enable our processing
pipeline to reach good classification results. Empirical evidence shows that
our proposal outperforms all the alternative Machine Learning solutions already
tested in Istat for the same task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Partial Response Network: a neural network nomogram. (arXiv:1908.05978v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lisboa_P/0/1/0/all/0/1">Paulo J. G. Lisboa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_Martorell_S/0/1/0/all/0/1">Sandra Ortega-Martorell</a>, <a href="http://arxiv.org/find/cs/1/au:+Cashman_S/0/1/0/all/0/1">Sadie Cashman</a>, <a href="http://arxiv.org/find/cs/1/au:+Olier_I/0/1/0/all/0/1">Ivan Olier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.05978">
                                    <div class="article-summary-box-inner">
                                        <span>Among interpretable machine learning methods, the class of Generalised
Additive Neural Networks (GANNs) is referred to as Self-Explaining Neural
Networks (SENN) because of the linear dependence on explicit functions of the
inputs. In binary classification this shows the precise weight that each input
contributes towards the logit. The nomogram is a graphical representation of
these weights. We show that functions of individual and pairs of variables can
be derived from a functional Analysis of Variance (ANOVA) representation,
enabling an efficient feature selection to be carried by application of the
logistic Lasso. This process infers the structure of GANNs which otherwise
needs to be predefined. As this method is particularly suited for tabular data,
it starts by fitting a generic flexible model, in this case a Multi-layer
Perceptron (MLP) to which the ANOVA decomposition is applied. This has the
further advantage that the resulting GANN can be replicated as a SENN, enabling
further refinement of the univariate and bivariate component functions to take
place. The component functions are partial responses hence the SENN is a
partial response network. The Partial Response Network (PRN) is equally as
transparent as a traditional logistic regression model, but capable of
non-linear classification with comparable or superior performance to the
original MLP. In other words, the PRN is a fully interpretable representation
of the MLP, at the level of univariate and bivariate effects. The performance
of the PRN is shown to be competitive for benchmark data, against
state-of-the-art machine learning methods including GBM, SVM and Random
Forests. It is also compared with spline-based Sparse Additive Models (SAM)
showing that a semi-parametric representation of the GAM as a neural network
can be as effective as the SAM though less constrained by the need to set
spline nodes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Automatic Actor-Critic Solutions to Continuous Control. (arXiv:2106.08918v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grigsby_J/0/1/0/all/0/1">Jake Grigsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Jin Yong Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yanjun Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08918">
                                    <div class="article-summary-box-inner">
                                        <span>Model-free off-policy actor-critic methods are an efficient solution to
complex continuous control tasks. However, these algorithms rely on a number of
design tricks and many hyperparameters, making their applications to new
domains difficult and computationally expensive. This paper creates an
evolutionary approach that automatically tunes these design decisions and
eliminates the RL-specific hyperparameters from the Soft Actor-Critic
algorithm. Our design is sample efficient and provides practical advantages
over baseline approaches, including improved exploration, generalization over
multiple control frequencies, and a robust ensemble of high-performance
policies. Empirically, we show that our agent outperforms well-tuned
hyperparameter settings in popular benchmarks from the DeepMind Control Suite.
We then apply it to new control tasks to find high-performance solutions with
minimal compute and research effort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Social Distance Estimation From Images: Performance Evaluation, Test Benchmark, and Algorithm. (arXiv:2103.06759v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1">Mert Seker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1">Anssi M&#xe4;nnist&#xf6;</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06759">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 virus has caused a global pandemic since March 2020. The World
Health Organization (WHO) has provided guidelines on how to reduce the spread
of the virus and one of the most important measures is social distancing.
Maintaining a minimum of one meter distance from other people is strongly
suggested to reduce the risk of infection. This has created a strong interest
in monitoring the social distances either as a safety measure or to study how
the measures have affected human behavior and country-wise differences in this.
The need for automatic social distance estimation algorithms is evident, but
there is no suitable test benchmark for such algorithms. Collecting images with
measured ground-truth pair-wise distances between all the people using
different camera settings is cumbersome. Furthermore, performance evaluation
for social distance estimation algorithms is not straightforward and there is
no widely accepted evaluation protocol. In this paper, we provide a dataset of
varying images with measured pair-wise social distances under different camera
positionings and focal length values. We suggest a performance evaluation
protocol and provide a benchmark to easily evaluate social distance estimation
algorithms. We also propose a method for automatic social distance estimation.
Our method takes advantage of object detection and human pose estimation. It
can be applied on any single image as long as focal length and sensor size
information are known. The results on our benchmark are encouraging with 92%
human detection rate and only 28.9% average error in distance estimation among
the detected people.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamically Grown Generative Adversarial Networks. (arXiv:2106.08505v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lanlan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuting Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jia Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08505">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work introduced progressive network growing as a promising way to ease
the training for large GANs, but the model design and architecture-growing
strategy still remain under-explored and needs manual design for different
image data. In this paper, we propose a method to dynamically grow a GAN during
training, optimizing the network architecture and its parameters together with
automation. The method embeds architecture search techniques as an interleaving
step with gradient-based training to periodically seek the optimal
architecture-growing strategy for the generator and discriminator. It enjoys
the benefits of both eased training because of progressive growing and improved
performance because of broader architecture design space. Experimental results
demonstrate new state-of-the-art of image generation. Observations in the
search procedure also provide constructive insights into the GAN model design
such as generator-discriminator balance and convolutional layer choices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random feature neural networks learn Black-Scholes type PDEs without curse of dimensionality. (arXiv:2106.08900v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonon_L/0/1/0/all/0/1">Lukas Gonon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08900">
                                    <div class="article-summary-box-inner">
                                        <span>This article investigates the use of random feature neural networks for
learning Kolmogorov partial (integro-)differential equations associated to
Black-Scholes and more general exponential L\&#x27;evy models. Random feature neural
networks are single-hidden-layer feedforward neural networks in which only the
output weights are trainable. This makes training particularly simple, but (a
priori) reduces expressivity. Interestingly, this is not the case for
Black-Scholes type PDEs, as we show here. We derive bounds for the prediction
error of random neural networks for learning sufficiently non-degenerate
Black-Scholes type models. A full error analysis is provided and it is shown
that the derived bounds do not suffer from the curse of dimensionality. We also
investigate an application of these results to basket options and validate the
bounds numerically.

These results prove that neural networks are able to \textit{learn} solutions
to Black-Scholes type PDEs without the curse of dimensionality. In addition,
this provides an example of a relevant learning problem in which random feature
neural networks are provably efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised GANs with Label Augmentation. (arXiv:2106.08601v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Liang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huawei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08601">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, transformation-based self-supervised learning has been applied to
generative adversarial networks (GANs) to mitigate the catastrophic forgetting
problem of discriminator by learning stable representations. However, the
separate self-supervised tasks in existing self-supervised GANs cause an
inconsistent goal with generative modeling due to the learning of the generator
from their generator distribution-agnostic classifiers. To address this issue,
we propose a novel self-supervised GANs framework with label augmentation,
i.e., augmenting the GAN labels (real or fake) with the self-supervised
pseudo-labels. In particular, the discriminator and the self-supervised
classifier are unified to learn a single task that predicts the augmented label
such that the discriminator/classifier is aware of the generator distribution,
while the generator tries to confuse the discriminator/classifier by optimizing
the discrepancy between the transformed real and generated distributions.
Theoretically, we prove that the generator, at the equilibrium point, converges
to replicate the data distribution. Empirically, we demonstrate that the
proposed method significantly outperforms competitive baselines on both
generative modeling and representation learning across benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drum-Aware Ensemble Architecture for Improved Joint Musical Beat and Downbeat Tracking. (arXiv:2106.08685v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Ching-Yu Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1">Alvin Wen-Yu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08685">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel system architecture that integrates blind source
separation with joint beat and downbeat tracking in musical audio signals. The
source separation module segregates the percussive and non-percussive
components of the input signal, over which beat and downbeat tracking are
performed separately and then the results are aggregated with a learnable
fusion mechanism. This way, the system can adaptively determine how much the
tracking result for an input signal should depend on the input&#x27;s percussive or
non-percussive components. Evaluation on four testing sets that feature
different levels of presence of drum sounds shows that the new architecture
consistently outperforms the widely-adopted baseline architecture that does not
employ source separation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Quantum Property Prediction via Deeper 2D and 3D Graph Networks. (arXiv:2106.08551v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Cong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yaochen Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shenglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08551">
                                    <div class="article-summary-box-inner">
                                        <span>Molecular property prediction is gaining increasing attention due to its
diverse applications. One task of particular interests and importance is to
predict quantum chemical properties without 3D equilibrium structures. This is
practically favorable since obtaining 3D equilibrium structures requires
extremely expensive calculations. In this work, we design a deep graph neural
network to predict quantum properties by directly learning from 2D molecular
graphs. In addition, we propose a 3D graph neural network to learn from
low-cost conformer sets, which can be obtained with open-source tools using an
affordable budget. We employ our methods to participate in the 2021 KDD Cup on
OGB Large-Scale Challenge (OGB-LSC), which aims to predict the HOMO-LUMO energy
gap of molecules. Final evaluation results reveal that we are one of the
winners with a mean absolute error of 0.1235 on the holdout test set. Our
implementation is available as part of the MoleculeX package
(https://github.com/divelab/MoleculeX).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-Efficient Agnostic Federated Averaging. (arXiv:2104.02748v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ro_J/0/1/0/all/0/1">Jae Ro</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingqing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1">Rajiv Mathews</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1">Mehryar Mohri</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ananda Theertha Suresh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02748">
                                    <div class="article-summary-box-inner">
                                        <span>In distributed learning settings such as federated learning, the training
algorithm can be potentially biased towards different clients. Mohri et al.
(2019) proposed a domain-agnostic learning algorithm, where the model is
optimized for any target distribution formed by a mixture of the client
distributions in order to overcome this bias. They further proposed an
algorithm for the cross-silo federated learning setting, where the number of
clients is small. We consider this problem in the cross-device setting, where
the number of clients is much larger. We propose a communication-efficient
distributed algorithm called Agnostic Federated Averaging (or AgnosticFedAvg)
to minimize the domain-agnostic objective proposed in Mohri et al. (2019),
which is amenable to other private mechanisms such as secure aggregation. We
highlight two types of naturally occurring domains in federated learning and
argue that AgnosticFedAvg performs well on both. To demonstrate the practical
effectiveness of AgnosticFedAvg, we report positive results for large-scale
language modeling tasks in both simulation and live experiments, where the
latter involves training language models for Spanish virtual keyboard for
millions of user devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Sample Complexity and Metastability of Heavy-tailed Policy Search in Continuous Control. (arXiv:2106.08414v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bedi_A/0/1/0/all/0/1">Amrit Singh Bedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parayil_A/0/1/0/all/0/1">Anjaly Parayil</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koppel_A/0/1/0/all/0/1">Alec Koppel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08414">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning is a framework for interactive decision-making with
incentives sequentially revealed across time without a system dynamics model.
Due to its scaling to continuous spaces, we focus on policy search where one
iteratively improves a parameterized policy with stochastic policy gradient
(PG) updates. In tabular Markov Decision Problems (MDPs), under persistent
exploration and suitable parameterization, global optimality may be obtained.
By contrast, in continuous space, the non-convexity poses a pathological
challenge as evidenced by existing convergence results being mostly limited to
stationarity or arbitrary local extrema. To close this gap, we step towards
persistent exploration in continuous space through policy parameterizations
defined by distributions of heavier tails defined by tail-index parameter
alpha, which increases the likelihood of jumping in state space. Doing so
invalidates smoothness conditions of the score function common to PG. Thus, we
establish how the convergence rate to stationarity depends on the policy&#x27;s tail
index alpha, a Holder continuity parameter, integrability conditions, and an
exploration tolerance parameter introduced here for the first time. Further, we
characterize the dependence of the set of local maxima on the tail index
through an exit and transition time analysis of a suitably defined Markov
chain, identifying that policies associated with Levy Processes of a heavier
tail converge to wider peaks. This phenomenon yields improved stability to
perturbations in supervised learning, which we corroborate also manifests in
improved performance of policy search, especially when myopic and farsighted
incentives are misaligned.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Evaluating and Training Verifiably Robust Neural Networks. (arXiv:2104.00447v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zhaoyang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Minghao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guodong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kehuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00447">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have shown that interval bound propagation (IBP) can be used to
train verifiably robust neural networks. Reseachers observe an intriguing
phenomenon on these IBP trained networks: CROWN, a bounding method based on
tight linear relaxation, often gives very loose bounds on these networks. We
also observe that most neurons become dead during the IBP training process,
which could hurt the representation capability of the network. In this paper,
we study the relationship between IBP and CROWN, and prove that CROWN is always
tighter than IBP when choosing appropriate bounding lines. We further propose a
relaxed version of CROWN, linear bound propagation (LBP), that can be used to
verify large networks to obtain lower verified errors than IBP. We also design
a new activation function, parameterized ramp function (ParamRamp), which has
more diversity of neuron status than ReLU. We conduct extensive experiments on
MNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve
state-of-the-art verified robustness. Code and the appendix are available at
https://github.com/ZhaoyangLyu/VerifiablyRobustNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sani_N/0/1/0/all/0/1">Numair Sani</a>, <a href="http://arxiv.org/find/cs/1/au:+Malinsky_D/0/1/0/all/0/1">Daniel Malinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Shpitser_I/0/1/0/all/0/1">Ilya Shpitser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02482">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to explain the behavior of black-box prediction methods (e.g.,
deep neural networks trained on image pixel data) using causal graphical
models. Specifically, we explore learning the structure of a causal graph where
the nodes represent prediction outcomes along with a set of macro-level
&quot;interpretable&quot; features, while allowing for arbitrary unmeasured confounding
among these variables. The resulting graph may indicate which of the
interpretable features, if any, are possible causes of the prediction outcome
and which may be merely associated with prediction outcomes due to confounding.
The approach is motivated by a counterfactual theory of causal explanation
wherein good explanations point to factors that are &quot;difference-makers&quot; in an
interventionist sense. The resulting analysis may be useful in algorithm
auditing and evaluation, by identifying features which make a causal difference
to the algorithm&#x27;s output.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thompson Sampling with Information Relaxation Penalties. (arXiv:1902.04251v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1">Seungki Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Maglaras_C/0/1/0/all/0/1">Costis Maglaras</a>, <a href="http://arxiv.org/find/cs/1/au:+Moallemi_C/0/1/0/all/0/1">Ciamac C. Moallemi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.04251">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a finite-horizon multi-armed bandit (MAB) problem in a Bayesian
setting, for which we propose an information relaxation sampling framework.
With this framework, we define an intuitive family of control policies that
include Thompson sampling (TS) and the Bayesian optimal policy as endpoints.
Analogous to TS, which, at each decision epoch pulls an arm that is best with
respect to the randomly sampled parameters, our algorithms sample entire future
reward realizations and take the corresponding best action. However, this is
done in the presence of &quot;penalties&quot; that seek to compensate for the
availability of future information.

We develop several novel policies and performance bounds for MAB problems
that vary in terms of improving performance and increasing computational
complexity between the two endpoints. Our policies can be viewed as natural
generalizations of TS that simultaneously incorporate knowledge of the time
horizon and explicitly consider the exploration-exploitation trade-off. We
prove associated structural results on performance bounds and suboptimality
gaps. Numerical experiments suggest that this new class of policies perform
well, in particular in settings where the finite time horizon introduces
significant exploration-exploitation tension into the problem. Finally,
inspired by the finite-horizon Gittins index, we propose an index policy that
builds on our framework that particularly outperforms the state-of-the-art
algorithms in our numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dense for the Price of Sparse: Improved Performance of Sparsely Initialized Networks via a Subspace Offset. (arXiv:2102.07655v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Price_I/0/1/0/all/0/1">Ilan Price</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanner_J/0/1/0/all/0/1">Jared Tanner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07655">
                                    <div class="article-summary-box-inner">
                                        <span>That neural networks may be pruned to high sparsities and retain high
accuracy is well established. Recent research efforts focus on pruning
immediately after initialization so as to allow the computational savings
afforded by sparsity to extend to the training process. In this work, we
introduce a new &#x60;DCT plus Sparse&#x27; layer architecture, which maintains
information propagation and trainability even with as little as 0.01% trainable
kernel parameters remaining. We show that standard training of networks built
with these layers, and pruned at initialization, achieves state-of-the-art
accuracy for extreme sparsities on a variety of benchmark network architectures
and datasets. Moreover, these results are achieved using only simple heuristics
to determine the locations of the trainable parameters in the network, and thus
without having to initially store or compute with the full, unpruned network,
as is required by competing prune-at-initialization algorithms. Switching from
standard sparse layers to DCT plus Sparse layers does not increase the storage
footprint of a network and incurs only a small additional computational
overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving. (arXiv:2106.08372v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_A/0/1/0/all/0/1">Anthony Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Max Paul Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Resch_M/0/1/0/all/0/1">Michael Resch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08372">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing safety validation requirements for the release of a
self-driving car, alternative approaches, such as simulation-based testing, are
emerging in addition to conventional real-world testing. In order to rely on
virtual tests the employed sensor models have to be validated. For this reason,
it is necessary to quantify the discrepancy between simulation and reality in
order to determine whether a certain fidelity is sufficient for a desired
intended use. There exists no sound method to measure this
simulation-to-reality gap of radar perception for autonomous driving. We
address this problem by introducing a multi-layered evaluation approach, which
consists of a combination of an explicit and an implicit sensor model
evaluation. The former directly evaluates the realism of the synthetically
generated sensor data, while the latter refers to an evaluation of a downstream
target application. In order to demonstrate the method, we evaluated the
fidelity of three typical radar model types (ideal, data-driven, ray
tracing-based) and their applicability for virtually testing radar-based
multi-object tracking. We have shown the effectiveness of the proposed approach
in terms of providing an in-depth sensor model assessment that renders existing
disparities visible and enables a realistic estimation of the overall model
fidelity across different scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Visibility Graph Neural Network and It&#x27;s Application in Modulation Classification. (arXiv:2106.08564v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1">Qi Xuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1">Kunfeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jinchao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhuangzhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dongwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shilian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoniu Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08564">
                                    <div class="article-summary-box-inner">
                                        <span>Our digital world is full of time series and graphs which capture the various
aspects of many complex systems. Traditionally, there are respective methods in
processing these two different types of data, e.g., Recurrent Neural Network
(RNN) and Graph Neural Network (GNN), while in recent years, time series could
be mapped to graphs by using the techniques such as Visibility Graph (VG), so
that researchers can use graph algorithms to mine the knowledge in time series.
Such mapping methods establish a bridge between time series and graphs, and
have high potential to facilitate the analysis of various real-world time
series. However, the VG method and its variants are just based on fixed rules
and thus lack of flexibility, largely limiting their application in reality. In
this paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can
adaptively map time series into graphs, based on which we further establish an
end-to-end classification framework AVGNet, by utilizing GNN model DiffPool as
the classifier. We then adopt AVGNet for radio signal modulation classification
which is an important task in the field of wireless communication. The
simulations validate that AVGNet outperforms a series of advanced deep learning
methods, achieving the state-of-the-art performance in this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining Language Models with Compositional Explanations. (arXiv:2103.10415v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Huihan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Ying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qinyuan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xisen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10415">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models have been successful on text classification
tasks, but are prone to learning spurious correlations from biased datasets,
and are thus vulnerable when making inferences in a new domain. Prior works
reveal such spurious patterns via post-hoc explanation algorithms which compute
the importance of input features. Further, the model is regularized to align
the importance scores with human knowledge, so that the unintended model
behaviors are eliminated. However, such a regularization technique lacks
flexibility and coverage, since only importance scores towards a pre-defined
list of features are adjusted, while more complex human knowledge such as
feature interaction and pattern generalization can hardly be incorporated. In
this work, we propose to refine a learned language model for a target domain by
collecting human-provided compositional explanations regarding observed biases.
By parsing these explanations into executable logic rules, the human-specified
refinement advice from a small set of explanations can be generalized to more
training examples. We additionally introduce a regularization term allowing
adjustments for both importance and interaction of features to better rectify
model behavior. We demonstrate the effectiveness of the proposed approach on
two text classification tasks by showing improved performance in target domain
as well as improved model fairness after refinement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Wasserstein Minimax Framework for Mixed Linear Regression. (arXiv:2106.07537v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Diamandis_T/0/1/0/all/0/1">Theo Diamandis</a>, <a href="http://arxiv.org/find/stat/1/au:+Eldar_Y/0/1/0/all/0/1">Yonina C. Eldar</a>, <a href="http://arxiv.org/find/stat/1/au:+Fallah_A/0/1/0/all/0/1">Alireza Fallah</a>, <a href="http://arxiv.org/find/stat/1/au:+Farnia_F/0/1/0/all/0/1">Farzan Farnia</a>, <a href="http://arxiv.org/find/stat/1/au:+Ozdaglar_A/0/1/0/all/0/1">Asuman Ozdaglar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07537">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-modal distributions are commonly used to model clustered data in
statistical learning tasks. In this paper, we consider the Mixed Linear
Regression (MLR) problem. We propose an optimal transport-based framework for
MLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the
Wasserstein distance between the learned and target mixture regression models.
Through a model-based duality analysis, WMLR reduces the underlying MLR task to
a nonconvex-concave minimax optimization problem, which can be provably solved
to find a minimax stationary point by the Gradient Descent Ascent (GDA)
algorithm. In the special case of mixtures of two linear regression models, we
show that WMLR enjoys global convergence and generalization guarantees. We
prove that WMLR&#x27;s sample complexity grows linearly with the dimension of data.
Finally, we discuss the application of WMLR to the federated learning task
where the training samples are collected by multiple agents in a network.
Unlike the Expectation Maximization algorithm, WMLR directly extends to the
distributed, federated learning setting. We support our theoretical results
through several numerical experiments, which highlight our framework&#x27;s ability
to handle the federated learning setting with mixture models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models. (arXiv:2106.03969v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boix_Adsera_E/0/1/0/all/0/1">Enric Boix-Adsera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bresler_G/0/1/0/all/0/1">Guy Bresler</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1">Frederic Koehler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03969">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning a tree-structured Ising model from data,
such that subsequent predictions computed using the model are accurate.
Concretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small
sets of variables $S$ are accurate. Since its introduction more than 50 years
ago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood
tree, has been the benchmark algorithm for learning tree-structured graphical
models. A bound on the sample complexity of the Chow-Liu algorithm with respect
to the prediction-centric local total variation loss was shown in [BK19]. While
those results demonstrated that it is possible to learn a useful model even
when recovering the true underlying graph is impossible, their bound depends on
the maximum strength of interactions and thus does not achieve the
information-theoretic optimum. In this paper, we introduce a new algorithm that
carefully combines elements of the Chow-Liu algorithm with tree metric
reconstruction methods to efficiently and optimally learn tree Ising models
under a prediction-centric loss. Our algorithm is robust to model
misspecification and adversarial corruptions. In contrast, we show that the
celebrated Chow-Liu algorithm can be arbitrarily suboptimal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition. (arXiv:2106.08922v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Higuchi_Y/0/1/0/all/0/1">Yosuke Higuchi</a>, <a href="http://arxiv.org/find/eess/1/au:+Moritz_N/0/1/0/all/0/1">Niko Moritz</a>, <a href="http://arxiv.org/find/eess/1/au:+Roux_J/0/1/0/all/0/1">Jonathan Le Roux</a>, <a href="http://arxiv.org/find/eess/1/au:+Hori_T/0/1/0/all/0/1">Takaaki Hori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08922">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-labeling (PL) has been shown to be effective in semi-supervised
automatic speech recognition (ASR), where a base model is self-trained with
pseudo-labels generated from unlabeled data. While PL can be further improved
by iteratively updating pseudo-labels as the model evolves, most of the
previous approaches involve inefficient retraining of the model or intricate
control of the label update. We present momentum pseudo-labeling (MPL), a
simple yet effective strategy for semi-supervised ASR. MPL consists of a pair
of online and offline models that interact and learn from each other, inspired
by the mean teacher method. The online model is trained to predict
pseudo-labels generated on the fly by the offline model. The offline model
maintains a momentum-based moving average of the online model. MPL is performed
in a single training process and the interaction between the two models
effectively helps them reinforce each other to improve the ASR performance. We
apply MPL to an end-to-end ASR model based on the connectionist temporal
classification. The experimental results demonstrate that MPL effectively
improves over the base model and is scalable to different semi-supervised
scenarios with varying amounts of data or domain mismatch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imperfect ImaGANation: Implications of GANs Exacerbating Biases on Facial Data Augmentation and Snapchat Selfie Lenses. (arXiv:2001.09528v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1">Niharika Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Olmo_A/0/1/0/all/0/1">Alberto Olmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1">Sailik Sengupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Manikonda_L/0/1/0/all/0/1">Lydia Manikonda</a>, <a href="http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1">Subbarao Kambhampati</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09528">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we show that popular Generative Adversarial Networks (GANs)
exacerbate biases along the axes of gender and skin tone when given a skewed
distribution of face-shots. While practitioners celebrate synthetic data
generation using GANs as an economical way to augment data for training
data-hungry machine learning models, it is unclear whether they recognize the
perils of such techniques when applied to real world datasets biased along
latent dimensions. Specifically, we show that (1) traditional GANs further skew
the distribution of a dataset consisting of engineering faculty headshots,
generating minority modes less often and of worse quality and (2)
image-to-image translation (conditional) GANs also exacerbate biases by
lightening skin color of non-white faces and transforming female facial
features to be masculine when generating faces of engineering professors. Thus,
our study is meant to serve as a cautionary tale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code to Comment Translation: A Comparative Study on Model Effectiveness &amp; Errors. (arXiv:2106.08415v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1">Junayed Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1">Fahim Faisal</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnob_R/0/1/0/all/0/1">Raihan Islam Arnob</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1">Antonios Anastasopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_K/0/1/0/all/0/1">Kevin Moran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08415">
                                    <div class="article-summary-box-inner">
                                        <span>Automated source code summarization is a popular software engineering
research topic wherein machine translation models are employed to &quot;translate&quot;
code snippets into relevant natural language descriptions. Most evaluations of
such models are conducted using automatic reference-based metrics. However,
given the relatively large semantic gap between programming languages and
natural language, we argue that this line of research would benefit from a
qualitative investigation into the various error modes of current
state-of-the-art models. Therefore, in this work, we perform both a
quantitative and qualitative comparison of three recently proposed source code
summarization models. In our quantitative evaluation, we compare the models
based on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,
and in our qualitative evaluation, we perform a manual open-coding of the most
common errors committed by the models when compared to ground truth captions.
Our investigation reveals new insights into the relationship between
metric-based performance and model prediction errors grounded in an empirically
derived error taxonomy that can be used to drive future research efforts</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Contextual Bandits with Overparameterized Models. (arXiv:2006.15368v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandfonbrener_D/0/1/0/all/0/1">David Brandfonbrener</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1">William F. Whitney</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1">Rajesh Ranganath</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15368">
                                    <div class="article-summary-box-inner">
                                        <span>Recent results in supervised learning suggest that while overparameterized
models have the capacity to overfit, they in fact generalize quite well. We ask
whether the same phenomenon occurs for offline contextual bandits. Our results
are mixed. Value-based algorithms benefit from the same generalization behavior
as overparameterized supervised learning, but policy-based algorithms do not.
We show that this discrepancy is due to the \emph{action-stability} of their
objectives. An objective is action-stable if there exists a prediction
(action-value vector or action distribution) which is optimal no matter which
action is observed. While value-based objectives are action-stable,
policy-based objectives are unstable. We formally prove upper bounds on the
regret of overparameterized value-based learning and lower bounds on the regret
for policy-based algorithms. In our experiments with large neural networks,
this gap between action-stable value-based objectives and unstable policy-based
objectives leads to significant performance differences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge Sparse Basis Network: A Deep Learning Framework for EEG Source Localization. (arXiv:2102.09188v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chen Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_K/0/1/0/all/0/1">Kexin Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhengyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mingqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantini_D/0/1/0/all/0/1">Dante Mantini</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Quanying Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09188">
                                    <div class="article-summary-box-inner">
                                        <span>EEG source localization is an important technical issue in EEG analysis.
Despite many numerical methods existed for EEG source localization, they all
rely on strong priors and the deep sources are intractable. Here we propose a
deep learning framework using spatial basis function decomposition for EEG
source localization. This framework combines the edge sparsity prior and
Gaussian source basis, called Edge Sparse Basis Network (ESBN). The performance
of ESBN is validated by both synthetic data and real EEG data during motor
tasks. The results suggest that the supervised ESBN outperforms the traditional
numerical methods in synthetic data and the unsupervised fine-tuning provides
more focal and accurate localizations in real data. Our proposed deep learning
framework can be extended to account for other source priors, and the real-time
property of ESBN can facilitate the applications of EEG in brain-computer
interfaces and clinics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent. (arXiv:2106.08502v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Altschuler_J/0/1/0/all/0/1">Jason M. Altschuler</a>, <a href="http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1">Sinho Chewi</a>, <a href="http://arxiv.org/find/math/1/au:+Gerber_P/0/1/0/all/0/1">Patrik Gerber</a>, <a href="http://arxiv.org/find/math/1/au:+Stromme_A/0/1/0/all/0/1">Austin J. Stromme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08502">
                                    <div class="article-summary-box-inner">
                                        <span>We study first-order optimization algorithms for computing the barycenter of
Gaussian distributions with respect to the optimal transport metric. Although
the objective is geodesically non-convex, Riemannian GD empirically converges
rapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP
solvers. This stands in stark contrast to the best-known theoretical results
for Riemannian GD, which depend exponentially on the dimension. In this work,
we prove new geodesic convexity results which provide stronger control of the
iterates, yielding a dimension-free convergence rate. Our techniques also
enable the analysis of two related notions of averaging, the
entropically-regularized barycenter and the geometric median, providing the
first convergence guarantees for Riemannian GD for these problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset-Level Geometric Framework for Ensemble Classifiers. (arXiv:2106.08658v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengli Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Weimin Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08658">
                                    <div class="article-summary-box-inner">
                                        <span>Ensemble classifiers have been investigated by many in the artificial
intelligence and machine learning community. Majority voting and weighted
majority voting are two commonly used combination schemes in ensemble learning.
However, understanding of them is incomplete at best, with some properties even
misunderstood. In this paper, we present a group of properties of these two
schemes formally under a dataset-level geometric framework. Two key factors,
every component base classifier&#x27;s performance and dissimilarity between each
pair of component classifiers are evaluated by the same metric - the Euclidean
distance. Consequently, ensembling becomes a deterministic problem and the
performance of an ensemble can be calculated directly by a formula. We prove
several theorems of interest and explain their implications for ensembles. In
particular, we compare and contrast the effect of the number of component
classifiers on these two types of ensemble schemes. Empirical investigation is
also conducted to verify the theoretical results when other metrics such as
accuracy are used. We believe that the results from this paper are very useful
for us to understand the fundamental properties of these two combination
schemes and the principles of ensemble classifiers in general. The results are
also helpful for us to investigate some issues in ensemble classifiers, such as
ensemble performance prediction, selecting a small number of base classifiers
to obtain efficient and effective ensembles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peijie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09373">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training has been the topic of dozens of studies and a leading
method for defending against adversarial attacks. Yet, it remains largely
unknown (a) how adversarially-robust ImageNet classifiers (R classifiers)
generalize to out-of-distribution examples; and (b) how their generalization
capability relates to their hidden representations. In this paper, we perform a
thorough, systematic study to answer these two questions across AlexNet,
GoogLeNet, and ResNet-50 architectures. We found that while standard ImageNet
classifiers have a strong texture bias, their R counterparts rely heavily on
shapes. Remarkably, adversarial training induces three simplicity biases into
hidden neurons in the process of &#x27;robustifying&#x27; the network. That is, each
convolutional neuron in R networks often changes to detecting (1) pixel-wise
smoother patterns i.e. a mechanism that blocks high-frequency noise from
passing through the network; (2) more lower-level features i.e. textures and
colors (instead of objects); and (3) fewer types of inputs. Our findings reveal
the interesting mechanisms that made networks more adversarially robust and
also explain some recent findings. Our findings reveal the interesting
mechanisms that made networks more adversarially robust and also explain some
recent findings e.g. why R networks benefit from much larger capacity (Xie and
Yuille, 2020) and can act as a strong image prior in image synthesis (Santurkar
et al., 2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hash Layers For Large Sparse Models. (arXiv:2106.04426v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1">Arthur Szlam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04426">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the training of sparse layers that use different parameters
for different inputs based on hashing in large Transformer models.
Specifically, we modify the feedforward layer to hash to different sets of
weights depending on the current token, over all tokens in the sequence. We
show that this procedure either outperforms or is competitive with
learning-to-route mixture-of-expert methods such as Switch Transformers and
BASE Layers, while requiring no routing parameters or extra terms in the
objective function such as a load balancing loss, and no sophisticated
assignment algorithm. We study the performance of different hashing techniques,
hash sizes and input features, and show that balanced and random hashes focused
on the most local features work best, compared to either learning clusters or
using longer-range context. We show our approach works well both on large
language modeling and dialogue tasks, and on downstream fine-tuning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Loss Landscape in Neural Architecture Search. (arXiv:2005.02960v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1">Colin White</a>, <a href="http://arxiv.org/find/cs/1/au:+Nolen_S/0/1/0/all/0/1">Sam Nolen</a>, <a href="http://arxiv.org/find/cs/1/au:+Savani_Y/0/1/0/all/0/1">Yash Savani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.02960">
                                    <div class="article-summary-box-inner">
                                        <span>Neural architecture search (NAS) has seen a steep rise in interest over the
last few years. Many algorithms for NAS consist of searching through a space of
architectures by iteratively choosing an architecture, evaluating its
performance by training it, and using all prior evaluations to come up with the
next choice. The evaluation step is noisy - the final accuracy varies based on
the random initialization of the weights. Prior work has focused on devising
new search algorithms to handle this noise, rather than quantifying or
understanding the level of noise in architecture evaluations. In this work, we
show that (1) the simplest hill-climbing algorithm is a powerful baseline for
NAS, and (2), when the noise in popular NAS benchmark datasets is reduced to a
minimum, hill-climbing to outperforms many popular state-of-the-art algorithms.
We further back up this observation by showing that the number of local minima
is substantially reduced as the noise decreases, and by giving a theoretical
characterization of the performance of local search in NAS. Based on our
findings, for NAS research we suggest (1) using local search as a baseline, and
(2) denoising the training pipeline when possible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting crop yields with little ground truth: A simple statistical model for in-season forecasting. (arXiv:2106.08720v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Semret_N/0/1/0/all/0/1">Nemo Semret</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08720">
                                    <div class="article-summary-box-inner">
                                        <span>We present a fully automated model for in-season crop yield prediction,
designed to work where there is a dearth of sub-national &quot;ground truth&quot;
information. Our approach relies primarily on satellite data and is
characterized by careful feature engineering combined with a simple regression
model. As such, it can work almost anywhere in the world. Applying it to 10
different crop-country pairs (5 cereals -- corn, wheat, sorghum, barley and
millet, in 2 countries -- Ethiopia and Kenya), we achieve RMSEs of 5\%-10\% for
predictions 9 months into the year, and 7\%-14\% for predictions 3 months into
the year. The model outputs daily forecasts for the final yield of the current
year. It is trained using approximately 4 million data points for each
crop-country pair. These consist of: historical country-level annual yields,
crop calendars, crop cover, NDVI, temperature, rainfall, and
evapotransporation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-Based Vulnerability Analysis of Cyber-Physical Systems. (arXiv:2103.06271v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khazraei_A/0/1/0/all/0/1">Amir Khazraei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hallyburton_S/0/1/0/all/0/1">Spencer Hallyburton</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qitong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1">Miroslav Pajic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06271">
                                    <div class="article-summary-box-inner">
                                        <span>This work focuses on the use of deep learning for vulnerability analysis of
cyber-physical systems (CPS). Specifically, we consider a control architecture
widely used in CPS (e.g., robotics), where the low-level control is based on
e.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate
analyzing the impact potential sensing attacks could have, our objective is to
develop learning-enabled attack generators capable of designing stealthy
attacks that maximally degrade system operation. We show how such problem can
be cast within a learning-based grey-box framework where parts of the runtime
information are known to the attacker, and introduce two models based on
feed-forward neural networks (FNN); both models are trained offline, using a
cost function that combines the attack effects on the estimation error and the
residual signal used for anomaly detection, so that the trained models are
capable of recursively generating such effective sensor attacks in real-time.
The effectiveness of the proposed methods is illustrated on several case
studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interval-censored Hawkes processes. (arXiv:2104.07932v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1">Marian-Andrei Rizoiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1">Alexander Soen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shidi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Leanne Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1">Pio Calderon</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Krishna Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lexing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07932">
                                    <div class="article-summary-box-inner">
                                        <span>This work builds a novel point process and tools to use the Hawkes process
with interval-censored data. Such data records the aggregated counts of events
solely during specific time intervals -- such as the number of patients
admitted to the hospital or the volume of vehicles passing traffic loop
detectors -- and not the exact occurrence time of the events. First, we
establish the Mean Behavior Poisson (MBP) process, a novel Poisson process with
a direct parameter correspondence to the popular self-exciting Hawkes process.
The event intensity function of the MBP is the expected intensity over all
possible Hawkes realizations with the same parameter set. We fit MBP in the
interval-censored setting using an interval-censored Poisson log-likelihood
(IC-LL). We use the parameter equivalence to uncover the parameters of the
associated Hawkes process. Second, we introduce two novel exogenous functions
to distinguish the exogenous from the endogenous events. We propose the
multi-impulse exogenous function when the exogenous events are observed as
event time and the latent homogeneous Poisson process exogenous function when
the exogenous events are presented as interval-censored volumes. Third, we
provide several approximation methods to estimate the intensity and compensator
function of MBP when no analytical solution exists. Fourth and finally, we
connect the interval-censored loss of MBP to a broader class of Bregman
divergence-based functions. Using the connection, we show that the current
state of the art in popularity estimation (Hawkes Intensity Process (HIP)
(Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our
models through empirical testing on synthetic data and real-world data. We find
that on real-world datasets that ourMBP process outperforms HIP for the task of
popularity prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PettingZoo: Gym for Multi-Agent Reinforcement Learning. (arXiv:2009.14471v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terry_J/0/1/0/all/0/1">J. K. Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_B/0/1/0/all/0/1">Benjamin Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Grammel_N/0/1/0/all/0/1">Nathaniel Grammel</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayakumar_M/0/1/0/all/0/1">Mario Jayakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hari_A/0/1/0/all/0/1">Ananth Hari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_R/0/1/0/all/0/1">Ryan Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1">Luis Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_R/0/1/0/all/0/1">Rodrigo Perez</a>, <a href="http://arxiv.org/find/cs/1/au:+Horsch_C/0/1/0/all/0/1">Caroline Horsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dieffendahl_C/0/1/0/all/0/1">Clemens Dieffendahl</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_N/0/1/0/all/0/1">Niall L. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokesh_Y/0/1/0/all/0/1">Yashas Lokesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_P/0/1/0/all/0/1">Praveen Ravi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14471">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the PettingZoo library and the accompanying Agent
Environment Cycle (&quot;AEC&quot;) games model. PettingZoo is a library of diverse sets
of multi-agent environments with a universal, elegant Python API. PettingZoo
was developed with the goal of accelerating research in Multi-Agent
Reinforcement Learning (&quot;MARL&quot;), by making work more interchangeable,
accessible and reproducible akin to what OpenAI&#x27;s Gym library did for
single-agent reinforcement learning. PettingZoo&#x27;s API, while inheriting many
features of Gym, is unique amongst MARL APIs in that it&#x27;s based around the
novel AEC games model. We argue, in part through case studies on major problems
in popular MARL environments, that the popular game models are poor conceptual
models of the games commonly used with MARL, that they promote severe bugs that
are hard to detect, and that the AEC games model addresses these problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Source Separation-based Data Augmentation for Improved Joint Beat and Downbeat Tracking. (arXiv:2106.08703v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Ching-Yu Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ching_J/0/1/0/all/0/1">Joann Ching</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsiao_W/0/1/0/all/0/1">Wen-Yi Hsiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Hua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1">Alvin Wen-Yu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08703">
                                    <div class="article-summary-box-inner">
                                        <span>Due to advances in deep learning, the performance of automatic beat and
downbeat tracking in musical audio signals has seen great improvement in recent
years. In training such deep learning based models, data augmentation has been
found an important technique. However, existing data augmentation methods for
this task mainly target at balancing the distribution of the training data with
respect to their tempo. In this paper, we investigate another approach for data
augmentation, to account for the composition of the training data in terms of
the percussive and non-percussive sound sources. Specifically, we propose to
employ a blind drum separation model to segregate the drum and non-drum sounds
from each training audio signal, filtering out training signals that are
drumless, and then use the obtained drum and non-drum stems to augment the
training data. We report experiments on four completely unseen test sets,
validating the effectiveness of the proposed method, and accordingly the
importance of drum sound composition in the training data for beat and downbeat
tracking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Biomanufacturing Harvesting Decisions under Limited Historical Data. (arXiv:2101.03735v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1">Wei Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Martagan_T/0/1/0/all/0/1">Tugce Martagan</a>, <a href="http://arxiv.org/find/stat/1/au:+Akcay_A/0/1/0/all/0/1">Alp Akcay</a>, <a href="http://arxiv.org/find/stat/1/au:+Ravenstein_B/0/1/0/all/0/1">Bram van Ravenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03735">
                                    <div class="article-summary-box-inner">
                                        <span>In biopharmaceutical manufacturing, fermentation processes play a critical
role on productivity and profit. A fermentation process uses living cells with
complex biological mechanisms, and this leads to high variability in the
process outputs. By building on the biological mechanisms of protein and
impurity growth, we introduce a stochastic model to characterize the
accumulation of the protein and impurity levels in the fermentation process.
However, a common challenge in industry is the availability of only very
limited amount of data especially in the development and early stage of
production. This adds an additional layer of uncertainty, referred to as model
risk, due to the difficulty of estimating the model parameters with limited
data. In this paper, we study the harvesting decision for a fermentation
process under model risk. In particular, we adopt a Bayesian approach to update
the unknown parameters of the growth-rate distributions, and use the resulting
posterior distributions to characterize the impact of model risk on
fermentation output variability. The harvesting problem is formulated as a
Markov decision process model with knowledge states that summarize the
posterior distributions and hence incorporate the model risk in
decision-making. The resulting model is solved by using a reinforcement
learning algorithm based on Bayesian sparse sampling. We provide analytical
results on the structure of the optimal policy and its objective function, and
explicitly study the impact of model risk on harvesting decisions. Our case
studies at MSD Animal Health demonstrate that the proposed model and solution
approach improve the harvesting decisions in real life by achieving
substantially higher average output from a fermentation batch along with lower
batch-to-batch variability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topology Distillation for Recommender System. (arXiv:2106.08700v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">SeongKu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Junyoung Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1">Wonbin Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08700">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender Systems (RS) have employed knowledge distillation which is a
model compression technique training a compact student model with the knowledge
transferred from a pre-trained large teacher model. Recent work has shown that
transferring knowledge from the teacher&#x27;s intermediate layer significantly
improves the recommendation quality of the student. However, they transfer the
knowledge of individual representation point-wise and thus have a limitation in
that primary information of RS lies in the relations in the representation
space. This paper proposes a new topology distillation approach that guides the
student by transferring the topological structure built upon the relations in
the teacher space. We first observe that simply making the student learn the
whole topological structure is not always effective and even degrades the
student&#x27;s performance. We demonstrate that because the capacity of the student
is highly limited compared to that of the teacher, learning the whole
topological structure is daunting for the student. To address this issue, we
propose a novel method named Hierarchical Topology Distillation (HTD) which
distills the topology hierarchically to cope with the large capacity gap. Our
extensive experiments on real-world datasets show that the proposed method
significantly outperforms the state-of-the-art competitors. We also provide
in-depth analyses to ascertain the benefit of distilling the topology for RS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Self-Knowledge From Contrastive Links to Classify Graph Nodes Without Passing Messages. (arXiv:2106.08541v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Aiguo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Ke Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08541">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, Graph Neural Networks (GNNs) following the Message Passing paradigm
become the dominant way to learn on graphic data. Models in this paradigm have
to spend extra space to look up adjacent nodes with adjacency matrices and
extra time to aggregate multiple messages from adjacent nodes. To address this
issue, we develop a method called LinkDist that distils self-knowledge from
connected node pairs into a Multi-Layer Perceptron (MLP) without the need to
aggregate messages. Experiment with 8 real-world datasets shows the MLP derived
from LinkDist can predict the label of a node without knowing its adjacencies
but achieve comparable accuracy against GNNs in the contexts of semi- and
full-supervised node classification. Moreover, LinkDist benefits from its
Non-Message Passing paradigm that we can also distil self-knowledge from
arbitrarily sampled node pairs in a contrastive way to further boost the
performance of LinkDist.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum-inspired event reconstruction with Tensor Networks: Matrix Product States. (arXiv:2106.08334v1 [hep-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ph/1/au:+Araz_J/0/1/0/all/0/1">Jack Y. Araz</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Spannowsky_M/0/1/0/all/0/1">Michael Spannowsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08334">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor Networks are non-trivial representations of high-dimensional tensors,
originally designed to describe quantum many-body systems. We show that Tensor
Networks are ideal vehicles to connect quantum mechanical concepts to machine
learning techniques, thereby facilitating an improved interpretability of
neural networks. This study presents the discrimination of top quark signal
over QCD background processes using a Matrix Product State classifier. We show
that entanglement entropy can be used to interpret what a network learns, which
can be used to reduce the complexity of the network and feature space without
loss of generality or performance. For the optimisation of the network, we
compare the Density Matrix Renormalization Group (DMRG) algorithm to stochastic
gradient descent (SGD) and propose a joined training algorithm to harness the
explainability of DMRG with the efficiency of SGD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polynomial Trajectory Predictions for Improved Learning Performance. (arXiv:2101.12616v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Freeman_I/0/1/0/all/0/1">Ido Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kummert_A/0/1/0/all/0/1">Anton Kummert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12616">
                                    <div class="article-summary-box-inner">
                                        <span>The rising demand for Active Safety systems in automotive applications
stresses the need for a reliable short to mid-term trajectory prediction.
Anticipating the unfolding path of road users, one can act to increase the
overall safety. In this work, we propose to train artificial neural networks
for movement understanding by predicting trajectories in their natural form, as
a function of time. Predicting polynomial coefficients allows us to increased
accuracy and improve generalisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-sample Test using Projected Wasserstein Distance: Breaking the Curse of Dimensionality. (arXiv:2010.11970v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jie Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1">Rui Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11970">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a projected Wasserstein distance for the two-sample test, a
fundamental problem in statistics and machine learning: given two sets of
samples, to determine whether they are from the same distribution. In
particular, we aim to circumvent the curse of dimensionality in Wasserstein
distance: when the dimension is high, it has diminishing testing power, which
is inherently due to the slow concentration property of Wasserstein metrics in
the high dimension space. A key contribution is to couple optimal projection to
find the low dimensional linear mapping to maximize the Wasserstein distance
between projected probability distributions. We characterize the theoretical
property of the finite-sample convergence rate on IPMs and present practical
algorithms for computing this metric. Numerical examples validate our
theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An unifying point of view on expressive power of GNNs. (arXiv:2106.08992v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1">Giuseppe Alessio D&#x27;Inverno</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1">Monica Bianchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sampoli_M/0/1/0/all/0/1">Maria Lucia Sampoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1">Franco Scarselli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08992">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) are a wide class of connectionist models for
graph processing. They perform an iterative message passing operation on each
node and its neighbors, to solve classification/ clustering tasks --- on some
nodes or on the whole graph --- collecting all such messages, regardless of
their order. Despite the differences among the various models belonging to this
class, most of them adopt the same computation scheme, based on a local
aggregation mechanism and, intuitively, the local computation framework is
mainly responsible for the expressive power of GNNs. In this paper, we prove
that the Weisfeiler--Lehman test induces an equivalence relationship on the
graph nodes that exactly corresponds to the unfolding equivalence, defined on
the original GNN model. Therefore, the results on the expressive power of the
original GNNs can be extended to general GNNs which, under mild conditions, can
be proved capable of approximating, in probability and up to any precision, any
function on graphs that respects the unfolding equivalence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Schr\&quot;odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1">Valentin De Bortoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1">James Thornton</a>, <a href="http://arxiv.org/find/stat/1/au:+Heng_J/0/1/0/all/0/1">Jeremy Heng</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01357">
                                    <div class="article-summary-box-inner">
                                        <span>Progressively applying Gaussian noise transforms complex data distributions
to approximately Gaussian. Reversing this dynamic defines a generative model.
When the forward noising process is given by a Stochastic Differential Equation
(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the
associated reverse-time SDE may be estimated using score-matching. A limitation
of this approach is that the forward-time SDE must be run for a sufficiently
long time for the final distribution to be approximately Gaussian. In contrast,
solving the Schr\&quot;odinger Bridge problem (SB), i.e. an entropy-regularized
optimal transport problem on path spaces, yields diffusions which generate
samples from the data distribution in finite time. We present Diffusion SB
(DSB), an original approximation of the Iterative Proportional Fitting (IPF)
procedure to solve the SB problem, and provide theoretical analysis along with
generative modeling experiments. The first DSB iteration recovers the
methodology proposed by Song et al. (2021), with the flexibility of using
shorter time intervals, as subsequent DSB iterations reduce the discrepancy
between the final-time marginal of the forward (resp. backward) SDE with
respect to the prior (resp. data) distribution. Beyond generative modeling, DSB
offers a widely applicable computational optimal transport tool as the
continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,
2013).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonequilibrium thermodynamics of self-supervised learning. (arXiv:2106.08981v1 [cond-mat.stat-mech])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Salazar_D/0/1/0/all/0/1">Domingos S. P. Salazar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08981">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning (SSL) of energy based models has an intuitive
relation to equilibrium thermodynamics because the softmax layer, mapping
energies to probabilities, is a Gibbs distribution. However, in what way SSL is
a thermodynamic process? We show that some SSL paradigms behave as a
thermodynamic composite system formed by representations and self-labels in
contact with a nonequilibrium reservoir. Moreover, this system is subjected to
usual thermodynamic cycles, such as adiabatic expansion and isochoric heating,
resulting in a generalized Gibbs ensemble (GGE). In this picture, we show that
learning is seen as a demon that operates in cycles using feedback measurements
to extract negative work from the system. As applications, we examine some SSL
algorithms using this idea.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis. (arXiv:2106.08352v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mohan_D/0/1/0/all/0/1">Devang S Ram Mohan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_V/0/1/0/all/0/1">Vivian Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Teh_T/0/1/0/all/0/1">Tian Huey Teh</a>, <a href="http://arxiv.org/find/eess/1/au:+Torresquintero_A/0/1/0/all/0/1">Alexandra Torresquintero</a>, <a href="http://arxiv.org/find/eess/1/au:+Wallis_C/0/1/0/all/0/1">Christopher G. R. Wallis</a>, <a href="http://arxiv.org/find/eess/1/au:+Staib_M/0/1/0/all/0/1">Marlene Staib</a>, <a href="http://arxiv.org/find/eess/1/au:+Foglianti_L/0/1/0/all/0/1">Lorenzo Foglianti</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_J/0/1/0/all/0/1">Jiameng Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+King_S/0/1/0/all/0/1">Simon King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08352">
                                    <div class="article-summary-box-inner">
                                        <span>Text does not fully specify the spoken form, so text-to-speech models must be
able to learn from speech data that vary in ways not explained by the
corresponding text. One way to reduce the amount of unexplained variation in
training data is to provide acoustic information as an additional learning
signal. When generating speech, modifying this acoustic information enables
multiple distinct renditions of a text to be produced.

Since much of the unexplained variation is in the prosody, we propose a model
that generates speech explicitly conditioned on the three primary acoustic
correlates of prosody: $F_{0}$, energy and duration. The model is flexible
about how the values of these features are specified: they can be externally
provided, or predicted from text, or predicted then subsequently modified.

Compared to a model that employs a variational auto-encoder to learn
unsupervised latent features, our model provides more interpretable,
temporally-precise, and disentangled control. When automatically predicting the
acoustic features from text, it generates speech that is more natural than that
from a Tacotron 2 model with reference encoder. Subsequent human-in-the-loop
modification of the predicted acoustic features can significantly further
increase naturalness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Reinforcement Learning Under Minimax Regret for Green Security. (arXiv:2106.08413v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lily Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1">Andrew Perrault</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1">Fei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haipeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1">Milind Tambe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08413">
                                    <div class="article-summary-box-inner">
                                        <span>Green security domains feature defenders who plan patrols in the face of
uncertainty about the adversarial behavior of poachers, illegal loggers, and
illegal fishers. Importantly, the deterrence effect of patrols on adversaries&#x27;
future behavior makes patrol planning a sequential decision-making problem.
Therefore, we focus on robust sequential patrol planning for green security
following the minimax regret criterion, which has not been considered in the
literature. We formulate the problem as a game between the defender and nature
who controls the parameter values of the adversarial behavior and design an
algorithm MIRROR to find a robust policy. MIRROR uses two reinforcement
learning-based oracles and solves a restricted game considering limited
defender strategies and parameter values. We evaluate MIRROR on real-world
poaching data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Interpretable Spatio-temporal Logic Properties for Spatially Distributed Systems. (arXiv:2106.08548v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohammadinejad_S/0/1/0/all/0/1">Sara Mohammadinejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1">Jyotirmy V. Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nenzi_L/0/1/0/all/0/1">Laura Nenzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08548">
                                    <div class="article-summary-box-inner">
                                        <span>The Internet-of-Things, complex sensor networks, multi-agent cyber-physical
systems are all examples of spatially distributed systems that continuously
evolve in time. Such systems generate huge amounts of spatio-temporal data, and
system designers are often interested in analyzing and discovering structure
within the data. There has been considerable interest in learning causal and
logical properties of temporal data using logics such as Signal Temporal Logic
(STL); however, there is limited work on discovering such relations on
spatio-temporal data. We propose the first set of algorithms for unsupervised
learning for spatio-temporal data. Our method does automatic feature extraction
from the spatio-temporal data by projecting it onto the parameter space of a
parametric spatio-temporal reach and escape logic (PSTREL). We propose an
agglomerative hierarchical clustering technique that guarantees that each
cluster satisfies a distinct STREL formula. We show that our method generates
STREL formulas of bounded description complexity using a novel decision-tree
approach which generalizes previous unsupervised learning techniques for Signal
Temporal Logic. We demonstrate the effectiveness of our approach on case
studies from diverse domains such as urban transportation, epidemiology, green
infrastructure, and air quality monitoring.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks. (arXiv:2106.07141v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozbulak_U/0/1/0/all/0/1">Utku Ozbulak</a>, <a href="http://arxiv.org/find/cs/1/au:+Anzaku_E/0/1/0/all/0/1">Esla Timothy Anzaku</a>, <a href="http://arxiv.org/find/cs/1/au:+Neve_W/0/1/0/all/0/1">Wesley De Neve</a>, <a href="http://arxiv.org/find/cs/1/au:+Messem_A/0/1/0/all/0/1">Arnout Van Messem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07141">
                                    <div class="article-summary-box-inner">
                                        <span>Although the adoption rate of deep neural networks (DNNs) has tremendously
increased in recent years, a solution for their vulnerability against
adversarial examples has not yet been found. As a result, substantial research
efforts are dedicated to fix this weakness, with many studies typically using a
subset of source images to generate adversarial examples, treating every image
in this subset as equal. We demonstrate that, in fact, not every source image
is equally suited for this kind of assessment. To do so, we devise a
large-scale model-to-model transferability scenario for which we meticulously
analyze the properties of adversarial examples, generated from every suitable
source image in ImageNet by making use of two of the most frequently deployed
attacks. In this transferability scenario, which involves seven distinct DNN
models, including the recently proposed vision transformers, we reveal that it
is possible to have a difference of up to $12.5\%$ in model-to-model
transferability success, $1.01$ in average $L_2$ perturbation, and $0.03$
($8/225$) in average $L_{\infty}$ perturbation when $1,000$ source images are
sampled randomly among all suitable candidates. We then take one of the first
steps in evaluating the robustness of images used to create adversarial
examples, proposing a number of simple but effective methods to identify
unsuitable source images, thus making it possible to mitigate extreme cases in
experimentation and support high-quality benchmarking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Better Understanding of Linear Models for Recommendation. (arXiv:2105.12937v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Ruoming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jing Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12937">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, linear regression models, such as EASE and SLIM, have shown to
often produce rather competitive results against more sophisticated deep
learning models. On the other side, the (weighted) matrix factorization
approaches have been popular choices for recommendation in the past and widely
adopted in the industry. In this work, we aim to theoretically understand the
relationship between these two approaches, which are the cornerstones of
model-based recommendations. Through the derivation and analysis of the
closed-form solutions for two basic regression and matrix factorization
approaches, we found these two approaches are indeed inherently related but
also diverge in how they &quot;scale-down&quot; the singular values of the original
user-item interaction matrix. This analysis also helps resolve the questions
related to the regularization parameter range and model complexities. We
further introduce a new learning algorithm in searching (hyper)parameters for
the closed-form solution and utilize it to discover the nearby models of the
existing solutions. The experimental results demonstrate that the basic models
and their closed-form solutions are indeed quite competitive against the
state-of-the-art models, thus, confirming the validity of studying the basic
models. The effectiveness of exploring the nearby models are also
experimentally validated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Classifiers in Product Space Forms. (arXiv:2102.10204v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1">Puoya Tabaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1">Eli Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Chao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jianhao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1">Olgica Milenkovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10204">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding methods for product spaces are powerful techniques for
low-distortion and low-dimensional representation of complex data structures.
Nevertheless, little is known regarding downstream learning and optimization
problems in such spaces. Here, we address the problem of linear classification
in a product space form -- a mix of Euclidean, spherical, and hyperbolic
spaces. First, we describe new formulations for linear classifiers on a
Riemannian manifold using geodesics and Riemannian metrics which generalize
straight lines and inner products in vector spaces, respectively. Second, we
prove that linear classifiers in $d$-dimensional space forms of any curvature
have the same expressive power, i.e., they can shatter exactly $d+1$ points.
Third, we formalize linear classifiers in product space forms, describe the
first corresponding perceptron and SVM classification algorithms, and establish
rigorous convergence results for the former. We support our theoretical
findings with simulation results on several datasets, including synthetic data,
CIFAR-100, MNIST, Omniglot, and single-cell RNA sequencing data. The results
show that learning methods applied to small-dimensional embeddings in product
space forms outperform their algorithmic counterparts in each space form.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ideal formulations for constrained convex optimization problems with indicator variables. (arXiv:2007.00107v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wei_L/0/1/0/all/0/1">Linchuan Wei</a>, <a href="http://arxiv.org/find/math/1/au:+Gomez_A/0/1/0/all/0/1">Andres Gomez</a>, <a href="http://arxiv.org/find/math/1/au:+Kucukyavuz_S/0/1/0/all/0/1">Simge Kucukyavuz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00107">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by modern regression applications, in this paper, we study the
convexification of a class of convex optimization problems with indicator
variables and combinatorial constraints on the indicators. Unlike most of the
previous work on convexification of sparse regression problems, we
simultaneously consider the nonlinear non-separable objective, indicator
variables, and combinatorial constraints. Specifically, we give the convex hull
description of the epigraph of the composition of a one-dimensional convex
function and an affine function under arbitrary combinatorial constraints. As
special cases of this result, we derive ideal convexifications for problems
with hierarchy, multi-collinearity, and sparsity constraints. Moreover, we also
give a short proof that for a separable objective function, the perspective
reformulation is ideal independent from the constraints of the problem. Our
computational experiments with regression problems under hierarchy constraints
on real datasets demonstrate the potential of the proposed approach in
improving the relaxation quality without significant computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-based Support Estimation in Sublinear Time. (arXiv:2106.08396v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eden_T/0/1/0/all/0/1">Talya Eden</a>, <a href="http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1">Piotr Indyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinfeld_R/0/1/0/all/0/1">Ronitt Rubinfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_T/0/1/0/all/0/1">Tal Wagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08396">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of estimating the number of distinct elements in a
large data set (or, equivalently, the support size of the distribution induced
by the data set) from a random sample of its elements. The problem occurs in
many applications, including biology, genomics, computer systems and
linguistics. A line of research spanning the last decade resulted in algorithms
that estimate the support up to $ \pm \varepsilon n$ from a sample of size
$O(\log^2(1/\varepsilon) \cdot n/\log n)$, where $n$ is the data set size.
Unfortunately, this bound is known to be tight, limiting further improvements
to the complexity of this problem. In this paper we consider estimation
algorithms augmented with a machine-learning-based predictor that, given any
element, returns an estimation of its frequency. We show that if the predictor
is correct up to a constant approximation factor, then the sample complexity
can be reduced significantly, to \[ \ \log (1/\varepsilon) \cdot
n^{1-\Theta(1/\log(1/\varepsilon))}. \] We evaluate the proposed algorithms on
a collection of data sets, using the neural-network based estimators from {Hsu
et al, ICLR&#x27;19} as predictors. Our experiments demonstrate substantial (up to
3x) improvements in the estimation accuracy compared to the state of the art
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Localization, Convexity, and Star Aggregation. (arXiv:2105.08866v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vijaykumar_S/0/1/0/all/0/1">Suhas Vijaykumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08866">
                                    <div class="article-summary-box-inner">
                                        <span>Offset Rademacher complexities have been shown to imply sharp, data-dependent
upper bounds for the square loss in a broad class of problems including
improper statistical learning and online learning. We show that in the
statistical setting, the offset complexity upper bound can be generalized to
any loss satisfying a certain uniform convexity condition. Amazingly, this
condition is shown to also capture exponential concavity and self-concordance,
uniting several apparently disparate results. By a unified geometric argument,
these bounds translate directly to improper learning in a non-convex class
using Audibert&#x27;s &quot;star algorithm.&quot; As applications, we recover the optimal
rates for proper and improper learning with the $p$-loss, $1 &lt; p &lt; \infty$ and
show that improper variants of empirical risk minimization can attain fast
rates for logistic regression and other generalized linear models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlation Clustering in Constant Many Parallel Rounds. (arXiv:2106.08448v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1">Vincent Cohen-Addad</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1">Silvio Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitrovic_S/0/1/0/all/0/1">Slobodan Mitrovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_Fard_A/0/1/0/all/0/1">Ashkan Norouzi-Fard</a>, <a href="http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1">Nikos Parotsidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarnawski_J/0/1/0/all/0/1">Jakub Tarnawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08448">
                                    <div class="article-summary-box-inner">
                                        <span>Correlation clustering is a central topic in unsupervised learning, with many
applications in ML and data mining. In correlation clustering, one receives as
input a signed graph and the goal is to partition it to minimize the number of
disagreements. In this work we propose a massively parallel computation (MPC)
algorithm for this problem that is considerably faster than prior work. In
particular, our algorithm uses machines with memory sublinear in the number of
nodes in the graph and returns a constant approximation while running only for
a constant number of rounds. To the best of our knowledge, our algorithm is the
first that can provably approximate a clustering problem on graphs using only a
constant number of MPC rounds in the sublinear memory regime. We complement our
analysis with an experimental analysis of our techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1">Joni Korpihalkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1">Tuomo Sipola</a>, <a href="http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1">Samir Puuska</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1">Tero Kokkonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00517">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT&#x27;s MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08382">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism of late has been quite popular in the computer vision
community. A lot of work has been done to improve the performance of the
network, although almost always it results in increased computational
complexity. In this paper, we propose a new attention module that not only
achieves the best performance but also has lesser parameters compared to most
existing models. Our attention module can easily be integrated with other
convolutional neural networks because of its lightweight nature. The proposed
network named Dual Multi Scale Attention Network (DMSANet) is comprised of two
parts: the first part is used to extract features at various scales and
aggregate them, the second part uses spatial and channel attention modules in
parallel to adaptively integrate local features with their global dependencies.
We benchmark our network performance for Image Classification on ImageNet
dataset, Object Detection and Instance Segmentation both on MS COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fundamental Limits of Reinforcement Learning in Environment with Endogeneous and Exogeneous Uncertainty. (arXiv:2106.08477v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rongpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08477">
                                    <div class="article-summary-box-inner">
                                        <span>Online reinforcement learning (RL) has been widely applied in information
processing scenarios, which usually exhibit much uncertainty due to the
intrinsic randomness of channels and service demands. In this paper, we
consider an un-discounted RL in general Markov decision processes (MDPs) with
both endogeneous and exogeneous uncertainty, where both the rewards and state
transition probability are unknown to the RL agent and evolve with the time as
long as their respective variations do not exceed certain dynamic budget (i.e.,
upper bound). We first develop a variation-aware Bernstein-based upper
confidence reinforcement learning (VB-UCRL), which we allow to restart
according to a schedule dependent on the variations. We successfully overcome
the challenges due to the exogeneous uncertainty and establish a regret bound
of saving at most $\sqrt{S}$ or $S^{\frac{1}{6}}T^{\frac{1}{12}}$ compared with
the latest results in the literature, where $S$ denotes the state size of the
MDP and $T$ indicates the iteration index of learning steps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System. (arXiv:2104.02125v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chojnacka_R/0/1/0/all/0/1">Roza Chojnacka</a>, <a href="http://arxiv.org/find/eess/1/au:+Pelecanos_J/0/1/0/all/0/1">Jason Pelecanos</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Moreno_I/0/1/0/all/0/1">Ignacio Lopez Moreno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02125">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we describe SpeakerStew - a hybrid system to perform speaker
verification on 46 languages. Two core ideas were explored in this system: (1)
Pooling training data of different languages together for multilingual
generalization and reducing development cycles; (2) A novel triage mechanism
between text-dependent and text-independent models to reduce runtime cost and
expected latency. To the best of our knowledge, this is the first study of
speaker verification systems at the scale of 46 languages. The problem is
framed from the perspective of using a smart speaker device with interactions
consisting of a wake-up keyword (text-dependent) followed by a speech query
(text-independent). Experimental evidence suggests that training on multiple
languages can generalize to unseen varieties while maintaining performance on
seen varieties. We also found that it can reduce computational requirements for
training models by an order of magnitude. Furthermore, during model inference
on English data, we observe that leveraging a triage framework can reduce the
number of calls to the more computationally expensive text-independent system
by 73% (and reduce latency by 59%) while maintaining an EER no worse than the
text-independent setup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Objective Evaluation of Post Hoc Explainers. (arXiv:2106.08376v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Carmichael_Z/0/1/0/all/0/1">Zachariah Carmichael</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheirer_W/0/1/0/all/0/1">Walter J. Scheirer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08376">
                                    <div class="article-summary-box-inner">
                                        <span>Many applications of data-driven models demand transparency of decisions,
especially in health care, criminal justice, and other high-stakes
environments. Modern trends in machine learning research have led to algorithms
that are increasingly intricate to the degree that they are considered to be
black boxes. In an effort to reduce the opacity of decisions, methods have been
proposed to construe the inner workings of such models in a
human-comprehensible manner. These post hoc techniques are described as being
universal explainers - capable of faithfully augmenting decisions with
algorithmic insight. Unfortunately, there is little agreement about what
constitutes a &quot;good&quot; explanation. Moreover, current methods of explanation
evaluation are derived from either subjective or proxy means. In this work, we
propose a framework for the evaluation of post hoc explainers on ground truth
that is directly derived from the additive structure of a model. We demonstrate
the efficacy of the framework in understanding explainers by evaluating popular
explainers on thousands of synthetic and several real-world tasks. The
framework unveils that explanations may be accurate but misattribute the
importance of individual features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Resolution Continuous Normalizing Flows. (arXiv:2106.08462v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Finlay_C/0/1/0/all/0/1">Chris Finlay</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08462">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that Neural Ordinary Differential Equations (ODEs) can
serve as generative models of images using the perspective of Continuous
Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and
invertible generation/density estimation. In this work we introduce a
Multi-Resolution variant of such models (MRCNF), by characterizing the
conditional distribution over the additional information required to generate a
fine image that is consistent with the coarse image. We introduce a
transformation between resolutions that allows for no change in the log
likelihood. We show that this approach yields comparable likelihood values for
various image datasets, with improved performance at higher resolutions, with
fewer parameters, using only 1 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Adversarial Robustness via Transductive Learning. (arXiv:2106.08387v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiefeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lao_Q/0/1/0/all/0/1">Qicheng Lao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Somesh Jha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08387">
                                    <div class="article-summary-box-inner">
                                        <span>There has been emerging interest to use transductive learning for adversarial
robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020). Compared to
traditional &quot;test-time&quot; defenses, these defense mechanisms &quot;dynamically
retrain&quot; the model based on test time input via transductive learning; and
theoretically, attacking these defenses boils down to bilevel optimization,
which seems to raise the difficulty for adaptive attacks. In this paper, we
first formalize and analyze modeling aspects of transductive robustness. Then,
we propose the principle of attacking model space for solving bilevel attack
objectives, and present an instantiation of the principle which breaks previous
transductive defenses. These attacks thus point to significant difficulties in
the use of transductive learning to improve adversarial robustness. To this
end, we present new theoretical and empirical evidence in support of the
utility of transductive learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Best of both worlds: local and global explanations with human-understandable concepts. (arXiv:2106.08641v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schrouff_J/0/1/0/all/0/1">Jessica Schrouff</a>, <a href="http://arxiv.org/find/cs/1/au:+Baur_S/0/1/0/all/0/1">Sebastien Baur</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_S/0/1/0/all/0/1">Shaobo Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1">Diana Mincu</a>, <a href="http://arxiv.org/find/cs/1/au:+Loreaux_E/0/1/0/all/0/1">Eric Loreaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Blanes_R/0/1/0/all/0/1">Ralph Blanes</a>, <a href="http://arxiv.org/find/cs/1/au:+Wexler_J/0/1/0/all/0/1">James Wexler</a>, <a href="http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1">Alan Karthikesalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Been Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08641">
                                    <div class="article-summary-box-inner">
                                        <span>Interpretability techniques aim to provide the rationale behind a model&#x27;s
decision, typically by explaining either an individual prediction (local
explanation, e.g. &#x60;why is this patient diagnosed with this condition&#x27;) or a
class of predictions (global explanation, e.g. &#x60;why are patients diagnosed with
this condition in general&#x27;). While there are many methods focused on either
one, few frameworks can provide both local and global explanations in a
consistent manner. In this work, we combine two powerful existing techniques,
one local (Integrated Gradients, IG) and one global (Testing with Concept
Activation Vectors), to provide local, and global concept-based explanations.
We first validate our idea using two synthetic datasets with a known ground
truth, and further demonstrate with a benchmark natural image dataset. We test
our method with various concepts, target classes, model architectures and IG
baselines. We show that our method improves global explanations over TCAV when
compared to ground truth, and provides useful insights. We hope our work
provides a step towards building bridges between many existing local and global
methods to get the best of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reproducing Kernel Hilbert Space, Mercer&#x27;s Theorem, Eigenfunctions, Nystr\&quot;om Method, and Use of Kernels in Machine Learning: Tutorial and Survey. (arXiv:2106.08443v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08443">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper on kernels, kernel methods, and related
fields. We start with reviewing the history of kernels in functional analysis
and machine learning. Then, Mercer kernel, Hilbert and Banach spaces,
Reproducing Kernel Hilbert Space (RKHS), Mercer&#x27;s theorem and its proof,
frequently used kernels, kernel construction from distance metric, important
classes of kernels (including bounded, integrally positive definite, universal,
stationary, and characteristic kernels), kernel centering and normalization,
and eigenfunctions are explained in detail. Then, we introduce types of use of
kernels in machine learning including kernel methods (such as kernel support
vector machines), kernel learning by semi-definite programming, Hilbert-Schmidt
independence criterion, maximum mean discrepancy, kernel mean embedding, and
kernel dimensionality reduction. We also cover rank and factorization of kernel
matrix as well as the approximation of eigenfunctions and kernels using the
Nystr{\&quot;o}m method. This paper can be useful for various fields of science
including machine learning, dimensionality reduction, functional analysis in
mathematics, and mathematical physics in quantum mechanics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation. (arXiv:2106.09017v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09017">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-task learning (MTL) aims to improve the generalization of several
related tasks by learning them jointly. As a comparison, in addition to the
joint training scheme, modern meta-learning allows unseen tasks with limited
labels during the test phase, in the hope of fast adaptation over them. Despite
the subtle difference between MTL and meta-learning in the problem formulation,
both learning paradigms share the same insight that the shared structure
between existing training tasks could lead to better generalization and
adaptation. In this paper, we take one important step further to understand the
close connection between these two learning paradigms, through both theoretical
analysis and empirical investigation. Theoretically, we first demonstrate that
MTL shares the same optimization formulation with a class of gradient-based
meta-learning (GBML) algorithms. We then prove that for over-parameterized
neural networks with sufficient depth, the learned predictive functions of MTL
and GBML are close. In particular, this result implies that the predictions
given by these two models are similar over the same unseen task. Empirically,
we corroborate our theoretical findings by showing that, with proper
implementation, MTL is competitive against state-of-the-art GBML algorithms on
a set of few-shot image classification benchmarks. Since existing GBML
algorithms often involve costly second-order bi-level optimization, our
first-order MTL method is an order of magnitude faster on large-scale datasets
such as mini-ImageNet. We believe this work could help bridge the gap between
these two learning paradigms, and provide a computationally efficient
alternative to GBML that also supports fast task adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms for Stochastic Shortest Path. (arXiv:2106.08377v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1">Mehdi Jafarnia-Jahromi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08377">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a generic template for developing regret minimization algorithms
in the Stochastic Shortest Path (SSP) model, which achieves minimax optimal
regret as long as certain properties are ensured. The key of our analysis is a
new technique called implicit finite-horizon approximation, which approximates
the SSP model by a finite-horizon counterpart only in the analysis without
explicit implementation. Using this template, we develop two new algorithms:
the first one is model-free (the first in the literature to our knowledge) and
minimax optimal under strictly positive costs; the second one is model-based
and minimax optimal even with zero-cost state-action pairs, matching the best
existing result from [Tarbouriech et al., 2021b]. Importantly, both algorithms
admit highly sparse updates, making them computationally more efficient than
all existing algorithms. Moreover, both can be made completely parameter-free.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis and Optimisation of Bellman Residual Errors with Neural Function Approximation. (arXiv:2106.08774v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gottwald_M/0/1/0/all/0/1">Martin Gottwald</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gronauer_S/0/1/0/all/0/1">Sven Gronauer</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Hao Shen</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Diepold_K/0/1/0/all/0/1">Klaus Diepold</a> (1) ((1) Technical University of Munich, (2) fortiss)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08774">
                                    <div class="article-summary-box-inner">
                                        <span>Recent development of Deep Reinforcement Learning has demonstrated superior
performance of neural networks in solving challenging problems with large or
even continuous state spaces. One specific approach is to deploy neural
networks to approximate value functions by minimising the Mean Squared Bellman
Error function. Despite great successes of Deep Reinforcement Learning,
development of reliable and efficient numerical algorithms to minimise the
Bellman Error is still of great scientific interest and practical demand. Such
a challenge is partially due to the underlying optimisation problem being
highly non-convex or using incorrect gradient information as done in
Semi-Gradient algorithms. In this work, we analyse the Mean Squared Bellman
Error from a smooth optimisation perspective combined with a Residual Gradient
formulation. Our contribution is two-fold.

First, we analyse critical points of the error function and provide technical
insights on the optimisation procure and design choices for neural networks.
When the existence of global minima is assumed and the objective fulfils
certain conditions we can eliminate suboptimal local minima when using
over-parametrised neural networks. We can construct an efficient Approximate
Newton&#x27;s algorithm based on our analysis and confirm theoretical properties of
this algorithm such as being locally quadratically convergent to a global
minimum numerically.

Second, we demonstrate feasibility and generalisation capabilities of the
proposed algorithm empirically using continuous control problems and provide a
numerical verification of our critical point analysis. We outline the short
coming of Semi-Gradients. To benefit from an approximate Newton&#x27;s algorithm
complete derivatives of the Mean Squared Bellman error must be considered
during training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Augmentation for Graph Convolutional Network on Semi-Supervised Classification. (arXiv:2106.08848v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhengzheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1">Ziyue Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1">Xuehai Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dharejo_F/0/1/0/all/0/1">Fayaz Ali Dharejo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuanchun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yi Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08848">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation aims to generate new and synthetic features from the
original data, which can identify a better representation of data and improve
the performance and generalizability of downstream tasks. However, data
augmentation for graph-based models remains a challenging problem, as graph
data is more complex than traditional data, which consists of two features with
different properties: graph topology and node attributes. In this paper, we
study the problem of graph data augmentation for Graph Convolutional Network
(GCN) in the context of improving the node embeddings for semi-supervised node
classification. Specifically, we conduct cosine similarity based cross
operation on the original features to create new graph features, including new
node attributes and new graph topologies, and we combine them as new pairwise
inputs for specific GCNs. Then, we propose an attentional integrating model to
weighted sum the hidden node embeddings encoded by these GCNs into the final
node embeddings. We also conduct a disparity constraint on these hidden node
embeddings when training to ensure that non-redundant information is captured
from different features. Experimental results on five real-world datasets show
that our method improves the classification accuracy with a clear margin (+2.5%
- +84.2%) than the original GCN model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Anomaly Detection in Edge Streams. (arXiv:2009.08452v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1">Siddharth Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1">Bryan Hooi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_M/0/1/0/all/0/1">Minji Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1">Kijung Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Faloutsos_C/0/1/0/all/0/1">Christos Faloutsos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08452">
                                    <div class="article-summary-box-inner">
                                        <span>Given a stream of graph edges from a dynamic graph, how can we assign anomaly
scores to edges in an online manner, for the purpose of detecting unusual
behavior, using constant time and memory? Existing approaches aim to detect
individually surprising edges. In this work, we propose MIDAS, which focuses on
detecting microcluster anomalies, or suddenly arriving groups of suspiciously
similar edges, such as lockstep behavior, including denial of service attacks
in network traffic data. We further propose MIDAS-F, to solve the problem by
which anomalies are incorporated into the algorithm&#x27;s internal states, creating
a &#x60;poisoning&#x27; effect that can allow future anomalies to slip through
undetected. MIDAS-F introduces two modifications: 1) We modify the anomaly
scoring function, aiming to reduce the &#x60;poisoning&#x27; effect of newly arriving
edges; 2) We introduce a conditional merge step, which updates the algorithm&#x27;s
data structures after each time tick, but only if the anomaly score is below a
threshold value, also to reduce the &#x60;poisoning&#x27; effect. Experiments show that
MIDAS-F has significantly higher accuracy than MIDAS. MIDAS has the following
properties: (a) it detects microcluster anomalies while providing theoretical
guarantees about its false positive probability; (b) it is online, thus
processing each edge in constant time and constant memory, and also processes
the data orders-of-magnitude faster than state-of-the-art approaches; (c) it
provides up to 62% higher ROC-AUC than state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM. (arXiv:2103.05056v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1">Daniele Cattaneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1">Matteo Vaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05056">
                                    <div class="article-summary-box-inner">
                                        <span>Loop closure detection is an essential component of Simultaneous Localization
and Mapping (SLAM) systems, which reduces the drift accumulated over time. Over
the years, several deep learning approaches have been proposed to address this
task, however their performance has been subpar compared to handcrafted
techniques, especially while dealing with reverse loops. In this paper, we
introduce the novel LCDNet that effectively detects loop closures in LiDAR
point clouds by simultaneously identifying previously visited places and
estimating the 6-DoF relative transformation between the current scan and the
map. LCDNet is composed of a shared encoder, a place recognition head that
extracts global descriptors, and a relative pose head that estimates the
transformation between two point clouds. We introduce a novel relative pose
head based on the unbalanced optimal transport theory that we implement in a
differentiable manner to allow for end-to-end training. Extensive evaluations
of LCDNet on multiple real-world autonomous driving datasets show that our
approach outperforms state-of-the-art loop closure detection and point cloud
registration techniques by a large margin, especially while dealing with
reverse loops. Moreover, we integrate our proposed loop closure detection
approach into a LiDAR SLAM library to provide a complete mapping system and
demonstrate the generalization ability using different sensor setup in an
unseen city.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework for Discovering Optimal Solutions in Photonic Inverse Design. (arXiv:2106.08419v1 [physics.optics])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Digani_J/0/1/0/all/0/1">Jagrit Digani</a>, <a href="http://arxiv.org/find/physics/1/au:+Hon_P/0/1/0/all/0/1">Phillip Hon</a>, <a href="http://arxiv.org/find/physics/1/au:+Davoyan_A/0/1/0/all/0/1">Artur R. Davoyan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08419">
                                    <div class="article-summary-box-inner">
                                        <span>Photonic inverse design has emerged as an indispensable engineering tool for
complex optical systems. In many instances it is important to optimize for both
material and geometry configurations, which results in complex non-smooth
search spaces with multiple local minima. Finding solutions approaching global
optimum may present a computationally intractable task. Here, we develop a
framework that allows expediting the search of solutions close to global
optimum on complex optimization spaces. We study the way representative black
box optimization algorithms work, including genetic algorithm (GA), particle
swarm optimization (PSO), simulated annealing (SA), and mesh adaptive direct
search (NOMAD). We then propose and utilize a two-step approach that identifies
best performance algorithms on arbitrarily complex search spaces. We reveal a
connection between the search space complexity and algorithm performance and
find that PSO and NOMAD consistently deliver better performance for mixed
integer problems encountered in photonic inverse design, particularly with the
account of material combinations. Our results differ from a commonly
anticipated advantage of GA. Our findings will foster more efficient design of
photonic systems with optimal performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HELP: Hardware-Adaptive Efficient Latency Predictor for NAS via Meta-Learning. (arXiv:2106.08630v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sewoong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_S/0/1/0/all/0/1">Song Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08630">
                                    <div class="article-summary-box-inner">
                                        <span>For deployment, neural architecture search should be hardware-aware, in order
to satisfy the device-specific constraints (e.g., memory usage, latency and
energy consumption) and enhance the model efficiency. Existing methods on
hardware-aware NAS collect a large number of samples (e.g., accuracy and
latency) from a target device, either builds a lookup table or a latency
estimator. However, such approach is impractical in real-world scenarios as
there exist numerous devices with different hardware specifications, and
collecting samples from such a large number of devices will require prohibitive
computational and monetary cost. To overcome such limitations, we propose
Hardware-adaptive Efficient Latency Predictor (HELP), which formulates the
device-specific latency estimation problem as a meta-learning problem, such
that we can estimate the latency of a model&#x27;s performance for a given task on
an unseen device with a few samples. To this end, we introduce novel hardware
embeddings to embed any devices considering them as black-box functions that
output latencies, and meta-learn the hardware-adaptive latency predictor in a
device-dependent manner, using the hardware embeddings. We validate the
proposed HELP for its latency estimation performance on unseen platforms, on
which it achieves high estimation performance with as few as 10 measurement
samples, outperforming all relevant baselines. We also validate end-to-end NAS
frameworks using HELP against ones without it, and show that it largely reduces
the total time cost of the base NAS method, in latency-constrained settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascading Modular Network (CAM-Net) for Multimodal Image Synthesis. (arXiv:2106.09015v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Moazeni_A/0/1/0/all/0/1">Alireza Moazeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09015">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models such as GANs have driven impressive advances in
conditional image synthesis in recent years. A persistent challenge has been to
generate diverse versions of output images from the same input image, due to
the problem of mode collapse: because only one ground truth output image is
given per input image, only one mode of the conditional distribution is
modelled. In this paper, we focus on this problem of multimodal conditional
image synthesis and build on the recently proposed technique of Implicit
Maximum Likelihood Estimation (IMLE). Prior IMLE-based methods required
different architectures for different tasks, which limit their applicability,
and were lacking in fine details in the generated images. We propose CAM-Net, a
unified architecture that can be applied to a broad range of tasks.
Additionally, it is capable of generating convincing high frequency details,
achieving a reduction of the Frechet Inception Distance (FID) by up to 45.3%
compared to the baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LassoNet: A Neural Network with Feature Sparsity. (arXiv:1907.12207v10 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lemhadri_I/0/1/0/all/0/1">Ismael Lemhadri</a>, <a href="http://arxiv.org/find/stat/1/au:+Ruan_F/0/1/0/all/0/1">Feng Ruan</a>, <a href="http://arxiv.org/find/stat/1/au:+Abraham_L/0/1/0/all/0/1">Louis Abraham</a>, <a href="http://arxiv.org/find/stat/1/au:+Tibshirani_R/0/1/0/all/0/1">Robert Tibshirani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.12207">
                                    <div class="article-summary-box-inner">
                                        <span>Much work has been done recently to make neural networks more interpretable,
and one obvious approach is to arrange for the network to use only a subset of
the available features. In linear models, Lasso (or $\ell_1$-regularized)
regression assigns zero weights to the most irrelevant or redundant features,
and is widely used in data science. However the Lasso only applies to linear
models. Here we introduce LassoNet, a neural network framework with global
feature selection. Our approach enforces a hierarchy: specifically a feature
can participate in a hidden unit only if its linear representative is active.
Unlike other approaches to feature selection for neural nets, our method uses a
modified objective function with constraints, and so integrates feature
selection with the parameter learning directly. As a result, it delivers an
entire regularization path of solutions with a range of feature sparsity. On
systematic experiments, LassoNet significantly outperforms state-of-the-art
methods for feature selection and regression. The LassoNet method uses
projected proximal gradient descent, and generalizes directly to deep networks.
It can be implemented by adding just a few lines of code to a standard neural
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks. (arXiv:2010.04261v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yikai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Annie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1">Rong Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04261">
                                    <div class="article-summary-box-inner">
                                        <span>Hessian captures important properties of the deep neural network loss
landscape. Previous works have observed low rank structure in the Hessians of
neural networks. We make several new observations about the top eigenspace of
layer-wise Hessian: top eigenspaces for different models have surprisingly high
overlap, and top eigenvectors form low rank matrices when they are reshaped
into the same shape as the corresponding weight matrix. Towards formally
explaining such structures of the Hessian, we show that the new eigenspace
structure can be explained by approximating the Hessian using Kronecker
factorization; we also prove the low rank structure for random data at random
initialization for over-parametrized two-layer neural nets. Our new
understanding can explain why some of these structures become weaker when the
network is trained with batch normalization. The Kronecker factorization also
leads to better explicit generalization bounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the exchange-correlation functional from nature with fully differentiable density functional theory. (arXiv:2102.04229v4 [physics.chem-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Kasim_M/0/1/0/all/0/1">Muhammad F. Kasim</a>, <a href="http://arxiv.org/find/physics/1/au:+Vinko_S/0/1/0/all/0/1">Sam M. Vinko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04229">
                                    <div class="article-summary-box-inner">
                                        <span>Improving the predictive capability of molecular properties in ab initio
simulations is essential for advanced material discovery. Despite recent
progress making use of machine learning, utilizing deep neural networks to
improve quantum chemistry modelling remains severely limited by the scarcity
and heterogeneity of appropriate experimental data. Here we show how training a
neural network to replace the exchange-correlation functional within a
fully-differentiable three-dimensional Kohn-Sham density functional theory
(DFT) framework can greatly improve simulation accuracy. Using only eight
experimental data points on diatomic molecules, our trained
exchange-correlation networks enable improved prediction accuracy of
atomization energies across a collection of 104 molecules containing new bonds
and atoms that are not present in the training dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational System Identification for Nonlinear State-Space Models. (arXiv:2012.05072v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Courts_J/0/1/0/all/0/1">Jarrad Courts</a>, <a href="http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1">Adrian Wills</a>, <a href="http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1">Thomas Sch&#xf6;n</a>, <a href="http://arxiv.org/find/stat/1/au:+Ninness_B/0/1/0/all/0/1">Brett Ninness</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05072">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers parameter estimation for nonlinear state-space models,
which is an important but challenging problem. We address this challenge by
employing a variational inference (VI) approach, which is a principled method
that has deep connections to maximum likelihood estimation. This VI approach
ultimately provides estimates of the model as solutions to an optimisation
problem, which is deterministic, tractable and can be solved using standard
optimisation tools. A specialisation of this approach for systems with additive
Gaussian noise is also detailed. The proposed method is examined numerically on
a range of simulated and real examples focusing on the robustness to parameter
initialisation; additionally, favourable comparisons are performed against
state-of-the-art alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Disentanglement for Rare Event Modeling. (arXiv:2009.08541v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xiu_Z/0/1/0/all/0/1">Zidi Xiu</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_M/0/1/0/all/0/1">Michael Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Davis_C/0/1/0/all/0/1">Connor Davis</a>, <a href="http://arxiv.org/find/stat/1/au:+Goldstein_B/0/1/0/all/0/1">Benjamin A. Goldstein</a>, <a href="http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1">Ricardo Henao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08541">
                                    <div class="article-summary-box-inner">
                                        <span>Combining the increasing availability and abundance of healthcare data and
the current advances in machine learning methods have created renewed
opportunities to improve clinical decision support systems. However, in
healthcare risk prediction applications, the proportion of cases with the
condition (label) of interest is often very low relative to the available
sample size. Though very prevalent in healthcare, such imbalanced
classification settings are also common and challenging in many other
scenarios. So motivated, we propose a variational disentanglement approach to
semi-parametrically learn from rare events in heavily imbalanced classification
problems. Specifically, we leverage the imposed extreme-distribution behavior
on a latent space to extract information from low-prevalence events, and
develop a robust prediction arm that joins the merits of the generalized
additive model and isotonic neural nets. Results on synthetic studies and
diverse real-world datasets, including mortality prediction on a COVID-19
cohort, demonstrate that the proposed approach outperforms existing
alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Causal Semantic Representation for Out-of-Distribution Prediction. (arXiv:2011.01681v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_X/0/1/0/all/0/1">Xinwei Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1">Haoyue Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_T/0/1/0/all/0/1">Tao Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01681">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional supervised learning methods, especially deep ones, are found to
be sensitive to out-of-distribution (OOD) examples, largely because the learned
representation mixes the semantic factor with the variation factor due to their
domain-specific correlation, while only the semantic factor causes the output.
To address the problem, we propose a Causal Semantic Generative model (CSG)
based on a causal reasoning so that the two factors are modeled separately, and
develop methods for OOD prediction from a single training domain, which is
common and challenging. The methods are based on the causal invariance
principle, with a novel design for both efficient learning and easy prediction.
Theoretically, we prove that under certain conditions, CSG can identify the
semantic factor by fitting training data, and this semantic-identification
guarantees the boundedness of OOD generalization error and the success of
adaptation. Empirical study shows improved OOD performance over prevailing
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complexity aspects of local minima and related notions. (arXiv:2008.06148v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1">Amir Ali Ahmadi</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1">Jeffrey Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06148">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the notions of (i) critical points, (ii) second-order points,
(iii) local minima, and (iv) strict local minima for multivariate polynomials.
For each type of point, and as a function of the degree of the polynomial, we
study the complexity of deciding (1) if a given point is of that type, and (2)
if a polynomial has a point of that type. Our results characterize the
complexity of these two questions for all degrees left open by prior
literature. Our main contributions reveal that many of these questions turn out
to be tractable for cubic polynomials. In particular, we present an
efficiently-checkable necessary and sufficient condition for local minimality
of a point for a cubic polynomial. We also show that a local minimum of a cubic
polynomial can be efficiently found by solving semidefinite programs of size
linear in the number of variables. By contrast, we show that it is strongly
NP-hard to decide if a cubic polynomial has a critical point. We also prove
that the set of second-order points of any cubic polynomial is a spectrahedron,
and conversely that any spectrahedron is the projection of the set of
second-order points of a cubic polynomial. In our final section, we briefly
present a potential application of finding local minima of cubic polynomials to
the design of a third-order Newton method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Variational Attention Models for Language Generation. (arXiv:2004.09764v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09764">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders have been widely applied for natural language
generation, however, there are two long-standing problems: information
under-representation and posterior collapse. The former arises from the fact
that only the last hidden state from the encoder is transformed to the latent
space, which is insufficient to summarize data. The latter comes as a result of
the imbalanced scale between the reconstruction loss and the KL divergence in
the objective function. To tackle these issues, in this paper we propose the
discrete variational attention model with categorical distribution over the
attention mechanism owing to the discrete nature in languages. Our approach is
combined with an auto-regressive prior to capture the sequential dependency
from observations, which can enhance the latent space for language generation.
Moreover, thanks to the property of discreteness, the training of our proposed
approach does not suffer from posterior collapse. Furthermore, we carefully
analyze the superiority of discrete latent space over the continuous space with
the common Gaussian distribution. Extensive experiments on language generation
demonstrate superior advantages of our proposed approach in comparison with the
state-of-the-art counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Development of Quantized DNN Library for Exact Hardware Emulation. (arXiv:2106.08892v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kiyama_M/0/1/0/all/0/1">Masato Kiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Amagasaki_M/0/1/0/all/0/1">Motoki Amagasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Iida_M/0/1/0/all/0/1">Masahiro Iida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08892">
                                    <div class="article-summary-box-inner">
                                        <span>Quantization is used to speed up execution time and save power when runnning
Deep neural networks (DNNs) on edge devices like AI chips. To investigate the
effect of quantization, we need performing inference after quantizing the
weights of DNN with 32-bit floating-point precision by a some bit width, and
then quantizing them back to 32-bit floating-point precision. This is because
the DNN library can only handle floating-point numbers. However, the accuracy
of the emulation does not provide accurate precision. We need accurate
precision to detect overflow in MAC operations or to verify the operation on
edge de vices. We have developed PyParch, a DNN library that executes quantized
DNNs (QNNs) with exactly the same be havior as hardware. In this paper, we
describe a new proposal and implementation of PyParch. As a result of the
evaluation, the accuracy of QNNs with arbitrary bit widths can be estimated for
la rge and complex DNNs such as YOLOv5, and the overflow can be detected. We
evaluated the overhead of the emulation time and found that it was 5.6 times
slower for QNN and 42

times slower for QNN with overflow detection compared to the normal DNN
execution time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reset-Free Lifelong Learning with Skill-Space Planning. (arXiv:2012.03548v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Kevin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03548">
                                    <div class="article-summary-box-inner">
                                        <span>The objective of lifelong reinforcement learning (RL) is to optimize agents
which can continuously adapt and interact in changing environments. However,
current RL approaches fail drastically when environments are non-stationary and
interactions are non-episodic. We propose Lifelong Skill Planning (LiSP), an
algorithmic framework for non-episodic lifelong RL based on planning in an
abstract space of higher-order skills. We learn the skills in an unsupervised
manner using intrinsic rewards and plan over the learned skills using a learned
dynamics model. Moreover, our framework permits skill discovery even from
offline data, thereby reducing the need for excessive real-world interactions.
We demonstrate empirically that LiSP successfully enables long-horizon planning
and learns agents that can avoid catastrophic failures even in challenging
non-stationary and non-episodic environments derived from gridworld and MuJoCo
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GemNet: Universal Directional Graph Neural Networks for Molecules. (arXiv:2106.08903v1 [physics.comp-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Klicpera_J/0/1/0/all/0/1">Johannes Klicpera</a>, <a href="http://arxiv.org/find/physics/1/au:+Becker_F/0/1/0/all/0/1">Florian Becker</a>, <a href="http://arxiv.org/find/physics/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08903">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively predicting molecular interactions has the potential to accelerate
molecular dynamics by multiple orders of magnitude and thus revolutionize
chemical simulations. Graph neural networks (GNNs) have recently shown great
successes for this task, overtaking classical methods based on fixed molecular
kernels. However, they still appear very limited from a theoretical
perspective, since regular GNNs cannot distinguish certain types of graphs. In
this work we close this gap between theory and practice. We show that GNNs with
directed edge embeddings and two-hop message passing are indeed universal
approximators for predictions that are invariant to global rotation and
translation, and equivariant to permutation. We then leverage these insights
and multiple structural improvements to propose the geometric message passing
neural network (GemNet). We demonstrate the benefits of the proposed changes in
multiple ablation studies. GemNet outperforms previous models on the COLL and
MD17 molecular dynamics datasets by 36%, performing especially well on the most
challenging molecules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Generative Adversarial Networks in One Stage. (arXiv:2103.00430v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chengchao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Youtan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinchao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xubin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jie Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00430">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have demonstrated unprecedented
success in various image generation tasks. The encouraging results, however,
come at the price of a cumbersome training process, during which the generator
and discriminator are alternately updated in two stages. In this paper, we
investigate a general training scheme that enables training GANs efficiently in
only one stage. Based on the adversarial losses of the generator and
discriminator, we categorize GANs into two classes, Symmetric GANs and
Asymmetric GANs, and introduce a novel gradient decomposition method to unify
the two, allowing us to train both classes in one stage and hence alleviate the
training effort. We also computationally analyze the efficiency of the proposed
method, and empirically demonstrate that, the proposed method yields a solid
$1.5\times$ acceleration across various datasets and network architectures.
Furthermore, we show that the proposed method is readily applicable to other
adversarial-training scenarios, such as data-free knowledge distillation. The
code is available at https://github.com/zju-vipa/OSGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularized Orthogonal Machine Learning for Nonlinear Semiparametric Models. (arXiv:1806.04823v7 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nekipelov_D/0/1/0/all/0/1">Denis Nekipelov</a>, <a href="http://arxiv.org/find/math/1/au:+Semenova_V/0/1/0/all/0/1">Vira Semenova</a>, <a href="http://arxiv.org/find/math/1/au:+Syrgkanis_V/0/1/0/all/0/1">Vasilis Syrgkanis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1806.04823">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a Lasso-type estimator for a high-dimensional sparse
parameter identified by a single index conditional moment restriction (CMR). In
addition to this parameter, the moment function can also depend on a nuisance
function, such as the propensity score or the conditional choice probability,
which we estimate by modern machine learning tools. We first adjust the moment
function so that the gradient of the future loss function is insensitive
(formally, Neyman-orthogonal) with respect to the first-stage regularization
bias, preserving the single index property. We then take the loss function to
be an indefinite integral of the adjusted moment function with respect to the
single index. The proposed Lasso estimator converges at the oracle rate, where
the oracle knows the nuisance function and solves only the parametric problem.
We demonstrate our method by estimating the short-term heterogeneous impact of
Connecticut&#x27;s Jobs First welfare reform experiment on women&#x27;s welfare
participation decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Bellman Operators. (arXiv:2106.05012v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1">Matthew Fellows</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1">Kristian Hartikainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05012">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel perspective on Bayesian reinforcement learning (RL);
whereas existing approaches infer a posterior over the transition distribution
or Q-function, we characterise the uncertainty in the Bellman operator. Our
Bayesian Bellman operator (BBO) framework is motivated by the insight that when
bootstrapping is introduced, model-free approaches actually infer a posterior
over Bellman operators, not value functions. In this paper, we use BBO to
provide a rigorous theoretical analysis of model-free Bayesian RL to better
understand its relationshipto established frequentist RL methodologies. We
prove that Bayesian solutions are consistent with frequentist RL solutions,
even when approximate inference isused, and derive conditions for which
convergence properties hold. Empirically, we demonstrate that algorithms
derived from the BBO framework have sophisticated deep exploration properties
that enable them to solve continuous control tasks at which state-of-the-art
regularised actor-critic algorithms fail catastrophically</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Error-Feedback Framework: Better Rates for SGD with Delayed Gradients and Compressed Communication. (arXiv:1909.05350v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.05350">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze (stochastic) gradient descent (SGD) with delayed updates on smooth
quasi-convex and non-convex functions and derive concise, non-asymptotic,
convergence rates. We show that the rate of convergence in all cases consists
of two terms: (i) a stochastic term which is not affected by the delay, and
(ii) a higher order deterministic term which is only linearly slowed down by
the delay. Thus, in the presence of noise, the effects of the delay become
negligible after a few iterations and the algorithm converges at the same
optimal rate as standard SGD. This result extends a line of research that
showed similar results in the asymptotic regime or for strongly-convex
quadratic functions only. We further show similar results for SGD with more
intricate form of delayed gradients---compressed gradients under error
compensation and for local~SGD where multiple workers perform local steps
before communicating with each other. In all of these settings, we improve upon
the best known rates. These results show that SGD is robust to compressed
and/or delayed stochastic gradient updates. This is in particular important for
distributed parallel implementations, where asynchronous and communication
efficient methods are the key to achieve linear speedups for optimization with
multiple devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better. (arXiv:2106.08962v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Menghani_G/0/1/0/all/0/1">Gaurav Menghani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08962">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning has revolutionized the fields of computer vision, natural
language understanding, speech recognition, information retrieval and more.
However, with the progressive improvements in deep learning models, their
number of parameters, latency, resources required to train, etc. have all have
increased significantly. Consequently, it has become important to pay attention
to these footprint metrics of a model as well, not just its quality. We present
and motivate the problem of efficiency in deep learning, followed by a thorough
survey of the five core areas of model efficiency (spanning modeling
techniques, infrastructure, and hardware) and the seminal work there. We also
present an experiment-based guide along with code, for practitioners to
optimize their model training and deployment. We believe this is the first
comprehensive survey in the efficient deep learning space that covers the
landscape of model efficiency from modeling techniques to hardware support. Our
hope is that this survey would provide the reader with the mental model and the
necessary understanding of the field to apply generic efficiency techniques to
immediately get significant improvements, and also equip them with ideas for
further research and experimentation to achieve additional gains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving filling level classification with adversarial training. (arXiv:2102.04057v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Modas_A/0/1/0/all/0/1">Apostolos Modas</a>, <a href="http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1">Alessio Xompero</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_Matilla_R/0/1/0/all/0/1">Ricardo Sanchez-Matilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1">Pascal Frossard</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04057">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem of classifying - from a single image - the level
of content in a cup or a drinking glass. This problem is made challenging by
several ambiguities caused by transparencies, shape variations and partial
occlusions, and by the availability of only small training datasets. In this
paper, we tackle this problem with an appropriate strategy for transfer
learning. Specifically, we use adversarial training in a generic source dataset
and then refine the training with a task-specific dataset. We also discuss and
experimentally evaluate several training strategies and their combination on a
range of container types of the CORSMAL Containers Manipulation dataset. We
show that transfer learning with adversarial training in the source domain
consistently improves the classification accuracy on the test set and limits
the overfitting of the classifier to specific features of the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin. (arXiv:1910.04284v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.04284">
                                    <div class="article-summary-box-inner">
                                        <span>For linear classifiers, the relationship between (normalized) output margin
and generalization is captured in a clear and simple bound -- a large output
margin implies good generalization. Unfortunately, for deep models, this
relationship is less clear: existing analyses of the output margin give
complicated bounds which sometimes depend exponentially on depth. In this work,
we propose to instead analyze a new notion of margin, which we call the
&quot;all-layer margin.&quot; Our analysis reveals that the all-layer margin has a clear
and direct relationship with generalization for deep models. This enables the
following concrete applications of the all-layer margin: 1) by analyzing the
all-layer margin, we obtain tighter generalization bounds for neural nets which
depend on Jacobian and hidden layer norms and remove the exponential dependency
on depth 2) our neural net results easily translate to the adversarially robust
setting, giving the first direct analysis of robust test error for deep
networks, and 3) we present a theoretically inspired training algorithm for
increasing the all-layer margin. Our algorithm improves both clean and
adversarially robust test performance over strong baselines in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lanfredi_R/0/1/0/all/0/1">Ricardo Bigolin Lanfredi</a>, <a href="http://arxiv.org/find/stat/1/au:+Schroeder_J/0/1/0/all/0/1">Joyce D. Schroeder</a>, <a href="http://arxiv.org/find/stat/1/au:+Tasdizen_T/0/1/0/all/0/1">Tolga Tasdizen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04709">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training, especially projected gradient descent (PGD), has been a
successful approach for improving robustness against adversarial attacks. After
adversarial training, gradients of models with respect to their inputs have a
preferential direction. However, the direction of alignment is not
mathematically well established, making it difficult to evaluate
quantitatively. We propose a novel definition of this direction as the
direction of the vector pointing toward the closest point of the support of the
closest inaccurate class in decision space. To evaluate the alignment with this
direction after adversarial training, we apply a metric that uses generative
adversarial networks to produce the smallest residual needed to change the
class present in the image. We show that PGD-trained models have a higher
alignment than the baseline according to our definition, that our metric
presents higher alignment values than a competing metric formulation, and that
enforcing this alignment increases the robustness of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimality of short-term synaptic plasticity in modelling certain dynamic environments. (arXiv:2009.06808v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1">Timoleon Moraitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1">Abu Sebastian</a>, <a href="http://arxiv.org/find/cs/1/au:+Eleftheriou_E/0/1/0/all/0/1">Evangelos Eleftheriou</a> (IBM Research - Zurich)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06808">
                                    <div class="article-summary-box-inner">
                                        <span>Biological neurons and their in-silico emulations for neuromorphic artificial
intelligence (AI) use extraordinarily energy-efficient mechanisms, such as
spike-based communication and local synaptic plasticity. It remains unclear
whether these neuronal mechanisms only offer efficiency or also underlie the
superiority of biological intelligence. Here, we prove rigorously that, indeed,
the Bayes-optimal prediction and inference of randomly but continuously
transforming environments, a common natural setting, relies on short-term
spike-timing-dependent plasticity, a hallmark of biological synapses. Further,
this dynamic Bayesian inference through plasticity enables circuits of the
cerebral cortex in simulations to recognize previously unseen, highly distorted
dynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,
the first to overcome multiple limitations of deep learning and outperform
artificial neural networks in a visual task. The cortical-like network is
spiking and event-based, trained only with unsupervised and local plasticity,
on a small, narrow, and static training dataset, but achieves recognition of
unseen, transformed, and dynamic data better than deep neural networks with
continuous activations, trained with supervised backpropagation on the
transforming data. These results link short-term plasticity to high-level
cortical function, suggest optimality of natural intelligence for natural
environments, and repurpose neuromorphic AI from mere efficiency to
computational supremacy altogether.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ditto: Fair and Robust Federated Learning Through Personalization. (arXiv:2012.04221v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1">Virginia Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04221">
                                    <div class="article-summary-box-inner">
                                        <span>Fairness and robustness are two important concerns for federated learning
systems. In this work, we identify that robustness to data and model poisoning
attacks and fairness, measured as the uniformity of performance across devices,
are competing constraints in statistically heterogeneous networks. To address
these constraints, we propose employing a simple, general framework for
personalized federated learning, Ditto, that can inherently provide fairness
and robustness benefits, and develop a scalable solver for it. Theoretically,
we analyze the ability of Ditto to achieve fairness and robustness
simultaneously on a class of linear problems. Empirically, across a suite of
federated datasets, we show that Ditto not only achieves competitive
performance relative to recent personalization methods, but also enables more
accurate, robust, and fair models relative to state-of-the-art fair or robust
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation. (arXiv:2106.09016v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yahui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1">Enver Sangineto</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yajing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoxian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1">Bruno Lepri</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadai_M/0/1/0/all/0/1">Marco De Nadai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09016">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-Image (I2I) multi-domain translation models are usually evaluated
also using the quality of their semantic interpolation results. However,
state-of-the-art models frequently show abrupt changes in the image appearance
during interpolation, and usually perform poorly in interpolations across
domains. In this paper, we propose a new training protocol based on three
specific losses which help a translation network to learn a smooth and
disentangled latent style space in which: 1) Both intra- and inter-domain
interpolations correspond to gradual changes in the generated images and 2) The
content of the source image is better preserved during the translation.
Moreover, we propose a novel evaluation metric to properly measure the
smoothness of latent style space of I2I translation models. The proposed method
can be plugged into existing translation approaches, and our extensive
experiments on different datasets show that it can significantly boost the
quality of the generated images and the graduality of the interpolations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint Support. (arXiv:2106.08929v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Glaser_P/0/1/0/all/0/1">Pierre Glaser</a>, <a href="http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1">Michael Arbel</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08929">
                                    <div class="article-summary-box-inner">
                                        <span>We study the gradient flow for a relaxed approximation to the
Kullback-Leibler (KL) divergence between a moving source and a fixed target
distribution. This approximation, termed the KALE (KL approximate lower-bound
estimator), solves a regularized version of the Fenchel dual problem defining
the KL over a restricted class of functions. When using a Reproducing Kernel
Hilbert Space (RKHS) to define the function class, we show that the KALE
continuously interpolates between the KL and the Maximum Mean Discrepancy
(MMD). Like the MMD and other Integral Probability Metrics, the KALE remains
well defined for mutually singular distributions. Nonetheless, the KALE
inherits from the limiting KL a greater sensitivity to mismatch in the support
of the distributions, compared with the MMD. These two properties make the KALE
gradient flow particularly well suited when the target distribution is
supported on a low-dimensional manifold. Under an assumption of sufficient
smoothness of the trajectories, we show the global convergence of the KALE
flow. We propose a particle implementation of the flow given initial samples
from the source and the target distribution, which we use to empirically
confirm the KALE&#x27;s properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Tertiary Protein Structures via an Interpretative Variational Autoencoder. (arXiv:2004.07119v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Guo_X/0/1/0/all/0/1">Xiaojie Guo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Du_Y/0/1/0/all/0/1">Yuanqi Du</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tadepalli_S/0/1/0/all/0/1">Sivani Tadepalli</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shehu_A/0/1/0/all/0/1">Amarda Shehu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07119">
                                    <div class="article-summary-box-inner">
                                        <span>Much scientific enquiry across disciplines is founded upon a mechanistic
treatment of dynamic systems that ties form to function. A highly visible
instance of this is in molecular biology, where an important goal is to
determine functionally-relevant forms/structures that a protein molecule
employs to interact with molecular partners in the living cell. This goal is
typically pursued under the umbrella of stochastic optimization with algorithms
that optimize a scoring function. Research repeatedly shows that current
scoring function, though steadily improving, correlate weakly with molecular
activity. Inspired by recent momentum in generative deep learning, this paper
proposes and evaluates an alternative approach to generating
functionally-relevant three-dimensional structures of a protein. Though
typically deep generative models struggle with highly-structured data, the work
presented here circumvents this challenge via graph-generative models. A
comprehensive evaluation of several deep architectures shows the promise of
generative models in directly revealing the latent space for sampling novel
tertiary structures, as well as in highlighting axes/factors that carry
structural meaning and open the black box often associated with deep models.
The work presented here is a first step towards interpretative, deep generative
models becoming viable and informative complementary approaches to protein
structure prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting chaos in lineage-trees: A deep learning approach. (arXiv:2106.08956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rappeport_H/0/1/0/all/0/1">Hagai Rappeport</a>, <a href="http://arxiv.org/find/cs/1/au:+Reisman_I/0/1/0/all/0/1">Irit Levin Reisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tishby_N/0/1/0/all/0/1">Naftali Tishby</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaban_N/0/1/0/all/0/1">Nathalie Q. Balaban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08956">
                                    <div class="article-summary-box-inner">
                                        <span>Many complex phenomena, from weather systems to heartbeat rhythm patterns,
are effectively modeled as low-dimensional dynamical systems. Such systems may
behave chaotically under certain conditions, and so the ability to detect chaos
based on empirical measurement is an important step in characterizing and
predicting these processes. Classifying a system as chaotic usually requires
estimating its largest Lyapunov exponent, which quantifies the average rate of
convergence or divergence of initially close trajectories in state space, and
for which a positive value is generally accepted as an operational definition
of chaos. Estimating the largest Lyapunov exponent from observations of a
process is especially challenging in systems affected by dynamical noise, which
is the case for many models of real-world processes, in particular models of
biological systems. We describe a novel method for estimating the largest
Lyapunov exponent from data, based on training Deep Learning models on
synthetically generated trajectories, and demonstrate that this method yields
accurate and noise-robust predictions given relatively short inputs and across
a range of different dynamical systems. Our method is unique in that it can
analyze tree-shaped data, a ubiquitous topology in biological settings, and
specifically in dynamics over lineages of cells or organisms. We also
characterize the types of input information extracted by our models for their
predictions, allowing for a deeper understanding into the different ways by
which chaos can be analyzed in different topologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization. (arXiv:2102.01670v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1">Kale-ab Tessera</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1">Benjamin Rosman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01670">
                                    <div class="article-summary-box-inner">
                                        <span>Training sparse networks to converge to the same performance as dense neural
architectures has proven to be elusive. Recent work suggests that
initialization is the key. However, while this direction of research has had
some success, focusing on initialization alone appears to be inadequate. In
this paper, we take a broader view of training sparse networks and consider the
role of regularization, optimization, and architecture choices on sparse
models. We propose a simple experimental framework, Same Capacity Sparse vs
Dense Comparison (SC-SDC), that allows for a fair comparison of sparse and
dense networks. Furthermore, we propose a new measure of gradient flow,
Effective Gradient Flow (EGF), that better correlates to performance in sparse
networks. Using top-line metrics, SC-SDC and EGF, we show that default choices
of optimizers, activation functions and regularizers used for dense networks
can disadvantage sparse networks. Based upon these findings, we show that
gradient flow in sparse networks can be improved by reconsidering aspects of
the architecture design and the training regime. Our work suggests that
initialization is only one piece of the puzzle and taking a wider view of
tailoring optimization to sparse networks yields promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LieTransformer: Equivariant self-attention for Lie Groups. (arXiv:2012.10885v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hutchinson_M/0/1/0/all/0/1">Michael Hutchinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Charline Le Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1">Sheheryar Zaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupont_E/0/1/0/all/0/1">Emilien Dupont</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunjik Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10885">
                                    <div class="article-summary-box-inner">
                                        <span>Group equivariant neural networks are used as building blocks of group
invariant neural networks, which have been shown to improve generalisation
performance and data efficiency through principled parameter sharing. Such
works have mostly focused on group equivariant convolutions, building on the
result that group equivariant linear maps are necessarily convolutions. In this
work, we extend the scope of the literature to self-attention, that is emerging
as a prominent building block of deep learning models. We propose the
LieTransformer, an architecture composed of LieSelfAttention layers that are
equivariant to arbitrary Lie groups and their discrete subgroups. We
demonstrate the generality of our approach by showing experimental results that
are competitive to baseline methods on a wide range of tasks: shape counting on
point clouds, molecular property regression and modelling particle trajectories
under Hamiltonian dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Quasi-Bayesian Inference for Instrumental Variable Regression. (arXiv:2106.08750v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Ziyu Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1">Yuhao Zhou</a>, <a href="http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1">Tongzheng Ren</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08750">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed an upsurge of interest in employing flexible
machine learning models for instrumental variable (IV) regression, but the
development of uncertainty quantification methodology is still lacking. In this
work we present a scalable quasi-Bayesian procedure for IV regression, building
upon the recently developed kernelized IV models. Contrary to Bayesian modeling
for IV, our approach does not require additional assumptions on the data
generating process, and leads to a scalable approximate inference algorithm
with time cost comparable to the corresponding point estimation methods. Our
algorithm can be further extended to work with neural network models. We
analyze the theoretical properties of the proposed quasi-posterior, and
demonstrate through empirical evaluation the competitive performance of our
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Banker Online Mirror Descent. (arXiv:2106.08943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiatai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08943">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Banker-OMD, a novel framework generalizing the classical Online
Mirror Descent (OMD) technique in online learning algorithm design. Banker-OMD
allows algorithms to robustly handle delayed feedback, and offers a general
methodology for achieving $\tilde{O}(\sqrt{T} + \sqrt{D})$-style regret bounds
in various delayed-feedback online learning tasks, where $T$ is the time
horizon length and $D$ is the total feedback delay. We demonstrate the power of
Banker-OMD with applications to three important bandit scenarios with delayed
feedback, including delayed adversarial Multi-armed bandits (MAB), delayed
adversarial linear bandits, and a novel delayed best-of-both-worlds MAB
setting. Banker-OMD achieves nearly-optimal performance in all the three
settings. In particular, it leads to the first delayed adversarial linear
bandit algorithm achieving $\tilde{O}(\text{poly}(n)(\sqrt{T} + \sqrt{D}))$
regret.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry of Similarity Comparisons. (arXiv:2006.09858v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1">Puoya Tabaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jianhao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1">Olgica Milenkovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Dokmanic_I/0/1/0/all/0/1">Ivan Dokmani&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09858">
                                    <div class="article-summary-box-inner">
                                        <span>Many data analysis problems can be cast as distance geometry problems in
\emph{space forms} -- Euclidean, spherical, or hyperbolic spaces. Often,
absolute distance measurements are often unreliable or simply unavailable and
only proxies to absolute distances in the form of similarities are available.
Hence we ask the following: Given only \emph{comparisons} of similarities
amongst a set of entities, what can be said about the geometry of the
underlying space form? To study this question, we introduce the notions of the
\textit{ordinal capacity} of a target space form and \emph{ordinal spread} of
the similarity measurements. The latter is an indicator of complex patterns in
the measurements, while the former quantifies the capacity of a space form to
accommodate a set of measurements with a specific ordinal spread profile. We
prove that the ordinal capacity of a space form is related to its dimension and
the sign of its curvature. This leads to a lower bound on the Euclidean and
spherical embedding dimension of what we term similarity graphs. More
importantly, we show that the statistical behavior of the ordinal spread random
variables defined on a similarity graph can be used to identify its underlying
space form. We support our theoretical claims with experiments on weighted
trees, single-cell RNA expression data and spherical cartographic measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data. (arXiv:2106.08977v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haoming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Danqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tianyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1">Bing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08977">
                                    <div class="article-summary-box-inner">
                                        <span>Weak supervision has shown promising results in many natural language
processing tasks, such as Named Entity Recognition (NER). Existing work mainly
focuses on learning deep NER models only with weak supervision, i.e., without
any human annotation, and shows that by merely using weakly labeled data, one
can achieve good performance, though still underperforms fully supervised NER
with manually/strongly labeled data. In this paper, we consider a more
practical scenario, where we have both a small amount of strongly labeled data
and a large amount of weakly labeled data. Unfortunately, we observe that
weakly labeled data does not necessarily improve, or even deteriorate the model
performance (due to the extensive noise in the weak labels) when we train deep
NER models over a simple or weighted combination of the strongly labeled and
weakly labeled data. To address this issue, we propose a new multi-stage
computational framework -- NEEDLE with three essential ingredients: (1) weak
label completion, (2) noise-aware loss function, and (3) final fine-tuning over
the strongly labeled data. Through experiments on E-commerce query NER and
Biomedical NER, we demonstrate that NEEDLE can effectively suppress the noise
of the weak labels and outperforms existing methods. In particular, we achieve
new SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,
BC5CDR-disease 90.69, NCBI-disease 92.28.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Costs and Benefits of Wasserstein Fair Regression. (arXiv:2106.08812v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08812">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world applications of machine learning tools in high-stakes domains are
often regulated to be fair, in the sense that the predicted target should
satisfy some quantitative notion of parity with respect to a protected
attribute. However, the exact tradeoff between fairness and accuracy with a
real-valued target is not clear. In this paper, we characterize the inherent
tradeoff between statistical parity and accuracy in the regression setting by
providing a lower bound on the error of any fair regressor. Our lower bound is
sharp, algorithm-independent, and admits a simple interpretation: when the
moments of the target differ between groups, any fair algorithm has to make a
large error on at least one of the groups. We further extend this result to
give a lower bound on the joint error of any (approximately) fair algorithm,
using the Wasserstein distance to measure the quality of the approximation. On
the upside, we establish the first connection between individual fairness,
accuracy parity, and the Wasserstein distance by showing that if a regressor is
individually fair, it also approximately verifies the accuracy parity, where
the gap is given by the Wasserstein distance between the two groups. Inspired
by our theoretical results, we develop a practical algorithm for fair
regression through the lens of representation learning, and conduct experiments
on a real-world dataset to corroborate our findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circa: Stochastic ReLUs for Private Deep Learning. (arXiv:2106.08475v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghodsi_Z/0/1/0/all/0/1">Zahra Ghodsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1">Nandan Kumar Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Reagen_B/0/1/0/all/0/1">Brandon Reagen</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Siddharth Garg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08475">
                                    <div class="article-summary-box-inner">
                                        <span>The simultaneous rise of machine learning as a service and concerns over user
privacy have increasingly motivated the need for private inference (PI). While
recent work demonstrates PI is possible using cryptographic primitives, the
computational overheads render it impractical. The community is largely
unprepared to address these overheads, as the source of slowdown in PI stems
from the ReLU operator whereas optimizations for plaintext inference focus on
optimizing FLOPs. In this paper we re-think the ReLU computation and propose
optimizations for PI tailored to properties of neural networks. Specifically,
we reformulate ReLU as an approximate sign test and introduce a novel
truncation method for the sign test that significantly reduces the cost per
ReLU. These optimizations result in a specific type of stochastic ReLU. The key
observation is that the stochastic fault behavior is well suited for the
fault-tolerant properties of neural network inference. Thus, we provide
significant savings without impacting accuracy. We collectively call the
optimizations Circa and demonstrate improvements of up to 4.7x storage and 3x
runtime over baseline implementations; we further show that Circa can be used
on top of recent PI optimizations to obtain 1.8x additional speedup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaomeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1">Michael Potter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gaurav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yun-Chan Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1">V. Ratna Saripalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08756">
                                    <div class="article-summary-box-inner">
                                        <span>It is no secret amongst deep learning researchers that finding the right data
augmentation strategy during training can mean the difference between a
state-of-the-art result and a run-of-the-mill ranking. To that end, the
community has seen many efforts to automate the process of finding the perfect
augmentation procedure for any task at hand. Unfortunately, even recent
cutting-edge methods bring massive computational overhead, requiring as many as
100 full model trainings to settle on an ideal configuration. We show how to
achieve even better performance in just 7: with Random Unidimensional
Augmentation. Source code is available at https://github.com/fastestimator/RUA</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning-based analysis of hyperspectral images for automated sepsis diagnosis. (arXiv:2106.08445v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_M/0/1/0/all/0/1">Maximilian Dietrich</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Seidlitz_S/0/1/0/all/0/1">Silvia Seidlitz</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Schreck_N/0/1/0/all/0/1">Nicholas Schreck</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1">Manuel Wiesenfarth</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1">Patrick Godau</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Tizabi_M/0/1/0/all/0/1">Minu Tizabi</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Sellner_J/0/1/0/all/0/1">Jan Sellner</a> (2, 3), <a href="http://arxiv.org/find/cs/1/au:+Marx_S/0/1/0/all/0/1">Sebastian Marx</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Knodler_S/0/1/0/all/0/1">Samuel Kn&#xf6;dler</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Allers_M/0/1/0/all/0/1">Michael M. Allers</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Ayala_L/0/1/0/all/0/1">Leonardo Ayala</a> (2, 7), <a href="http://arxiv.org/find/cs/1/au:+Schmidt_K/0/1/0/all/0/1">Karsten Schmidt</a> (8), <a href="http://arxiv.org/find/cs/1/au:+Brenner_T/0/1/0/all/0/1">Thorsten Brenner</a> (8), <a href="http://arxiv.org/find/cs/1/au:+Studier_Fischer_A/0/1/0/all/0/1">Alexander Studier-Fischer</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Nickel_F/0/1/0/all/0/1">Felix Nickel</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Muller_Stich_B/0/1/0/all/0/1">Beat P. M&#xfc;ller-Stich</a> (5), <a href="http://arxiv.org/find/cs/1/au:+Kopp_Schneider_A/0/1/0/all/0/1">Annette Kopp-Schneider</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Weigand_M/0/1/0/all/0/1">Markus A. Weigand</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1">Lena Maier-Hein</a> (2, 6, 7) ((1) Department of Anesthesiology, Heidelberg University Hospital, Heidelberg, Germany, (2) Division of Computer Assisted Medical Interventions, German Cancer Research Center (DKFZ), Heidelberg, Germany, (3) HIDSS4Health - Helmholtz Information and Data Science School for Health, Karlsruhe/Heidelberg, Germany (4) Division of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, Germany, (5) Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany, (6) Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany, (7) Medical Faculty, Heidelberg University, Heidelberg, Germany, (8) Department of Anesthesiology and Intensive Care Medicine, University Hospital Essen, University Duisburg-Essen, Essen, Germany)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08445">
                                    <div class="article-summary-box-inner">
                                        <span>Sepsis is a leading cause of mortality and critical illness worldwide. While
robust biomarkers for early diagnosis are still missing, recent work indicates
that hyperspectral imaging (HSI) has the potential to overcome this bottleneck
by monitoring microcirculatory alterations. Automated machine learning-based
diagnosis of sepsis based on HSI data, however, has not been explored to date.
Given this gap in the literature, we leveraged an existing data set to (1)
investigate whether HSI-based automated diagnosis of sepsis is possible and (2)
put forth a list of possible confounders relevant for HSI-based tissue
classification. While we were able to classify sepsis with an accuracy of over
$98\,\%$ using the existing data, our research also revealed several subject-,
therapy- and imaging-related confounders that may lead to an overestimation of
algorithm performance when not balanced across the patient groups. We conclude
that further prospective studies, carefully designed with respect to these
confounders, are necessary to confirm the preliminary results obtained in this
study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cardiovascular Disease Prediction using Recursive Feature Elimination and Gradient Boosting Classification Techniques. (arXiv:2106.08889v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Theerthagiri_P/0/1/0/all/0/1">Prasannavenkatesan Theerthagiri</a>, <a href="http://arxiv.org/find/cs/1/au:+J_V/0/1/0/all/0/1">Vidya J</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08889">
                                    <div class="article-summary-box-inner">
                                        <span>Cardiovascular diseases (CVDs) are one of the most common chronic illnesses
that affect peoples health. Early detection of CVDs can reduce mortality rates
by preventing or reducing the severity of the disease. Machine learning
algorithms are a promising method for identifying risk factors. This paper
proposes a proposed recursive feature elimination-based gradient boosting
(RFE-GB) algorithm in order to obtain accurate heart disease prediction. The
patients health record with important CVD features has been analyzed for the
evaluation of the results. Several other machine learning methods were also
used to build the prediction model, and the results were compared with the
proposed model. The results of this proposed model infer that the combined
recursive feature elimination and gradient boosting algorithm achieves the
highest accuracy (89.7 %). Further, with an area under the curve of 0.84, the
proposed RFE-GB algorithm was found superior and had obtained a substantial
gain over other techniques. Thus, the proposed RFE-GB algorithm will serve as a
prominent model for CVD estimation and treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Continuous Control with Episodic Memory. (arXiv:2106.08832v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuznetsov_I/0/1/0/all/0/1">Igor Kuznetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Filchenkov_A/0/1/0/all/0/1">Andrey Filchenkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08832">
                                    <div class="article-summary-box-inner">
                                        <span>Episodic memory lets reinforcement learning algorithms remember and exploit
promising experience from the past to improve agent performance. Previous works
on memory mechanisms show benefits of using episodic-based data structures for
discrete action problems in terms of sample-efficiency. The application of
episodic memory for continuous control with a large action space is not
trivial. Our study aims to answer the question: can episodic memory be used to
improve agent&#x27;s performance in continuous control? Our proposed algorithm
combines episodic memory with Actor-Critic architecture by modifying critic&#x27;s
objective. We further improve performance by introducing episodic-based replay
buffer prioritization. We evaluate our algorithm on OpenAI gym domains and show
greater sample-efficiency compared with the state-of-the art model-free
off-policy algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Training in High Dimensions via Block Coordinate Geometric Median Descent. (arXiv:2106.08882v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Anish Acharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_A/0/1/0/all/0/1">Abolfazl Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1">Sujay Sanghavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1">Inderjit S. Dhillon</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08882">
                                    <div class="article-summary-box-inner">
                                        <span>Geometric median (\textsc{Gm}) is a classical method in statistics for
achieving a robust estimation of the uncorrupted data; under gross corruption,
it achieves the optimal breakdown point of 0.5. However, its computational
complexity makes it infeasible for robustifying stochastic gradient descent
(SGD) for high-dimensional optimization problems. In this paper, we show that
by applying \textsc{Gm} to only a judiciously chosen block of coordinates at a
time and using a memory mechanism, one can retain the breakdown point of 0.5
for smooth non-convex problems, with non-asymptotic convergence rates
comparable to the SGD with \textsc{Gm}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Input Invex Neural Network. (arXiv:2106.08748v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sapkota_S/0/1/0/all/0/1">Suman Sapkota</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1">Binod Bhattarai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08748">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel method to constrain invexity on Neural
Networks (NN). Invex functions ensure every stationary point is global minima.
Hence, gradient descent commenced from any point will lead to the global
minima. Another advantage of invexity on NN is to divide data space locally
into two connected sets with a highly non-linear decision boundary by simply
thresholding the output. To this end, we formulate a universal invex function
approximator and employ it to enforce invexity in NN. We call it Input Invex
Neural Networks (II-NN). We first fit data with a known invex function,
followed by modification with a NN, compare the direction of the gradient and
penalize the direction of gradient on NN if it contradicts with the direction
of reference invex function. In order to penalize the direction of the gradient
we perform Gradient Clipped Gradient Penalty (GC-GP). We applied our method to
the existing NNs for both image classification and regression tasks. From the
extensive empirical and qualitative experiments, we observe that our method
gives the performance similar to ordinary NN yet having invexity. Our method
outperforms linear NN and Input Convex Neural Network (ICNN) with a large
margin. We publish our code and implementation details at github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridge Networks. (arXiv:2106.08446v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Olin_Ammentorp_W/0/1/0/all/0/1">Wilkie Olin-Ammentorp</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazhenov_M/0/1/0/all/0/1">Maxim Bazhenov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08446">
                                    <div class="article-summary-box-inner">
                                        <span>Despite rapid progress, current deep learning methods face a number of
critical challenges. These include high energy consumption, catastrophic
forgetting, dependance on global losses, and an inability to reason
symbolically. By combining concepts from information bottleneck theory and
vector-symbolic architectures, we propose and implement a novel information
processing architecture, the &#x27;Bridge network.&#x27; We show this architecture
provides unique advantages which can address the problem of global losses and
catastrophic forgetting. Furthermore, we argue that it provides a further basis
for increasing energy efficiency of execution and the ability to reason
symbolically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbiased Methods for Multi-Goal Reinforcement Learning. (arXiv:2106.08863v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blier_L/0/1/0/all/0/1">L&#xe9;onard Blier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ollivier_Y/0/1/0/all/0/1">Yann Ollivier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08863">
                                    <div class="article-summary-box-inner">
                                        <span>In multi-goal reinforcement learning (RL) settings, the reward for each goal
is sparse, and located in a small neighborhood of the goal. In large dimension,
the probability of reaching a reward vanishes and the agent receives little
learning signal. Methods such as Hindsight Experience Replay (HER) tackle this
issue by also learning from realized but unplanned-for goals. But HER is known
to introduce bias, and can converge to low-return policies by overestimating
chancy outcomes. First, we vindicate HER by proving that it is actually
unbiased in deterministic environments, such as many optimal control settings.
Next, for stochastic environments in continuous spaces, we tackle sparse
rewards by directly taking the infinitely sparse reward limit. We fully
formalize the problem of multi-goal RL with infinitely sparse Dirac rewards at
each goal. We introduce unbiased deep Q-learning and actor-critic algorithms
that can handle such infinitely sparse rewards, and test them in toy
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Training of Partially Masked Neural Networks. (arXiv:2106.08895v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohtashami_A/0/1/0/all/0/1">Amirkeivan Mohtashami</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08895">
                                    <div class="article-summary-box-inner">
                                        <span>For deploying deep learning models to lower end devices, it is necessary to
train less resource-demanding variants of state-of-the-art architectures. This
does not eliminate the need for more expensive models as they have a higher
performance. In order to avoid training two separate models, we show that it is
possible to train neural networks in such a way that a predefined &#x27;core&#x27;
subnetwork can be split-off from the trained full network with remarkable good
performance. We extend on prior methods that focused only on core networks of
smaller width, while we focus on supporting arbitrary core network
architectures. Our proposed training scheme switches consecutively between
optimizing only the core part of the network and the full one. The accuracy of
the full model remains comparable, while the core network achieves better
performance than when it is trained in isolation. In particular, we show that
training a Transformer with a low-rank core gives a low-rank model with
superior performance than when training the low-rank model alone. We analyze
our training scheme theoretically, and show its convergence under assumptions
that are either standard or practically justified. Moreover, we show that the
developed theoretical framework allows analyzing many other partial training
schemes for neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more Scalable than Optimism?. (arXiv:2106.08771v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gast_N/0/1/0/all/0/1">Nicolas Gast</a> (POLARIS), <a href="http://arxiv.org/find/cs/1/au:+Gaujal_B/0/1/0/all/0/1">Bruno Gaujal</a> (POLARIS), <a href="http://arxiv.org/find/cs/1/au:+Khun_K/0/1/0/all/0/1">Kimang Khun</a> (POLARIS)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08771">
                                    <div class="article-summary-box-inner">
                                        <span>We study learning algorithms for the classical Markovian bandit problem with
discount. We explain how to adapt PSRL [24] and UCRL2 [2] to exploit the
problem structure. These variants are called MB-PSRL and MB-UCRL2. While the
regret bound and runtime of vanilla implementations of PSRL and UCRL2 are
exponential in the number of bandits, we show that the episodic regret of
MB-PSRL and MB-UCRL2 is�(S $\sqrt$ nK) where K is the number of episodes, n is
the number of bandits and S is the number of states of each bandit (the exact
bound in S, n and K is given in the paper). Up to a factor $\sqrt$ S, this
matches the lower bound of $\Omega$($\sqrt$ SnK) that we also derive in the
paper. MB-PSRL is also computationally efficient: its runtime is linear in the
number of bandits. We further show that this linear runtime cannot be achieved
by adapting classical non-Bayesian algorithms such as UCRL2 or UCBVI to
Markovian bandit problems. Finally, we perform numerical experiments that
confirm that MB-PSRL outperforms other existing algorithms in practice, both in
terms of regret and of computation time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Rhythm Style Transfer Without Text Transcriptions. (arXiv:2106.08519v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Qian_K/0/1/0/all/0/1">Kaizhi Qian</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_S/0/1/0/all/0/1">Shiyu Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiong_J/0/1/0/all/0/1">Jinjun Xiong</a>, <a href="http://arxiv.org/find/eess/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/eess/1/au:+Cox_D/0/1/0/all/0/1">David Cox</a>, <a href="http://arxiv.org/find/eess/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1">Mark Hasegawa-Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08519">
                                    <div class="article-summary-box-inner">
                                        <span>Prosody plays an important role in characterizing the style of a speaker or
an emotion, but most non-parallel voice or emotion style transfer algorithms do
not convert any prosody information. Two major components of prosody are pitch
and rhythm. Disentangling the prosody information, particularly the rhythm
component, from the speech is challenging because it involves breaking the
synchrony between the input speech and the disentangled speech representation.
As a result, most existing prosody style transfer algorithms would need to rely
on some form of text transcriptions to identify the content information, which
confines their application to high-resource languages only. Recently,
SpeechSplit has made sizeable progress towards unsupervised prosody style
transfer, but it is unable to extract high-level global prosody style in an
unsupervised manner. In this paper, we propose AutoPST, which can disentangle
global prosody style from speech without relying on any text transcriptions.
AutoPST is an Autoencoder-based Prosody Style Transfer framework with a
thorough rhythm removal module guided by the self-expressive representation
learning. Experiments on different style transfer tasks show that AutoPST can
effectively convert prosody that correctly reflects the styles of the target
domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foo_L/0/1/0/all/0/1">Lin Geng Foo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiamei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Binder_A/0/1/0/all/0/1">Alexander Binder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10817">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of segmenting cell nuclei instances from Hematoxylin
and Eosin (H&amp;E) stains with dot annotations only. While most recent works focus
on improving the segmentation quality, this is usually insufficient for
instance segmentation of cell instances clustered together or with a small
size. In this work, we propose a simple two-step post-processing procedure,
Split and Expand, that directly improves the conversion of segmentation maps to
instances. In the splitting step, we generate fine-grained cell instances from
the segmentation map with the guidance of cell-center predictions. For the
expansion step, we utilize Layer-wise Relevance Propagation (LRP) explanation
results to add small cells that are not captured in the segmentation map.
Although we additionally train an output head to predict cell-centers, the
post-processing procedure itself is not explicitly trained and is executed at
inference-time only. A feature re-weighting loss based on LRP is proposed to
improve our method even further. We test our procedure on the MoNuSeg and TNBC
datasets and show quantitatively and qualitatively that our proposed method
improves object-level metrics substantially.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Class Classification from Single-Class Data with Confidences. (arXiv:2106.08864v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yuzhou Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_S/0/1/0/all/0/1">Senlin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yitian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08864">
                                    <div class="article-summary-box-inner">
                                        <span>Can we learn a multi-class classifier from only data of a single class? We
show that without any assumptions on the loss functions, models, and
optimizers, we can successfully learn a multi-class classifier from only data
of a single class with a rigorous consistency guarantee when confidences (i.e.,
the class-posterior probabilities for all the classes) are available.
Specifically, we propose an empirical risk minimization framework that is
loss-/model-/optimizer-independent. Instead of constructing a boundary between
the given class and other classes, our method can conduct discriminative
classification between all the classes even if no data from the other classes
are provided. We further theoretically and experimentally show that our method
can be Bayes-consistent with a simple modification even if the provided
confidences are highly noisy. Then, we provide an extension of our method for
the case where data from a subset of all the classes are available.
Experimental results demonstrate the effectiveness of our methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the long-term learning ability of LSTM LMs. (arXiv:2106.08927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boes_W/0/1/0/all/0/1">Wim Boes</a>, <a href="http://arxiv.org/find/cs/1/au:+Rompaey_R/0/1/0/all/0/1">Robbe Van Rompaey</a>, <a href="http://arxiv.org/find/cs/1/au:+Verwimp_L/0/1/0/all/0/1">Lyan Verwimp</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelemans_J/0/1/0/all/0/1">Joris Pelemans</a>, <a href="http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1">Hugo Van hamme</a>, <a href="http://arxiv.org/find/cs/1/au:+Wambacq_P/0/1/0/all/0/1">Patrick Wambacq</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08927">
                                    <div class="article-summary-box-inner">
                                        <span>We inspect the long-term learning ability of Long Short-Term Memory language
models (LSTM LMs) by evaluating a contextual extension based on the Continuous
Bag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and
by analyzing its performance. We evaluate on text and speech. Sentence-level
models using the long-term contextual module perform comparably to vanilla
discourse-level LSTM LMs. On the other hand, the extension does not provide
gains for discourse-level models. These findings indicate that discourse-level
LSTM LMs already rely on contextual information to perform long-term learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections. (arXiv:2106.08908v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pappas_D/0/1/0/all/0/1">Dimitris Pappas</a>, <a href="http://arxiv.org/find/cs/1/au:+Androutsopoulos_I/0/1/0/all/0/1">Ion Androutsopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08908">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) systems for large document collections typically use
pipelines that (i) retrieve possibly relevant documents, (ii) re-rank them,
(iii) rank paragraphs or other snippets of the top-ranked documents, and (iv)
select spans of the top-ranked snippets as exact answers. Pipelines are
conceptually simple, but errors propagate from one component to the next,
without later components being able to revise earlier decisions. We present an
architecture for joint document and snippet ranking, the two middle stages,
which leverages the intuition that relevant documents have good snippets and
good snippets come from relevant documents. The architecture is general and can
be used with any neural text relevance ranker. We experiment with two main
instantiations of the architecture, based on POSIT-DRMM (PDRMM) and a
BERT-based ranker. Experiments on biomedical data from BIOASQ show that our
joint models vastly outperform the pipelines in snippet retrieval, the main
goal for QA, with fewer trainable parameters, also remaining competitive in
document retrieval. Furthermore, our joint PDRMM-based model is competitive
with BERT-based models, despite using orders of magnitude fewer parameters.
These claims are also supported by human evaluation on two test batches of
BIOASQ. To test our key findings on another dataset, we modified the Natural
Questions dataset so that it can also be used for document and snippet
retrieval. Our joint PDRMM-based model again outperforms the corresponding
pipeline in snippet retrieval on the modified Natural Questions dataset, even
though it performs worse than the pipeline in document retrieval. We make our
code and the modified Natural Questions dataset publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Covariance-based smoothed particle hydrodynamics. A machine-learning application to simulating disc fragmentation. (arXiv:2106.08870v1 [physics.comp-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Marinho_E/0/1/0/all/0/1">Eraldo Pereira Marinho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08870">
                                    <div class="article-summary-box-inner">
                                        <span>A PCA-based, machine learning version of the SPH method is proposed. In the
present scheme, the smoothing tensor is computed to have their eigenvalues
proportional to the covariance&#x27;s principal components, using a modified octree
data structure, which allows the fast estimation of the anisotropic
self-regulating kNN. Each SPH particle is the center of such an optimal kNN
cluster, i.e., the one whose covariance tensor allows the find of the kNN
cluster itself according to the Mahalanobis metric. Such machine learning
constitutes a fixed point problem. The definitive (self-regulating) kNN cluster
defines the smoothing volume, or properly saying, the smoothing ellipsoid,
required to perform the anisotropic interpolation. Thus, the smoothing kernel
has an ellipsoidal profile, which changes how the kernel gradients are
computed. As an application, it was performed the simulation of collapse and
fragmentation of a non-magnetic, rotating gaseous sphere. An interesting
outcome was the formation of protostars in the disc fragmentation, shown to be
much more persistent and much more abundant in the anisotropic simulation than
in the isotropic case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding Spatio-Temporal Language with Transformers. (arXiv:2106.08858v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karch_T/0/1/0/all/0/1">Tristan Karch</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1">Laetitia Teodorescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1">Cl&#xe9;ment Moulin-Frier</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08858">
                                    <div class="article-summary-box-inner">
                                        <span>Language is an interface to the outside world. In order for embodied agents
to use it, language must be grounded in other, sensorimotor modalities. While
there is an extended literature studying how machines can learn grounded
language, the topic of how to learn spatio-temporal linguistic concepts is
still largely uncharted. To make progress in this direction, we here introduce
a novel spatio-temporal language grounding task where the goal is to learn the
meaning of spatio-temporal descriptions of behavioral traces of an embodied
agent. This is achieved by training a truth function that predicts if a
description matches a given history of observations. The descriptions involve
time-extended predicates in past and present tense as well as spatio-temporal
references to objects in the scene. To study the role of architectural biases
in this task, we train several models including multimodal Transformer
architectures; the latter implement different attention computations between
words and objects across space and time. We test models on two classes of
generalization: 1) generalization to randomly held-out sentences; 2)
generalization to grammar primitives. We observe that maintaining object
identity in the attention computation of our Transformers is instrumental to
achieving good performance on generalization overall, and that summarizing
object traces in a single token has little influence on performance. We then
discuss how this opens new perspectives for language-guided autonomous embodied
agents. We also release our code under open-source license as well as
pretrained models and datasets to encourage the wider community to build upon
and extend our work in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scene Transformer: A unified multi-task model for behavior prediction and planning. (arXiv:2106.08417v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngiam_J/0/1/0/all/0/1">Jiquan Ngiam</a>, <a href="http://arxiv.org/find/cs/1/au:+Caine_B/0/1/0/all/0/1">Benjamin Caine</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1">Vijay Vasudevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hao-Tien Lewis Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1">Jeffrey Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1">Alex Bewley</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chenxi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1">Ashish Venugopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Weiss_D/0/1/0/all/0/1">David Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1">Ben Sapp</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1">Jonathon Shlens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08417">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the future motion of multiple agents is necessary for planning in
dynamic environments. This task is challenging for autonomous driving since
agents (e.g., vehicles and pedestrians) and their associated behaviors may be
diverse and influence each other. Most prior work has focused on first
predicting independent futures for each agent based on all past motion, and
then planning against these independent predictions. However, planning against
fixed predictions can suffer from the inability to represent the future
interaction possibilities between different agents, leading to sub-optimal
planning. In this work, we formulate a model for predicting the behavior of all
agents jointly in real-world driving environments in a unified manner. Inspired
by recent language modeling approaches, we use a masking strategy as the query
to our model, enabling one to invoke a single model to predict agent behavior
in many ways, such as potentially conditioned on the goal or full future
trajectory of the autonomous vehicle or the behavior of other agents in the
environment. Our model architecture fuses heterogeneous world state in a
unified Transformer architecture by employing attention across road elements,
agent interactions and time steps. We evaluate our approach on autonomous
driving datasets for behavior prediction, and achieve state-of-the-art
performance. Our work demonstrates that formulating the problem of behavior
prediction in a unified architecture with a masking strategy may allow us to
have a single model that can perform multiple motion prediction and planning
related tasks effectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algorithm to Compilation Codesign: An Integrated View of Neural Network Sparsity. (arXiv:2106.08846v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1">Fu-Ming Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Austin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08846">
                                    <div class="article-summary-box-inner">
                                        <span>Reducing computation cost, inference latency, and memory footprint of neural
networks are frequently cited as research motivations for pruning and sparsity.
However, operationalizing those benefits and understanding the end-to-end
effect of algorithm design and regularization on the runtime execution is not
often examined in depth.

Here we apply structured and unstructured pruning to attention weights of
transformer blocks of the BERT language model, while also expanding block
sparse representation (BSR) operations in the TVM compiler. Integration of BSR
operations enables the TVM runtime execution to leverage structured pattern
sparsity induced by model regularization.

This integrated view of pruning algorithms enables us to study relationships
between modeling decisions and their direct impact on sparsity-enhanced
execution. Our main findings are: 1) we validate that performance benefits of
structured sparsity block regularization must be enabled by the BSR
augmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x
speedup relative to standard TVM compilation (without expanded BSR support). 2)
for BERT attention weights, the end-to-end optimal block sparsity shape in this
CPU inference context is not a square block (as in \cite{gray2017gpu}) but
rather a linear 32x1 block 3) the relationship between performance and block
size / shape is is suggestive of how model regularization parameters interact
with task scheduler optimizations resulting in the observed end-to-end
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean Estimation. (arXiv:2106.08537v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Kongsgaard_D/0/1/0/all/0/1">Daniel Kongsgaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08537">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of list-decodable mean estimation, where an adversary
can corrupt a majority of the dataset. Specifically, we are given a set $T$ of
$n$ points in $\mathbb{R}^d$ and a parameter $0&lt; \alpha &lt;\frac 1 2$ such that
an $\alpha$-fraction of the points in $T$ are i.i.d. samples from a
well-behaved distribution $\mathcal{D}$ and the remaining $(1-\alpha)$-fraction
of the points are arbitrary. The goal is to output a small list of vectors at
least one of which is close to the mean of $\mathcal{D}$. As our main
contribution, we develop new algorithms for list-decodable mean estimation,
achieving nearly-optimal statistical guarantees, with running time $n^{1 +
o(1)} d$. All prior algorithms for this problem had additional polynomial
factors in $\frac 1 \alpha$. As a corollary, we obtain the first almost-linear
time algorithms for clustering mixtures of $k$ separated well-behaved
distributions, nearly-matching the statistical guarantees of spectral methods.
Prior clustering algorithms inherently relied on an application of $k$-PCA,
thereby incurring runtimes of $\Omega(n d k)$. This marks the first runtime
improvement for this basic statistical problem in nearly two decades.

The starting point of our approach is a novel and simpler near-linear time
robust mean estimation algorithm in the $\alpha \to 1$ regime, based on a
one-shot matrix multiplicative weights-inspired potential decrease. We
crucially leverage this new algorithmic framework in the context of the
iterative multi-filtering technique of Diakonikolas et. al. &#x27;18, &#x27;20, providing
a method to simultaneously cluster and downsample points using one-dimensional
projections --- thus, bypassing the $k$-PCA subroutines required by prior
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating the Robustness of Public Transport Systems Using Machine Learning. (arXiv:2106.08967v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_Hannemann_M/0/1/0/all/0/1">Matthias M&#xfc;ller-Hannemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruckert_R/0/1/0/all/0/1">Ralf R&#xfc;ckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Schiewe_A/0/1/0/all/0/1">Alexander Schiewe</a>, <a href="http://arxiv.org/find/cs/1/au:+Schobel_A/0/1/0/all/0/1">Anita Sch&#xf6;bel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08967">
                                    <div class="article-summary-box-inner">
                                        <span>The planning of attractive and cost efficient public transport systems is a
highly complex optimization process involving many steps. Integrating
robustness from a passenger&#x27;s point of view makes the task even more
challenging. With numerous different definitions of robustness in literature, a
real-world acceptable evaluation of the robustness of a public transport system
is to simulate its performance under a large number of possible scenarios.
Unfortunately, this is computationally very expensive. In this paper, we
therefore explore a new way of such a scenario-based robustness approximation
by using methods from machine learning. We achieve a fast approach with a very
high accuracy by gathering a subset of key features of a public transport
system and its passenger demand and training an artificial neural network to
learn the outcome of a given set of robustness tests. The network is then able
to predict the robustness of untrained instances with high accuracy using only
its key features, allowing for a robustness oracle for transport planners that
approximates the robustness in constant time. Such an oracle can be used as
black box to increase the robustness within a local search framework for
integrated public transportation planning. In computational experiments with
different benchmark instances we demonstrate an excellent quality of our
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ParticleAugment: Sampling-Based Data Augmentation. (arXiv:2106.08693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsaregorodtsev_A/0/1/0/all/0/1">Alexander Tsaregorodtsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1">Vasileios Belagiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08693">
                                    <div class="article-summary-box-inner">
                                        <span>We present an automated data augmentation approach for image classification.
We formulate the problem as Monte Carlo sampling where our goal is to
approximate the optimal augmentation policies. We propose a particle filtering
formulation to find optimal augmentation policies and their schedules during
model training. Our performance measurement procedure relies on a validation
subset of our training set, while the policy transition model depends on a
Gaussian prior and an optional augmentation velocity parameter. In our
experiments, we show that our formulation for automated augmentation reaches
promising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the
standard network architectures for this problem. By comparing with the related
work, we also show that our method reaches a balance between the computational
cost of policy search and the model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Probabilistic Circuits for Nonparametric Multi-Output Regression. (arXiv:2106.08687v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhongjie Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingye Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1">Martin Trapp</a>, <a href="http://arxiv.org/find/cs/1/au:+Skryagin_A/0/1/0/all/0/1">Arseny Skryagin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08687">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by recent advances in the field of expert-based approximations of
Gaussian processes (GPs), we present an expert-based approach to large-scale
multi-output regression using single-output GP experts. Employing a deeply
structured mixture of single-output GPs encoded via a probabilistic circuit
allows us to capture correlations between multiple output dimensions
accurately. By recursively partitioning the covariate space and the output
space, posterior inference in our model reduces to inference on single-output
GP experts, which only need to be conditioned on a small subset of the
observations. We show that inference can be performed exactly and efficiently
in our model, that it can capture correlations between output dimensions and,
hence, often outperforms approaches that do not incorporate inter-output
correlations, as demonstrated on several data sets in terms of the negative log
predictive density.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maxmin-Fair Ranking: Individual Fairness under Group-Fairness Constraints. (arXiv:2106.08652v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garcia_Soriano_D/0/1/0/all/0/1">David Garcia-Soriano</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1">Francesco Bonchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08652">
                                    <div class="article-summary-box-inner">
                                        <span>We study a novel problem of fairness in ranking aimed at minimizing the
amount of individual unfairness introduced when enforcing group-fairness
constraints. Our proposal is rooted in the distributional maxmin fairness
theory, which uses randomization to maximize the expected satisfaction of the
worst-off individuals. We devise an exact polynomial-time algorithm to find
maxmin-fair distributions of general search problems (including, but not
limited to, ranking), and show that our algorithm can produce rankings which,
while satisfying the given group-fairness constraints, ensure that the maximum
possible value is brought to individuals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Learning to Select High-Quality Measurements. (arXiv:2106.08891v1 [physics.data-an])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Edmonds_A/0/1/0/all/0/1">Andrew Edmonds</a>, <a href="http://arxiv.org/find/physics/1/au:+Brown_D/0/1/0/all/0/1">David Brown</a>, <a href="http://arxiv.org/find/physics/1/au:+Vinas_L/0/1/0/all/0/1">Luciano Vinas</a>, <a href="http://arxiv.org/find/physics/1/au:+Pagan_S/0/1/0/all/0/1">Samantha Pagan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08891">
                                    <div class="article-summary-box-inner">
                                        <span>We describe the use of machine learning algorithms to select high-quality
measurements for the Mu2e experiment. This technique is important for
experiments with backgrounds that arise due to measurement errors. The
algorithms use multiple pieces of ancillary information that are sensitive to
measurement quality to separate high-quality and low-quality measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI. (arXiv:2106.08706v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pandey_L/0/1/0/all/0/1">Laxmi Pandey</a>, <a href="http://arxiv.org/find/eess/1/au:+Arif_A/0/1/0/all/0/1">Ahmed Sabbir Arif</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08706">
                                    <div class="article-summary-box-inner">
                                        <span>Speech sounds of spoken language are obtained by varying configuration of the
articulators surrounding the vocal tract. They contain abundant information
that can be utilized to better understand the underlying mechanism of human
speech production. We propose a novel deep neural network-based learning
framework that understands acoustic information in the variable-length sequence
of vocal tract shaping during speech production, captured by real-time magnetic
resonance imaging (rtMRI), and translate it into text. The proposed framework
comprises of spatiotemporal convolutions, a recurrent network, and the
connectionist temporal classification loss, trained entirely end-to-end. On the
USC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better
compared to the existing models. To the best of our knowledge, this is the
first study that demonstrates the recognition of entire spoken sentence based
on an individual&#x27;s articulatory motions captured by rtMRI video. We also
performed an analysis of variations in the geometry of articulation in each
sub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard
palate, labial constriction region) with respect to different emotions and
genders. Results suggest that each sub-regions distortion is affected by both
emotion and gender.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Accounting of Differential Privacy via Characteristic Function. (arXiv:2106.08567v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuqing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jinshuo Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Xiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08567">
                                    <div class="article-summary-box-inner">
                                        <span>Characterizing the privacy degradation over compositions, i.e., privacy
accounting, is a fundamental topic in differential privacy (DP) with many
applications to differentially private machine learning and federated learning.

We propose a unification of recent advances (Renyi DP, privacy profiles,
$f$-DP and the PLD formalism) via the characteristic function ($\phi$-function)
of a certain &#x60;&#x60;worst-case&#x27;&#x27; privacy loss random variable.

We show that our approach allows natural adaptive composition like Renyi DP,

provides exactly tight privacy accounting like PLD, and can be (often
losslessly) converted to privacy profile and $f$-DP, thus providing
$(\epsilon,\delta)$-DP guarantees and interpretable tradeoff functions.
Algorithmically, we propose an analytical Fourier accountant that represents
the complex logarithm of $\phi$-functions symbolically and uses Gaussian
quadrature for numerical computation. On several popular DP mechanisms and
their subsampled counterparts, we demonstrate the flexibility and tightness of
our approach in theory and experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence. (arXiv:2106.08710v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jacky Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1">Kit-Yung Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1">Lik-Hang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1">Pan Hui</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1">Xiang Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08710">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Augmented Reality (MAR) integrates computer-generated virtual objects
with physical environments for mobile devices. MAR systems enable users to
interact with MAR devices, such as smartphones and head-worn wearables, and
performs seamless transitions from the physical world to a mixed world with
digital entities. These MAR systems support user experiences by using MAR
devices to provide universal accessibility to digital contents. Over the past
20 years, a number of MAR systems have been developed, however, the studies and
design of MAR frameworks have not yet been systematically reviewed from the
perspective of user-centric design. This article presents the first effort of
surveying existing MAR frameworks (count: 37) and further discusses the latest
studies on MAR through a top-down approach: 1) MAR applications; 2) MAR
visualisation techniques adaptive to user mobility and contexts; 3) systematic
evaluation of MAR frameworks including supported platforms and corresponding
features such as tracking, feature extraction plus sensing capabilities; and 4)
underlying machine learning approaches supporting intelligent operations within
MAR systems. Finally, we summarise the development of emerging research fields,
current state-of-the-art, and discuss the important open challenges and
possible theoretical and technical directions. This survey aims to benefit both
researchers and MAR system developers alike.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How memory architecture affects performance and learning in simple POMDPs. (arXiv:2106.08849v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1">Mario Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Eloy_C/0/1/0/all/0/1">Christophe Eloy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1">Matthieu Wyart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08849">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning is made much more complex when the agent&#x27;s observation
is partial or noisy. This case corresponds to a partially observable Markov
decision process (POMDP). One strategy to seek good performance in POMDPs is to
endow the agent with a finite memory, whose update is governed by the policy.
However, policy optimization is non-convex in that case and can lead to poor
training performance for random initialization. The performance can be
empirically improved by constraining the memory architecture, then sacrificing
optimality to facilitate training. Here we study this trade-off in the two-arm
bandit problem, and compare two extreme cases: (i) the random access memory
where any transitions between $M$ memory states are allowed and (ii) a fixed
memory where the agent can access its last $m$ actions and rewards. For (i),
the probability $q$ to play the worst arm is known to be exponentially small in
$M$ for the optimal policy. Our main result is to show that similar performance
can be reached for (ii) as well, despite the simplicity of the memory
architecture: using a conjecture on Gray-ordered binary necklaces, we find
policies for which $q$ is exponentially small in $2^m$ i.e. $q\sim\alpha^{2^m}$
for some $\alpha &lt; 1$. Interestingly, we observe empirically that training from
random initialization leads to very poor results for (i), and significantly
better results for (ii).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2106.08571v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08571">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locality defeats the curse of dimensionality in convolutional teacher-student scenarios. (arXiv:2106.08619v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Favero_A/0/1/0/all/0/1">Alessandro Favero</a>, <a href="http://arxiv.org/find/stat/1/au:+Cagnetta_F/0/1/0/all/0/1">Francesco Cagnetta</a>, <a href="http://arxiv.org/find/stat/1/au:+Wyart_M/0/1/0/all/0/1">Matthieu Wyart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08619">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks perform a local and translationally-invariant
treatment of the data: quantifying which of these two aspects is central to
their success remains a challenge. We study this problem within a
teacher-student framework for kernel regression, using &#x60;convolutional&#x27; kernels
inspired by the neural tangent kernel of simple convolutional architectures of
given filter size. Using heuristic methods from physics, we find in the
ridgeless case that locality is key in determining the learning curve exponent
$\beta$ (that relates the test error $\epsilon_t\sim P^{-\beta}$ to the size of
the training set $P$), whereas translational invariance is not. In particular,
if the filter size of the teacher $t$ is smaller than that of the student $s$,
$\beta$ is a function of $s$ only and does not depend on the input dimension.
We confirm our predictions on $\beta$ empirically. Theoretically, in some cases
(including when teacher and student are equal) it can be shown that this
prediction is an upper bound on performance. We conclude by proving, using a
natural universality assumption, that performing kernel regression with a ridge
that decreases with the size of the training set leads to similar learning
curve exponents to those we obtain in the ridgeless case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-free Locally Accelerated Conditional Gradients. (arXiv:2102.06806v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Carderera_A/0/1/0/all/0/1">Alejandro Carderera</a>, <a href="http://arxiv.org/find/math/1/au:+Diakonikolas_J/0/1/0/all/0/1">Jelena Diakonikolas</a>, <a href="http://arxiv.org/find/math/1/au:+Lin_C/0/1/0/all/0/1">Cheuk Yin Lin</a>, <a href="http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1">Sebastian Pokutta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06806">
                                    <div class="article-summary-box-inner">
                                        <span>Projection-free conditional gradient (CG) methods are the algorithms of
choice for constrained optimization setups in which projections are often
computationally prohibitive but linear optimization over the constraint set
remains computationally feasible. Unlike in projection-based methods, globally
accelerated convergence rates are in general unattainable for CG. However, a
very recent work on Locally accelerated CG (LaCG) has demonstrated that local
acceleration for CG is possible for many settings of interest. The main
downside of LaCG is that it requires knowledge of the smoothness and strong
convexity parameters of the objective function. We remove this limitation by
introducing a novel, Parameter-Free Locally accelerated CG (PF-LaCG) algorithm,
for which we provide rigorous convergence guarantees. Our theoretical results
are complemented by numerical experiments, which demonstrate local acceleration
and showcase the practical improvements of PF-LaCG over non-accelerated
algorithms, both in terms of iteration count and wall-clock time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out-of-Scope Intent Detection with Self-Supervision and Discriminative Training. (arXiv:2106.08616v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Li-Ming Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haowen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lu Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiao-Ming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1">Albert Y.S. Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08616">
                                    <div class="article-summary-box-inner">
                                        <span>Out-of-scope intent detection is of practical importance in task-oriented
dialogue systems. Since the distribution of outlier utterances is arbitrary and
unknown in the training stage, existing methods commonly rely on strong
assumptions on data distribution such as mixture of Gaussians to make
inference, resulting in either complex multi-step training procedures or
hand-crafted rules such as confidence threshold selection for outlier
detection. In this paper, we propose a simple yet effective method to train an
out-of-scope intent classifier in a fully end-to-end manner by simulating the
test scenario in training, which requires no assumption on data distribution
and no additional post-processing or threshold setting. Specifically, we
construct a set of pseudo outliers in the training stage, by generating
synthetic outliers using inliner features via self-supervision and sampling
out-of-scope sentences from easily available open-domain datasets. The pseudo
outliers are used to train a discriminative classifier that can be directly
applied to and generalize well on the test task. We evaluate our method
extensively on four benchmark dialogue datasets and observe significant
improvements over state-of-the-art approaches. Our code has been released at
https://github.com/liam0949/DCLOOS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Gender Bias in Hindi-English Machine Translation. (arXiv:2106.08680v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1">Gauri Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1">Krithika Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sanjay Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08680">
                                    <div class="article-summary-box-inner">
                                        <span>With language models being deployed increasingly in the real world, it is
essential to address the issue of the fairness of their outputs. The word
embedding representations of these language models often implicitly draw
unwanted associations that form a social bias within the model. The nature of
gendered languages like Hindi, poses an additional problem to the
quantification and mitigation of bias, owing to the change in the form of the
words in the sentence, based on the gender of the subject. Additionally, there
is sparse work done in the realm of measuring and debiasing systems for Indic
languages. In our work, we attempt to evaluate and quantify the gender bias
within a Hindi-English machine translation system. We implement a modified
version of the existing TGBI metric based on the grammatical considerations for
Hindi. We also compare and contrast the resulting bias measurements across
multiple metrics for pre-trained embeddings and the ones learned by our machine
translation model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CODA: Constructivism Learning for Instance-Dependent Dropout Architecture Construction. (arXiv:2106.08444v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08444">
                                    <div class="article-summary-box-inner">
                                        <span>Dropout is attracting intensive research interest in deep learning as an
efficient approach to prevent overfitting. Recently incorporating structural
information when deciding which units to drop out produced promising results
comparing to methods that ignore the structural information. However, a major
issue of the existing work is that it failed to differentiate among instances
when constructing the dropout architecture. This can be a significant
deficiency for many applications. To solve this issue, we propose
Constructivism learning for instance-dependent Dropout Architecture (CODA),
which is inspired from a philosophical theory, constructivism learning.
Specially, based on the theory we have designed a better drop out technique,
Uniform Process Mixture Models, using a Bayesian nonparametric method Uniform
process. We have evaluated our proposed method on 5 real-world datasets and
compared the performance with other state-of-the-art dropout techniques. The
experimental results demonstrated the effectiveness of CODA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Directed Graph Embeddings in Pseudo-Riemannian Manifolds. (arXiv:2106.08678v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sim_A/0/1/0/all/0/1">Aaron Sim</a>, <a href="http://arxiv.org/find/stat/1/au:+Wiatrak_M/0/1/0/all/0/1">Maciej Wiatrak</a>, <a href="http://arxiv.org/find/stat/1/au:+Brayne_A/0/1/0/all/0/1">Angus Brayne</a>, <a href="http://arxiv.org/find/stat/1/au:+Creed_P/0/1/0/all/0/1">P&#xe1;id&#xed; Creed</a>, <a href="http://arxiv.org/find/stat/1/au:+Paliwal_S/0/1/0/all/0/1">Saee Paliwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08678">
                                    <div class="article-summary-box-inner">
                                        <span>The inductive biases of graph representation learning algorithms are often
encoded in the background geometry of their embedding space. In this paper, we
show that general directed graphs can be effectively represented by an
embedding model that combines three components: a pseudo-Riemannian metric
structure, a non-trivial global topology, and a unique likelihood function that
explicitly incorporates a preferred direction in embedding space. We
demonstrate the representational capabilities of this method by applying it to
the task of link prediction on a series of synthetic and real directed graphs
from natural language applications and biology. In particular, we show that
low-dimensional cylindrical Minkowski and anti-de Sitter spacetimes can produce
equal or better graph representations than curved Riemannian manifolds of
higher dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spoofing Generalization: When Can&#x27;t You Trust Proprietary Models?. (arXiv:2106.08393v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1">Elchanan Mossel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandon_C/0/1/0/all/0/1">Colin Sandon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08393">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we study the computational complexity of determining whether a
machine learning model that perfectly fits the training data will generalizes
to unseen data. In particular, we study the power of a malicious agent whose
goal is to construct a model g that fits its training data and nothing else,
but is indistinguishable from an accurate model f. We say that g strongly
spoofs f if no polynomial-time algorithm can tell them apart. If instead we
restrict to algorithms that run in $n^c$ time for some fixed $c$, we say that g
c-weakly spoofs f. Our main results are

1. Under cryptographic assumptions, strong spoofing is possible and 2. For
any c&gt; 0, c-weak spoofing is possible unconditionally

While the assumption of a malicious agent is an extreme scenario (hopefully
companies training large models are not malicious), we believe that it sheds
light on the inherent difficulties of blindly trusting large proprietary models
or data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Graphs for Explainable Classification of Brain Networks. (arXiv:2106.08640v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrate_C/0/1/0/all/0/1">Carlo Abrate</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1">Francesco Bonchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08640">
                                    <div class="article-summary-box-inner">
                                        <span>Training graph classifiers able to distinguish between healthy brains and
dysfunctional ones, can help identifying substructures associated to specific
cognitive phenotypes. However, the mere predictive power of the graph
classifier is of limited interest to the neuroscientists, which have plenty of
tools for the diagnosis of specific mental disorders. What matters is the
interpretation of the model, as it can provide novel insights and new
hypotheses.

In this paper we propose \emph{counterfactual graphs} as a way to produce
local post-hoc explanations of any black-box graph classifier. Given a graph
and a black-box, a counterfactual is a graph which, while having high
structural similarity with the original graph, is classified by the black-box
in a different class. We propose and empirically compare several strategies for
counterfactual graph search. Our experiments against a white-box classifier
with known optimal counterfactual, show that our methods, although heuristic,
can produce counterfactuals very close to the optimal one. Finally, we show how
to use counterfactual graphs to build global explanations correctly capturing
the behaviour of different black-box classifiers and providing interesting
insights for the neuroscientists.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive Modeling of Hospital Readmission: Challenges and Solutions. (arXiv:2106.08488v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuwen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingquan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08488">
                                    <div class="article-summary-box-inner">
                                        <span>Hospital readmission prediction is a study to learn models from historical
medical data to predict probability of a patient returning to hospital in a
certain period, 30 or 90 days, after the discharge. The motivation is to help
health providers deliver better treatment and post-discharge strategies, lower
the hospital readmission rate, and eventually reduce the medical costs. Due to
inherent complexity of diseases and healthcare ecosystems, modeling hospital
readmission is facing many challenges. By now, a variety of methods have been
developed, but existing literature fails to deliver a complete picture to
answer some fundamental questions, such as what are the main challenges and
solutions in modeling hospital readmission; what are typical features/models
used for readmission prediction; how to achieve meaningful and transparent
predictions for decision making; and what are possible conflicts when deploying
predictive approaches for real-world usages. In this paper, we systematically
review computational models for hospital readmission prediction, and propose a
taxonomy of challenges featuring four main categories: (1) data variety and
complexity; (2) data imbalance, locality and privacy; (3) model
interpretability; and (4) model implementation. The review summarizes methods
in each category, and highlights technical solutions proposed to address the
challenges. In addition, a review of datasets and resources available for
hospital readmission modeling also provides firsthand materials to support
researchers and practitioners to design new approaches for effective and
efficient hospital readmission prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ada-BKB: Scalable Gaussian Process Optimization on Continuous Domain by Adaptive Discretization. (arXiv:2106.08598v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rando_M/0/1/0/all/0/1">Marco Rando</a>, <a href="http://arxiv.org/find/cs/1/au:+Carratino_L/0/1/0/all/0/1">Luigi Carratino</a>, <a href="http://arxiv.org/find/cs/1/au:+Villa_S/0/1/0/all/0/1">Silvia Villa</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosasco_L/0/1/0/all/0/1">Lorenzo Rosasco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08598">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian process optimization is a successful class of algorithms (e.g.
GP-UCB) to optimize a black-box function through sequential evaluations.
However, when the domain of the function is continuous, Gaussian process
optimization has to either rely on a fixed discretization of the space, or
solve a non-convex optimization subproblem at each evaluation. The first
approach can negatively affect performance, while the second one puts a heavy
computational burden on the algorithm. A third option, that only recently has
been theoretically studied, is to adaptively discretize the function domain.
Even though this approach avoids the extra non-convex optimization costs, the
overall computational complexity is still prohibitive. An algorithm such as
GP-UCB has a runtime of $O(T^4)$, where $T$ is the number of iterations. In
this paper, we introduce Ada-BKB (Adaptive Budgeted Kernelized Bandit), a
no-regret Gaussian process optimization algorithm for functions on continuous
domains, that provably runs in $O(T^2 d_\text{eff}^2)$, where $d_\text{eff}$ is
the effective dimension of the explored space, and which is typically much
smaller than $T$. We corroborate our findings with experiments on synthetic
non-convex functions and on the real-world problem of hyper-parameter
optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WaveNet-Based Deep Neural Networks for the Characterization of Anomalous Diffusion (WADNet). (arXiv:2106.08887v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dezhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Qiujin Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zihan Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08887">
                                    <div class="article-summary-box-inner">
                                        <span>Anomalous diffusion, which shows a deviation of transport dynamics from the
framework of standard Brownian motion, is involved in the evolution of various
physical, chemical, biological, and economic systems. The study of such random
processes is of fundamental importance in unveiling the physical properties of
random walkers and complex systems. However, classical methods to characterize
anomalous diffusion are often disqualified for individual short trajectories,
leading to the launch of the Anomalous Diffusion (AnDi) Challenge. This
challenge aims at objectively assessing and comparing new approaches for single
trajectory characterization, with respect to three different aspects: the
inference of the anomalous diffusion exponent; the classification of the
diffusion model; and the segmentation of trajectories. In this article, to
address the inference and classification tasks in the challenge, we develop a
WaveNet-based deep neural network (WADNet) by combining a modified WaveNet
encoder with long short-term memory networks, without any prior knowledge of
anomalous diffusion. As the performance of our model has surpassed the current
1st places in the challenge leaderboard on both two tasks for all dimensions (6
subtasks), WADNet could be the part of state-of-the-art techniques to decode
the AnDi database. Our method presents a benchmark for future research, and
could accelerate the development of a versatile tool for the characterization
of anomalous diffusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSO: Curriculum Generation using continuous optimization. (arXiv:2106.08569v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dipankar Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Mukur Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08569">
                                    <div class="article-summary-box-inner">
                                        <span>The training of deep learning models poses vast challenges of including
parameter tuning and ordering of training data. Significant research has been
done in Curriculum learning for optimizing the sequence of training data.
Recent works have focused on using complex reinforcement learning techniques to
find the optimal data ordering strategy to maximize learning for a given
network. In this paper, we present a simple and efficient technique based on
continuous optimization. We call this new approach Training Sequence
Optimization (TSO). There are three critical components in our proposed
approach: (a) An encoder network maps/embeds training sequence into continuous
space. (b) A predictor network uses the continuous representation of a strategy
as input and predicts the accuracy for fixed network architecture. (c) A
decoder further maps a continuous representation of a strategy to the ordered
training dataset. The performance predictor and encoder enable us to perform
gradient-based optimization in the continuous space to find the embedding of
optimal training data ordering with potentially better accuracy. Experiments
show that we can gain 2AP with our generated optimal curriculum strategy over
the random strategy using the CIFAR-100 dataset and have better boosts than the
state of the art CL algorithms. We do an ablation study varying the
architecture, dataset and sample sizes showcasing our approach&#x27;s robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-PSD Matrix Sketching with Applications to Regression and Optimization. (arXiv:2106.08544v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhili Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Roosta_F/0/1/0/all/0/1">Fred Roosta</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08544">
                                    <div class="article-summary-box-inner">
                                        <span>A variety of dimensionality reduction techniques have been applied for
computations involving large matrices. The underlying matrix is randomly
compressed into a smaller one, while approximately retaining many of its
original properties. As a result, much of the expensive computation can be
performed on the small matrix. The sketching of positive semidefinite (PSD)
matrices is well understood, but there are many applications where the related
matrices are not PSD, including Hessian matrices in non-convex optimization and
covariance matrices in regression applications involving complex numbers. In
this paper, we present novel dimensionality reduction methods for non-PSD
matrices, as well as their &#x60;&#x60;square-roots&quot;, which involve matrices with complex
entries. We show how these techniques can be used for multiple downstream
tasks. In particular, we show how to use the proposed matrix sketching
techniques for both convex and non-convex optimization, $\ell_p$-regression for
every $1 \leq p \leq \infty$, and vector-matrix-vector queries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dataset Dynamics via Gradient Flows in Probability Space. (arXiv:2010.12760v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alvarez_Melis_D/0/1/0/all/0/1">David Alvarez-Melis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusi_N/0/1/0/all/0/1">Nicol&#xf2; Fusi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12760">
                                    <div class="article-summary-box-inner">
                                        <span>Various machine learning tasks, from generative modeling to domain
adaptation, revolve around the concept of dataset transformation and
manipulation. While various methods exist for transforming unlabeled datasets,
principled methods to do so for labeled (e.g., classification) datasets are
missing. In this work, we propose a novel framework for dataset transformation,
which we cast as optimization over data-generating joint probability
distributions. We approach this class of problems through Wasserstein gradient
flows in probability space, and derive practical and efficient particle-based
methods for a flexible but well-behaved class of objective functions. Through
various experiments, we show that this framework can be used to impose
constraints on classification datasets, adapt them for transfer learning, or to
re-purpose fixed or black-box models to classify ---with high accuracy---
previously unseen datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic DAG Search. (arXiv:2106.08717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grosse_J/0/1/0/all/0/1">Julia Grosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08717">
                                    <div class="article-summary-box-inner">
                                        <span>Exciting contemporary machine learning problems have recently been phrased in
the classic formalism of tree search -- most famously, the game of Go.
Interestingly, the state-space underlying these sequential decision-making
problems often posses a more general latent structure than can be captured by a
tree. In this work, we develop a probabilistic framework to exploit a search
space&#x27;s latent structure and thereby share information across the search tree.
The method is based on a combination of approximate inference in jointly
Gaussian models for the explored part of the problem, and an abstraction for
the unexplored part that imposes a reduction of complexity ad hoc. We
empirically find our algorithm to compare favorably to existing
non-probabilistic alternatives in Tic-Tac-Toe and a feature selection
application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Raise or Not To Raise: The Autonomous Learning Rate Question. (arXiv:2106.08767v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaomeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1">Michael Potter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yun-Chan Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gaurav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1">V. Ratna Saripalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08767">
                                    <div class="article-summary-box-inner">
                                        <span>There is a parameter ubiquitous throughout the deep learning world: learning
rate. There is likewise a ubiquitous question: what should that learning rate
be? The true answer to this question is often tedious and time consuming to
obtain, and a great deal of arcane knowledge has accumulated in recent years
over how to pick and modify learning rates to achieve optimal training
performance. Moreover, the long hours spent carefully crafting the perfect
learning rate can come to nothing the moment your network architecture,
optimizer, dataset, or initial conditions change ever so slightly. But it need
not be this way. We propose a new answer to the great learning rate question:
the Autonomous Learning Rate Controller. Find it at
https://github.com/fastestimator/ARC</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ModelDiff: Testing-Based DNN Similarity Comparison for Model Reuse Detection. (arXiv:2106.08890v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanchun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bingyan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziyue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunxin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08890">
                                    <div class="article-summary-box-inner">
                                        <span>The knowledge of a deep learning model may be transferred to a student model,
leading to intellectual property infringement or vulnerability propagation.
Detecting such knowledge reuse is nontrivial because the suspect models may not
be white-box accessible and/or may serve different tasks. In this paper, we
propose ModelDiff, a testing-based approach to deep learning model similarity
comparison. Instead of directly comparing the weights, activations, or outputs
of two models, we compare their behavioral patterns on the same set of test
inputs. Specifically, the behavioral pattern of a model is represented as a
decision distance vector (DDV), in which each element is the distance between
the model&#x27;s reactions to a pair of inputs. The knowledge similarity between two
models is measured with the cosine similarity between their DDVs. To evaluate
ModelDiff, we created a benchmark that contains 144 pairs of models that cover
most popular model reuse methods, including transfer learning, model
compression, and model stealing. Our method achieved 91.7% correctness on the
benchmark, which demonstrates the effectiveness of using ModelDiff for model
reuse detection. A study on mobile deep learning apps has shown the feasibility
of ModelDiff on real-world models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SEEN: Sharpening Explanations for Graph Neural Networks using Explanations from Neighborhoods. (arXiv:2106.08532v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hyeoncheol Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Youngrock Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1">Eunjoo Jeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08532">
                                    <div class="article-summary-box-inner">
                                        <span>Explaining the foundations for predictions obtained from graph neural
networks (GNNs) is critical for credible use of GNN models for real-world
problems. Owing to the rapid growth of GNN applications, recent progress in
explaining predictions from GNNs, such as sensitivity analysis, perturbation
methods, and attribution methods, showed great opportunities and possibilities
for explaining GNN predictions. In this study, we propose a method to improve
the explanation quality of node classification tasks that can be applied in a
post hoc manner through aggregation of auxiliary explanations from important
neighboring nodes, named SEEN. Applying SEEN does not require modification of a
graph and can be used with diverse explainability techniques due to its
independent mechanism. Experiments on matching motif-participating nodes from a
given graph show great improvement in explanation accuracy of up to 12.71% and
demonstrate the correlation between the auxiliary explanations and the enhanced
explanation accuracy through leveraging their contributions. SEEN provides a
simple but effective method to enhance the explanation quality of GNN model
outputs, and this method is applicable in combination with most explainability
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Achieving Domain Robustness in Stereo Matching Networks by Removing Shortcut Learning. (arXiv:2106.08486v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chuah_W/0/1/0/all/0/1">WeiQin Chuah</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennakoon_R/0/1/0/all/0/1">Ruwan Tennakoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bab_Hadiashar_A/0/1/0/all/0/1">Alireza Bab-Hadiashar</a>, <a href="http://arxiv.org/find/cs/1/au:+Suter_D/0/1/0/all/0/1">David Suter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08486">
                                    <div class="article-summary-box-inner">
                                        <span>Learning-based stereo matching and depth estimation networks currently excel
on public benchmarks with impressive results. However, state-of-the-art
networks often fail to generalize from synthetic imagery to more challenging
real data domains. This paper is an attempt to uncover hidden secrets of
achieving domain robustness and in particular, discovering the important
ingredients of generalization success of stereo matching networks by analyzing
the effect of synthetic image learning on real data performance. We provide
evidence that demonstrates that learning of features in the synthetic domain by
a stereo matching network is heavily influenced by two &quot;shortcuts&quot; presented in
the synthetic data: (1) identical local statistics (RGB colour features)
between matching pixels in the synthetic stereo images and (2) lack of realism
in synthetic textures on 3D objects simulated in game engines. We will show
that by removing such shortcuts, we can achieve domain robustness in the
state-of-the-art stereo matching frameworks and produce a remarkable
performance on multiple realistic datasets, despite the fact that the networks
were trained on synthetic data, only. Our experimental results point to the
fact that eliminating shortcuts from the synthetic data is key to achieve
domain-invariant generalization between synthetic and real data domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memorization and Generalization in Neural Code Intelligence Models. (arXiv:2106.08704v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rabin_M/0/1/0/all/0/1">Md Rafiqul Islam Rabin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1">Aftab Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellendoorn_V/0/1/0/all/0/1">Vincent J. Hellendoorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Alipour_M/0/1/0/all/0/1">Mohammad Amin Alipour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08704">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNN) are increasingly commonly used in software
engineering and code intelligence tasks. These are powerful tools that are
capable of learning highly generalizable patterns from large datasets through
millions of parameters. At the same time, training DNNs means walking a knife&#x27;s
edges, because their large capacity also renders them prone to memorizing data
points. While traditionally thought of as an aspect of over-training, recent
work suggests that the memorization risk manifests especially strongly when the
training datasets are noisy and memorization is the only recourse.
Unfortunately, most code intelligence tasks rely on rather noise-prone and
repetitive data sources, such as GitHub, which, due to their sheer size, cannot
be manually inspected and evaluated. We evaluate the memorization and
generalization tendencies in neural code intelligence models through a case
study across several benchmarks and model families by leveraging established
approaches from other fields that use DNNs, such as introducing targeted noise
into the training dataset. In addition to reinforcing prior general findings
about the extent of memorization in DNNs, our results shed light on the impact
of noisy dataset in training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-shot Neural Architecture Search. (arXiv:2006.06863v8 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiyang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linnan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_R/0/1/0/all/0/1">Rodrigo Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1">Tian Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06863">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient evaluation of a network architecture drawn from a large search
space remains a key challenge in Neural Architecture Search (NAS). Vanilla NAS
evaluates each architecture by training from scratch, which gives the true
performance but is extremely time-consuming. Recently, one-shot NAS
substantially reduces the computation cost by training only one supernetwork,
a.k.a. supernet, to approximate the performance of every architecture in the
search space via weight-sharing. However, the performance estimation can be
very inaccurate due to the co-adaption among operations. In this paper, we
propose few-shot NAS that uses multiple supernetworks, called sub-supernet,
each covering different regions of the search space to alleviate the undesired
co-adaption. Compared to one-shot NAS, few-shot NAS improves the accuracy of
architecture evaluation with a small increase of evaluation cost. With only up
to 7 sub-supernets, few-shot NAS establishes new SoTAs: on ImageNet, it finds
models that reach 80.5% top-1 accuracy at 600 MB FLOPS and 77.5% top-1 accuracy
at 238 MFLOPS; on CIFAR10, it reaches 98.72% top-1 accuracy without using extra
data or transfer learning. In Auto-GAN, few-shot NAS outperforms the previously
published results by up to 20%. Extensive experiments show that few-shot NAS
significantly improves various one-shot methods, including 4 gradient-based and
6 search-based methods on 3 different tasks in NasBench-201 and
NasBench1-shot-1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Device-Cloud Collaborative Learning for Recommendation. (arXiv:2104.06624v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiangchao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">KunYang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06624">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of storage and computing power on mobile devices,
it becomes critical and popular to deploy models on devices to save onerous
communication latencies and to capture real-time features. While quite a lot of
works have explored to facilitate on-device learning and inference, most of
them focus on dealing with response delay or privacy protection. Little has
been done to model the collaboration between the device and the cloud modeling
and benefit both sides jointly. To bridge this gap, we are among the first
attempts to study the Device-Cloud Collaborative Learning (DCCL) framework.
Specifically, we propose a novel MetaPatch learning approach on the device side
to efficiently achieve &quot;thousands of people with thousands of models&quot; given a
centralized cloud model. Then, with billions of updated personalized device
models, we propose a &quot;model-over-models&quot; distillation algorithm, namely
MoMoDistill, to update the centralized cloud model. Our extensive experiments
over a range of datasets with different settings demonstrate the effectiveness
of such collaboration on both cloud and devices, especially its superiority to
model long-tailed users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Inference in medicine and in health policy, a summary. (arXiv:2105.04655v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramezani_R/0/1/0/all/0/1">Ramin Ramezani</a>, <a href="http://arxiv.org/find/cs/1/au:+Naeim_A/0/1/0/all/0/1">Arash Naeim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04655">
                                    <div class="article-summary-box-inner">
                                        <span>A data science task can be deemed as making sense of the data or testing a
hypothesis about it. The conclusions inferred from data can greatly guide us to
make informative decisions. Big data has enabled us to carry out countless
prediction tasks in conjunction with machine learning, such as identifying high
risk patients suffering from a certain disease and taking preventable measures.
However, healthcare practitioners are not content with mere predictions - they
are also interested in the cause-effect relation between input features and
clinical outcomes. Understanding such relations will help doctors treat
patients and reduce the risk effectively. Causality is typically identified by
randomized controlled trials. Often such trials are not feasible when
scientists and researchers turn to observational studies and attempt to draw
inferences. However, observational studies may also be affected by selection
and/or confounding biases that can result in wrong causal conclusions. In this
chapter, we will try to highlight some of the drawbacks that may arise in
traditional machine learning and statistical approaches to analyze the
observational data, particularly in the healthcare data analytics domain. We
will discuss causal inference and ways to discover the cause-effect from
observational studies in healthcare domain. Moreover, we will demonstrate the
applications of causal inference in tackling some common machine learning
issues such as missing data and model transportability. Finally, we will
discuss the possibility of integrating reinforcement learning with causality as
a way to counter confounding bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds. (arXiv:2007.07978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nielsen_A/0/1/0/all/0/1">A. H. Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">A. Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Karstoft_H/0/1/0/all/0/1">H. Karstoft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07978">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the formation and development of clouds is a central element of
modern weather forecasting systems. Incorrect clouds forecasts can lead to
major uncertainty in the overall accuracy of weather forecasts due to their
intrinsic role in the Earth&#x27;s climate system. Few studies have tackled this
challenging problem from a machine learning point-of-view due to a shortage of
high-resolution datasets with many historical observations globally. In this
paper, we present a novel satellite-based dataset called &#x60;&#x60;CloudCast&#x27;&#x27;. It
consists of 70,080 images with 10 different cloud types for multiple layers of
the atmosphere annotated on a pixel level. The spatial resolution of the
dataset is 928 x 1530 pixels (3x3 km per pixel) with 15-min intervals between
frames for the period 2017-01-01 to 2018-12-31. All frames are centered and
projected over Europe. To supplement the dataset, we conduct an evaluation
study with current state-of-the-art video prediction methods such as
convolutional long short-term memory networks, generative adversarial networks,
and optical flow-based extrapolation methods. As the evaluation of video
prediction is difficult in practice, we aim for a thorough evaluation in the
spatial and temporal domain. Our benchmark models show promising results but
with ample room for improvement. This is the first publicly available
global-scale dataset with high-resolution cloud types on a high temporal
granularity to the authors&#x27; best knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate. (arXiv:2106.09019v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xingyuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1">Tianju Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Rusinkiewicz_S/0/1/0/all/0/1">Szymon M. Rusinkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_R/0/1/0/all/0/1">Ryan P. Adams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09019">
                                    <div class="article-summary-box-inner">
                                        <span>In design, fabrication, and control problems, we are often faced with the
task of synthesis, in which we must generate an object or configuration that
satisfies a set of constraints while maximizing one or more objective
functions. The synthesis problem is typically characterized by a physical
process in which many different realizations may achieve the goal. This
many-to-one map presents challenges to the supervised learning of feed-forward
synthesis, as the set of viable designs may have a complex structure. In
addition, the non-differentiable nature of many physical simulations prevents
direct optimization. We address both of these problems with a two-stage neural
network architecture that we may consider to be an autoencoder. We first learn
the decoder: a differentiable surrogate that approximates the many-to-one
physical realization process. We then learn the encoder, which maps from goal
to design, while using the fixed decoder to evaluate the quality of the
realization. We evaluate the approach on two case studies: extruder path
planning in additive manufacturing and constrained soft robot inverse
kinematics. We compare our approach to direct optimization of design using the
learned surrogate, and to supervised learning of the synthesis problem. We find
that our approach produces higher quality solutions than supervised learning,
while being competitive in quality with direct optimization, at a greatly
reduced computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TabularNet: A Neural Network Architecture for Understanding Semantic Structures of Tabular Data. (arXiv:2106.03096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1">Lun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Fei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ran Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junshan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03096">
                                    <div class="article-summary-box-inner">
                                        <span>Tabular data are ubiquitous for the widespread applications of tables and
hence have attracted the attention of researchers to extract underlying
information. One of the critical problems in mining tabular data is how to
understand their inherent semantic structures automatically. Existing studies
typically adopt Convolutional Neural Network (CNN) to model the spatial
information of tabular structures yet ignore more diverse relational
information between cells, such as the hierarchical and paratactic
relationships. To simultaneously extract spatial and relational information
from tables, we propose a novel neural network architecture, TabularNet. The
spatial encoder of TabularNet utilizes the row/column-level Pooling and the
Bidirectional Gated Recurrent Unit (Bi-GRU) to capture statistical information
and local positional correlation, respectively. For relational information, we
design a new graph construction method based on the WordNet tree and adopt a
Graph Convolutional Network (GCN) based encoder that focuses on the
hierarchical and paratactic relationships between cells. Our neural network
architecture can be a unified neural backbone for different understanding tasks
and utilized in a multitask scenario. We conduct extensive experiments on three
classification tasks with two real-world spreadsheet data sets, and the results
demonstrate the effectiveness of our proposed TabularNet over state-of-the-art
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Learning and Personalization in Multi-Agent Stochastic Linear Bandits. (arXiv:2106.08902v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1">Avishek Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1">Abishek Sankararaman</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08902">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of minimizing regret in an $N$ agent heterogeneous
stochastic linear bandits framework, where the agents (users) are similar but
not all identical. We model user heterogeneity using two popularly used ideas
in practice; (i) A clustering framework where users are partitioned into groups
with users in the same group being identical to each other, but different
across groups, and (ii) a personalization framework where no two users are
necessarily identical, but a user&#x27;s parameters are close to that of the
population average. In the clustered users&#x27; setup, we propose a novel
algorithm, based on successive refinement of cluster identities and regret
minimization. We show that, for any agent, the regret scales as
$\mathcal{O}(\sqrt{T/N})$, if the agent is in a &#x60;well separated&#x27; cluster, or
scales as $\mathcal{O}(T^{\frac{1}{2} + \varepsilon}/(N)^{\frac{1}{2}
-\varepsilon})$ if its cluster is not well separated, where $\varepsilon$ is
positive and arbitrarily close to $0$. Our algorithm is adaptive to the cluster
separation, and is parameter free -- it does not need to know the number of
clusters, separation and cluster size, yet the regret guarantee adapts to the
inherent complexity. In the personalization framework, we introduce a natural
algorithm where, the personal bandit instances are initialized with the
estimates of the global average model. We show that, an agent $i$ whose
parameter deviates from the population average by $\epsilon_i$, attains a
regret scaling of $\widetilde{O}(\epsilon_i\sqrt{T})$. This demonstrates that
if the user representations are close (small $\epsilon_i)$, the resulting
regret is low, and vice-versa. The results are empirically validated and we
observe superior performance of our adaptive algorithms over non-adaptive
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Eigen Analysis of Self-Attention and its Reconstruction from Partial Computation. (arXiv:2106.08823v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1">Srinadh Bhojanapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_H/0/1/0/all/0/1">Himanshu Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1">Michal Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1">Andreas Veit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08823">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art transformer models use pairwise dot-product based
self-attention, which comes at a computational cost quadratic in the input
sequence length. In this paper, we investigate the global structure of
attention scores computed using this dot product mechanism on a typical
distribution of inputs, and study the principal components of their variation.
Through eigen analysis of full attention score matrices, as well as of their
individual rows, we find that most of the variation among attention scores lie
in a low-dimensional eigenspace. Moreover, we find significant overlap between
these eigenspaces for different layers and even different transformer models.
Based on this, we propose to compute scores only for a partial subset of token
pairs, and use them to estimate scores for the remaining pairs. Beyond
investigating the accuracy of reconstructing attention scores themselves, we
investigate training transformer models that employ these approximations, and
analyze the effect on overall accuracy. Our analysis and the proposed method
provide insights into how to balance the benefits of exact pair-wise attention
and its significant computational expense.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaze Preserving CycleGANs for Eyeglass Removal &amp; Persistent Gaze Estimation. (arXiv:2002.02077v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1">Akshay Rangesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bowen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1">Mohan M. Trivedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02077">
                                    <div class="article-summary-box-inner">
                                        <span>A driver&#x27;s gaze is critical for determining their attention, state,
situational awareness, and readiness to take over control from partially
automated vehicles. Estimating the gaze direction is the most obvious way to
gauge a driver&#x27;s state under ideal conditions when limited to using
non-intrusive imaging sensors. Unfortunately, the vehicular environment
introduces a variety of challenges that are usually unaccounted for - harsh
illumination, nighttime conditions, and reflective eyeglasses. Relying on head
pose alone under such conditions can prove to be unreliable and erroneous. In
this study, we offer solutions to address these problems encountered in the
real world. To solve issues with lighting, we demonstrate that using an
infrared camera with suitable equalization and normalization suffices. To
handle eyeglasses and their corresponding artifacts, we adopt image-to-image
translation using generative adversarial networks to pre-process images prior
to gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is
trained to preserve the driver&#x27;s gaze while removing potential eyeglasses from
face images. GPCycleGAN is based on the well-known CycleGAN approach - with the
addition of a gaze classifier and a gaze consistency loss for additional
supervision. Our approach exhibits improved performance, interpretability,
robustness and superior qualitative results on challenging real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing the Impact: Does an Improvement to a Revenue Management System Lead to an Improved Revenue?. (arXiv:2101.10249v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laage_G/0/1/0/all/0/1">Greta Laage</a>, <a href="http://arxiv.org/find/cs/1/au:+Frejinger_E/0/1/0/all/0/1">Emma Frejinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1">Andrea Lodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1">Guillaume Rabusseau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10249">
                                    <div class="article-summary-box-inner">
                                        <span>Airlines and other industries have been making use of sophisticated Revenue
Management Systems to maximize revenue for decades. While improving the
different components of these systems has been the focus of numerous studies,
estimating the impact of such improvements on the revenue has been overlooked
in the literature despite its practical importance. Indeed, quantifying the
benefit of a change in a system serves as support for investment decisions.
This is a challenging problem as it corresponds to the difference between the
generated value and the value that would have been generated keeping the system
as before. The latter is not observable. Moreover, the expected impact can be
small in relative value. In this paper, we cast the problem as counterfactual
prediction of unobserved revenue. The impact on revenue is then the difference
between the observed and the estimated revenue. The originality of this work
lies in the innovative application of econometric methods proposed for
macroeconomic applications to a new problem setting. Broadly applicable, the
approach benefits from only requiring revenue data observed for
origin-destination pairs in the network of the airline at each day, before and
after a change in the system is applied. We report results using real
large-scale data from Air Canada. We compare a deep neural network
counterfactual predictions model with econometric models. They achieve
respectively 1% and 1.1% of error on the counterfactual revenue predictions,
and allow to accurately estimate small impacts (in the order of 2%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline RL Without Off-Policy Evaluation. (arXiv:2106.08909v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandfonbrener_D/0/1/0/all/0/1">David Brandfonbrener</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1">William F. Whitney</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1">Rajesh Ranganath</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08909">
                                    <div class="article-summary-box-inner">
                                        <span>Most prior approaches to offline reinforcement learning (RL) have taken an
iterative actor-critic approach involving off-policy evaluation. In this paper
we show that simply doing one step of constrained/regularized policy
improvement using an on-policy Q estimate of the behavior policy performs
surprisingly well. This one-step algorithm beats the previously reported
results of iterative algorithms on a large portion of the D4RL benchmark. The
simple one-step baseline achieves this strong performance without many of the
tricks used by previously proposed iterative algorithms and is more robust to
hyperparameters. We argue that the relatively poor performance of iterative
approaches is a result of the high variance inherent in doing off-policy
evaluation and magnified by the repeated optimization of policies against those
high-variance estimates. In addition, we hypothesize that the strong
performance of the one-step algorithm is due to a combination of favorable
structure in the environment and behavior policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep-learning based Tools for Automated Protocol Definition of Advanced Diagnostic Imaging Exams. (arXiv:2106.08963v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nencka_A/0/1/0/all/0/1">Andrew S. Nencka</a>, <a href="http://arxiv.org/find/cs/1/au:+Sherafati_M/0/1/0/all/0/1">Mohammad Sherafati</a>, <a href="http://arxiv.org/find/cs/1/au:+Goebel_T/0/1/0/all/0/1">Timothy Goebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolat_P/0/1/0/all/0/1">Parag Tolat</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_K/0/1/0/all/0/1">Kevin M. Koch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08963">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: This study evaluates the effectiveness and impact of automated
order-based protocol assignment for magnetic resonance imaging (MRI) exams
using natural language processing (NLP) and deep learning (DL).

Methods: NLP tools were applied to retrospectively process orders from over
116,000 MRI exams with 200 unique sub-specialized protocols (&quot;Local&quot; protocol
class). Separate DL models were trained on 70\% of the processed data for
&quot;Local&quot; protocols as well as 93 American College of Radiology (&quot;ACR&quot;) protocols
and 48 &quot;General&quot; protocols. The DL Models were assessed in an &quot;auto-protocoling
(AP)&quot; inference mode which returns the top recommendation and in a &quot;clinical
decision support (CDS)&quot; inference mode which returns up to 10 protocols for
radiologist review. The accuracy of each protocol recommendation was computed
and analyzed based on the difference between the normalized output score of the
corresponding neural net for the top two recommendations.

Results: The top predicted protocol in AP mode was correct for 82.8%, 73.8%,
and 69.3% of the test cases for &quot;General&quot;, &quot;ACR&quot;, and &quot;Local&quot; protocol classes,
respectively. Higher levels of accuracy over 96% were obtained for all protocol
classes in CDS mode. However, at current validation performance levels, the
proposed models offer modest, positive, financial impact on large-scale imaging
networks.

Conclusions: DL-based protocol automation is feasible and can be tuned to
route substantial fractions of exams for auto-protocoling, with higher accuracy
with more general protocols. Economic analyses of the tested algorithms
indicate that improved algorithm performance is required to yield a practical
exam auto-protocoling tool for sub-specialized imaging exams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LemgoRL: An open-source Benchmark Tool to Train Reinforcement Learning Agents for Traffic Signal Control in a real-world simulation scenario. (arXiv:2103.16223v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_A/0/1/0/all/0/1">Arthur M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Rangras_V/0/1/0/all/0/1">Vishal Rangras</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnittker_G/0/1/0/all/0/1">Georg Schnittker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waldmann_M/0/1/0/all/0/1">Michael Waldmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Friesen_M/0/1/0/all/0/1">Maxim Friesen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferfers_T/0/1/0/all/0/1">Tobias Ferfers</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreckenberg_L/0/1/0/all/0/1">Lukas Schreckenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Hufen_F/0/1/0/all/0/1">Florian Hufen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jasperneite_J/0/1/0/all/0/1">J&#xfc;rgen Jasperneite</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiering_M/0/1/0/all/0/1">Marco Wiering</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16223">
                                    <div class="article-summary-box-inner">
                                        <span>Sub-optimal control policies in intersection traffic signal controllers (TSC)
contribute to congestion and lead to negative effects on human health and the
environment. Reinforcement learning (RL) for traffic signal control is a
promising approach to design better control policies and has attracted
considerable research interest in recent years. However, most work done in this
area used simplified simulation environments of traffic scenarios to train
RL-based TSC. To deploy RL in real-world traffic systems, the gap between
simplified simulation environments and real-world applications has to be
closed. Therefore, we propose LemgoRL, a benchmark tool to train RL agents as
TSC in a realistic simulation environment of Lemgo, a medium-sized town in
Germany. In addition to the realistic simulation model, LemgoRL encompasses a
traffic signal logic unit that ensures compliance with all regulatory and
safety requirements. LemgoRL offers the same interface as the well-known OpenAI
gym toolkit to enable easy deployment in existing research work. Our benchmark
tool drives the development of RL algorithms towards real-world applications.
We provide LemgoRL as an open-source tool at https://github.com/rl-ina/lemgorl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of Outlier Detection Techniques for Structured Data. (arXiv:2106.08779v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Amulya Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nitin Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08779">
                                    <div class="article-summary-box-inner">
                                        <span>An outlier is an observation or a data point that is far from rest of the
data points in a given dataset or we can be said that an outlier is away from
the center of mass of observations. Presence of outliers can skew statistical
measures and data distributions which can lead to misleading representation of
the underlying data and relationships. It is seen that the removal of outliers
from the training dataset before modeling can give better predictions. With the
advancement of machine learning, the outlier detection models are also
advancing at a good pace. The goal of this work is to highlight and compare
some of the existing outlier detection techniques for the data scientists to
use that information for outlier algorithm selection while building a machine
learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilinear Dirichlet Processes. (arXiv:2106.08852v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08852">
                                    <div class="article-summary-box-inner">
                                        <span>Dependent Dirichlet processes (DDP) have been widely applied to model data
from distributions over collections of measures which are correlated in some
way. On the other hand, in recent years, increasing research efforts in machine
learning and data mining have been dedicated to dealing with data involving
interactions from two or more factors. However, few researchers have addressed
the heterogeneous relationship in data brought by modulation of multiple
factors using techniques of DDP. In this paper, we propose a novel technique,
MultiLinear Dirichlet Processes (MLDP), to constructing DDPs by combining DP
with a state-of-the-art factor analysis technique, multilinear factor analyzers
(MLFA). We have evaluated MLDP on real-word data sets for different
applications and have achieved state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early fault detection with multi-target neural networks. (arXiv:2106.08957v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meyer_A/0/1/0/all/0/1">Angela Meyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08957">
                                    <div class="article-summary-box-inner">
                                        <span>Wind power is seeing a strong growth around the world. At the same time,
shrinking profit margins in the energy markets let wind farm managers explore
options for cost reductions in the turbine operation and maintenance.
Sensor-based condition monitoring facilitates remote diagnostics of turbine
subsystems, enabling faster responses when unforeseen maintenance is required.
Condition monitoring with data from the turbines&#x27; supervisory control and data
acquisition (SCADA) systems was proposed and SCADA-based fault detection and
diagnosis approaches introduced based on single-task normal operation models of
turbine state variables. As the number of SCADA channels has grown strongly,
thousands of independent single-target models are in place today for monitoring
a single turbine. Multi-target learning was recently proposed to limit the
number of models. This study applied multi-target neural networks to the task
of early fault detection in drive-train components. The accuracy and delay of
detecting gear bearing faults were compared to state-of-the-art single-target
approaches. We found that multi-target multi-layer perceptrons (MLPs) detected
faults at least as early and in many cases earlier than single-target MLPs. The
multi-target MLPs could detect faults up to several days earlier than the
single-target models. This can deliver a significant advantage in the planning
and performance of maintenance work. At the same time, the multi-target MLPs
achieved the same level of prediction stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">mSHAP: SHAP Values for Two-Part Models. (arXiv:2106.08990v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Matthews_S/0/1/0/all/0/1">Spencer Matthews</a>, <a href="http://arxiv.org/find/stat/1/au:+Hartman_B/0/1/0/all/0/1">Brian Hartman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08990">
                                    <div class="article-summary-box-inner">
                                        <span>Two-part models are important to and used throughout insurance and actuarial
science. Since insurance is required for registering a car, obtaining a
mortgage, and participating in certain businesses, it is especially important
that the models which price insurance policies are fair and non-discriminatory.
Black box models can make it very difficult to know which covariates are
influencing the results. SHAP values enable interpretation of various black box
models, but little progress has been made in two-part models. In this paper, we
propose mSHAP (or multiplicative SHAP), a method for computing SHAP values of
two-part models using the SHAP values of the individual models. This method
will allow for the predictions of two-part models to be explained at an
individual observation level. After developing mSHAP, we perform an in-depth
simulation study. Although the kernelSHAP algorithm is also capable of
computing approximate SHAP values for a two-part model, a comparison with our
method demonstrates that mSHAP is exponentially faster. Ultimately, we apply
mSHAP to a two-part ratemaking model for personal auto property damage
insurance coverage. Additionally, an R package (mshap) is available to easily
implement the method in a wide variety of applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Image Compositions for Feature Representation Learning. (arXiv:2106.09011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cascante_Bonilla_P/0/1/0/all/0/1">Paola Cascante-Bonilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1">Arshdeep Sekhon</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yanjun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1">Vicente Ordonez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09011">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks for visual recognition require large amounts of
training samples and usually benefit from data augmentation. This paper
proposes PatchMix, a data augmentation method that creates new samples by
composing patches from pairs of images in a grid-like pattern. These new
samples&#x27; ground truth labels are set as proportional to the number of patches
from each image. We then add a set of additional losses at the patch-level to
regularize and to encourage good representations at both the patch and image
levels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior
transfer learning capabilities across a wide array of benchmarks. Although
PatchMix can rely on random pairings and random grid-like patterns for mixing,
we explore evolutionary search as a guiding strategy to discover optimal
grid-like patterns and image pairing jointly. For this purpose, we conceive a
fitness function that bypasses the need to re-train a model to evaluate each
choice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),
CIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant
margins, also outperforming previous state-of-the-art pairwise augmentation
strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Voice and Biofeedback to Predict User Engagement during Requirements Interviews. (arXiv:2104.02410v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferrari_A/0/1/0/all/0/1">Alessio Ferrari</a>, <a href="http://arxiv.org/find/cs/1/au:+Huichapa_T/0/1/0/all/0/1">Thaide Huichapa</a>, <a href="http://arxiv.org/find/cs/1/au:+Spoletini_P/0/1/0/all/0/1">Paola Spoletini</a>, <a href="http://arxiv.org/find/cs/1/au:+Novielli_N/0/1/0/all/0/1">Nicole Novielli</a>, <a href="http://arxiv.org/find/cs/1/au:+Fucci_D/0/1/0/all/0/1">Davide Fucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Girardi_D/0/1/0/all/0/1">Daniela Girardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02410">
                                    <div class="article-summary-box-inner">
                                        <span>Capturing users engagement is crucial for gathering feedback about the
features of a software product. In a market-driven context, current approaches
to collect and analyze users feedback are based on techniques leveraging
information extracted from product reviews and social media. These approaches
are hardly applicable in bespoke software development, or in contexts in which
one needs to gather information from specific users. In such cases, companies
need to resort to face-to-face interviews to get feedback on their products. In
this paper, we propose to utilize biometric data, in terms of physiological and
voice features, to complement interviews with information about the engagement
of the user on the discussed product-relevant topics. We evaluate our approach
by interviewing users while gathering their physiological data (i.e.,
biofeedback) using an Empatica E4 wristband, and capturing their voice through
the default audio-recorder of a common laptop. Our results show that we can
predict users&#x27; engagement by training supervised machine learning algorithms on
biometric data, and that voice features alone can be sufficiently effective.
The performance of the prediction algorithms is maximised when pre-processing
the training data with the synthetic minority oversampling technique (SMOTE).
The results of our work suggest that biofeedback and voice analysis can be used
to facilitate prioritization of requirements oriented to product improvement,
and to steer the interview based on users&#x27; engagement. Furthermore, the usage
of voice features can be particularly helpful for emotion-aware requirements
elicitation in remote communication, either performed by human analysts or
voice-based chatbots.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Voicy: Zero-Shot Non-Parallel Voice Conversion in Noisy Reverberant Environments. (arXiv:2106.08873v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mottini_A/0/1/0/all/0/1">Alejandro Mottini</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorenzo_Trueba_J/0/1/0/all/0/1">Jaime Lorenzo-Trueba</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlapati_S/0/1/0/all/0/1">Sri Vishnu Kumar Karlapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Drugman_T/0/1/0/all/0/1">Thomas Drugman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08873">
                                    <div class="article-summary-box-inner">
                                        <span>Voice Conversion (VC) is a technique that aims to transform the
non-linguistic information of a source utterance to change the perceived
identity of the speaker. While there is a rich literature on VC, most proposed
methods are trained and evaluated on clean speech recordings. However, many
acoustic environments are noisy and reverberant, severely restricting the
applicability of popular VC methods to such scenarios. To address this
limitation, we propose Voicy, a new VC framework particularly tailored for
noisy speech. Our method, which is inspired by the de-noising auto-encoders
framework, is comprised of four encoders (speaker, content, phonetic and
acoustic-ASR) and one decoder. Importantly, Voicy is capable of performing
non-parallel zero-shot VC, an important requirement for any VC system that
needs to work on speakers not seen during training. We have validated our
approach using a noisy reverberant version of the LibriSpeech dataset.
Experimental results show that Voicy outperforms other tested VC techniques in
terms of naturalness and target speaker similarity in noisy reverberant
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System. (arXiv:2106.08801v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhiyuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08801">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) alignment aims at finding equivalent entities and
relations (i.e., mappings) between two KGs. The existing approaches utilize
either reasoning-based or semantic embedding-based techniques, but few studies
explore their combination. In this demonstration, we present PRASEMap, an
unsupervised KG alignment system that iteratively computes the Mappings with
both Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.
PRASEMap can support various embedding-based KG alignment approaches as the SE
module, and enables easy human computer interaction that additionally provides
an option for users to feed the mapping annotations back to the system for
better results. The demonstration showcases these features via a stand-alone
Web application with user friendly interfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine Hesitancy on Twitter. (arXiv:2106.08423v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1">Karishma Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizhou Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08423">
                                    <div class="article-summary-box-inner">
                                        <span>Vaccine hesitancy and misinformation on social media has increased concerns
about COVID-19 vaccine uptake required to achieve herd immunity and overcome
the pandemic. However anti-science and political misinformation and
conspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,
we investigate misinformation and conspiracy campaigns and their characteristic
behaviours. We identify whether coordinated efforts are used to promote
misinformation in vaccine related discussions, and find accounts coordinately
promoting a &#x60;Great Reset&#x27; conspiracy group promoting vaccine related
misinformation and strong anti-vaccine and anti-social messages such as boycott
vaccine passports, no lock-downs and masks. We characterize other
misinformation communities from the information diffusion structure, and study
the large anti-vaccine misinformation community and smaller anti-vaccine
communities, including a far-right anti-vaccine conspiracy group. In comparison
with the mainstream and health news, left-leaning group, which are more
pro-vaccine, the right-leaning group is influenced more by the anti-vaccine and
far-right misinformation/conspiracy communities. The misinformation communities
are more vocal either specific to the vaccine discussion or political
discussion, and we find other differences in the characteristic behaviours of
different communities. Lastly, we investigate misinformation narratives and
tactics of information distortion that can increase vaccine hesitancy, using
topic modeling and comparison with reported vaccine side-effects (VAERS)
finding rarer side-effects are more frequently discussed on social media.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge-Adaptation Priors. (arXiv:2106.08769v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Emtiyaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaroop_S/0/1/0/all/0/1">Siddharth Swaroop</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08769">
                                    <div class="article-summary-box-inner">
                                        <span>Humans and animals have a natural ability to quickly adapt to their
surroundings, but machine-learning models, when subjected to changes, often
require a complete retraining from scratch. We present Knowledge-adaptation
priors (K-priors) to reduce the cost of retraining by enabling quick and
accurate adaptation for a wide-variety of tasks and models. This is made
possible by a combination of weight and function-space priors to reconstruct
the gradients of the past, which recovers and generalizes many existing, but
seemingly-unrelated, adaptation strategies. Training with simple first-order
gradient methods can often recover the exact retrained model to an arbitrary
accuracy by choosing a sufficiently large memory of the past data. Empirical
results confirm that the adaptation can be cheap and accurate, and a promising
alternative to retraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Breaking The Dimension Dependence in Sparse Distribution Estimation under Communication Constraints. (arXiv:2106.08597v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1">Wei-Ning Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Kairouz_P/0/1/0/all/0/1">Peter Kairouz</a>, <a href="http://arxiv.org/find/stat/1/au:+Ozgur_A/0/1/0/all/0/1">Ayfer &#xd6;zg&#xfc;r</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08597">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of estimating a $d$-dimensional $s$-sparse discrete
distribution from its samples observed under a $b$-bit communication
constraint. The best-known previous result on $\ell_2$ estimation error for
this problem is $O\left( \frac{s\log\left( {d}/{s}\right)}{n2^b}\right)$.
Surprisingly, we show that when sample size $n$ exceeds a minimum threshold
$n^*(s, d, b)$, we can achieve an $\ell_2$ estimation error of $O\left(
\frac{s}{n2^b}\right)$. This implies that when $n&gt;n^*(s, d, b)$ the convergence
rate does not depend on the ambient dimension $d$ and is the same as knowing
the support of the distribution beforehand.

We next ask the question: &#x60;&#x60;what is the minimum $n^*(s, d, b)$ that allows
dimension-free convergence?&#x27;&#x27;. To upper bound $n^*(s, d, b)$, we develop novel
localization schemes to accurately and efficiently localize the unknown
support. For the non-interactive setting, we show that $n^*(s, d, b) &#x3D; O\left(
\min \left( {d^2\log^2 d}/{2^b}, {s^4\log^2 d}/{2^b}\right) \right)$. Moreover,
we connect the problem with non-adaptive group testing and obtain a
polynomial-time estimation scheme when $n &#x3D; \tilde{\Omega}\left({s^4\log^4
d}/{2^b}\right)$. This group testing based scheme is adaptive to the sparsity
parameter $s$, and hence can be applied without knowing it. For the interactive
setting, we propose a novel tree-based estimation scheme and show that the
minimum sample-size needed to achieve dimension-free convergence can be further
reduced to $n^*(s, d, b) &#x3D; \tilde{O}\left( {s^2\log^2 d}/{2^b} \right)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Unreliable Predictions by Shattering a Neural Network. (arXiv:2106.08365v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xu Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1">Devon Hjelm</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1">Andrea Vedaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1">Balaji Lakshminarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08365">
                                    <div class="article-summary-box-inner">
                                        <span>Piecewise linear neural networks can be split into subfunctions, each with
its own activation pattern, domain, and empirical error. Empirical error for
the full network can be written as an expectation over empirical error of
subfunctions. Constructing a generalization bound on subfunction empirical
error indicates that the more densely a subfunction is surrounded by training
samples in representation space, the more reliable its predictions are.
Further, it suggests that models with fewer activation regions generalize
better, and models that abstract knowledge to a greater degree generalize
better, all else equal. We propose not only a theoretical framework to reason
about subfunction error bounds but also a pragmatic way of approximately
evaluating it, which we apply to predicting which samples the network will not
successfully generalize to. We test our method on detection of
misclassification and out-of-distribution samples, finding that it performs
competitively in both cases. In short, some network activation patterns are
associated with higher reliability than others, and these can be identified
using subfunction error bounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Spiking Neural Network for Image Segmentation. (arXiv:2106.08921v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1">Kinjal Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Hunsberger_E/0/1/0/all/0/1">Eric Hunsberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Batir_S/0/1/0/all/0/1">Sean Batir</a>, <a href="http://arxiv.org/find/cs/1/au:+Eliasmith_C/0/1/0/all/0/1">Chris Eliasmith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08921">
                                    <div class="article-summary-box-inner">
                                        <span>We seek to investigate the scalability of neuromorphic computing for computer
vision, with the objective of replicating non-neuromorphic performance on
computer vision tasks while reducing power consumption. We convert the deep
Artificial Neural Network (ANN) architecture U-Net to a Spiking Neural Network
(SNN) architecture using the Nengo framework. Both rate-based and spike-based
models are trained and optimized for benchmarking performance and power, using
a modified version of the ISBI 2D EM Segmentation dataset consisting of
microscope images of cells. We propose a partitioning method to optimize
inter-chip communication to improve speed and energy efficiency when deploying
multi-chip networks on the Loihi neuromorphic chip. We explore the advantages
of regularizing firing rates of Loihi neurons for converting ANN to SNN with
minimum accuracy loss and optimized energy consumption. We propose a percentile
based regularization loss function to limit the spiking rate of the neuron
between a desired range. The SNN is converted directly from the corresponding
ANN, and demonstrates similar semantic segmentation as the ANN using the same
number of neurons and weights. However, the neuromorphic implementation on the
Intel Loihi neuromorphic chip is over 2x more energy-efficient than
conventional hardware (CPU, GPU) when running online (one image at a time).
These power improvements are achieved without sacrificing the task performance
accuracy of the network, and when all weights (Loihi, CPU, and GPU networks)
are quantized to 8 bits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lorenz System State Stability Identification using Neural Networks. (arXiv:2106.08489v1 [math.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Subramanian_M/0/1/0/all/0/1">Megha Subramanian</a>, <a href="http://arxiv.org/find/math/1/au:+Tipireddy_R/0/1/0/all/0/1">Ramakrishna Tipireddy</a>, <a href="http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1">Samrat Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08489">
                                    <div class="article-summary-box-inner">
                                        <span>Nonlinear dynamical systems such as Lorenz63 equations are known to be
chaotic in nature and sensitive to initial conditions. As a result, a small
perturbation in the initial conditions results in deviation in state trajectory
after a few time steps. The algorithms and computational resources needed to
accurately identify the system states vary depending on whether the solution is
in transition region or not. We refer to the transition and non-transition
regions as unstable and stable regions respectively. We label a system state to
be stable if it&#x27;s immediate past and future states reside in the same regime.
However, at a given time step we don&#x27;t have the prior knowledge about whether
system is in stable or unstable region. In this paper, we develop and train a
feed forward (multi-layer perceptron) Neural Network to classify the system
states of a Lorenz system as stable and unstable. We pose this task as a
supervised learning problem where we train the neural network on Lorenz system
which have states labeled as stable or unstable. We then test the ability of
the neural network models to identify the stable and unstable states on a
different Lorenz system that is generated using different initial conditions.
We also evaluate the classification performance in the mismatched case i.e.,
when the initial conditions for training and validation data are sampled from
different intervals. We show that certain normalization schemes can greatly
improve the performance of neural networks in especially these mismatched
scenarios. The classification framework developed in the paper can be a
preprocessor for a larger context of sequential decision making framework where
the decision making is performed based on observed stable or unstable states.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Learning with Uncertain Feedback Graphs. (arXiv:2106.08441v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghari_P/0/1/0/all/0/1">Pouya M Ghari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yanning Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08441">
                                    <div class="article-summary-box-inner">
                                        <span>Online learning with expert advice is widely used in various machine learning
tasks. It considers the problem where a learner chooses one from a set of
experts to take advice and make a decision. In many learning problems, experts
may be related, henceforth the learner can observe the losses associated with a
subset of experts that are related to the chosen one. In this context, the
relationship among experts can be captured by a feedback graph, which can be
used to assist the learner&#x27;s decision making. However, in practice, the nominal
feedback graph often entails uncertainties, which renders it impossible to
reveal the actual relationship among experts. To cope with this challenge, the
present work studies various cases of potential uncertainties, and develops
novel online learning algorithms to deal with uncertainties while making use of
the uncertain feedback graph. The proposed algorithms are proved to enjoy
sublinear regret under mild conditions. Experiments on real datasets are
presented to demonstrate the effectiveness of the novel algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Attacks on Deep Models for Financial Transaction Records. (arXiv:2106.08361v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fursov_I/0/1/0/all/0/1">Ivan Fursov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_M/0/1/0/all/0/1">Matvey Morozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaploukhaya_N/0/1/0/all/0/1">Nina Kaploukhaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovtun_E/0/1/0/all/0/1">Elizaveta Kovtun</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivera_Castro_R/0/1/0/all/0/1">Rodrigo Rivera-Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusev_G/0/1/0/all/0/1">Gleb Gusev</a>, <a href="http://arxiv.org/find/cs/1/au:+Babaev_D/0/1/0/all/0/1">Dmitry Babaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Kireev_I/0/1/0/all/0/1">Ivan Kireev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1">Alexey Zaytsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08361">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models using transaction records as inputs are popular among
financial institutions. The most efficient models use deep-learning
architectures similar to those in the NLP community, posing a challenge due to
their tremendous number of parameters and limited robustness. In particular,
deep-learning models are vulnerable to adversarial attacks: a little change in
the input harms the model&#x27;s output.

In this work, we examine adversarial attacks on transaction records data and
defences from these attacks. The transaction records data have a different
structure than the canonical NLP or time series data, as neighbouring records
are less connected than words in sentences, and each record consists of both
discrete merchant code and continuous transaction amount. We consider a
black-box attack scenario, where the attack doesn&#x27;t know the true decision
model, and pay special attention to adding transaction tokens to the end of a
sequence. These limitations provide more realistic scenario, previously
unexplored in NLP world.

The proposed adversarial attacks and the respective defences demonstrate
remarkable performance using relevant datasets from the financial industry. Our
results show that a couple of generated transactions are sufficient to fool a
deep-learning model. Further, we improve model robustness via adversarial
training or separate adversarial examples detection. This work shows that
embedding protection from adversarial attacks improves model robustness,
allowing a wider adoption of deep models for transaction records in banking and
finance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of Automated Machine Learning Tools for SMS Spam Message Filtering. (arXiv:2106.08671v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saeed_W/0/1/0/all/0/1">Waddah Saeed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08671">
                                    <div class="article-summary-box-inner">
                                        <span>Short Message Service (SMS) is a very popular service used for communication
by mobile users. However, this popular service can be abused by executing
illegal activities and influencing security risks. Nowadays, many automatic
machine learning (AutoML) tools exist which can help domain experts and lay
users to build high-quality ML models with little or no machine learning
knowledge. In this work, a classification performance comparison was conducted
between three automatic ML tools for SMS spam message filtering. These tools
are mljar-supervised AutoML, H2O AutoML, and Tree-based Pipeline Optimization
Tool (TPOT) AutoML. Experimental results showed that ensemble models achieved
the best classification performance. The Stacked Ensemble model, which was
built using H2O AutoML, achieved the best performance in terms of Log Loss
(0.8370), true positive (1088/1116), and true negative (281/287) metrics. There
is a 19.05\% improvement in Log Loss with respect to TPOT AutoML and 10.53\%
improvement with respect to mljar-supervised AutoML. The satisfactory filtering
performance achieved with AutoML tools provides a potential application for
AutoML tools to automatically determine the best ML model that can perform best
for SMS spam message filtering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Developing a Fidelity Evaluation Approach for Interpretable Machine Learning. (arXiv:2106.08492v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Velmurugan_M/0/1/0/all/0/1">Mythreyi Velmurugan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Chun Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1">Catarina Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1">Renuka Sindhgatta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08492">
                                    <div class="article-summary-box-inner">
                                        <span>Although modern machine learning and deep learning methods allow for complex
and in-depth data analytics, the predictive models generated by these methods
are often highly complex, and lack transparency. Explainable AI (XAI) methods
are used to improve the interpretability of these complex models, and in doing
so improve transparency. However, the inherent fitness of these explainable
methods can be hard to evaluate. In particular, methods to evaluate the
fidelity of the explanation to the underlying black box require further
development, especially for tabular data. In this paper, we (a) propose a three
phase approach to developing an evaluation method; (b) adapt an existing
evaluation method primarily for image and text data to evaluate models trained
on tabular data; and (c) evaluate two popular explainable methods using this
evaluation method. Our evaluations suggest that the internal mechanism of the
underlying predictive model, the internal mechanism of the explainable method
used and model and data complexity all affect explanation fidelity. Given that
explanation fidelity is so sensitive to context and tools and data used, we
could not clearly identify any specific explainable method as being superior to
another.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Silhouettes and quasi residual plots for neural nets and tree-based classifiers. (arXiv:2106.08814v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Raymaekers_J/0/1/0/all/0/1">Jakob Raymaekers</a>, <a href="http://arxiv.org/find/stat/1/au:+Rousseeuw_P/0/1/0/all/0/1">Peter J. Rousseeuw</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08814">
                                    <div class="article-summary-box-inner">
                                        <span>Classification by neural nets and by tree-based methods are powerful tools of
machine learning. There exist interesting visualizations of the inner workings
of these and other classifiers. Here we pursue a different goal, which is to
visualize the cases being classified, either in training data or in test data.
An important aspect is whether a case has been classified to its given class
(label) or whether the classifier wants to assign it to different class. This
is reflected in the (conditional and posterior) probability of the alternative
class (PAC). A high PAC indicates label bias, i.e. the possibility that the
case was mislabeled. The PAC is used to construct a silhouette plot which is
similar in spirit to the silhouette plot for cluster analysis (Rousseeuw,
1987). The average silhouette width can be used to compare different
classifications of the same dataset. We will also draw quasi residual plots of
the PAC versus a data feature, which may lead to more insight in the data. One
of these data features is how far each case lies from its given class. The
graphical displays are illustrated and interpreted on benchmark data sets
containing images, mixed features, and tweets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-trained Weights in Wide Neural Networks Align Layerwise to Error-scaled Input Correlations. (arXiv:2106.08453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boopathy_A/0/1/0/all/0/1">Akhilan Boopathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiete_I/0/1/0/all/0/1">Ila Fiete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08453">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have examined how deep neural networks, which can solve a
variety of difficult problems, incorporate the statistics of training data to
achieve their success. However, existing results have been established only in
limited settings. In this work, we derive the layerwise weight dynamics of
infinite-width neural networks with nonlinear activations trained by gradient
descent. We show theoretically that weight updates are aligned with input
correlations from intermediate layers weighted by error, and demonstrate
empirically that the result also holds in finite-width wide networks. The
alignment result allows us to formulate backpropagation-free learning rules,
named Align-zero and Align-ada, that theoretically achieve the same alignment
as backpropagation. Finally, we test these learning rules on benchmark problems
in feedforward and recurrent neural networks and demonstrate, in wide networks,
comparable performance to backpropagation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Mappings: Generating Open-Ended Expressive Mappings Using Variational Autoencoders. (arXiv:2106.08867v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murray_Browne_T/0/1/0/all/0/1">Tim Murray-Browne</a>, <a href="http://arxiv.org/find/cs/1/au:+Tigas_P/0/1/0/all/0/1">Panagiotis Tigas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08867">
                                    <div class="article-summary-box-inner">
                                        <span>In many contexts, creating mappings for gestural interactions can form part
of an artistic process. Creators seeking a mapping that is expressive, novel,
and affords them a sense of authorship may not know how to program it up in a
signal processing patch. Tools like Wekinator and MIMIC allow creators to use
supervised machine learning to learn mappings from example input/output
pairings. However, a creator may know a good mapping when they encounter it yet
start with little sense of what the inputs or outputs should be. We call this
an open-ended mapping process. Addressing this need, we introduce the latent
mapping, which leverages the latent space of an unsupervised machine learning
algorithm such as a Variational Autoencoder trained on a corpus of unlabelled
gestural data from the creator. We illustrate it with Sonified Body, a system
mapping full-body movement to sound which we explore in a residency with three
dancers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1">Luka Murn</a>, <a href="http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1">Saverio Blasi</a>, <a href="http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1">Alan F. Smeaton</a>, <a href="http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1">Marta Mrak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08936">
                                    <div class="article-summary-box-inner">
                                        <span>The versatility of recent machine learning approaches makes them ideal for
improvement of next generation video compression solutions. Unfortunately,
these approaches typically bring significant increases in computational
complexity and are difficult to interpret into explainable models, affecting
their potential for implementation within practical video coding applications.
This paper introduces a novel explainable neural network-based inter-prediction
scheme, to improve the interpolation of reference samples needed for fractional
precision motion compensation. The approach requires a single neural network to
be trained from which a full quarter-pixel interpolation filter set is derived,
as the network is easily interpretable due to its linear structure. A novel
training framework enables each network branch to resemble a specific
fractional shift. This practical solution makes it very efficient to use
alongside conventional video coding schemes. When implemented in the context of
the state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and
2.25% BD-rate savings can be achieved on average for lower resolution sequences
under the random access, low-delay B and low-delay P configurations,
respectively, while the complexity of the learned interpolation schemes is
significantly reduced compared to the interpolation with full CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-06-23T00:39:33.480Z">2021-06-23T00:39:33.480Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>