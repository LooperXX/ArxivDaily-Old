 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-05">2021-07-05</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Machine Reading Comprehension for Vietnamese Healthcare Texts. (arXiv:2105.01542v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1">Son T. Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1">Mao Nguyen Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Loi Duc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1">Khiem Vinh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01542">
                                    <div class="article-summary-box-inner">
                                        <span>Machine reading comprehension (MRC) is a sub-field in natural language
processing that aims to assist computers understand unstructured texts and then
answer questions related to them. In practice, the conversation is an essential
way to communicate and transfer information. To help machines understand
conversation texts, we present UIT-ViCoQA, a new corpus for conversational
machine reading comprehension in the Vietnamese language. This corpus consists
of 10,000 questions with answers over 2,000 conversations about health news
articles. Then, we evaluate several baseline approaches for conversational
machine comprehension on the UIT-ViCoQA corpus. The best model obtains an F1
score of 45.27%, which is 30.91 points behind human performance (76.18%),
indicating that there is ample room for improvement. Our dataset is available
at our website: this http URL for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Lifelong Learning of End-to-end ASR. (arXiv:2104.01616v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Heng-Jui Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1">Lin-shan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01616">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) technologies today are primarily optimized
for given datasets; thus, any changes in the application environment (e.g.,
acoustic conditions or topic domains) may inevitably degrade the performance.
We can collect new data describing the new environment and fine-tune the
system, but this naturally leads to higher error rates for the earlier
datasets, referred to as catastrophic forgetting. The concept of lifelong
learning (LLL) aiming to enable a machine to sequentially learn new tasks from
new datasets describing the changing real world without forgetting the
previously learned knowledge is thus brought to attention. This paper reports,
to our knowledge, the first effort to extensively consider and analyze the use
of various approaches of LLL in end-to-end (E2E) ASR, including proposing novel
methods in saving data for past domains to mitigate the catastrophic forgetting
problem. An overall relative reduction of 28.7% in WER was achieved compared to
the fine-tuning baseline when sequentially learning on three very different
benchmark corpora. This can be the first step toward the highly desired ASR
technologies capable of synchronizing with the continuously changing real
world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Learning for Grapheme-to-Phoneme Conversion of Anglicisms in German Speech Recognition. (arXiv:2105.12708v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pritzen_J/0/1/0/all/0/1">Julia Pritzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gref_M/0/1/0/all/0/1">Michael Gref</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuhlke_D/0/1/0/all/0/1">Dietlind Z&#xfc;hlke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_C/0/1/0/all/0/1">Christoph Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12708">
                                    <div class="article-summary-box-inner">
                                        <span>Loanwords, such as Anglicisms, are a challenge in German speech recognition.
Due to their irregular pronunciation compared to native German words,
automatically generated pronunciation dictionaries often include faulty phoneme
sequences for Anglicisms. In this work, we propose a multitask
sequence-to-sequence approach for grapheme-to-phoneme conversion to improve the
phonetization of Anglicisms. We extended a grapheme-to-phoneme model with a
classifier to distinguish Anglicisms from native German words. With this
approach, the model learns to generate pronunciations differently depending on
the classification result. We used our model to create supplementary Anglicism
pronunciation dictionaries that are added to an existing German speech
recognition model. Tested on a dedicated Anglicism evaluation set, we improved
the recognition of Anglicisms compared to a baseline model, reducing the word
error rate by 1 % and the Anglicism error rate by 3 %. We show that multitask
learning can help solving the challenge of loanwords in German speech
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. (arXiv:2106.12672v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1">Yi Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Vinh Q. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1">Jai Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hyung Won Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_S/0/1/0/all/0/1">Simon Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1">Donald Metzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12672">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art models in natural language processing rely on separate rigid
subword tokenization algorithms, which limit their generalization ability and
adaptation to new settings. In this paper, we propose a new model inductive
bias that learns a subword tokenization end-to-end as part of the model. To
this end, we introduce a soft gradient-based subword tokenization module (GBST)
that automatically learns latent subword representations from characters in a
data-driven fashion. Concretely, GBST enumerates candidate subword blocks and
learns to score them in a position-wise fashion using a block scoring network.
We additionally introduce Charformer, a deep Transformer model that integrates
GBST and operates on the byte level. Via extensive experiments on English GLUE,
multilingual, and noisy text datasets, we show that Charformer outperforms a
series of competitive byte-level baselines while generally performing on par
and sometimes outperforming subword-based models. Additionally, Charformer is
fast, improving the speed of both vanilla byte-level and subword-level
Transformers by 28%-100% while maintaining competitive quality. We believe this
work paves the way for highly performant token-free models that are trained
completely end-to-end.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Patent Mining and Relevance Classification using Transformers. (arXiv:2105.03979v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1">Th&#xe9;o Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Vermeiren_W/0/1/0/all/0/1">Walter Vermeiren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranwez_S/0/1/0/all/0/1">Sylvie Ranwez</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Binbin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03979">
                                    <div class="article-summary-box-inner">
                                        <span>Patent analysis and mining are time-consuming and costly processes for
companies, but nevertheless essential if they are willing to remain
competitive. To face the overload induced by numerous patents, the idea is to
automatically filter them, bringing only few to read to experts. This paper
reports a successful application of fine-tuning and retraining on pre-trained
deep Natural Language Processing models on patent classification. The solution
that we propose combines several state-of-the-art treatments to achieve our
goal - decrease the workload while preserving recall and precision metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Gender Bias in Speech Translation. (arXiv:2010.14465v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1">Marta R. Costa-juss&#xe0;</a>, <a href="http://arxiv.org/find/cs/1/au:+Basta_C/0/1/0/all/0/1">Christine Basta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1">Gerard I. G&#xe1;llego</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14465">
                                    <div class="article-summary-box-inner">
                                        <span>The scientific community is increasingly aware of the necessity to embrace
pluralism and consistently represent major and minor social groups. Currently,
there are no standard evaluation techniques for different types of biases.
Accordingly, there is an urgent need to provide evaluation sets and protocols
to measure existing biases in our automatic systems. Evaluating the biases
should be an essential step towards mitigating them in the systems.

This paper introduces WinoST, a new freely available challenge set for
evaluating gender bias in speech translation. WinoST is the speech version of
WinoMT which is a MT challenge set and both follow an evaluation protocol to
measure gender accuracy. Using a state-of-the-art end-to-end speech translation
system, we report the gender bias evaluation on four language pairs and we show
that gender accuracy in speech translation is more than 23% lower than in MT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Augmentation by Concatenation for Low-Resource Translation: A Mystery and a Solution. (arXiv:2105.01691v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Toan Q. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1">Kenton Murray</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1">David Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01691">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the driving factors behind concatenation, a
simple but effective data augmentation method for low-resource neural machine
translation. Our experiments suggest that discourse context is unlikely the
cause for the improvement of about +1 BLEU across four language pairs. Instead,
we demonstrate that the improvement comes from three other factors unrelated to
discourse: context diversity, length diversity, and (to a lesser extent)
position shifting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlloST: Low-resource Speech Translation without Source Transcription. (arXiv:2105.00171v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yao-Fei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-Shin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hsin-Min Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00171">
                                    <div class="article-summary-box-inner">
                                        <span>The end-to-end architecture has made promising progress in speech translation
(ST). However, the ST task is still challenging under low-resource conditions.
Most ST models have shown unsatisfactory results, especially in the absence of
word information from the source speech utterance. In this study, we survey
methods to improve ST performance without using source transcription, and
propose a learning framework that utilizes a language-independent universal
phone recognizer. The framework is based on an attention-based
sequence-to-sequence model, where the encoder generates the phonetic embeddings
and phone-aware acoustic representations, and the decoder controls the fusion
of the two embedding streams to produce the target token sequence. In addition
to investigating different fusion strategies, we explore the specific usage of
byte pair encoding (BPE), which compresses a phone sequence into a
syllable-like segmented sequence. Due to the conversion of symbols, a segmented
sequence represents not only pronunciation but also language-dependent
information lacking in phones. Experiments conducted on the Fisher
Spanish-English and Taigi-Mandarin drama corpora show that our method
outperforms the conformer-based baseline, and the performance is close to that
of the existing best method using source transcription.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExplainaBoard: An Explainable Leaderboard for NLP. (arXiv:2104.06387v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shuaicheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zihuiwen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06387">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of NLP research, leaderboards have emerged as one
tool to track the performance of various systems on various NLP tasks. They are
effective in this goal to some extent, but generally present a rather
simplistic one-dimensional view of the submitted systems, communicated only
through holistic accuracy numbers. In this paper, we present a new
conceptualization and implementation of NLP evaluation: the ExplainaBoard,
which in addition to inheriting the functionality of the standard leaderboard,
also allows researchers to (i) diagnose strengths and weaknesses of a single
system (e.g.~what is the best-performing system bad at?) (ii) interpret
relationships between multiple systems. (e.g.~where does system A outperform
system B? What if we combine systems A, B, and C?) and (iii) examine prediction
results closely (e.g.~what are common errors made by multiple systems, or in
what contexts do particular errors occur?). So far, ExplainaBoard covers more
than 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps
updated and is recently upgraded by supporting (1) multilingual multi-task
benchmark, (2) meta-evaluation, and (3) more complicated task: machine
translation, which reviewers also suggested.} We not only released an online
platform on the website \url{this http URL} but also make
our evaluation tool an API with MIT Licence at Github
\url{https://github.com/neulab/explainaBoard} and PyPi
\url{https://pypi.org/project/interpret-eval/} that allows users to
conveniently assess their models offline. We additionally release all output
files from systems that we have run or collected to motivate &quot;output-driven&quot;
research in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-guided Legal Knowledge Graph Reasoning. (arXiv:2104.02284v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Luoqiu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hongbin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shumin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tou_H/0/1/0/all/0/1">Huaixiao Tou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02284">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed the prosperity of legal artificial intelligence
with the development of technologies. In this paper, we propose a novel legal
application of legal provision prediction (LPP), which aims to predict the
related legal provisions of affairs. We formulate this task as a challenging
knowledge graph completion problem, which requires not only text understanding
but also graph reasoning. To this end, we propose a novel text-guided graph
reasoning approach. We collect amounts of real-world legal provision data from
the Guangdong government service website and construct a legal dataset called
LegalLPP. Extensive experimental results on the dataset show that our approach
achieves better performance compared with baselines. The code and dataset are
available in \url{https://github.com/zjunlp/LegalPP} for reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-to-English Machine Translation Tools, Data, and Pretrained Models. (arXiv:2104.00290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gowda_T/0/1/0/all/0/1">Thamme Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattmann_C/0/1/0/all/0/1">Chris A Mattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00290">
                                    <div class="article-summary-box-inner">
                                        <span>While there are more than 7000 languages in the world, most translation
research efforts have targeted a few high-resource languages. Commercial
translation systems support only one hundred languages or fewer, and do not
make these models available for transfer to low resource languages. In this
work, we present useful tools for machine translation research: MTData,
NLCodec, and RTG. We demonstrate their usefulness by creating a multilingual
neural machine translation model capable of translating from 500 source
languages to English. We make this multilingual model readily downloadable and
usable as a service, or as a parent model for transfer-learning to even
lower-resource languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethics Sheets for AI Tasks. (arXiv:2107.01183v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1">Saif M. Mohammad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01183">
                                    <div class="article-summary-box-inner">
                                        <span>Several high-profile events, such as the use of biased recidivism systems and
mass testing of emotion recognition systems on vulnerable sub-populations, have
highlighted how technology will often lead to more adverse outcomes for those
that are already marginalized. In this paper, I will make a case for thinking
about ethical considerations not just at the level of individual models and
datasets, but also at the level of AI tasks. I will present a new form of such
an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the
assumptions and ethical considerations hidden in how a task is commonly framed
and in the choices we make regarding the data, method, and evaluation. Finally,
I will provide an example ethics sheet for automatic emotion recognition.
Together with Data Sheets for datasets and Model Cards for AI systems, Ethics
Sheets aid in the development and deployment of responsible AI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporally Correlated Task Scheduling for Sequence Learning. (arXiv:2007.05290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xueqing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lewen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yingce Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lijun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shufang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05290">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence learning has attracted much research attention from the machine
learning community in recent years. In many applications, a sequence learning
task is usually associated with multiple temporally correlated auxiliary tasks,
which are different in terms of how much input information to use or which
future step to predict. For example, (i) in simultaneous machine translation,
one can conduct translation under different latency (i.e., how many input words
to read/wait before translation); (ii) in stock trend forecasting, one can
predict the price of a stock in different future days (e.g., tomorrow, the day
after tomorrow). While it is clear that those temporally correlated tasks can
help each other, there is a very limited exploration on how to better leverage
multiple auxiliary tasks to boost the performance of the main task. In this
work, we introduce a learnable scheduler to sequence learning, which can
adaptively select auxiliary tasks for training depending on the model status
and the current training data. The scheduler and the model for the main task
are jointly trained through bi-level optimization. Experiments show that our
method significantly improves the performance of simultaneous machine
translation and stock trend forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UIT-ISE-NLP at SemEval-2021 Task 5: Toxic Spans Detection with BiLSTM-CRF and ToxicBERT Comment Classification. (arXiv:2104.10100v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1">Son T. Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10100">
                                    <div class="article-summary-box-inner">
                                        <span>We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This
task aims to build a model for identifying toxic words in whole posts. We use
the BiLSTM-CRF model combining with ToxicBERT Classification to train the
detection model for identifying toxic words in posts. Our model achieves 62.23%
by F1-score on the Toxic Spans Detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Decisions in Language Based Persuasion Games. (arXiv:2012.09966v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Apel_R/0/1/0/all/0/1">Reut Apel</a>, <a href="http://arxiv.org/find/cs/1/au:+Erev_I/0/1/0/all/0/1">Ido Erev</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_M/0/1/0/all/0/1">Moshe Tennenholtz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09966">
                                    <div class="article-summary-box-inner">
                                        <span>Sender-receiver interactions, and specifically persuasion games, are widely
researched in economic modeling and artificial intelligence, and serve as a
solid foundation for powerful applications. However, in the classic persuasion
games setting, the messages sent from the expert to the decision-maker are
abstract or well-structured application-specific signals rather than natural
(human) language messages, although natural language is a very common
communication signal in real-world persuasion setups. This paper addresses the
use of natural language in persuasion games, exploring its impact on the
decisions made by the players and aiming to construct effective models for the
prediction of these decisions. For this purpose, we conduct an online repeated
interaction experiment. At each trial of the interaction, an informed expert
aims to sell an uninformed decision-maker a vacation in a hotel, by sending her
a review that describes the hotel. While the expert is exposed to several
scored reviews, the decision-maker observes only the single review sent by the
expert, and her payoff in case she chooses to take the hotel is a random draw
from the review score distribution available to the expert only. The expert&#x27;s
payoff, in turn, depends on the number of times the decision-maker chooses the
hotel. We consider a number of modeling approaches for this setup, differing
from each other in the model type (deep neural network (DNN) vs. linear
classifier), the type of features used by the model (textual, behavioral or
both) and the source of the textual features (DNN-based vs. hand-crafted). Our
results demonstrate that given a prefix of the interaction sequence, our models
can predict the future decisions of the decision-maker, particularly when a
sequential modeling approach and hand-crafted textual features are applied.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concept Identification of Directly and Indirectly Related Mentions Referring to Groups of Persons. (arXiv:2107.00955v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1">Anastasia Zhukova</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1">Felix Hamborg</a>, <a href="http://arxiv.org/find/cs/1/au:+Donnay_K/0/1/0/all/0/1">Karsten Donnay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1">Bela Gipp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00955">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised concept identification through clustering, i.e., identification
of semantically related words and phrases, is a common approach to identify
contextual primitives employed in various use cases, e.g., text dimension
reduction, i.e., replace words with the concepts to reduce the vocabulary size,
summarization, and named entity resolution. We demonstrate the first results of
an unsupervised approach for the identification of groups of persons as actors
extracted from a set of related articles. Specifically, the approach clusters
mentions of groups of persons that act as non-named entity actors in the texts,
e.g., &quot;migrant families&quot; &#x3D; &quot;asylum-seekers.&quot; Compared to our baseline, the
approach keeps the mentions of the geopolitical entities separated, e.g., &quot;Iran
leaders&quot; !&#x3D; &quot;European leaders,&quot; and clusters (in)directly related mentions with
diverse wording, e.g., &quot;American officials&quot; &#x3D; &quot;Trump Administration.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Abheesht Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1">Gunjan Chhablani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1">Harshit Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_R/0/1/0/all/0/1">Rajaswa Patil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01198">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUKweb: Diachronic word representations from the UK Web Archive corpus. (arXiv:2107.01076v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1">Adam Tsakalidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Basile_P/0/1/0/all/0/1">Pierpaolo Basile</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazzi_M/0/1/0/all/0/1">Marya Bazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>, <a href="http://arxiv.org/find/cs/1/au:+McGillivray_B/0/1/0/all/0/1">Barbara McGillivray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01076">
                                    <div class="article-summary-box-inner">
                                        <span>Lexical semantic change (detecting shifts in the meaning and usage of words)
is an important task for social and cultural studies as well as for Natural
Language Processing applications. Diachronic word embeddings (time-sensitive
vector representations of words that preserve their meaning) have become the
standard resource for this task. However, given the significant computational
resources needed for their generation, very few resources exist that make
diachronic word embeddings available to the scientific community.

In this paper we present DUKweb, a set of large-scale resources designed for
the diachronic analysis of contemporary English. DUKweb was created from the
JISC UK Web Domain Dataset (1996-2013), a very large archive which collects
resources from the Internet Archive that were hosted on domains ending in
&#x60;.uk&#x27;. DUKweb consists of a series word co-occurrence matrices and two types of
word embeddings for each year in the JISC UK Web Domain dataset. We show the
reuse potential of DUKweb and its quality standards via a case study on word
meaning change detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Identification of Hindi-English tweets using code-mixed BERT. (arXiv:2107.01202v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohd Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">M M Sufyan Beg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohd Jazib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasim_G/0/1/0/all/0/1">Ghazali Wasim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01202">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification of social media text has been an interesting problem
of study in recent years. Social media messages are predominantly in code mixed
in non-English speaking states. Prior knowledge by pre-training contextual
embeddings have shown state of the art results for a range of downstream tasks.
Recently, models such as BERT have shown that using a large amount of unlabeled
data, the pretrained language models are even more beneficial for learning
common language representations. Extensive experiments exploiting transfer
learning and fine-tuning BERT models to identify language on Twitter are
presented in this paper. The work utilizes a data collection of
Hindi-English-Urdu codemixed text for language pre-training and Hindi-English
codemixed for subsequent word-level language classification. The results show
that the representations pre-trained over codemixed data produce better results
by their monolingual counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. (arXiv:2107.00967v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haitao Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zujie Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yafang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1">Gerard de Melo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00967">
                                    <div class="article-summary-box-inner">
                                        <span>Human language understanding operates at multiple levels of granularity
(e.g., words, phrases, and sentences) with increasing levels of abstraction
that can be hierarchically combined. However, existing deep models with stacked
layers do not explicitly model any sort of hierarchical process. This paper
proposes a recursive Transformer model based on differentiable CKY style binary
trees to emulate the composition process. We extend the bidirectional language
model pre-training objective to this architecture, attempting to predict each
word given its left and right abstraction nodes. To scale up our approach, we
also introduce an efficient pruned tree induction algorithm to enable encoding
in just a linear number of composition steps. Experimental results on language
modeling and unsupervised parsing show the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Spoken Utterance Classification. (arXiv:2107.01068v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalalvand_S/0/1/0/all/0/1">Shahab Jalalvand</a>, <a href="http://arxiv.org/find/cs/1/au:+Bangalore_S/0/1/0/all/0/1">Srinivas Bangalore</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01068">
                                    <div class="article-summary-box-inner">
                                        <span>An intelligent virtual assistant (IVA) enables effortless conversations in
call routing through spoken utterance classification (SUC) which is a special
form of spoken language understanding (SLU). Building a SUC system requires a
large amount of supervised in-domain data that is not always available. In this
paper, we introduce an unsupervised spoken utterance classification approach
(USUC) that does not require any in-domain data except for the intent labels
and a few para-phrases per intent. USUC is consisting of a KNN classifier (K&#x3D;1)
and a complex embedding model trained on a large amount of unsupervised
customer service corpus. Among all embedding models, we demonstrate that Elmo
works best for USUC. However, an Elmo model is too slow to be used at run-time
for call routing. To resolve this issue, first, we compute the uni- and bi-gram
embedding vectors offline and we build a lookup table of n-grams and their
corresponding embedding vector. Then we use this table to compute sentence
embedding vectors at run-time, along with back-off techniques for unseen
n-grams. Experiments show that USUC outperforms the traditional utterance
classification methods by reducing the classification error rate from 32.9% to
27.0% without requiring supervised data. Moreover, our lookup and back-off
technique increases the processing speed from 16 utterances per second to 118
utterances per second.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents. (arXiv:2107.00956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1">R&#xe9;my Portelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00956">
                                    <div class="article-summary-box-inner">
                                        <span>Building embodied autonomous agents capable of participating in social
interactions with humans is one of the main challenges in AI. Within the Deep
Reinforcement Learning (DRL) field, this objective motivated multiple works on
embodied language use. However, current approaches focus on language as a
communication tool in very simplified and non-diverse social situations: the
&quot;naturalness&quot; of language is reduced to the concept of high vocabulary size and
variability. In this paper, we argue that aiming towards human-level AI
requires a broader set of key social skills: 1) language use in complex and
variable social contexts; 2) beyond language, complex embodied communication in
multimodal settings within constantly evolving social worlds. We explain how
concepts from cognitive sciences could help AI to draw a roadmap towards
human-like intelligence, with a focus on its social dimensions. As a first
step, we propose to expand current research to a broader set of core social
skills. To do this, we present SocialAI, a benchmark to assess the acquisition
of social skills of DRL agents using multiple grid-world environments featuring
other (scripted) social agents. We then study the limits of a recent SOTA DRL
approach when tested on SocialAI and discuss important next steps towards
proficient social agents. Videos and code are available at
https://sites.google.com/view/socialai.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nitish Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00753">
                                    <div class="article-summary-box-inner">
                                        <span>While pretrained language models achieve excellent performance on natural
language understanding benchmarks, they tend to rely on spurious correlations
and generalize poorly to out-of-distribution (OOD) data. Recent work has
explored using counterfactually-augmented data (CAD) -- data generated by
minimally perturbing examples to flip the ground-truth label -- to identify
robust features that are invariant under distribution shift. However, empirical
results using CAD for OOD generalization have been mixed. To explain this
discrepancy, we draw insights from a linear Gaussian model and demonstrate the
pitfalls of CAD. Specifically, we show that (a) while CAD is effective at
identifying robust features, it may prevent the model from learning unperturbed
robust features, and (b) CAD may exacerbate existing spurious correlations in
the data. Our results show that the lack of perturbation diversity in current
CAD datasets limits its effectiveness on OOD generalization, calling for
innovative crowdsourcing procedures to elicit diverse perturbation of examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Centric Domain Adaptation for Historical Text with OCR Errors. (arXiv:2107.00927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marz_L/0/1/0/all/0/1">Luisa M&#xe4;rz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schweter_S/0/1/0/all/0/1">Stefan Schweter</a>, <a href="http://arxiv.org/find/cs/1/au:+Poerner_N/0/1/0/all/0/1">Nina Poerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00927">
                                    <div class="article-summary-box-inner">
                                        <span>We propose new methods for in-domain and cross-domain Named Entity
Recognition (NER) on historical data for Dutch and French. For the cross-domain
case, we address domain shift by integrating unsupervised in-domain data via
contextualized string embeddings; and OCR errors by injecting synthetic OCR
errors into the source domain and address data centric domain adaptation. We
propose a general approach to imitate OCR errors in arbitrary input data. Our
cross-domain as well as our in-domain results outperform several strong
baselines and establish state-of-the-art results. We publish preprocessed
versions of the French and Dutch Europeana NER corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Token Pruning for Transformers. (arXiv:2107.00910v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sehoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Sheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorsley_D/0/1/0/all/0/1">David Thorsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1">Amir Gholami</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassoun_J/0/1/0/all/0/1">Joseph Hassoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00910">
                                    <div class="article-summary-box-inner">
                                        <span>A major challenge in deploying transformer models is their prohibitive
inference cost, which quadratically scales with the input sequence length. This
makes it especially difficult to use transformers for processing long
sequences. To address this, we present a novel Learned Token Pruning (LTP)
method that reduces redundant tokens as the data passes through the different
layers of the transformer. In particular, LTP prunes tokens with an attention
score below a threshold value, which is learned during training. Importantly,
our threshold based method avoids algorithmically expensive operations such as
top-k token selection which are used in prior token pruning methods, and also
leads to structured pruning. We extensively test the performance of our
approach on multiple GLUE tasks and show that our learned threshold based
method consistently outperforms the prior state-of-the-art top-k token based
method by up to ~2% higher accuracy with the same amount of FLOPs. Furthermore,
our preliminary results show up to 1.4x and 1.9x throughput improvement on
Tesla T4 GPU and Intel Haswell CPU, respectively, with less than 1% of accuracy
drop (and up to 2.1x FLOPs reduction). Our code has been developed in PyTorch
and has been open-sourced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions. (arXiv:2107.00789v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kambara_M/0/1/0/all/0/1">Motonari Kambara</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00789">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many studies in robotics to improve the communication skills
of domestic service robots. Most studies, however, have not fully benefited
from recent advances in deep neural networks because the training datasets are
not large enough. In this paper, our aim is to augment the datasets based on a
crossmodal language generation model. We propose the Case Relation Transformer
(CRT), which generates a fetching instruction sentence from an image, such as
&quot;Move the blue flip-flop to the lower left box.&quot; Unlike existing methods, the
CRT uses the Transformer to integrate the visual features and geometry features
of objects in the image. The CRT can handle the objects because of the Case
Relation Block. We conducted comparison experiments and a human evaluation. The
experimental results show the CRT outperforms baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Target-dependent UNITER: A Transformer-Based Multimodal Language Comprehension Model for Domestic Service Robots. (arXiv:2107.00811v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_S/0/1/0/all/0/1">Shintaro Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00811">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, domestic service robots have an insufficient ability to interact
naturally through language. This is because understanding human instructions is
complicated by various ambiguities and missing information. In existing
methods, the referring expressions that specify the relationships between
objects are insufficiently modeled. In this paper, we propose Target-dependent
UNITER, which learns the relationship between the target object and other
objects directly by focusing on the relevant regions within an image, rather
than the whole image. Our method is an extension of the UNITER-based
Transformer that can be pretrained on general-purpose datasets. We extend the
UNITER approach by introducing a new architecture for handling the target
candidates. Our model is validated on two standard datasets, and the results
show that Target-dependent UNITER outperforms the baseline method in terms of
classification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension. (arXiv:2107.00841v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jian-Cheng Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zi-Li Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yan-Yan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujita_H/0/1/0/all/0/1">Hamido Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00841">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-hop machine reading comprehension is a challenging task in natural
language processing, which requires more reasoning ability and explainability.
Spectral models based on graph convolutional networks grant the inferring
abilities and lead to competitive results, however, part of them still face the
challenge of analyzing the reasoning in a human-understandable way. Inspired by
the concept of the Grandmother Cells in cognitive neuroscience, a spatial graph
attention framework named crname, imitating the procedure was proposed. This
model is designed to assemble the semantic features in multi-angle
representations and automatically concentrate or alleviate the information for
reasoning. The name &quot;crname&quot; is a metaphor for the pattern of the model: regard
the subjects of queries as the start points of clues, take the reasoning
entities as bridge points, and consider the latent candidate entities as the
grandmother cells, and the clues end up in candidate entities. The proposed
model allows us to visualize the reasoning graph and analyze the importance of
edges connecting two entities and the selectivity in the mention and candidate
nodes, which can be easier to be comprehended empirically. The official
evaluations in open-domain multi-hop reading dataset WikiHop and Drug-drug
Interactions dataset MedHop prove the validity of our approach and show the
probability of the application of the model in the molecular biology domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Misinformation Detection on YouTube Using Video Captions. (arXiv:2107.00941v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jagtap_R/0/1/0/all/0/1">Raj Jagtap</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1">Rahul Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Shakshi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rajesh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+George_C/0/1/0/all/0/1">Clint P. George</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00941">
                                    <div class="article-summary-box-inner">
                                        <span>Millions of people use platforms such as YouTube, Facebook, Twitter, and
other mass media. Due to the accessibility of these platforms, they are often
used to establish a narrative, conduct propaganda, and disseminate
misinformation. This work proposes an approach that uses state-of-the-art NLP
techniques to extract features from video captions (subtitles). To evaluate our
approach, we utilize a publicly accessible and labeled dataset for classifying
videos as misinformation or not. The motivation behind exploring video captions
stems from our analysis of videos metadata. Attributes such as the number of
views, likes, dislikes, and comments are ineffective as videos are hard to
differentiate using this information. Using caption dataset, the proposed
models can classify videos among three classes (Misinformation, Debunking
Misinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the
relevance of the misinformation class, we re-formulate our classification
problem as a two-class classification - Misinformation vs. others (Debunking
Misinformation and Neutral). In our experiments, the proposed models can
classify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">He Thinks He Knows Better than the Doctors: BERT for Event Factuality Fails on Pragmatics. (arXiv:2107.00807v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nanjiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Marneffe_M/0/1/0/all/0/1">Marie-Catherine de Marneffe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00807">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate how well BERT performs on predicting factuality in several
existing English datasets, encompassing various linguistic constructions.
Although BERT obtains a strong performance on most datasets, it does so by
exploiting common surface patterns that correlate with certain factuality
labels, and it fails on instances where pragmatic reasoning is necessary.
Contrary to what the high performance suggests, we are still far from having a
robust system for factuality prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Primer on Pretrained Multilingual Language Models. (arXiv:2107.00676v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1">Sumanth Doddapaneni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1">Gowtham Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1">Anoop Kunchukuttan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratyush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1">Mitesh M. Khapra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00676">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual Language Models (MLLMs) such as mBERT, XLM, XLM-R, \textit{etc.}
have emerged as a viable option for bringing the power of pretraining to a
large number of languages. Given their success in zero shot transfer learning,
there has emerged a large body of work in (i) building bigger MLLMs covering a
large number of languages (ii) creating exhaustive benchmarks covering a wider
variety of tasks and languages for evaluating MLLMs (iii) analysing the
performance of MLLMs on monolingual, zero shot crosslingual and bilingual tasks
(iv) understanding the universal language patterns (if any) learnt by MLLMs and
(v) augmenting the (often) limited capacity of MLLMs to improve their
performance on seen or even unseen languages. In this survey, we review the
existing literature covering the above broad areas of research pertaining to
MLLMs. Based on our survey, we recommend some promising directions of future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive decoding of words from visual speech recognition models. (arXiv:2107.00692v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shillingford_B/0/1/0/all/0/1">Brendan Shillingford</a>, <a href="http://arxiv.org/find/cs/1/au:+Assael_Y/0/1/0/all/0/1">Yannis Assael</a>, <a href="http://arxiv.org/find/cs/1/au:+Denil_M/0/1/0/all/0/1">Misha Denil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00692">
                                    <div class="article-summary-box-inner">
                                        <span>This work describes an interactive decoding method to improve the performance
of visual speech recognition systems using user input to compensate for the
inherent ambiguity of the task. Unlike most phoneme-to-word decoding pipelines,
which produce phonemes and feed these through a finite state transducer, our
method instead expands words in lockstep, facilitating the insertion of
interaction points at each word position. Interaction points enable us to
solicit input during decoding, allowing users to interactively direct the
decoding process. We simulate the behavior of user input using an oracle to
give an automated evaluation, and show promise for the use of this method for
text input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-F: A Transformer network with effective methods for learning universal sentence representation. (arXiv:2107.00653v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00653">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer model is widely used in natural language processing for
sentence representation. However, the previous Transformer-based models focus
on function words that have limited meaning in most cases and could merely
extract high-level semantic abstraction features. In this paper, two approaches
are introduced to improve the performance of Transformers. We calculated the
attention score by multiplying the part-of-speech weight vector with the
correlation coefficient, which helps extract the words with more practical
meaning. The weight vector is obtained by the input text sequence based on the
importance of the part-of-speech. Furthermore, we fuse the features of each
layer to make the sentence representation results more comprehensive and
accurate. In experiments, we demonstrate the effectiveness of our model
Transformer-F on three standard text classification datasets. Experimental
results show that our proposed model significantly boosts the performance of
text classification as compared to the baseline model. Specifically, we obtain
a 5.28% relative improvement over the vanilla Transformer on the simple tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalizing Flow based Hidden Markov Models for Classification of Speech Phones with Explainability. (arXiv:2107.00730v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anubhab Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Honore_A/0/1/0/all/0/1">Antoine Honor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Saikat Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00730">
                                    <div class="article-summary-box-inner">
                                        <span>In pursuit of explainability, we develop generative models for sequential
data. The proposed models provide state-of-the-art classification results and
robust performance for speech phone classification. We combine modern neural
networks (normalizing flows) and traditional generative models (hidden Markov
models - HMMs). Normalizing flow-based mixture models (NMMs) are used to model
the conditional probability distribution given the hidden state in the HMMs.
Model parameters are learned through judicious combinations of time-tested
Bayesian learning methods and contemporary neural network learning methods. We
mainly combine expectation-maximization (EM) and mini-batch gradient descent.
The proposed generative models can compute likelihood of a data and hence
directly suitable for maximum-likelihood (ML) classification approach. Due to
structural flexibility of HMMs, we can use different normalizing flow models.
This leads to different types of HMMs providing diversity in data modeling
capacity. The diversity provides an opportunity for easy decision fusion from
different models. For a standard speech phone classification setup involving 39
phones (classes) and the TIMIT dataset, we show that the use of standard
features called mel-frequency-cepstral-coeffcients (MFCCs), the proposed
generative models, and the decision fusion together can achieve $86.6\%$
accuracy by generative training only. This result is close to state-of-the-art
results, for examples, $86.2\%$ accuracy of PyTorch-Kaldi toolkit [1], and
$85.1\%$ accuracy using light gated recurrent units [2]. We do not use any
discriminative learning approach and related sophisticated features in this
article.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Max-Mahalanobis Classifiers for Image Classification, Generation and More. (arXiv:2101.00122v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00122">
                                    <div class="article-summary-box-inner">
                                        <span>Joint Energy-based Model (JEM) of Grathwohl et al. shows that a standard
softmax classifier can be reinterpreted as an energy-based model (EBM) for the
joint distribution p(x,y); the resulting model can be optimized to improve
calibration, robustness, and out-of-distribution detection, while generating
samples rivaling the quality of recent GAN-based approaches. However, the
softmax classifier that JEM exploits is inherently discriminative and its
latent feature space is not well formulated as probabilistic distributions,
which may hinder its potential for image generation and incur training
instability. We hypothesize that generative classifiers, such as Linear
Discriminant Analysis (LDA), might be more suitable for image generation since
generative classifiers model the data generation process explicitly. This paper
therefore investigates an LDA classifier for image classification and
generation. In particular, the Max-Mahalanobis Classifier (MMC), a special case
of LDA, fits our goal very well. We show that our Generative MMC (GMMC) can be
trained discriminatively, generatively, or jointly for image classification and
generation. Extensive experiments on multiple datasets show that GMMC achieves
state-of-the-art discriminative and generative performances, while
outperforming JEM in calibration, adversarial robustness, and
out-of-distribution detection by a significant margin. Our source code is
available at https://github.com/sndnyang/GMMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NTIRE 2021 Multi-modal Aerial View Object Classification Challenge. (arXiv:2107.01189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jerrick Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nina_O/0/1/0/all/0/1">Oliver Nina</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Bob Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yuru Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songzheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiaqi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mengru Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gongzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Huanqia Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chengxue Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_S/0/1/0/all/0/1">Sol Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_C/0/1/0/all/0/1">Casian Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasarica_A/0/1/0/all/0/1">Alexandru Pasarica</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Yen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hung-Min Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiarui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jie Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Chia-Ying Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1">Michael Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Z/0/1/0/all/0/1">Zhongkai Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zihe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yifei_X/0/1/0/all/0/1">Xu Yifei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lehan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1">Min Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01189">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce the first Challenge on Multi-modal Aerial View
Object Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at
CVPR. This challenge is composed of two different tracks using EO andSAR
imagery. Both EO and SAR sensors possess different advantages and drawbacks.
The purpose of this competition is to analyze how to use both sets of sensory
information in complementary ways. We discuss the top methods submitted for
this competition and evaluate their results on our blind test set. Our
challenge results show significant improvement of more than 15% accuracy from
our current baselines for each track of the competition</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Learning Technique for Video Segmentation. (arXiv:2107.01153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianfei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1">Fatih Porikli</a>, <a href="http://arxiv.org/find/cs/1/au:+Crandall_D/0/1/0/all/0/1">David Crandall</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01153">
                                    <div class="article-summary-box-inner">
                                        <span>Video segmentation, i.e., partitioning video frames into multiple segments or
objects, plays a critical role in a broad range of practical applications,
e.g., visual effect assistance in movie, scene understanding in autonomous
driving, and virtual background creation in video conferencing, to name a few.
Recently, due to the renaissance of connectionism in computer vision, there has
been an influx of numerous deep learning based approaches that have been
dedicated to video segmentation and delivered compelling performance. In this
survey, we comprehensively review two basic lines of research in this area,
i.e., generic object segmentation (of unknown categories) in videos and video
semantic segmentation, by introducing their respective task settings,
background concepts, perceived need, development history, and main challenges.
We also provide a detailed overview of representative literature on both
methods and datasets. Additionally, we present quantitative performance
comparisons of the reviewed methods on benchmark datasets. At last, we point
out a set of unsolved open issues in this field, and suggest possible
opportunities for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Fire Detection in Landsat-8 Imagery: a Large-Scale Dataset and a Deep-Learning Study. (arXiv:2101.03409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Gabriel Henrique de Almeida Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusioka_A/0/1/0/all/0/1">Andr&#xe9; Minoro Fusioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassu_B/0/1/0/all/0/1">Bogdan Tomoyuki Nassu</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03409">
                                    <div class="article-summary-box-inner">
                                        <span>Active fire detection in satellite imagery is of critical importance to the
management of environmental conservation policies, supporting decision-making
and law enforcement. This is a well established field, with many techniques
being proposed over the years, usually based on pixel or region-level
comparisons involving sensor-specific thresholds and neighborhood statistics.
In this paper, we address the problem of active fire detection using deep
learning techniques. In recent years, deep learning techniques have been
enjoying an enormous success in many fields, but their use for active fire
detection is relatively new, with open questions and demand for datasets and
architectures for evaluation. This paper addresses these issues by introducing
a new large-scale dataset for active fire detection, with over 150,000 image
patches (more than 200 GB of data) extracted from Landsat-8 images captured
around the world in August and September 2020, containing wildfires in several
locations. The dataset was split in two parts, and contains 10-band spectral
images with associated outputs, produced by three well known handcrafted
algorithms for active fire detection in the first part, and manually annotated
masks in the second part. We also present a study on how different
convolutional neural network architectures can be used to approximate these
handcrafted algorithms, and how models trained on automatically segmented
patches can be combined to achieve better performance than the original
algorithms - with the best combination having 87.2% precision and 92.4% recall
on our manually annotated dataset. The proposed dataset, source codes and
trained models are available on Github
(https://github.com/pereira-gha/activefire), creating opportunities for further
advances in the field</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness for Image Generation with Uncertain Sensitive Attributes. (arXiv:2106.12182v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalal_A/0/1/0/all/0/1">Ajil Jalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1">Sushrut Karmalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1">Jessica Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1">Eric Price</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12182">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the issue of fairness in the context of generative
procedures, such as image super-resolution, which entail different definitions
from the standard classification setting. Moreover, while traditional group
fairness definitions are typically defined with respect to specified protected
groups -- camouflaging the fact that these groupings are artificial and carry
historical and political motivations -- we emphasize that there are no ground
truth identities. For instance, should South and East Asians be viewed as a
single group or separate groups? Should we consider one race as a whole or
further split by gender? Choosing which groups are valid and who belongs in
them is an impossible dilemma and being &quot;fair&quot; with respect to Asians may
require being &quot;unfair&quot; with respect to South Asians. This motivates the
introduction of definitions that allow algorithms to be \emph{oblivious} to the
relevant groupings.

We define several intuitive notions of group fairness and study their
incompatibilities and trade-offs. We show that the natural extension of
demographic parity is strongly dependent on the grouping, and \emph{impossible}
to achieve obliviously. On the other hand, the conceptually new definition we
introduce, Conditional Proportional Representation, can be achieved obliviously
through Posterior Sampling. Our experiments validate our theoretical results
and achieve fair image reconstruction using state-of-the-art generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-Time Deep Glioma Growth Models. (arXiv:2106.12917v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Petersen_J/0/1/0/all/0/1">Jens Petersen</a>, <a href="http://arxiv.org/find/eess/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohler_G/0/1/0/all/0/1">Gregor K&#xf6;hler</a>, <a href="http://arxiv.org/find/eess/1/au:+Jager_P/0/1/0/all/0/1">Paul F. J&#xe4;ger</a>, <a href="http://arxiv.org/find/eess/1/au:+Zimmerer_D/0/1/0/all/0/1">David Zimmerer</a>, <a href="http://arxiv.org/find/eess/1/au:+Neuberger_U/0/1/0/all/0/1">Ulf Neuberger</a>, <a href="http://arxiv.org/find/eess/1/au:+Wick_W/0/1/0/all/0/1">Wolfgang Wick</a>, <a href="http://arxiv.org/find/eess/1/au:+Debus_J/0/1/0/all/0/1">J&#xfc;rgen Debus</a>, <a href="http://arxiv.org/find/eess/1/au:+Heiland_S/0/1/0/all/0/1">Sabine Heiland</a>, <a href="http://arxiv.org/find/eess/1/au:+Bendszus_M/0/1/0/all/0/1">Martin Bendszus</a>, <a href="http://arxiv.org/find/eess/1/au:+Vollmuth_P/0/1/0/all/0/1">Philipp Vollmuth</a>, <a href="http://arxiv.org/find/eess/1/au:+Maier_Hein_K/0/1/0/all/0/1">Klaus H. Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12917">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to estimate how a tumor might evolve in the future could have
tremendous clinical benefits, from improved treatment decisions to better dose
distribution in radiation therapy. Recent work has approached the glioma growth
modeling problem via deep learning and variational inference, thus learning
growth dynamics entirely from a real patient data distribution. So far, this
approach was constrained to predefined image acquisition intervals and
sequences of fixed length, which limits its applicability in more realistic
scenarios. We overcome these limitations by extending Neural Processes, a class
of conditional generative models for stochastic time series, with a
hierarchical multi-scale representation encoding including a spatio-temporal
attention mechanism. The result is a learned growth model that can be
conditioned on an arbitrary number of observations, and that can produce a
distribution of temporally consistent growth trajectories on a continuous time
axis. On a dataset of 379 patients, the approach successfully captures both
global and finer-grained variations in the images, exhibiting superior
performance compared to other learned growth models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topo-boundary: A Benchmark Dataset on Topological Road-boundary Detection Using Aerial Images for Autonomous Driving. (arXiv:2103.17119v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhenhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17119">
                                    <div class="article-summary-box-inner">
                                        <span>Road-boundary detection is important for autonomous driving. It can be used
to constrain autonomous vehicles running on road areas to ensure driving
safety. Compared with online road-boundary detection using on-vehicle
cameras/Lidars, offline detection using aerial images could alleviate the
severe occlusion issue. Moreover, the offline detection results can be directly
employed to annotate high-definition (HD) maps. In recent years, deep-learning
technologies have been used in offline detection. But there still lacks a
publicly available dataset for this task, which hinders the research progress
in this area. So in this paper, we propose a new benchmark dataset, named
\textit{Topo-boundary}, for offline topological road-boundary detection. The
dataset contains 25,295 $1000\times1000$-sized 4-channel aerial images. Each
image is provided with 8 training labels for different sub-tasks. We also
design a new entropy-based metric for connectivity evaluation, which could
better handle noises or outliers. We implement and evaluate 3
segmentation-based baselines and 5 graph-based baselines using the dataset. We
also propose a new imitation-learning-based baseline which is enhanced from our
previous work. The superiority of our enhancement is demonstrated from the
comparison. The dataset and our-implemented code for the baselines are
available at \texttt{\url{https://tonyxuqaq.github.io/Topo-boundary/}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HandVoxNet++: 3D Hand Shape and Pose Estimation using Voxel-Based Neural Networks. (arXiv:2107.01205v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jameel Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimada_S/0/1/0/all/0/1">Soshi Shimada</a>, <a href="http://arxiv.org/find/cs/1/au:+Elhayek_A/0/1/0/all/0/1">Ahmed Elhayek</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sk Aziz Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01205">
                                    <div class="article-summary-box-inner">
                                        <span>3D hand shape and pose estimation from a single depth map is a new and
challenging computer vision problem with many applications. Existing methods
addressing it directly regress hand meshes via 2D convolutional neural
networks, which leads to artifacts due to perspective distortions in the
images. To address the limitations of the existing methods, we develop
HandVoxNet++, i.e., a voxel-based deep network with 3D and graph convolutions
trained in a fully supervised manner. The input to our network is a 3D
voxelized-depth-map-based on the truncated signed distance function (TSDF).
HandVoxNet++ relies on two hand shape representations. The first one is the 3D
voxelized grid of hand shape, which does not preserve the mesh topology and
which is the most accurate representation. The second representation is the
hand surface that preserves the mesh topology. We combine the advantages of
both representations by aligning the hand surface to the voxelized hand shape
either with a new neural Graph-Convolutions-based Mesh Registration
(GCN-MeshReg) or classical segment-wise Non-Rigid Gravitational Approach
(NRGA++) which does not rely on training data. In extensive evaluations on
three public benchmarks, i.e., SynHand5M, depth-based HANDS19 challenge and
HO-3D, the proposed HandVoxNet++ achieves the state-of-the-art performance. In
this journal extension of our previous approach presented at CVPR 2020, we gain
41.09% and 13.7% higher shape alignment accuracy on SynHand5M and HANDS19
datasets, respectively. Our method is ranked first on the HANDS19 challenge
dataset (Task 1: Depth-Based 3D Hand Pose Estimation) at the moment of the
submission of our results to the portal in August 2020.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Marching Cubes. (arXiv:2106.11272v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiqin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11272">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Neural Marching Cubes (NMC), a data-driven approach for
extracting a triangle mesh from a discretized implicit field. Classical MC is
defined by coarse tessellation templates isolated to individual cubes. While
more refined tessellations have been proposed, they all make heuristic
assumptions, such as trilinearity, when determining the vertex positions and
local mesh topologies in each cube. In principle, none of these approaches can
reconstruct geometric features that reveal coherence or dependencies between
nearby cubes (e.g., a sharp edge), as such information is unaccounted for,
resulting in poor estimates of the true underlying implicit field. To tackle
these challenges, we re-cast MC from a deep learning perspective, by designing
tessellation templates more apt at preserving geometric features, and learning
the vertex positions and mesh topologies from training meshes, to account for
contextual information from nearby cubes. We develop a compact per-cube
parameterization to represent the output triangle mesh, while being compatible
with neural processing, so that a simple 3D convolutional network can be
employed for the training. We show that all topological cases in each cube that
are applicable to our design can be easily derived using our representation,
and the resulting tessellations can also be obtained naturally and efficiently
by following a few design guidelines. In addition, our network learns local
features with limited receptive fields, hence it generalizes well to new shapes
and new datasets. We evaluate our neural MC approach by quantitative and
qualitative comparisons to all well-known MC variants. In particular, we
demonstrate the ability of our network to recover sharp features such as edges
and corners, a long-standing issue of MC and its variants. Our network also
reconstructs local mesh topologies more accurately than previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Plant Cover Estimation with Convolutional Neural Networks. (arXiv:2106.11154v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korschens_M/0/1/0/all/0/1">Matthias K&#xf6;rschens</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodesheim_P/0/1/0/all/0/1">Paul Bodesheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Romermann_C/0/1/0/all/0/1">Christine R&#xf6;mermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucher_S/0/1/0/all/0/1">Solveig Franziska Bucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Migliavacca_M/0/1/0/all/0/1">Mirco Migliavacca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulrich_J/0/1/0/all/0/1">Josephine Ulrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11154">
                                    <div class="article-summary-box-inner">
                                        <span>Monitoring the responses of plants to environmental changes is essential for
plant biodiversity research. This, however, is currently still being done
manually by botanists in the field. This work is very laborious, and the data
obtained is, though following a standardized method to estimate plant coverage,
usually subjective and has a coarse temporal resolution. To remedy these
caveats, we investigate approaches using convolutional neural networks (CNNs)
to automatically extract the relevant data from images, focusing on plant
community composition and species coverages of 9 herbaceous plant species. To
this end, we investigate several standard CNN architectures and different
pretraining methods. We find that we outperform our previous approach at higher
image resolutions using a custom CNN with a mean absolute error of 5.16%. In
addition to these investigations, we also conduct an error analysis based on
the temporal aspect of the plant cover images. This analysis gives insight into
where problems for automatic approaches lie, like occlusion and likely
misclassifications caused by temporal changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReGO: Reference-Guided Outpainting for Scenery Image. (arXiv:2106.10601v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xueming Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Li Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10601">
                                    <div class="article-summary-box-inner">
                                        <span>We aim to tackle the challenging yet practical scenery image outpainting task
in this work. Recently, generative adversarial learning has significantly
advanced the image outpainting by producing semantic consistent content for the
given image. However, the existing methods always suffer from the blurry
texture and the artifacts of the generative part, making the overall
outpainting results lack authenticity. To overcome the weakness, this work
investigates a principle way to synthesize texture-rich results by borrowing
pixels from its neighbors (\ie, reference images), named
\textbf{Re}ference-\textbf{G}uided \textbf{O}utpainting (ReGO). Particularly,
the ReGO designs an Adaptive Content Selection (ACS) module to transfer the
pixel of reference images for texture compensating of the target one. To
prevent the style of the generated part from being affected by the reference
images, a style ranking loss is further proposed to augment the ReGO to
synthesize style-consistent results. Extensive experiments on two popular
benchmarks, NS6K~\cite{yangzx} and NS8K~\cite{wang}, well demonstrate the
effectiveness of our ReGO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fourier Transform Approximation as an Auxiliary Task for Image Classification. (arXiv:2106.11478v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11478">
                                    <div class="article-summary-box-inner">
                                        <span>Image reconstruction is likely the most predominant auxiliary task for image
classification, but we would like to think twice about this convention. In this
paper, we investigated &quot;approximating the Fourier Transform of the input image&quot;
as a potential alternative, in the hope that it may further boost the
performances on the primary task or introduce novel constraints not well
covered by image reconstruction. We experimented with five popular
classification architectures on the CIFAR-10 dataset, and the empirical results
indicated that our proposed auxiliary task generally improves the
classification accuracy. More notably, the results showed that in certain cases
our proposed auxiliary task may enhance the classifiers&#x27; resistance to
adversarial attacks generated using the fast gradient sign method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Training Enhances Online Continual Learning. (arXiv:2103.14010v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gallardo_J/0/1/0/all/0/1">Jhair Gallardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1">Tyler L. Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1">Christopher Kanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14010">
                                    <div class="article-summary-box-inner">
                                        <span>In continual learning, a system must incrementally learn from a
non-stationary data stream without catastrophic forgetting. Recently, multiple
methods have been devised for incrementally learning classes on large-scale
image classification tasks, such as ImageNet. State-of-the-art continual
learning methods use an initial supervised pre-training phase, in which the
first 10% - 50% of the classes in a dataset are used to learn representations
in an offline manner before continual learning of new classes begins. We
hypothesize that self-supervised pre-training could yield features that
generalize better than supervised learning, especially when the number of
samples used for pre-training is small. We test this hypothesis using the
self-supervised MoCo-V2, Barlow Twins, and SwAV algorithms. On ImageNet, we
find that these methods outperform supervised pre-training considerably for
online continual learning, and the gains are larger when fewer samples are
available. Our findings are consistent across three online continual learning
algorithms. Our best system achieves a 14.95% relative increase in top-1
accuracy on class incremental ImageNet over the prior state of the art for
online continual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Clinical Outcomes in COVID-19 using Radiomics and Deep Learning on Chest Radiographs: A Multi-Institutional Study. (arXiv:2007.08028v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bae_J/0/1/0/all/0/1">Joseph Bae</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kapse_S/0/1/0/all/0/1">Saarthak Kapse</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gattu_R/0/1/0/all/0/1">Rishabh Gattu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Syed Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shah_N/0/1/0/all/0/1">Neal Shah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marshall_C/0/1/0/all/0/1">Colin Marshall</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pierce_J/0/1/0/all/0/1">Jonathan Pierce</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Phatak_T/0/1/0/all/0/1">Tej Phatak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1">Amit Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Green_J/0/1/0/all/0/1">Jeremy Green</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Madan_N/0/1/0/all/0/1">Nikhil Madan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Prasanna_P/0/1/0/all/0/1">Prateek Prasanna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08028">
                                    <div class="article-summary-box-inner">
                                        <span>We predict mechanical ventilation requirement and mortality using
computational modeling of chest radiographs (CXRs) for coronavirus disease 2019
(COVID-19) patients. This two-center, retrospective study analyzed 530
deidentified CXRs from 515 COVID-19 patients treated at Stony Brook University
Hospital and Newark Beth Israel Medical Center between March and August 2020.
DL and machine learning classifiers to predict mechanical ventilation
requirement and mortality were trained and evaluated using patient CXRs. A
novel radiomic embedding framework was also explored for outcome prediction.
All results are compared against radiologist grading of CXRs (zone-wise expert
severity scores). Radiomic and DL classification models had mAUCs of
0.78+/-0.02 and 0.81+/-0.04, compared with expert scores mAUCs of 0.75+/-0.02
and 0.79+/-0.05 for mechanical ventilation requirement and mortality
prediction, respectively. Combined classifiers using both radiomics and expert
severity scores resulted in mAUCs of 0.79+/-0.04 and 0.83+/-0.04 for each
prediction task, demonstrating improvement over either artificial intelligence
or radiologist interpretation alone. Our results also suggest instances where
inclusion of radiomic features in DL improves model predictions, something that
might be explored in other pathologies. The models proposed in this study and
the prognostic information they provide might aid physician decision making and
resource allocation during the COVID-19 pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Outlier-Robust Estimation: Hardness, Minimally Tuned Algorithms, and Applications. (arXiv:2007.15109v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonante_P/0/1/0/all/0/1">Pasquale Antonante</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzoumas_V/0/1/0/all/0/1">Vasileios Tzoumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Heng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlone_L/0/1/0/all/0/1">Luca Carlone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15109">
                                    <div class="article-summary-box-inner">
                                        <span>Nonlinear estimation in robotics and vision is typically plagued with
outliers due to wrong data association, or to incorrect detections from signal
processing and machine learning methods. This paper introduces two unifying
formulations for outlier-robust estimation, Generalized Maximum Consensus
(G-MC) and Generalized Truncated Least Squares (G-TLS), and investigates
fundamental limits, practical algorithms, and applications. Our first
contribution is a proof that outlier-robust estimation is inapproximable: in
the worst case, it is impossible to (even approximately) find the set of
outliers, even with slower-than-polynomial-time algorithms (particularly,
algorithms running in quasi-polynomial time). As a second contribution, we
review and extend two general-purpose algorithms. The first, Adaptive Trimming
(ADAPT), is combinatorial, and is suitable for G-MC; the second, Graduated
Non-Convexity (GNC), is based on homotopy methods, and is suitable for G-TLS.
We extend ADAPT and GNC to the case where the user does not have prior
knowledge of the inlier-noise statistics (or the statistics may vary over time)
and is unable to guess a reasonable threshold to separate inliers from outliers
(as the one commonly used in RANSAC). We propose the first minimally tuned
algorithms for outlier rejection, that dynamically decide how to separate
inliers from outliers. Our third contribution is an evaluation of the proposed
algorithms on robot perception problems: mesh registration, image-based object
detection (shape alignment), and pose graph optimization. ADAPT and GNC execute
in real-time, are deterministic, outperform RANSAC, and are robust up to 80-90%
outliers. Their minimally tuned versions also compare favorably with the state
of the art, even though they do not rely on a noise bound for the inliers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VMAF And Variants: Towards A Unified VQA. (arXiv:2103.07770v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Topiwala_P/0/1/0/all/0/1">Pankaj Topiwala</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_W/0/1/0/all/0/1">Wei Dai</a>, <a href="http://arxiv.org/find/eess/1/au:+Pian_J/0/1/0/all/0/1">Jiangfeng Pian</a>, <a href="http://arxiv.org/find/eess/1/au:+Biondi_K/0/1/0/all/0/1">Katalina Biondi</a>, <a href="http://arxiv.org/find/eess/1/au:+Krovvidi_A/0/1/0/all/0/1">Arvind Krovvidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07770">
                                    <div class="article-summary-box-inner">
                                        <span>Video quality assessment (VQA) is now a fastgrowing subject, beginning to
mature in the full reference (FR) case, while the burgeoning no reference (NR)
case remains challenging. We investigate variants of the popular VMAF video
quality assessment algorithm for the FR case, using support vector regression
and feedforward neural networks, and extend it to the NR case, using the same
learning architectures, to develop a partially unified framework for VQA. When
heavily trained, algorithms such as VMAF perform well on test datasets, with
90%+ match; but predicting performance in the wild is better done by
training/testing from scratch, as we do. Even from scratch, we achieve 90%+
performance in FR, with gains over VMAF. And we greatly reduce complexity vs.
leading recent NR algorithms, VIDEVAL, RAPIQUE, yet exceed 80% in SRCC. In our
preliminary testing, we find the improvements in trainability, while also
constraining computational complexity, as quite encouraging, suggesting further
study and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointGuard: Provably Robust 3D Point Cloud Classification. (arXiv:2103.03046v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jinyuan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03046">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud classification has many safety-critical applications such as
autonomous driving and robotic grasping. However, several studies showed that
it is vulnerable to adversarial attacks. In particular, an attacker can make a
classifier predict an incorrect label for a 3D point cloud via carefully
modifying, adding, and/or deleting a small number of its points. Randomized
smoothing is state-of-the-art technique to build certifiably robust 2D image
classifiers. However, when applied to 3D point cloud classification, randomized
smoothing can only certify robustness against adversarially modified points.

In this work, we propose PointGuard, the first defense that has provable
robustness guarantees against adversarially modified, added, and/or deleted
points. Specifically, given a 3D point cloud and an arbitrary point cloud
classifier, our PointGuard first creates multiple subsampled point clouds, each
of which contains a random subset of the points in the original point cloud;
then our PointGuard predicts the label of the original point cloud as the
majority vote among the labels of the subsampled point clouds predicted by the
point cloud classifier. Our first major theoretical contribution is that we
show PointGuard provably predicts the same label for a 3D point cloud when the
number of adversarially modified, added, and/or deleted points is bounded. Our
second major theoretical contribution is that we prove the tightness of our
derived bound when no assumptions on the point cloud classifier are made.
Moreover, we design an efficient algorithm to compute our certified robustness
guarantees. We also empirically evaluate PointGuard on ModelNet40 and ScanNet
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The 2021 Image Similarity Dataset and Challenge. (arXiv:2106.09672v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolias_G/0/1/0/all/0/1">Giorgos Tolias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pizzi_E/0/1/0/all/0/1">Ed Pizzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papakipos_Z/0/1/0/all/0/1">Zo&#xeb; Papakipos</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_L/0/1/0/all/0/1">Lowik Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Radenovic_F/0/1/0/all/0/1">Filip Radenovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenicek_T/0/1/0/all/0/1">Tomas Jenicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Maximov_M/0/1/0/all/0/1">Maxim Maximov</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1">Ismail Elezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chum_O/0/1/0/all/0/1">Ond&#x159;ej Chum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09672">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a new benchmark for large-scale image similarity
detection. This benchmark is used for the Image Similarity Challenge at
NeurIPS&#x27;21 (ISC2021). The goal is to determine whether a query image is a
modified copy of any image in a reference corpus of size 1~million. The
benchmark features a variety of image transformations such as automated
transformations, hand-crafted image edits and machine-learning based
manipulations. This mimics real-life cases appearing in social media, for
example for integrity-related problems dealing with misinformation and
objectionable content. The strength of the image manipulations, and therefore
the difficulty of the benchmark, is calibrated according to the performance of
a set of baseline approaches. Both the query and reference set contain a
majority of &quot;distractor&quot; images that do not match, which corresponds to a
real-life needle-in-haystack setting, and the evaluation metric reflects that.
We expect the DISC21 benchmark to promote image copy detection as an important
and challenging computer vision task and refresh the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.410 for valence and 0.661 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Relationship Forecasting in Videos. (arXiv:2107.01181v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mi_L/0/1/0/all/0/1">Li Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1">Yangjun Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01181">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world scenarios often require the anticipation of object interactions in
unknown future, which would assist the decision-making process of both humans
and agents. To meet this challenge, we present a new task named Visual
Relationship Forecasting (VRF) in videos to explore the prediction of visual
relationships in a reasoning manner. Specifically, given a subject-object pair
with H existing frames, VRF aims to predict their future interactions for the
next T frames without visual evidence. To evaluate the VRF task, we introduce
two video datasets named VRF-AG and VRF-VidOR, with a series of
spatio-temporally localized visual relation annotations in a video. These two
datasets densely annotate 13 and 35 visual relationships in 1923 and 13447
video clips, respectively. In addition, we present a novel Graph Convolutional
Transformer (GCT) framework, which captures both object-level and frame-level
dependencies by spatio-temporal Graph Convolution Network and Transformer.
Experimental results on both VRF-AG and VRF-VidOR datasets demonstrate that GCT
outperforms the state-of-the-art sequence modelling methods on visual
relationship forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Representation Learning for Hand Shape Estimation. (arXiv:2106.04324v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_C/0/1/0/all/0/1">Christian Zimmermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Argus_M/0/1/0/all/0/1">Max Argus</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04324">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents improvements in monocular hand shape estimation by
building on top of recent advances in unsupervised learning. We extend momentum
contrastive learning and contribute a structured collection of hand images,
well suited for visual representation learning, which we call HanCo. We find
that the representation learned by established contrastive learning methods can
be improved significantly by exploiting advanced background removal techniques
and multi-view information. These allow us to generate more diverse instance
pairs than those obtained by augmentations commonly used in exemplar based
approaches. Our method leads to a more suitable representation for the hand
shape estimation task and shows a 4.7% reduction in mesh error and a 3.6%
improvement in F-score compared to an ImageNet pretrained baseline. We make our
benchmark dataset publicly available, to encourage further research into this
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of Loss Functions to Improve Generalizability of Deep Metric Learning methods. (arXiv:2107.01130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01130">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Metric Learning (DML) learns a non-linear semantic embedding from input
data that brings similar pairs together while keeps dissimilar data away from
each other. To this end, many different methods are proposed in the last decade
with promising results in various applications. The success of a DML algorithm
greatly depends on its loss function. However, no loss function is perfect, and
it deals only with some aspects of an optimal similarity embedding. Besides,
the generalizability of the DML on unseen categories during the test stage is
an important matter that is not considered by existing loss functions. To
address these challenges, we propose novel approaches to combine different
losses built on top of a shared deep feature extractor. The proposed ensemble
of losses enforces the deep model to extract features that are consistent with
all losses. Since the selected losses are diverse and each emphasizes different
aspects of an optimal semantic embedding, our effective combining methods yield
a considerable improvement over any individual loss and generalize well on
unseen categories. Here, there is no limitation in choosing loss functions, and
our methods can work with any set of existing ones. Besides, they can optimize
each loss function as well as its weight in an end-to-end paradigm with no need
to adjust any hyper-parameter. We evaluate our methods on some popular datasets
from the machine vision domain in conventional Zero-Shot-Learning (ZSL)
settings. The results are very encouraging and show that our methods outperform
all baseline losses by a large margin in all datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Incomplete is Contrastive Learning? AnInter-intra Variant Dual Representation Method forSelf-supervised Video Recognition. (arXiv:2107.01194v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhengyang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01194">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning applied to self-supervised representation learning has
seen a resurgence in deep models. In this paper, we find that existing
contrastive learning based solutions for self-supervised video recognition
focus on inter-variance encoding but ignore the intra-variance existing in
clips within the same video. We thus propose to learn dual representations for
each clip which (\romannumeral 1) encode intra-variance through a shuffle-rank
pretext task; (\romannumeral 2) encode inter-variance through a temporal
coherent contrastive loss. Experiment results show that our method plays an
essential role in balancing inter and intra variances and brings consistent
performance gains on multiple backbones and contrastive learning frameworks.
Integrated with SimCLR and pretrained on Kinetics-400, our method achieves
$\textbf{82.0\%}$ and $\textbf{51.2\%}$ downstream classification accuracy on
UCF101 and HMDB51 test sets respectively and $\textbf{46.1\%}$ video retrieval
accuracy on UCF101, outperforming both pretext-task based and contrastive
learning based counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSN: Multi-Style Network for Trajectory Prediction. (arXiv:2107.00932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1">Conghao Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_B/0/1/0/all/0/1">Beihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qinmu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+You_X/0/1/0/all/0/1">Xinge You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00932">
                                    <div class="article-summary-box-inner">
                                        <span>It is essential but challenging to predict future trajectories of various
agents in complex scenes. Whether it is internal personality factors of agents,
interactive behavior of the neighborhood, or the influence of surroundings, it
will have an impact on their future behavior styles. It means that even for the
same physical type of agents, there are huge differences in their behavior
preferences. Although recent works have made significant progress in studying
agents&#x27; multi-modal plannings, most of them still apply the same prediction
strategy to all agents, which makes them difficult to fully show the multiple
styles of vast agents. In this paper, we propose the Multi-Style Network (MSN)
to focus on this problem by divide agents&#x27; preference styles into several
hidden behavior categories adaptively and train each category&#x27;s prediction
network separately, therefore giving agents all styles of predictions
simultaneously. Experiments demonstrate that our deterministic MSN-D and
generative MSN-G outperform many recent state-of-the-art methods and show
better multi-style characteristics in the visualized results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1">Zenglin Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mettes_P/0/1/0/all/0/1">Pascal Mettes</a>, <a href="http://arxiv.org/find/eess/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>, <a href="http://arxiv.org/find/eess/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01125">
                                    <div class="article-summary-box-inner">
                                        <span>The deep image prior has demonstrated the remarkable ability that untrained
networks can address inverse imaging problems, such as denoising, inpainting
and super-resolution, by optimizing on just a single degraded image. Despite
its promise, it suffers from two limitations. First, it remains unclear how one
can control the prior beyond the choice of the network architecture. Second, it
requires an oracle to determine when to stop the optimization as the
performance degrades after reaching a peak. In this paper, we study the deep
image prior from a spectral bias perspective to address these problems. By
introducing a frequency-band correspondence measure, we observe that deep image
priors for inverse imaging exhibit a spectral bias during optimization, where
low-frequency image signals are learned faster and better than high-frequency
noise signals. This pinpoints why degraded images can be denoised or inpainted
when the optimization is stopped at the right time. Based on our observations,
we propose to control the spectral bias in the deep image prior to prevent
performance degradation and to speed up optimization convergence. We do so in
the two core layer types of inverse imaging networks: the convolution layer and
the upsampling layer. We present a Lipschitz-controlled approach for the
convolution and a Gaussian-controlled approach for the upsampling layer. We
further introduce a stopping criterion to avoid superfluous computation. The
experiments on denoising, inpainting and super-resolution show that our method
no longer suffers from performance degradation during optimization, relieving
us from the need for an oracle criterion to stop early. We further outline a
stopping criterion to avoid superfluous computation. Finally, we show that our
approach obtains favorable restoration results compared to current approaches,
across all tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive Learners With FlatNCE. (arXiv:2107.01152v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1">Liqun Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Shuyang Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_T/0/1/0/all/0/1">Tagyoung Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_B/0/1/0/all/0/1">Belinda Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_W/0/1/0/all/0/1">Wenlian Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01152">
                                    <div class="article-summary-box-inner">
                                        <span>InfoNCE-based contrastive representation learners, such as SimCLR, have been
tremendously successful in recent years. However, these contrastive schemes are
notoriously resource demanding, as their effectiveness breaks down with
small-batch training (i.e., the log-K curse, whereas K is the batch-size). In
this work, we reveal mathematically why contrastive learners fail in the
small-batch-size regime, and present a novel simple, non-trivial contrastive
objective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no
longer explicitly appeals to a discriminative classification goal for
contrastive learning. Theoretically, we show FlatNCE is the mathematical dual
formulation of InfoNCE, thus bridging the classical literature on energy
modeling; and empirically, we demonstrate that, with minimal modification of
code, FlatNCE enables immediate performance boost independent of the
subject-matter engineering efforts. The significance of this work is furthered
by the powerful generalization of contrastive learning techniques, and the
introduction of new tools to monitor and diagnose contrastive training. We
substantiate our claims with empirical evidence on CIFAR10, ImageNet, and other
datasets, where FlatNCE consistently outperforms InfoNCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sub-millisecond Video Synchronization of Multiple Android Smartphones. (arXiv:2107.00987v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhmetyanov_A/0/1/0/all/0/1">Azat Akhmetyanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kornilova_A/0/1/0/all/0/1">Anastasiia Kornilova</a>, <a href="http://arxiv.org/find/cs/1/au:+Faizullin_M/0/1/0/all/0/1">Marsel Faizullin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pozo_D/0/1/0/all/0/1">David Pozo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_G/0/1/0/all/0/1">Gonzalo Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00987">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of building an affordable easy-to-setup
synchronized multi-view camera system, which is in demand for many Computer
Vision and Robotics applications in high-dynamic environments. In our work, we
propose a solution for this problem - a publicly-available Android application
for synchronized video recording on multiple smartphones with sub-millisecond
accuracy. We present a generalized mathematical model of timestamping for
Android smartphones and prove its applicability on 47 different physical
devices. Also, we estimate the time drift parameter for those smartphones,
which is less than 1.2 millisecond per minute for most of the considered
devices, that makes smartphones&#x27; camera system a worthy analog for professional
multi-view systems. Finally, we demonstrate Android-app performance on the
camera system built from Android smartphones quantitatively, showing less than
300 microseconds synchronization error, and qualitatively - on panorama
stitching task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of end-to-end neural network architectures and data augmentation methods for automatic infant motility assessment using wearable sensors. (arXiv:2107.01086v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Airaksinen_M/0/1/0/all/0/1">Manu Airaksinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanhatalo_S/0/1/0/all/0/1">Sampsa Vanhatalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasanen_O/0/1/0/all/0/1">Okko R&#xe4;s&#xe4;nen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01086">
                                    <div class="article-summary-box-inner">
                                        <span>Infant motility assessment using intelligent wearables is a promising new
approach for assessment of infant neurophysiological development, and where
efficient signal analysis plays a central role. This study investigates the use
of different end-to-end neural network architectures for processing infant
motility data from wearable sensors. We focus on the performance and
computational burden of alternative sensor encoder and time-series modelling
modules and their combinations. In addition, we explore the benefits of data
augmentation methods in ideal and non-ideal recording conditions. The
experiments are conducted using a data-set of multi-sensor movement recordings
from 7-month-old infants, as captured by a recently proposed smart jumpsuit for
infant motility assessment. Our results indicate that the choice of the encoder
module has a major impact on classifier performance. For sensor encoders, the
best performance was obtained with parallel 2-dimensional convolutions for
intra-sensor channel fusion with shared weights for all sensors. The results
also indicate that a relatively compact feature representation is obtainable
for within-sensor feature extraction without a drastic loss to classifier
performance. Comparison of time-series models revealed that feed-forward
dilated convolutions with residual and skip connections outperformed all
RNN-based models in performance, training time, and training stability. The
experiments also indicate that data augmentation improves model robustness in
simulated packet loss or sensor dropout scenarios. In particular, signal- and
sensor-dropout-based augmentation strategies provided considerable boosts to
performance without negatively affecting the baseline performance. Overall the
results provide tangible suggestions on how to optimize end-to-end neural
network training for multi-channel movement sensor data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-view Geo-localization with Evolving Transformer. (arXiv:2107.00842v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongji Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiufan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yingying Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00842">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of cross-view geo-localization, which
estimates the geospatial location of a street view image by matching it with a
database of geo-tagged aerial images. The cross-view matching task is extremely
challenging due to drastic appearance and geometry differences across views.
Unlike existing methods that predominantly fall back on CNN, here we devise a
novel evolving geo-localization Transformer (EgoTR) that utilizes the
properties of self-attention in Transformer to model global dependencies, thus
significantly decreasing visual ambiguities in cross-view geo-localization. We
also exploit the positional encoding of Transformer to help the EgoTR
understand and correspond geometric configurations between ground and aerial
images. Compared to state-of-the-art methods that impose strong assumption on
geometry knowledge, the EgoTR flexibly learns the positional embeddings through
the training objective and hence becomes more practical in many real-world
scenarios. Although Transformer is well suited to our task, its vanilla
self-attention mechanism independently interacts within image patches in each
layer, which overlooks correlations between layers. Instead, this paper propose
a simple yet effective self-cross attention mechanism to improve the quality of
learned representations. The self-cross attention models global dependencies
between adjacent layers, which relates between image patches while modeling how
features evolve in the previous layer. As a result, the proposed self-cross
attention leads to more stable training, improves the generalization ability
and encourages representations to keep evolving as the network goes deeper.
Extensive experiments demonstrate that our EgoTR performs favorably against
state-of-the-art methods on standard, fine-grained and cross-dataset cross-view
geo-localization tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning. (arXiv:2107.00968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suwannaphong_T/0/1/0/all/0/1">Thanaphon Suwannaphong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavana_S/0/1/0/all/0/1">Sawaphob Chavana</a>, <a href="http://arxiv.org/find/cs/1/au:+Tongsom_S/0/1/0/all/0/1">Sahapol Tongsom</a>, <a href="http://arxiv.org/find/cs/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00968">
                                    <div class="article-summary-box-inner">
                                        <span>Intestinal parasitic infection leads to several morbidities to humans
worldwide, especially in tropical countries. The traditional diagnosis usually
relies on manual analysis from microscopic images which is prone to human error
due to morphological similarity of different parasitic eggs and abundance of
impurities in a sample. Many studies have developed automatic systems for
parasite egg detection to reduce human workload. However, they work with high
quality microscopes, which unfortunately remain unaffordable in some rural
areas. Our work thus exploits a benefit of a low-cost USB microscope. This
instrument however provides poor quality of images due to limitation of
magnification (10x), causing difficulty in parasite detection and species
classification. In this paper, we propose a CNN-based technique using transfer
learning strategy to enhance the efficiency of automatic parasite
classification in poor-quality microscopic images. The patch-based technique
with sliding window is employed to search for location of the eggs. Two
networks, AlexNet and ResNet50, are examined with a trade-off between
architecture size and classification performance. The results show that our
proposed framework outperforms the state-of-the-art object recognition methods.
Our system combined with final decision from an expert may improve the real
faecal examination with low-cost microscopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Visual Navigation. (arXiv:2107.01151v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haiyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xizhou Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01151">
                                    <div class="article-summary-box-inner">
                                        <span>As a fundamental problem for Artificial Intelligence, multi-agent system
(MAS) is making rapid progress, mainly driven by multi-agent reinforcement
learning (MARL) techniques. However, previous MARL methods largely focused on
grid-world like or game environments; MAS in visually rich environments has
remained less explored. To narrow this gap and emphasize the crucial role of
perception in MAS, we propose a large-scale 3D dataset, CollaVN, for
multi-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed
to cooperatively navigate across photo-realistic environments to reach target
locations. Diverse MAVN variants are explored to make our problem more general.
Moreover, a memory-augmented communication framework is proposed. Each agent is
equipped with a private, external memory to persistently store communication
information. This allows agents to make better use of their past communication
information, enabling more efficient collaboration and robust long-term
planning. In our experiments, several baselines and evaluation metrics are
designed. We also empirically verify the efficacy of our proposed MARL approach
across different MAVN task settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optical Braille Recognition using Circular Hough Transform. (arXiv:2107.00993v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khanam_Z/0/1/0/all/0/1">Zeba Khanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Usmani_A/0/1/0/all/0/1">Atiya Usmani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00993">
                                    <div class="article-summary-box-inner">
                                        <span>Braille has empowered visually challenged community to read and write. But at
the same time, it has created a gap due to widespread inability of non-Braille
users to understand Braille scripts. This gap has fuelled researchers to
propose Optical Braille Recognition techniques to convert Braille documents to
natural language. The main motivation of this work is to cement the
communication gap at academic institutions by translating personal documents of
blind students. This has been accomplished by proposing an economical and
effective technique which digitizes Braille documents using a smartphone
camera. For any given Braille image, a dot detection mechanism based on Hough
transform is proposed which is invariant to skewness, noise and other
deterrents. The detected dots are then clustered into Braille cells using
distance-based clustering algorithm. In succession, the standard physical
parameters of each Braille cells are estimated for feature extraction and
classification as natural language characters. The comprehensive evaluation of
this technique on the proposed dataset of 54 Braille scripts has yielded into
accuracy of 98.71%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation. (arXiv:2107.01079v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammernik_K/0/1/0/all/0/1">Kerstin Hammernik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01079">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based segmentation methods are vulnerable to unforeseen data
distribution shifts during deployment, e.g. change of image appearances or
contrasts caused by different scanners, unexpected imaging artifacts etc. In
this paper, we present a cooperative framework for training image segmentation
models and a latent space augmentation method for generating hard examples.
Both contributions improve model generalization and robustness with limited
data. The cooperative training framework consists of a fast-thinking network
(FTN) and a slow-thinking network (STN). The FTN learns decoupled image
features and shape features for image reconstruction and segmentation tasks.
The STN learns shape priors for segmentation correction and refinement. The two
networks are trained in a cooperative manner. The latent space augmentation
generates challenging examples for training by masking the decoupled latent
space in both channel-wise and spatial-wise manners. We performed extensive
experiments on public cardiac imaging datasets. Using only 10 subjects from a
single site for training, we demonstrated improved cross-site segmentation
performance and increased robustness against various unforeseen imaging
artifacts compared to strong baseline methods. Particularly, cooperative
training with latent space data augmentation yields 15% improvement in terms of
average Dice score when compared to a standard training method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise Labels. (arXiv:2107.01002v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karmanov_I/0/1/0/all/0/1">Ilia Karmanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanjani_F/0/1/0/all/0/1">Farhad G. Zanjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlin_S/0/1/0/all/0/1">Simone Merlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadampot_I/0/1/0/all/0/1">Ishaque Kadampot</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijkman_D/0/1/0/all/0/1">Daniel Dijkman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01002">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce WiCluster, a new machine learning (ML) approach for passive
indoor positioning using radio frequency (RF) channel state information (CSI).
WiCluster can predict both a zone-level position and a precise 2D or 3D
position, without using any precise position labels during training. Prior
CSI-based indoor positioning work has relied on non-parametric approaches using
digital signal-processing (DSP) and, more recently, parametric approaches
(e.g., fully supervised ML methods). However these do not handle the complexity
of real-world environments well and do not meet requirements for large-scale
commercial deployments: the accuracy of DSP-based method deteriorates
significantly in non-line-of-sight conditions, while supervised ML methods need
large amounts of hard-to-acquire centimeter accuracy position labels. In
contrast, WiCluster is both precise and requires weaker label-information that
can be easily collected. Our first contribution is a novel dimensionality
reduction method for charting. It combines a triplet-loss with a multi-scale
clustering-loss to map the high-dimensional CSI representation to a 2D/3D
latent space. Our second contribution is two weakly supervised losses that map
this latent space into a Cartesian map, resulting in meter-accuracy position
results. These losses only require simple to acquire priors: a sketch of the
floorplan, approximate location of access-point locations and a few CSI packets
that are labeled with the corresponding zone in the floorplan. Thirdly, we
report results and a robustness study for 2D positioning in a single-floor
office building and 3D positioning in a two-floor home to show the robustness
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Usefulness of Unsupervised monitoring in Cultural Heritage Monuments. (arXiv:2107.00964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafeiropoulos_C/0/1/0/all/0/1">Charalampos Zafeiropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzortzis_I/0/1/0/all/0/1">Ioannis N. Tzortzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rallis_I/0/1/0/all/0/1">Ioannis Rallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Protopapadakis_E/0/1/0/all/0/1">Eftychios Protopapadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1">Nikolaos Doulamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1">Anastasios Doulamis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00964">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we scrutinize the effectiveness of various clustering
techniques, investigating their applicability in Cultural Heritage monitoring
applications. In the context of this paper, we detect the level of
decomposition and corrosion on the walls of Saint Nicholas fort in Rhodes
utilizing hyperspectral images. A total of 6 different clustering approaches
have been evaluated over a set of 14 different orthorectified hyperspectral
images. Experimental setup in this study involves K-means, Spectral, Meanshift,
DBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate
its performance by the use of performance metrics such as Calinski-Harabasz,
Davies-Bouldin indexes and Silhouette value. In this approach, we evaluate the
outcomes of the clustering methods by comparing them with a set of annotated
images which denotes the ground truth regarding the decomposition and/or
corrosion area of the original images. The results depict that a few clustering
techniques applied on the given dataset succeeded decent accuracy, precision,
recall and f1 scores. Eventually, it was observed that the deterioration was
detected quite accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LensID: A CNN-RNN-Based Framework Towards Lens Irregularity Detection in Cataract Surgery Videos. (arXiv:2107.00875v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ghamsarian_N/0/1/0/all/0/1">Negin Ghamsarian</a>, <a href="http://arxiv.org/find/eess/1/au:+Taschwer_M/0/1/0/all/0/1">Mario Taschwer</a>, <a href="http://arxiv.org/find/eess/1/au:+Putzgruber_Adamitsch_D/0/1/0/all/0/1">Doris Putzgruber-Adamitsch</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarny_S/0/1/0/all/0/1">Stephanie Sarny</a>, <a href="http://arxiv.org/find/eess/1/au:+El_Shabrawi_Y/0/1/0/all/0/1">Yosuf El-Shabrawi</a>, <a href="http://arxiv.org/find/eess/1/au:+Schoeffmann_K/0/1/0/all/0/1">Klaus Schoeffmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00875">
                                    <div class="article-summary-box-inner">
                                        <span>A critical complication after cataract surgery is the dislocation of the lens
implant leading to vision deterioration and eye trauma. In order to reduce the
risk of this complication, it is vital to discover the risk factors during the
surgery. However, studying the relationship between lens dislocation and its
suspicious risk factors using numerous videos is a time-extensive procedure.
Hence, the surgeons demand an automatic approach to enable a larger-scale and,
accordingly, more reliable study. In this paper, we propose a novel framework
as the major step towards lens irregularity detection. In particular, we
propose (I) an end-to-end recurrent neural network to recognize the
lens-implantation phase and (II) a novel semantic segmentation network to
segment the lens and pupil after the implantation phase. The phase recognition
results reveal the effectiveness of the proposed surgical phase recognition
approach. Moreover, the segmentation results confirm the proposed segmentation
network&#x27;s effectiveness compared to state-of-the-art rival approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Christopher M. Jermaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00961">
                                    <div class="article-summary-box-inner">
                                        <span>We propose {\rm \texttt{ResIST}}, a novel distributed training protocol for
Residual Networks (ResNets). {\rm \texttt{ResIST}} randomly decomposes a global
ResNet into several shallow sub-ResNets that are trained independently in a
distributed manner for several local iterations, before having their updates
synchronized and aggregated into the global model. In the next round, new
sub-ResNets are randomly generated and the process repeats. By construction,
per iteration, {\rm \texttt{ResIST}} communicates only a small portion of
network parameters to each machine and never uses the full model during
training. Thus, {\rm \texttt{ResIST}} reduces the communication, memory, and
time requirements of ResNet training to only a fraction of the requirements of
previous methods. In comparison to common protocols like data-parallel training
and data-parallel training with local SGD, {\rm \texttt{ResIST}} yields a
decrease in wall-clock training time, while being competitive with respect to
model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Single Image Super-resolution Under Complex Noise. (arXiv:2107.00986v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zongsheng Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jianwen Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00986">
                                    <div class="article-summary-box-inner">
                                        <span>While the researches on single image super-resolution (SISR), especially
equipped with deep neural networks (DNNs), have achieved tremendous successes
recently, they still suffer from two major limitations. Firstly, the real image
degradation is usually unknown and highly variant from one to another, making
it extremely hard to train a single model to handle the general SISR task.
Secondly, most of current methods mainly focus on the downsampling process of
the degradation, but ignore or underestimate the inevitable noise
contamination. For example, the commonly-used independent and identically
distributed (i.i.d.) Gaussian noise distribution always largely deviates from
the real image noise (e.g., camera sensor noise), which limits their
performance in real scenarios. To address these issues, this paper proposes a
model-based unsupervised SISR method to deal with the general SISR task with
unknown degradations. Instead of the traditional i.i.d. Gaussian noise
assumption, a novel patch-based non-i.i.d. noise modeling method is proposed to
fit the complex real noise. Besides, a deep generator parameterized by a DNN is
used to map the latent variable to the high-resolution image, and the
conventional hyper-Laplacian prior is also elaborately embedded into such
generator to further constrain the image gradients. Finally, a Monte Carlo EM
algorithm is designed to solve our model, which provides a general inference
framework to update the image generator both w.r.t. the latent variable and the
network parameters. Comprehensive experiments demonstrate that the proposed
method can evidently surpass the current state of the art (SotA) method (about
1dB PSNR) not only with a slighter model (0.34M vs. 2.40M) but also faster
speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ultrasound Video Transformers for Cardiac Ejection Fraction Estimation. (arXiv:2107.00977v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reynaud_H/0/1/0/all/0/1">Hadrien Reynaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1">Benjamin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Beqiri_A/0/1/0/all/0/1">Arian Beqiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeson_P/0/1/0/all/0/1">Paul Leeson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00977">
                                    <div class="article-summary-box-inner">
                                        <span>Cardiac ultrasound imaging is used to diagnose various heart diseases. Common
analysis pipelines involve manual processing of the video frames by expert
clinicians. This suffers from intra- and inter-observer variability. We propose
a novel approach to ultrasound video analysis using a transformer architecture
based on a Residual Auto-Encoder Network and a BERT model adapted for token
classification. This enables videos of any length to be processed. We apply our
model to the task of End-Systolic (ES) and End-Diastolic (ED) frame detection
and the automated computation of the left ventricular ejection fraction. We
achieve an average frame distance of 3.36 frames for the ES and 7.17 frames for
the ED on videos of arbitrary length. Our end-to-end learnable approach can
estimate the ejection fraction with a MAE of 5.95 and $R^2$ of 0.52 in 0.15s
per video, showing that segmentation is not the only way to predict ejection
fraction. Code and models are available at https://github.com/HReynaud/UVT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets. (arXiv:2107.00860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyung_E/0/1/0/all/0/1">Eunyoung Hyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00860">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of recent Neural Architecture Search (NAS) methods on
various tasks which have shown to output networks that largely outperform
human-designed networks, conventional NAS methods have mostly tackled the
optimization of searching for the network architecture for a single task
(dataset), which does not generalize well across multiple tasks (datasets).
Moreover, since such task-specific methods search for a neural architecture
from scratch for every given task, they incur a large computational cost, which
is problematic when the time and monetary budget are limited. In this paper, we
propose an efficient NAS framework that is trained once on a database
consisting of datasets and pretrained networks and can rapidly search for a
neural architecture for a novel dataset. The proposed MetaD2A (Meta
Dataset-to-Architecture) model can stochastically generate graphs
(architectures) from a given set (dataset) via a cross-modal latent space
learned with amortized meta-learning. Moreover, we also propose a
meta-performance predictor to estimate and select the best architecture without
direct training on target datasets. The experimental results demonstrate that
our model meta-learned on subsets of ImageNet-1K and architectures from
NAS-Bench 201 search space successfully generalizes to multiple unseen datasets
including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU
seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than
NSGANetV2, a transferable NAS method, with comparable performance. We believe
that the MetaD2A proposes a new research direction for rapid NAS as well as
ways to utilize the knowledge from rich databases of datasets and architectures
accumulated over the past years. Code is available at
https://github.com/HayeonLee/MetaD2A.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed Supervision Learning for Whole Slide Image Classification. (arXiv:2107.00934v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiahui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaodi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiqiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Q/0/1/0/all/0/1">Qi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris N. Metaxas</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaoting Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00934">
                                    <div class="article-summary-box-inner">
                                        <span>Weak supervision learning on classification labels has demonstrated high
performance in various tasks. When a few pixel-level fine annotations are also
affordable, it is natural to leverage both of the pixel-level (e.g.,
segmentation) and image level (e.g., classification) annotation to further
improve the performance. In computational pathology, however, such weak or
mixed supervision learning is still a challenging task, since the high
resolution of whole slide images makes it unattainable to perform end-to-end
training of classification models. An alternative approach is to analyze such
data by patch-base model training, i.e., using self-supervised learning to
generate pixel-level pseudo labels for patches. However, such methods usually
have model drifting issues, i.e., hard to converge, because the noise
accumulates during the self-training process. To handle those problems, we
propose a mixed supervision learning framework for super high-resolution images
to effectively utilize their various labels (e.g., sufficient image-level
coarse annotations and a few pixel-level fine labels). During the patch
training stage, this framework can make use of coarse image-level labels to
refine self-supervised learning and generate high-quality pixel-level pseudo
labels. A comprehensive strategy is proposed to suppress pixel-level false
positives and false negatives. Three real-world datasets with very large number
of images (i.e., more than 10,000 whole slide images) and various types of
labels are used to evaluate the effectiveness of mixed supervision learning. We
reduced the false positive rate by around one third compared to state of the
art while retaining 100\% sensitivity, in the task of image-level
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Magnification-independent Histopathological Image Classification with Similarity-based Multi-scale Embeddings. (arXiv:2107.01063v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yibao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xingru Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qianni Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01063">
                                    <div class="article-summary-box-inner">
                                        <span>The classification of histopathological images is of great value in both
cancer diagnosis and pathological studies. However, multiple reasons, such as
variations caused by magnification factors and class imbalance, make it a
challenging task where conventional methods that learn from image-label
datasets perform unsatisfactorily in many cases. We observe that tumours of the
same class often share common morphological patterns. To exploit this fact, we
propose an approach that learns similarity-based multi-scale embeddings (SMSE)
for magnification-independent histopathological image classification. In
particular, a pair loss and a triplet loss are leveraged to learn
similarity-based embeddings from image pairs or image triplets. The learned
embeddings provide accurate measurements of similarities between images, which
are regarded as a more effective form of representation for histopathological
morphology than normal image features. Furthermore, in order to ensure the
generated models are magnification-independent, images acquired at different
magnification factors are simultaneously fed to networks during training for
learning multi-scale embeddings. In addition to the SMSE, to eliminate the
impact of class imbalance, instead of using the hard sample mining strategy
that intuitively discards some easy samples, we introduce a new reinforced
focal loss to simultaneously punish hard misclassified samples while
suppressing easy well-classified samples. Experimental results show that the
SMSE improves the performance for histopathological image classification tasks
for both breast and liver cancers by a large margin compared to previous
methods. In particular, the SMSE achieves the best performance on the BreakHis
benchmark with an improvement ranging from 5% to 18% compared to previous
methods using traditional features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors. (arXiv:2107.00710v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1">Ulysse C&#xf4;t&#xe9;-Allard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_P/0/1/0/all/0/1">Petter Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stautland_A/0/1/0/all/0/1">Andrea Stautland</a>, <a href="http://arxiv.org/find/cs/1/au:+Nordgreen_T/0/1/0/all/0/1">Tine Nordgreen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fasmer_O/0/1/0/all/0/1">Ole Bernt Fasmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oedegaard_K/0/1/0/all/0/1">Ketil Joachim Oedegaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresen_J/0/1/0/all/0/1">Jim Torresen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00710">
                                    <div class="article-summary-box-inner">
                                        <span>Manic episodes of bipolar disorder can lead to uncritical behaviour and
delusional psychosis, often with destructive consequences for those affected
and their surroundings. Early detection and intervention of a manic episode are
crucial to prevent escalation, hospital admission and premature death. However,
people with bipolar disorder may not recognize that they are experiencing a
manic episode and symptoms such as euphoria and increased productivity can also
deter affected individuals from seeking help. This work proposes to perform
user-independent, automatic mood-state detection based on actigraphy and
electrodermal activity acquired from a wrist-worn device during mania and after
recovery (euthymia). This paper proposes a new deep learning-based ensemble
method leveraging long (20h) and short (5 minutes) time-intervals to
discriminate between the mood-states. When tested on 47 bipolar patients, the
proposed classification scheme achieves an average accuracy of 91.59% in
euthymic/manic mood-state recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HO-3D_v3: Improving the Accuracy of Hand-Object Annotations of the HO-3D Dataset. (arXiv:2107.00887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hampali_S/0/1/0/all/0/1">Shreyas Hampali</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1">Sayan Deb Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1">Vincent Lepetit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00887">
                                    <div class="article-summary-box-inner">
                                        <span>HO-3D is a dataset providing image sequences of various hand-object
interaction scenarios annotated with the 3D pose of the hand and the object and
was originally introduced as HO-3D_v2. The annotations were obtained
automatically using an optimization method, &#x27;HOnnotate&#x27;, introduced in the
original paper. HO-3D_v3 provides more accurate annotations for both the hand
and object poses thus resulting in better estimates of contact regions between
the hand and the object. In this report, we elaborate on the improvements to
the HOnnotate method and provide evaluations to compare the accuracy of
HO-3D_v2 and HO-3D_v3. HO-3D_v3 results in 4mm higher accuracy compared to
HO-3D_v2 for hand poses while exhibiting higher contact regions with the object
surface.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Target-dependent UNITER: A Transformer-Based Multimodal Language Comprehension Model for Domestic Service Robots. (arXiv:2107.00811v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_S/0/1/0/all/0/1">Shintaro Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00811">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, domestic service robots have an insufficient ability to interact
naturally through language. This is because understanding human instructions is
complicated by various ambiguities and missing information. In existing
methods, the referring expressions that specify the relationships between
objects are insufficiently modeled. In this paper, we propose Target-dependent
UNITER, which learns the relationship between the target object and other
objects directly by focusing on the relevant regions within an image, rather
than the whole image. Our method is an extension of the UNITER-based
Transformer that can be pretrained on general-purpose datasets. We extend the
UNITER approach by introducing a new architecture for handling the target
candidates. Our model is validated on two standard datasets, and the results
show that Target-dependent UNITER outperforms the baseline method in terms of
classification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions. (arXiv:2107.00789v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kambara_M/0/1/0/all/0/1">Motonari Kambara</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00789">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many studies in robotics to improve the communication skills
of domestic service robots. Most studies, however, have not fully benefited
from recent advances in deep neural networks because the training datasets are
not large enough. In this paper, our aim is to augment the datasets based on a
crossmodal language generation model. We propose the Case Relation Transformer
(CRT), which generates a fetching instruction sentence from an image, such as
&quot;Move the blue flip-flop to the lower left box.&quot; Unlike existing methods, the
CRT uses the Transformer to integrate the visual features and geometry features
of objects in the image. The CRT can handle the objects because of the Case
Relation Block. We conducted comparison experiments and a human evaluation. The
experimental results show the CRT outperforms baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic Image Transfer for Illumination Manipulation. (arXiv:2107.00704v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junqing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzhansky_M/0/1/0/all/0/1">Michael Ruzhansky</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qianying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haihui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00704">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel intrinsic image transfer (IIT) algorithm for
illumination manipulation, which creates a local image translation between two
illumination surfaces. This model is built on an optimization-based framework
consisting of three photo-realistic losses defined on the sub-layers factorized
by an intrinsic image decomposition. We illustrate that all losses can be
reduced without the necessity of taking an intrinsic image decomposition under
the well-known spatial-varying illumination illumination-invariant reflectance
prior knowledge. Moreover, with a series of relaxations, all of them can be
directly defined on images, giving a closed-form solution for image
illumination manipulation. This new paradigm differs from the prevailing
Retinex-based algorithms, as it provides an implicit way to deal with the
per-pixel image illumination. We finally demonstrate its versatility and
benefits to the illumination-related tasks such as illumination compensation,
image enhancement, and high dynamic range (HDR) image compression, and show the
high-quality results on natural image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MMF: Multi-Task Multi-Structure Fusion for Hierarchical Image Classification. (arXiv:2107.00808v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoni Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yucan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00808">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical classification is significant for complex tasks by providing
multi-granular predictions and encouraging better mistakes. As the label
structure decides its performance, many existing approaches attempt to
construct an excellent label structure for promoting the classification
results. In this paper, we consider that different label structures provide a
variety of prior knowledge for category recognition, thus fusing them is
helpful to achieve better hierarchical classification results. Furthermore, we
propose a multi-task multi-structure fusion model to integrate different label
structures. It contains two kinds of branches: one is the traditional
classification branch to classify the common subclasses, the other is
responsible for identifying the heterogeneous superclasses defined by different
label structures. Besides the effect of multiple label structures, we also
explore the architecture of the deep model for better hierachical
classification and adjust the hierarchical evaluation metrics for multiple
label structures. Experimental results on CIFAR100 and Car196 show that our
method obtains significantly better results than using a flat classifier or a
hierarchical classifier with any single label structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Uncertainty of Classifier for Unsupervised Domain Adaptation. (arXiv:2107.00727v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Shanu Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod Kumar Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praphul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00727">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding unsupervised domain adaptation has been an important task that
has been well explored. However, the wide variety of methods have not analyzed
the role of a classifier&#x27;s performance in detail. In this paper, we thoroughly
examine the role of a classifier in terms of matching source and target
distributions. We specifically investigate the classifier ability by matching
a) the distribution of features, b) probabilistic uncertainty for samples and
c) certainty activation mappings. Our analysis suggests that using these three
distributions does result in a consistently improved performance on all the
datasets. Our work thus extends present knowledge on the role of the various
distributions obtained from the classifier towards solving unsupervised domain
adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Passing a Non-verbal Turing Test: Evaluating Gesture Animations Generated from Speech. (arXiv:2107.00712v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rebol_M/0/1/0/all/0/1">Manuel Rebol</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutl_C/0/1/0/all/0/1">Christian G&#xfc;tl</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietroszek_K/0/1/0/all/0/1">Krzysztof Pietroszek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00712">
                                    <div class="article-summary-box-inner">
                                        <span>In real life, people communicate using both speech and non-verbal signals
such as gestures, face expression or body pose. Non-verbal signals impact the
meaning of the spoken utterance in an abundance of ways. An absence of
non-verbal signals impoverishes the process of communication. Yet, when users
are represented as avatars, it is difficult to translate non-verbal signals
along with the speech into the virtual world without specialized motion-capture
hardware. In this paper, we propose a novel, data-driven technique for
generating gestures directly from speech. Our approach is based on the
application of Generative Adversarial Neural Networks (GANs) to model the
correlation rather than causation between speech and gestures. This approach
approximates neuroscience findings on how non-verbal communication and speech
are correlated. We create a large dataset which consists of speech and
corresponding gestures in a 3D human pose format from which our model learns
the speaker-specific correlation. We evaluate the proposed technique in a user
study that is inspired by the Turing test. For the study, we animate the
generated gestures on a virtual character. We find that users are not able to
distinguish between the generated and the recorded gestures. Moreover, users
are able to identify our synthesized gestures as related or not related to a
given utterance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">1st Place Solutions for UG2+ Challenge 2021 -- (Semi-)supervised Face detection in the low light condition. (arXiv:2107.00818v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengcheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lingqiao Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zhilong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00818">
                                    <div class="article-summary-box-inner">
                                        <span>In this technical report, we briefly introduce the solution of our team
&quot;TAL-ai&quot; for (Semi-) supervised Face detection in the low light condition in
UG2+ Challenge in CVPR 2021. By conducting several experiments with popular
image enhancement methods and image transfer methods, we pulled the low light
image and the normal image to a more closer domain. And it is observed that
using these data to training can achieve better performance. We also adapt
several popular object detection frameworks, e.g., DetectoRS, Cascade-RCNN, and
large backbone like Swin-transformer. Finally, we ensemble several models which
achieved mAP 74.89 on the testing set, ranking 1st on the final leaderboard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Multi-Robot Perception via Learned Data Association. (arXiv:2107.00769v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1">Nathaniel Glaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yen-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Junjiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00769">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address the multi-robot collaborative perception problem,
specifically in the context of multi-view infilling for distributed semantic
segmentation. This setting entails several real-world challenges, especially
those relating to unregistered multi-agent image data. Solutions must
effectively leverage multiple, non-static, and intermittently-overlapping RGB
perspectives. To this end, we propose the Multi-Agent Infilling Network: an
extensible neural architecture that can be deployed (in a distributed manner)
to each agent in a robotic swarm. Specifically, each robot is in charge of
locally encoding and decoding visual information, and an extensible neural
mechanism allows for an uncertainty-aware and context-based exchange of
intermediate features. We demonstrate improved performance on a realistic
multi-robot AirSim dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios. (arXiv:2107.00717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1">Suraj Kothawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1">Krishnateja Killamsetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00717">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning has proven to be useful for minimizing labeling costs by
selecting the most informative samples. However, existing active learning
methods do not work well in realistic scenarios such as imbalance or rare
classes, out-of-distribution data in the unlabeled set, and redundancy. In this
work, we propose SIMILAR (Submodular Information Measures based actIve
LeARning), a unified active learning framework using recently proposed
submodular information measures (SIM) as acquisition functions. We argue that
SIMILAR not only works in standard active learning, but also easily extends to
the realistic settings considered above and acts as a one-stop solution for
active learning that is scalable to large real-world datasets. Empirically, we
show that SIMILAR significantly outperforms existing active learning algorithms
by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case
of out-of-distribution data on several image classification tasks like
CIFAR-10, MNIST, and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Image Segmentation by Mutual Information Maximization and Adversarial Regularization. (arXiv:2107.00691v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirsadeghi_S/0/1/0/all/0/1">S. Ehsan Mirsadeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Royat_A/0/1/0/all/0/1">Ali Royat</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezatofighi_H/0/1/0/all/0/1">Hamid Rezatofighi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00691">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation is one of the basic, yet essential scene understanding
tasks for an autonomous agent. The recent developments in supervised machine
learning and neural networks have enjoyed great success in enhancing the
performance of the state-of-the-art techniques for this task. However, their
superior performance is highly reliant on the availability of a large-scale
annotated dataset. In this paper, we propose a novel fully unsupervised
semantic segmentation method, the so-called Information Maximization and
Adversarial Regularization Segmentation (InMARS). Inspired by human perception
which parses a scene into perceptual groups, rather than analyzing each pixel
individually, our proposed approach first partitions an input image into
meaningful regions (also known as superpixels). Next, it utilizes
Mutual-Information-Maximization followed by an adversarial training strategy to
cluster these regions into semantically meaningful classes. To customize an
adversarial training scheme for the problem, we incorporate adversarial pixel
noise along with spatial perturbations to impose photometrical and geometrical
invariance on the deep neural network. Our experiments demonstrate that our
method achieves the state-of-the-art performance on two commonly used
unsupervised semantic segmentation datasets, COCO-Stuff, and Potsdam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UTNet: A Hybrid Transformer Architecture for Medical Image Segmentation. (arXiv:2107.00781v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris Metaxas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00781">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer architecture has emerged to be successful in a number of natural
language processing tasks. However, its applications to medical vision remain
largely unexplored. In this study, we present UTNet, a simple yet powerful
hybrid Transformer architecture that integrates self-attention into a
convolutional neural network for enhancing medical image segmentation. UTNet
applies self-attention modules in both encoder and decoder for capturing
long-range dependency at different scales with minimal overhead. To this end,
we propose an efficient self-attention mechanism along with relative position
encoding that reduces the complexity of self-attention operation significantly
from $O(n^2)$ to approximate $O(n)$. A new self-attention decoder is also
proposed to recover fine-grained details from the skipped connections in the
encoder. Our approach addresses the dilemma that Transformer requires huge
amounts of data to learn vision inductive bias. Our hybrid layer design allows
the initialization of Transformer into convolutional networks without a need of
pre-training. We have evaluated UTNet on the multi-label, multi-vendor cardiac
magnetic resonance imaging cohort. UTNet demonstrates superior segmentation
performance and robustness against the state-of-the-art approaches, holding the
promise to generalize well on other medical image segmentations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polarized Self-Attention: Towards High-quality Pixel-wise Regression. (arXiv:2107.00782v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huajun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fuqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xinyi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00782">
                                    <div class="article-summary-box-inner">
                                        <span>Pixel-wise regression is probably the most common problem in fine-grained
computer vision tasks, such as estimating keypoint heatmaps and segmentation
masks. These regression problems are very challenging particularly because they
require, at low computation overheads, modeling long-range dependencies on
high-resolution inputs/outputs to estimate the highly nonlinear pixel-wise
semantics. While attention mechanisms in Deep Convolutional Neural
Networks(DCNNs) has become popular for boosting long-range dependencies,
element-specific attention, such as Nonlocal blocks, is highly complex and
noise-sensitive to learn, and most of simplified attention hybrids try to reach
the best compromise among multiple types of tasks. In this paper, we present
the Polarized Self-Attention(PSA) block that incorporates two critical designs
towards high-quality pixel-wise regression: (1) Polarized filtering: keeping
high internal resolution in both channel and spatial attention computation
while completely collapsing input tensors along their counterpart dimensions.
(2) Enhancement: composing non-linearity that directly fits the output
distribution of typical fine-grained regression, such as the 2D Gaussian
distribution (keypoint heatmaps), or the 2D Binormial distribution (binary
segmentation masks). PSA appears to have exhausted the representation capacity
within its channel-only and spatial-only branches, such that there is only
marginal metric differences between its sequential and parallel layouts.
Experimental results show that PSA boosts standard baselines by $2-4$ points,
and boosts state-of-the-arts by $1-2$ points on 2D pose estimation and semantic
segmentation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Image Super-Resolution via Contrastive Representation Learning. (arXiv:2107.00708v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiahui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00708">
                                    <div class="article-summary-box-inner">
                                        <span>Image super-resolution (SR) research has witnessed impressive progress thanks
to the advance of convolutional neural networks (CNNs) in recent years.
However, most existing SR methods are non-blind and assume that degradation has
a single fixed and known distribution (e.g., bicubic) which struggle while
handling degradation in real-world data that usually follows a multi-modal,
spatially variant, and unknown distribution. The recent blind SR studies
address this issue via degradation estimation, but they do not generalize well
to multi-source degradation and cannot handle spatially variant degradation. We
design CRL-SR, a contrastive representation learning network that focuses on
blind SR of images with multi-modal and spatially variant distributions. CRL-SR
addresses the blind SR challenges from two perspectives. The first is
contrastive decoupling encoding which introduces contrastive learning to
extract resolution-invariant embedding and discard resolution-variant embedding
under the guidance of a bidirectional contrastive loss. The second is
contrastive feature refinement which generates lost or corrupted high-frequency
details under the guidance of a conditional contrastive loss. Extensive
experiments on synthetic datasets and real images show that the proposed CRL-SR
can handle multi-modal and spatially variant degradation effectively under
blind settings and it also outperforms state-of-the-art SR methods
qualitatively and quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Obstructions via Bandwidth-Limited Multi-Agent Spatial Handshaking. (arXiv:2107.00771v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1">Nathaniel Glaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yen-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Junjiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00771">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address bandwidth-limited and obstruction-prone
collaborative perception, specifically in the context of multi-agent semantic
segmentation. This setting presents several key challenges, including
processing and exchanging unregistered robotic swarm imagery. To be successful,
solutions must effectively leverage multiple non-static and
intermittently-overlapping RGB perspectives, while heeding bandwidth
constraints and overcoming unwanted foreground obstructions. As such, we
propose an end-to-end learn-able Multi-Agent Spatial Handshaking network (MASH)
to process, compress, and propagate visual information across a robotic swarm.
Our distributed communication module operates directly (and exclusively) on raw
image data, without additional input requirements such as pose, depth, or
warping data. We demonstrate superior performance of our model compared against
several baselines in a photo-realistic multi-robot AirSim environment,
especially in the presence of image occlusions. Our method achieves an absolute
11% IoU improvement over strong baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aerial Map-Based Navigation Using Semantic Segmentation and Pattern Matching. (arXiv:2107.00689v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Youngjoo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00689">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel approach to map-based navigation system for
unmanned aircraft. The proposed system attempts label-to-label matching, not
image-to-image matching between aerial images and a map database. By using
semantic segmentation, the ground objects are labelled and the configuration of
the objects is used to find the corresponding location in the map database. The
use of the deep learning technique as a tool for extracting high-level features
reduces the image-based localization problem to a pattern matching problem.
This paper proposes a pattern matching algorithm which does not require
altitude information or a camera model to estimate the absolute horizontal
position. The feasibility analysis with simulated images shows the proposed
map-based navigation can be realized with the proposed pattern matching
algorithm and it is able to provide positions given the labelled objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Cross-Session Information for Session-based Recommendation with Graph Neural Networks. (arXiv:2107.00852v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jingjing_L/0/1/0/all/0/1">Li Jingjing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00852">
                                    <div class="article-summary-box-inner">
                                        <span>Different from the traditional recommender system, the session-based
recommender system introduces the concept of the session, i.e., a sequence of
interactions between a user and multiple items within a period, to preserve the
user&#x27;s recent interest. The existing work on the session-based recommender
system mainly relies on mining sequential patterns within individual sessions,
which are not expressive enough to capture more complicated dependency
relationships among items. In addition, it does not consider the cross-session
information due to the anonymity of the session data, where the linkage between
different sessions is prevented. In this paper, we solve these problems with
the graph neural networks technique. First, each session is represented as a
graph rather than a linear sequence structure, based on which a novel Full
Graph Neural Network (FGNN) is proposed to learn complicated item dependency.
To exploit and incorporate cross-session information in the individual
session&#x27;s representation learning, we further construct a Broadly Connected
Session (BCS) graph to link different sessions and a novel Mask-Readout
function to improve session embedding based on the BCS graph. Extensive
experiments have been conducted on two e-commerce benchmark datasets, i.e.,
Yoochoose and Diginetica, and the experimental results demonstrate the
superiority of our proposal through comparisons with state-of-the-art
session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration with DBpedia. (arXiv:2107.00873v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brockmeier_M/0/1/0/all/0/1">Malte Brockmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yawen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pateer_S/0/1/0/all/0/1">Sunita Pateer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertling_S/0/1/0/all/0/1">Sven Hertling</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00873">
                                    <div class="article-summary-box-inner">
                                        <span>Modern large-scale knowledge graphs, such as DBpedia, are datasets which
require large computational resources to serve and process. Moreover, they
often have longer release cycles, which leads to outdated information in those
graphs. In this paper, we present DBpedia on Demand -- a system which serves
DBpedia resources on demand without the need to materialize and store the
entire graph, and which even provides limited querying functionality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Positional Information for Session-based Recommendation. (arXiv:2107.00846v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_C/0/1/0/all/0/1">Chen Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00846">
                                    <div class="article-summary-box-inner">
                                        <span>For present e-commerce platforms, session-based recommender systems are
developed to predict users&#x27; preference for next-item recommendation. Although a
session can usually reflect a user&#x27;s current preference, a local shift of the
user&#x27;s intention within the session may still exist. Specifically, the
interactions that take place in the early positions within a session generally
indicate the user&#x27;s initial intention, while later interactions are more likely
to represent the latest intention. Such positional information has been rarely
considered in existing methods, which restricts their ability to capture the
significance of interactions at different positions. To thoroughly exploit the
positional information within a session, a theoretical framework is developed
in this paper to provide an in-depth analysis of the positional information. We
formally define the properties of forward-awareness and backward-awareness to
evaluate the ability of positional encoding schemes in capturing the initial
and the latest intention. According to our analysis, existing positional
encoding schemes are generally forward-aware only, which can hardly represent
the dynamics of the intention in a session. To enhance the positional encoding
scheme for the session-based recommendation, a dual positional encoding (DPE)
is proposed to account for both forward-awareness and backward-awareness. Based
on DPE, we propose a novel Positional Recommender (PosRec) model with a
well-designed Position-aware Gated Graph Neural Network module to fully exploit
the positional information for session-based recommendation tasks. Extensive
experiments are conducted on two e-commerce benchmark datasets, Yoochoose and
Diginetica and the experimental results show the superiority of the PosRec by
comparing it with the state-of-the-art session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability. (arXiv:2107.00833v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1">Mihaela Curmei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a>, <a href="http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00833">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider how preference models in interactive recommendation
systems determine the availability of content and users&#x27; opportunities for
discovery. We propose an evaluation procedure based on stochastic reachability
to quantify the maximum probability of recommending a target piece of content
to an user for a set of allowable strategic modifications. This framework
allows us to compute an upper bound on the likelihood of recommendation with
minimal assumptions about user behavior. Stochastic reachability can be used to
detect biases in the availability of content and diagnose limitations in the
opportunities for discovery granted to users. We show that this metric can be
computed efficiently as a convex program for a variety of practical settings,
and further argue that reachability is not inherently at odds with accuracy. We
demonstrate evaluations of recommendation algorithms trained on large datasets
of explicit and implicit ratings. Our results illustrate how preference models,
selection rules, and user interventions impact reachability and how these
effects can be distributed unevenly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Low-Pass Filters: Adaptive Feature Propagation on Graphs. (arXiv:2103.14187v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sean Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14187">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have been extensively studied for prediction
tasks on graphs. As pointed out by recent studies, most GNNs assume local
homophily, i.e., strong similarities in local neighborhoods. This assumption
however limits the generalizability power of GNNs. To address this limitation,
we propose a flexible GNN model, which is capable of handling any graphs
without being restricted by their underlying homophily. At its core, this model
adopts a node attention mechanism based on multiple learnable spectral filters;
therefore, the aggregation scheme is learned adaptively for each graph in the
spectral domain. We evaluated the proposed model on node classification tasks
over eight benchmark datasets. The proposed model is shown to generalize well
to both homophilic and heterophilic graphs. Further, it outperforms all
state-of-the-art baselines on heterophilic graphs and performs comparably with
them on homophilic graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Fire Detection in Landsat-8 Imagery: a Large-Scale Dataset and a Deep-Learning Study. (arXiv:2101.03409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Gabriel Henrique de Almeida Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusioka_A/0/1/0/all/0/1">Andr&#xe9; Minoro Fusioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassu_B/0/1/0/all/0/1">Bogdan Tomoyuki Nassu</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03409">
                                    <div class="article-summary-box-inner">
                                        <span>Active fire detection in satellite imagery is of critical importance to the
management of environmental conservation policies, supporting decision-making
and law enforcement. This is a well established field, with many techniques
being proposed over the years, usually based on pixel or region-level
comparisons involving sensor-specific thresholds and neighborhood statistics.
In this paper, we address the problem of active fire detection using deep
learning techniques. In recent years, deep learning techniques have been
enjoying an enormous success in many fields, but their use for active fire
detection is relatively new, with open questions and demand for datasets and
architectures for evaluation. This paper addresses these issues by introducing
a new large-scale dataset for active fire detection, with over 150,000 image
patches (more than 200 GB of data) extracted from Landsat-8 images captured
around the world in August and September 2020, containing wildfires in several
locations. The dataset was split in two parts, and contains 10-band spectral
images with associated outputs, produced by three well known handcrafted
algorithms for active fire detection in the first part, and manually annotated
masks in the second part. We also present a study on how different
convolutional neural network architectures can be used to approximate these
handcrafted algorithms, and how models trained on automatically segmented
patches can be combined to achieve better performance than the original
algorithms - with the best combination having 87.2% precision and 92.4% recall
on our manually annotated dataset. The proposed dataset, source codes and
trained models are available on Github
(https://github.com/pereira-gha/activefire), creating opportunities for further
advances in the field</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable and Instance-Robust Predictions for Online Matching, Flows and Load Balancing. (arXiv:2011.11743v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lavastida_T/0/1/0/all/0/1">Thomas Lavastida</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_R/0/1/0/all/0/1">R. Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenyang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11743">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new model for augmenting algorithms with predictions by
requiring that they are formally learnable and instance robust. Learnability
ensures that predictions can be efficiently constructed from a reasonable
amount of past data. Instance robustness ensures that the prediction is robust
to modest changes in the problem input, where the measure of the change may be
problem specific. Instance robustness insists on a smooth degradation in
performance as a function of the change. Ideally, the performance is never
worse than worst-case bounds. This also allows predictions to be objectively
compared.

We design online algorithms with predictions for a network flow allocation
problem and restricted assignment makespan minimization. For both problems, two
key properties are established: high quality predictions can be learned from a
small sample of prior instances and these predictions are robust to errors that
smoothly degrade as the underlying problem instance changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum machine learning with adaptive linear optics. (arXiv:2102.04579v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Chabaud_U/0/1/0/all/0/1">Ulysse Chabaud</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Markham_D/0/1/0/all/0/1">Damian Markham</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sohbi_A/0/1/0/all/0/1">Adel Sohbi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04579">
                                    <div class="article-summary-box-inner">
                                        <span>We study supervised learning algorithms in which a quantum device is used to
perform a computational subroutine - either for prediction via probability
estimation, or to compute a kernel via estimation of quantum states overlap. We
design implementations of these quantum subroutines using Boson Sampling
architectures in linear optics, supplemented by adaptive measurements. We then
challenge these quantum algorithms by deriving classical simulation algorithms
for the tasks of output probability estimation and overlap estimation. We
obtain different classical simulability regimes for these two computational
tasks in terms of the number of adaptive measurements and input photons. In
both cases, our results set explicit limits to the range of parameters for
which a quantum advantage can be envisaged with adaptive linear optics compared
to classical machine learning algorithms: we show that the number of input
photons and the number of adaptive measurements cannot be simultaneously small
compared to the number of modes. Interestingly, our analysis leaves open the
possibility of a near-term quantum advantage with a single adaptive
measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Complexity of Symbolic Finite-State Automata. (arXiv:2011.05389v3 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fisman_D/0/1/0/all/0/1">Dana Fisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Frenkel_H/0/1/0/all/0/1">Hadar Frenkel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zilles_S/0/1/0/all/0/1">Sandra Zilles</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05389">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the complexity of procedures on SFAs (such as intersection,
emptiness, etc.) and analyze them according to the measures we find suitable
for symbolic automata: the number of states, the maximal number of transitions
exiting a state, and the size of the most complex transition predicate. We pay
attention to the special forms of SFAs: {normalized SFAs} and {neat SFAs}, as
well as to SFAs over a {monotonic} effective Boolean algebra.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointGuard: Provably Robust 3D Point Cloud Classification. (arXiv:2103.03046v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jinyuan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03046">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud classification has many safety-critical applications such as
autonomous driving and robotic grasping. However, several studies showed that
it is vulnerable to adversarial attacks. In particular, an attacker can make a
classifier predict an incorrect label for a 3D point cloud via carefully
modifying, adding, and/or deleting a small number of its points. Randomized
smoothing is state-of-the-art technique to build certifiably robust 2D image
classifiers. However, when applied to 3D point cloud classification, randomized
smoothing can only certify robustness against adversarially modified points.

In this work, we propose PointGuard, the first defense that has provable
robustness guarantees against adversarially modified, added, and/or deleted
points. Specifically, given a 3D point cloud and an arbitrary point cloud
classifier, our PointGuard first creates multiple subsampled point clouds, each
of which contains a random subset of the points in the original point cloud;
then our PointGuard predicts the label of the original point cloud as the
majority vote among the labels of the subsampled point clouds predicted by the
point cloud classifier. Our first major theoretical contribution is that we
show PointGuard provably predicts the same label for a 3D point cloud when the
number of adversarially modified, added, and/or deleted points is bounded. Our
second major theoretical contribution is that we prove the tightness of our
derived bound when no assumptions on the point cloud classifier are made.
Moreover, we design an efficient algorithm to compute our certified robustness
guarantees. We also empirically evaluate PointGuard on ModelNet40 and ScanNet
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure Learning from Related Data Sets with a Hierarchical Bayesian Score. (arXiv:2008.01683v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Azzimonti_L/0/1/0/all/0/1">Laura Azzimonti</a>, <a href="http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1">Giorgio Corani</a>, <a href="http://arxiv.org/find/stat/1/au:+Scutari_M/0/1/0/all/0/1">Marco Scutari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01683">
                                    <div class="article-summary-box-inner">
                                        <span>Score functions for learning the structure of Bayesian networks in the
literature assume that data are a homogeneous set of observations; whereas it
is often the case that they comprise different related, but not homogeneous,
data sets collected in different ways. In this paper we propose a new Bayesian
Dirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The
proposed score is based on a hierarchical model that pools information across
data sets to learn a single encompassing network structure, while taking into
account the differences in their probabilistic structures. We derive a
closed-form expression for BHD using a variational approximation of the
marginal likelihood and we study its performance using simulated data. We find
that, when data comprise multiple related data sets, BHD outperforms the
Bayesian Dirichlet equivalent uniform (BDeu) score in terms of reconstruction
accuracy as measured by the Structural Hamming distance, and that it is as
accurate as BDeu when data are homogeneous. Moreover, the estimated networks
are sparser and therefore more interpretable than those obtained with BDeu,
thanks to a lower number of false positive arcs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Oracle Complexity of Higher-Order Smooth Non-Convex Finite-Sum Optimization. (arXiv:2103.05138v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Emmenegger_N/0/1/0/all/0/1">Nicolas Emmenegger</a>, <a href="http://arxiv.org/find/math/1/au:+Kyng_R/0/1/0/all/0/1">Rasmus Kyng</a>, <a href="http://arxiv.org/find/math/1/au:+Zehmakan_A/0/1/0/all/0/1">Ahad N. Zehmakan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05138">
                                    <div class="article-summary-box-inner">
                                        <span>We prove lower bounds for higher-order methods in smooth non-convex
finite-sum optimization. Our contribution is threefold: We first show that a
deterministic algorithm cannot profit from the finite-sum structure of the
objective, and that simulating a pth-order regularized method on the whole
function by constructing exact gradient information is optimal up to constant
factors. We further show lower bounds for randomized algorithms and compare
them with the best known upper bounds. To address some gaps between the bounds,
we propose a new second-order smoothness assumption that can be seen as an
analogue of the first-order mean-squared smoothness assumption. We prove that
it is sufficient to ensure state-of-the-art convergence guarantees, while
allowing for a sharper lower bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Real-World BCI: CCSPNet, A Compact Subject-Independent Motor Imagery Framework. (arXiv:2012.13567v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nouri_M/0/1/0/all/0/1">Mahbod Nouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradi_F/0/1/0/all/0/1">Faraz Moradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaemi_H/0/1/0/all/0/1">Hafez Ghaemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_A/0/1/0/all/0/1">Ali Motie Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13567">
                                    <div class="article-summary-box-inner">
                                        <span>A conventional subject-dependent (SD) brain-computer interface (BCI) requires
a complete data-gathering, training, and calibration phase for each user before
it can be used. In recent years, a number of subject-independent (SI) BCIs have
been developed. However, there are many problems preventing them from being
used in real-world BCI applications. A weaker performance compared to the
subject-dependent (SD) approach, and a relatively large model requiring high
computational power are the most important ones. Therefore, a potential
real-world BCI would greatly benefit from a compact low-power
subject-independent BCI framework, ready to be used immediately after the user
puts it on. To move towards this goal, we propose a novel subject-independent
BCI framework named CCSPNet (Convolutional Common Spatial Pattern Network)
trained on the motor imagery (MI) paradigm of a large-scale
electroencephalography (EEG) signals database consisting of 21600 trials for 54
subjects performing two-class hand-movement MI tasks. The proposed framework
applies a wavelet kernel convolutional neural network (WKCNN) and a temporal
convolutional neural network (TCNN) in order to represent and extract the
diverse spectral features of EEG signals. The outputs of the convolutional
layers go through a common spatial pattern (CSP) algorithm for spatial feature
extraction. The number of CSP features is reduced by a dense neural network,
and the final class label is determined by a linear discriminative analysis
(LDA) classifier. The CCSPNet framework evaluation results show that it is
possible to have a low-power compact BCI that achieves both SD and SI
performance comparable to complex and computationally expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROOTS: Object-Centric Representation and Rendering of 3D Scenes. (arXiv:2006.06130v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1">Fei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungjin Ahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06130">
                                    <div class="article-summary-box-inner">
                                        <span>A crucial ability of human intelligence is to build up models of individual
3D objects from partial scene observations. Recent works achieve object-centric
generation but without the ability to infer the representation, or achieve 3D
scene representation learning but without object-centric compositionality.
Therefore, learning to represent and render 3D scenes with object-centric
compositionality remains elusive. In this paper, we propose a probabilistic
generative model for learning to build modular and compositional 3D object
models from partial observations of a multi-object scene. The proposed model
can (i) infer the 3D object representations by learning to search and group
object areas and also (ii) render from an arbitrary viewpoint not only
individual objects but also the full scene by compositing the objects. The
entire learning process is unsupervised and end-to-end. In experiments, in
addition to generation quality, we also demonstrate that the learned
representation permits object-wise manipulation and novel scene generation, and
generalizes to various settings. Results can be found on our project website:
https://sites.google.com/view/roots3d</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How good is your explanation? Algorithmic stability measures to assess the qualityof explanations for deep neural networks. (arXiv:2009.04521v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fel_T/0/1/0/all/0/1">Thomas Fel</a> (ANITI), <a href="http://arxiv.org/find/cs/1/au:+Vigouroux_D/0/1/0/all/0/1">David Vigouroux</a>, <a href="http://arxiv.org/find/cs/1/au:+Cadene_R/0/1/0/all/0/1">R&#xe9;mi Cad&#xe8;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1">Thomas Serre</a> (ANITI)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04521">
                                    <div class="article-summary-box-inner">
                                        <span>A plethora of methods have been proposed to explain howdeep neural networks
reach a decision but comparativelylittle effort has been made to ensure that
the explanationsproduced by these methods are objectively relevant.
Whiledesirable properties for a good explanation are easy to come,objective
measures have been harder to derive. Here, we pro-pose two new measures to
evaluate explanations borrowedfrom the field of algorithmic stability: relative
consistencyReCo and mean generalizability MeGe. We conduct severalexperiments
on multiple image datasets and network archi-tectures to demonstrate the
benefits of the proposed measuresover representative methods. We show that
popular fidelitymeasures are not sufficient to guarantee good
explanations.Finally, we show empirically that 1-Lipschitz networks pro-vide
general and consistent explanations, regardless of theexplanation method used,
making them a relevant directionfor explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Clinical Outcomes in COVID-19 using Radiomics and Deep Learning on Chest Radiographs: A Multi-Institutional Study. (arXiv:2007.08028v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bae_J/0/1/0/all/0/1">Joseph Bae</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kapse_S/0/1/0/all/0/1">Saarthak Kapse</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gattu_R/0/1/0/all/0/1">Rishabh Gattu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Syed Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shah_N/0/1/0/all/0/1">Neal Shah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marshall_C/0/1/0/all/0/1">Colin Marshall</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pierce_J/0/1/0/all/0/1">Jonathan Pierce</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Phatak_T/0/1/0/all/0/1">Tej Phatak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1">Amit Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Green_J/0/1/0/all/0/1">Jeremy Green</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Madan_N/0/1/0/all/0/1">Nikhil Madan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Prasanna_P/0/1/0/all/0/1">Prateek Prasanna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08028">
                                    <div class="article-summary-box-inner">
                                        <span>We predict mechanical ventilation requirement and mortality using
computational modeling of chest radiographs (CXRs) for coronavirus disease 2019
(COVID-19) patients. This two-center, retrospective study analyzed 530
deidentified CXRs from 515 COVID-19 patients treated at Stony Brook University
Hospital and Newark Beth Israel Medical Center between March and August 2020.
DL and machine learning classifiers to predict mechanical ventilation
requirement and mortality were trained and evaluated using patient CXRs. A
novel radiomic embedding framework was also explored for outcome prediction.
All results are compared against radiologist grading of CXRs (zone-wise expert
severity scores). Radiomic and DL classification models had mAUCs of
0.78+/-0.02 and 0.81+/-0.04, compared with expert scores mAUCs of 0.75+/-0.02
and 0.79+/-0.05 for mechanical ventilation requirement and mortality
prediction, respectively. Combined classifiers using both radiomics and expert
severity scores resulted in mAUCs of 0.79+/-0.04 and 0.83+/-0.04 for each
prediction task, demonstrating improvement over either artificial intelligence
or radiologist interpretation alone. Our results also suggest instances where
inclusion of radiomic features in DL improves model predictions, something that
might be explored in other pathologies. The models proposed in this study and
the prognostic information they provide might aid physician decision making and
resource allocation during the COVID-19 pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks. (arXiv:2007.15951v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1">Brian Kenji Iwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15951">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, deep artificial neural networks have achieved many successes
in pattern recognition. Part of this success can be attributed to the reliance
on big data to increase generalization. However, in the field of time series
recognition, many datasets are often very small. One method of addressing this
problem is through the use of data augmentation. In this paper, we survey data
augmentation techniques for time series and their application to time series
classification with neural networks. We propose a taxonomy and outline the four
families in time series data augmentation, including transformation-based
methods, pattern mixing, generative models, and decomposition methods.
Furthermore, we empirically evaluate 12 time series data augmentation methods
on 128 time series classification datasets with six different types of neural
networks. Through the results, we are able to analyze the characteristics,
advantages and disadvantages, and recommendations of each data augmentation
method. This survey aims to help in the selection of time series data
augmentation for neural network applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field Approximation. (arXiv:2103.02898v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghalamkari_K/0/1/0/all/0/1">Kazu Ghalamkari</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Mahito Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02898">
                                    <div class="article-summary-box-inner">
                                        <span>We present an efficient low-rank approximation algorithm for non-negative
tensors. The algorithm is derived from our two findings: First, we show that
rank-1 approximation for tensors can be viewed as a mean-field approximation by
treating each tensor as a probability distribution. Second, we theoretically
provide a sufficient condition for distribution parameters to reduce Tucker
ranks of tensors and, interestingly, this sufficient condition can be achieved
by iterative application of the mean-field approximation. Since the mean-field
approximation is always given as a closed formula, our findings lead to a fast
low-rank approximation algorithm without using a gradient method. We
empirically demonstrate that our algorithm is faster than the existing
non-negative Tucker rank reduction methods with achieving competitive or better
approximation of given tensors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards closing the gap between the theory and practice of SVRG. (arXiv:1908.02725v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sebbouh_O/0/1/0/all/0/1">Othmane Sebbouh</a>, <a href="http://arxiv.org/find/math/1/au:+Gazagnadou_N/0/1/0/all/0/1">Nidham Gazagnadou</a>, <a href="http://arxiv.org/find/math/1/au:+Jelassi_S/0/1/0/all/0/1">Samy Jelassi</a>, <a href="http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>, <a href="http://arxiv.org/find/math/1/au:+Gower_R/0/1/0/all/0/1">Robert M. Gower</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.02725">
                                    <div class="article-summary-box-inner">
                                        <span>Among the very first variance reduced stochastic methods for solving the
empirical risk minimization problem was the SVRG method (Johnson &amp; Zhang 2013).
SVRG is an inner-outer loop based method, where in the outer loop a reference
full gradient is evaluated, after which $m \in \mathbb{N}$ steps of an inner
loop are executed where the reference gradient is used to build a variance
reduced estimate of the current gradient. The simplicity of the SVRG method and
its analysis have led to multiple extensions and variants for even non-convex
optimization. We provide a more general analysis of SVRG than had been
previously done by using arbitrary sampling, which allows us to analyse
virtually all forms of mini-batching through a single theorem. Furthermore, our
analysis is focused on more practical variants of SVRG including a new variant
of the loopless SVRG (Hofman et al 2015, Kovalev et al 2019, Kulunchakov and
Mairal 2019) and a variant of k-SVRG (Raj and Stich 2018) where $m&#x3D;n$ and where
$n$ is the number of data points. Since our setup and analysis reflect what is
done in practice, we are able to set the parameters such as the mini-batch size
and step size using our theory in such a way that produces a more efficient
algorithm in practice, as we show in extensive numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Dependent Randomized Smoothing. (arXiv:2012.04351v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04351">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized smoothing is a recent technique that achieves state-of-art
performance in training certifiably robust deep neural networks. While the
smoothing family of distributions is often connected to the choice of the norm
used for certification, the parameters of these distributions are always set as
global hyper parameters independent of the input data on which a network is
certified. In this work, we revisit Gaussian randomized smoothing and show that
the variance of the Gaussian distribution can be optimized at each input so as
to maximize the certification radius for the construction of the smoothed
classifier. This new approach is generic, parameter-free, and easy to
implement. In fact, we show that our data dependent framework can be seamlessly
incorporated into 3 randomized smoothing approaches, leading to consistent
improved certified accuracy. When this framework is used in the training
routine of these approaches followed by a data dependent certification, we
achieve 9\% and 6\% improvement over the certified accuracy of the strongest
baseline for a radius of 0.5 on CIFAR10 and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory Efficient Meta-Learning with Large Images. (arXiv:2107.01105v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bronskill_J/0/1/0/all/0/1">John Bronskill</a>, <a href="http://arxiv.org/find/stat/1/au:+Massiceti_D/0/1/0/all/0/1">Daniela Massiceti</a>, <a href="http://arxiv.org/find/stat/1/au:+Patacchiola_M/0/1/0/all/0/1">Massimiliano Patacchiola</a>, <a href="http://arxiv.org/find/stat/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/stat/1/au:+Nowozin_S/0/1/0/all/0/1">Sebastian Nowozin</a>, <a href="http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01105">
                                    <div class="article-summary-box-inner">
                                        <span>Meta learning approaches to few-shot classification are computationally
efficient at test time requiring just a few optimization steps or single
forward pass to learn a new task, but they remain highly memory-intensive to
train. This limitation arises because a task&#x27;s entire support set, which can
contain up to 1000 images, must be processed before an optimization step can be
taken. Harnessing the performance gains offered by large images thus requires
either parallelizing the meta-learner across multiple GPUs, which may not be
available, or trade-offs between task and image size when memory constraints
apply. We improve on both options by proposing LITE, a general and memory
efficient episodic training scheme that enables meta-training on large tasks
composed of large images on a single GPU. We achieve this by observing that the
gradients for a task can be decomposed into a sum of gradients over the task&#x27;s
training images. This enables us to perform a forward pass on a task&#x27;s entire
training set but realize significant memory savings by back-propagating only a
random subset of these images which we show is an unbiased approximation of the
full gradient. We use LITE to train meta-learners and demonstrate new
state-of-the-art accuracy on the real-world ORBIT benchmark and 3 of the 4
parts of the challenging VTAB+MD benchmark relative to leading meta-learners.
LITE also enables meta-learners to be competitive with transfer learning
approaches but at a fraction of the test-time computational cost, thus serving
as a counterpoint to the recent narrative that transfer learning is all you
need for few-shot classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHADOWCAST: Controllable Graph Generation. (arXiv:2006.03774v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tann_W/0/1/0/all/0/1">Wesley Joon-Wie Tann</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ee-Chien Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1">Bryan Hooi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03774">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the controllable graph generation problem, formulated as
controlling graph attributes during the generative process to produce desired
graphs with understandable structures. Using a transparent and straightforward
Markov model to guide this generative process, practitioners can shape and
understand the generated graphs. We propose ${\rm S{\small HADOW}C{\small
AST}}$, a generative model capable of controlling graph generation while
retaining the original graph&#x27;s intrinsic properties. The proposed model is
based on a conditional generative adversarial network. Given an observed graph
and some user-specified Markov model parameters, ${\rm S{\small HADOW}C{\small
AST}}$ controls the conditions to generate desired graphs. Comprehensive
experiments on three real-world network datasets demonstrate our model&#x27;s
competitive performance in the graph generation task. Furthermore, we show its
effective controllability by directing ${\rm S{\small HADOW}C{\small AST}}$ to
generate hypothetical scenarios with different graph structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mirrorless Mirror Descent: A Natural Derivation of Mirror Descent. (arXiv:2004.01025v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1">Suriya Gunasekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodworth_B/0/1/0/all/0/1">Blake Woodworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01025">
                                    <div class="article-summary-box-inner">
                                        <span>We present a primal only derivation of Mirror Descent as a &quot;partial&quot;
discretization of gradient flow on a Riemannian manifold where the metric
tensor is the Hessian of the Mirror Descent potential. We contrast this
discretization to Natural Gradient Descent, which is obtained by a &quot;full&quot;
forward Euler discretization. This view helps shed light on the relationship
between the methods and allows generalizing Mirror Descent to general
Riemannian geometries, even when the metric tensor is {\em not} a Hessian, and
thus there is no &quot;dual.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Functional Perspective on Learning Symmetric Functions with Neural Networks. (arXiv:2008.06952v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zweig_A/0/1/0/all/0/1">Aaron Zweig</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06952">
                                    <div class="article-summary-box-inner">
                                        <span>Symmetric functions, which take as input an unordered, fixed-size set, are
known to be universally representable by neural networks that enforce
permutation invariance. These architectures only give guarantees for fixed
input sizes, yet in many practical applications, including point clouds and
particle physics, a relevant notion of generalization should include varying
the input size. In this work we treat symmetric functions (of any size) as
functions over probability measures, and study the learning and representation
of neural networks defined on measures. By focusing on shallow architectures,
we establish approximation and generalization bounds under different choices of
regularization (such as RKHS and variation norms), that capture a hierarchy of
functional spaces with increasing degree of non-linear learning. The resulting
models can be learned efficiently and enjoy generalization guarantees that
extend across input sizes, as we verify empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Machine Learning-Ready HPC Ensembles with Merlin. (arXiv:1912.02892v2 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peterson_J/0/1/0/all/0/1">J. Luc Peterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bay_B/0/1/0/all/0/1">Ben Bay</a>, <a href="http://arxiv.org/find/cs/1/au:+Koning_J/0/1/0/all/0/1">Joe Koning</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1">Peter Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Semler_J/0/1/0/all/0/1">Jessica Semler</a>, <a href="http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1">Jeremy White</a>, <a href="http://arxiv.org/find/cs/1/au:+Anirudh_R/0/1/0/all/0/1">Rushil Anirudh</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_K/0/1/0/all/0/1">Kevin Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bremer_P/0/1/0/all/0/1">Peer-Timo Bremer</a>, <a href="http://arxiv.org/find/cs/1/au:+Natale_F/0/1/0/all/0/1">Francesco Di Natale</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">David Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_J/0/1/0/all/0/1">Jim A. Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_S/0/1/0/all/0/1">Sam A. Jacobs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kustowski_B/0/1/0/all/0/1">Bogdan Kustowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1">Steven Langer</a>, <a href="http://arxiv.org/find/cs/1/au:+Spears_B/0/1/0/all/0/1">Brian Spears</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1">Jayaraman Thiagarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Essen_B/0/1/0/all/0/1">Brian Van Essen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1">Jae-Seung Yeom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02892">
                                    <div class="article-summary-box-inner">
                                        <span>With the growing complexity of computational and experimental facilities,
many scientific researchers are turning to machine learning (ML) techniques to
analyze large scale ensemble data. With complexities such as multi-component
workflows, heterogeneous machine architectures, parallel file systems, and
batch scheduling, care must be taken to facilitate this analysis in a high
performance computing (HPC) environment. In this paper, we present Merlin, a
workflow framework to enable large ML-friendly ensembles of scientific HPC
simulations. By augmenting traditional HPC with distributed compute
technologies, Merlin aims to lower the barrier for scientific subject matter
experts to incorporate ML into their analysis. In addition to its design, we
describe some example applications that Merlin has enabled on leadership-class
HPC resources, such as the ML-augmented optimization of nuclear fusion
experiments and the calibration of infectious disease models to study the
progression of and possible mitigation strategies for COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Road Roughness Estimation Using Machine Learning. (arXiv:2107.01199v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bajic_M/0/1/0/all/0/1">Milena Bajic</a>, <a href="http://arxiv.org/find/cs/1/au:+Pour_S/0/1/0/all/0/1">Shahrzad M. Pour</a>, <a href="http://arxiv.org/find/cs/1/au:+Skar_A/0/1/0/all/0/1">Asmus Skar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pettinari_M/0/1/0/all/0/1">Matteo Pettinari</a>, <a href="http://arxiv.org/find/cs/1/au:+Levenberg_E/0/1/0/all/0/1">Eyal Levenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Alstrom_T/0/1/0/all/0/1">Tommy Sonne Alstr&#xf8;m</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01199">
                                    <div class="article-summary-box-inner">
                                        <span>Road roughness is a very important road condition for the infrastructure, as
the roughness affects both the safety and ride comfort of passengers. The roads
deteriorate over time which means the road roughness must be continuously
monitored in order to have an accurate understand of the condition of the road
infrastructure. In this paper, we propose a machine learning pipeline for road
roughness prediction using the vertical acceleration of the car and the car
speed. We compared well-known supervised machine learning models such as linear
regression, naive Bayes, k-nearest neighbor, random forest, support vector
machine, and the multi-layer perceptron neural network. The models are trained
on an optimally selected set of features computed in the temporal and
statistical domain. The results demonstrate that machine learning methods can
accurately predict road roughness, using the recordings of the cost
approachable in-vehicle sensors installed in conventional passenger cars. Our
findings demonstrate that the technology is well suited to meet future pavement
condition monitoring, by enabling continuous monitoring of a wide road network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Identification of Hindi-English tweets using code-mixed BERT. (arXiv:2107.01202v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohd Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">M M Sufyan Beg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohd Jazib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasim_G/0/1/0/all/0/1">Ghazali Wasim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01202">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification of social media text has been an interesting problem
of study in recent years. Social media messages are predominantly in code mixed
in non-English speaking states. Prior knowledge by pre-training contextual
embeddings have shown state of the art results for a range of downstream tasks.
Recently, models such as BERT have shown that using a large amount of unlabeled
data, the pretrained language models are even more beneficial for learning
common language representations. Extensive experiments exploiting transfer
learning and fine-tuning BERT models to identify language on Twitter are
presented in this paper. The work utilizes a data collection of
Hindi-English-Urdu codemixed text for language pre-training and Hindi-English
codemixed for subsequent word-level language classification. The results show
that the representations pre-trained over codemixed data produce better results
by their monolingual counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Model Compression Via Two-Stage Deep Reinforcement Learning. (arXiv:1912.02254v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1">Huixin Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei-Ming Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yongcan Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02254">
                                    <div class="article-summary-box-inner">
                                        <span>Besides accuracy, the model size of convolutional neural networks (CNN)
models is another important factor considering limited hardware resources in
practical applications. For example, employing deep neural networks on mobile
systems requires the design of accurate yet fast CNN for low latency in
classification and object detection. To fulfill the need, we aim at obtaining
CNN models with both high testing accuracy and small size to address resource
constraints in many embedded devices. In particular, this paper focuses on
proposing a generic reinforcement learning-based model compression approach in
a two-stage compression pipeline: pruning and quantization. The first stage of
compression, i.e., pruning, is achieved via exploiting deep reinforcement
learning (DRL) to co-learn the accuracy and the FLOPs updated after layer-wise
channel pruning and element-wise variational pruning via information dropout.
The second stage, i.e., quantization, is achieved via a similar DRL approach
but focuses on obtaining the optimal bits representation for individual layers.
We further conduct experimental results on CIFAR-10 and ImageNet datasets. For
the CIFAR-10 dataset, the proposed method can reduce the size of VGGNet by 9x
from 20.04MB to 2.2MB with a slight accuracy increase. For the ImageNet
dataset, the proposed method can reduce the size of VGG-16 by 33x from 138MB to
4.14MB with no accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Causal Structure Discovery in Earth System Sciences. (arXiv:2107.01126v1 [physics.data-an])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Melkas_L/0/1/0/all/0/1">Laila Melkas</a>, <a href="http://arxiv.org/find/physics/1/au:+Savvides_R/0/1/0/all/0/1">Rafael Savvides</a>, <a href="http://arxiv.org/find/physics/1/au:+Chandramouli_S/0/1/0/all/0/1">Suyog Chandramouli</a>, <a href="http://arxiv.org/find/physics/1/au:+Makela_J/0/1/0/all/0/1">Jarmo M&#xe4;kel&#xe4;</a>, <a href="http://arxiv.org/find/physics/1/au:+Nieminen_T/0/1/0/all/0/1">Tuomo Nieminen</a>, <a href="http://arxiv.org/find/physics/1/au:+Mammarella_I/0/1/0/all/0/1">Ivan Mammarella</a>, <a href="http://arxiv.org/find/physics/1/au:+Puolamaki_K/0/1/0/all/0/1">Kai Puolam&#xe4;ki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01126">
                                    <div class="article-summary-box-inner">
                                        <span>Causal structure discovery (CSD) models are making inroads into several
domains, including Earth system sciences. Their widespread adaptation is
however hampered by the fact that the resulting models often do not take into
account the domain knowledge of the experts and that it is often necessary to
modify the resulting models iteratively. We present a workflow that is required
to take this knowledge into account and to apply CSD algorithms in Earth system
sciences. At the same time, we describe open research questions that still need
to be addressed. We present a way to interactively modify the outputs of the
CSD algorithms and argue that the user interaction can be modelled as a greedy
finding of the local maximum-a-posteriori solution of the likelihood function,
which is composed of the likelihood of the causal model and the prior
distribution representing the knowledge of the expert user. We use a real-world
data set for examples constructed in collaboration with our co-authors, who are
the domain area experts. We show that finding maximally usable causal models in
the Earth system sciences or other similar domains is a difficult task which
contains many interesting open research questions. We argue that taking the
domain knowledge into account has a substantial effect on the final causal
models discovered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization. (arXiv:2107.01131v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1">Yuewei Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Deng_X/0/1/0/all/0/1">Xinwei Deng</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01131">
                                    <div class="article-summary-box-inner">
                                        <span>Successful applications of InfoNCE and its variants have popularized the use
of contrastive variational mutual information (MI) estimators in machine
learning. While featuring superior stability, these estimators crucially depend
on costly large-batch training, and they sacrifice bound tightness for variance
reduction. To overcome these limitations, we revisit the mathematics of popular
variational MI bounds from the lens of unnormalized statistical modeling and
convex optimization. Our investigation not only yields a new unified
theoretical framework encompassing popular variational MI bounds but also leads
to a novel, simple, and powerful contrastive MI estimator named as FLO.
Theoretically, we show that the FLO estimator is tight, and it provably
converges under stochastic gradient descent. Empirically, our FLO estimator
overcomes the limitations of its predecessors and learns more efficiently. The
utility of FLO is verified using an extensive set of benchmarks, which also
reveals the trade-offs in practical MI estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Neural Network for Cybersecurity: A Comprehensive Review. (arXiv:2107.01185v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Podder_P/0/1/0/all/0/1">Prajoy Podder</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharati_S/0/1/0/all/0/1">Subrato Bharati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_M/0/1/0/all/0/1">M. Rubaiyat Hossain Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_P/0/1/0/all/0/1">Pinto Kumar Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kose_U/0/1/0/all/0/1">Utku Kose</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01185">
                                    <div class="article-summary-box-inner">
                                        <span>Cybersecurity is a very emerging field that protects systems, networks, and
data from digital attacks. With the increase in the scale of the Internet and
the evolution of cyber attacks, developing novel cybersecurity tools has become
important, particularly for Internet of things (IoT) networks. This paper
provides a systematic review of the application of deep learning (DL)
approaches for cybersecurity. This paper provides a short description of DL
methods which is used in cybersecurity, including deep belief networks,
generative adversarial networks, recurrent neural networks, and others. Next,
we illustrate the differences between shallow learning and DL. Moreover, a
discussion is provided on the currently prevailing cyber-attacks in IoT and
other networks, and the effectiveness of DL methods to manage these attacks.
Besides, this paper describes studies that highlight the DL technique,
cybersecurity applications, and the source of datasets. Next, a discussion is
provided on the feasibility of DL systems for malware detection and
classification, intrusion detection, and other frequent cyber-attacks,
including identifying file type, spam, and network traffic. Our review
indicates that high classification accuracy of 99.72% is obtained by restricted
Boltzmann machine (RBM) when applied to a custom dataset, while long short-term
memory (LSTM) achieves an accuracy of 99.80% for KDD Cup 99 dataset. Finally,
this article discusses the importance of cybersecurity for reliable and
practicable IoT-driven healthcare systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CHISEL: Compression-Aware High-Accuracy Embedded Indoor Localization with Deep Learning. (arXiv:2107.01192v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiku_S/0/1/0/all/0/1">Saideep Tiku</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasricha_S/0/1/0/all/0/1">Sudeep Pasricha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01192">
                                    <div class="article-summary-box-inner">
                                        <span>GPS technology has revolutionized the way we localize and navigate outdoors.
However, the poor reception of GPS signals in buildings makes it unsuitable for
indoor localization. WiFi fingerprinting-based indoor localization is one of
the most promising ways to meet this demand. Unfortunately, most work in the
domain fails to resolve challenges associated with deployability on
resource-limited embedded devices. In this work, we propose a compression-aware
and high-accuracy deep learning framework called CHISEL that outperforms the
best-known works in the area while maintaining localization robustness on
embedded devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-user VoiceFilter-Lite via Attentive Speaker Embedding. (arXiv:2107.01201v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1">Rajeev Rikhye</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1">Qiao Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1">Yanzhang He</a>, <a href="http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1">Ian McGraw</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01201">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a solution to allow speaker conditioned speech
models, such as VoiceFilter-Lite, to support an arbitrary number of enrolled
users in a single pass. This is achieved by using an attention mechanism on
multiple speaker embeddings to compute a single attentive embedding, which is
then used as a side input to the model. We implemented multi-user
VoiceFilter-Lite and evaluated it for three tasks: (1) a streaming automatic
speech recognition (ASR) task; (2) a text-independent speaker verification
task; and (3) a personalized keyphrase detection task, where ASR has to detect
keyphrases from multiple enrolled users in a noisy environment. Our experiments
show that, with up to four enrolled users, multi-user VoiceFilter-Lite is able
to significantly reduce speech recognition and speaker verification errors when
there is overlapping speech, without affecting performance under other acoustic
conditions. This attentive speaker embedding approach can also be easily
applied to other speaker-conditioned models such as personal VAD and
personalized ASR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Uncertainty of Classifier for Unsupervised Domain Adaptation. (arXiv:2107.00727v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Shanu Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod Kumar Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praphul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00727">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding unsupervised domain adaptation has been an important task that
has been well explored. However, the wide variety of methods have not analyzed
the role of a classifier&#x27;s performance in detail. In this paper, we thoroughly
examine the role of a classifier in terms of matching source and target
distributions. We specifically investigate the classifier ability by matching
a) the distribution of features, b) probabilistic uncertainty for samples and
c) certainty activation mappings. Our analysis suggests that using these three
distributions does result in a consistently improved performance on all the
datasets. Our work thus extends present knowledge on the role of the various
distributions obtained from the classifier towards solving unsupervised domain
adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Algorithms for Structured Prediction. (arXiv:1809.04091v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sepehry_B/0/1/0/all/0/1">Behrooz Sepehry</a>, <a href="http://arxiv.org/find/cs/1/au:+Iranmanesh_E/0/1/0/all/0/1">Ehsan Iranmanesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedlander_M/0/1/0/all/0/1">Michael P. Friedlander</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronagh_P/0/1/0/all/0/1">Pooya Ronagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1809.04091">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce two quantum algorithms for solving structured prediction
problems. We first show that a stochastic gradient descent that uses the
quantum minimum finding algorithm and takes its probabilistic failure into
account solves the structured prediction problem with a runtime that scales
with the square root of the size of the label space, and in $\widetilde
O\left(1/\epsilon\right)$ with respect to the precision, $\epsilon$, of the
solution. Motivated by robust inference techniques in machine learning, we then
introduce another quantum algorithm that solves a smooth approximation of the
structured prediction problem with a similar quantum speedup in the size of the
label space and a similar scaling in the precision parameter. In doing so, we
analyze a variant of stochastic gradient descent for convex optimization in the
presence of an additive error in the calculation of the gradients, and show
that its convergence rate does not deteriorate if the additive errors are of
the order $O(\sqrt\epsilon)$. This algorithm uses quantum Gibbs sampling at
temperature $\Omega (\epsilon)$ as a subroutine. Based on these theoretical
observations, we propose a method for using quantum Gibbs samplers to combine
feedforward neural networks with probabilistic graphical models for quantum
machine learning. Our numerical results using Monte Carlo simulations on an
image tagging task demonstrate the benefit of the approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeformRS: Certifying Input Deformations with Randomized Smoothing. (arXiv:2107.00996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naeemullah Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00996">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are vulnerable to input deformations in the form of
vector fields of pixel displacements and to other parameterized geometric
deformations e.g. translations, rotations, etc. Current input deformation
certification methods either (i) do not scale to deep networks on large input
datasets, or (ii) can only certify a specific class of deformations, e.g. only
rotations. We reformulate certification in randomized smoothing setting for
both general vector field and parameterized deformations and propose
DeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large
networks on large input datasets. For instance, DeformRS-Par certifies rich
deformations, covering translations, rotations, scaling, affine deformations,
and other visually aligned deformations such as ones parameterized by
Discrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10 and
ImageNet show that DeformRS-Par outperforms existing state-of-the-art in
certified accuracy, e.g. improved certified accuracy of 6% against perturbed
rotations in the set [-10,10] degrees on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Christopher M. Jermaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00961">
                                    <div class="article-summary-box-inner">
                                        <span>We propose {\rm \texttt{ResIST}}, a novel distributed training protocol for
Residual Networks (ResNets). {\rm \texttt{ResIST}} randomly decomposes a global
ResNet into several shallow sub-ResNets that are trained independently in a
distributed manner for several local iterations, before having their updates
synchronized and aggregated into the global model. In the next round, new
sub-ResNets are randomly generated and the process repeats. By construction,
per iteration, {\rm \texttt{ResIST}} communicates only a small portion of
network parameters to each machine and never uses the full model during
training. Thus, {\rm \texttt{ResIST}} reduces the communication, memory, and
time requirements of ResNet training to only a fraction of the requirements of
previous methods. In comparison to common protocols like data-parallel training
and data-parallel training with local SGD, {\rm \texttt{ResIST}} yields a
decrease in wall-clock training time, while being competitive with respect to
model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Metro Origin-Destination Prediction via Heterogeneous Information Aggregation. (arXiv:2107.00946v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingbo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuying Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1">Mingzhi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00946">
                                    <div class="article-summary-box-inner">
                                        <span>Metro origin-destination prediction is a crucial yet challenging task for
intelligent transportation management, which aims to accurately forecast two
specific types of cross-station ridership, i.e., Origin-Destination (OD) one
and Destination-Origin (DO) one. However, complete OD matrices of previous time
intervals can not be obtained immediately in online metro systems, and
conventional methods only used limited information to forecast the future OD
and DO ridership separately.In this work, we proposed a novel neural network
module termed Heterogeneous Information Aggregation Machine (HIAM), which fully
exploits heterogeneous information of historical data (e.g., incomplete OD
matrices, unfinished order vectors, and DO matrices) to jointly learn the
evolutionary patterns of OD and DO ridership. Specifically, an OD modeling
branch estimates the potential destinations of unfinished orders explicitly to
complement the information of incomplete OD matrices, while a DO modeling
branch takes DO matrices as input to capture the spatial-temporal distribution
of DO ridership. Moreover, a Dual Information Transformer is introduced to
propagate the mutual information among OD features and DO features for modeling
the OD-DO causality and correlation. Based on the proposed HIAM, we develop a
unified Seq2Seq network to forecast the future OD and DO ridership
simultaneously. Extensive experiments conducted on two large-scale benchmarks
demonstrate the effectiveness of our method for online metro origin-destination
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation. (arXiv:2107.01079v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammernik_K/0/1/0/all/0/1">Kerstin Hammernik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01079">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based segmentation methods are vulnerable to unforeseen data
distribution shifts during deployment, e.g. change of image appearances or
contrasts caused by different scanners, unexpected imaging artifacts etc. In
this paper, we present a cooperative framework for training image segmentation
models and a latent space augmentation method for generating hard examples.
Both contributions improve model generalization and robustness with limited
data. The cooperative training framework consists of a fast-thinking network
(FTN) and a slow-thinking network (STN). The FTN learns decoupled image
features and shape features for image reconstruction and segmentation tasks.
The STN learns shape priors for segmentation correction and refinement. The two
networks are trained in a cooperative manner. The latent space augmentation
generates challenging examples for training by masking the decoupled latent
space in both channel-wise and spatial-wise manners. We performed extensive
experiments on public cardiac imaging datasets. Using only 10 subjects from a
single site for training, we demonstrated improved cross-site segmentation
performance and increased robustness against various unforeseen imaging
artifacts compared to strong baseline methods. Particularly, cooperative
training with latent space data augmentation yields 15% improvement in terms of
average Dice score when compared to a standard training method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Backward-Compatible Prediction Updates: A Probabilistic Approach. (arXiv:2107.01057v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trauble_F/0/1/0/all/0/1">Frederik Tr&#xe4;uble</a>, <a href="http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleindessner_M/0/1/0/all/0/1">Matth&#xe4;us Kleindessner</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1">Peter Gehler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01057">
                                    <div class="article-summary-box-inner">
                                        <span>When machine learning systems meet real world applications, accuracy is only
one of several requirements. In this paper, we assay a complementary
perspective originating from the increasing availability of pre-trained and
regularly improving state-of-the-art models. While new improved models develop
at a fast pace, downstream tasks vary more slowly or stay constant. Assume that
we have a large unlabelled data set for which we want to maintain accurate
predictions. Whenever a new and presumably better ML models becomes available,
we encounter two problems: (i) given a limited budget, which data points should
be re-evaluated using the new model?; and (ii) if the new predictions differ
from the current ones, should we update? Problem (i) is about compute cost,
which matters for very large data sets and models. Problem (ii) is about
maintaining consistency of the predictions, which can be highly relevant for
downstream applications; our demand is to avoid negative flips, i.e., changing
correct to incorrect predictions. In this paper, we formalize the Prediction
Update Problem and present an efficient probabilistic approach as answer to the
above questions. In extensive experiments on standard classification benchmark
data sets, we show that our method outperforms alternative strategies along key
metrics for backward-compatible prediction updates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Momentum Accelerates the Convergence of Stochastic AUPRC Maximization. (arXiv:2107.01173v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01173">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study stochastic optimization of areas under
precision-recall curves (AUPRC), which is widely used for combating imbalanced
classification tasks. Although a few methods have been proposed for maximizing
AUPRC, stochastic optimization of AUPRC with convergence guarantee remains an
undeveloped territory. A recent work [42] has proposed a promising approach
towards AUPRC based on maximizing a surrogate loss for the average precision,
and proved an $O(1/\epsilon^5)$ complexity for finding an $\epsilon$-stationary
solution of the non-convex objective. In this paper, we further improve the
stochastic optimization of AURPC by (i) developing novel stochastic momentum
methods with a better iteration complexity of $O(1/\epsilon^4)$ for finding an
$\epsilon$-stationary solution; and (ii) designing a novel family of stochastic
adaptive methods with the same iteration complexity of $O(1/\epsilon^4)$, which
enjoy faster convergence in practice. To this end, we propose two innovative
techniques that are critical for improving the convergence: (i) the biased
estimators for tracking individual ranking scores are updated in a randomized
coordinate-wise manner; and (ii) a momentum update is used on top of the
stochastic gradient estimator for tracking the gradient of the objective.
Extensive experiments on various data sets demonstrate the effectiveness of the
proposed algorithms. Of independent interest, the proposed stochastic momentum
and adaptive algorithms are also applicable to a class of two-level stochastic
dependent compositional optimization problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vox Populi, Vox DIY: Benchmark Dataset for Crowdsourced Audio Transcription. (arXiv:2107.01091v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pavlichenko_N/0/1/0/all/0/1">Nikita Pavlichenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Stelmakh_I/0/1/0/all/0/1">Ivan Stelmakh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ustalov_D/0/1/0/all/0/1">Dmitry Ustalov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01091">
                                    <div class="article-summary-box-inner">
                                        <span>Domain-specific data is the crux of the successful transfer of machine
learning systems from benchmarks to real life. Crowdsourcing has become one of
the standard tools for cheap and time-efficient data collection for simple
problems such as image classification: thanks in large part to advances in
research on aggregation methods. However, the applicability of crowdsourcing to
more complex tasks (e.g., speech recognition) remains limited due to the lack
of principled aggregation methods for these modalities. The main obstacle
towards designing advanced aggregation methods is the absence of training data,
and in this work, we focus on bridging this gap in speech recognition. For
this, we collect and release CrowdSpeech -- the first publicly available
large-scale dataset of crowdsourced audio transcriptions. Evaluation of
existing aggregation methods on our data shows room for improvement, suggesting
that our work may entail the design of better algorithms. At a higher level, we
also contribute to the more general challenge of collecting high-quality
datasets using crowdsourcing: we develop a principled pipeline for constructing
datasets of crowdsourced audio transcriptions in any novel domain. We show its
applicability on an under-resourced language by constructing VoxDIY -- a
counterpart of CrowdSpeech for the Russian language. We also release the code
that allows a full replication of our data collection pipeline and share
various insights on best practices of data collection via crowdsourcing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Layer Algebra: A Framework to Measure Capacity and Compression in Deep Learning. (arXiv:2107.01081v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Badias_A/0/1/0/all/0/1">Alberto Badias</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Ashis Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01081">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new framework to measure the intrinsic properties of (deep)
neural networks. While we focus on convolutional networks, our framework can be
extrapolated to any network architecture. In particular, we evaluate two
network properties, namely, capacity (related to expressivity) and compression,
both of which depend only on the network structure and are independent of the
training and test data. To this end, we propose two metrics: the first one,
called layer complexity, captures the architectural complexity of any network
layer; and, the second one, called layer intrinsic power, encodes how data is
compressed along the network. The metrics are based on the concept of layer
algebra, which is also introduced in this paper. This concept is based on the
idea that the global properties depend on the network topology, and the leaf
nodes of any neural network can be approximated using local transfer functions,
thereby, allowing a simple computation of the global metrics. We also compare
the properties of the state-of-the art architectures using our metrics and use
the properties to analyze the classification accuracy on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NTIRE 2021 Multi-modal Aerial View Object Classification Challenge. (arXiv:2107.01189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jerrick Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nina_O/0/1/0/all/0/1">Oliver Nina</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Bob Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yuru Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songzheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiaqi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mengru Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gongzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Huanqia Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chengxue Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_S/0/1/0/all/0/1">Sol Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_C/0/1/0/all/0/1">Casian Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasarica_A/0/1/0/all/0/1">Alexandru Pasarica</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Yen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hung-Min Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiarui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jie Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Chia-Ying Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1">Michael Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Z/0/1/0/all/0/1">Zhongkai Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zihe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yifei_X/0/1/0/all/0/1">Xu Yifei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lehan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1">Min Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01189">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce the first Challenge on Multi-modal Aerial View
Object Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at
CVPR. This challenge is composed of two different tracks using EO andSAR
imagery. Both EO and SAR sensors possess different advantages and drawbacks.
The purpose of this competition is to analyze how to use both sets of sensory
information in complementary ways. We discuss the top methods submitted for
this competition and evaluate their results on our blind test set. Our
challenge results show significant improvement of more than 15% accuracy from
our current baselines for each track of the competition</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding. (arXiv:2104.13020v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1">Jose M. Pe&#xf1;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13020">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for assessing the sensitivity of the true causal effect
to unmeasured confounding. The method requires the analyst to specify two
intuitive parameters. Otherwise, the method is assumption-free. The method
returns an interval that contains the true causal effect. Moreover, the bounds
of the interval are sharp, i.e. attainable. We show experimentally that our
bounds can be sharper than those obtained by the method of Ding and VanderWeele
(2016). Finally, we extend our method to bound the natural direct and indirect
effects when there are measured mediators and unmeasured exposure-outcome
confounding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness for Image Generation with Uncertain Sensitive Attributes. (arXiv:2106.12182v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalal_A/0/1/0/all/0/1">Ajil Jalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1">Sushrut Karmalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1">Jessica Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1">Eric Price</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12182">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the issue of fairness in the context of generative
procedures, such as image super-resolution, which entail different definitions
from the standard classification setting. Moreover, while traditional group
fairness definitions are typically defined with respect to specified protected
groups -- camouflaging the fact that these groupings are artificial and carry
historical and political motivations -- we emphasize that there are no ground
truth identities. For instance, should South and East Asians be viewed as a
single group or separate groups? Should we consider one race as a whole or
further split by gender? Choosing which groups are valid and who belongs in
them is an impossible dilemma and being &quot;fair&quot; with respect to Asians may
require being &quot;unfair&quot; with respect to South Asians. This motivates the
introduction of definitions that allow algorithms to be \emph{oblivious} to the
relevant groupings.

We define several intuitive notions of group fairness and study their
incompatibilities and trade-offs. We show that the natural extension of
demographic parity is strongly dependent on the grouping, and \emph{impossible}
to achieve obliviously. On the other hand, the conceptually new definition we
introduce, Conditional Proportional Representation, can be achieved obliviously
through Posterior Sampling. Our experiments validate our theoretical results
and achieve fair image reconstruction using state-of-the-art generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive Learners With FlatNCE. (arXiv:2107.01152v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1">Liqun Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Shuyang Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_T/0/1/0/all/0/1">Tagyoung Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_B/0/1/0/all/0/1">Belinda Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_W/0/1/0/all/0/1">Wenlian Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01152">
                                    <div class="article-summary-box-inner">
                                        <span>InfoNCE-based contrastive representation learners, such as SimCLR, have been
tremendously successful in recent years. However, these contrastive schemes are
notoriously resource demanding, as their effectiveness breaks down with
small-batch training (i.e., the log-K curse, whereas K is the batch-size). In
this work, we reveal mathematically why contrastive learners fail in the
small-batch-size regime, and present a novel simple, non-trivial contrastive
objective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no
longer explicitly appeals to a discriminative classification goal for
contrastive learning. Theoretically, we show FlatNCE is the mathematical dual
formulation of InfoNCE, thus bridging the classical literature on energy
modeling; and empirically, we demonstrate that, with minimal modification of
code, FlatNCE enables immediate performance boost independent of the
subject-matter engineering efforts. The significance of this work is furthered
by the powerful generalization of contrastive learning techniques, and the
introduction of new tools to monitor and diagnose contrastive training. We
substantiate our claims with empirical evidence on CIFAR10, ImageNet, and other
datasets, where FlatNCE consistently outperforms InfoNCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combinatorial Optimization with Physics-Inspired Graph Neural Networks. (arXiv:2107.01188v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuetz_M/0/1/0/all/0/1">Martin J. A. Schuetz</a>, <a href="http://arxiv.org/find/cs/1/au:+Brubaker_J/0/1/0/all/0/1">J. Kyle Brubaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Katzgraber_H/0/1/0/all/0/1">Helmut G. Katzgraber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01188">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate how graph neural networks can be used to solve combinatorial
optimization problems. Our approach is broadly applicable to canonical NP-hard
problems in the form of quadratic unconstrained binary optimization problems,
such as maximum cut, minimum vertex cover, maximum independent set, as well as
Ising spin glasses and higher-order generalizations thereof in the form of
polynomial unconstrained binary optimization problems. We apply a relaxation
strategy to the problem Hamiltonian to generate a differentiable loss function
with which we train the graph neural network and apply a simple projection to
integer variables once the unsupervised training process has completed. We
showcase our approach with numerical results for the canonical maximum cut and
maximum independent set problems. We find that the graph neural network
optimizer performs on par or outperforms existing solvers, with the ability to
scale beyond the state of the art to problems with millions of variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirically Measuring Transfer Distance for System Design and Operation. (arXiv:2107.01184v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1">Tyler Cody</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_S/0/1/0/all/0/1">Stephen Adams</a>, <a href="http://arxiv.org/find/cs/1/au:+Beling_P/0/1/0/all/0/1">Peter A. Beling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01184">
                                    <div class="article-summary-box-inner">
                                        <span>Classical machine learning approaches are sensitive to non-stationarity.
Transfer learning can address non-stationarity by sharing knowledge from one
system to another, however, in areas like machine prognostics and defense, data
is fundamentally limited. Therefore, transfer learning algorithms have little,
if any, examples from which to learn. Herein, we suggest that these constraints
on algorithmic learning can be addressed by systems engineering. We formally
define transfer distance in general terms and demonstrate its use in
empirically quantifying the transferability of models. We consider the use of
transfer distance in the design of machine rebuild procedures to allow for
transferable prognostic models. We also consider the use of transfer distance
in predicting operational performance in computer vision. Practitioners can use
the presented methodology to design and operate systems with consideration for
the learning theoretic challenges faced by component learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1">Paul Mineiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Alekh Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06926">
                                    <div class="article-summary-box-inner">
                                        <span>The use of pessimism, when reasoning about datasets lacking exhaustive
exploration has recently gained prominence in offline reinforcement learning.
Despite the robustness it adds to the algorithm, overly pessimistic reasoning
can be equally damaging in precluding the discovery of good policies, which is
an issue for the popular bonus-based pessimism. In this paper, we introduce the
notion of Bellman-consistent pessimism for general function approximation:
instead of calculating a point-wise lower bound for the value function, we
implement pessimism at the initial state over the set of functions consistent
with the Bellman equations. Our theoretical guarantees only require Bellman
closedness as standard in the exploratory setting, in which case bonus-based
pessimism fails to provide guarantees. Even in the special case of linear MDPs
where stronger function-approximation assumptions hold, our result improves
upon a recent bonus-based approach by $\mathcal{O}(d)$ in its sample complexity
when the action space is finite. Remarkably, our algorithms automatically adapt
to the best bias-variance tradeoff in the hindsight, whereas most prior
approaches require tuning extra hyperparameters a priori.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap. (arXiv:2102.04692v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haike Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04692">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new model-free algorithm for episodic finite-horizon
Markov Decision Processes (MDP), Adaptive Multi-step Bootstrap (AMB), which
enjoys a stronger gap-dependent regret bound. The first innovation is to
estimate the optimal $Q$-function by combining an optimistic bootstrap with an
adaptive multi-step Monte Carlo rollout. The second innovation is to select the
action with the largest confidence interval length among admissible actions
that are not dominated by any other actions. We show when each state has a
unique optimal action, AMB achieves a gap-dependent regret bound that only
scales with the sum of the inverse of the sub-optimality gaps. In contrast,
Simchowitz and Jamieson (2019) showed all upper-confidence-bound (UCB)
algorithms suffer an additional $\Omega\left(\frac{S}{\Delta_{min}}\right)$
regret due to over-exploration where $\Delta_{min}$ is the minimum
sub-optimality gap and $S$ is the number of states. We further show that for
general MDPs, AMB suffers an additional $\frac{|Z_{mul}|}{\Delta_{min}}$
regret, where $Z_{mul}$ is the set of state-action pairs $(s,a)$&#x27;s satisfying
$a$ is a non-unique optimal action for $s$. We complement our upper bound with
a lower bound showing the dependency on $\frac{|Z_{mul}|}{\Delta_{min}}$ is
unavoidable for any consistent algorithm. This lower bound also implies a
separation between reinforcement learning and contextual bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unintended Effects on Adaptive Learning Rate for Training Neural Network with Output Scale Change. (arXiv:2103.03466v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanoh_R/0/1/0/all/0/1">Ryuichi Kanoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Mahito Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03466">
                                    <div class="article-summary-box-inner">
                                        <span>A multiplicative constant scaling factor is often applied to the model output
to adjust the dynamics of neural network parameters. This has been used as one
of the key interventions in an empirical study of lazy and active behavior.
However, we show that the combination of such scaling and a commonly used
adaptive learning rate optimizer strongly affects the training behavior of the
neural network. This is problematic as it can cause \emph{unintended behavior}
of neural networks, resulting in the misinterpretation of experimental results.
Specifically, for some scaling settings, the effect of the adaptive learning
rate disappears or is strongly influenced by the scaling factor. To avoid the
unintended effect, we present a modification of an optimization algorithm and
demonstrate remarkable differences between adaptive learning rate optimization
and simple gradient descent, especially with a small ($&lt;1.0$) scaling factor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FF-NSL: Feed-Forward Neural-Symbolic Learner. (arXiv:2106.13103v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cunnington_D/0/1/0/all/0/1">Daniel Cunnington</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1">Mark Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1">Alessandra Russo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lobo_J/0/1/0/all/0/1">Jorge Lobo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13103">
                                    <div class="article-summary-box-inner">
                                        <span>Inductive Logic Programming (ILP) aims to learn generalised, interpretable
hypotheses in a data-efficient manner. However, current ILP systems require
training examples to be specified in a structured logical form. To address this
problem, this paper proposes a neural-symbolic learning framework, called
Feed-Forward Neural-Symbolic Learner (FF-NSL), that integrates state-of-the-art
ILP systems, based on the Answer Set semantics, with Neural Networks (NNs), in
order to learn interpretable hypotheses from labelled unstructured data. To
demonstrate the generality and robustness of FF-NSL, we use two datasets
subject to distributional shifts, for which pre-trained NNs may give incorrect
predictions with high confidence. Experimental results show that FF-NSL
outperforms tree-based and neural-based approaches by learning more accurate
and interpretable hypotheses with fewer examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1">Mohammad Javad Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1">Branislav Kveton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04763">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of best-arm identification (BAI) in contextual bandits
in the fixed-budget setting. We propose a general successive elimination
algorithm that proceeds in stages and eliminates a fixed fraction of suboptimal
arms in each stage. This design takes advantage of the strengths of static and
adaptive allocations. We analyze the algorithm in linear models and obtain a
better error bound than prior work. We also apply it to generalized linear
models (GLMs) and bound its error. This is the first BAI algorithm for GLMs in
the fixed-budget setting. Our extensive numerical experiments show that our
algorithm outperforms the state of art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Application of neural networks to classification of data of the TUS orbital telescope. (arXiv:2106.03361v2 [astro-ph.IM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Zotov_M/0/1/0/all/0/1">Mikhail Zotov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03361">
                                    <div class="article-summary-box-inner">
                                        <span>We employ neural networks for classification of data of the TUS fluorescence
telescope, the world&#x27;s first orbital detector of ultra-high energy cosmic rays.
We focus on two particular types of signals in the TUS data: track-like flashes
produced by cosmic ray hits of the photodetector and flashes that originated
from distant lightnings. We demonstrate that even simple neural networks
combined with certain conventional methods of data analysis can be highly
effective in tasks of classification of data of fluorescence telescopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weather-based forecasting of energy generation, consumption and price for electrical microgrids management. (arXiv:2107.01034v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01034">
                                    <div class="article-summary-box-inner">
                                        <span>The Intergovernmental Panel on Climate Change proposes different mitigation
strategies to achieve the net emissions reductions that would be required to
follow a pathway that limits global warming to 1.5{\deg}C with no or limited
overshoot. The transition towards a carbon-free society goes through an
inevitable increase of the share of renewable generation in the energy mix and
a drastic decrease in terms of the total consumption of fossil fuels.
Therefore, this thesis studies the integration of renewables in power systems
by investigating forecasting and decision-making tools. Indeed, in contrast to
conventional power plants, renewable energy is subject to uncertainty. Most of
the generation technologies based on renewable sources are non-dispatchable,
and their production is stochastic and hard to predict in advance. A high share
of renewables is a great challenge for power systems that have been designed
and sized for dispatchable units. In this context, probabilistic forecasts,
which aim at modeling the distribution of all possible future realizations,
have become an important tool to equip decision-makers, hopefully leading to
better decisions in energy applications. This thesis focus on two main research
questions: (1) How to produce reliable probabilistic forecasts of renewable
generation, consumption, and electricity prices? (2) How to make decisions with
uncertainty using probabilistic forecasts? The thesis perimeter is the energy
management of &quot;small&quot; systems such as microgrids at a residential scale on a
day-ahead basis. It is divided into two main parts to propose directions to
address both research questions (1) a forecasting part; (2) a planning and
control part.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Optimize: A Primer and A Benchmark. (arXiv:2103.12828v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_W/0/1/0/all/0/1">Wuyang Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Heaton_H/0/1/0/all/0/1">Howard Heaton</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1">Jialin Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12828">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to optimize (L2O) is an emerging approach that leverages machine
learning to develop optimization methods, aiming at reducing the laborious
iterations of hand engineering. It automates the design of an optimization
method based on its performance on a set of training problems. This data-driven
procedure generates methods that can efficiently solve problems similar to
those in the training. In sharp contrast, the typical and traditional designs
of optimization methods are theory-driven, so they obtain performance
guarantees over the classes of problems specified by the theory. The difference
makes L2O suitable for repeatedly solving a certain type of optimization
problems over a specific distribution of data, while it typically fails on
out-of-distribution problems. The practicality of L2O depends on the type of
target optimization, the chosen architecture of the method to learn, and the
training procedure. This new paradigm has motivated a community of researchers
to explore L2O and report their findings.

This article is poised to be the first comprehensive survey and benchmark of
L2O for continuous optimization. We set up taxonomies, categorize existing
works and research directions, present insights, and identify open challenges.
We also benchmarked many existing L2O approaches on a few but representative
optimization problems. For reproducible research and fair benchmarking
purposes, we released our software implementation and data in the package
Open-L2O at https://github.com/VITA-Group/Open-L2O.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel Thinning. (arXiv:2105.05842v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1">Raaz Dwivedi</a>, <a href="http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05842">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce kernel thinning, a new procedure for compressing a distribution
$\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given
a suitable reproducing kernel $\mathbf{k}$ and $\mathcal{O}(n^2)$ time, kernel
thinning compresses an $n$-point approximation to $\mathbb{P}$ into a
$\sqrt{n}$-point approximation with comparable worst-case integration error in
the associated reproducing kernel Hilbert space. With high probability, the
maximum discrepancy in integration error is
$\mathcal{O}_d(n^{-\frac{1}{2}}\sqrt{\log n})$ for compactly supported
$\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} \sqrt{(\log n)^{d+1}\log\log
n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an
equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-\frac14})$
integration error. Our sub-exponential guarantees resemble the classical
quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply
to general distributions on $\mathbb{R}^d$ and a wide range of common kernels.
We use our results to derive explicit non-asymptotic maximum mean discrepancy
bounds for Gaussian, Mat\&#x27;ern, and B-spline kernels and present two vignettes
illustrating the practical benefits of kernel thinning over i.i.d. sampling and
standard Markov chain Monte Carlo thinning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmented Federated Learning for Adaptive Intrusion Detection System. (arXiv:2107.00881v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shingi_G/0/1/0/all/0/1">Geet Shingi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saglani_H/0/1/0/all/0/1">Harsh Saglani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Preeti Jain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00881">
                                    <div class="article-summary-box-inner">
                                        <span>Cyberattacks are a major issues and it causes organizations great financial,
and reputation harm. However, due to various factors, the current network
intrusion detection systems (NIDS) seem to be insufficent. Predominant NIDS
identifies Cyberattacks through a handcrafted dataset of rules. Although the
recent applications of machine learning and deep learning have alleviated the
enormous effort in NIDS, the security of network data has always been a prime
concern. However, to encounter the security problem and enable sharing among
organizations, Federated Learning (FL) scheme is employed. Although the current
FL systems have been successful, a network&#x27;s data distribution does not always
fit into a single global model as in FL. Thus, in such cases, having a single
global model in FL is no feasible. In this paper, we propose a
Segmented-Federated Learning (Segmented-FL) learning scheme for a more
efficient NIDS. The Segmented-FL approach employs periodic local model
evaluation based on which the segmentation occurs. We aim to bring similar
network environments to the same group. Further, the Segmented-FL system is
coupled with a weighted aggregation of local model parameters based on the
number of data samples a worker possesses to further augment the performance.
The improved performance by our system as compared to the FL and centralized
systems on standard dataset further validates our system and makes a strong
case for extending our technique across various tasks. The solution finds its
application in organizations that want to collaboratively learn on diverse
network environments and protect the privacy of individual datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-to-English Machine Translation Tools, Data, and Pretrained Models. (arXiv:2104.00290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gowda_T/0/1/0/all/0/1">Thamme Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattmann_C/0/1/0/all/0/1">Chris A Mattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00290">
                                    <div class="article-summary-box-inner">
                                        <span>While there are more than 7000 languages in the world, most translation
research efforts have targeted a few high-resource languages. Commercial
translation systems support only one hundred languages or fewer, and do not
make these models available for transfer to low resource languages. In this
work, we present useful tools for machine translation research: MTData,
NLCodec, and RTG. We demonstrate their usefulness by creating a multilingual
neural machine translation model capable of translating from 500 source
languages to English. We make this multilingual model readily downloadable and
usable as a service, or as a parent model for transfer-learning to even
lower-resource languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-Speakers Single Channel Speech Separation with Optimal Permutation Training. (arXiv:2104.08955v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dovrat_S/0/1/0/all/0/1">Shaked Dovrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1">Eliya Nachmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08955">
                                    <div class="article-summary-box-inner">
                                        <span>Single channel speech separation has experienced great progress in the last
few years. However, training neural speech separation for a large number of
speakers (e.g., more than 10 speakers) is out of reach for the current methods,
which rely on the Permutation Invariant Loss (PIT). In this work, we present a
permutation invariant training that employs the Hungarian algorithm in order to
train with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in
comparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified
architecture that can handle the increased number of speakers. Our approach
separates up to $20$ speakers and improves the previous results for large $C$
by a wide margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Encoding with AutoEncoders for Weakly-supervised Anomaly Detection. (arXiv:2105.10500v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yingjie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xucheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fanxing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Ce Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingqiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10500">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised anomaly detection aims at learning an anomaly detector from
a limited amount of labeled data and abundant unlabeled data. Recent works
build deep neural networks for anomaly detection by discriminatively mapping
the normal samples and abnormal samples to different regions in the feature
space or fitting different distributions. However, due to the limited number of
annotated anomaly samples, directly training networks with the discriminative
loss may not be sufficient. To overcome this issue, this paper proposes a novel
strategy to transform the input data into a more meaningful representation that
could be used for anomaly detection. Specifically, we leverage an autoencoder
to encode the input data and utilize three factors, hidden representation,
reconstruction residual vector, and reconstruction error, as the new
representation for the input data. This representation amounts to encode a test
sample with its projection on the training data manifold, its direction to its
projection and its distance to its projection. In addition to this encoding, we
also propose a novel network architecture to seamlessly incorporate those three
factors. From our extensive experiments, the benefits of the proposed strategy
are clearly demonstrated by its superior performance over the competitive
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Neural Relational Inference for Interacting Systems. (arXiv:2106.11083v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramos_J/0/1/0/all/0/1">Joao A. Candido Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Blonde_L/0/1/0/all/0/1">Lionel Blond&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Armand_S/0/1/0/all/0/1">St&#xe9;phane Armand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1">Alexandros Kalousis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11083">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we want to learn to model the dynamics of similar yet distinct
groups of interacting objects. These groups follow some common physical laws
that exhibit specificities that are captured through some vectorial
description. We develop a model that allows us to do conditional generation
from any such group given its vectorial description. Unlike previous work on
learning dynamical systems that can only do trajectory completion and require a
part of the trajectory dynamics to be provided as input in generation time, we
do generation using only the conditioning vector with no access to generation
time&#x27;s trajectories. We evaluate our model in the setting of modeling human
gait and, in particular pathological human gait.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural networks for Anatomical Therapeutic Chemical (ATC). (arXiv:2101.11713v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Nanni_L/0/1/0/all/0/1">Loris Nanni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lumini_A/0/1/0/all/0/1">Alessandra Lumini</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Brahnam_S/0/1/0/all/0/1">Sheryl Brahnam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11713">
                                    <div class="article-summary-box-inner">
                                        <span>Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification is
a critical and highly competitive area of research in bioinformatics because of
its potential for expediting drug develop-ment and research. Predicting an
unknown compound&#x27;s therapeutic and chemical characteristics ac-cording to how
these characteristics affect multiple organs/systems makes automatic ATC
classifica-tion a challenging multi-label problem. Results: In this work, we
propose combining multiple multi-label classifiers trained on distinct sets of
features, including sets extracted from a Bidirectional Long Short-Term Memory
Network (BiLSTM). Experiments demonstrate the power of this approach, which is
shown to outperform the best methods reported in the literature, including the
state-of-the-art developed by the fast.ai research group. Availability: All
source code developed for this study is available at
https://github.com/LorisNanni. Contact: loris.nanni@unipd.it</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating the electrical power output of industrial devices with end-to-end time-series classification in the presence of label noise. (arXiv:2105.00349v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellani_A/0/1/0/all/0/1">Andrea Castellani</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1">Sebastian Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1">Barbara Hammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00349">
                                    <div class="article-summary-box-inner">
                                        <span>In complex industrial settings, it is common practice to monitor the
operation of machines in order to detect undesired states, adjust maintenance
schedules, optimize system performance or collect usage statistics of
individual machines. In this work, we focus on estimating the power output of a
Combined Heat and Power (CHP) machine of a medium-sized company facility by
analyzing the total facility power consumption. We formulate the problem as a
time-series classification problem where the class label represents the CHP
power output. As the facility is fully instrumented and sensor measurements
from the CHP are available, we generate the training labels in an automated
fashion from the CHP sensor readings. However, sensor failures result in
mislabeled training data samples which are hard to detect and remove from the
dataset. Therefore, we propose a novel multi-task deep learning approach that
jointly trains a classifier and an autoencoder with a shared embedding
representation. The proposed approach targets to gradually correct the
mislabelled data samples during training in a self-supervised fashion, without
any prior assumption on the amount of label noise. We benchmark our approach on
several time-series classification datasets and find it to be comparable and
sometimes better than state-of-the-art methods. On the real-world use-case of
predicting the CHP power output, we thoroughly evaluate the architectural
design choices and show that the final architecture considerably increases the
robustness of the learning process and consistently beats other recent
state-of-the-art algorithms in the presence of unstructured as well as
structured label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Textual Echo Cancellation. (arXiv:2008.06006v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1">Shaojin Ding</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_Y/0/1/0/all/0/1">Ye Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06006">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Textual Echo Cancellation (TEC) - a framework for
cancelling the text-to-speech (TTS) playback echo from overlapping speech
recordings. Such a system can largely improve speech recognition performance
and user experience for intelligent devices such as smart speakers, as the user
can talk to the device while the device is still playing the TTS signal
responding to the previous query. We implement this system by using a novel
sequence-to-sequence model with multi-source attention that takes both the
microphone mixture signal and source text of the TTS playback as inputs, and
predicts the enhanced audio. Experiments show that the textual information of
the TTS playback is critical to enhancement performance. Besides, the text
sequence is much smaller in size compared with the raw acoustic signal of the
TTS playback, and can be immediately transmitted to the device or ASR server
even before the playback is synthesized. Therefore, our proposed approach
effectively reduces Internet communication and latency compared with
alternative approaches such as acoustic echo cancellation (AEC).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Screening for a Reweighted Penalized Conditional Gradient Method. (arXiv:2107.01106v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>, <a href="http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01106">
                                    <div class="article-summary-box-inner">
                                        <span>The conditional gradient method (CGM) is widely used in large-scale sparse
convex optimization, having a low per iteration computational cost for
structured sparse regularizers and a greedy approach to collecting nonzeros. We
explore the sparsity acquiring properties of a general penalized CGM (P-CGM)
for convex regularizers and a reweighted penalized CGM (RP-CGM) for nonconvex
regularizers, replacing the usual convex constraints with gauge-inspired
penalties. This generalization does not increase the per-iteration complexity
noticeably. Without assuming bounded iterates or using line search, we show
$O(1/t)$ convergence of the gap of each subproblem, which measures distance to
a stationary point. We couple this with a screening rule which is safe in the
convex case, converging to the true support at a rate $O(1/(\delta^2))$ where
$\delta \geq 0$ measures how close the problem is to degeneracy. In the
nonconvex case the screening rule converges to the true support in a finite
number of iterations, but is not necessarily safe in the intermediate iterates.
In our experiments, we verify the consistency of the method and adjust the
aggressiveness of the screening rule by tuning the concavity of the
regularizer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. (arXiv:2107.00967v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haitao Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zujie Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yafang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1">Gerard de Melo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00967">
                                    <div class="article-summary-box-inner">
                                        <span>Human language understanding operates at multiple levels of granularity
(e.g., words, phrases, and sentences) with increasing levels of abstraction
that can be hierarchically combined. However, existing deep models with stacked
layers do not explicitly model any sort of hierarchical process. This paper
proposes a recursive Transformer model based on differentiable CKY style binary
trees to emulate the composition process. We extend the bidirectional language
model pre-training objective to this architecture, attempting to predict each
word given its left and right abstraction nodes. To scale up our approach, we
also introduce an efficient pruned tree induction algorithm to enable encoding
in just a linear number of composition steps. Experimental results on language
modeling and unsupervised parsing show the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Multivariate Signs for Nonparametric Hypothesis Testing in High Dimensions. (arXiv:2107.01103v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Majumdar_S/0/1/0/all/0/1">Subhabrata Majumdar</a>, <a href="http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1">Snigdhansu Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01103">
                                    <div class="article-summary-box-inner">
                                        <span>High-dimensional data, where the dimension of the feature space is much
larger than sample size, arise in a number of statistical applications. In this
context, we construct the generalized multivariate sign transformation, defined
as a vector divided by its norm. For different choices of the norm function,
the resulting transformed vector adapts to certain geometrical features of the
data distribution. Building up on this idea, we obtain one-sample and
two-sample testing procedures for mean vectors of high-dimensional data using
these generalized sign vectors. These tests are based on U-statistics using
kernel inner products, do not require prohibitive assumptions, and are amenable
to a fast randomization-based implementation. Through experiments in a number
of data settings, we show that tests using generalized signs display higher
power than existing tests, while maintaining nominal type-I error rates.
Finally, we provide example applications on the MNIST and Minnesota Twin
Studies genomic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unveiling the structure of wide flat minima in neural networks. (arXiv:2107.01163v1 [cond-mat.dis-nn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Baldassi_C/0/1/0/all/0/1">Carlo Baldassi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lauditi_C/0/1/0/all/0/1">Clarissa Lauditi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Malatesta_E/0/1/0/all/0/1">Enrico M. Malatesta</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Perugini_G/0/1/0/all/0/1">Gabriele Perugini</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zecchina_R/0/1/0/all/0/1">Riccardo Zecchina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01163">
                                    <div class="article-summary-box-inner">
                                        <span>The success of deep learning has revealed the application potential of neural
networks across the sciences and opened up fundamental theoretical problems. In
particular, the fact that learning algorithms based on simple variants of
gradient methods are able to find near-optimal minima of highly nonconvex loss
functions is an unexpected feature of neural networks which needs to be
understood in depth. Such algorithms are able to fit the data almost perfectly,
even in the presence of noise, and yet they have excellent predictive
capabilities. Several empirical results have shown a reproducible correlation
between the so-called flatness of the minima achieved by the algorithms and the
generalization performance. At the same time, statistical physics results have
shown that in nonconvex networks a multitude of narrow minima may coexist with
a much smaller number of wide flat minima, which generalize well. Here we show
that wide flat minima arise from the coalescence of minima that correspond to
high-margin classifications. Despite being exponentially rare compared to
zero-margin solutions, high-margin minima tend to concentrate in particular
regions. These minima are in turn surrounded by other solutions of smaller and
smaller margin, leading to dense regions of solutions over long distances. Our
analysis also provides an alternative analytical method for estimating when
flat minima appear and when algorithms begin to find solutions, as the number
of model parameters varies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Centric Domain Adaptation for Historical Text with OCR Errors. (arXiv:2107.00927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marz_L/0/1/0/all/0/1">Luisa M&#xe4;rz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schweter_S/0/1/0/all/0/1">Stefan Schweter</a>, <a href="http://arxiv.org/find/cs/1/au:+Poerner_N/0/1/0/all/0/1">Nina Poerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00927">
                                    <div class="article-summary-box-inner">
                                        <span>We propose new methods for in-domain and cross-domain Named Entity
Recognition (NER) on historical data for Dutch and French. For the cross-domain
case, we address domain shift by integrating unsupervised in-domain data via
contextualized string embeddings; and OCR errors by injecting synthetic OCR
errors into the source domain and address data centric domain adaptation. We
propose a general approach to imitate OCR errors in arbitrary input data. Our
cross-domain as well as our in-domain results outperform several strong
baselines and establish state-of-the-art results. We publish preprocessed
versions of the French and Dutch Europeana NER corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discretization Drift in Two-Player Games. (arXiv:2105.13922v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1">Mihaela Rosca</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1">Benoit Dherin</a>, <a href="http://arxiv.org/find/stat/1/au:+Barrett_D/0/1/0/all/0/1">David G. T. Barrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13922">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient-based methods for two-player games produce rich dynamics that can
solve challenging problems, yet can be difficult to stabilize and understand.
Part of this complexity originates from the discrete update steps given by
simultaneous or alternating gradient descent, which causes each player to drift
away from the continuous gradient flow -- a phenomenon we call discretization
drift. Using backward error analysis, we derive modified continuous dynamical
systems that closely follow the discrete dynamics. These modified dynamics
provide an insight into the notorious challenges associated with zero-sum
games, including Generative Adversarial Networks. In particular, we identify
distinct components of the discretization drift that can alter performance and
in some cases destabilize the game. Finally, quantifying discretization drift
allows us to identify regularizers that explicitly cancel harmful forms of
drift or strengthen beneficial forms of drift, and thus improve performance of
GAN training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MegazordNet: combining statistical and machine learning standpoints for time series forecasting. (arXiv:2107.01017v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Menezes_A/0/1/0/all/0/1">Angelo Garangau Menezes</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mastelini_S/0/1/0/all/0/1">Saulo Martiello Mastelini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01017">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting financial time series is considered to be a difficult task due to
the chaotic feature of the series. Statistical approaches have shown solid
results in some specific problems such as predicting market direction and
single-price of stocks; however, with the recent advances in deep learning and
big data techniques, new promising options have arises to tackle financial time
series forecasting. Moreover, recent literature has shown that employing a
combination of statistics and machine learning may improve accuracy in the
forecasts in comparison to single solutions. Taking into consideration the
mentioned aspects, in this work, we proposed the MegazordNet, a framework that
explores statistical features within a financial series combined with a
structured deep learning model for time series forecasting. We evaluated our
approach predicting the closing price of stocks in the S&amp;P 500 using different
metrics, and we were able to beat single statistical and machine learning
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning. (arXiv:2107.00968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suwannaphong_T/0/1/0/all/0/1">Thanaphon Suwannaphong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavana_S/0/1/0/all/0/1">Sawaphob Chavana</a>, <a href="http://arxiv.org/find/cs/1/au:+Tongsom_S/0/1/0/all/0/1">Sahapol Tongsom</a>, <a href="http://arxiv.org/find/cs/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00968">
                                    <div class="article-summary-box-inner">
                                        <span>Intestinal parasitic infection leads to several morbidities to humans
worldwide, especially in tropical countries. The traditional diagnosis usually
relies on manual analysis from microscopic images which is prone to human error
due to morphological similarity of different parasitic eggs and abundance of
impurities in a sample. Many studies have developed automatic systems for
parasite egg detection to reduce human workload. However, they work with high
quality microscopes, which unfortunately remain unaffordable in some rural
areas. Our work thus exploits a benefit of a low-cost USB microscope. This
instrument however provides poor quality of images due to limitation of
magnification (10x), causing difficulty in parasite detection and species
classification. In this paper, we propose a CNN-based technique using transfer
learning strategy to enhance the efficiency of automatic parasite
classification in poor-quality microscopic images. The patch-based technique
with sliding window is employed to search for location of the eggs. Two
networks, AlexNet and ResNet50, are examined with a trade-off between
architecture size and classification performance. The results show that our
proposed framework outperforms the state-of-the-art object recognition methods.
Our system combined with final decision from an expert may improve the real
faecal examination with low-cost microscopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Personalized Medicine to Population Health: A Survey of mHealth Sensing Techniques. (arXiv:2107.00948v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sijia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhechba_M/0/1/0/all/0/1">Mehdi Boukhechba</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1">Laura E. Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daqing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00948">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Sensing Apps have been widely used as a practical approach to collect
behavioral and health-related information from individuals and provide timely
intervention to promote health and well-beings, such as mental health and
chronic cares. As the objectives of mobile sensing could be either \emph{(a)
personalized medicine for individuals} or \emph{(b) public health for
populations}, in this work we review the design of these mobile sensing apps,
and propose to categorize the design of these apps/systems in two paradigms --
\emph{(i) Personal Sensing} and \emph{(ii) Crowd Sensing} paradigms. While both
sensing paradigms might incorporate with common ubiquitous sensing
technologies, such as wearable sensors, mobility monitoring, mobile data
offloading, and/or cloud-based data analytics to collect and process sensing
data from individuals, we present a novel taxonomy system with two major
components that can specify and classify apps/systems from aspects of the
life-cycle of mHealth Sensing: \emph{(1) Sensing Task Creation \&amp;
Participation}, \emph{(2) Health Surveillance \&amp; Data Collection}, and
\emph{(3) Data Analysis \&amp; Knowledge Discovery}. With respect to different
goals of the two paradigms, this work systematically reviews this field, and
summarizes the design of typical apps/systems in the view of the configurations
and interactions between these two components. In addition to summarization,
the proposed taxonomy system also helps figure out the potential directions of
mobile sensing for health from both personalized medicines and population
health perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design and implementation of an islanded hybrid microgrid system for a large resort center for Penang Island with the proper application of excess energy. (arXiv:2107.01032v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shezan_S/0/1/0/all/0/1">SK. A. Shezan</a>, <a href="http://arxiv.org/find/eess/1/au:+Rawdah_S/0/1/0/all/0/1">S. Rawdah</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Shafin Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Rahman_Z/0/1/0/all/0/1">Ziaur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01032">
                                    <div class="article-summary-box-inner">
                                        <span>The energy demand is growing daily at an accelerated pace due to the
internationalization and development of civilization. Yet proper economic
utilization of additional energy generated by the Islanded Hybrid Microgrid
System (IHMS) that was not consumed by the load is a major global challenge. To
resolve the above-stated summons, this research focuses on a multi-optimal
combination of IHMS for the Penang Hill Resort located on Penang Island,
Malaysia, with effective use of redundant energy. To avail this excess energy
efficiently, an electrical heater along with a storage tank has been designed
concerning diversion load having proper energy management. Furthermore, the
system design has adopted the HOMER Pro software for profitable and practical
analysis. Alongside, MATLAB Simulink had stabilized the whole system by
representing the values of 2068 and 19,072 kW that have been determined as the
approximated peak and average load per day for the resort. Moreover, the
optimized IHMS is comprehended of Photovoltaic (PV) cells, Diesel Generator,
Wind Turbine, Battery, and Converter. Adjacent to this, the optimized system
ensued in having a Net Present Cost (NPC) of $21.66 million, Renewable Fraction
(RF) of 27.8%, Cost of Energy (COE) of $0.165/kWh, CO2 of 1,735,836 kg/year,
and excess energy of 517.29MWh per annum. Since the diesel generator lead
system was included in the scheme, a COE of $0.217/kWh, CO2 of 5,124,879
kg/year, and NPC of $23.25 million were attained. The amount of excess energy
is effectively utilized with an electrical heater as a diversion load.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Usefulness of Unsupervised monitoring in Cultural Heritage Monuments. (arXiv:2107.00964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafeiropoulos_C/0/1/0/all/0/1">Charalampos Zafeiropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzortzis_I/0/1/0/all/0/1">Ioannis N. Tzortzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rallis_I/0/1/0/all/0/1">Ioannis Rallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Protopapadakis_E/0/1/0/all/0/1">Eftychios Protopapadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1">Nikolaos Doulamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1">Anastasios Doulamis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00964">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we scrutinize the effectiveness of various clustering
techniques, investigating their applicability in Cultural Heritage monitoring
applications. In the context of this paper, we detect the level of
decomposition and corrosion on the walls of Saint Nicholas fort in Rhodes
utilizing hyperspectral images. A total of 6 different clustering approaches
have been evaluated over a set of 14 different orthorectified hyperspectral
images. Experimental setup in this study involves K-means, Spectral, Meanshift,
DBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate
its performance by the use of performance metrics such as Calinski-Harabasz,
Davies-Bouldin indexes and Silhouette value. In this approach, we evaluate the
outcomes of the clustering methods by comparing them with a set of annotated
images which denotes the ground truth regarding the decomposition and/or
corrosion area of the original images. The results depict that a few clustering
techniques applied on the given dataset succeeded decent accuracy, precision,
recall and f1 scores. Eventually, it was observed that the deterioration was
detected quite accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUKweb: Diachronic word representations from the UK Web Archive corpus. (arXiv:2107.01076v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1">Adam Tsakalidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Basile_P/0/1/0/all/0/1">Pierpaolo Basile</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazzi_M/0/1/0/all/0/1">Marya Bazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>, <a href="http://arxiv.org/find/cs/1/au:+McGillivray_B/0/1/0/all/0/1">Barbara McGillivray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01076">
                                    <div class="article-summary-box-inner">
                                        <span>Lexical semantic change (detecting shifts in the meaning and usage of words)
is an important task for social and cultural studies as well as for Natural
Language Processing applications. Diachronic word embeddings (time-sensitive
vector representations of words that preserve their meaning) have become the
standard resource for this task. However, given the significant computational
resources needed for their generation, very few resources exist that make
diachronic word embeddings available to the scientific community.

In this paper we present DUKweb, a set of large-scale resources designed for
the diachronic analysis of contemporary English. DUKweb was created from the
JISC UK Web Domain Dataset (1996-2013), a very large archive which collects
resources from the Internet Archive that were hosted on domains ending in
&#x60;.uk&#x27;. DUKweb consists of a series word co-occurrence matrices and two types of
word embeddings for each year in the JISC UK Web Domain dataset. We show the
reuse potential of DUKweb and its quality standards via a case study on word
meaning change detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise Labels. (arXiv:2107.01002v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karmanov_I/0/1/0/all/0/1">Ilia Karmanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanjani_F/0/1/0/all/0/1">Farhad G. Zanjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlin_S/0/1/0/all/0/1">Simone Merlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadampot_I/0/1/0/all/0/1">Ishaque Kadampot</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijkman_D/0/1/0/all/0/1">Daniel Dijkman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01002">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce WiCluster, a new machine learning (ML) approach for passive
indoor positioning using radio frequency (RF) channel state information (CSI).
WiCluster can predict both a zone-level position and a precise 2D or 3D
position, without using any precise position labels during training. Prior
CSI-based indoor positioning work has relied on non-parametric approaches using
digital signal-processing (DSP) and, more recently, parametric approaches
(e.g., fully supervised ML methods). However these do not handle the complexity
of real-world environments well and do not meet requirements for large-scale
commercial deployments: the accuracy of DSP-based method deteriorates
significantly in non-line-of-sight conditions, while supervised ML methods need
large amounts of hard-to-acquire centimeter accuracy position labels. In
contrast, WiCluster is both precise and requires weaker label-information that
can be easily collected. Our first contribution is a novel dimensionality
reduction method for charting. It combines a triplet-loss with a multi-scale
clustering-loss to map the high-dimensional CSI representation to a 2D/3D
latent space. Our second contribution is two weakly supervised losses that map
this latent space into a Cartesian map, resulting in meter-accuracy position
results. These losses only require simple to acquire priors: a sketch of the
floorplan, approximate location of access-point locations and a few CSI packets
that are labeled with the corresponding zone in the floorplan. Thirdly, we
report results and a robustness study for 2D positioning in a single-floor
office building and 3D positioning in a two-floor home to show the robustness
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure-aware reinforcement learning for node-overload protection in mobile edge computing. (arXiv:2107.01025v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jitani_A/0/1/0/all/0/1">Anirudha Jitani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Aditya Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhongwen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abou_zeid_H/0/1/0/all/0/1">Hatem Abou-zeid</a>, <a href="http://arxiv.org/find/cs/1/au:+Fapi_E/0/1/0/all/0/1">Emmanuel T. Fapi</a>, <a href="http://arxiv.org/find/cs/1/au:+Purmehdi_H/0/1/0/all/0/1">Hakimeh Purmehdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01025">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Edge Computing (MEC) refers to the concept of placing computational
capability and applications at the edge of the network, providing benefits such
as reduced latency in handling client requests, reduced network congestion, and
improved performance of applications. The performance and reliability of MEC
are degraded significantly when one or several edge servers in the cluster are
overloaded. Especially when a server crashes due to the overload, it causes
service failures in MEC. In this work, an adaptive admission control policy to
prevent edge node from getting overloaded is presented. This approach is based
on a recently-proposed low complexity RL (Reinforcement Learning) algorithm
called SALMUT (Structure-Aware Learning for Multiple Thresholds), which
exploits the structure of the optimal admission control policy in multi-class
queues for an average-cost setting. We extend the framework to work for node
overload-protection problem in a discounted-cost setting. The proposed solution
is validated using several scenarios mimicking real-world deployments in two
different settings - computer simulations and a docker testbed. Our empirical
evaluations show that the total discounted cost incurred by SALMUT is similar
to state-of-the-art deep RL algorithms such as PPO (Proximal Policy
Optimization) and A2C (Advantage Actor Critic) but requires an order of
magnitude less time to train, outputs easily interpretable policy, and can be
deployed in an online manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feeling of Presence Maximization: mmWave-Enabled Virtual Reality Meets Deep Reinforcement Learning. (arXiv:2107.01001v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q. S. Quek</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingxuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chaoqun You</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xianbin Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01001">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the problem of providing ultra-reliable and
energy-efficient virtual reality (VR) experiences for wireless mobile users. To
ensure reliable ultra-high-definition (UHD) video frame delivery to mobile
users and enhance their immersive visual experiences, a coordinated multipoint
(CoMP) transmission technique and millimeter wave (mmWave) communications are
exploited. Owing to user movement and time-varying wireless channels, the
wireless VR experience enhancement problem is formulated as a
sequence-dependent and mixed-integer problem with a goal of maximizing users&#x27;
feeling of presence (FoP) in the virtual world, subject to power consumption
constraints on access points (APs) and users&#x27; head-mounted displays (HMDs). The
problem, however, is hard to be directly solved due to the lack of users&#x27;
accurate tracking information and the sequence-dependent and mixed-integer
characteristics. To overcome this challenge, we develop a parallel echo state
network (ESN) learning method to predict users&#x27; tracking information by
training fresh and historical tracking samples separately collected by APs.
With the learnt results, we propose a deep reinforcement learning (DRL) based
optimization algorithm to solve the formulated problem. In this algorithm, we
implement deep neural networks (DNNs) as a scalable solution to produce integer
decision variables and solving a continuous power control problem to criticize
the integer decision variables. Finally, the performance of the proposed
algorithm is compared with various benchmark algorithms, and the impact of
different design parameters is also discussed. Simulation results demonstrate
that the proposed algorithm is more 4.14% energy-efficient than the benchmark
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gamers Private Network Performance Forecasting. From Raw Data to the Data Warehouse with Machine Learning and Neural Nets. (arXiv:2107.00998v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Albert Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Chun Yin Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hains_G/0/1/0/all/0/1">Ga&#xe9;tan Hains</a>, <a href="http://arxiv.org/find/cs/1/au:+Humphrey_J/0/1/0/all/0/1">Jack Humphrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuhrmann_H/0/1/0/all/0/1">Hans Fuhrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Khmelevsky_Y/0/1/0/all/0/1">Youry Khmelevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazur_C/0/1/0/all/0/1">Chris Mazur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00998">
                                    <div class="article-summary-box-inner">
                                        <span>Gamers Private Network (GPN) is a client/server technology that guarantees a
connection for online video games that is more reliable and lower latency than
a standard internet connection. Users of the GPN technology benefit from a
stable and high-quality gaming experience for online games, which are hosted
and played across the world. After transforming a massive volume of raw
networking data collected by WTFast, we have structured the cleaned data into a
special-purpose data warehouse and completed the extensive analysis using
machine learning and neural nets technologies, and business intelligence tools.
These analyses demonstrate the ability to predict and quantify changes in the
network and demonstrate the benefits gained from the use of a GPN for users
when connected to an online game session.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Representation for Neural Code Search. (arXiv:2107.00992v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zimin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1">Martin Monperrus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00992">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic code search is about finding semantically relevant code snippets for
a given natural language query. In the state-of-the-art approaches, the
semantic similarity between code and query is quantified as the distance of
their representation in the shared vector space. In this paper, to improve the
vector space, we introduce tree-serialization methods on a simplified form of
AST and build the multimodal representation for the code data. We conduct
extensive experiments using a single corpus that is large-scale and
multi-language: CodeSearchNet. Our results show that both our tree-serialized
representations and multimodal learning model improve the performance of neural
code search. Last, we define two intuitive quantification metrics oriented to
the completeness of semantic and syntactic information of the code data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExplainaBoard: An Explainable Leaderboard for NLP. (arXiv:2104.06387v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shuaicheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zihuiwen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06387">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of NLP research, leaderboards have emerged as one
tool to track the performance of various systems on various NLP tasks. They are
effective in this goal to some extent, but generally present a rather
simplistic one-dimensional view of the submitted systems, communicated only
through holistic accuracy numbers. In this paper, we present a new
conceptualization and implementation of NLP evaluation: the ExplainaBoard,
which in addition to inheriting the functionality of the standard leaderboard,
also allows researchers to (i) diagnose strengths and weaknesses of a single
system (e.g.~what is the best-performing system bad at?) (ii) interpret
relationships between multiple systems. (e.g.~where does system A outperform
system B? What if we combine systems A, B, and C?) and (iii) examine prediction
results closely (e.g.~what are common errors made by multiple systems, or in
what contexts do particular errors occur?). So far, ExplainaBoard covers more
than 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps
updated and is recently upgraded by supporting (1) multilingual multi-task
benchmark, (2) meta-evaluation, and (3) more complicated task: machine
translation, which reviewers also suggested.} We not only released an online
platform on the website \url{this http URL} but also make
our evaluation tool an API with MIT Licence at Github
\url{https://github.com/neulab/explainaBoard} and PyPi
\url{https://pypi.org/project/interpret-eval/} that allows users to
conveniently assess their models offline. We additionally release all output
files from systems that we have run or collected to motivate &quot;output-driven&quot;
research in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data. (arXiv:1912.09379v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gepperth_A/0/1/0/all/0/1">Alexander Gepperth</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfulb_B/0/1/0/all/0/1">Benedikt Pf&#xfc;lb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.09379">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for efficiently training Gaussian Mixture Model (GMM)
by Stochastic Gradient Descent (SGD) with non-stationary, high-dimensional
streaming data. Our training scheme does not require data-driven parameter
initialization (e.g., k-means) and can thus be trained based on a random
initialization. Furthermore, the approach allows mini-batch sizes as low as 1,
which are typical for streaming-data settings. Major problems in such settings
are undesirable local optima during early training phases and numerical
instabilities due to high data dimensionalities. We introduce an adaptive
annealing procedure to address the first problem, whereas numerical
instabilities are eliminated by using an exponential-free approximation to the
standard GMM log-likelihood. Experiments on a variety of visual and non-visual
benchmarks show that our SGD approach can be trained completely without, for
instance, k-means based centroid initialization. It also compares favorably to
an online variant of Expectation-Maximization (EM) - stochastic EM (sEM), which
it outperforms by a large margin for very high-dimensional data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Spotlight: A General Method for Discovering Systematic Errors in Deep Learning Models. (arXiv:2107.00758v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+dEon_G/0/1/0/all/0/1">Greg d&#x27;Eon</a>, <a href="http://arxiv.org/find/cs/1/au:+dEon_J/0/1/0/all/0/1">Jason d&#x27;Eon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">James R. Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Leyton_Brown_K/0/1/0/all/0/1">Kevin Leyton-Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00758">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning models often make systematic errors on rare subsets of
the data. However, such systematic errors can be difficult to identify, as
model performance can only be broken down across sensitive groups when these
groups are known and explicitly labelled. This paper introduces a method for
discovering systematic errors, which we call the spotlight. The key idea is
that similar inputs tend to have similar representations in the final hidden
layer of a neural network. We leverage this structure by &quot;shining a spotlight&quot;
on this representation space to find contiguous regions where the model
performs poorly. We show that the spotlight surfaces semantically meaningful
areas of weakness in a wide variety of model architectures, including image
classifiers, language models, and recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based statistical noise reduction for multidimensional spectral data. (arXiv:2107.00844v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Younsik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_D/0/1/0/all/0/1">Dongjin Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Huh_S/0/1/0/all/0/1">Soonsang Huh</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjoon Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1">Sunbeom Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_J/0/1/0/all/0/1">Junyoung Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minsoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1">Hanyoung Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1">Jongkeun Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyung_W/0/1/0/all/0/1">Wonshik Kyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_B/0/1/0/all/0/1">Byungmin Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Suyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyun_J/0/1/0/all/0/1">Jounghoon Hyun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yeonghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yeongkwan Kimand Changyoung Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00844">
                                    <div class="article-summary-box-inner">
                                        <span>In spectroscopic experiments, data acquisition in multi-dimensional phase
space may require long acquisition time, owing to the large phase space volume
to be covered. In such case, the limited time available for data acquisition
can be a serious constraint for experiments in which multidimensional spectral
data are acquired. Here, taking angle-resolved photoemission spectroscopy
(ARPES) as an example, we demonstrate a denoising method that utilizes deep
learning as an intelligent way to overcome the constraint. With readily
available ARPES data and random generation of training data set, we
successfully trained the denoising neural network without overfitting. The
denoising neural network can remove the noise in the data while preserving its
intrinsic information. We show that the denoising neural network allows us to
perform similar level of second-derivative and line shape analysis on data
taken with two orders of magnitude less acquisition time. The importance of our
method lies in its applicability to any multidimensional spectral data that are
susceptible to statistical noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of Loss Functions to Improve Generalizability of Deep Metric Learning methods. (arXiv:2107.01130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01130">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Metric Learning (DML) learns a non-linear semantic embedding from input
data that brings similar pairs together while keeps dissimilar data away from
each other. To this end, many different methods are proposed in the last decade
with promising results in various applications. The success of a DML algorithm
greatly depends on its loss function. However, no loss function is perfect, and
it deals only with some aspects of an optimal similarity embedding. Besides,
the generalizability of the DML on unseen categories during the test stage is
an important matter that is not considered by existing loss functions. To
address these challenges, we propose novel approaches to combine different
losses built on top of a shared deep feature extractor. The proposed ensemble
of losses enforces the deep model to extract features that are consistent with
all losses. Since the selected losses are diverse and each emphasizes different
aspects of an optimal semantic embedding, our effective combining methods yield
a considerable improvement over any individual loss and generalize well on
unseen categories. Here, there is no limitation in choosing loss functions, and
our methods can work with any set of existing ones. Besides, they can optimize
each loss function as well as its weight in an end-to-end paradigm with no need
to adjust any hyper-parameter. We evaluate our methods on some popular datasets
from the machine vision domain in conventional Zero-Shot-Learning (ZSL)
settings. The results are very encouraging and show that our methods outperform
all baseline losses by a large margin in all datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Marching Cubes. (arXiv:2106.11272v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiqin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11272">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Neural Marching Cubes (NMC), a data-driven approach for
extracting a triangle mesh from a discretized implicit field. Classical MC is
defined by coarse tessellation templates isolated to individual cubes. While
more refined tessellations have been proposed, they all make heuristic
assumptions, such as trilinearity, when determining the vertex positions and
local mesh topologies in each cube. In principle, none of these approaches can
reconstruct geometric features that reveal coherence or dependencies between
nearby cubes (e.g., a sharp edge), as such information is unaccounted for,
resulting in poor estimates of the true underlying implicit field. To tackle
these challenges, we re-cast MC from a deep learning perspective, by designing
tessellation templates more apt at preserving geometric features, and learning
the vertex positions and mesh topologies from training meshes, to account for
contextual information from nearby cubes. We develop a compact per-cube
parameterization to represent the output triangle mesh, while being compatible
with neural processing, so that a simple 3D convolutional network can be
employed for the training. We show that all topological cases in each cube that
are applicable to our design can be easily derived using our representation,
and the resulting tessellations can also be obtained naturally and efficiently
by following a few design guidelines. In addition, our network learns local
features with limited receptive fields, hence it generalizes well to new shapes
and new datasets. We evaluate our neural MC approach by quantitative and
qualitative comparisons to all well-known MC variants. In particular, we
demonstrate the ability of our network to recover sharp features such as edges
and corners, a long-standing issue of MC and its variants. Our network also
reconstructs local mesh topologies more accurately than previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Max-Mahalanobis Classifiers for Image Classification, Generation and More. (arXiv:2101.00122v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00122">
                                    <div class="article-summary-box-inner">
                                        <span>Joint Energy-based Model (JEM) of Grathwohl et al. shows that a standard
softmax classifier can be reinterpreted as an energy-based model (EBM) for the
joint distribution p(x,y); the resulting model can be optimized to improve
calibration, robustness, and out-of-distribution detection, while generating
samples rivaling the quality of recent GAN-based approaches. However, the
softmax classifier that JEM exploits is inherently discriminative and its
latent feature space is not well formulated as probabilistic distributions,
which may hinder its potential for image generation and incur training
instability. We hypothesize that generative classifiers, such as Linear
Discriminant Analysis (LDA), might be more suitable for image generation since
generative classifiers model the data generation process explicitly. This paper
therefore investigates an LDA classifier for image classification and
generation. In particular, the Max-Mahalanobis Classifier (MMC), a special case
of LDA, fits our goal very well. We show that our Generative MMC (GMMC) can be
trained discriminatively, generatively, or jointly for image classification and
generation. Extensive experiments on multiple datasets show that GMMC achieves
state-of-the-art discriminative and generative performances, while
outperforming JEM in calibration, adversarial robustness, and
out-of-distribution detection by a significant margin. Our source code is
available at https://github.com/sndnyang/GMMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. (arXiv:2106.12672v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1">Yi Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Vinh Q. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1">Jai Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hyung Won Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_S/0/1/0/all/0/1">Simon Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1">Donald Metzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12672">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art models in natural language processing rely on separate rigid
subword tokenization algorithms, which limit their generalization ability and
adaptation to new settings. In this paper, we propose a new model inductive
bias that learns a subword tokenization end-to-end as part of the model. To
this end, we introduce a soft gradient-based subword tokenization module (GBST)
that automatically learns latent subword representations from characters in a
data-driven fashion. Concretely, GBST enumerates candidate subword blocks and
learns to score them in a position-wise fashion using a block scoring network.
We additionally introduce Charformer, a deep Transformer model that integrates
GBST and operates on the byte level. Via extensive experiments on English GLUE,
multilingual, and noisy text datasets, we show that Charformer outperforms a
series of competitive byte-level baselines while generally performing on par
and sometimes outperforming subword-based models. Additionally, Charformer is
fast, improving the speed of both vanilla byte-level and subword-level
Transformers by 28%-100% while maintaining competitive quality. We believe this
work paves the way for highly performant token-free models that are trained
completely end-to-end.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents. (arXiv:2107.00956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1">R&#xe9;my Portelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00956">
                                    <div class="article-summary-box-inner">
                                        <span>Building embodied autonomous agents capable of participating in social
interactions with humans is one of the main challenges in AI. Within the Deep
Reinforcement Learning (DRL) field, this objective motivated multiple works on
embodied language use. However, current approaches focus on language as a
communication tool in very simplified and non-diverse social situations: the
&quot;naturalness&quot; of language is reduced to the concept of high vocabulary size and
variability. In this paper, we argue that aiming towards human-level AI
requires a broader set of key social skills: 1) language use in complex and
variable social contexts; 2) beyond language, complex embodied communication in
multimodal settings within constantly evolving social worlds. We explain how
concepts from cognitive sciences could help AI to draw a roadmap towards
human-like intelligence, with a focus on its social dimensions. As a first
step, we propose to expand current research to a broader set of core social
skills. To do this, we present SocialAI, a benchmark to assess the acquisition
of social skills of DRL agents using multiple grid-world environments featuring
other (scripted) social agents. We then study the limits of a recent SOTA DRL
approach when tested on SocialAI and discuss important next steps towards
proficient social agents. Videos and code are available at
https://sites.google.com/view/socialai.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Feedback-Enabled Cyber Resilience. (arXiv:2107.00783v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yunhan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Linan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Quanyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00783">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid growth in the number of devices and their connectivity has enlarged
the attack surface and weakened cyber systems. As attackers become increasingly
sophisticated and resourceful, mere reliance on traditional cyber protection,
such as intrusion detection, firewalls, and encryption, is insufficient to
secure cyber systems. Cyber resilience provides a new security paradigm that
complements inadequate protection with resilience mechanisms. A Cyber-Resilient
Mechanism (CRM) adapts to the known or zero-day threats and uncertainties in
real-time and strategically responds to them to maintain the critical functions
of the cyber systems. Feedback architectures play a pivotal role in enabling
the online sensing, reasoning, and actuation of the CRM. Reinforcement Learning
(RL) is an important class of algorithms that epitomize the feedback
architectures for cyber resiliency, allowing the CRM to provide dynamic and
sequential responses to attacks with limited prior knowledge of the attacker.
In this work, we review the literature on RL for cyber resiliency and discuss
the cyber-resilient defenses against three major types of vulnerabilities,
i.e., posture-related, information-related, and human-related vulnerabilities.
We introduce moving target defense, defensive cyber deception, and assistive
human security technologies as three application domains of CRMs to elaborate
on their designs. The RL technique also has vulnerabilities itself. We explain
the major vulnerabilities of RL and present several attack models in which the
attacks target the rewards, the measurements, and the actuators. We show that
the attacker can trick the RL agent into learning a nefarious policy with
minimum attacking effort, which shows serious security concerns for RL-enabled
systems. Finally, we discuss the future challenges of RL for cyber security and
resiliency and emerging applications of RL-based CRMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A\c{C}AI: Ascent Similarity Caching with Approximate Indexes. (arXiv:2107.00957v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salem_T/0/1/0/all/0/1">Tareq Si Salem</a>, <a href="http://arxiv.org/find/cs/1/au:+Neglia_G/0/1/0/all/0/1">Giovanni Neglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Carra_D/0/1/0/all/0/1">Damiano Carra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00957">
                                    <div class="article-summary-box-inner">
                                        <span>Similarity search is a key operation in multimedia retrieval systems and
recommender systems, and it will play an important role also for future machine
learning and augmented reality applications. When these systems need to serve
large objects with tight delay constraints, edge servers close to the end-user
can operate as similarity caches to speed up the retrieval. In this paper we
present A\c{C}AI, a new similarity caching policy which improves on the state
of the art by using (i) an (approximate) index for the whole catalog to decide
which objects to serve locally and which to retrieve from the remote server,
and (ii) a mirror ascent algorithm to update the set of local objects with
strong guarantees even when the request process does not exhibit any
statistical regularity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consequence-aware Sequential Counterfactual Generation. (arXiv:2104.05592v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naumann_P/0/1/0/all/0/1">Philip Naumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05592">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactuals have become a popular technique nowadays for interacting with
black-box machine learning models and understanding how to change a particular
instance to obtain a desired outcome from the model. However, most existing
approaches assume instant materialization of these changes, ignoring that they
may require effort and a specific order of application. Recently, methods have
been proposed that also consider the order in which actions are applied,
leading to the so-called sequential counterfactual generation problem.

In this work, we propose a model-agnostic method for sequential
counterfactual generation. We formulate the task as a multi-objective
optimization problem and present a genetic algorithm approach to find optimal
sequences of actions leading to the counterfactuals. Our cost model considers
not only the direct effect of an action, but also its consequences.
Experimental results show that compared to state-of-the-art, our approach
generates less costly solutions, is more efficient and provides the user with a
diverse set of solutions to choose from.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Hyperparameter Optimization with BoTorch, GPyTorch and Ax. (arXiv:1912.05686v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Daniel T. Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.05686">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models are full of hyperparameters, which are set manually
before the learning process can start. To find the best configuration for these
hyperparameters in such a high dimensional space, with time-consuming and
expensive model training / validation, is not a trivial challenge. Bayesian
optimization is a powerful tool for the joint optimization of hyperparameters,
efficiently trading off exploration and exploitation of the hyperparameter
space. In this paper, we discuss Bayesian hyperparameter optimization,
including hyperparameter optimization, Bayesian optimization, and Gaussian
processes. We also review BoTorch, GPyTorch and Ax, the new open-source
frameworks that we use for Bayesian optimization, Gaussian process inference
and adaptive experimentation, respectively. For experimentation, we apply
Bayesian hyperparameter optimization, for optimizing group weights, to weighted
group pooling, which couples unsupervised tiered graph autoencoders learning
and supervised graph prediction learning for molecular graphs. We find that Ax,
BoTorch and GPyTorch together provide a simple-to-use but powerful framework
for Bayesian hyperparameter optimization, using Ax&#x27;s high-level API that
constructs and runs a full optimization loop and returns the best
hyperparameter configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SparseDNN: Fast Sparse Deep Learning Inference on CPUs. (arXiv:2101.07948v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07948">
                                    <div class="article-summary-box-inner">
                                        <span>The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning. (arXiv:2107.00848v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ke_N/0/1/0/all/0/1">Nan Rosemary Ke</a>, <a href="http://arxiv.org/find/stat/1/au:+Didolkar_A/0/1/0/all/0/1">Aniket Didolkar</a>, <a href="http://arxiv.org/find/stat/1/au:+Mittal_S/0/1/0/all/0/1">Sarthak Mittal</a>, <a href="http://arxiv.org/find/stat/1/au:+Goyal_A/0/1/0/all/0/1">Anirudh Goyal</a>, <a href="http://arxiv.org/find/stat/1/au:+Lajoie_G/0/1/0/all/0/1">Guillaume Lajoie</a>, <a href="http://arxiv.org/find/stat/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1">Danilo Rezende</a>, <a href="http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/stat/1/au:+Mozer_M/0/1/0/all/0/1">Michael Mozer</a>, <a href="http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00848">
                                    <div class="article-summary-box-inner">
                                        <span>Inducing causal relationships from observations is a classic problem in
machine learning. Most work in causality starts from the premise that the
causal variables themselves are observed. However, for AI agents such as robots
trying to make sense of their environment, the only observables are low-level
variables like pixels in images. To generalize well, an agent must induce
high-level variables, particularly those which are causal or are affected by
causal variables. A central goal for AI and causality is thus the joint
discovery of abstract representations and causal structure. However, we note
that existing environments for studying causal induction are poorly suited for
this objective because they have complicated task-specific causal graphs which
are impossible to manipulate parametrically (e.g., number of nodes, sparsity,
causal chain length, etc.). In this work, our goal is to facilitate research in
learning representations of high-level variables as well as causal structures
among them. In order to systematically probe the ability of methods to identify
these variables and structures, we design a suite of benchmarking RL
environments. We evaluate various representation learning algorithms from the
literature and find that explicitly incorporating structure and modularity in
models can help causal induction in model-based reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SE(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials. (arXiv:2101.03164v2 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Batzner_S/0/1/0/all/0/1">Simon Batzner</a>, <a href="http://arxiv.org/find/physics/1/au:+Musaelian_A/0/1/0/all/0/1">Albert Musaelian</a>, <a href="http://arxiv.org/find/physics/1/au:+Sun_L/0/1/0/all/0/1">Lixin Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Geiger_M/0/1/0/all/0/1">Mario Geiger</a>, <a href="http://arxiv.org/find/physics/1/au:+Mailoa_J/0/1/0/all/0/1">Jonathan P. Mailoa</a>, <a href="http://arxiv.org/find/physics/1/au:+Kornbluth_M/0/1/0/all/0/1">Mordechai Kornbluth</a>, <a href="http://arxiv.org/find/physics/1/au:+Molinari_N/0/1/0/all/0/1">Nicola Molinari</a>, <a href="http://arxiv.org/find/physics/1/au:+Smidt_T/0/1/0/all/0/1">Tess E. Smidt</a>, <a href="http://arxiv.org/find/physics/1/au:+Kozinsky_B/0/1/0/all/0/1">Boris Kozinsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03164">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents Neural Equivariant Interatomic Potentials (NequIP), a
SE(3)-equivariant neural network approach for learning interatomic potentials
from ab-initio calculations for molecular dynamics simulations. While most
contemporary symmetry-aware models use invariant convolutions and only act on
scalars, NequIP employs SE(3)-equivariant convolutions for interactions of
geometric tensors, resulting in a more information-rich and faithful
representation of atomic environments. The method achieves state-of-the-art
accuracy on a challenging set of diverse molecules and materials while
exhibiting remarkable data efficiency. NequIP outperforms existing models with
up to three orders of magnitude fewer training data, challenging the widely
held belief that deep neural networks require massive training sets. The high
data efficiency of the method allows for the construction of accurate
potentials using high-order quantum chemical level of theory as reference and
enables high-fidelity molecular dynamics simulations over long time scales.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systems Theory of Transfer Learning. (arXiv:2107.01196v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1">Tyler Cody</a>, <a href="http://arxiv.org/find/cs/1/au:+Beling_P/0/1/0/all/0/1">Peter A. Beling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01196">
                                    <div class="article-summary-box-inner">
                                        <span>Existing frameworks for transfer learning are incomplete from a systems
theoretic perspective. They place emphasis on notions of domain and task, and
neglect notions of structure and behavior. In doing so, they limit the extent
to which formalism can be carried through into the elaboration of their
frameworks. Herein, we use Mesarovician systems theory to define transfer
learning as a relation on sets and subsequently characterize the general nature
of transfer learning as a mathematical construct. We interpret existing
frameworks in terms of ours and go beyond existing frameworks to define notions
of transferability, transfer roughness, and transfer distance. Importantly,
despite its formalism, our framework avoids the detailed mathematics of
learning theory or machine learning solution methods without excluding their
consideration. As such, we provide a formal, general systems framework for
modeling transfer learning that offers a rigorous foundation for system design
and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conflict-free collective stochastic decision making by orbital angular momentum entangled photons. (arXiv:2107.00877v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Amakasu_T/0/1/0/all/0/1">Takashi Amakasu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chauvet_N/0/1/0/all/0/1">Nicolas Chauvet</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bachelier_G/0/1/0/all/0/1">Guillaume Bachelier</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Huant_S/0/1/0/all/0/1">Serge Huant</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Horisaki_R/0/1/0/all/0/1">Ryoichi Horisaki</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Naruse_M/0/1/0/all/0/1">Makoto Naruse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00877">
                                    <div class="article-summary-box-inner">
                                        <span>In recent cross-disciplinary studies involving both optics and computing,
single-photon-based decision-making has been demonstrated by utilizing the
wave-particle duality of light to solve multi-armed bandit problems.
Furthermore, entangled-photon-based decision-making has managed to solve a
competitive multi-armed bandit problem in such a way that conflicts of
decisions among players are avoided while ensuring equality. However, as these
studies are based on the polarization of light, the number of available choices
is limited to two, corresponding to two orthogonal polarization states. Here we
propose a scalable principle to solve competitive decision-making situations by
using the orbital angular momentum as the tunable degree of freedom of photons,
which theoretically allows an unlimited number of arms. Moreover, by extending
the Hong-Ou-Mandel effect to more than two states, we theoretically establish
an experimental configuration able to generate entangled photon states with
orbital angular momentum and conditions that provide conflict-free selections
at every turn. We numerically examine total rewards regarding three-armed
bandit problems, for which the proposed strategy accomplishes almost the
theoretical maximum, which is greater than a conventional mixed strategy
intending to realize Nash equilibrium. This is thanks to the entanglement
property that achieves no-conflict selections, even in the exploring phase to
find the best arms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reconsidering Dependency Networks from an Information Geometry Perspective. (arXiv:2107.00871v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takabatake_K/0/1/0/all/0/1">Kazuya Takabatake</a>, <a href="http://arxiv.org/find/cs/1/au:+Akaho_S/0/1/0/all/0/1">Shotaro Akaho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00871">
                                    <div class="article-summary-box-inner">
                                        <span>Dependency networks (Heckerman et al., 2000) are potential probabilistic
graphical models for systems comprising a large number of variables. Like
Bayesian networks, the structure of a dependency network is represented by a
directed graph, and each node has a conditional probability table. Learning and
inference are realized locally on individual nodes; therefore, computation
remains tractable even with a large number of variables. However, the
dependency network&#x27;s learned distribution is the stationary distribution of a
Markov chain called pseudo-Gibbs sampling and has no closed-form expressions.
This technical disadvantage has impeded the development of dependency networks.
In this paper, we consider a certain manifold for each node. Then, we can
interpret pseudo-Gibbs sampling as iterative m-projections onto these
manifolds. This interpretation provides a theoretical bound for the location
where the stationary distribution of pseudo-Gibbs sampling exists in
distribution space. Furthermore, this interpretation involves structure and
parameter learning algorithms as optimization problems. In addition, we compare
dependency and Bayesian networks experimentally. The results demonstrate that
the dependency network and the Bayesian network have roughly the same
performance in terms of the accuracy of their learned distributions. The
results also show that the dependency network can learn much faster than the
Bayesian network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-Leakage Resilient Federated Learning. (arXiv:2107.01154v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wenqi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Gong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyengar_A/0/1/0/all/0/1">Arun Iyengar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01154">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning(FL) is an emerging distributed learning paradigm with
default client privacy because clients can keep sensitive data on their devices
and only share local training parameter updates with the federated server.
However, recent studies reveal that gradient leakages in FL may compromise the
privacy of client training data. This paper presents a gradient leakage
resilient approach to privacy-preserving federated learning with per training
example-based client differential privacy, coined as Fed-CDP. It makes three
original contributions. First, we identify three types of client gradient
leakage threats in federated learning even with encrypted client-server
communications. We articulate when and why the conventional server coordinated
differential privacy approach, coined as Fed-SDP, is insufficient to protect
the privacy of the training data. Second, we introduce Fed-CDP, the per
example-based client differential privacy algorithm, and provide a formal
analysis of Fed-CDP with the $(\epsilon, \delta)$ differential privacy
guarantee, and a formal comparison between Fed-CDP and Fed-SDP in terms of
privacy accounting. Third, we formally analyze the privacy-utility trade-off
for providing differential privacy guarantee by Fed-CDP and present a dynamic
decay noise-injection policy to further improve the accuracy and resiliency of
Fed-CDP. We evaluate and compare Fed-CDP and Fed-CDP(decay) with Fed-SDP in
terms of differential privacy guarantee and gradient leakage resilience over
five benchmark datasets. The results show that the Fed-CDP approach outperforms
conventional Fed-SDP in terms of resilience to client gradient leakages while
offering competitive accuracy performance in federated learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Theory of Deep Convolutional Neural Networks III: Approximating Radial Functions. (arXiv:2107.00896v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_T/0/1/0/all/0/1">Tong Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhongjie Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Ding-Xuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00896">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a family of deep neural networks consisting of two groups of
convolutional layers, a downsampling operator, and a fully connected layer. The
network structure depends on two structural parameters which determine the
numbers of convolutional layers and the width of the fully connected layer. We
establish an approximation theory with explicit approximation rates when the
approximated function takes a composite form $f\circ Q$ with a feature
polynomial $Q$ and a univariate function $f$. In particular, we prove that such
a network can outperform fully connected shallow networks in approximating
radial functions with $Q(x) &#x3D;|x|^2$, when the dimension $d$ of data from
$\mathbb{R}^d$ is large. This gives the first rigorous proof for the
superiority of deep convolutional neural networks in approximating functions
with special structures. Then we carry out generalization analysis for
empirical risk minimization with such a deep network in a regression framework
with the regression function of the form $f\circ Q$. Our network structure
which does not use any composite information or the functions $Q$ and $f$ can
automatically extract features and make use of the composite nature of the
regression function via tuning the structural parameters. Our analysis provides
an error bound which decreases with the network depth to a minimum and then
increases, verifying theoretically a trade-off phenomenon observed for network
depths in many practical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating deep double descent by concatenating inputs. (arXiv:2107.00797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qihan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00797">
                                    <div class="article-summary-box-inner">
                                        <span>The double descent curve is one of the most intriguing properties of deep
neural networks. It contrasts the classical bias-variance curve with the
behavior of modern neural networks, occurring where the number of samples nears
the number of parameters. In this work, we explore the connection between the
double descent phenomena and the number of samples in the deep neural network
setting. In particular, we propose a construction which augments the existing
dataset by artificially increasing the number of samples. This construction
empirically mitigates the double descent curve in this setting. We reproduce
existing work on deep double descent, and observe a smooth descent into the
overparameterized region for our construction. This occurs both with respect to
the model size, and with respect to the number epochs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-optimal Algorithms for Explainable k-Medians and k-Means. (arXiv:2107.00798v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_L/0/1/0/all/0/1">Liren Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00798">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of explainable $k$-medians and $k$-means introduced
by Dasgupta, Frost, Moshkovitz, and Rashtchian~(ICML 2020). In this problem,
our goal is to find a \emph{threshold decision tree} that partitions data into
$k$ clusters and minimizes the $k$-medians or $k$-means objective. The obtained
clustering is easy to interpret because every decision node of a threshold tree
splits data based on a single feature into two groups. We propose a new
algorithm for this problem which is $\tilde O(\log k)$ competitive with
$k$-medians with $\ell_1$ norm and $\tilde O(k)$ competitive with $k$-means.
This is an improvement over the previous guarantees of $O(k)$ and $O(k^2)$ by
Dasgupta et al (2020). We also provide a new algorithm which is $O(\log^{3/2}
k)$ competitive for $k$-medians with $\ell_2$ norm. Our first algorithm is
near-optimal: Dasgupta et al (2020) showed a lower bound of $\Omega(\log k)$
for $k$-medians; in this work, we prove a lower bound of $\tilde\Omega(k)$ for
$k$-means. We also provide a lower bound of $\Omega(\log k)$ for $k$-medians
with $\ell_2$ norm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shared Data and Algorithms for Deep Learning in Fundamental Physics. (arXiv:2107.00656v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benato_L/0/1/0/all/0/1">Lisa Benato</a>, <a href="http://arxiv.org/find/cs/1/au:+Buhmann_E/0/1/0/all/0/1">Erik Buhmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdmann_M/0/1/0/all/0/1">Martin Erdmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fackeldey_P/0/1/0/all/0/1">Peter Fackeldey</a>, <a href="http://arxiv.org/find/cs/1/au:+Glombitza_J/0/1/0/all/0/1">Jonas Glombitza</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartmann_N/0/1/0/all/0/1">Nikolai Hartmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/cs/1/au:+Korcari_W/0/1/0/all/0/1">William Korcari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhr_T/0/1/0/all/0/1">Thomas Kuhr</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinheimer_J/0/1/0/all/0/1">Jan Steinheimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Stocker_H/0/1/0/all/0/1">Horst St&#xf6;cker</a>, <a href="http://arxiv.org/find/cs/1/au:+Plehn_T/0/1/0/all/0/1">Tilman Plehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00656">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a collection of datasets from fundamental physics research --
including particle physics, astroparticle physics, and hadron- and nuclear
physics -- for supervised machine learning studies. These datasets, containing
hadronic top quarks, cosmic-ray induced air showers, phase transitions in
hadronic matter, and generator-level histories, are made public to simplify
future work on cross-disciplinary machine learning and transfer learning in
fundamental physics. Based on these data, we present a simple yet flexible
graph-based neural network architecture that can easily be applied to a wide
range of supervised learning tasks in these domains. We show that our approach
reaches performance close to state-of-the-art dedicated methods on all
datasets. To simplify adaptation for various problems, we provide
easy-to-follow instructions on how graph-based representations of data
structures, relevant for fundamental physics, can be constructed and provide
code implementations for several of them. Implementations are also provided for
our proposed method and all reference algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cell-average based neural network method for hyperbolic and parabolic partial differential equations. (arXiv:2107.00813v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Qiu_C/0/1/0/all/0/1">Changxin Qiu</a>, <a href="http://arxiv.org/find/math/1/au:+Yan_J/0/1/0/all/0/1">Jue Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00813">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by finite volume scheme, a cell-average based neural network method
is proposed. The method is based on the integral or weak formulation of partial
differential equations. A simple feed forward network is forced to learn the
solution average evolution between two neighboring time steps. Offline
supervised training is carried out to obtain the optimal network parameter set,
which uniquely identifies one finite volume like neural network method. Once
well trained, the network method is implemented as a finite volume scheme, thus
is mesh dependent. Different to traditional numerical methods, our method can
be relieved from the explicit scheme CFL restriction and can adapt to any time
step size for solution evolution. For Heat equation, first order of convergence
is observed and the errors are related to the spatial mesh size but are
observed independent of the mesh size in time. The cell-average based neural
network method can sharply evolve contact discontinuity with almost zero
numerical diffusion introduced. Shock and rarefaction waves are well captured
for nonlinear hyperbolic conservation laws.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios. (arXiv:2107.00717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1">Suraj Kothawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1">Krishnateja Killamsetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00717">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning has proven to be useful for minimizing labeling costs by
selecting the most informative samples. However, existing active learning
methods do not work well in realistic scenarios such as imbalance or rare
classes, out-of-distribution data in the unlabeled set, and redundancy. In this
work, we propose SIMILAR (Submodular Information Measures based actIve
LeARning), a unified active learning framework using recently proposed
submodular information measures (SIM) as acquisition functions. We argue that
SIMILAR not only works in standard active learning, but also easily extends to
the realistic settings considered above and acts as a one-stop solution for
active learning that is scalable to large real-world datasets. Empirically, we
show that SIMILAR significantly outperforms existing active learning algorithms
by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case
of out-of-distribution data on several image classification tasks like
CIFAR-10, MNIST, and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Experience Report on Machine Learning Reproducibility: Guidance for Practitioners and TensorFlow Model Garden Contributors. (arXiv:2107.00821v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banna_V/0/1/0/all/0/1">Vishnu Banna</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinnakotla_A/0/1/0/all/0/1">Akhil Chinnakotla</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhengxin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegesana_A/0/1/0/all/0/1">Ani Vegesana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vivek_N/0/1/0/all/0/1">Naveen Vivek</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnappa_K/0/1/0/all/0/1">Kruthi Krishnappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yung-Hsiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiruvathukal_G/0/1/0/all/0/1">George K. Thiruvathukal</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James C. Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00821">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques are becoming a fundamental tool for scientific
and engineering progress. These techniques are applied in contexts as diverse
as astronomy and spam filtering. However, correctly applying these techniques
requires careful engineering. Much attention has been paid to the technical
potential; relatively little attention has been paid to the software
engineering process required to bring research-based machine learning
techniques into practical utility. Technology companies have supported the
engineering community through machine learning frameworks such as TensorFLow
and PyTorch, but the details of how to engineer complex machine learning models
in these frameworks have remained hidden.

To promote best practices within the engineering community, academic
institutions and Google have partnered to launch a Special Interest Group on
Machine Learning Models (SIGMODELS) whose goal is to develop exemplary
implementations of prominent machine learning models in community locations
such as the TensorFlow Model Garden (TFMG). The purpose of this report is to
define a process for reproducing a state-of-the-art machine learning model at a
level of quality suitable for inclusion in the TFMG. We define the engineering
process and elaborate on each step, from paper analysis to model release. We
report on our experiences implementing the YOLO model family with a team of 26
student researchers, share the tools we developed, and describe the lessons we
learned along the way.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gap-Dependent Bounds for Two-Player Markov Games. (arXiv:2107.00685v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zehao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S.Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00685">
                                    <div class="article-summary-box-inner">
                                        <span>As one of the most popular methods in the field of reinforcement learning,
Q-learning has received increasing attention. Recently, there have been more
theoretical works on the regret bound of algorithms that belong to the
Q-learning class in different settings. In this paper, we analyze the
cumulative regret when conducting Nash Q-learning algorithm on 2-player
turn-based stochastic Markov games (2-TBSG), and propose the very first gap
dependent logarithmic upper bounds in the episodic tabular setting. This bound
matches the theoretical lower bound only up to a logarithmic term. Furthermore,
we extend the conclusion to the discounted game setting with infinite horizon
and propose a similar gap dependent logarithmic regret bound. Also, under the
linear MDP assumption, we obtain another logarithmic regret for 2-TBSG, in both
centralized and independent settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Map of Bandits for E-commerce. (arXiv:2107.00680v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lihong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00680">
                                    <div class="article-summary-box-inner">
                                        <span>The rich body of Bandit literature not only offers a diverse toolbox of
algorithms, but also makes it hard for a practitioner to find the right
solution to solve the problem at hand. Typical textbooks on Bandits focus on
designing and analyzing algorithms, and surveys on applications often present a
list of individual applications. While these are valuable resources, there
exists a gap in mapping applications to appropriate Bandit algorithms. In this
paper, we aim to reduce this gap with a structured map of Bandits to help
practitioners navigate to find relevant and practical Bandit algorithms.
Instead of providing a comprehensive overview, we focus on a small number of
key decision points related to reward, action, and features, which often affect
how Bandit algorithms are chosen in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets. (arXiv:2107.00860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyung_E/0/1/0/all/0/1">Eunyoung Hyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00860">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of recent Neural Architecture Search (NAS) methods on
various tasks which have shown to output networks that largely outperform
human-designed networks, conventional NAS methods have mostly tackled the
optimization of searching for the network architecture for a single task
(dataset), which does not generalize well across multiple tasks (datasets).
Moreover, since such task-specific methods search for a neural architecture
from scratch for every given task, they incur a large computational cost, which
is problematic when the time and monetary budget are limited. In this paper, we
propose an efficient NAS framework that is trained once on a database
consisting of datasets and pretrained networks and can rapidly search for a
neural architecture for a novel dataset. The proposed MetaD2A (Meta
Dataset-to-Architecture) model can stochastically generate graphs
(architectures) from a given set (dataset) via a cross-modal latent space
learned with amortized meta-learning. Moreover, we also propose a
meta-performance predictor to estimate and select the best architecture without
direct training on target datasets. The experimental results demonstrate that
our model meta-learned on subsets of ImageNet-1K and architectures from
NAS-Bench 201 search space successfully generalizes to multiple unseen datasets
including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU
seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than
NSGANetV2, a transferable NAS method, with comparable performance. We believe
that the MetaD2A proposes a new research direction for rapid NAS as well as
ways to utilize the knowledge from rich databases of datasets and architectures
accumulated over the past years. Code is available at
https://github.com/HayeonLee/MetaD2A.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploration noise for learning linear-quadratic mean field games. (arXiv:2107.00839v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Delarue_F/0/1/0/all/0/1">Fran&#xe7;ois Delarue</a>, <a href="http://arxiv.org/find/math/1/au:+Vasileiadis_A/0/1/0/all/0/1">Athanasios Vasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00839">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of this paper is to demonstrate that common noise may serve as an
exploration noise for learning the solution of a mean field game. This concept
is here exemplified through a toy linear-quadratic model, for which a suitable
form of common noise has already been proven to restore existence and
uniqueness. We here go one step further and prove that the same form of common
noise may force the convergence of the learning algorithm called &#x60;fictitious
play&#x27;, and this without any further potential or monotone structure. Several
numerical examples are provided in order to support our theoretical analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Robust Drug-Target Interaction Prediction via Ensemble Modeling and Transfer Learning. (arXiv:2107.00719v1 [q-bio.BM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Kao_P/0/1/0/all/0/1">Po-Yu Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kao_S/0/1/0/all/0/1">Shu-Min Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_N/0/1/0/all/0/1">Nan-Lan Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Chu Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00719">
                                    <div class="article-summary-box-inner">
                                        <span>Drug-target interaction (DTI) prediction plays a crucial role in drug
discovery, and deep learning approaches have achieved state-of-the-art
performance in this field. We introduce an ensemble of deep learning models
(EnsembleDLM) for robust DTI prediction. EnsembleDLM only uses the sequence
information of chemical compounds and proteins, and it aggregates the
predictions from multiple deep neural networks. This approach reduces the
chance of overfitting, yields an unbiased prediction, and achieves
state-of-the-art performance in Davis and KIBA datasets. EnsembleDLM also
reaches state-of-the-art performance in cross-domain applications and decent
cross-domain performance (Pearson correlation coefficient and concordance index
&gt; 0.8) with transfer learning using approximately twice the amount of test data
in the new domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inverse-Dirichlet Weighting Enables Reliable Training of Physics Informed Neural Networks. (arXiv:2107.00940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maddu_S/0/1/0/all/0/1">Suryanarayana Maddu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sturm_D/0/1/0/all/0/1">Dominik Sturm</a>, <a href="http://arxiv.org/find/cs/1/au:+M%7Fuller_C/0/1/0/all/0/1">Christian L. M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sbalzarini_I/0/1/0/all/0/1">Ivo F. Sbalzarini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00940">
                                    <div class="article-summary-box-inner">
                                        <span>We characterize and remedy a failure mode that may arise from multi-scale
dynamics with scale imbalances during training of deep neural networks, such as
Physics Informed Neural Networks (PINNs). PINNs are popular machine-learning
templates that allow for seamless integration of physical equation models with
data. Their training amounts to solving an optimization problem over a weighted
sum of data-fidelity and equation-fidelity objectives. Conflicts between
objectives can arise from scale imbalances, heteroscedasticity in the data,
stiffness of the physical equation, or from catastrophic interference during
sequential training. We explain the training pathology arising from this and
propose a simple yet effective inverse-Dirichlet weighting strategy to
alleviate the issue. We compare with Sobolev training of neural networks,
providing the baseline of analytically $\boldsymbol{\epsilon}$-optimal
training. We demonstrate the effectiveness of inverse-Dirichlet weighting in
various applications, including a multi-scale model of active turbulence, where
we show orders of magnitude improvement in accuracy and convergence over
conventional PINN training. For inverse modeling using sequential training, we
find that inverse-Dirichlet weighting protects a PINN against catastrophic
forgetting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Misinformation Detection on YouTube Using Video Captions. (arXiv:2107.00941v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jagtap_R/0/1/0/all/0/1">Raj Jagtap</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1">Rahul Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Shakshi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rajesh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+George_C/0/1/0/all/0/1">Clint P. George</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00941">
                                    <div class="article-summary-box-inner">
                                        <span>Millions of people use platforms such as YouTube, Facebook, Twitter, and
other mass media. Due to the accessibility of these platforms, they are often
used to establish a narrative, conduct propaganda, and disseminate
misinformation. This work proposes an approach that uses state-of-the-art NLP
techniques to extract features from video captions (subtitles). To evaluate our
approach, we utilize a publicly accessible and labeled dataset for classifying
videos as misinformation or not. The motivation behind exploring video captions
stems from our analysis of videos metadata. Attributes such as the number of
views, likes, dislikes, and comments are ineffective as videos are hard to
differentiate using this information. Using caption dataset, the proposed
models can classify videos among three classes (Misinformation, Debunking
Misinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the
relevance of the misinformation class, we re-formulate our classification
problem as a two-class classification - Misinformation vs. others (Debunking
Misinformation and Neutral). In our experiments, the proposed models can
classify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-F: A Transformer network with effective methods for learning universal sentence representation. (arXiv:2107.00653v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00653">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer model is widely used in natural language processing for
sentence representation. However, the previous Transformer-based models focus
on function words that have limited meaning in most cases and could merely
extract high-level semantic abstraction features. In this paper, two approaches
are introduced to improve the performance of Transformers. We calculated the
attention score by multiplying the part-of-speech weight vector with the
correlation coefficient, which helps extract the words with more practical
meaning. The weight vector is obtained by the input text sequence based on the
importance of the part-of-speech. Furthermore, we fuse the features of each
layer to make the sentence representation results more comprehensive and
accurate. In experiments, we demonstrate the effectiveness of our model
Transformer-F on three standard text classification datasets. Experimental
results show that our proposed model significantly boosts the performance of
text classification as compared to the baseline model. Specifically, we obtain
a 5.28% relative improvement over the vanilla Transformer on the simple tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decision tree heuristics can fail, even in the smoothed setting. (arXiv:2107.00819v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1">Guy Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1">Jane Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_M/0/1/0/all/0/1">Mingda Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1">Li-Yang Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00819">
                                    <div class="article-summary-box-inner">
                                        <span>Greedy decision tree learning heuristics are mainstays of machine learning
practice, but theoretical justification for their empirical success remains
elusive. In fact, it has long been known that there are simple target functions
for which they fail badly (Kearns and Mansour, STOC 1996).

Recent work of Brutzkus, Daniely, and Malach (COLT 2020) considered the
smoothed analysis model as a possible avenue towards resolving this disconnect.
Within the smoothed setting and for targets $f$ that are $k$-juntas, they
showed that these heuristics successfully learn $f$ with depth-$k$ decision
tree hypotheses. They conjectured that the same guarantee holds more generally
for targets that are depth-$k$ decision trees.

We provide a counterexample to this conjecture: we construct targets that are
depth-$k$ decision trees and show that even in the smoothed setting, these
heuristics build trees of depth $2^{\Omega(k)}$ before achieving high accuracy.
We also show that the guarantees of Brutzkus et al. cannot extend to the
agnostic setting: there are targets that are very close to $k$-juntas, for
which these heuristics build trees of depth $2^{\Omega(k)}$ before achieving
high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Causal Neural Connection: Expressiveness, Learnability, and Inference. (arXiv:2107.00793v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_K/0/1/0/all/0/1">Kevin Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kai-Zhan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1">Elias Bareinboim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00793">
                                    <div class="article-summary-box-inner">
                                        <span>One of the central elements of any causal inference is an object called
structural causal model (SCM), which represents a collection of mechanisms and
exogenous sources of random variation of the system under investigation (Pearl,
2000). An important property of many kinds of neural networks is universal
approximability: the ability to approximate any function to arbitrary
precision. Given this property, one may be tempted to surmise that a collection
of neural nets is capable of learning any SCM by training on data generated by
that SCM. In this paper, we show this is not the case by disentangling the
notions of expressivity and learnability. Specifically, we show that the causal
hierarchy theorem (Thm. 1, Bareinboim et al., 2020), which describes the limits
of what can be learned from data, still holds for neural models. For instance,
an arbitrarily complex and expressive neural net is unable to predict the
effects of interventions given observational data alone. Given this result, we
introduce a special type of SCM called a neural causal model (NCM), and
formalize a new type of inductive bias to encode structural constraints
necessary for performing causal inferences. Building on this new class of
models, we focus on solving two canonical tasks found in the literature known
as causal identification and estimation. Leveraging the neural toolbox, we
develop an algorithm that is both sufficient and necessary to determine whether
a causal effect can be learned from data (i.e., causal identifiability); it
then estimates the effect whenever identifiability holds (causal estimation).
Simulations corroborate the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Bridging Generic and Personalized Federated Learning. (arXiv:2107.00778v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hong-You Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00778">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is promising for its ability to collaboratively train
models with multiple clients without accessing their data, but vulnerable when
clients&#x27; data distributions diverge from each other. This divergence further
leads to a dilemma: &quot;Should we prioritize the learned model&#x27;s generic
performance (for future use at the server) or its personalized performance (for
each client)?&quot; These two, seemingly competing goals have divided the community
to focus on one or the other, yet in this paper we show that it is possible to
approach both at the same time. Concretely, we propose a novel federated
learning framework that explicitly decouples a model&#x27;s dual duties with two
prediction tasks. On the one hand, we introduce a family of losses that are
robust to non-identical class distributions, enabling clients to train a
generic predictor with a consistent objective across them. On the other hand,
we formulate the personalized predictor as a lightweight adaptive module that
is learned to minimize each client&#x27;s empirical risk on top of the generic
predictor. With this two-loss, two-predictor framework which we name Federated
Robust Decoupling Fed-RoD, the learned model can simultaneously achieve
state-of-the-art generic and personalized performance, essentially bridging the
two tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nitish Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00753">
                                    <div class="article-summary-box-inner">
                                        <span>While pretrained language models achieve excellent performance on natural
language understanding benchmarks, they tend to rely on spurious correlations
and generalize poorly to out-of-distribution (OOD) data. Recent work has
explored using counterfactually-augmented data (CAD) -- data generated by
minimally perturbing examples to flip the ground-truth label -- to identify
robust features that are invariant under distribution shift. However, empirical
results using CAD for OOD generalization have been mixed. To explain this
discrepancy, we draw insights from a linear Gaussian model and demonstrate the
pitfalls of CAD. Specifically, we show that (a) while CAD is effective at
identifying robust features, it may prevent the model from learning unperturbed
robust features, and (b) CAD may exacerbate existing spurious correlations in
the data. Our results show that the lack of perturbation diversity in current
CAD datasets limits its effectiveness on OOD generalization, calling for
innovative crowdsourcing procedures to elicit diverse perturbation of examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Primal Heuristics for Mixed Integer Programs. (arXiv:2107.00866v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yunzhuang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Eberhard_A/0/1/0/all/0/1">Andrew Eberhard</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00866">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel primal heuristic for Mixed Integer Programs, by
employing machine learning techniques. Mixed Integer Programming is a general
technique for formulating combinatorial optimization problems. Inside a solver,
primal heuristics play a critical role in finding good feasible solutions that
enable one to tighten the duality gap from the outset of the Branch-and-Bound
algorithm (B&amp;B), greatly improving its performance by pruning the B&amp;B tree
aggressively. In this paper, we investigate whether effective primal heuristics
can be automatically learned via machine learning. We propose a new method to
represent an optimization problem as a graph, and train a Graph Convolutional
Network on solved problem instances with known optimal solutions. This in turn
can predict the values of decision variables in the optimal solution for an
unseen problem instance of a similar type. The prediction of variable solutions
is then leveraged by a novel configuration of the B&amp;B method, Probabilistic
Branching with guided Depth-first Search (PB-DFS) approach, aiming to find
(near-)optimal solutions quickly. The experimental results show that this new
heuristic can find better primal solutions at a much earlier stage of the
solving process, compared to other state-of-the-art primal heuristics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Contrastive Learning for Accented Speech Recognition. (arXiv:2107.00921v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hantao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00921">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network based speech recognition systems suffer from performance
degradation due to accented speech, especially unfamiliar accents. In this
paper, we study the supervised contrastive learning framework for accented
speech recognition. To build different views (similar &quot;positive&quot; data samples)
for contrastive learning, three data augmentation techniques including noise
injection, spectrogram augmentation and TTS-same-sentence generation are
further investigated. From the experiments on the Common Voice dataset, we have
shown that contrastive learning helps to build data-augmentation invariant and
pronunciation invariant representations, which significantly outperforms
traditional joint training methods in both zero-shot and full-shot settings.
Experiments show that contrastive learning can improve accuracy by 3.66%
(zero-shot) and 3.78% (full-shot) on average, comparing to the joint training
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RL-NCS: Reinforcement learning based data-driven approach for nonuniform compressed sensing. (arXiv:2107.00838v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1">Nazmul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaeemzadeh_A/0/1/0/all/0/1">Alireza Zaeemzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1">Nazanin Rahnavard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00838">
                                    <div class="article-summary-box-inner">
                                        <span>A reinforcement-learning-based non-uniform compressed sensing (NCS) framework
for time-varying signals is introduced. The proposed scheme, referred to as
RL-NCS, aims to boost the performance of signal recovery through an optimal and
adaptive distribution of sensing energy among two groups of coefficients of the
signal, referred to as the region of interest (ROI) coefficients and non-ROI
coefficients. The coefficients in ROI usually have greater importance and need
to be reconstructed with higher accuracy compared to non-ROI coefficients. In
order to accomplish this task, the ROI is predicted at each time step using two
specific approaches. One of these approaches incorporates a long short-term
memory (LSTM) network for the prediction. The other approach employs the
previous ROI information for predicting the next step ROI. Using the
exploration-exploitation technique, a Q-network learns to choose the best
approach for designing the measurement matrix. Furthermore, a joint loss
function is introduced for the efficient training of the Q-network as well as
the LSTM network. The result indicates a significant performance gain for our
proposed method, even for rapidly varying signals and a reduced number of
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors. (arXiv:2107.00710v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1">Ulysse C&#xf4;t&#xe9;-Allard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_P/0/1/0/all/0/1">Petter Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stautland_A/0/1/0/all/0/1">Andrea Stautland</a>, <a href="http://arxiv.org/find/cs/1/au:+Nordgreen_T/0/1/0/all/0/1">Tine Nordgreen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fasmer_O/0/1/0/all/0/1">Ole Bernt Fasmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oedegaard_K/0/1/0/all/0/1">Ketil Joachim Oedegaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresen_J/0/1/0/all/0/1">Jim Torresen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00710">
                                    <div class="article-summary-box-inner">
                                        <span>Manic episodes of bipolar disorder can lead to uncritical behaviour and
delusional psychosis, often with destructive consequences for those affected
and their surroundings. Early detection and intervention of a manic episode are
crucial to prevent escalation, hospital admission and premature death. However,
people with bipolar disorder may not recognize that they are experiencing a
manic episode and symptoms such as euphoria and increased productivity can also
deter affected individuals from seeking help. This work proposes to perform
user-independent, automatic mood-state detection based on actigraphy and
electrodermal activity acquired from a wrist-worn device during mania and after
recovery (euthymia). This paper proposes a new deep learning-based ensemble
method leveraging long (20h) and short (5 minutes) time-intervals to
discriminate between the mood-states. When tested on 47 bipolar patients, the
proposed classification scheme achieves an average accuracy of 91.59% in
euthymic/manic mood-state recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning for Relative Density-Ratio Estimation. (arXiv:2107.00801v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a>, <a href="http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/stat/1/au:+Fujiwara_Y/0/1/0/all/0/1">Yasuhiro Fujiwara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00801">
                                    <div class="article-summary-box-inner">
                                        <span>The ratio of two probability densities, called a density-ratio, is a vital
quantity in machine learning. In particular, a relative density-ratio, which is
a bounded extension of the density-ratio, has received much attention due to
its stability and has been used in various applications such as outlier
detection and dataset comparison. Existing methods for (relative) density-ratio
estimation (DRE) require many instances from both densities. However,
sufficient instances are often unavailable in practice. In this paper, we
propose a meta-learning method for relative DRE, which estimates the relative
density-ratio from a few instances by using knowledge in related datasets.
Specifically, given two datasets that consist of a few instances, our model
extracts the datasets&#x27; information by using neural networks and uses it to
obtain instance embeddings appropriate for the relative DRE. We model the
relative density-ratio by a linear model on the embedded space, whose global
optimum solution can be obtained as a closed-form solution. The closed-form
solution enables fast and effective adaptation to a few instances, and its
differentiability enables us to train our model such that the expected test
error for relative DRE can be explicitly minimized after adapting to a few
instances. We empirically demonstrate the effectiveness of the proposed method
by using three problems: relative DRE, dataset comparison, and outlier
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">q-Paths: Generalizing the Geometric Annealing Path using Power Means. (arXiv:2107.00745v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Masrani_V/0/1/0/all/0/1">Vaden Masrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1">Rob Brekelmans</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Thang Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00745">
                                    <div class="article-summary-box-inner">
                                        <span>Many common machine learning methods involve the geometric annealing path, a
sequence of intermediate densities between two distributions of interest
constructed using the geometric average. While alternatives such as the
moment-averaging path have demonstrated performance gains in some settings,
their practical applicability remains limited by exponential family endpoint
assumptions and a lack of closed form energy function. In this work, we
introduce $q$-paths, a family of paths which is derived from a generalized
notion of the mean, includes the geometric and arithmetic mixtures as special
cases, and admits a simple closed form involving the deformed logarithm
function from nonextensive thermodynamics. Following previous analysis of the
geometric path, we interpret our $q$-paths as corresponding to a
$q$-exponential family of distributions, and provide a variational
representation of intermediate densities as minimizing a mixture of
$\alpha$-divergences to the endpoints. We show that small deviations away from
the geometric path yield empirical gains for Bayesian inference using
Sequential Monte Carlo and generative model evaluation using Annealed
Importance Sampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-shot Learning for Unsupervised Feature Selection. (arXiv:2107.00816v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujiwara_Y/0/1/0/all/0/1">Yasuhiro Fujiwara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00816">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a few-shot learning method for unsupervised feature selection,
which is a task to select a subset of relevant features in unlabeled data.
Existing methods usually require many instances for feature selection. However,
sufficient instances are often unavailable in practice. The proposed method can
select a subset of relevant features in a target task given a few unlabeled
target instances by training with unlabeled instances in multiple source tasks.
Our model consists of a feature selector and decoder. The feature selector
outputs a subset of relevant features taking a few unlabeled instances as input
such that the decoder can reconstruct the original features of unseen instances
from the selected ones. The feature selector uses the Concrete random variables
to select features via gradient descent. To encode task-specific properties
from a few unlabeled instances to the model, the Concrete random variables and
decoder are modeled using permutation-invariant neural networks that take a few
unlabeled instances as input. Our model is trained by minimizing the expected
test reconstruction error given a few unlabeled instances that is calculated
with datasets in source tasks. We experimentally demonstrate that the proposed
method outperforms existing feature selection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-Beat Interval Estimation with Tiramisu Model: A Novel Approach with Reduced Error. (arXiv:2107.00693v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arefeen_A/0/1/0/all/0/1">Asiful Arefeen</a>, <a href="http://arxiv.org/find/eess/1/au:+Akbari_A/0/1/0/all/0/1">Ali Akbari</a>, <a href="http://arxiv.org/find/eess/1/au:+Mirzadeh_S/0/1/0/all/0/1">Seyed Iman Mirzadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Jafari_R/0/1/0/all/0/1">Roozbeh Jafari</a>, <a href="http://arxiv.org/find/eess/1/au:+Shirazi_B/0/1/0/all/0/1">Behrooz A. Shirazi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghasemzadeh_H/0/1/0/all/0/1">Hassan Ghasemzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00693">
                                    <div class="article-summary-box-inner">
                                        <span>Inter-beat interval (IBI) measurement enables estimation of heart-rate
variability (HRV) which, in turns, can provide early indication of potential
cardiovascular diseases. However, extracting IBIs from noisy signals is
challenging since the morphology of the signal is distorted in the presence of
the noise. Electrocardiogram (ECG) of a person in heavy motion is highly
corrupted with noise, known as motion-artifact, and IBI extracted from it is
inaccurate. As a part of remote health monitoring and wearable system
development, denoising ECG signals and estimating IBIs correctly from them have
become an emerging topic among signal-processing researchers. Apart from
conventional methods, deep-learning techniques have been successfully used in
signal denoising recently, and diagnosis process has become easier, leading to
accuracy levels that were previously unachievable. We propose a deep-learning
approach leveraging tiramisu autoencoder model to suppress motion-artifact
noise and make the R-peaks of the ECG signal prominent even in the presence of
high-intensity motion. After denoising, IBIs are estimated more accurately
expediting diagnosis tasks. Results illustrate that our method enables IBI
estimation from noisy ECG signals with SNR up to -30dB with average root mean
square error (RMSE) of 13 milliseconds for estimated IBIs. At this noise level,
our error percentage remains below 8% and outperforms other state of the art
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability. (arXiv:2107.00833v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1">Mihaela Curmei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a>, <a href="http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00833">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider how preference models in interactive recommendation
systems determine the availability of content and users&#x27; opportunities for
discovery. We propose an evaluation procedure based on stochastic reachability
to quantify the maximum probability of recommending a target piece of content
to an user for a set of allowable strategic modifications. This framework
allows us to compute an upper bound on the likelihood of recommendation with
minimal assumptions about user behavior. Stochastic reachability can be used to
detect biases in the availability of content and diagnose limitations in the
opportunities for discovery granted to users. We show that this metric can be
computed efficiently as a convex program for a variety of practical settings,
and further argue that reachability is not inherently at odds with accuracy. We
demonstrate evaluations of recommendation algorithms trained on large datasets
of explicit and implicit ratings. Our results illustrate how preference models,
selection rules, and user interventions impact reachability and how these
effects can be distributed unevenly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Task Success Classifiers for Robotic Manipulation from Few Real Demonstrations. (arXiv:2107.00722v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohtasib_A/0/1/0/all/0/1">Abdalkarim Mohtasib</a>, <a href="http://arxiv.org/find/cs/1/au:+E%2E_A/0/1/0/all/0/1">Amir Ghalamzan E.</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellotto_N/0/1/0/all/0/1">Nicola Bellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuayahuitl_H/0/1/0/all/0/1">Heriberto Cuay&#xe1;huitl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00722">
                                    <div class="article-summary-box-inner">
                                        <span>Robots learning a new manipulation task from a small amount of demonstrations
are increasingly demanded in different workspaces. A classifier model assessing
the quality of actions can predict the successful completion of a task, which
can be used by intelligent agents for action-selection. This paper presents a
novel classifier that learns to classify task completion only from a few
demonstrations. We carry out a comprehensive comparison of different neural
classifiers, e.g. fully connected-based, fully convolutional-based,
sequence2sequence-based, and domain adaptation-based classification. We also
present a new dataset including five robot manipulation tasks, which is
publicly available. We compared the performances of our novel classifier and
the existing models using our dataset and the MIME dataset. The results suggest
domain adaptation and timing-based features improve success prediction. Our
novel model, i.e. fully convolutional neural network with domain adaptation and
timing features, achieves an average classification accuracy of 97.3\% and
95.5\% across tasks in both datasets whereas state-of-the-art classifiers
without domain adaptation and timing-features only achieve 82.4\% and 90.3\%,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Reinforcement Learning Tricks for Video Games. (arXiv:2107.00703v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanervisto_A/0/1/0/all/0/1">Anssi Kanervisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1">Christian Scheller</a>, <a href="http://arxiv.org/find/cs/1/au:+Schraner_Y/0/1/0/all/0/1">Yanick Schraner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hautamaki_V/0/1/0/all/0/1">Ville Hautam&#xe4;ki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00703">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) research focuses on general solutions that can be
applied across different domains. This results in methods that RL practitioners
can use in almost any domain. However, recent studies often lack the
engineering steps (&quot;tricks&quot;) which may be needed to effectively use RL, such as
reward shaping, curriculum learning, and splitting a large task into smaller
chunks. Such tricks are common, if not necessary, to achieve state-of-the-art
results and win RL competitions. To ease the engineering efforts, we distill
descriptions of tricks from state-of-the-art results and study how well these
tricks can improve a standard deep Q-learning agent. The long-term goal of this
work is to enable combining proven RL methods with domain-specific tricks by
providing a unified software framework and accompanying insights in multiple
domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Bike Spreading Problem. (arXiv:2107.00761v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_E/0/1/0/all/0/1">Elia Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1">Francesco Silvestri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00761">
                                    <div class="article-summary-box-inner">
                                        <span>A free-floating bike-sharing system (FFBSS) is a dockless rental system where
an individual can borrow a bike and returns it everywhere, within the service
area. To improve the rental service, available bikes should be distributed over
the entire service area: a customer leaving from any position is then more
likely to find a near bike and then to use the service. Moreover, spreading
bikes among the entire service area increases urban spatial equity since the
benefits of FFBSS are not a prerogative of just a few zones. For guaranteeing
such distribution, the FFBSS operator can use vans to manually relocate bikes,
but it incurs high economic and environmental costs. We propose a novel
approach that exploits the existing bike flows generated by customers to
distribute bikes. More specifically, by envisioning the problem as an Influence
Maximization problem, we show that it is possible to position batches of bikes
on a small number of zones, and then the daily use of FFBSS will efficiently
spread these bikes on a large area. We show that detecting these areas is
NP-complete, but there exists a simple and efficient $1-1/e$ approximation
algorithm; our approach is then evaluated on a dataset of rides from the
free-floating bike-sharing system of the city of Padova.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Almost Tight Approximation Algorithms for Explainable Clustering. (arXiv:2107.00774v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Esfandiari_H/0/1/0/all/0/1">Hossein Esfandiari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, due to an increasing interest for transparency in artificial
intelligence, several methods of explainable machine learning have been
developed with the simultaneous goal of accuracy and interpretability by
humans. In this paper, we study a recent framework of explainable clustering
first suggested by Dasgupta et al.~\cite{dasgupta2020explainable}.
Specifically, we focus on the $k$-means and $k$-medians problems and provide
nearly tight upper and lower bounds.

First, we provide an $O(\log k \log \log k)$-approximation algorithm for
explainable $k$-medians, improving on the best known algorithm of
$O(k)$~\cite{dasgupta2020explainable} and nearly matching the known
$\Omega(\log k)$ lower bound~\cite{dasgupta2020explainable}. In addition, in
low-dimensional spaces $d \ll \log k$, we show that our algorithm also provides
an $O(d \log^2 d)$-approximate solution for explainable $k$-medians. This
improves over the best known bound of $O(d \log k)$ for low
dimensions~\cite{laber2021explainable}, and is a constant for constant
dimensional spaces. To complement this, we show a nearly matching $\Omega(d)$
lower bound. Next, we study the $k$-means problem in this context and provide
an $O(k \log k)$-approximation algorithm for explainable $k$-means, improving
over the $O(k^2)$ bound of Dasgupta et al. and the $O(d k \log k)$ bound of
\cite{laber2021explainable}. To complement this we provide an almost tight
$\Omega(k)$ lower bound, improving over the $\Omega(\log k)$ lower bound of
Dasgupta et al. All our algorithms run in near linear time in the number of
points and the dimension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Deep Reinforcement Learning Based Stock Direction Prediction using Knowledge Graph and Community Aware Sentiments. (arXiv:2107.00931v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altuner_A/0/1/0/all/0/1">Anil Berk Altuner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1">Zeynep Hilal Kilimci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00931">
                                    <div class="article-summary-box-inner">
                                        <span>Stock market prediction has been an important topic for investors,
researchers, and analysts. Because it is affected by too many factors, stock
market prediction is a difficult task to handle. In this study, we propose a
novel method that is based on deep reinforcement learning methodologies for the
direction prediction of stocks using sentiments of community and knowledge
graph. For this purpose, we firstly construct a social knowledge graph of users
by analyzing relations between connections. After that, time series analysis of
related stock and sentiment analysis is blended with deep reinforcement
methodology. Turkish version of Bidirectional Encoder Representations from
Transformers (BerTurk) is employed to analyze the sentiments of the users while
deep Q-learning methodology is used for the deep reinforcement learning side of
the proposed model to construct the deep Q network. In order to demonstrate the
effectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK),
T\&quot;urkiye \.I\c{s} Bankas{\i} (ISCTR) stocks in Istanbul Stock Exchange are
used as a case study. Experiment results show that the proposed novel model
achieves remarkable results for stock market prediction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalizing Flow based Hidden Markov Models for Classification of Speech Phones with Explainability. (arXiv:2107.00730v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anubhab Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Honore_A/0/1/0/all/0/1">Antoine Honor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Saikat Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00730">
                                    <div class="article-summary-box-inner">
                                        <span>In pursuit of explainability, we develop generative models for sequential
data. The proposed models provide state-of-the-art classification results and
robust performance for speech phone classification. We combine modern neural
networks (normalizing flows) and traditional generative models (hidden Markov
models - HMMs). Normalizing flow-based mixture models (NMMs) are used to model
the conditional probability distribution given the hidden state in the HMMs.
Model parameters are learned through judicious combinations of time-tested
Bayesian learning methods and contemporary neural network learning methods. We
mainly combine expectation-maximization (EM) and mini-batch gradient descent.
The proposed generative models can compute likelihood of a data and hence
directly suitable for maximum-likelihood (ML) classification approach. Due to
structural flexibility of HMMs, we can use different normalizing flow models.
This leads to different types of HMMs providing diversity in data modeling
capacity. The diversity provides an opportunity for easy decision fusion from
different models. For a standard speech phone classification setup involving 39
phones (classes) and the TIMIT dataset, we show that the use of standard
features called mel-frequency-cepstral-coeffcients (MFCCs), the proposed
generative models, and the decision fusion together can achieve $86.6\%$
accuracy by generative training only. This result is close to state-of-the-art
results, for examples, $86.2\%$ accuracy of PyTorch-Kaldi toolkit [1], and
$85.1\%$ accuracy using light gated recurrent units [2]. We do not use any
discriminative learning approach and related sophisticated features in this
article.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flow-based sampling for multimodal distributions in lattice field theory. (arXiv:2107.00734v1 [hep-lat])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1">Daniel C. Hackett</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Hsieh_C/0/1/0/all/0/1">Chung-Chun Hsieh</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1">Michael S. Albergo</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1">Denis Boyda</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Chen_J/0/1/0/all/0/1">Jiunn-Wei Chen</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Chen_K/0/1/0/all/0/1">Kai-Feng Chen</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1">Kyle Cranmer</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1">Gurtej Kanwar</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1">Phiala E. Shanahan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00734">
                                    <div class="article-summary-box-inner">
                                        <span>Recent results have demonstrated that samplers constructed with flow-based
generative models are a promising new approach for configuration generation in
lattice field theory. In this paper, we present a set of methods to construct
flow models for targets with multiple separated modes (i.e. theories with
multiple vacua). We demonstrate the application of these methods to modeling
two-dimensional real scalar field theory in its symmetry-broken phase. In this
context we investigate the performance of different flow-based sampling
algorithms, including a composite sampling algorithm where flow-based proposals
are occasionally augmented by applying updates using traditional algorithms
like HMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.410 for valence and 0.661 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instagrammable Data: Using Visuals to Showcase More Than Numbers on AJ Labs Instagram Page. (arXiv:2107.00938v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+de_Lima_Santos_M/0/1/0/all/0/1">Mathias-Felipe de-Lima-Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kooli_A/0/1/0/all/0/1">Arwa Kooli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00938">
                                    <div class="article-summary-box-inner">
                                        <span>News outlets are developing formats dedicated to social platforms that
capture audience attention, such as Instagram stories, Facebook Instant
articles, and YouTube videos. In some cases, these formats are created in
collaboration with the tech companies themselves. At the same time, the use of
data-driven storytelling is becoming increasingly integrated into the
ever-complex business models of news outlets, generating more impact and
visibility. Previous studies have focused on studying these two effects
separately. To address this gap in the literature, this paper identifies and
analyzes the use of data journalism on the Instagram content of AJ Labs, the
team dedicated to producing data-driven and interactive stories for the Al
Jazeera news network. Drawing upon a mixed-method approach, this study examines
the use and characteristics of data stories on social media platforms. Results
suggest that there is reliance on producing visual content that covers topics
such as politics and violence. In general, AJ Labs relies on the use of
infographics and produces its own unique data. To conclude, this paper suggests
potential ways to improve the use of Instagram to tell data stories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-02">2021-07-02</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards the evaluation of automatic simultaneous speech translation from a communicative perspective. (arXiv:2103.08364v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fantinuoli_C/0/1/0/all/0/1">Claudio Fantinuoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Prandi_B/0/1/0/all/0/1">Bianca Prandi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08364">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, automatic speech-to-speech and speech-to-text translation
has gained momentum thanks to advances in artificial intelligence, especially
in the domains of speech recognition and machine translation. The quality of
such applications is commonly tested with automatic metrics, such as BLEU,
primarily with the goal of assessing improvements of releases or in the context
of evaluation campaigns. However, little is known about how the output of such
systems is perceived by end users or how they compare to human performances in
similar communicative tasks.

In this paper, we present the results of an experiment aimed at evaluating
the quality of a real-time speech translation engine by comparing it to the
performance of professional simultaneous interpreters. To do so, we adopt a
framework developed for the assessment of human interpreters and use it to
perform a manual evaluation on both human and machine performances. In our
sample, we found better performance for the human interpreters in terms of
intelligibility, while the machine performs slightly better in terms of
informativeness. The limitations of the study and the possible enhancements of
the chosen framework are discussed. Despite its intrinsic limitations, the use
of this framework represents a first step towards a user-centric and
communication-oriented methodology for evaluating real-time automatic speech
translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPBERT: An Efficient Pre-training BERT on SPARQL Queries for Question Answering over Knowledge Graphs. (arXiv:2106.09997v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1">Hieu Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1">Long Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Anibal_J/0/1/0/all/0/1">James Anibal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Truong-Son Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09997">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose SPBERT, a transformer-based language model
pre-trained on massive SPARQL query logs. By incorporating masked language
modeling objectives and the word structural objective, SPBERT can learn
general-purpose representations in both natural language and SPARQL query
language. We investigate how SPBERT and encoder-decoder architecture can be
adapted for Knowledge-based QA corpora. We conduct exhaustive experiments on
two additional tasks, including SPARQL Query Construction and Answer
Verbalization Generation. The experimental results show that SPBERT can obtain
promising results, achieving state-of-the-art BLEU scores on several of these
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Graph-based Transformer Framework for Biomedical Relation Extraction. (arXiv:2107.00596v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pingali_S/0/1/0/all/0/1">Sriram Pingali</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_S/0/1/0/all/0/1">Shweta Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_P/0/1/0/all/0/1">Pratik Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sriparna Saha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00596">
                                    <div class="article-summary-box-inner">
                                        <span>The recent advancement of pre-trained Transformer models has propelled the
development of effective text mining models across various biomedical tasks.
However, these models are primarily learned on the textual data and often lack
the domain knowledge of the entities to capture the context beyond the
sentence. In this study, we introduced a novel framework that enables the model
to learn multi-omnics biological information about entities (proteins) with the
help of additional multi-modal cues like molecular structure. Towards this,
rather developing modality-specific architectures, we devise a generalized and
optimized graph based multi-modal learning mechanism that utilizes the
GraphBERT model to encode the textual and molecular structure information and
exploit the underlying features of various modalities to enable end-to-end
learning. We evaluated our proposed method on ProteinProtein Interaction task
from the biomedical corpus, where our proposed generalized approach is observed
to be benefited by the additional domain-specific modality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis. (arXiv:2107.00439v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1">Nadir Durrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00439">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end DNN architectures have pushed the state-of-the-art in speech
technologies, as well as in other spheres of AI, leading researchers to train
more complex and deeper models. These improvements came at the cost of
transparency. DNNs are innately opaque and difficult to interpret. We no longer
understand what features are learned, where they are preserved, and how they
inter-operate. Such an analysis is important for better model understanding,
debugging and to ensure fairness in ethical decision making. In this work, we
analyze the representations trained within deep speech models, towards the task
of speaker recognition, dialect identification and reconstruction of masked
signals. We carry a layer- and neuron-level analysis on the utterance-level
representations captured within pretrained speech models for speaker, language
and channel properties. We study: is this information captured in the learned
representations? where is it preserved? how is it distributed? and can we
identify a minimal subset of network that posses this information. Using
diagnostic classifiers, we answered these questions. Our results reveal: (i)
channel and gender information is omnipresent and is redundantly distributed
(ii) complex properties such as dialectal information is encoded only in the
task-oriented pretrained network and is localised in the upper layers (iii) a
minimal subset of neurons can be extracted to encode the predefined property
(iv) salient neurons are sometimes shared between properties and can highlights
presence of biases in the network. Our cross-architectural comparison indicates
that (v) the pretrained models captures speaker-invariant information and (vi)
the pretrained CNNs models are competitive to the Transformers for encoding
information for the studied properties. To the best of our knowledge, this is
the first study to investigate neuron analysis on the speech models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training. (arXiv:2009.12064v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kitada_S/0/1/0/all/0/1">Shunsuke Kitada</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12064">
                                    <div class="article-summary-box-inner">
                                        <span>Although attention mechanisms have been applied to a variety of deep learning
models and have been shown to improve the prediction performance, it has been
reported to be vulnerable to perturbations to the mechanism. To overcome the
vulnerability to perturbations in the mechanism, we are inspired by adversarial
training (AT), which is a powerful regularization technique for enhancing the
robustness of the models. In this paper, we propose a general training
technique for natural language processing tasks, including AT for attention
(Attention AT) and more interpretable AT for attention (Attention iAT). The
proposed techniques improved the prediction performance and the model
interpretability by exploiting the mechanisms with AT. In particular, Attention
iAT boosts those advantages by introducing adversarial perturbation, which
enhances the difference in the attention of the sentences. Evaluation
experiments with ten open datasets revealed that AT for attention mechanisms,
especially Attention iAT, demonstrated (1) the best performance in nine out of
ten tasks and (2) more interpretable attention (i.e., the resulting attention
correlated more strongly with gradient-based word importance) for all tasks.
Additionally, the proposed techniques are (3) much less dependent on
perturbation size in AT. Our code is available at
https://github.com/shunk031/attention-meets-perturbation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR. (arXiv:2107.00635v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Inaguma_H/0/1/0/all/0/1">Hirofumi Inaguma</a>, <a href="http://arxiv.org/find/eess/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00635">
                                    <div class="article-summary-box-inner">
                                        <span>While attention-based encoder-decoder (AED) models have been successfully
extended to the online variants for streaming automatic speech recognition
(ASR), such as monotonic chunkwise attention (MoChA), the models still have a
large label emission latency because of the unconstrained end-to-end training
objective. Previous works tackled this problem by leveraging alignment
information to control the timing to emit tokens during training. In this work,
we propose a simple alignment-free regularization method, StableEmit, to
encourage MoChA to emit tokens earlier. StableEmit discounts the selection
probabilities in hard monotonic attention for token boundary detection by a
constant factor and regularizes them to recover the total attention mass during
training. As a result, the scale of the selection probabilities is increased,
and the values can reach a threshold for token emission earlier, leading to a
reduction of emission latency and deletion errors. Moreover, StableEmit can be
combined with methods that constraint alignments to further improve the
accuracy and latency. Experimental evaluations with LSTM and Conformer encoders
demonstrate that StableEmit significantly reduces the recognition errors and
the emission latency simultaneously. We also show that the use of alignment
information is complementary in both metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention. (arXiv:2103.15722v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chengdong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Menglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15722">
                                    <div class="article-summary-box-inner">
                                        <span>Self-attention (SA), which encodes vector sequences according to their
pairwise similarity, is widely used in speech recognition due to its strong
context modeling ability. However, when applied to long sequence data, its
accuracy is reduced. This is caused by the fact that its weighted average
operator may lead to the dispersion of the attention distribution, which
results in the relationship between adjacent signals ignored. To address this
issue, in this paper, we introduce relative-position-awareness self-attention
(RPSA). It not only maintains the global-range dependency modeling ability of
self-attention, but also improves the localness modeling ability. Because the
local window length of the original RPSA is fixed and sensitive to different
test data, here we propose Gaussian-based self-attention (GSA) whose window
length is learnable and adaptive to the test data automatically. We further
generalize GSA to a new residual Gaussian self-attention (resGSA) for the
performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based
speech recognition respectively. Experimental results on the AISHELL-1 Mandarin
speech recognition corpus demonstrate the effectiveness of the proposed
methods. For example, the resGSA-Transformer achieves a character error rate
(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the
SA-Transformer. Although the performance of the proposed resGSA-Transformer is
only slightly better than that of the RPSA-Transformer, it does not have to
tune the window length manually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft&#x27;s Submission to SwissText 2021. (arXiv:2106.08126v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1">Yuriy Arabskyy</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1">Aashish Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1">Subhadeep Dey</a>, <a href="http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1">Oscar Koller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08126">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the winning approach in the Shared Task 3 at SwissText
2021 on Swiss German Speech to Standard German Text, a public competition on
dialect recognition and translation. Swiss German refers to the multitude of
Alemannic dialects spoken in the German-speaking parts of Switzerland. Swiss
German differs significantly from standard German in pronunciation, word
inventory and grammar. It is mostly incomprehensible to native German speakers.
Moreover, it lacks a standardized written script. To solve the challenging
task, we propose a hybrid automatic speech recognition system with a lexicon
that incorporates translations, a 1st pass language model that deals with Swiss
German particularities, a transfer-learned acoustic model and a strong neural
language model for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a
blind conversational test set and outperforms the second best competitor by a
12% relative margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keyboards as a new model of computation. (arXiv:2102.10182v3 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geran_Y/0/1/0/all/0/1">Yoan G&#xe9;ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Laboureix_B/0/1/0/all/0/1">Bastien Laboureix</a>, <a href="http://arxiv.org/find/cs/1/au:+Mascle_C/0/1/0/all/0/1">Corto Mascle</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_V/0/1/0/all/0/1">Valentin D. Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10182">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new formalisation of languages, called keyboards. We consider
a set of elementary operations (writing/erasing a letter, going to the right or
to the left,...) and we define a keyboard as a set of finite sequences of such
operations, called keys. The corresponding language is the set of words
obtained by applying some sequence of those keys. Unlike classical models of
computation, every key can be applied anytime. We define various classes of
languages based on different sets of elementary operations, and compare their
expressive powers. We also compare them to well-known classes of languages
(Chomsky hierarchy). We obtain a strict hierarchy of languages, whose
expressivity is orthogonal to the one of the aforementionned classical models.

--

Nous introduisons une nouvelle repr\&#x27;esentation de langages, les claviers. On
se munit d&#x27;un ensemble d&#x27;op\&#x27;erations \&#x27;el\&#x27;ementaires (ajout, effacement d&#x27;une
lettre, d\&#x27;eplacement \&#x60;a droite, \&#x60;a gauche, ...), et on d\&#x27;efinit un clavier
comme un ensemble de suites finies d&#x27;op\&#x27;erations \&#x27;el\&#x27;ementaires, appel\&#x27;ees
touches. Son langage sera l&#x27;ensemble des mots obtenus en appliquant une suite
quelconque de touches. Contrairement \&#x60;a des mod\&#x60;eles de calcul classiques,
toutes les touches peuvent \^etre appliqu\&#x27;ees \&#x60;a tout moment. En premier lieu
nous d\&#x27;efinissons diff\&#x27;erentes classes de claviers en faisant varier
l&#x27;ensemble des op\&#x27;erations \&#x27;el\&#x27;ementaires autoris\&#x27;ees, et nous comparons
l&#x27;expressivit\&#x27;e des classes de langages obtenues. Nous comparons \&#x27;egalement
ces classes \&#x60;a la hi\&#x27;erarchie de Chomsky. Nous obtenons que toutes les
classes \&#x27;etudi\&#x27;ees sont diff\&#x27;erentes, et nous caract\&#x27;erisons les classes
inclues dans les rationnels et les alg\&#x27;ebriques. L&#x27;expressivit\&#x27;e des claviers
semble orthogonale \&#x60;a celle des mod\&#x60;eles \&#x27;evoqu\&#x27;es pr\&#x27;ec\&#x27;edemment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Generation of Temporally-ordered Event Sequences. (arXiv:2012.15786v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shih-Ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15786">
                                    <div class="article-summary-box-inner">
                                        <span>Models of narrative schema knowledge have proven useful for a range of
event-related tasks, but they typically do not capture the temporal
relationships between events. We propose a single model that addresses both
temporal ordering, sorting given events into the order they occurred, and event
infilling, predicting new events which fit into an existing temporally-ordered
sequence. We use a BART-based conditional generation model that can capture
both temporality and common event co-occurrence, meaning it can be flexibly
applied to different tasks in this space. Our model is trained as a denoising
autoencoder: we take temporally-ordered event sequences, shuffle them, delete
some events, and then attempt to recover the original event sequence. This task
teaches the model to make inferences given incomplete knowledge about the
events in an underlying scenario. On the temporal ordering task, we show that
our model is able to unscramble event sequences from existing datasets without
access to explicitly labeled temporal training data, outperforming both a
BERT-based pairwise model and a BERT-based pointer network. On event infilling,
human evaluation shows that our model is able to generate events that fit
better temporally into the input events when compared to GPT-2 story completion
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSNoise: An Effective Countermeasure Against Topic Biases in Authorship Analysis. (arXiv:2005.06605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halvani_O/0/1/0/all/0/1">Oren Halvani</a>, <a href="http://arxiv.org/find/cs/1/au:+Graner_L/0/1/0/all/0/1">Lukas Graner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06605">
                                    <div class="article-summary-box-inner">
                                        <span>Authorship verification (AV) is a fundamental research task in digital text
forensics, which addresses the problem of whether two texts were written by the
same person. In recent years, a variety of AV methods have been proposed that
focus on this problem and can be divided into two categories: The first
category refers to such methods that are based on explicitly defined features,
where one has full control over which features are considered and what they
actually represent. The second category, on the other hand, relates to such AV
methods that are based on implicitly defined features, where no control
mechanism is involved, so that any character sequence in a text can serve as a
potential feature. However, AV methods belonging to the second category bear
the risk that the topic of the texts may bias their classification predictions,
which in turn may lead to misleading conclusions regarding their results. To
tackle this problem, we propose a preprocessing technique called POSNoise,
which effectively masks topic-related content in a given text. In this way, AV
methods are forced to focus on such text units that are more related to the
writing style. Our empirical evaluation based on six AV methods (falling into
the second category) and seven corpora shows that POSNoise leads to better
results compared to a well-known topic masking approach in 34 out of 42 cases,
with an increase in accuracy of up to 10%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Feature and Instance Attribution to Detect Artifacts. (arXiv:2107.00323v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1">Pouya Pezeshkpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sarthak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00323">
                                    <div class="article-summary-box-inner">
                                        <span>Training the large deep neural networks that dominate NLP requires large
datasets. Many of these are collected automatically or via crowdsourcing, and
may exhibit systematic biases or annotation artifacts. By the latter, we mean
correlations between inputs and outputs that are spurious, insofar as they do
not represent a generally held causal relationship between features and
classes; models that exploit such correlations may appear to perform a given
task well, but fail on out of sample data. In this paper we propose methods to
facilitate identification of training data artifacts, using new hybrid
approaches that combine saliency maps (which highlight important input
features) with instance attribution methods (which retrieve training samples
influential to a given prediction). We show that this proposed training-feature
attribution approach can be used to uncover artifacts in training data, and use
it to identify previously unreported artifacts in a few standard NLP datasets.
We execute a small user study to evaluate whether these methods are useful to
NLP researchers in practice, with promising results. We make code for all
methods and experiments in this paper available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Dependency Parsing for Semi-Structured Document Information Extraction. (arXiv:2005.00642v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonseok Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yim_J/0/1/0/all/0/1">Jinyeong Yim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sohee Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minjoon Seo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00642">
                                    <div class="article-summary-box-inner">
                                        <span>Information Extraction (IE) for semi-structured document images is often
approached as a sequence tagging problem by classifying each recognized input
token into one of the IOB (Inside, Outside, and Beginning) categories. However,
such problem setup has two inherent limitations that (1) it cannot easily
handle complex spatial relationships and (2) it is not suitable for highly
structured information, which are nevertheless frequently observed in
real-world document images. To tackle these issues, we first formulate the IE
task as spatial dependency parsing problem that focuses on the relationship
among text tokens in the documents. Under this setup, we then propose SPADE
(SPAtial DEpendency parser) that models highly complex spatial relationships
and an arbitrary number of information layers in the documents in an end-to-end
manner. We evaluate it on various kinds of documents such as receipts, name
cards, forms, and invoices, and show that it achieves a similar or better
performance compared to strong baselines including BERT-based IOB taggger.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding. (arXiv:2107.00440v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Piji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00440">
                                    <div class="article-summary-box-inner">
                                        <span>Despite pre-trained language models have proven useful for learning
high-quality semantic representations, these models are still vulnerable to
simple perturbations. Recent works aimed to improve the robustness of
pre-trained models mainly focus on adversarial training from perturbed examples
with similar semantics, neglecting the utilization of different or even
opposite semantics. Different from the image processing field, the text is
discrete and few word substitutions can cause significant semantic changes. To
study the impact of semantics caused by small perturbations, we conduct a
series of pilot experiments and surprisingly find that adversarial training is
useless or even harmful for the model to detect these semantic changes. To
address this problem, we propose Contrastive Learning with semantIc Negative
Examples (CLINE), which constructs semantic negative examples unsupervised to
improve the robustness under semantically adversarial attacking. By comparing
with similar and opposite semantic examples, the model can effectively perceive
the semantic changes caused by small perturbations. Empirical results show that
our approach yields substantial improvements on a range of sentiment analysis,
reasoning, and reading comprehension tasks. And CLINE also ensures the
compactness within the same semantics and separability across different
semantics in sentence-level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of COVID-19 related Fake News via Neural Stacking. (arXiv:2101.03988v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1">Boshko Koloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdih_T/0/1/0/all/0/1">Timen Stepi&#x161;nik Perdih</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1">Senja Pollak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1">Bla&#x17e; &#x160;krlj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03988">
                                    <div class="article-summary-box-inner">
                                        <span>Identification of Fake News plays a prominent role in the ongoing pandemic,
impacting multiple aspects of day-to-day life. In this work we present a
solution to the shared task titled COVID19 Fake News Detection in English,
scoring the 50th place amongst 168 submissions. The solution was within 1.5% of
the best performing solution. The proposed solution employs a heterogeneous
representation ensemble, adapted for the classification task via an additional
neural classification head comprised of multiple hidden layers. The paper
consists of detailed ablation studies further displaying the proposed method&#x27;s
behavior and possible implications. The solution is freely available.
\url{https://gitlab.com/boshko.koloski/covid19-fake-news}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Zero-Shot Translation by Disentangling Positional Information. (arXiv:2012.15127v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Danni Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1">Jan Niehues</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_J/0/1/0/all/0/1">James Cross</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_F/0/1/0/all/0/1">Francisco Guzm&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xian Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15127">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual neural machine translation has shown the capability of directly
translating between language pairs unseen in training, i.e. zero-shot
translation. Despite being conceptually attractive, it often suffers from low
output quality. The difficulty of generalizing to new translation directions
suggests the model representations are highly specific to those language pairs
seen in training. We demonstrate that a main factor causing the
language-specific representations is the positional correspondence to input
tokens. We show that this can be easily alleviated by removing residual
connections in an encoder layer. With this modification, we gain up to 18.5
BLEU points on zero-shot translation while retaining quality on supervised
directions. The improvements are particularly prominent between related
languages, where our proposed model outperforms pivot-based translation.
Moreover, our approach allows easy integration of new languages, which
substantially expands translation coverage. By thorough inspections of the
hidden layer outputs, we show that our approach indeed leads to more
language-independent representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ESPnet-ST IWSLT 2021 Offline Speech Translation System. (arXiv:2107.00636v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Inaguma_H/0/1/0/all/0/1">Hirofumi Inaguma</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_B/0/1/0/all/0/1">Brian Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Dalmia_S/0/1/0/all/0/1">Siddharth Dalmia</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_P/0/1/0/all/0/1">Pengcheng Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1">Jiatong Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Duh_K/0/1/0/all/0/1">Kevin Duh</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00636">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the ESPnet-ST group&#x27;s IWSLT 2021 submission in the
offline speech translation track. This year we made various efforts on training
data, architecture, and audio segmentation. On the data side, we investigated
sequence-level knowledge distillation (SeqKD) for end-to-end (E2E) speech
translation. Specifically, we used multi-referenced SeqKD from multiple
teachers trained on different amounts of bitext. On the architecture side, we
adopted the Conformer encoder and the Multi-Decoder architecture, which equips
dedicated decoders for speech recognition and translation tasks in a unified
encoder-decoder model and enables search in both source and target language
spaces during inference. We also significantly improved audio segmentation by
using the pyannote.audio toolkit and merging multiple short segments for long
context modeling. Experimental evaluations showed that each of them contributed
to large improvements in translation performance. Our best E2E system combined
all the above techniques with model ensembling and achieved 31.4 BLEU on the
2-ref of tst2021 and 21.2 BLEU and 19.3 BLEU on the two single references of
tst2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Learning-Based Approach for Improving Generalization Capability of Machine Reading Comprehension Systems. (arXiv:2107.00368v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baradaran_R/0/1/0/all/0/1">Razieh Baradaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirkhani_H/0/1/0/all/0/1">Hossein Amirkhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00368">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Reading Comprehension (MRC) is an active field in natural language
processing with many successful developed models in recent years. Despite their
high in-distribution accuracy, these models suffer from two issues: high
training cost and low out-of-distribution accuracy. Even though some approaches
have been presented to tackle the generalization problem, they have high,
intolerable training costs. In this paper, we investigate the effect of
ensemble learning approach to improve generalization of MRC systems without
retraining a big model. After separately training the base models with
different structures on different datasets, they are ensembled using weighting
and stacking approaches in probabilistic and non-probabilistic settings. Three
configurations are investigated including heterogeneous, homogeneous, and
hybrid on eight datasets and six state-of-the-art models. We identify the
important factors in the effectiveness of ensemble methods. Also, we compare
the robustness of ensemble and fine-tuned models against data distribution
shifts. The experimental results show the effectiveness and robustness of the
ensemble approach in improving the out-of-distribution accuracy of MRC systems,
especially when the base models are similar in accuracies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph. (arXiv:2107.00395v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00395">
                                    <div class="article-summary-box-inner">
                                        <span>Previous works indicate that the glyph of Chinese characters contains rich
semantic information and has the potential to enhance the representation of
Chinese characters. The typical method to utilize the glyph features is by
incorporating them into the character embedding space. Inspired by previous
methods, we innovatively propose a Chinese pre-trained representation model
named as GlyphCRM, which abandons the ID-based character embedding method yet
solely based on sequential character images. We render each character into a
binary grayscale image and design two-channel position feature maps for it.
Formally, we first design a two-layer residual convolutional neural network,
namely HanGlyph to generate the initial glyph representation of Chinese
characters, and subsequently adopt multiple bidirectional encoder Transformer
blocks as the superstructure to capture the context-sensitive information.
Meanwhile, we feed the glyph features extracted from each layer of the HanGlyph
module into the underlying Transformer blocks by skip-connection method to
fully exploit the glyph features of Chinese characters. As the HanGlyph module
can obtain a sufficient glyph representation of any Chinese character, the
long-standing out-of-vocabulary problem could be effectively solved. Extensive
experimental results indicate that GlyphCRM substantially outperforms the
previous BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has
strong transferability and generalization on specialized fields and
low-resource tasks. We hope this work could spark further research beyond the
realms of well-established representation of Chinese texts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Target-side Inflection in Placeholder Translation. (arXiv:2107.00334v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1">Ryokan Ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakazawa_T/0/1/0/all/0/1">Toshiaki Nakazawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1">Yoshimasa Tsuruoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00334">
                                    <div class="article-summary-box-inner">
                                        <span>Placeholder translation systems enable the users to specify how a specific
phrase is translated in the output sentence. The system is trained to output
special placeholder tokens, and the user-specified term is injected into the
output through the context-free replacement of the placeholder token. However,
this approach could result in ungrammatical sentences because it is often the
case that the specified term needs to be inflected according to the context of
the output, which is unknown before the translation. To address this problem,
we propose a novel method of placeholder translation that can inflect specified
terms according to the grammatical construction of the output sentence. We
extend the sequence-to-sequence architecture with a character-level decoder
that takes the lemma of a user-specified term and the words generated from the
word-level decoder to output the correct inflected form of the lemma. We
evaluate our approach with a Japanese-to-English translation task in the
scientific writing domain, and show that our model can incorporate specified
terms in the correct form more successfully than other comparable models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiCite: Modeling realistic citations requires moving beyond the single-sentence single-label setting. (arXiv:2107.00414v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_B/0/1/0/all/0/1">Brandon Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_B/0/1/0/all/0/1">Bailey Kuhl</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1">Sophie Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1">David Jurgens</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1">Arman Cohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00414">
                                    <div class="article-summary-box-inner">
                                        <span>Citation context analysis (CCA) is an important task in natural language
processing that studies how and why scholars discuss each others&#x27; work. Despite
being studied for decades, traditional frameworks for CCA have largely relied
on overly-simplistic assumptions of how authors cite, which ignore several
important phenomena. For instance, scholarly papers often contain rich
discussions of cited work that span multiple sentences and express multiple
intents concurrently. Yet, CCA is typically approached as a single-sentence,
single-label classification task, and thus existing datasets fail to capture
this interesting discourse. In our work, we address this research gap by
proposing a novel framework for CCA as a document-level context extraction and
labeling task. We release MultiCite, a new dataset of 12,653 citation contexts
from over 1,200 computational linguistics papers. Not only is it the largest
collection of expert-annotated citation contexts to-date, MultiCite contains
multi-sentence, multi-label citation contexts within full paper texts. Finally,
we demonstrate how our dataset, while still usable for training classic CCA
models, also supports the development of new types of models for CCA beyond
fixed-width text classification. We release our code and dataset at
https://github.com/allenai/multicite.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scientia Potentia Est -- On the Role of Knowledge in Computational Argumentation. (arXiv:2107.00281v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1">Henning Wachsmuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00281">
                                    <div class="article-summary-box-inner">
                                        <span>Despite extensive research in the past years, the computational modeling of
argumentation remains challenging. The primary reason lies in the inherent
complexity of the human processes behind, which commonly requires the
integration of extensive knowledge far beyond what is needed for many other
natural language understanding tasks. Existing work on the mining, assessment,
reasoning, and generation of arguments acknowledges this issue, calling for
more research on the integration of common sense and world knowledge into
computational models. However, a systematic effort to collect and organize the
types of knowledge needed is still missing, hindering targeted progress in the
field. In this opinionated survey paper, we address the issue by (1) proposing
a pyramid of types of knowledge required in computational argumentation, (2)
briefly discussing the state of the art on the role and integration of these
types in the field, and (3) outlining the main challenges for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Distillation for Quality Estimation. (arXiv:2107.00411v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gajbhiye_A/0/1/0/all/0/1">Amit Gajbhiye</a>, <a href="http://arxiv.org/find/cs/1/au:+Fomicheva_M/0/1/0/all/0/1">Marina Fomicheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Alva_Manchego_F/0/1/0/all/0/1">Fernando Alva-Manchego</a>, <a href="http://arxiv.org/find/cs/1/au:+Blain_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Blain</a>, <a href="http://arxiv.org/find/cs/1/au:+Obamuyide_A/0/1/0/all/0/1">Abiola Obamuyide</a>, <a href="http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1">Nikolaos Aletras</a>, <a href="http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1">Lucia Specia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00411">
                                    <div class="article-summary-box-inner">
                                        <span>Quality Estimation (QE) is the task of automatically predicting Machine
Translation quality in the absence of reference translations, making it
applicable in real-time settings, such as translating online social media
conversations. Recent success in QE stems from the use of multilingual
pre-trained representations, where very large models lead to impressive
results. However, the inference time, disk and memory requirements of such
models do not allow for wide usage in the real world. Models trained on
distilled pre-trained representations remain prohibitively large for many usage
scenarios. We instead propose to directly transfer knowledge from a strong QE
teacher model to a much smaller model with a different, shallower architecture.
We show that this approach, in combination with data augmentation, leads to
light-weight QE models that perform competitively with distilled pre-trained
representations with 8x fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Central Repository: a Cross-lingual Framework for Developing Wordnets. (arXiv:2107.00333v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guinovart_X/0/1/0/all/0/1">Xavier G&#xf3;mez Guinovart</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Dios_I/0/1/0/all/0/1">Itziar Gonzalez-Dios</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliver_A/0/1/0/all/0/1">Antoni Oliver</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1">German Rigau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00333">
                                    <div class="article-summary-box-inner">
                                        <span>Language resources are necessary for language processing,but building them is
costly, involves many researches from different areas and needs constant
updating. In this paper, we describe the crosslingual framework used for
developing the Multilingual Central Repository (MCR), a multilingual knowledge
base that includes wordnets of Basque, Catalan, English, Galician, Portuguese,
Spanish and the following ontologies: Base Concepts, Top Ontology, WordNet
Domains and Suggested Upper Merged Ontology. We present the story of MCR, its
state in 2017 and the developed tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Objective Evaluation Framework for Pathological Speech Synthesis. (arXiv:2107.00308v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halpern_B/0/1/0/all/0/1">Bence Mark Halpern</a>, <a href="http://arxiv.org/find/cs/1/au:+Fritsch_J/0/1/0/all/0/1">Julian Fritsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermann_E/0/1/0/all/0/1">Enno Hermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_R/0/1/0/all/0/1">Rob van Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharenborg_O/0/1/0/all/0/1">Odette Scharenborg</a>, <a href="http://arxiv.org/find/cs/1/au:+_Doss_M/0/1/0/all/0/1">Mathew Magimai.-Doss</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00308">
                                    <div class="article-summary-box-inner">
                                        <span>The development of pathological speech systems is currently hindered by the
lack of a standardised objective evaluation framework. In this work, (1) we
utilise existing detection and analysis techniques to propose a general
framework for the consistent evaluation of synthetic pathological speech. This
framework evaluates the voice quality and the intelligibility aspects of speech
and is shown to be complementary using our experiments. (2) Using our proposed
evaluation framework, we develop and test a dysarthric voice conversion system
(VC) using CycleGAN-VC and a PSOLA-based speech rate modification technique. We
show that the developed system is able to synthesise dysarthric speech with
different levels of speech intelligibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Capturing Event Argument Interaction via A Bi-Directional Entity-Level Recurrent Decoder. (arXiv:2107.00189v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_X/0/1/0/all/0/1">Xiangyu Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wei Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shikun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quanxiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Huixing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00189">
                                    <div class="article-summary-box-inner">
                                        <span>Capturing interactions among event arguments is an essential step towards
robust event argument extraction (EAE). However, existing efforts in this
direction suffer from two limitations: 1) The argument role type information of
contextual entities is mainly utilized as training signals, ignoring the
potential merits of directly adopting it as semantically rich input features;
2) The argument-level sequential semantics, which implies the overall
distribution pattern of argument roles over an event mention, is not well
characterized. To tackle the above two bottlenecks, we formalize EAE as a
Seq2Seq-like learning problem for the first time, where a sentence with a
specific event trigger is mapped to a sequence of event argument roles. A
neural architecture with a novel Bi-directional Entity-level Recurrent Decoder
(BERD) is proposed to generate argument roles by incorporating contextual
entities&#x27; argument role predictions, like a word-by-word text generation
process, thereby distinguishing implicit argument distribution patterns within
an event more accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-pronoun Data Augmentation for Japanese-to-English Translation. (arXiv:2107.00318v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1">Ryokan Ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakazawa_T/0/1/0/all/0/1">Toshiaki Nakazawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1">Yoshimasa Tsuruoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00318">
                                    <div class="article-summary-box-inner">
                                        <span>For Japanese-to-English translation, zero pronouns in Japanese pose a
challenge, since the model needs to infer and produce the corresponding pronoun
in the target side of the English sentence. However, although fully resolving
zero pronouns often needs discourse context, in some cases, the local context
within a sentence gives clues to the inference of the zero pronoun. In this
study, we propose a data augmentation method that provides additional training
signals for the translation model to learn correlations between local context
and zero pronouns. We show that the proposed method significantly improves the
accuracy of zero pronoun translation with machine translation experiments in
the conversational domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word-Free Spoken Language Understanding for Mandarin-Chinese. (arXiv:2107.00186v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhiyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuexin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Akshat Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00186">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken dialogue systems such as Siri and Alexa provide great convenience to
people&#x27;s everyday life. However, current spoken language understanding (SLU)
pipelines largely depend on automatic speech recognition (ASR) modules, which
require a large amount of language-specific training data. In this paper, we
propose a Transformer-based SLU system that works directly on phones. This
acoustic-based SLU system consists of only two blocks and does not require the
presence of ASR module. The first block is a universal phone recognition
system, and the second block is a Transformer-based language model for phones.
We verify the effectiveness of the system on an intent classification dataset
in Mandarin Chinese.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021. (arXiv:2107.00279v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Mengge Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuchen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1">Lirong Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00279">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes USTC-NELSLIP&#x27;s submissions to the IWSLT2021 Simultaneous
Speech Translation task. We proposed a novel simultaneous translation model,
Cross Attention Augmented Transducer (CAAT), which extends conventional RNN-T
to sequence-to-sequence tasks without monotonic constraints, e.g., simultaneous
translation. Experiments on speech-to-text (S2T) and text-to-text (T2T)
simultaneous translation tasks shows CAAT achieves better quality-latency
trade-offs compared to \textit{wait-k}, one of the previous state-of-the-art
approaches. Based on CAAT architecture and data augmentation, we build S2T and
T2T simultaneous translation systems in this evaluation campaign. Compared to
last year&#x27;s optimal systems, our S2T simultaneous translation system improves
by an average of 11.3 BLEU for all latency regimes, and our T2T simultaneous
translation system improves by an average of 4.6 BLEU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">All That&#x27;s &#x27;Human&#x27; Is Not Gold: Evaluating Human Evaluation of Generated Text. (arXiv:2107.00061v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Clark_E/0/1/0/all/0/1">Elizabeth Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+August_T/0/1/0/all/0/1">Tal August</a>, <a href="http://arxiv.org/find/cs/1/au:+Serrano_S/0/1/0/all/0/1">Sofia Serrano</a>, <a href="http://arxiv.org/find/cs/1/au:+Haduong_N/0/1/0/all/0/1">Nikita Haduong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1">Suchin Gururangan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00061">
                                    <div class="article-summary-box-inner">
                                        <span>Human evaluations are typically considered the gold standard in natural
language generation, but as models&#x27; fluency improves, how well can evaluators
detect and judge machine-generated text? We run a study assessing non-experts&#x27;
ability to distinguish between human- and machine-authored text (GPT2 and GPT3)
in three domains (stories, news articles, and recipes). We find that, without
training, evaluators distinguished between GPT3- and human-authored text at
random chance level. We explore three approaches for quickly training
evaluators to better identify GPT3-authored text (detailed instructions,
annotated examples, and paired examples) and find that while evaluators&#x27;
accuracy improved up to 55%, it did not significantly improve across the three
domains. Given the inconsistent results across text domains and the often
contradictory reasons evaluators gave for their judgments, we examine the role
untrained human evaluations play in NLG evaluation and provide recommendations
to NLG researchers for improving human evaluations of text generated from
state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Abstractive Question Summarization with Question-aware Semantic Rewards. (arXiv:2107.00176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_S/0/1/0/all/0/1">Shweta Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1">Deepak Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Abacha_A/0/1/0/all/0/1">Asma Ben Abacha</a>, <a href="http://arxiv.org/find/cs/1/au:+Demner_Fushman_D/0/1/0/all/0/1">Dina Demner-Fushman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00176">
                                    <div class="article-summary-box-inner">
                                        <span>The growth of online consumer health questions has led to the necessity for
reliable and accurate question answering systems. A recent study showed that
manual summarization of consumer health questions brings significant
improvement in retrieving relevant answers. However, the automatic
summarization of long questions is a challenging task due to the lack of
training data and the complexity of the related subtasks, such as the question
focus and type recognition. In this paper, we introduce a reinforcement
learning-based framework for abstractive question summarization. We propose two
novel rewards obtained from the downstream tasks of (i) question-type
identification and (ii) question-focus recognition to regularize the question
generation model. These rewards ensure the generation of semantically valid
questions and encourage the inclusion of key medical entities/foci in the
question summary. We evaluated our proposed method on two benchmark datasets
and achieved higher performance over state-of-the-art models. The manual
evaluation of the summaries reveals that the generated questions are more
diverse and have fewer factual inconsistencies than the baseline summaries</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressing Location on Text for Probabilistic Geocoding. (arXiv:2107.00080v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radford_B/0/1/0/all/0/1">Benjamin J. Radford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00080">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are an important source of detailed information about social and
political events. Automated systems parse large volumes of text data to infer
or extract structured information that describes actors, actions, dates, times,
and locations. One of these sub-tasks is geocoding: predicting the geographic
coordinates associated with events or locations described by a given text. We
present an end-to-end probabilistic model for geocoding text data.
Additionally, we collect a novel data set for evaluating the performance of
geocoding systems. We compare the model-based solution, called ELECTRo-map, to
the current state-of-the-art open source system for geocoding texts for event
data. Finally, we discuss the benefits of end-to-end model-based geocoding,
including principled uncertainty estimation and the ability of these models to
leverage contextual information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to communicate about shared procedural abstractions. (arXiv:2107.00077v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McCarthy_W/0/1/0/all/0/1">William P. McCarthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawkins_R/0/1/0/all/0/1">Robert D. Hawkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Holdaway_C/0/1/0/all/0/1">Cameron Holdaway</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Judith E. Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00077">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world tasks require agents to coordinate their behavior to achieve
shared goals. Successful collaboration requires not only adopting the same
communicative conventions, but also grounding these conventions in the same
task-appropriate conceptual abstractions. We investigate how humans use natural
language to collaboratively solve physical assembly problems more effectively
over time. Human participants were paired up in an online environment to
reconstruct scenes containing two block towers. One participant could see the
target towers, and sent assembly instructions for the other participant to
reconstruct. Participants provided increasingly concise instructions across
repeated attempts on each pair of towers, using higher-level referring
expressions that captured each scene&#x27;s hierarchical structure. To explain these
findings, we extend recent probabilistic models of ad-hoc convention formation
with an explicit perceptual learning mechanism. These results shed light on the
inductive biases that enable intelligent agents to coordinate upon shared
procedural abstractions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zipf&#x27;s laws of meaning in Catalan. (arXiv:2107.00042v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Catala_N/0/1/0/all/0/1">Neus Catal&#xe0;</a>, <a href="http://arxiv.org/find/cs/1/au:+Baixeries_J/0/1/0/all/0/1">Jaume Baixeries</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_Cancho_R/0/1/0/all/0/1">Ramon Ferrer-Cancho</a>, <a href="http://arxiv.org/find/cs/1/au:+Padro_L/0/1/0/all/0/1">Llu&#xed;s Padr&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Fernandez_A/0/1/0/all/0/1">Antoni Hern&#xe1;ndez-Fern&#xe1;ndez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00042">
                                    <div class="article-summary-box-inner">
                                        <span>In his pioneering research, G. K. Zipf formulated a couple of statistical
laws on the relationship between the frequency of a word with its number of
meanings: the law of meaning distribution, relating the frequency of a word and
its frequency rank, and the meaning-frequency law, relating the frequency of a
word with its number of meanings. Although these laws were formulated more than
half a century ago, they have been only investigated in a few languages. Here
we present the first study of these laws in Catalan.

We verify these laws in Catalan via the relationship among their exponents
and that of the rank-frequency law. We present a new protocol for the analysis
of these Zipfian laws that can be extended to other languages. We report the
first evidence of two marked regimes for these laws in written language and
speech, paralleling the two regimes in Zipf&#x27;s rank-frequency law in large
multi-author corpora discovered in early 2000s. Finally, the implications of
these two regimes will be discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Reversible Embedding Mapping using Bi-Directional Manifold Alignment. (arXiv:2107.00124v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_A/0/1/0/all/0/1">Ashwinkumar Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1">Francis Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1">Tim Oates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00124">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a Bi-Directional Manifold Alignment (BDMA) that learns a
non-linear mapping between two manifolds by explicitly training it to be
bijective. We demonstrate BDMA by training a model for a pair of languages
rather than individual, directed source and target combinations, reducing the
number of models by 50%. We show that models trained with BDMA in the &quot;forward&quot;
(source to target) direction can successfully map words in the &quot;reverse&quot;
(target to source) direction, yielding equivalent (or better) performance to
standard unidirectional translation models where the source and target language
is flipped. We also show how BDMA reduces the overall size of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Open-ended Question Generation with A New Question Type Ontology. (arXiv:2107.00152v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shuyang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00152">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the less-explored task of generating open-ended questions that
are typically answered by multiple sentences. We first define a new question
type ontology which differentiates the nuanced nature of questions better than
widely used question words. A new dataset with 4,959 questions is labeled based
on the new ontology. We then propose a novel question type-aware question
generation framework, augmented by a semantic graph representation, to jointly
predict question focuses and produce the question. Based on this framework, we
further use both exemplars and automatically generated templates to improve
controllability and diversity. Experiments on two newly collected large-scale
datasets show that our model improves question quality over competitive
comparisons based on automatic metrics. Human judges also rate our model
outputs highly in answerability, coverage of scope, and overall quality.
Finally, our model variants with templates can produce questions with enhanced
controllability and diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elbert: Fast Albert with Confidence-Window Based Early Exit. (arXiv:2107.00175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1">Keli Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Siyuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00175">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great success in Natural Language Processing (NLP) area, large
pre-trained language models like BERT are not well-suited for
resource-constrained or real-time applications owing to the large number of
parameters and slow inference speed. Recently, compressing and accelerating
BERT have become important topics. By incorporating a parameter-sharing
strategy, ALBERT greatly reduces the number of parameters while achieving
competitive performance. Nevertheless, ALBERT still suffers from a long
inference time. In this work, we propose the ELBERT, which significantly
improves the average inference speed compared to ALBERT due to the proposed
confidence-window based early exit mechanism, without introducing additional
parameters or extra training overhead. Experimental results show that ELBERT
achieves an adaptive inference speedup varying from 2$\times$ to 10$\times$
with negligible accuracy degradation compared to ALBERT on various datasets.
Besides, ELBERT achieves higher accuracy than existing early exit methods used
for accelerating BERT under the same computation cost. Furthermore, to
understand the principle of the early exit mechanism, we also visualize the
decision-making process of it in ELBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Space: A Geometrical Perspective. (arXiv:2007.00062v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kansizoglou_I/0/1/0/all/0/1">Ioannis Kansizoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bampis_L/0/1/0/all/0/1">Loukas Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasteratos_A/0/1/0/all/0/1">Antonios Gasteratos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00062">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most prominent attributes of Neural Networks (NNs) constitutes
their capability of learning to extract robust and descriptive features from
high dimensional data, like images. Hence, such an ability renders their
exploitation as feature extractors particularly frequent in an abundant of
modern reasoning systems. Their application scope mainly includes complex
cascade tasks, like multi-modal recognition and deep Reinforcement Learning
(RL). However, NNs induce implicit biases that are difficult to avoid or to
deal with and are not met in traditional image descriptors. Moreover, the lack
of knowledge for describing the intra-layer properties -- and thus their
general behavior -- restricts the further applicability of the extracted
features. With the paper at hand, a novel way of visualizing and understanding
the vector space before the NNs&#x27; output layer is presented, aiming to enlighten
the deep feature vectors&#x27; properties under classification tasks. Main attention
is paid to the nature of overfitting in the feature space and its adverse
effect on further exploitation. We present the findings that can be derived
from our model&#x27;s formulation, and we evaluate them on realistic recognition
scenarios, proving its prominence by improving the obtained results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks. (arXiv:2106.12900v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xuelong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12900">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning model can quickly adapt to new tasks using few-shot labeled
data. However, despite achieving good generalization on few-shot classification
tasks, it is still challenging to improve the adversarial robustness of the
meta-learning model in few-shot learning. Although adversarial training (AT)
methods such as Adversarial Query (AQ) can improve the adversarially robust
performance of meta-learning models, AT is still computationally expensive
training. On the other hand, meta-learning models trained with AT will drop
significant accuracy on the original clean images. This paper proposed a
meta-learning method on the adversarially robust neural network called
Long-term Cross Adversarial Training (LCAT). LCAT will update meta-learning
model parameters cross along the natural and adversarial sample distribution
direction with long-term to improve both adversarial and clean few-shot
classification accuracy. Due to cross-adversarial training, LCAT only needs
half of the adversarial training epoch than AQ, resulting in a low adversarial
training computation. Experiment results show that LCAT achieves superior
performance both on the clean and adversarial few-shot classification accuracy
than SOTA adversarial training methods for meta-learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmenting two-dimensional structures with strided tensor networks. (arXiv:2102.06900v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Selvan_R/0/1/0/all/0/1">Raghavendra Selvan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dam_E/0/1/0/all/0/1">Erik B Dam</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_J/0/1/0/all/0/1">Jens Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06900">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor networks provide an efficient approximation of operations involving
high dimensional tensors and have been extensively used in modelling quantum
many-body systems. More recently, supervised learning has been attempted with
tensor networks, primarily focused on tasks such as image classification. In
this work, we propose a novel formulation of tensor networks for supervised
image segmentation which allows them to operate on high resolution medical
images. We use the matrix product state (MPS) tensor network on non-overlapping
patches of a given input image to predict the segmentation mask by learning a
pixel-wise linear classification rule in a high dimensional space. The proposed
model is end-to-end trainable using backpropagation. It is implemented as a
Strided Tensor Network to reduce the parameter complexity. The performance of
the proposed method is evaluated on two public medical imaging datasets and
compared to relevant baselines. The evaluation shows that the strided tensor
network yields competitive performance compared to CNN-based models while using
fewer resources. Additionally, based on the experiments we discuss the
feasibility of using fully linear models for segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Fusion Networks for Image Denoising. (arXiv:2011.14196v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hosseini_S/0/1/0/all/0/1">Seyed Mohsen Hosseini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14196">
                                    <div class="article-summary-box-inner">
                                        <span>A novel method for feature fusion in convolutional neural networks is
proposed in this paper. Different feature fusion techniques are suggested to
facilitate the flow of information and improve the training of deep neural
networks. Some of these techniques as well as the proposed network can be
considered a type of Directed Acyclic Graph (DAG) Network, where a layer can
receive inputs from other layers and have outputs to other layers. In the
proposed general framework of Lattice Fusion Network (LFNet), feature maps of
each convolutional layer are passed to other layers based on a lattice graph
structure, where nodes are convolutional layers. To evaluate the performance of
the proposed architecture, different designs based on the general framework of
LFNet are implemented for the task of image denoising. This task is used as an
example where training deep convolutional networks is needed. Results are
compared with state of the art methods. The proposed network is able to achieve
better results with far fewer learnable parameters, which shows the
effectiveness of LFNets for training of deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interval-valued aggregation functions based on moderate deviations applied to Motor-Imagery-Based Brain Computer Interface. (arXiv:2011.09831v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fumanal_Idocin_J/0/1/0/all/0/1">Javier Fumanal-Idocin</a>, <a href="http://arxiv.org/find/cs/1/au:+Takac_Z/0/1/0/all/0/1">Zdenko Tak&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanz_J/0/1/0/all/0/1">Javier Fern&#xe1;ndez Jose Antonio Sanz</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyena_H/0/1/0/all/0/1">Harkaitz Goyena</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Ching-Teng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1">Humberto Bustince</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09831">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we study the use of moderate deviation functions to measure
similarity and dissimilarity among a set of given interval-valued data. To do
so, we introduce the notion of interval-valued moderate deviation function and
we study in particular those interval-valued moderate deviation functions which
preserve the width of the input intervals. Then, we study how to apply these
functions to construct interval-valued aggregation functions. We have applied
them in the decision making phase of two Motor-Imagery Brain Computer Interface
frameworks, obtaining better results than those obtained using other numerical
and intervalar aggregations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition. (arXiv:2107.00606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1">Simone Angarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelini_F/0/1/0/all/0/1">Federico Angelini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent, and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time
short-time human action recognition. Extensive experimentation on MPOSE2021
with our proposed methodology and several previous architectural solutions
proves the effectiveness of the AcT model and poses the base for future work on
HAR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Color Variants Identification in Fashion e-commerce via Contrastive Self-Supervised Representation Learning. (arXiv:2104.08581v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_U/0/1/0/all/0/1">Ujjal Kr Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Repakula_S/0/1/0/all/0/1">Sandeep Repakula</a>, <a href="http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1">Maulik Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_A/0/1/0/all/0/1">Abhinav Ravi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08581">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we utilize deep visual Representation Learning to address an
important problem in fashion e-commerce: color variants identification, i.e.,
identifying fashion products that match exactly in their design (or style), but
only to differ in their color. At first we attempt to tackle the problem by
obtaining manual annotations (depicting whether two products are color
variants), and train a supervised triplet loss based neural network model to
learn representations of fashion products. However, for large scale real-world
industrial datasets such as addressed in our paper, it is infeasible to obtain
annotations for the entire dataset, while capturing all the difficult corner
cases. Interestingly, we observed that color variants are essentially
manifestations of color jitter based augmentations. Thus, we instead explore
Self-Supervised Learning (SSL) to solve this problem. We observed that existing
state-of-the-art SSL methods perform poor, for our problem. To address this, we
propose a novel SSL based color variants model that simultaneously focuses on
different parts of an apparel. Quantitative and qualitative evaluation shows
that our method outperforms existing SSL methods, and at times, the supervised
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Resolution Face Editing with Masked GAN Latent Code Optimization. (arXiv:2103.11135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pernus_M/0/1/0/all/0/1">Martin Pernu&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Struc_V/0/1/0/all/0/1">Vitomir &#x160;truc</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobrisek_S/0/1/0/all/0/1">Simon Dobri&#x161;ek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11135">
                                    <div class="article-summary-box-inner">
                                        <span>Face editing represents a popular research topic within the computer vision
and image processing communities. While significant progress has been made
recently in this area, existing solutions: (i) are still largely focused on
low-resolution images, (ii) often generate editing results with visual
artefacts, or (iii) lack fine-grained control and alter multiple (entangled)
attributes at once, when trying to generate the desired facial semantics. In
this paper, we aim to address these issues though a novel attribute editing
approach called MaskFaceGAN. The proposed approach is based on an optimization
procedure that directly optimizes the latent code of a pre-trained
(state-of-the-art) Generative Adversarial Network (i.e., StyleGAN2) with
respect to several constraints that ensure: (i) preservation of relevant image
content, (ii) generation of the targeted facial attributes, and (iii)
spatially--selective treatment of local image areas. The constraints are
enforced with the help of an (differentiable) attribute classifier and face
parser that provide the necessary reference information for the optimization
procedure. MaskFaceGAN is evaluated in extensive experiments on the CelebA-HQ,
Helen and SiblingsDB-HQf datasets and in comparison with several
state-of-the-art techniques from the literature, i.e., StarGAN, AttGAN, STGAN,
and two versions of InterFaceGAN. Our experimental results show that the
proposed approach is able to edit face images with respect to several facial
attributes with unprecedented image quality and at high-resolutions
(1024x1024), while exhibiting considerably less problems with attribute
entanglement than competing solutions. The source code is made freely available
from: https://github.com/MartinPernus/MaskFaceGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D Salient Object Detection. (arXiv:2106.09517v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1">Guangyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1">Tania Stathaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09517">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-D salient object detection(SOD) demonstrates its superiority on detecting
in complex environments due to the additional depth information introduced in
the data. Inevitably, an independent stream is introduced to extract features
from depth images, leading to extra computation and parameters. This
methodology which sacrifices the model size to improve the detection accuracy
may impede the practical application of SOD problems. To tackle this dilemma,
we propose a dynamic distillation method along with a lightweight framework,
which significantly reduces the parameters. This method considers the factors
of both teacher and student performance within the training stage and
dynamically assigns the distillation weight instead of applying a fixed weight
on the student model. Extensive experiments are conducted on five public
datasets to demonstrate that our method can achieve competitive performance
compared to 10 prior methods through a 78.2MB lightweight structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video. (arXiv:2011.10670v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Junwei Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10670">
                                    <div class="article-summary-box-inner">
                                        <span>With the advancement in computer vision deep learning, systems now are able
to analyze an unprecedented amount of rich visual information from videos to
enable applications such as autonomous driving, socially-aware robot assistant
and public safety monitoring. Deciphering human behaviors to predict their
future paths/trajectories and what they would do from videos is important in
these applications. However, human trajectory prediction still remains a
challenging task, as scene semantics and human intent are difficult to model.
Many systems do not provide high-level semantic attributes to reason about
pedestrian future. This design hinders prediction performance in video data
from diverse domains and unseen scenarios. To enable optimal future human
behavioral forecasting, it is crucial for the system to be able to detect and
analyze human activities as well as scene semantics, passing informative
features to the subsequent prediction module for context understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction. (arXiv:2101.03244v10 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saha_A/0/1/0/all/0/1">Anindo Saha</a>, <a href="http://arxiv.org/find/eess/1/au:+Hosseinzadeh_M/0/1/0/all/0/1">Matin Hosseinzadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03244">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multi-stage 3D computer-aided detection and diagnosis (CAD)
model for automated localization of clinically significant prostate cancer
(csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive
its detection network, targeting salient structures and highly discriminative
feature dimensions across multiple resolutions. Its goal is to accurately
identify csPCa lesions from indolent cancer and the wide range of benign
pathology that can afflict the prostate gland. Simultaneously, a decoupled
residual classifier is used to achieve consistent false positive reduction,
without sacrificing high sensitivity or computational efficiency. In order to
guide model generalization with domain-specific clinical knowledge, a
probabilistic anatomical prior is used to encode the spatial prevalence and
zonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired
with radiologically-estimated annotations, we hypothesize that such CNN-based
models can be trained to detect biopsy-confirmed malignancies in an independent
cohort.

For 486 institutional testing scans, the 3D CAD system achieves
83.69$\pm$5.22% and 93.19$\pm$2.96% detection sensitivity at 0.50 and 1.46
false positive(s) per patient, respectively, with 0.882$\pm$0.030 AUROC in
patient-based diagnosis $-$significantly outperforming four state-of-the-art
baseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from
recent literature. For 296 external biopsy-confirmed testing scans, the
ensembled CAD system shares moderate agreement with a consensus of expert
radiologists (76.69%; $kappa$ $&#x3D;$ 0.51$\pm$0.04) and independent pathologists
(81.08%; $kappa$ $&#x3D;$ 0.56$\pm$0.06); demonstrating strong generalization to
histologically-confirmed csPCa diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Self Supervised Learning: the BT, the HSIC, and the VICReg. (arXiv:2105.12247v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sayan Nag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12247">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning and pre-training strategies have developed over the
last few years especially for Convolutional Neural Networks (CNNs). Recently
application of such methods can also be noticed for Graph Neural Networks
(GNNs) . In this paper, we have used a graph based self-supervised learning
strategy with different loss functions (Barlow Twins[Zbontar et al., 2021],
HSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown
promising results when applied with CNNs previously. We have also proposed a
hybrid loss function combining the advantages of VICReg and HSIC and called it
as VICRegHSIC. The performance of these aforementioned methods have been
compared when applied to different datasets such as MUTAG, PROTEINS and
IMDB-Binary. Moreover, the impact of different batch sizes, projector
dimensions and data augmentation strategies have also been explored</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1">Ivan Evtimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1">Ian Covert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1">Tadayoshi Kohno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06654">
                                    <div class="article-summary-box-inner">
                                        <span>When data is publicly released for human consumption, it is unclear how to
prevent its unauthorized usage for machine learning purposes. Successful model
training may be preventable with carefully designed dataset modifications, and
we present a proof-of-concept approach for the image classification setting. We
propose methods based on the notion of adversarial shortcuts, which encourage
models to rely on non-robust signals rather than semantic features, and our
experiments demonstrate that these measures successfully prevent deep learning
models from achieving high accuracy on real, unmodified data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to See before Learning to Act: Visual Pre-training for Manipulation. (arXiv:2107.00646v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yen_Chen_L/0/1/0/all/0/1">Lin Yen-Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Andy Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuran Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00646">
                                    <div class="article-summary-box-inner">
                                        <span>Does having visual priors (e.g. the ability to detect objects) facilitate
learning to perform vision-based manipulation (e.g. picking up objects)? We
study this problem under the framework of transfer learning, where the model is
first trained on a passive vision task, and adapted to perform an active
manipulation task. We find that pre-training on vision tasks significantly
improves generalization and sample efficiency for learning to manipulate
objects. However, realizing these gains requires careful selection of which
parts of the model to transfer. Our key insight is that outputs of standard
vision models highly correlate with affordance maps commonly used in
manipulation. Therefore, we explore directly transferring model parameters from
vision networks to affordance prediction networks, and show that this can
result in successful zero-shot adaptation, where a robot can pick up certain
objects with zero robotic experience. With just a small amount of robotic
experience, we can further fine-tune the affordance model to achieve better
results. With just 10 minutes of suction experience or 1 hour of grasping
experience, our method achieves ~80% success rate at picking up novel objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows. (arXiv:2107.00652v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00652">
                                    <div class="article-summary-box-inner">
                                        <span>We present CSWin Transformer, an efficient and effective Transformer-based
backbone for general-purpose vision tasks. A challenging issue in Transformer
design is that global self-attention is very expensive to compute whereas local
self-attention often limits the field of interactions of each token. To address
this issue, we develop the Cross-Shaped Window self-attention mechanism for
computing self-attention in the horizontal and vertical stripes in parallel
that form a cross-shaped window, with each stripe obtained by splitting the
input feature into stripes of equal width. We provide a detailed mathematical
analysis of the effect of the stripe width and vary the stripe width for
different layers of the Transformer network which achieves strong modeling
capability while limiting the computation cost. We also introduce
Locally-enhanced Positional Encoding (LePE), which handles the local positional
information better than existing encoding schemes. LePE naturally supports
arbitrary input resolutions, and is thus especially effective and friendly for
downstream tasks. Incorporated with these designs and a hierarchical structure,
CSWin Transformer demonstrates competitive performance on common vision tasks.
Specifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra
training data or label, 53.9 box AP and 46.4 mask AP on the COCO detection
task, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing
previous state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and
+2.0 respectively under the similar FLOPs setting. By further pretraining on
the larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K
and state-of-the-art segmentation performance on ADE20K with 55.2 mIoU. The
code and models will be available at
https://github.com/microsoft/CSWin-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds. (arXiv:2010.00824v4 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lirui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yu Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00824">
                                    <div class="article-summary-box-inner">
                                        <span>6D robotic grasping beyond top-down bin-picking scenarios is a challenging
task. Previous solutions based on 6D grasp synthesis with robot motion planning
usually operate in an open-loop setting, which are sensitive to grasp synthesis
errors. In this work, we propose a new method for learning closed-loop control
policies for 6D grasping. Our policy takes a segmented point cloud of an object
from an egocentric camera as input, and outputs continuous 6D control actions
of the robot gripper for grasping the object. We combine imitation learning and
reinforcement learning and introduce a goal-auxiliary actor-critic algorithm
for policy learning. We demonstrate that our learned policy can be integrated
into a tabletop 6D grasping system and a human-robot handover system to improve
the grasping performance of unseen objects. Our videos and code can be found at
https://sites.google.com/view/gaddpg .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Individual Tree Detection and Crown Delineation with 3D Information from Multi-view Satellite Images. (arXiv:2107.00592v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Changlin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00592">
                                    <div class="article-summary-box-inner">
                                        <span>Individual tree detection and crown delineation (ITDD) are critical in forest
inventory management and remote sensing based forest surveys are largely
carried out through satellite images. However, most of these surveys only use
2D spectral information which normally has not enough clues for ITDD. To fully
explore the satellite images, we propose a ITDD method using the orthophoto and
digital surface model (DSM) derived from the multi-view satellite data. Our
algorithm utilizes the top-hat morphological operation to efficiently extract
the local maxima from DSM as treetops, and then feed them to a modi-fied
superpixel segmentation that combines both 2D and 3D information for tree crown
delineation. In subsequent steps, our method incorporates the biological
characteristics of the crowns through plant allometric equation to falsify
potential outliers. Experiments against manually marked tree plots on three
representative regions have demonstrated promising results - the best overall
detection accuracy can be 89%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointINS: Point-based Instance Segmentation. (arXiv:2003.06148v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yukang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingcong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06148">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the mask representation in instance segmentation
with Point-of-Interest (PoI) features. Differentiating multiple potential
instances within a single PoI feature is challenging because learning a
high-dimensional mask feature for each instance using vanilla convolution
demands a heavy computing burden. To address this challenge, we propose an
instance-aware convolution. It decomposes this mask representation learning
task into two tractable modules as instance-aware weights and instance-agnostic
features. The former is to parametrize convolution for producing mask features
corresponding to different instances, improving mask learning efficiency by
avoiding employing several independent convolutions. Meanwhile, the latter
serves as mask templates in a single point. Together, instance-aware mask
features are computed by convolving the template with dynamic weights, used for
the mask prediction. Along with instance-aware convolution, we propose
PointINS, a simple and practical instance segmentation approach, building upon
dense one-stage detectors. Through extensive experiments, we evaluated the
effectiveness of our framework built upon RetinaNet and FCOS. PointINS in
ResNet101 backbone achieves a 38.3 mask mean average precision (mAP) on COCO
dataset, outperforming existing point-based methods by a large margin. It gives
a comparable performance to the region-based Mask R-CNN with faster inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1">Andrea Dittadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papa_S/0/1/0/all/0/1">Samuele Papa</a>, <a href="http://arxiv.org/find/cs/1/au:+Vita_M/0/1/0/all/0/1">Michele De Vita</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00637">
                                    <div class="article-summary-box-inner">
                                        <span>The idea behind object-centric representation learning is that natural scenes
can better be modeled as compositions of objects and their relations as opposed
to distributed representations. This inductive bias can be injected into neural
networks to potentially improve systematic generalization and learning
efficiency of downstream tasks in scenes with multiple objects. In this paper,
we train state-of-the-art unsupervised models on five common multi-object
datasets and evaluate segmentation accuracy and downstream object property
prediction. In addition, we study systematic generalization and robustness by
investigating the settings where either single objects are out-of-distribution
-- e.g., having unseen colors, textures, and shapes -- or global properties of
the scene are altered -- e.g., by occlusions, cropping, or increasing the
number of objects. From our experimental study, we find object-centric
representations to be generally useful for downstream tasks and robust to
shifts in the data distribution, especially if shifts affect single objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters. (arXiv:2007.08194v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haoyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_Z/0/1/0/all/0/1">Zhihao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yuyuan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08194">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been successfully used in a range
of tasks. However, CNNs are often viewed as &quot;black-box&quot; and lack of
interpretability. One main reason is due to the filter-class entanglement -- an
intricate many-to-many correspondence between filters and classes. Most
existing works attempt post-hoc interpretation on a pre-trained model, while
neglecting to reduce the entanglement underlying the model. In contrast, we
focus on alleviating filter-class entanglement during training. Inspired by
cellular differentiation, we propose a novel strategy to train interpretable
CNNs by encouraging class-specific filters, among which each filter responds to
only one (or few) class. Concretely, we design a learnable sparse
Class-Specific Gate (CSG) structure to assign each filter with one (or few)
class in a flexible way. The gate allows a filter&#x27;s activation to pass only
when the input samples come from the specific class. Extensive experiments
demonstrate the fabulous performance of our method in generating a sparse and
highly class-related representation of the input, which leads to stronger
interpretability. Moreover, comparing with the standard training strategy, our
model displays benefits in applications like object localization and
adversarial sample detection. Code link: https://github.com/hyliang96/CSGCNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Gravitational Approach for Rigid Point Set Registration with Ordinary Differential Equations. (arXiv:2009.14005v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sk Aziz Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahraman_K/0/1/0/all/0/1">Kerem Kahraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14005">
                                    <div class="article-summary-box-inner">
                                        <span>This article introduces a new physics-based method for rigid point set
alignment called Fast Gravitational Approach (FGA). In FGA, the source and
target point sets are interpreted as rigid particle swarms with masses
interacting in a globally multiply-linked manner while moving in a simulated
gravitational force field. The optimal alignment is obtained by explicit
modeling of forces acting on the particles as well as their velocities and
displacements with second-order ordinary differential equations of motion.
Additional alignment cues (point-based or geometric features, and other
boundary conditions) can be integrated into FGA through particle masses. We
propose a smooth-particle mass function for point mass initialization, which
improves robustness to noise and structural discontinuities. To avoid
prohibitive quadratic complexity of all-to-all point interactions, we adapt a
Barnes-Hut tree for accelerated force computation and achieve quasilinear
computational complexity. We show that the new method class has characteristics
not found in previous alignment methods such as efficient handling of partial
overlaps, inhomogeneous point sampling densities, and coping with large point
clouds with reduced runtime compared to the state of the art. Experiments show
that our method performs on par with or outperforms all compared competing
non-deep-learning-based and general-purpose techniques (which do not assume the
availability of training data and a scene prior) in resolving transformations
for LiDAR data and gains state-of-the-art accuracy and speed when coping with
different types of data disturbances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task Two-stream Spatiotemporal Convolutional Neural Network for Convective Storm Nowcasting. (arXiv:2010.14100v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">W. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">H. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">P. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">L. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14100">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of convective storm nowcasting is local prediction of severe and
imminent convective storms. Here, we consider the convective storm nowcasting
problem from the perspective of machine learning. First, we use a pixel-wise
sampling method to construct spatiotemporal features for nowcasting, and
flexibly adjust the proportions of positive and negative samples in the
training set to mitigate class-imbalance issues. Second, we employ a concise
two-stream convolutional neural network to extract spatial and temporal cues
for nowcasting. This simplifies the network structure, reduces the training
time requirement, and improves classification accuracy. The two-stream network
used both radar and satellite data. In the resulting two-stream, fused
convolutional neural network, some of the parameters are entered into a
single-stream convolutional neural network, but it can learn the features of
many data. Further, considering the relevance of classification and regression
tasks, we develop a multi-task learning strategy that predicts the labels used
in such tasks. We integrate two-stream multi-task learning into a single
convolutional neural network. Given the compact architecture, this network is
more efficient and easier to optimize than existing recurrent neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to Data Imbalance in Deep Learning Based Segmentation. (arXiv:2106.12387v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puyol_Anton_E/0/1/0/all/0/1">Esther Puyol-Anton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruijsink_B/0/1/0/all/0/1">Bram Ruijsink</a>, <a href="http://arxiv.org/find/cs/1/au:+Piechnik_S/0/1/0/all/0/1">Stefan K. Piechnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubauer_S/0/1/0/all/0/1">Stefan Neubauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_S/0/1/0/all/0/1">Steffen E. Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/cs/1/au:+King_A/0/1/0/all/0/1">Andrew P. King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12387">
                                    <div class="article-summary-box-inner">
                                        <span>The subject of &quot;fairness&quot; in artificial intelligence (AI) refers to assessing
AI algorithms for potential bias based on demographic characteristics such as
race and gender, and the development of algorithms to address this bias. Most
applications to date have been in computer vision, although some work in
healthcare has started to emerge. The use of deep learning (DL) in cardiac MR
segmentation has led to impressive results in recent years, and such techniques
are starting to be translated into clinical practice. However, no work has yet
investigated the fairness of such models. In this work, we perform such an
analysis for racial/gender groups, focusing on the problem of training data
imbalance, using a nnU-Net model trained and evaluated on cine short axis
cardiac MR data from the UK Biobank dataset, consisting of 5,903 subjects from
6 different racial groups. We find statistically significant differences in
Dice performance between different racial groups. To reduce the racial bias, we
investigated three strategies: (1) stratified batch sampling, in which batch
sampling is stratified to ensure balance between racial groups; (2) fair
meta-learning for segmentation, in which a DL classifier is trained to classify
race and jointly optimized with the segmentation model; and (3) protected group
models, in which a different segmentation model is trained for each racial
group. We also compared the results to the scenario where we have a perfectly
balanced database. To assess fairness we used the standard deviation (SD) and
skewed error ratio (SER) of the average Dice values. Our results demonstrate
that the racial bias results from the use of imbalanced training data, and that
all proposed bias mitigation strategies improved fairness, with the best SD and
SER resulting from the use of protected group models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure. (arXiv:2106.11516v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangrui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wanlong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_F/0/1/0/all/0/1">Feng Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11516">
                                    <div class="article-summary-box-inner">
                                        <span>LiDAR-based SLAM system is admittedly more accurate and stable than others,
while its loop closure detection is still an open issue. With the development
of 3D semantic segmentation for point cloud, semantic information can be
obtained conveniently and steadily, essential for high-level intelligence and
conductive to SLAM. In this paper, we present a novel semantic-aided LiDAR SLAM
with loop closure based on LOAM, named SA-LOAM, which leverages semantics in
odometry as well as loop closure detection. Specifically, we propose a
semantic-assisted ICP, including semantically matching, downsampling and plane
constraint, and integrates a semantic graph-based place recognition method in
our loop closure detection module. Benefitting from semantics, we can improve
the localization accuracy, detect loop closures effectively, and construct a
global consistent semantic map even in large-scale scenes. Extensive
experiments on KITTI and Ford Campus dataset show that our system significantly
improves baseline performance, has generalization ability to unseen data and
achieves competitive results compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks. (arXiv:2104.07085v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hongyi Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabawi_D/0/1/0/all/0/1">Diaa Dabawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cetin_A/0/1/0/all/0/1">Ahmet Enis Cetin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07085">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel layer based on fast Walsh-Hadamard
transform (WHT) and smooth-thresholding to replace $1\times 1$ convolution
layers in deep neural networks. In the WHT domain, we denoise the transform
domain coefficients using the new smooth-thresholding non-linearity, a smoothed
version of the well-known soft-thresholding operator. We also introduce a
family of multiplication-free operators from the basic 2$\times$2 Hadamard
transform to implement $3\times 3$ depthwise separable convolution layers.
Using these two types of layers, we replace the bottleneck layers in
MobileNet-V2 to reduce the network&#x27;s number of parameters with a slight loss in
accuracy. For example, by replacing the final third bottleneck layers, we
reduce the number of parameters from 2.270M to 540K. This reduces the accuracy
from 95.21\% to 92.98\% on the CIFAR-10 dataset. Our approach significantly
improves the speed of data processing. The fast Walsh-Hadamard transform has a
computational complexity of $O(m\log_2 m)$. As a result, it is computationally
more efficient than the $1\times1$ convolution layer. The fast Walsh-Hadamard
layer processes a tensor in $\mathbb{R}^{10\times32\times32\times1024}$ about 2
times faster than $1\times1$ convolution layer on NVIDIA Jetson Nano computer
board.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based Action Recognition. (arXiv:2105.01563v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_P/0/1/0/all/0/1">Pan Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+McKay_B/0/1/0/all/0/1">Bob McKay</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1">Saeed Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01563">
                                    <div class="article-summary-box-inner">
                                        <span>Skeleton sequences are lightweight and compact, thus are ideal candidates for
action recognition on edge devices. Recent skeleton-based action recognition
methods extract features from 3D joint coordinates as spatial-temporal cues,
using these representations in a graph neural network for feature fusion to
boost recognition performance. The use of first- and second-order features,
\ie{} joint and bone representations, has led to high accuracy. Nonetheless,
many models are still confused by actions that have similar motion
trajectories. To address these issues, we propose fusing third-order features
in the form of angular encoding into modern architectures to robustly capture
the relationships between joints and body parts. This simple fusion with
popular spatial-temporal graph neural networks achieves new state-of-the-art
accuracy in two large benchmarks, including NTU60 and NTU120, while employing
fewer parameters and reduced run time. Our source code is publicly available
at: https://github.com/ZhenyueQin/Angular-Skeleton-Encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multimodal VAEs through Mutual Supervision. (arXiv:2106.12570v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joy_T/0/1/0/all/0/1">Tom Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuge Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmon_S/0/1/0/all/0/1">Sebastian M. Schmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1">N. Siddharth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12570">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal VAEs seek to model the joint distribution over heterogeneous data
(e.g.\ vision, language), whilst also capturing a shared representation across
such modalities. Prior work has typically combined information from the
modalities by reconciling idiosyncratic representations directly in the
recognition model through explicit products, mixtures, or other such
factorisations. Here we introduce a novel alternative, the MEME, that avoids
such explicit combinations by repurposing semi-supervised VAEs to combine
information between modalities implicitly through mutual supervision. This
formulation naturally allows learning from partially-observed data where some
modalities can be entirely missing -- something that most existing approaches
either cannot handle, or do so to a limited extent. We demonstrate that MEME
outperforms baselines on standard metrics across both partial and complete
observation schemes on the MNIST-SVHN (image-image) and CUB (image-text)
datasets. We also contrast the quality of the representations learnt by mutual
supervision against standard approaches and observe interesting trends in its
ability to capture relatedness between data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning. (arXiv:2106.11562v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Beomyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">Youngjoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11562">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a class-incremental semantic segmentation (CISS) problem. While
some recently proposed algorithms utilized variants of knowledge distillation
(KD) technique to tackle the problem, they only partially addressed the key
additional challenges in CISS that causes the catastrophic forgetting; i.e.,
the semantic drift of the background class and multi-label prediction issue. To
better address these challenges, we propose a new method, dubbed as SSUL-M
(Semantic Segmentation with Unknown Label with Memory), by carefully combining
several techniques tailored for semantic segmentation. More specifically, we
make three main contributions; (1) modeling unknown class within the background
class to help learning future classes (help plasticity), (2) freezing backbone
network and past classifiers with binary cross-entropy loss and pseudo-labeling
to overcome catastrophic forgetting (help stability), and (3) utilizing tiny
exemplar memory for the first time in CISS to improve both plasticity and
stability. As a result, we show our method achieves significantly better
performance than the recent state-of-the-art baselines on the standard
benchmark datasets. Furthermore, we justify our contributions with thorough and
extensive ablation analyses and discuss different natures of the CISS problem
compared to the standard class-incremental learning for classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation. (arXiv:2107.00644v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00644">
                                    <div class="article-summary-box-inner">
                                        <span>While agents trained by Reinforcement Learning (RL) can solve increasingly
challenging tasks directly from visual observations, generalizing learned
skills to novel environments remains very challenging. Extensive use of data
augmentation is a promising technique for improving generalization in RL, but
it is often found to decrease sample efficiency and can even lead to
divergence. In this paper, we investigate causes of instability when using data
augmentation in common off-policy RL algorithms. We identify two problems, both
rooted in high-variance Q-targets. Based on our findings, we propose a simple
yet effective technique for stabilizing this class of algorithms under
augmentation. We perform extensive empirical evaluation of image-based RL using
both ConvNets and Vision Transformers (ViT) on a family of benchmarks based on
DeepMind Control Suite, as well as in robotic manipulation tasks. Our method
greatly improves stability and sample efficiency of ConvNets under
augmentation, and achieves generalization results competitive with
state-of-the-art methods for image-based RL. We further show that our method
scales to RL with ViT-based architectures, and that data augmentation may be
especially important in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoFormer: Searching Transformers for Visual Recognition. (arXiv:2107.00651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Houwen Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibin Ling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00651">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pure transformer-based models have shown great potentials for
vision tasks such as image classification and detection. However, the design of
transformer networks is challenging. It has been observed that the depth,
embedding dimension, and number of heads can largely affect the performance of
vision transformers. Previous models configure these dimensions based upon
manual crafting. In this work, we propose a new one-shot architecture search
framework, namely AutoFormer, dedicated to vision transformer search.
AutoFormer entangles the weights of different blocks in the same layers during
supernet training. Benefiting from the strategy, the trained supernet allows
thousands of subnets to be very well-trained. Specifically, the performance of
these subnets with weights inherited from the supernet is comparable to those
retrained from scratch. Besides, the searched models, which we refer to
AutoFormers, surpass the recent state-of-the-arts such as ViT and DeiT. In
particular, AutoFormer-tiny/small/base achieve 74.7%/81.7%/82.4% top-1 accuracy
on ImageNet with 5.7M/22.9M/53.7M parameters, respectively. Lastly, we verify
the transferability of AutoFormer by providing the performance on downstream
benchmarks and distillation experiments. Code and models are available at
https://github.com/microsoft/AutoML.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP-It! Language-Guided Video Summarization. (arXiv:2107.00650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_M/0/1/0/all/0/1">Medhini Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00650">
                                    <div class="article-summary-box-inner">
                                        <span>A generic video summary is an abridged version of a video that conveys the
whole story and features the most important scenes. Yet the importance of
scenes in a video is often subjective, and users should have the option of
customizing the summary by using natural language to specify what is important
to them. Further, existing models for fully automatic generic summarization
have not exploited available language models, which can serve as an effective
prior for saliency. This work introduces CLIP-It, a single framework for
addressing both generic and query-focused video summarization, typically
approached separately in the literature. We propose a language-guided
multimodal transformer that learns to score frames in a video based on their
importance relative to one another and their correlation with a user-defined
query (for query-focused summarization) or an automatically generated dense
video caption (for generic video summarization). Our model can be extended to
the unsupervised setting by training without ground-truth supervision. We
outperform baselines and prior work by a significant margin on both standard
video summarization datasets (TVSum and SumMe) and a query-focused video
summarization dataset (QFVS). Particularly, we achieve large improvements in
the transfer setting, attesting to our method&#x27;s strong generalization
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Neural Domain Adaptation for Document Image Binarization. (arXiv:2012.01204v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellanos_F/0/1/0/all/0/1">Francisco J. Castellanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_A/0/1/0/all/0/1">Antonio-Javier Gallego</a>, <a href="http://arxiv.org/find/cs/1/au:+Calvo_Zaragoza_J/0/1/0/all/0/1">Jorge Calvo-Zaragoza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01204">
                                    <div class="article-summary-box-inner">
                                        <span>Binarization is a well-known image processing task, whose objective is to
separate the foreground of an image from the background. One of the many tasks
for which it is useful is that of preprocessing document images in order to
identify relevant information, such as text or symbols. The wide variety of
document types, alphabets, and formats makes binarization challenging. There
are multiple proposals with which to solve this problem, from classical
manually-adjusted methods, to more recent approaches based on machine learning.
The latter techniques require a large amount of training data in order to
obtain good results; however, labeling a portion of each existing collection of
documents is not feasible in practice. This is a common problem in supervised
learning, which can be addressed by using the so-called Domain Adaptation (DA)
techniques. These techniques take advantage of the knowledge learned in one
domain, for which labeled data are available, to apply it to other domains for
which there are no labeled data. This paper proposes a method that combines
neural networks and DA in order to carry out unsupervised document
binarization. However, when both the source and target domains are very
similar, this adaptation could be detrimental. Our methodology, therefore,
first measures the similarity between domains in an innovative manner in order
to determine whether or not it is appropriate to apply the adaptation process.
The results reported in the experimentation, when evaluating up to 20 possible
combinations among five different domains, show that our proposal successfully
deals with the binarization of new document domains without the need for
labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework of Bundle Adjustment and Feature Matching for High-Resolution Satellite Images. (arXiv:2107.00598v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiao Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00598">
                                    <div class="article-summary-box-inner">
                                        <span>Bundle adjustment (BA) is a technique for refining sensor orientations of
satellite images, while adjustment accuracy is correlated with feature matching
results. Feature match-ing often contains high uncertainties in weak/repeat
textures, while BA results are helpful in reducing these uncertainties. To
compute more accurate orientations, this article incorpo-rates BA and feature
matching in a unified framework and formulates the union as the optimization of
a global energy function so that the solutions of the BA and feature matching
are constrained with each other. To avoid a degeneracy in the optimization, we
propose a comprised solution by breaking the optimization of the global energy
function into two-step suboptimizations and compute the local minimums of each
suboptimization in an incremental manner. Experiments on multi-view
high-resolution satellite images show that our proposed method outperforms
state-of-the-art orientation techniques with or without accurate least-squares
matching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are Convolutional Neural Networks or Transformers more like human vision?. (arXiv:2105.07197v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuli_S/0/1/0/all/0/1">Shikhar Tuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1">Ishita Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1">Erin Grant</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07197">
                                    <div class="article-summary-box-inner">
                                        <span>Modern machine learning models for computer vision exceed humans in accuracy
on specific visual recognition tasks, notably on datasets like ImageNet.
However, high accuracy can be achieved in many ways. The particular decision
function found by a machine learning system is determined not only by the data
to which the system is exposed, but also the inductive biases of the model,
which are typically harder to characterize. In this work, we follow a recent
trend of in-depth behavioral analyses of neural network models that go beyond
accuracy as an evaluation metric by looking at patterns of errors. Our focus is
on comparing a suite of standard Convolutional Neural Networks (CNNs) and a
recently-proposed attention-based network, the Vision Transformer (ViT), which
relaxes the translation-invariance constraint of CNNs and therefore represents
a model with a weaker set of inductive biases. Attention-based networks have
previously been shown to achieve higher accuracy than CNNs on vision tasks, and
we demonstrate, using new metrics for examining error consistency with more
granularity, that their errors are also more consistent with those of humans.
These results have implications both for building more human-like vision
models, as well as for understanding visual object recognition in humans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Sparsity for Smoothing Filters. (arXiv:2107.00627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junqing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuechao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzhansky_M/0/1/0/all/0/1">Michael Ruzhansky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00627">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an interesting semi-sparsity smoothing algorithm
based on a novel sparsity-inducing optimization framework. This method is
derived from the multiple observations, that is, semi-sparsity prior knowledge
is more universally applicable, especially in areas where sparsity is not fully
admitted, such as polynomial-smoothing surfaces. We illustrate that this
semi-sparsity can be identified into a generalized $L_0$-norm minimization in
higher-order gradient domains, thereby giving rise to a new &#x60;&#x60;feature-aware&#x27;&#x27;
filtering method with a powerful simultaneous-fitting ability in both sparse
features (singularities and sharpening edges) and non-sparse regions
(polynomial-smoothing surfaces). Notice that a direct solver is always
unavailable due to the non-convexity and combinatorial nature of $L_0$-norm
minimization. Instead, we solve the model based on an efficient half-quadratic
splitting minimization with fast Fourier transforms (FFTs) for acceleration. We
finally demonstrate its versatility and many benefits to a series of
signal/image processing and computer vision applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explicit Clothing Modeling for an Animatable Full-Body Avatar. (arXiv:2106.14879v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_D/0/1/0/all/0/1">Donglai Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_F/0/1/0/all/0/1">Fabian Andres Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagautdinov_T/0/1/0/all/0/1">Timur Bagautdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">He Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodgins_J/0/1/0/all/0/1">Jessica Hodgins</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenglei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14879">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown great progress in building photorealistic animatable
full-body codec avatars, but these avatars still face difficulties in
generating high-fidelity animation of clothing. To address the difficulties, we
propose a method to build an animatable clothed body avatar with an explicit
representation of the clothing on the upper body from multi-view captured
videos. We use a two-layer mesh representation to separately register the 3D
scans with templates. In order to improve the photometric correspondence across
different frames, texture alignment is then performed through inverse rendering
of the clothing geometry and texture predicted by a variational autoencoder. We
then train a new two-layer codec avatar with separate modeling of the upper
clothing and the inner body layer. To learn the interaction between the body
dynamics and clothing states, we use a temporal convolution network to predict
the clothing latent code based on a sequence of input skeletal poses. We show
photorealistic animation output for three different actors, and demonstrate the
advantage of our clothed-body avatars over single-layer avatars in the previous
work. We also show the benefit of an explicit clothing model which allows the
clothing texture to be edited in the animation output.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Practicality of Deterministic Epistemic Uncertainty. (arXiv:2107.00649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Postels_J/0/1/0/all/0/1">Janis Postels</a>, <a href="http://arxiv.org/find/cs/1/au:+Segu_M/0/1/0/all/0/1">Mattia Segu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fisher Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00649">
                                    <div class="article-summary-box-inner">
                                        <span>A set of novel approaches for estimating epistemic uncertainty in deep neural
networks with a single forward pass has recently emerged as a valid alternative
to Bayesian Neural Networks. On the premise of informative representations,
these deterministic uncertainty methods (DUMs) achieve strong performance on
detecting out-of-distribution (OOD) data while adding negligible computational
costs at inference time. However, it remains unclear whether DUMs are well
calibrated and can seamlessly scale to real-world applications - both
prerequisites for their practical deployment. To this end, we first provide a
taxonomy of DUMs, evaluate their calibration under continuous distributional
shifts and their performance on OOD detection for image classification tasks.
Then, we extend the most promising approaches to semantic segmentation. We find
that, while DUMs scale to realistic vision tasks and perform well on OOD
detection, the practicality of current methods is undermined by poor
calibration under realistic distributional shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focal Self-attention for Local-Global Interactions in Vision Transformers. (arXiv:2107.00641v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformer and its variants have shown great promise on
various computer vision tasks. The ability of capturing short- and long-range
visual dependencies through self-attention is arguably the main source for the
success. But it also brings challenges due to quadratic computational overhead,
especially for the high-resolution vision tasks (e.g., object detection). In
this paper, we present focal self-attention, a new mechanism that incorporates
both fine-grained local and coarse-grained global interactions. Using this new
mechanism, each token attends the closest surrounding tokens at fine
granularity but the tokens far away at coarse granularity, and thus can capture
both short- and long-range visual dependencies efficiently and effectively.
With focal self-attention, we propose a new variant of Vision Transformer
models, called Focal Transformer, which achieves superior performance over the
state-of-the-art vision Transformers on a range of public image classification
and object detection benchmarks. In particular, our Focal Transformer models
with a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8
Top-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.
Using Focal Transformers as the backbones, we obtain consistent and substantial
improvements over the current state-of-the-art Swin Transformers for 6
different object detection methods trained with standard 1x and 3x schedules.
Our largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs
on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,
creating new SoTA on three of the most challenging computer vision tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Visual Recognition in Limited Data Regime using Self-Supervision and Self-Distillation. (arXiv:2107.00067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazumder_P/0/1/0/all/0/1">Pratik Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Pravendra Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P. Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00067">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models generally learn the biases present in the training data.
Researchers have proposed several approaches to mitigate such biases and make
the model fair. Bias mitigation techniques assume that a sufficiently large
number of training examples are present. However, we observe that if the
training data is limited, then the effectiveness of bias mitigation methods is
severely degraded. In this paper, we propose a novel approach to address this
problem. Specifically, we adapt self-supervision and self-distillation to
reduce the impact of biases on the model in this setting. Self-supervision and
self-distillation are not used for bias mitigation. However, through this work,
we demonstrate for the first time that these techniques are very effective in
bias mitigation. We empirically show that our approach can significantly reduce
the biases learned by the model. Further, we experimentally demonstrate that
our approach is complementary to other bias mitigation strategies. Our approach
significantly improves their performance and further reduces the model biases
in the limited data regime. Specifically, on the L-CIFAR-10S skewed dataset,
our approach significantly reduces the bias score of the baseline model by
78.22% and outperforms it in terms of accuracy by a significant absolute margin
of 8.89%. It also significantly reduces the bias score for the state-of-the-art
domain independent bias mitigation method by 59.26% and improves its
performance by a significant absolute margin of 7.08%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Filter Networks for Image Classification. (arXiv:2107.00645v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00645">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-attention and pure multi-layer perceptrons (MLP)
models for vision have shown great potential in achieving promising performance
with fewer inductive biases. These models are generally based on learning
interaction among spatial locations from raw data. The complexity of
self-attention and MLP grows quadratically as the image size increases, which
makes these models hard to scale up when high-resolution features are required.
In this paper, we present the Global Filter Network (GFNet), a conceptually
simple yet computationally efficient architecture, that learns long-term
spatial dependencies in the frequency domain with log-linear complexity. Our
architecture replaces the self-attention layer in vision transformers with
three key operations: a 2D discrete Fourier transform, an element-wise
multiplication between frequency-domain features and learnable global filters,
and a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity
trade-offs of our models on both ImageNet and downstream tasks. Our results
demonstrate that GFNet can be a very competitive alternative to
transformer-style models and CNNs in efficiency, generalization ability and
robustness. Code is available at https://github.com/raoyongming/GFNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Segmentation with Domain Adaptation for Small Sampled Orbital CT Images. (arXiv:2107.00418v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Suh_S/0/1/0/all/0/1">Sungho Suh</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheon_S/0/1/0/all/0/1">Sojeong Cheon</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_W/0/1/0/all/0/1">Wonseo Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Chung_Y/0/1/0/all/0/1">Yeon Woong Chung</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_W/0/1/0/all/0/1">Won-Kyung Cho</a>, <a href="http://arxiv.org/find/eess/1/au:+Paik_J/0/1/0/all/0/1">Ji-Sun Paik</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1">Sung Eun Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_D/0/1/0/all/0/1">Dong-Jin Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_Y/0/1/0/all/0/1">Yong Oh Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00418">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have been widely used for medical image analysis.
However, the lack of access a to large-scale annotated dataset poses a great
challenge, especially in the case of rare diseases, or new domains for the
research society. Transfer of pre-trained features, from the relatively large
dataset is a considerable solution. In this paper, we have explored supervised
segmentation using domain adaptation for optic nerve and orbital tumor, when
only small sampled CT images are given. Even the lung image database consortium
image collection (LIDC-IDRI) is a cross-domain to orbital CT, but the proposed
domain adaptation method improved the performance of attention U-Net for the
segmentation in public optic nerve dataset and our clinical orbital tumor
dataset. The code and dataset are available at https://github.com/cmcbigdata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Iterative Spatiotemporal Filtering for Classification of Multitemporal Satellite Data Sets. (arXiv:2107.00590v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Albanwan_H/0/1/0/all/0/1">Hessah Albanwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaohu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Desheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guldmann_J/0/1/0/all/0/1">Jean-Michel Guldmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00590">
                                    <div class="article-summary-box-inner">
                                        <span>The current practice in land cover/land use change analysis relies heavily on
the individually classified maps of the multitemporal data set. Due to varying
acquisition conditions (e.g., illumination, sensors, seasonal differences), the
classification maps yielded are often inconsistent through time for robust
statistical analysis. 3D geometric features have been shown to be stable for
assessing differences across the temporal data set. Therefore, in this article
we investigate he use of a multitemporal orthophoto and digital surface model
derived from satellite data for spatiotemporal classification. Our approach
consists of two major steps: generating per-class probability distribution maps
using the random-forest classifier with limited training samples, and making
spatiotemporal inferences using an iterative 3D spatiotemporal filter operating
on per-class probability maps. Our experimental results demonstrate that the
proposed methods can consistently improve the individual classification results
by 2%-6% and thus can be an important postclassification refinement approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generic Event Boundary Detection Challenge at CVPR 2021 Technical Report: Cascaded Temporal Attention Network (CASTANET). (arXiv:2107.00239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Dexiang Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Congcong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Longyin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Libo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00239">
                                    <div class="article-summary-box-inner">
                                        <span>This report presents the approach used in the submission of Generic Event
Boundary Detection (GEBD) Challenge at CVPR21. In this work, we design a
Cascaded Temporal Attention Network (CASTANET) for GEBD, which is formed by
three parts, the backbone network, the temporal attention module, and the
classification module. Specifically, the Channel-Separated Convolutional
Network (CSN) is used as the backbone network to extract features, and the
temporal attention module is designed to enforce the network to focus on the
discriminative features. After that, the cascaded architecture is used in the
classification module to generate more accurate boundaries. In addition, the
ensemble strategy is used to further improve the performance of the proposed
method. The proposed method achieves 83.30% F1 score on Kinetics-GEBD test set,
which improves 20.5% F1 score compared to the baseline method. Code is
available at https://github.com/DexiangHong/Cascade-PC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SALYPATH: A Deep-Based Architecture for visual attention prediction. (arXiv:2107.00559v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kerkouri_M/0/1/0/all/0/1">Mohamed Amine Kerkouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tliba_M/0/1/0/all/0/1">Marouane Tliba</a>, <a href="http://arxiv.org/find/cs/1/au:+Chetouani_A/0/1/0/all/0/1">Aladine Chetouani</a>, <a href="http://arxiv.org/find/cs/1/au:+Harba_R/0/1/0/all/0/1">Rachid Harba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00559">
                                    <div class="article-summary-box-inner">
                                        <span>Human vision is naturally more attracted by some regions within their field
of view than others. This intrinsic selectivity mechanism, so-called visual
attention, is influenced by both high- and low-level factors; such as the
global environment (illumination, background texture, etc.), stimulus
characteristics (color, intensity, orientation, etc.), and some prior visual
information. Visual attention is useful for many computer vision applications
such as image compression, recognition, and captioning. In this paper, we
propose an end-to-end deep-based method, so-called SALYPATH (SALiencY and
scanPATH), that efficiently predicts the scanpath of an image through features
of a saliency model. The idea is predict the scanpath by exploiting the
capacity of a deep-based model to predict the saliency. The proposed method was
evaluated through 2 well-known datasets. The results obtained showed the
relevance of the proposed framework comparing to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency Modeling. (arXiv:2107.00070v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00070">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks with an $L_0$ regularization is one of the
prominent approaches for network pruning or sparsification. The method prunes
the network during training by encouraging weights to become exactly zero.
However, recent work of Gale et al. reveals that although this method yields
high compression rates on smaller datasets, it performs inconsistently on
large-scale learning tasks, such as ResNet50 on ImageNet. We analyze this
phenomenon through the lens of variational inference and find that it is likely
due to the independent modeling of binary gates, the mean-field approximation,
which is known in Bayesian statistics for its poor performance due to the crude
approximation. To mitigate this deficiency, we propose a dependency modeling of
binary gates, which can be modeled effectively as a multi-layer perceptron
(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a
dependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,
CIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$
outperforms the original $L_0$-HC algorithm of Louizos et al. by a significant
margin, especially on ImageNet. Compared with the state-of-the-arts network
sparsification algorithms, our dependency modeling makes the $L_0$-based
sparsification once again very competitive on large-scale learning tasks. Our
source code is available at https://github.com/leo-yangli/dep-l0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Certified Segmentation via Randomized Smoothing. (arXiv:2107.00228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1">Marc Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1">Maximilian Baader</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00228">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new certification method for image and point cloud segmentation
based on randomized smoothing. The method leverages a novel scalable algorithm
for prediction and certification that correctly accounts for multiple testing,
necessary for ensuring statistical guarantees. The key to our approach is
reliance on established multiple-testing correction mechanisms as well as the
ability to abstain from classifying single pixels or points while still
robustly segmenting the overall input. Our experimental evaluation on synthetic
data and challenging datasets, such as Pascal Context, Cityscapes, and
ShapeNet, shows that our algorithm can achieve, for the first time, competitive
accuracy and certification guarantees on real-world segmentation tasks. We
provide an implementation at https://github.com/eth-sri/segmentation-smoothing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossless Coding of Point Cloud Geometry using a Deep Generative Model. (arXiv:2107.00400v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1">Dat Thanh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Quach_M/0/1/0/all/0/1">Maurice Quach</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenzise_G/0/1/0/all/0/1">Giuseppe Valenzise</a>, <a href="http://arxiv.org/find/eess/1/au:+Duhamel_P/0/1/0/all/0/1">Pierre Duhamel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00400">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a lossless point cloud (PC) geometry compression method
that uses neural networks to estimate the probability distribution of voxel
occupancy. First, to take into account the PC sparsity, our method adaptively
partitions a point cloud into multiple voxel block sizes. This partitioning is
signalled via an octree. Second, we employ a deep auto-regressive generative
model to estimate the occupancy probability of each voxel given the previously
encoded ones. We then employ the estimated probabilities to code efficiently a
block using a context-based arithmetic coder. Our context has variable size and
can expand beyond the current block to learn more accurate probabilities. We
also consider using data augmentation techniques to increase the generalization
capability of the learned probability models, in particular in the presence of
noise and lower-density point clouds. Experimental evaluation, performed on a
variety of point clouds from four different datasets and with diverse
characteristics, demonstrates that our method reduces significantly (by up to
30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overhead-MNIST: Machine Learning Baselines for Image Classification. (arXiv:2107.00436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Larsen_E/0/1/0/all/0/1">Erik Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+MacVittie_K/0/1/0/all/0/1">Korey MacVittie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lilly_J/0/1/0/all/0/1">John Lilly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00436">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-three machine learning algorithms were trained then scored to
establish baseline comparison metrics and to select an image classification
algorithm worthy of embedding into mission-critical satellite imaging systems.
The Overhead-MNIST dataset is a collection of satellite images similar in style
to the ubiquitous MNIST hand-written digits found in the machine learning
literature. The CatBoost classifier, Light Gradient Boosting Machine, and
Extreme Gradient Boosting models produced the highest accuracies, Areas Under
the Curve (AUC), and F1 scores in a PyCaret general comparison. Separate
evaluations showed that a deep convolutional architecture was the most
promising. We present results for the overall best performing algorithm as a
baseline for edge deployability and future performance improvement: a
convolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen
test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivergentNets: Medical Image Segmentation by Network Ensemble. (arXiv:2107.00283v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00283">
                                    <div class="article-summary-box-inner">
                                        <span>Detection of colon polyps has become a trending topic in the intersecting
fields of machine learning and gastrointestinal endoscopy. The focus has mainly
been on per-frame classification. More recently, polyp segmentation has gained
attention in the medical community. Segmentation has the advantage of being
more accurate than per-frame classification or object detection as it can show
the affected area in greater detail. For our contribution to the EndoCV 2021
segmentation challenge, we propose two separate approaches. First, a
segmentation model named TriUNet composed of three separate UNet models.
Second, we combine TriUNet with an ensemble of well-known segmentation models,
namely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called
DivergentNets to produce more generalizable medical image segmentation masks.
In addition, we propose a modified Dice loss that calculates loss only for a
single class when performing multiclass segmentation, forcing the model to
focus on what is most important. Overall, the proposed methods achieved the
best average scores for each respective round in the challenge, with TriUNet
being the winning model in Round I and DivergentNets being the winning model in
Round II of the segmentation generalization challenge at EndoCV 2021. The
implementation of our approach is made publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the detection-to-track association for online multi-object tracking. (arXiv:2107.00500v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xufeng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chang-Tsun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1">Victor Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1">Carsten Maple</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00500">
                                    <div class="article-summary-box-inner">
                                        <span>Driven by recent advances in object detection with deep neural networks, the
tracking-by-detection paradigm has gained increasing prevalence in the research
community of multi-object tracking (MOT). It has long been known that
appearance information plays an essential role in the detection-to-track
association, which lies at the core of the tracking-by-detection paradigm.
While most existing works consider the appearance distances between the
detections and the tracks, they ignore the statistical information implied by
the historical appearance distance records in the tracks, which can be
particularly useful when a detection has similar distances with two or more
tracks. In this work, we propose a hybrid track association (HTA) algorithm
that models the historical appearance distances of a track with an incremental
Gaussian mixture model (IGMM) and incorporates the derived statistical
information into the calculation of the detection-to-track association cost.
Experimental results on three MOT benchmarks confirm that HTA effectively
improves the target identification performance with a small compromise to the
tracking speed. Additionally, compared to many state-of-the-art trackers, the
DeepSORT tracker equipped with HTA achieves better or comparable performance in
terms of the balance of tracking quality and speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Measuring Bias in Image Classification. (arXiv:2107.00360v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaaf_N/0/1/0/all/0/1">Nina Schaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitri_O/0/1/0/all/0/1">Omar de Mitri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hang Beom Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Windberger_A/0/1/0/all/0/1">Alexander Windberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1">Marco F. Huber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00360">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNN) have become de fact state-of-the-art for
the main computer vision tasks. However, due to the complex underlying
structure their decisions are hard to understand which limits their use in some
context of the industrial world. A common and hard to detect challenge in
machine learning (ML) tasks is data bias. In this work, we present a systematic
approach to uncover data bias by means of attribution maps. For this purpose,
first an artificial dataset with a known bias is created and used to train
intentionally biased CNNs. The networks&#x27; decisions are then inspected using
attribution maps. Finally, meaningful metrics are used to measure the
attribution maps&#x27; representativeness with respect to the known bias. The
proposed study shows that some attribution map techniques highlight the
presence of bias in the data better than others and metrics can support the
identification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph. (arXiv:2107.00395v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00395">
                                    <div class="article-summary-box-inner">
                                        <span>Previous works indicate that the glyph of Chinese characters contains rich
semantic information and has the potential to enhance the representation of
Chinese characters. The typical method to utilize the glyph features is by
incorporating them into the character embedding space. Inspired by previous
methods, we innovatively propose a Chinese pre-trained representation model
named as GlyphCRM, which abandons the ID-based character embedding method yet
solely based on sequential character images. We render each character into a
binary grayscale image and design two-channel position feature maps for it.
Formally, we first design a two-layer residual convolutional neural network,
namely HanGlyph to generate the initial glyph representation of Chinese
characters, and subsequently adopt multiple bidirectional encoder Transformer
blocks as the superstructure to capture the context-sensitive information.
Meanwhile, we feed the glyph features extracted from each layer of the HanGlyph
module into the underlying Transformer blocks by skip-connection method to
fully exploit the glyph features of Chinese characters. As the HanGlyph module
can obtain a sufficient glyph representation of any Chinese character, the
long-standing out-of-vocabulary problem could be effectively solved. Extensive
experimental results indicate that GlyphCRM substantially outperforms the
previous BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has
strong transferability and generalization on specialized fields and
low-resource tasks. We hope this work could spark further research beyond the
realms of well-established representation of Chinese texts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowdsourcing Evaluation of Saliency-based XAI Methods. (arXiv:2107.00456v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaotian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1">Arseny Tolmachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Tatsuya Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1">Koh Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1">Seiji Okajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1">Tomoyoshi Takebayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00456">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the reasons behind the predictions made by deep neural networks
is critical for gaining human trust in many important applications, which is
reflected in the increasing demand for explainability in AI (XAI) in recent
years. Saliency-based feature attribution methods, which highlight important
parts of images that contribute to decisions by classifiers, are often used as
XAI methods, especially in the field of computer vision. In order to compare
various saliency-based XAI methods quantitatively, several approaches for
automated evaluation schemes have been proposed; however, there is no guarantee
that such automated evaluation metrics correctly evaluate explainability, and a
high rating by an automated evaluation scheme does not necessarily mean a high
explainability for humans. In this study, instead of the automated evaluation,
we propose a new human-based evaluation scheme using crowdsourcing to evaluate
XAI methods. Our method is inspired by a human computation game, &quot;Peek-a-boom&quot;,
and can efficiently compare different XAI methods by exploiting the power of
crowds. We evaluate the saliency maps of various XAI methods on two datasets
with automated and crowd-based evaluation schemes. Our experiments show that
the result of our crowd-based evaluation scheme is different from those of
automated evaluation schemes. In addition, we regard the crowd-based evaluation
results as ground truths and provide a quantitative performance measure to
compare different automated evaluation schemes. We also discuss the impact of
crowd workers on the results and show that the varying ability of crowd workers
does not significantly impact the results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Disambiguate Strongly Interacting Hands via Probabilistic Per-pixel Part Segmentation. (arXiv:2107.00434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zicong Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1">Adrian Spurr</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1">Muhammed Kocabas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siyu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00434">
                                    <div class="article-summary-box-inner">
                                        <span>In natural conversation and interaction, our hands often overlap or are in
contact with each other. Due to the homogeneous appearance of hands, this makes
estimating the 3D pose of interacting hands from images difficult. In this
paper we demonstrate that self-similarity, and the resulting ambiguities in
assigning pixel observations to the respective hands and their parts, is a
major cause of the final 3D pose error. Motivated by this insight, we propose
DIGIT, a novel method for estimating the 3D poses of two interacting hands from
a single monocular image. The method consists of two interwoven branches that
process the input imagery into a per-pixel semantic part segmentation mask and
a visual feature volume. In contrast to prior work, we do not decouple the
segmentation from the pose estimation stage, but rather leverage the per-pixel
probabilities directly in the downstream pose estimation task. To do so, the
part probabilities are merged with the visual features and processed via
fully-convolutional layers. We experimentally show that the proposed approach
achieves new state-of-the-art performance on the InterHand2.6M dataset for both
single and interacting hands across all metrics. We provide detailed ablation
studies to demonstrate the efficacy of our method and to provide insights into
how the modelling of pixel ownership affects single and interacting hand pose
estimation. Our code will be released for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OPT: Omni-Perception Pre-Trainer for Cross-Modal Understanding and Generation. (arXiv:2107.00249v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinxin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longteng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zijia Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingzhen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weining Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinqiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hanqing Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00249">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an Omni-perception Pre-Trainer (OPT) for
cross-modal understanding and generation, by jointly modeling visual, text and
audio resources. OPT is constructed in an encoder-decoder framework, including
three single-modal encoders to generate token-based embeddings for each
modality, a cross-modal encoder to encode the correlations among the three
modalities, and two cross-modal decoders to generate text and image
respectively. For the OPT&#x27;s pre-training, we design a multi-task pretext
learning scheme to model multi-modal resources from three different data
granularities, \ie, token-, modality-, and sample-level modeling, through which
OPT learns to align and translate among different modalities. The pre-training
task is carried out on a large amount of image-text-audio triplets from Open
Images. Experimental results show that OPT can learn strong image-text-audio
multi-modal representations and achieve promising results on a variety of
cross-modal understanding and generation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Human Motion Prediction Through Continual Learning. (arXiv:2107.00544v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yasar_M/0/1/0/all/0/1">Mohammad Samin Yasar</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_T/0/1/0/all/0/1">Tariq Iqbal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00544">
                                    <div class="article-summary-box-inner">
                                        <span>Human motion prediction is an essential component for enabling closer
human-robot collaboration. The task of accurately predicting human motion is
non-trivial. It is compounded by the variability of human motion, both at a
skeletal level due to the varying size of humans and at a motion level due to
individual movement&#x27;s idiosyncrasies. These variables make it challenging for
learning algorithms to obtain a general representation that is robust to the
diverse spatio-temporal patterns of human motion. In this work, we propose a
modular sequence learning approach that allows end-to-end training while also
having the flexibility of being fine-tuned. Our approach relies on the
diversity of training samples to first learn a robust representation, which can
then be fine-tuned in a continual learning setup to predict the motion of new
subjects. We evaluated the proposed approach by comparing its performance
against state-of-the-art baselines. The results suggest that our approach
outperforms other methods over all the evaluated temporal horizons, using a
small amount of data for fine-tuning. The improved performance of our approach
opens up the possibility of using continual learning for personalized and
reliable motion prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter Extreme Points Geodesics for Weakly Supervised Segmentation. (arXiv:2107.00583v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dorent_R/0/1/0/all/0/1">Reuben Dorent</a>, <a href="http://arxiv.org/find/cs/1/au:+Joutard_S/0/1/0/all/0/1">Samuel Joutard</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapey_J/0/1/0/all/0/1">Jonathan Shapey</a>, <a href="http://arxiv.org/find/cs/1/au:+Kujawa_A/0/1/0/all/0/1">Aaron Kujawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Modat_M/0/1/0/all/0/1">Marc Modat</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vercauteren_T/0/1/0/all/0/1">Tom Vercauteren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00583">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce $\textit{InExtremIS}$, a weakly supervised 3D approach to train
a deep image segmentation network using particularly weak train-time
annotations: only 6 extreme clicks at the boundary of the objects of interest.
Our fully-automatic method is trained end-to-end and does not require any
test-time annotations. From the extreme points, 3D bounding boxes are extracted
around objects of interest. Then, deep geodesics connecting extreme points are
generated to increase the amount of &quot;annotated&quot; voxels within the bounding
boxes. Finally, a weakly supervised regularised loss derived from a Conditional
Random Field formulation is used to encourage prediction consistency over
homogeneous regions. Extensive experiments are performed on a large open
dataset for Vestibular Schwannoma segmentation. $\textit{InExtremIS}$ obtained
competitive performance, approaching full supervision and outperforming
significantly other weakly supervised techniques based on bounding boxes.
Moreover, given a fixed annotation time budget, $\textit{InExtremIS}$
outperforms full supervision. Our code and data are available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedMix: Approximation of Mixup under Mean Augmented Federated Learning. (arXiv:2107.00233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1">Tehrim Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Sumin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00233">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) allows edge devices to collectively learn a model
without directly sharing data within each device, thus preserving privacy and
eliminating the need to store data globally. While there are promising results
under the assumption of independent and identically distributed (iid) local
data, current state-of-the-art algorithms suffer from performance degradation
as the heterogeneity of local data across clients increases. To resolve this
issue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),
where clients send and receive averaged local data, subject to the privacy
requirements of target applications. Under our framework, we propose a new
augmentation algorithm, named FedMix, which is inspired by a phenomenal yet
simple data augmentation method, Mixup, but does not require local raw data to
be directly shared among devices. Our method shows greatly improved performance
in the standard benchmark datasets of FL, under highly non-iid federated
settings, compared to conventional algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Compression Towards Machine Vision: Network Architecture Design and Optimization. (arXiv:2107.00328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shurun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00328">
                                    <div class="article-summary-box-inner">
                                        <span>The research of visual signal compression has a long history. Fueled by deep
learning, exciting progress has been made recently. Despite achieving better
compression performance, existing end-to-end compression algorithms are still
designed towards better signal quality in terms of rate-distortion
optimization. In this paper, we show that the design and optimization of
network architecture could be further improved for compression towards machine
vision. We propose an inverted bottleneck structure for end-to-end compression
towards machine vision, which specifically accounts for efficient
representation of the semantic information. Moreover, we quest the capability
of optimization by incorporating the analytics accuracy into the optimization
process, and the optimality is further explored with generalized rate-accuracy
optimization in an iterative manner. We use object detection as a showcase for
end-to-end compression towards machine vision, and extensive experiments show
that the proposed scheme achieves significant BD-rate savings in terms of
analysis performance. Moreover, the promise of the scheme is also demonstrated
with strong generalization capability towards other machine vision tasks, due
to the enabling of signal-level reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Diabetic Retinopathy Detection and Retinal Image Generation. (arXiv:2107.00296v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Niu_Y/0/1/0/all/0/1">Yuhao Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_L/0/1/0/all/0/1">Lin Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yitian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00296">
                                    <div class="article-summary-box-inner">
                                        <span>Though deep learning has shown successful performance in classifying the
label and severity stage of certain diseases, most of them give few
explanations on how to make predictions. Inspired by Koch&#x27;s Postulates, the
foundation in evidence-based medicine (EBM) to identify the pathogen, we
propose to exploit the interpretability of deep learning application in medical
diagnosis. By determining and isolating the neuron activation patterns on which
diabetic retinopathy (DR) detector relies to make decisions, we demonstrate the
direct relation between the isolated neuron activation and lesions for a
pathological explanation. To be specific, we first define novel pathological
descriptors using activated neurons of the DR detector to encode both spatial
and appearance information of lesions. Then, to visualize the symptom encoded
in the descriptor, we propose Patho-GAN, a new network to synthesize medically
plausible retinal images. By manipulating these descriptors, we could even
arbitrarily control the position, quantity, and categories of generated
lesions. We also show that our synthesized images carry the symptoms directly
related to diabetic retinopathy diagnosis. Our generated images are both
qualitatively and quantitatively superior to the ones by previous methods.
Besides, compared to existing methods that take hours to generate an image, our
second level speed endows the potential to be an effective solution for data
augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoLightFormer: Lightweight Action Recognition using Transformers. (arXiv:2107.00451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient video action recognition remains a challenging problem. One large
model after another takes the place of the state-of-the-art on the Kinetics
dataset, but real-world efficiency evaluations are often lacking. In this work,
we fill this gap and investigate the use of transformers for efficient action
recognition. We propose a novel, lightweight action recognition architecture,
VideoLightFormer. In a factorized fashion, we carefully extend the 2D
convolutional Temporal Segment Network with transformers, while maintaining
spatial and temporal video structure throughout the entire model. Existing
methods often resort to one of the two extremes, where they either apply huge
transformers to video features, or minimal transformers on highly pooled video
features. Our method differs from them by keeping the transformer models small,
but leveraging full spatiotemporal feature structure. We evaluate
VideoLightFormer in a high-efficiency setting on the temporally-demanding
EPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it
achieves a better mix of efficiency and accuracy than existing state-of-the-art
models, apart from the Temporal Shift Module on SSV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSC: Semantic Scan Context for Large-Scale Place Recognition. (arXiv:2107.00382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangrui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tianxin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00382">
                                    <div class="article-summary-box-inner">
                                        <span>Place recognition gives a SLAM system the ability to correct cumulative
errors. Unlike images that contain rich texture features, point clouds are
almost pure geometric information which makes place recognition based on point
clouds challenging. Existing works usually encode low-level features such as
coordinate, normal, reflection intensity, etc., as local or global descriptors
to represent scenes. Besides, they often ignore the translation between point
clouds when matching descriptors. Different from most existing methods, we
explore the use of high-level features, namely semantics, to improve the
descriptor&#x27;s representation ability. Also, when matching descriptors, we try to
correct the translation between point clouds to improve accuracy. Concretely,
we propose a novel global descriptor, Semantic Scan Context, which explores
semantic information to represent scenes more effectively. We also present a
two-step global semantic ICP to obtain the 3D pose (x, y, yaw) used to align
the point cloud to improve matching performance. Our experiments on the KITTI
dataset show that our approach outperforms the state-of-the-art methods with a
large margin. Our code is available at: https://github.com/lilin-hitcrt/SSC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIDV-2020: A Comprehensive Benchmark Dataset for Identity Document Analysis. (arXiv:2107.00396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bulatov_K/0/1/0/all/0/1">Konstantin Bulatov</a>, <a href="http://arxiv.org/find/cs/1/au:+Emelianova_E/0/1/0/all/0/1">Ekaterina Emelianova</a>, <a href="http://arxiv.org/find/cs/1/au:+Tropin_D/0/1/0/all/0/1">Daniil Tropin</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoryukina_N/0/1/0/all/0/1">Natalya Skoryukina</a>, <a href="http://arxiv.org/find/cs/1/au:+Chernyshova_Y/0/1/0/all/0/1">Yulia Chernyshova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheshkus_A/0/1/0/all/0/1">Alexander Sheshkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Usilin_S/0/1/0/all/0/1">Sergey Usilin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_Z/0/1/0/all/0/1">Zuheng Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Burie_J/0/1/0/all/0/1">Jean-Christophe Burie</a>, <a href="http://arxiv.org/find/cs/1/au:+Luqman_M/0/1/0/all/0/1">Muhammad Muzzamil Luqman</a>, <a href="http://arxiv.org/find/cs/1/au:+Arlazarov_V/0/1/0/all/0/1">Vladimir V. Arlazarov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00396">
                                    <div class="article-summary-box-inner">
                                        <span>Identity documents recognition is an important sub-field of document
analysis, which deals with tasks of robust document detection, type
identification, text fields recognition, as well as identity fraud prevention
and document authenticity validation given photos, scans, or video frames of an
identity document capture. Significant amount of research has been published on
this topic in recent years, however a chief difficulty for such research is
scarcity of datasets, due to the subject matter being protected by security
requirements. A few datasets of identity documents which are available lack
diversity of document types, capturing conditions, or variability of document
field values. In addition, the published datasets were typically designed only
for a subset of document recognition problems, not for a complex identity
document analysis. In this paper, we present a dataset MIDV-2020 which consists
of 1000 video clips, 2000 scanned images, and 1000 photos of 1000 unique mock
identity documents, each with unique text field values and unique artificially
generated faces, with rich annotation. For the presented benchmark dataset
baselines are provided for such tasks as document location and identification,
text fields recognition, and face detection. With 72409 annotated images in
total, to the date of publication the proposed dataset is the largest publicly
available identity documents dataset with variable artificially generated data,
and we believe that it will prove invaluable for advancement of the field of
document analysis and recognition. The dataset is available for download at
this ftp URL and this http URL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis. (arXiv:2107.00285v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Henglin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zitong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhaoz%3F_G/0/1/0/all/0/1">Guoying Zhaoz?</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00285">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new dataset for the emotional artificial intelligence
research: identity-free video dataset for Micro-Gesture Understanding and
Emotion analysis (iMiGUE). Different from existing public datasets, iMiGUE
focuses on nonverbal body gestures without using any identity information,
while the predominant researches of emotion analysis concern sensitive
biometric data, like face and speech. Most importantly, iMiGUE focuses on
micro-gestures, i.e., unintentional behaviors driven by inner feelings, which
are different from ordinary scope of gestures from other gesture datasets which
are mostly intentionally performed for illustrative purposes. Furthermore,
iMiGUE is designed to evaluate the ability of models to analyze the emotional
states by integrating information of recognized micro-gesture, rather than just
recognizing prototypes in the sequences separately (or isolatedly). This is
because the real need for emotion AI is to understand the emotional states
behind gestures in a holistic way. Moreover, to counter for the challenge of
imbalanced sample distribution of this dataset, an unsupervised learning method
is proposed to capture latent representations from the micro-gesture sequences
themselves. We systematically investigate representative methods on this
dataset, and comprehensive experimental results reveal several interesting
insights from the iMiGUE, e.g., micro-gesture-based analysis can promote
emotion understanding. We confirm that the new iMiGUE dataset could advance
studies of micro-gesture and emotion AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Graph Learning for Disease Prediction. (arXiv:2107.00206v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00206">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from the powerful expressive capability of graphs, graph-based
approaches have achieved impressive performance in various biomedical
applications. Most existing methods tend to define the adjacency matrix among
samples manually based on meta-features, and then obtain the node embeddings
for downstream tasks by Graph Representation Learning (GRL). However, it is not
easy for these approaches to generalize to unseen samples. Meanwhile, the
complex correlation between modalities is also ignored. As a result, these
factors inevitably yield the inadequacy of providing valid information about
the patient&#x27;s condition for a reliable diagnosis. In this paper, we propose an
end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.
To effectively exploit the rich information across multi-modality associated
with diseases, amodal-attentional multi-modal fusion is proposed to integrate
the features of each modality by leveraging the correlation and complementarity
between the modalities. Furthermore, instead of defining the adjacency matrix
manually as existing methods, the latent graph structure can be captured
through a novel way of adaptive graph learning. It could be jointly optimized
with the prediction model, thus revealing the intrinsic connections among
samples. Unlike the previous transductive methods, our model is also applicable
to the scenario of inductive learning for those unseen data. An extensive group
of experiments on two disease prediction problems is then carefully designed
and presented, demonstrating that MMGL obtains more favorable performances. In
addition, we also visualize and analyze the learned graph structure to provide
more reliable decision support for doctors in real medical applications and
inspiration for disease research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinGAN-Seg: Synthetic Training Data Generation for Medical Image Segmentation. (arXiv:2107.00471v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Salehi_P/0/1/0/all/0/1">Pegah Salehi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sheshkal_S/0/1/0/all/0/1">Sajad Amouei Sheshkal</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Hammer_H/0/1/0/all/0/1">Hugo L.Hammer</a>, <a href="http://arxiv.org/find/eess/1/au:+Parasa_S/0/1/0/all/0/1">Sravanthi Parasa</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00471">
                                    <div class="article-summary-box-inner">
                                        <span>Processing medical data to find abnormalities is a time-consuming and costly
task, requiring tremendous efforts from medical experts. Therefore, Ai has
become a popular tool for the automatic processing of medical data, acting as a
supportive tool for doctors. AI tools highly depend on data for training the
models. However, there are several constraints to access to large amounts of
medical data to train machine learning algorithms in the medical domain, e.g.,
due to privacy concerns and the costly, time-consuming medical data annotation
process. To address this, in this paper we present a novel synthetic data
generation pipeline called SinGAN-Seg to produce synthetic medical data with
the corresponding annotated ground truth masks. We show that these synthetic
data generation pipelines can be used as an alternative to bypass privacy
concerns and as an alternative way to produce artificial segmentation datasets
with corresponding ground truth masks to avoid the tedious medical data
annotation process. As a proof of concept, we used an open polyp segmentation
dataset. By training UNet++ using both the real polyp segmentation dataset and
the corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we
show that the synthetic data can achieve a very close performance to the real
data when the real segmentation datasets are large enough. In addition, we show
that synthetic data generated from the SinGAN-Seg pipeline improving the
performance of segmentation algorithms when the training dataset is very small.
Since our SinGAN-Seg pipeline is applicable for any medical dataset, this
pipeline can be used with any other segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Bottlenecks for Multimodal Fusion. (arXiv:2107.00135v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagrani_A/0/1/0/all/0/1">Arsha Nagrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnab_A/0/1/0/all/0/1">Anurag Arnab</a>, <a href="http://arxiv.org/find/cs/1/au:+Jansen_A/0/1/0/all/0/1">Aren Jansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00135">
                                    <div class="article-summary-box-inner">
                                        <span>Humans perceive the world by concurrently processing and fusing
high-dimensional inputs from multiple modalities such as vision and audio.
Machine perception models, in stark contrast, are typically modality-specific
and optimised for unimodal benchmarks, and hence late-stage fusion of final
representations or predictions from each modality (&#x60;late-fusion&#x27;) is still a
dominant paradigm for multimodal video classification. Instead, we introduce a
novel transformer based architecture that uses &#x60;fusion bottlenecks&#x27; for
modality fusion at multiple layers. Compared to traditional pairwise
self-attention, our model forces information between different modalities to
pass through a small number of bottleneck latents, requiring the model to
collate and condense the most relevant information in each modality and only
share what is necessary. We find that such a strategy improves fusion
performance, at the same time reducing computational cost. We conduct thorough
ablation studies, and achieve state-of-the-art results on multiple audio-visual
classification benchmarks including Audioset, Epic-Kitchens and VGGSound. All
code and models will be released.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks. (arXiv:2107.00415v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Pira_G/0/1/0/all/0/1">Giacomo Pira</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00415">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs), despite being energy-efficient when
implemented on neuromorphic hardware and coupled with event-based Dynamic
Vision Sensors (DVS), are vulnerable to security threats, such as adversarial
attacks, i.e., small perturbations added to the input for inducing a
misclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet
efficient adversarial attack methodologies targeted to perturb the event
sequences that compose the input of the SNNs. First, we show that noise filters
for DVS can be used as defense mechanisms against adversarial attacks.
Afterwards, we implement several attacks and test them in the presence of two
types of noise filters for DVS cameras. The experimental results show that the
filters can only partially defend the SNNs against our proposed DVS-Attacks.
Using the best settings for the noise filters, our proposed Mask Filter-Aware
Dash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset
and by more than 65% on the MNIST dataset, compared to the original clean
frames. The source code of all the proposed DVS-Attacks and noise filters is
released at https://github.com/albertomarchisio/DVS-Attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Knowledge Distillation: An Inheritance and Exploration Framework. (arXiv:2107.00181v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1">Jun Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Bing Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00181">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) is a popular technique to transfer knowledge from
a teacher model or ensemble to a student model. Its success is generally
attributed to the privileged information on similarities/consistency between
the class distributions or intermediate feature representations of the teacher
model and the student model. However, directly pushing the student model to
mimic the probabilities/features of the teacher model to a large extent limits
the student model in learning undiscovered knowledge/features. In this paper,
we propose a novel inheritance and exploration knowledge distillation framework
(IE-KD), in which a student model is split into two parts - inheritance and
exploration. The inheritance part is learned with a similarity loss to transfer
the existing learned knowledge from the teacher model to the student model,
while the exploration part is encouraged to learn representations different
from the inherited ones with a dis-similarity loss. Our IE-KD framework is
generic and can be easily combined with existing distillation or mutual
learning methods for training deep neural networks. Extensive experiments
demonstrate that these two parts can jointly push the student model to learn
more diversified and effective representations, and our IE-KD can be a general
technique to improve the student network to achieve SOTA performance.
Furthermore, by applying our IE-KD to the training of two networks, the
performance of both can be improved w.r.t. deep mutual learning. The code and
models of IE-KD will be make publicly available at
https://github.com/yellowtownhz/IE-KD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feasibility of Haralick&#x27;s Texture Features for the Classification of Chromogenic In-situ Hybridization Images. (arXiv:2107.00235v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pavlov_S/0/1/0/all/0/1">Stoyan Pavlov</a>, <a href="http://arxiv.org/find/eess/1/au:+Momcheva_G/0/1/0/all/0/1">Galina Momcheva</a>, <a href="http://arxiv.org/find/eess/1/au:+Burlakova_P/0/1/0/all/0/1">Pavlina Burlakova</a>, <a href="http://arxiv.org/find/eess/1/au:+Atanasov_S/0/1/0/all/0/1">Simeon Atanasov</a>, <a href="http://arxiv.org/find/eess/1/au:+Stoyanov_D/0/1/0/all/0/1">Dimo Stoyanov</a>, <a href="http://arxiv.org/find/eess/1/au:+Ivanov_M/0/1/0/all/0/1">Martin Ivanov</a>, <a href="http://arxiv.org/find/eess/1/au:+Tonchev_A/0/1/0/all/0/1">Anton Tonchev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00235">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a proof of concept for the usefulness of second-order
texture features for the qualitative analysis and classification of chromogenic
in-situ hybridization whole slide images in high-throughput imaging
experiments. The challenge is that currently, the gold standard for gene
expression grading in such images is expert assessment. The idea of the
research team is to use different approaches in the analysis of these images
that will be used for structural segmentation and functional analysis in gene
expression. The article presents such perspective idea to select a number of
textural features that are going to be used for classification. In our
experiment, natural grouping of image samples (tiles) depending on their local
texture properties was explored in an unsupervised classification procedure.
The features are reduced to two dimensions with fuzzy c-means clustering. The
overall conclusion of this experiment is that Haralick features are a viable
choice for classification and analysis of chromogenic in-situ hybridization
image data. The principal component analysis approach produced slightly more
&quot;understandable&quot; from an annotator&#x27;s point of view classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drone swarm patrolling with uneven coverage requirements. (arXiv:2107.00362v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piciarelli_C/0/1/0/all/0/1">Claudio Piciarelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Foresti_G/0/1/0/all/0/1">Gian Luca Foresti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00362">
                                    <div class="article-summary-box-inner">
                                        <span>Swarms of drones are being more and more used in many practical scenarios,
such as surveillance, environmental monitoring, search and rescue in
hardly-accessible areas, etc.. While a single drone can be guided by a human
operator, the deployment of a swarm of multiple drones requires proper
algorithms for automatic task-oriented control. In this paper, we focus on
visual coverage optimization with drone-mounted camera sensors. In particular,
we consider the specific case in which the coverage requirements are uneven,
meaning that different parts of the environment have different coverage
priorities. We model these coverage requirements with relevance maps and
propose a deep reinforcement learning algorithm to guide the swarm. The paper
first defines a proper learning model for a single drone, and then extends it
to the case of multiple drones both with greedy and cooperative strategies.
Experimental results show the performance of the proposed method, also compared
with a standard patrolling algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?. (arXiv:2107.00166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00166">
                                    <div class="article-summary-box-inner">
                                        <span>There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the &quot;winning ticket&quot; in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Model Drift Estimation with Batch Normalization Statistics for Dataset Shift Detection and Model Selection. (arXiv:2107.00191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wonju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_S/0/1/0/all/0/1">Seok-Yong Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jooeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Minje Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechil_K/0/1/0/all/0/1">Kirill Chechil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00191">
                                    <div class="article-summary-box-inner">
                                        <span>While many real-world data streams imply that they change frequently in a
nonstationary way, most of deep learning methods optimize neural networks on
training data, and this leads to severe performance degradation when dataset
shift happens. However, it is less possible to annotate or inspect newly
streamed data by humans, and thus it is desired to measure model drift at
inference time in an unsupervised manner. In this paper, we propose a novel
method of model drift estimation by exploiting statistics of batch
normalization layer on unlabeled test data. To remedy possible sampling error
of streamed input data, we adopt low-rank approximation to each
representational layer. We show the effectiveness of our method not only on
dataset shift detection but also on model selection when there are multiple
candidate models among model zoo or training trajectories in an unsupervised
way. We further demonstrate the consistency of our method by comparing model
drift scores between different network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaXpert: Adapting Neural Architecture for Growing Data. (arXiv:2107.00254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiaxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guanghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00254">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications, data often come in a growing manner, where the
data volume and the number of classes may increase dynamically. This will bring
a critical challenge for learning: given the increasing data volume or the
number of classes, one has to instantaneously adjust the neural model capacity
to obtain promising performance. Existing methods either ignore the growing
nature of data or seek to independently search an optimal architecture for a
given dataset, and thus are incapable of promptly adjusting the architectures
for the changed data. To address this, we present a neural architecture
adaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust
previous architectures on the growing data. Specifically, we introduce an
architecture adjuster to generate a suitable architecture for each data
snapshot, based on the previous architecture and the different extent between
current and previous data distributions. Furthermore, we propose an adaptation
condition to determine the necessity of adjustment, thereby avoiding
unnecessary and time-consuming adjustments. Extensive experiments on two growth
scenarios (increasing data volume and number of classes) demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Hierarchical Super-Resolution for Scientific Data Reduction and Visualization. (arXiv:2107.00462v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wurster_S/0/1/0/all/0/1">Skylar W. Wurster</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_H/0/1/0/all/0/1">Hanqi Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Peterka_T/0/1/0/all/0/1">Thomas Peterka</a>, <a href="http://arxiv.org/find/eess/1/au:+Raj_M/0/1/0/all/0/1">Mukund Raj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jiayi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00462">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for hierarchical super resolution (SR) using neural
networks on an octree data representation. We train a hierarchy of neural
networks, each capable of 2x upscaling in each spatial dimension between two
levels of detail, and use these networks in tandem to facilitate large scale
factor super resolution, scaling with the number of trained networks. We
utilize these networks in a hierarchical super resolution algorithm that
upscales multiresolution data to a uniform high resolution without introducing
seam artifacts on octree node boundaries. We evaluate application of this
algorithm in a data reduction framework by dynamically downscaling input data
to an octree-based data structure to represent the multiresolution data before
compressing for additional storage reduction. We demonstrate that our approach
avoids seam artifacts common to multiresolution data formats, and show how
neural network super resolution assisted data reduction can preserve global
features better than compressors alone at the same compression ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoliTO-IIT Submission to the EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition. (arXiv:2107.00337v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Plizzari_C/0/1/0/all/0/1">Chiara Plizzari</a>, <a href="http://arxiv.org/find/cs/1/au:+Planamente_M/0/1/0/all/0/1">Mirco Planamente</a>, <a href="http://arxiv.org/find/cs/1/au:+Alberti_E/0/1/0/all/0/1">Emanuele Alberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1">Barbara Caputo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00337">
                                    <div class="article-summary-box-inner">
                                        <span>In this report, we describe the technical details of our submission to the
EPIC-Kitchens-100 Unsupervised Domain Adaptation (UDA) Challenge in Action
Recognition. To tackle the domain-shift which exists under the UDA setting, we
first exploited a recent Domain Generalization (DG) technique, called Relative
Norm Alignment (RNA). It consists in designing a model able to generalize well
to any unseen domain, regardless of the possibility to access target data at
training time. Then, in a second phase, we extended the approach to work on
unlabelled target data, allowing the model to adapt to the target distribution
in an unsupervised fashion. For this purpose, we included in our framework
existing UDA algorithms, such as Temporal Attentive Adversarial Adaptation
Network (TA3N), jointly with new multi-stream consistency losses, namely
Temporal Hard Norm Alignment (T-HNA) and Min-Entropy Consistency (MEC). Our
submission (entry &#x27;plnet&#x27;) is visible on the leaderboard and it achieved the
1st position for &#x27;verb&#x27;, and the 3rd position for both &#x27;noun&#x27; and &#x27;action&#x27;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Task Adaptation for Cross-domain Few-shot Learning. (arXiv:2107.00358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei-Hong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xialei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1">Hakan Bilen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00358">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we look at the problem of cross-domain few-shot classification
that aims to learn a classifier from previously unseen classes and domains with
few labeled samples. We study several strategies including various adapter
topologies and operations in terms of their performance and efficiency that can
be easily attached to existing methods with different meta-training strategies
and adapt them for a given task during meta-test phase. We show that parametric
adapters attached to convolutional layers with residual connections performs
the best, and significantly improves the performance of the state-of-the-art
models in the Meta-Dataset benchmark with minor additional cost. Our code will
be available at https://github.com/VICO-UoE/URL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CBNetV2: A Composite Backbone Network Architecture for Object Detection. (arXiv:2107.00420v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1">Tingting Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaojie Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yudong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibing Ling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00420">
                                    <div class="article-summary-box-inner">
                                        <span>Modern top-performing object detectors depend heavily on backbone networks,
whose advances bring consistent performance gains through exploring more
effective network structures. However, designing or searching for a new
backbone and pre-training it on ImageNet may require a large number of
computational resources, making it costly to obtain better detection
performance. In this paper, we propose a novel backbone network, namely
CBNetV2, by constructing compositions of existing open-sourced pre-trained
backbones. In particular, CBNetV2 architecture groups multiple identical
backbones, which are connected through composite connections. We also propose a
better training strategy with the Assistant Supervision for CBNet-based
detectors. Without additional pre-training, CBNetV2 can be integrated into
mainstream detectors, including one-stage and two-stage detectors, as well as
anchor-based and anchor-free-based ones, and significantly improve their
performance by more than 3.0% AP over the baseline on COCO. Also, experiments
provide strong evidence showing that composite backbones are more efficient and
resource-friendly than pre-trained wider and deeper networks, including
manual-based and NAS-based, as well as CNN-based and Transformer-based ones.
Particularly, with single-model and single-scale testing, our HTC Dual-Swin-B
achieves 58.6% box AP and 51.1% mask AP on COCO test-dev, which is
significantly better than the state-of-the-art result (i.e., 57.7% box AP and
50.2% mask AP) achieved by a stronger baseline HTC++ with a larger backbone
Swin-L. Code will be released at https://github.com/VDIGPKU/CBNetV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with Transformer-based Stereoscopic Depth Perception. (arXiv:2107.00229v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yonghao Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaoshuo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yee_C/0/1/0/all/0/1">Chi Hang Yee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_C/0/1/0/all/0/1">Chi Fai Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_R/0/1/0/all/0/1">Russell H. Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00229">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing the scene of robotic surgery from the stereo endoscopic video
is an important and promising topic in surgical data science, which potentially
supports many applications such as surgical visual perception, robotic surgery
education and intra-operative context awareness. However, current methods are
mostly restricted to reconstructing static anatomy assuming no tissue
deformation, tool occlusion and de-occlusion, and camera movement. However,
these assumptions are not always satisfied in minimal invasive robotic
surgeries. In this work, we present an efficient reconstruction pipeline for
highly dynamic surgical scenes that runs at 28 fps. Specifically, we design a
transformer-based stereoscopic depth perception for efficient depth estimation
and a light-weight tool segmentor to handle tool occlusion. After that, a
dynamic reconstruction algorithm which can estimate the tissue deformation and
camera movement, and aggregate the information over time is proposed for
surgical scene reconstruction. We evaluate the proposed pipeline on two
datasets, the public Hamlyn Centre Endoscopic Video Dataset and our in-house
DaVinci robotic surgery dataset. The results demonstrate that our method can
recover the scene obstructed by the surgical tool and handle the movement of
camera in realistic surgical scenarios effectively at real-time speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthonormal Product Quantization Network for Scalable Face Image Retrieval. (arXiv:2107.00327v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_X/0/1/0/all/0/1">Xuefei Zhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hong Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00327">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep hashing with Hamming distance metric has drawn increasing
attention for face image retrieval tasks. However, its counterpart deep
quantization methods, which learn binary code representations with
dictionary-related distance metrics, have seldom been explored for the task.
This paper makes the first attempt to integrate product quantization into an
end-to-end deep learning framework for face image retrieval. Unlike prior deep
quantization methods where the codewords for quantization are learned from
data, we propose a novel scheme using predefined orthonormal vectors as
codewords, which aims to enhance the quantization informativeness and reduce
the codewords&#x27; redundancy. To make the most of the discriminative information,
we design a tailored loss function that maximizes the identity discriminability
in each quantization subspace for both the quantized and the original features.
Furthermore, an entropy-based regularization term is imposed to reduce the
quantization error. We conduct experiments on three commonly-used datasets
under the settings of both single-domain and cross-domain retrieval. It shows
that the proposed method outperforms all the compared deep hashing/quantization
methods under both settings with significant superiority. The proposed
codewords scheme consistently improves both regular model performance and model
generalization ability, verifying the importance of codewords&#x27; distribution for
the quantization quality. Besides, our model&#x27;s better generalization ability
than deep hashing models indicates that it is more suitable for scalable face
image retrieval tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmenting 3D Hybrid Scenes via Zero-Shot Learning. (arXiv:2107.00430v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhanyi Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00430">
                                    <div class="article-summary-box-inner">
                                        <span>This work is to tackle the problem of point cloud semantic segmentation for
3D hybrid scenes under the framework of zero-shot learning. Here by hybrid, we
mean the scene consists of both seen-class and unseen-class 3D objects, a more
general and realistic setting in application. To our knowledge, this problem
has not been explored in the literature. To this end, we propose a network to
synthesize point features for various classes of objects by leveraging the
semantic features of both seen and unseen object classes, called PFNet. The
proposed PFNet employs a GAN architecture to synthesize point features, where
the semantic relationship between seen-class and unseen-class features is
consolidated by adapting a new semantic regularizer, and the synthesized
features are used to train a classifier for predicting the labels of the
testing 3D scene points. Besides we also introduce two benchmarks for
algorithmic evaluation by re-organizing the public S3DIS and ScanNet datasets
under six different data splits. Experimental results on the two benchmarks
validate our proposed method, and we hope our introduced two benchmarks and
methodology could be of help for more research on this new direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple Training Strategies and Model Scaling for Object Detection. (arXiv:2107.00057v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xianzhi Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1">Barret Zoph</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_W/0/1/0/all/0/1">Wei-Chih Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00057">
                                    <div class="article-summary-box-inner">
                                        <span>The speed-accuracy Pareto curve of object detection systems have advanced
through a combination of better model architectures, training and inference
methods. In this paper, we methodically evaluate a variety of these techniques
to understand where most of the improvements in modern detection systems come
from. We benchmark these improvements on the vanilla ResNet-FPN backbone with
RetinaNet and RCNN detectors. The vanilla detectors are improved by 7.7% in
accuracy while being 30% faster in speed. We further provide simple scaling
strategies to generate family of models that form two Pareto curves, named
RetinaNet-RS and Cascade RCNN-RS. These simple rescaled detectors explore the
speed-accuracy trade-off between the one-stage RetinaNet detectors and
two-stage RCNN detectors. Our largest Cascade RCNN-RS models achieve 52.9% AP
with a ResNet152-FPN backbone and 53.6% with a SpineNet143L backbone. Finally,
we show the ResNet architecture, with three minor architectural changes,
outperforms EfficientNet as the backbone for object detection and instance
segmentation systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_L/0/1/0/all/0/1">Lu Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00197">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to train a strong classifier using limited
labeled examples. Many existing works take the meta-learning approach, sampling
few-shot tasks in turn and optimizing the few-shot learner&#x27;s performance on
classifying the query examples. In this paper, we point out two potential
weaknesses of this approach. First, the sampled query examples may not provide
sufficient supervision for the few-shot learner. Second, the effectiveness of
meta-learning diminishes sharply with increasing shots (i.e., the number of
training examples per class). To resolve these issues, we propose a novel
objective to directly train the few-shot learner to perform like a strong
classifier. Concretely, we associate each sampled few-shot task with a strong
classifier, which is learned with ample labeled examples. The strong classifier
has a better generalization ability and we use it to supervise the few-shot
learner. We present an efficient way to construct the strong classifier, making
our proposed objective an easily plug-and-play term to existing meta-learning
based FSL methods. We validate our approach in combinations with many
representative meta-learning methods. On several benchmark datasets including
miniImageNet and tiredImageNet, our approach leads to a notable improvement
across a variety of tasks. More importantly, with our approach, meta-learning
based FSL methods can consistently outperform non-meta-learning based ones,
even in a many-shot setting, greatly strengthening their applicability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circuit Complexity of Visual Search. (arXiv:2107.00223v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uchizawa_K/0/1/0/all/0/1">Kei Uchizawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_H/0/1/0/all/0/1">Haruki Abe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00223">
                                    <div class="article-summary-box-inner">
                                        <span>We study computational hardness of feature and conjunction search through the
lens of circuit complexity. Let $x &#x3D; (x_1, ... , x_n)$ (resp., $y &#x3D; (y_1, ... ,
y_n)$) be Boolean variables each of which takes the value one if and only if a
neuron at place $i$ detects a feature (resp., another feature). We then simply
formulate the feature and conjunction search as Boolean functions ${\rm
FTR}_n(x) &#x3D; \bigvee_{i&#x3D;1}^n x_i$ and ${\rm CONJ}_n(x, y) &#x3D; \bigvee_{i&#x3D;1}^n x_i
\wedge y_i$, respectively. We employ a threshold circuit or a discretized
circuit (such as a sigmoid circuit or a ReLU circuit with discretization) as
our models of neural networks, and consider the following four computational
resources: [i] the number of neurons (size), [ii] the number of levels (depth),
[iii] the number of active neurons outputting non-zero values (energy), and
[iv] synaptic weight resolution (weight).

We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy
$e$ and weight $w$ satisfies $\log rk(M_C) \le ed (\log s + \log w + \log n)$,
where $rk(M_C)$ is the rank of the communication matrix $M_C$ of a
$2n$-variable Boolean function that $C$ computes. Since ${\rm CONJ}_n$ has rank
$2^n$, we have $n \le ed (\log s + \log w + \log n)$. Thus, an exponential
lower bound on the size of even sublinear-depth threshold circuits exists if
the energy and weight are sufficiently small. Since ${\rm FTR}_n$ is computable
independently of $n$, our result suggests that computational capacity for the
feature and conjunction search are different. We also show that the inequality
is tight up to a constant factor if $ed &#x3D; o(n/ \log n)$. We next show that a
similar inequality holds for any discretized circuit. Thus, if we regard the
number of gates outputting non-zero values as a measure for sparse activity,
our results suggest that larger depth helps neural networks to acquire sparse
activity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Egocentric Image Captioning for Privacy-Preserved Passive Dietary Intake Monitoring. (arXiv:2107.00372v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_F/0/1/0/all/0/1">Frank P.-W. Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xiao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jobarteh_M/0/1/0/all/0/1">Modou L. Jobarteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1">Wenyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Baranowski_T/0/1/0/all/0/1">Tom Baranowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_Asiedu_M/0/1/0/all/0/1">Matilda Steiner-Asiedu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_A/0/1/0/all/0/1">Alex K. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+McCrory_M/0/1/0/all/0/1">Megan A McCrory</a>, <a href="http://arxiv.org/find/cs/1/au:+Sazonov_E/0/1/0/all/0/1">Edward Sazonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Frost_G/0/1/0/all/0/1">Gary Frost</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_B/0/1/0/all/0/1">Benny Lo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00372">
                                    <div class="article-summary-box-inner">
                                        <span>Camera-based passive dietary intake monitoring is able to continuously
capture the eating episodes of a subject, recording rich visual information,
such as the type and volume of food being consumed, as well as the eating
behaviours of the subject. However, there currently is no method that is able
to incorporate these visual clues and provide a comprehensive context of
dietary intake from passive recording (e.g., is the subject sharing food with
others, what food the subject is eating, and how much food is left in the
bowl). On the other hand, privacy is a major concern while egocentric wearable
cameras are used for capturing. In this paper, we propose a privacy-preserved
secure solution (i.e., egocentric image captioning) for dietary assessment with
passive monitoring, which unifies food recognition, volume estimation, and
scene understanding. By converting images into rich text descriptions,
nutritionists can assess individual dietary intake based on the captions
instead of the original images, reducing the risk of privacy leakage from
images. To this end, an egocentric dietary image captioning dataset has been
built, which consists of in-the-wild images captured by head-worn and
chest-worn cameras in field studies in Ghana. A novel transformer-based
architecture is designed to caption egocentric dietary images. Comprehensive
experiments have been conducted to evaluate the effectiveness and to justify
the design of the proposed architecture for egocentric dietary image
captioning. To the best of our knowledge, this is the first work that applies
image captioning to dietary intake assessment in real life settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Graph-Based Deep Learning for Computational Histopathology. (arXiv:2107.00272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmedt_Aristizabal_D/0/1/0/all/0/1">David Ahmedt-Aristizabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Armin_M/0/1/0/all/0/1">Mohammad Ali Armin</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00272">
                                    <div class="article-summary-box-inner">
                                        <span>With the remarkable success of representation learning for prediction
problems, we have witnessed a rapid expansion of the use of machine learning
and deep learning for the analysis of digital pathology and biopsy image
patches. However, traditional learning over patch-wise features using
convolutional neural networks limits the model when attempting to capture
global contextual information. The phenotypical and topological distribution of
constituent histological entities play a critical role in tissue diagnosis. As
such, graph data representations and deep learning have attracted significant
attention for encoding tissue representations, and capturing intra- and inter-
entity level interactions. In this review, we provide a conceptual grounding of
graph-based deep learning and discuss its current success for tumor
localization and classification, tumor invasion and staging, image retrieval,
and survival prediction. We provide an overview of these methods in a
systematic manner organized by the graph representation of the input image
including whole slide images and tissue microarrays. We also outline the
limitations of existing techniques, and suggest potential future advances in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLDA: Contrastive Learning for Semi-Supervised Domain Adaptation. (arXiv:2107.00085v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ankit Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00085">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) aims to align the labeled source
distribution with the unlabeled target distribution to obtain domain invariant
predictive models. However, the application of well-known UDA approaches does
not generalize well in Semi-Supervised Domain Adaptation (SSDA) scenarios where
few labeled samples from the target domain are available. In this paper, we
propose a simple Contrastive Learning framework for semi-supervised Domain
Adaptation (CLDA) that attempts to bridge the intra-domain gap between the
labeled and unlabeled target distributions and inter-domain gap between source
and unlabeled target distribution in SSDA. We suggest employing class-wise
contrastive learning to reduce the inter-domain gap and instance-level
contrastive alignment between the original (input image) and strongly augmented
unlabeled target images to minimize the intra-domain discrepancy. We have shown
empirically that both of these modules complement each other to achieve
superior performance. Experiments on three well-known domain adaptation
benchmark datasets namely DomainNet, Office-Home, and Office31 demonstrate the
effectiveness of our approach. CLDA achieves state-of-the-art results on all
the above datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction of Key-frames of Endoscopic Videos by using Depth Information. (arXiv:2107.00005v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sasmal_P/0/1/0/all/0/1">Pradipta Sasmal</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Avinash Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhuyan_M/0/1/0/all/0/1">M.K. Bhuyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwahori_Y/0/1/0/all/0/1">Yuji Iwahori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00005">
                                    <div class="article-summary-box-inner">
                                        <span>A deep learning-based monocular depth estimation (MDE) technique is proposed
for selection of most informative frames (key frames) of an endoscopic video.
In most of the cases, ground truth depth maps of polyps are not readily
available and that is why the transfer learning approach is adopted in our
method. An endoscopic modalities generally capture thousands of frames. In this
scenario, it is quite important to discard low-quality and clinically
irrelevant frames of an endoscopic video while the most informative frames
should be retained for clinical diagnosis. In this view, a key-frame selection
strategy is proposed by utilizing the depth information of polyps. In our
method, image moment, edge magnitude, and key-points are considered for
adaptively selecting the key frames. One important application of our proposed
method could be the 3D reconstruction of polyps with the help of extracted key
frames. Also, polyps are localized with the help of extracted depth maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Detection and Diagnosis of Diabetic Retinopathy: A Comprehensive Survey. (arXiv:2107.00115v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lakshminarayanan_V/0/1/0/all/0/1">Vasudevan Lakshminarayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kherdfallah_H/0/1/0/all/0/1">Hoda Kherdfallah</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarkar_A/0/1/0/all/0/1">Arya Sarkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Balaji_J/0/1/0/all/0/1">J. Jothi Balaji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00115">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetic Retinopathy (DR) is a leading cause of vision loss in the world,. In
the past few Diabetic Retinopathy (DR) is a leading cause of vision loss in the
world. In the past few years, Artificial Intelligence (AI) based approaches
have been used to detect and grade DR. Early detection enables appropriate
treatment and thus prevents vision loss, Both fundus and optical coherence
tomography (OCT) images are used to image the retina. With deep
learning/machine learning apprroaches it is possible to extract features from
the images and detect the presence of DR. Multiple strategies are implemented
to detect and grade the presence of DR using classification, segmentation, and
hybrid techniques. This review covers the literature dealing with AI approaches
to DR that have been published in the open literature over a five year span
(2016-2021). In addition a comprehensive list of available DR datasets is
reported. Both the PICO (P-patient, I-intervention, C-control O-outcome) and
Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA)2009
search strategies were employed. We summarize a total of 114 published articles
which conformed to the scope of the review. In addition a list of 43 major
datasets is presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep auxiliary learning for visual localization using colorization task. (arXiv:2107.00222v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_M/0/1/0/all/0/1">Mi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Q/0/1/0/all/0/1">Qiong Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Hao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xiahua Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00222">
                                    <div class="article-summary-box-inner">
                                        <span>Visual localization is one of the most important components for robotics and
autonomous driving. Recently, inspiring results have been shown with CNN-based
methods which provide a direct formulation to end-to-end regress 6-DoF absolute
pose. Additional information like geometric or semantic constraints is
generally introduced to improve performance. Especially, the latter can
aggregate high-level semantic information into localization task, but it
usually requires enormous manual annotations. To this end, we propose a novel
auxiliary learning strategy for camera localization by introducing
scene-specific high-level semantics from self-supervised representation
learning task. Viewed as a powerful proxy task, image colorization task is
chosen as complementary task that outputs pixel-wise color version of grayscale
photograph without extra annotations. In our work, feature representations from
colorization network are embedded into localization network by design to
produce discriminative features for pose regression. Meanwhile an attention
mechanism is introduced for the benefit of localization performance. Extensive
experiments show that our model significantly improve localization accuracy
over state-of-the-arts on both indoor and outdoor datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-class Steel Detector Using Patch GAN Discriminator for Visualising Anomalous Feature Map. (arXiv:2107.00143v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yasuno_T/0/1/0/all/0/1">Takato Yasuno</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_J/0/1/0/all/0/1">Junichiro Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukami_S/0/1/0/all/0/1">Sakura Fukami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00143">
                                    <div class="article-summary-box-inner">
                                        <span>For steel product manufacturing in indoor factories, steel defect detection
is important for quality control. For example, a steel sheet is extremely
delicate, and must be accurately inspected. However, to maintain the painted
steel parts of the infrastructure around a severe outdoor environment,
corrosion detection is critical for predictive maintenance. In this paper, we
propose a general-purpose application for steel anomaly detection that consists
of the following four components. The first, a learner, is a unit image
classification network to determine whether the region of interest or
background has been recognised, after dividing the original large sized image
into 256 square unit images. The second, an extractor, is a discriminator
feature encoder based on a pre-trained steel generator with a patch generative
adversarial network discriminator(GAN). The third, an anomaly detector, is a
one-class support vector machine(SVM) to predict the anomaly score using the
discriminator feature. The fourth, an indicator, is an anomalous probability
map used to visually explain the anomalous features. Furthermore, we
demonstrated our method through the inspection of steel sheet defects with
13,774 unit images using high-speed cameras, and painted steel corrosion with
19,766 unit images based on an eye inspection of the photographs. Finally, we
visualise anomalous feature maps of steel using a strip and painted steel
inspection dataset</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MASS: Multi-Attentional Semantic Segmentation of LiDAR Data for Dense Top-View Understanding. (arXiv:2107.00346v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_J/0/1/0/all/0/1">Juncong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roitberg_A/0/1/0/all/0/1">Alina Roitberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bieder_F/0/1/0/all/0/1">Frank Bieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidenreich_P/0/1/0/all/0/1">Philipp Heidenreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00346">
                                    <div class="article-summary-box-inner">
                                        <span>At the heart of all automated driving systems is the ability to sense the
surroundings, e.g., through semantic segmentation of LiDAR sequences, which
experienced a remarkable progress due to the release of large datasets such as
SemanticKITTI and nuScenes-LidarSeg. While most previous works focus on sparse
segmentation of the LiDAR input, dense output masks provide self-driving cars
with almost complete environment information. In this paper, we introduce MASS
- a Multi-Attentional Semantic Segmentation model specifically built for dense
top-view understanding of the driving scenes. Our framework operates on pillar-
and occupancy features and comprises three attention-based building blocks: (1)
a keypoint-driven graph attention, (2) an LSTM-based attention computed from a
vector embedding of the spatial input, and (3) a pillar-based attention,
resulting in a dense 360-degree segmentation mask. With extensive experiments
on both, SemanticKITTI and nuScenes-LidarSeg, we quantitatively demonstrate the
effectiveness of our model, outperforming the state of the art by 19.0% on
SemanticKITTI and reaching 32.7% in mIoU on nuScenes-LidarSeg, where MASS is
the first work addressing the dense segmentation task. Furthermore, our
multi-attention model is shown to be very effective for 3D object detection
validated on the KITTI-3D dataset, showcasing its high generalizability to
other tasks related to 3D vision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Synthetic Training Data for Deep Learning-Based UAV Trajectory Prediction. (arXiv:2107.00422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">Stefan Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1">Ronny Hug</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1">Wolfgang H&#xfc;bner</a>, <a href="http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1">Michael Arens</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan T. Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00422">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based models, such as recurrent neural networks (RNNs), have
been applied to various sequence learning tasks with great success. Following
this, these models are increasingly replacing classic approaches in object
tracking applications for motion prediction. On the one hand, these models can
capture complex object dynamics with less modeling required, but on the other
hand, they depend on a large amount of training data for parameter tuning.
Towards this end, we present an approach for generating synthetic trajectory
data of unmanned-aerial-vehicles (UAVs) in image space. Since UAVs, or rather
quadrotors are dynamical systems, they can not follow arbitrary trajectories.
With the prerequisite that UAV trajectories fulfill a smoothness criterion
corresponding to a minimal change of higher-order motion, methods for planning
aggressive quadrotors flights can be utilized to generate optimal trajectories
through a sequence of 3D waypoints. By projecting these maneuver trajectories,
which are suitable for controlling quadrotors, to image space, a versatile
trajectory data set is realized. To demonstrate the applicability of the
synthetic trajectory data, we show that an RNN-based prediction model solely
trained on the generated data can outperform classic reference models on a
real-world UAV tracking dataset. The evaluation is done on the publicly
available ANTI-UAV dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedding-based Recommender System for Job to Candidate Matching on Scale. (arXiv:2107.00221v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingya Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigdel_M/0/1/0/all/0/1">Madhav Sigdel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_P/0/1/0/all/0/1">Phuong Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengshu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Korayem_M/0/1/0/all/0/1">Mohammed Korayem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00221">
                                    <div class="article-summary-box-inner">
                                        <span>The online recruitment matching system has been the core technology and
service platform in CareerBuilder. One of the major challenges in an online
recruitment scenario is to provide good matches between job posts and
candidates using a recommender system on the scale. In this paper, we discussed
the techniques for applying an embedding-based recommender system for the large
scale of job to candidates matching. To learn the comprehensive and effective
embedding for job posts and candidates, we have constructed a fused-embedding
via different levels of representation learning from raw text, semantic
entities and location information. The clusters of fused-embedding of job and
candidates are then used to build and train the Faiss index that supports
runtime approximate nearest neighbor search for candidate retrieval. After the
first stage of candidate retrieval, a second stage reranking model that
utilizes other contextual information was used to generate the final matching
result. Both offline and online evaluation results indicate a significant
improvement of our proposed two-staged embedding-based system in terms of
click-through rate (CTR), quality and normalized discounted accumulated gain
(nDCG), compared to those obtained from our baseline system. We further
described the deployment of the system that supports the million-scale job and
candidate matching process at CareerBuilder. The overall improvement of our job
to candidate matching system has demonstrated its feasibility and scalability
at a major online recruitment site.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proof of Reference(PoR): A unified informetrics based consensus mechanism. (arXiv:2107.00214v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khurana_P/0/1/0/all/0/1">Parul Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesan_G/0/1/0/all/0/1">Geetha Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gulshan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1">Kiran Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00214">
                                    <div class="article-summary-box-inner">
                                        <span>Bibliometrics is useful to analyze the research impact for measuring the
research quality. Different bibliographic databases like Scopus, Web of
Science, Google Scholar etc. are accessed for evaluating the trend of
publications and citations from time to time. Some of these databases are free
and some are subscription based. Its always debatable that which bibliographic
database is better and in what terms. To provide an optimal solution to
availability of multiple bibliographic databases, we have implemented a single
authentic database named as &#x60;&#x60;conflate&#x27;&#x27; which can be used for fetching
publication and citation trend of an author. To further strengthen the
generated database and to provide the transparent system to the stakeholders, a
consensus mechanism &#x60;&#x60;proof of reference (PoR)&#x27;&#x27; is proposed. Due to three
consent based checks implemented in PoR, we feel that it could be considered as
a authentic and honest citation data source for the calculation of unified
informetrics for an author.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SearchGCN: Powering Embedding Retrieval by Graph Convolution Networks for E-Commerce Search. (arXiv:2107.00525v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xinlin Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Songlin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Sulong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wen-Yun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00525">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolution networks (GCN), which recently becomes new state-of-the-art
method for graph node classification, recommendation and other applications,
has not been successfully applied to industrial-scale search engine yet. In
this proposal, we introduce our approach, namely SearchGCN, for embedding-based
candidate retrieval in one of the largest e-commerce search engine in the
world. Empirical studies demonstrate that SearchGCN learns better embedding
representations than existing methods, especially for long tail queries and
items. Thus, SearchGCN has been deployed into JD.com&#x27;s search production since
July 2020.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphHINGE: Learning Interaction Models of Structured Neighborhood on Heterogeneous Information Network. (arXiv:2011.12683v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiarui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1">Kounianhua Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jiarui Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuchen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12683">
                                    <div class="article-summary-box-inner">
                                        <span>Heterogeneous information network (HIN) has been widely used to characterize
entities of various types and their complex relations. Recent attempts either
rely on explicit path reachability to leverage path-based semantic relatedness
or graph neighborhood to learn heterogeneous network representations before
predictions. These weakly coupled manners overlook the rich interactions among
neighbor nodes, which introduces an early summarization issue. In this paper,
we propose GraphHINGE (Heterogeneous INteract and aggreGatE), which captures
and aggregates the interactive patterns between each pair of nodes through
their structured neighborhoods. Specifically, we first introduce
Neighborhood-based Interaction (NI) module to model the interactive patterns
under the same metapaths, and then extend it to Cross Neighborhood-based
Interaction (CNI) module to deal with different metapaths. Next, in order to
address the complexity issue on large-scale networks, we formulate the
interaction modules via a convolutional framework and learn the parameters
efficiently with fast Fourier transform. Furthermore, we design a novel
neighborhood-based selection (NS) mechanism, a sampling strategy, to filter
high-order neighborhood information based on their low-order performance. The
extensive experiments on six different types of heterogeneous graphs
demonstrate the performance gains by comparing with state-of-the-arts in both
click-through rate prediction and top-N recommendation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval. (arXiv:2106.11251v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11251">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-relevance feedback mechanisms, from Rocchio to the relevance models,
have shown the usefulness of expanding and reweighting the users&#x27; initial
queries using information occurring in an initial set of retrieved documents,
known as the pseudo-relevant set. Recently, dense retrieval -- through the use
of neural contextual language models such as BERT for analysing the documents&#x27;
and queries&#x27; contents and computing their relevance scores -- has shown a
promising performance on several information retrieval tasks still relying on
the traditional inverted index for identifying documents relevant to a query.
Two different dense retrieval families have emerged: the use of single embedded
representations for each passage and query (e.g. using BERT&#x27;s [CLS] token), or
via multiple representations (e.g. using an embedding for each token of the
query and document). In this work, we conduct the first study into the
potential for multiple representation dense retrieval to be enhanced using
pseudo-relevance feedback. In particular, based on the pseudo-relevant set of
documents identified using a first-pass dense retrieval, we extract
representative feedback embeddings (using KMeans clustering) -- while ensuring
that these embeddings discriminate among passages (based on IDF) -- which are
then added to the query representation. These additional feedback embeddings
are shown to both enhance the effectiveness of a reranking as well as an
additional dense retrieval operation. Indeed, experiments on the MSMARCO
passage ranking dataset show that MAP can be improved by upto 26% on the TREC
2019 query set and 10% on the TREC 2020 query set by the application of our
proposed ColBERT-PRF method on a ColBERT dense retrieval approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Search Engine for Scientific Publications: a Cybersecurity Case Study. (arXiv:2107.00082v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oliveira_N/0/1/0/all/0/1">Nuno Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sousa_N/0/1/0/all/0/1">Norberto Sousa</a>, <a href="http://arxiv.org/find/cs/1/au:+Praca_I/0/1/0/all/0/1">Isabel Pra&#xe7;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00082">
                                    <div class="article-summary-box-inner">
                                        <span>Cybersecurity is a very challenging topic of research nowadays, as
digitalization increases the interaction of people, software and services on
the Internet by means of technology devices and networks connected to it. The
field is broad and has a lot of unexplored ground under numerous disciplines
such as management, psychology, and data science. Its large disciplinary
spectrum and many significant research topics generate a considerable amount of
information, making it hard for us to find what we are looking for when
researching a particular subject. This work proposes a new search engine for
scientific publications which combines both information retrieval and reading
comprehension algorithms to extract answers from a collection of
domain-specific documents. The proposed solution although being applied to the
context of cybersecurity exhibited great generalization capabilities and can be
easily adapted to perform under other distinct knowledge domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Use of Bandit Algorithms in Intelligent Interactive Recommender Systems. (arXiv:2107.00161v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00161">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s business marketplace, many high-tech Internet enterprises
constantly explore innovative ways to provide optimal online user experiences
for gaining competitive advantages. The great needs of developing intelligent
interactive recommendation systems are indicated, which could sequentially
suggest users the most proper items by accurately predicting their preferences,
while receiving the up-to-date feedback to refine the recommendation results,
continuously. Multi-armed bandit algorithms, which have been widely applied
into various online systems, are quite capable of delivering such efficient
recommendation services. However, few existing bandit models are able to adapt
to new changes introduced by the modern recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1">Ivan Evtimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1">Ian Covert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1">Tadayoshi Kohno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06654">
                                    <div class="article-summary-box-inner">
                                        <span>When data is publicly released for human consumption, it is unclear how to
prevent its unauthorized usage for machine learning purposes. Successful model
training may be preventable with carefully designed dataset modifications, and
we present a proof-of-concept approach for the image classification setting. We
propose methods based on the notion of adversarial shortcuts, which encourage
models to rely on non-robust signals rather than semantic features, and our
experiments demonstrate that these measures successfully prevent deep learning
models from achieving high accuracy on real, unmodified data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks. (arXiv:2106.12900v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xuelong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12900">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning model can quickly adapt to new tasks using few-shot labeled
data. However, despite achieving good generalization on few-shot classification
tasks, it is still challenging to improve the adversarial robustness of the
meta-learning model in few-shot learning. Although adversarial training (AT)
methods such as Adversarial Query (AQ) can improve the adversarially robust
performance of meta-learning models, AT is still computationally expensive
training. On the other hand, meta-learning models trained with AT will drop
significant accuracy on the original clean images. This paper proposed a
meta-learning method on the adversarially robust neural network called
Long-term Cross Adversarial Training (LCAT). LCAT will update meta-learning
model parameters cross along the natural and adversarial sample distribution
direction with long-term to improve both adversarial and clean few-shot
classification accuracy. Due to cross-adversarial training, LCAT only needs
half of the adversarial training epoch than AQ, resulting in a low adversarial
training computation. Experiment results show that LCAT achieves superior
performance both on the clean and adversarial few-shot classification accuracy
than SOTA adversarial training methods for meta-learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Lingual Adaptation for Type Inference. (arXiv:2107.00157v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiaofei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhengzi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00157">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based techniques have been widely applied to the program
analysis tasks, in fields such as type inference, fault localization, and code
summarization. Hitherto deep learning-based software engineering systems rely
thoroughly on supervised learning approaches, which require laborious manual
effort to collect and label a prohibitively large amount of data. However, most
Turing-complete imperative languages share similar control- and data-flow
structures, which make it possible to transfer knowledge learned from one
language to another. In this paper, we propose cross-lingual adaptation of
program analysis, which allows us to leverage prior knowledge learned from the
labeled dataset of one language and transfer it to the others. Specifically, we
implemented a cross-lingual adaptation framework, PLATO, to transfer a deep
learning-based type inference procedure across weakly typed languages, e.g.,
Python to JavaScript and vice versa. PLATO incorporates a novel joint graph
kernelized attention based on abstract syntax tree and control flow graph, and
applies anchor word augmentation across different languages. Besides, by
leveraging data from strongly typed languages, PLATO improves the perplexity of
the backbone cross-programming-language model and the performance of downstream
cross-lingual transfer for type inference. Experimental results illustrate that
our framework significantly improves the transferability over the baseline
method by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multimodal VAEs through Mutual Supervision. (arXiv:2106.12570v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joy_T/0/1/0/all/0/1">Tom Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuge Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmon_S/0/1/0/all/0/1">Sebastian M. Schmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1">N. Siddharth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12570">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal VAEs seek to model the joint distribution over heterogeneous data
(e.g.\ vision, language), whilst also capturing a shared representation across
such modalities. Prior work has typically combined information from the
modalities by reconciling idiosyncratic representations directly in the
recognition model through explicit products, mixtures, or other such
factorisations. Here we introduce a novel alternative, the MEME, that avoids
such explicit combinations by repurposing semi-supervised VAEs to combine
information between modalities implicitly through mutual supervision. This
formulation naturally allows learning from partially-observed data where some
modalities can be entirely missing -- something that most existing approaches
either cannot handle, or do so to a limited extent. We demonstrate that MEME
outperforms baselines on standard metrics across both partial and complete
observation schemes on the MNIST-SVHN (image-image) and CUB (image-text)
datasets. We also contrast the quality of the representations learnt by mutual
supervision against standard approaches and observe interesting trends in its
ability to capture relatedness between data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fea2Fea: Exploring Structural Feature Correlations via Graph Neural Networks. (arXiv:2106.13061v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiaqing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1">Rex Ying</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13061">
                                    <div class="article-summary-box-inner">
                                        <span>Structural features are important features in graph datasets. However,
although there are some correlation analysis of features based on covariance,
there is no relevant research on exploring structural feature correlation on
graphs with graph neural network based models. In this paper, we introduce
graph feature to feature (Fea2Fea) prediction pipelines in a low dimensional
space to explore some preliminary results on structural feature correlation,
which is based on graph neural network. The results show that there exists high
correlation between some of the structural features. A redundant feature
combination with initial node features, which is filtered by graph neural
network has improved its classification accuracy in some graph datasets. We
compare the difference between concatenation methods on connecting embeddings
between features and show that the simplest is the best. We generalize on the
synthetic geometric graphs and certify the results on prediction difficulty
between two structural features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning. (arXiv:2106.11562v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Beomyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">Youngjoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11562">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a class-incremental semantic segmentation (CISS) problem. While
some recently proposed algorithms utilized variants of knowledge distillation
(KD) technique to tackle the problem, they only partially addressed the key
additional challenges in CISS that causes the catastrophic forgetting; i.e.,
the semantic drift of the background class and multi-label prediction issue. To
better address these challenges, we propose a new method, dubbed as SSUL-M
(Semantic Segmentation with Unknown Label with Memory), by carefully combining
several techniques tailored for semantic segmentation. More specifically, we
make three main contributions; (1) modeling unknown class within the background
class to help learning future classes (help plasticity), (2) freezing backbone
network and past classifiers with binary cross-entropy loss and pseudo-labeling
to overcome catastrophic forgetting (help stability), and (3) utilizing tiny
exemplar memory for the first time in CISS to improve both plasticity and
stability. As a result, we show our method achieves significantly better
performance than the recent state-of-the-art baselines on the standard
benchmark datasets. Furthermore, we justify our contributions with thorough and
extensive ablation analyses and discuss different natures of the CISS problem
compared to the standard class-incremental learning for classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSNoise: An Effective Countermeasure Against Topic Biases in Authorship Analysis. (arXiv:2005.06605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halvani_O/0/1/0/all/0/1">Oren Halvani</a>, <a href="http://arxiv.org/find/cs/1/au:+Graner_L/0/1/0/all/0/1">Lukas Graner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06605">
                                    <div class="article-summary-box-inner">
                                        <span>Authorship verification (AV) is a fundamental research task in digital text
forensics, which addresses the problem of whether two texts were written by the
same person. In recent years, a variety of AV methods have been proposed that
focus on this problem and can be divided into two categories: The first
category refers to such methods that are based on explicitly defined features,
where one has full control over which features are considered and what they
actually represent. The second category, on the other hand, relates to such AV
methods that are based on implicitly defined features, where no control
mechanism is involved, so that any character sequence in a text can serve as a
potential feature. However, AV methods belonging to the second category bear
the risk that the topic of the texts may bias their classification predictions,
which in turn may lead to misleading conclusions regarding their results. To
tackle this problem, we propose a preprocessing technique called POSNoise,
which effectively masks topic-related content in a given text. In this way, AV
methods are forced to focus on such text units that are more related to the
writing style. Our empirical evaluation based on six AV methods (falling into
the second category) and seven corpora shows that POSNoise leads to better
results compared to a well-known topic masking approach in 34 out of 42 cases,
with an increase in accuracy of up to 10%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional independence for pretext task selection in Self-supervised speech representation learning. (arXiv:2104.07388v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1">Salah Zaiem</a>, <a href="http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1">Slim Essid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07388">
                                    <div class="article-summary-box-inner">
                                        <span>Through solving pretext tasks, self-supervised learning (SSL) leverages
unlabeled data to extract useful latent representations replacing traditional
input features in the downstream task. A common pretext task consists in
pretraining a SSL model on pseudo-labels derived from the original signal. This
technique is particularly relevant for speech data where various meaningful
signal processing features may serve as pseudo-labels. However, the process of
selecting pseudo-labels, for speech or other types of data, remains mostly
unexplored and currently relies on observing the results on the final
downstream task. Nevertheless, this methodology is not sustainable at scale due
to substantial computational (hence carbon) costs. Thus, this paper introduces
a practical and theoretical framework to select relevant pseudo-labels with
respect to a given downstream task. More precisely, we propose a functional
estimator of the pseudo-label utility grounded in the conditional independence
theory, which does not require any training. The experiments conducted on
speaker recognition and automatic speech recognition validate our estimator,
showing a significant correlation between the performance observed on the
downstream task and the utility estimates obtained with our approach,
facilitating the prospection of relevant pseudo-labels for self-supervised
speech representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Space: A Geometrical Perspective. (arXiv:2007.00062v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kansizoglou_I/0/1/0/all/0/1">Ioannis Kansizoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bampis_L/0/1/0/all/0/1">Loukas Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasteratos_A/0/1/0/all/0/1">Antonios Gasteratos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00062">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most prominent attributes of Neural Networks (NNs) constitutes
their capability of learning to extract robust and descriptive features from
high dimensional data, like images. Hence, such an ability renders their
exploitation as feature extractors particularly frequent in an abundant of
modern reasoning systems. Their application scope mainly includes complex
cascade tasks, like multi-modal recognition and deep Reinforcement Learning
(RL). However, NNs induce implicit biases that are difficult to avoid or to
deal with and are not met in traditional image descriptors. Moreover, the lack
of knowledge for describing the intra-layer properties -- and thus their
general behavior -- restricts the further applicability of the extracted
features. With the paper at hand, a novel way of visualizing and understanding
the vector space before the NNs&#x27; output layer is presented, aiming to enlighten
the deep feature vectors&#x27; properties under classification tasks. Main attention
is paid to the nature of overfitting in the feature space and its adverse
effect on further exploitation. We present the findings that can be derived
from our model&#x27;s formulation, and we evaluate them on realistic recognition
scenarios, proving its prominence by improving the obtained results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Self Supervised Learning: the BT, the HSIC, and the VICReg. (arXiv:2105.12247v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sayan Nag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12247">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning and pre-training strategies have developed over the
last few years especially for Convolutional Neural Networks (CNNs). Recently
application of such methods can also be noticed for Graph Neural Networks
(GNNs) . In this paper, we have used a graph based self-supervised learning
strategy with different loss functions (Barlow Twins[Zbontar et al., 2021],
HSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown
promising results when applied with CNNs previously. We have also proposed a
hybrid loss function combining the advantages of VICReg and HSIC and called it
as VICRegHSIC. The performance of these aforementioned methods have been
compared when applied to different datasets such as MUTAG, PROTEINS and
IMDB-Binary. Moreover, the impact of different batch sizes, projector
dimensions and data augmentation strategies have also been explored</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Hyperboxes. (arXiv:2006.00695v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khuat_T/0/1/0/all/0/1">Thanh Tung Khuat</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabrys_B/0/1/0/all/0/1">Bogdan Gabrys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.00695">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a simple yet powerful ensemble classifier, called Random
Hyperboxes, constructed from individual hyperbox-based classifiers trained on
the random subsets of sample and feature spaces of the training set. We also
show a generalization error bound of the proposed classifier based on the
strength of the individual hyperbox-based classifiers as well as the
correlation among them. The effectiveness of the proposed classifier is
analyzed using a carefully selected illustrative example and compared
empirically with other popular single and ensemble classifiers via 20 datasets
using statistical testing methods. The experimental results confirmed that our
proposed method outperformed other fuzzy min-max neural networks, popular
learning algorithms, and is competitive with other ensemble methods. Finally,
we identify the existing issues related to the generalization error bounds of
the real datasets and inform the potential research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning How to Search: Generating Effective Test Cases Through Adaptive Fitness Function Selection. (arXiv:2102.04822v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almulla_H/0/1/0/all/0/1">Hussein Almulla</a>, <a href="http://arxiv.org/find/cs/1/au:+Gay_G/0/1/0/all/0/1">Gregory Gay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04822">
                                    <div class="article-summary-box-inner">
                                        <span>Search-based test generation is guided by feedback from one or more fitness
functions -- scoring functions that judge solution optimality. Choosing
informative fitness functions is crucial to meeting the goals of a tester.
Unfortunately, many goals - such as forcing the class-under-test to throw
exceptions, increasing test suite diversity, and attaining Strong Mutation
Coverage - do not have effective fitness function formulations. We propose that
meeting such goals requires treating fitness function identification as a
secondary optimization step. An adaptive algorithm that can vary the selection
of fitness functions could adjust its selection throughout the generation
process to maximize goal attainment, based on the current population of test
suites. To test this hypothesis, we have implemented two reinforcement learning
algorithms in the EvoSuite unit test generation framework, and used these
algorithms to dynamically set the fitness functions used during generation for
the three goals identified above.

We have evaluated our framework, EvoSuiteFIT, on a set of Java case examples.
EvoSuiteFIT techniques attain significant improvements for two of the three
goals, and show limited improvements on the third when the number of
generations of evolution is fixed. Additionally, for two of the three goals,
EvoSuiteFIT detects faults missed by the other techniques. The ability to
adjust fitness functions allows strategic choices that efficiently produce more
effective test suites, and examining these choices offers insight into how to
attain our testing goals. We find that adaptive fitness function selection is a
powerful technique to apply when an effective fitness function does not already
exist for achieving a testing goal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Color Variants Identification in Fashion e-commerce via Contrastive Self-Supervised Representation Learning. (arXiv:2104.08581v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_U/0/1/0/all/0/1">Ujjal Kr Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Repakula_S/0/1/0/all/0/1">Sandeep Repakula</a>, <a href="http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1">Maulik Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_A/0/1/0/all/0/1">Abhinav Ravi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08581">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we utilize deep visual Representation Learning to address an
important problem in fashion e-commerce: color variants identification, i.e.,
identifying fashion products that match exactly in their design (or style), but
only to differ in their color. At first we attempt to tackle the problem by
obtaining manual annotations (depicting whether two products are color
variants), and train a supervised triplet loss based neural network model to
learn representations of fashion products. However, for large scale real-world
industrial datasets such as addressed in our paper, it is infeasible to obtain
annotations for the entire dataset, while capturing all the difficult corner
cases. Interestingly, we observed that color variants are essentially
manifestations of color jitter based augmentations. Thus, we instead explore
Self-Supervised Learning (SSL) to solve this problem. We observed that existing
state-of-the-art SSL methods perform poor, for our problem. To address this, we
propose a novel SSL based color variants model that simultaneously focuses on
different parts of an apparel. Quantitative and qualitative evaluation shows
that our method outperforms existing SSL methods, and at times, the supervised
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters. (arXiv:2007.08194v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haoyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_Z/0/1/0/all/0/1">Zhihao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yuyuan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08194">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been successfully used in a range
of tasks. However, CNNs are often viewed as &quot;black-box&quot; and lack of
interpretability. One main reason is due to the filter-class entanglement -- an
intricate many-to-many correspondence between filters and classes. Most
existing works attempt post-hoc interpretation on a pre-trained model, while
neglecting to reduce the entanglement underlying the model. In contrast, we
focus on alleviating filter-class entanglement during training. Inspired by
cellular differentiation, we propose a novel strategy to train interpretable
CNNs by encouraging class-specific filters, among which each filter responds to
only one (or few) class. Concretely, we design a learnable sparse
Class-Specific Gate (CSG) structure to assign each filter with one (or few)
class in a flexible way. The gate allows a filter&#x27;s activation to pass only
when the input samples come from the specific class. Extensive experiments
demonstrate the fabulous performance of our method in generating a sparse and
highly class-related representation of the input, which leads to stronger
interpretability. Moreover, comparing with the standard training strategy, our
model displays benefits in applications like object localization and
adversarial sample detection. Code link: https://github.com/hyliang96/CSGCNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Physical Layer Communications. (arXiv:2106.11595v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mary_P/0/1/0/all/0/1">Philippe Mary</a>, <a href="http://arxiv.org/find/cs/1/au:+Koivunen_V/0/1/0/all/0/1">Visa Koivunen</a>, <a href="http://arxiv.org/find/cs/1/au:+Moy_C/0/1/0/all/0/1">Christophe Moy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11595">
                                    <div class="article-summary-box-inner">
                                        <span>In this chapter, we will give comprehensive examples of applying RL in
optimizing the physical layer of wireless communications by defining different
class of problems and the possible solutions to handle them. In Section 9.2, we
present all the basic theory needed to address a RL problem, i.e. Markov
decision process (MDP), Partially observable Markov decision process (POMDP),
but also two very important and widely used algorithms for RL, i.e. the
Q-learning and SARSA algorithms. We also introduce the deep reinforcement
learning (DRL) paradigm and the section ends with an introduction to the
multi-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples
to illustrate how the basic concepts of RL are employed in communication
systems. We present applications extracted from literature with simplified
system models using similar notation as in Section 9.2 of this Chapter. In
Section 9.3, we also focus on modeling RL problems, i.e. how action and state
spaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a
prospective thought on RL trends and it ends with a review of a broader state
of the art in Section 9.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic persistent homology via density-based metric learning. (arXiv:2012.07621v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Borghini_E/0/1/0/all/0/1">Eugenio Borghini</a>, <a href="http://arxiv.org/find/stat/1/au:+Fernandez_X/0/1/0/all/0/1">Ximena Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/stat/1/au:+Groisman_P/0/1/0/all/0/1">Pablo Groisman</a>, <a href="http://arxiv.org/find/stat/1/au:+Mindlin_G/0/1/0/all/0/1">Gabriel Mindlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07621">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of estimating intrinsic distances in a manifold from a
finite sample. We prove that the metric space defined by the sample endowed
with a computable metric known as sample Fermat distance converges a.s. in the
sense of Gromov-Hausdorff. The limiting object is the manifold itself endowed
with the population Fermat distance, an intrinsic metric that accounts for both
the geometry of the manifold and the density that produces the sample. This
result is applied to obtain intrinsic persistence diagrams, which are less
sensitive to the particular embedding of the manifold in the Euclidean space.
We show that this approach is robust to outliers and deduce a method for
pattern recognition in signals, with applications in real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupled Exploration and Exploitation Policies for Sample-Efficient Reinforcement Learning. (arXiv:2101.09458v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1">William F. Whitney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloesch_M/0/1/0/all/0/1">Michael Bloesch</a>, <a href="http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1">Jost Tobias Springenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1">Abbas Abdolmaleki</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1">Martin Riedmiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09458">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the close connection between exploration and sample efficiency, most
state of the art reinforcement learning algorithms include no considerations
for exploration beyond maximizing the entropy of the policy. In this work we
address this seeming missed opportunity. We observe that the most common
formulation of directed exploration in deep RL, known as bonus-based
exploration (BBE), suffers from bias and slow coverage in the few-sample
regime. This causes BBE to be actively detrimental to policy learning in many
control tasks. We show that by decoupling the task policy from the exploration
policy, directed exploration can be highly effective for sample-efficient
continuous control. Our method, Decoupled Exploration and Exploitation Policies
(DEEP), can be combined with any off-policy RL algorithm without modification.
When used in conjunction with soft actor-critic, DEEP incurs no performance
penalty in densely-rewarding environments. On sparse environments, DEEP gives a
several-fold improvement in data efficiency due to better exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A general approach for Explanations in terms of Middle Level Features. (arXiv:2106.05037v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1">Andrea Apicella</a>, <a href="http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1">Francesco Isgr&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1">Roberto Prevete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05037">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, it is growing interest to make Machine Learning (ML) systems more
understandable and trusting to general users. Thus, generating explanations for
ML system behaviours that are understandable to human beings is a central
scientific and technological issue addressed by the rapidly growing research
area of eXplainable Artificial Intelligence (XAI). Recently, it is becoming
more and more evident that new directions to create better explanations should
take into account what a good explanation is to a human user, and consequently,
develop XAI solutions able to provide user-centred explanations. This paper
suggests taking advantage of developing an XAI general approach that allows
producing explanations for an ML system behaviour in terms of different and
user-selected input features, i.e., explanations composed of input properties
that the human user can select according to his background knowledge and goals.
To this end, we propose an XAI general approach which is able: 1) to construct
explanations in terms of input features that represent more salient and
understandable input properties for a user, which we call here Middle-Level
input Features (MLFs), 2) to be applied to different types of MLFs. We
experimentally tested our approach on two different datasets and using three
different types of MLFs. The results seem encouraging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning deep autoregressive models for hierarchical data. (arXiv:2104.13853v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andersson_C/0/1/0/all/0/1">Carl R. Andersson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wahlstrom_N/0/1/0/all/0/1">Niklas Wahlstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Thomas B. Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13853">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a model for hierarchical structured data as an extension to the
stochastic temporal convolutional network. The proposed model combines an
autoregressive model with a hierarchical variational autoencoder and
downsampling to achieve superior computational complexity. We evaluate the
proposed model on two different types of sequential data: speech and
handwritten text. The results are promising with the proposed model achieving
state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition. (arXiv:2107.00606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1">Simone Angarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelini_F/0/1/0/all/0/1">Federico Angelini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent, and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time
short-time human action recognition. Extensive experimentation on MPOSE2021
with our proposed methodology and several previous architectural solutions
proves the effectiveness of the AcT model and poses the base for future work on
HAR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attribute Selection using Contranominal Scales. (arXiv:2106.10978v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Durrschnabel_D/0/1/0/all/0/1">Dominik D&#xfc;rrschnabel</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyda_M/0/1/0/all/0/1">Maren Koyda</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1">Gerd Stumme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10978">
                                    <div class="article-summary-box-inner">
                                        <span>Formal Concept Analysis (FCA) allows to analyze binary data by deriving
concepts and ordering them in lattices. One of the main goals of FCA is to
enable humans to comprehend the information that is encapsulated in the data;
however, the large size of concept lattices is a limiting factor for the
feasibility of understanding the underlying structural properties. The size of
such a lattice depends on the number of subcontexts in the corresponding formal
context that are isomorphic to a contranominal scale of high dimension. In this
work, we propose the algorithm ContraFinder that enables the computation of all
contranominal scales of a given formal context. Leveraging this algorithm, we
introduce delta-adjusting, a novel approach in order to decrease the number of
contranominal scales in a formal context by the selection of an appropriate
attribute subset. We demonstrate that delta-adjusting a context reduces the
size of the hereby emerging sub-semilattice and that the implication set is
restricted to meaningful implications. This is evaluated with respect to its
associated knowledge by means of a classification task. Hence, our proposed
technique strongly improves understandability while preserving important
conceptual structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of COVID-19 related Fake News via Neural Stacking. (arXiv:2101.03988v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1">Boshko Koloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdih_T/0/1/0/all/0/1">Timen Stepi&#x161;nik Perdih</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1">Senja Pollak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1">Bla&#x17e; &#x160;krlj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03988">
                                    <div class="article-summary-box-inner">
                                        <span>Identification of Fake News plays a prominent role in the ongoing pandemic,
impacting multiple aspects of day-to-day life. In this work we present a
solution to the shared task titled COVID19 Fake News Detection in English,
scoring the 50th place amongst 168 submissions. The solution was within 1.5% of
the best performing solution. The proposed solution employs a heterogeneous
representation ensemble, adapted for the classification task via an additional
neural classification head comprised of multiple hidden layers. The paper
consists of detailed ablation studies further displaying the proposed method&#x27;s
behavior and possible implications. The solution is freely available.
\url{https://gitlab.com/boshko.koloski/covid19-fake-news}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v12 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Siyang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1">Seth Austin Harding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shih-wei Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03479">
                                    <div class="article-summary-box-inner">
                                        <span>Many complex multi-robot systems such as robot swarms control and autonomous
vehicle coordination can be modeled as Multi-Agent Reinforcement Learning
(MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a
baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge
(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX
target relaxing the monotonicity constraint of QMIX, allowing for performance
improvement in SMAC. In this paper, we investigate the code-level optimizations
of these variants and the monotonicity constraint. (1) We find that such
improvements of the variants are significantly affected by various code-level
optimizations. (2) The experiment results show that QMIX with normalized
optimizations outperforms other works in SMAC; (3) beyond the common wisdom
from these works, the monotonicity constraint can improve sample efficiency in
SMAC and DEPP. We also discuss why monotonicity constraints work well in purely
cooperative tasks with a theoretical analysis. We open-source the code at
\url{https://github.com/hijkzzz/pymarl2}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Geometry and Classical Cram\&#x27;{e}r-Rao Type Inequalities. (arXiv:2104.01061v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_K/0/1/0/all/0/1">Kumar Vijay Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">M. Ashok Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01061">
                                    <div class="article-summary-box-inner">
                                        <span>We examine the role of information geometry in the context of classical
Cram\&#x27;er-Rao (CR) type inequalities. In particular, we focus on Eguchi&#x27;s theory
of obtaining dualistic geometric structures from a divergence function and then
applying Amari-Nagoaka&#x27;s theory to obtain a CR type inequality. The classical
deterministic CR inequality is derived from Kullback-Leibler (KL)-divergence.
We show that this framework could be generalized to other CR type inequalities
through four examples: $\alpha$-version of CR inequality, generalized CR
inequality, Bayesian CR inequality, and Bayesian $\alpha$-CR inequality. These
are obtained from, respectively, $I_\alpha$-divergence (or relative
$\alpha$-entropy), generalized Csisz\&#x27;ar divergence, Bayesian KL divergence,
and Bayesian $I_\alpha$-divergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual Bandits. (arXiv:2008.11918v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ren_Z/0/1/0/all/0/1">Zhimei Ren</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11918">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of dynamic batch learning in high-dimensional sparse
linear contextual bandits, where a decision maker can only adapt decisions at a
batch level. In particular, the decision maker, only observing rewards at the
end of each batch, dynamically decides how many individuals to include in the
next batch (at the current batch&#x27;s end) and what personalized action-selection
scheme to adopt within the batch. Such batch constraints are ubiquitous in a
variety of practical contexts, including personalized product offerings in
marketing and medical treatment selection in clinical trials. We characterize
the fundamental learning limit in this problem via a novel lower bound analysis
and provide a simple, exploration-free algorithm that uses the LASSO estimator,
which achieves the minimax optimal performance characterized by the lower bound
(up to log factors). To our best knowledge, our work provides the first inroad
into a rigorous understanding of dynamic batch learning with high-dimensional
covariates. We also demonstrate the efficacy of our algorithm on both synthetic
data and the Warfarin medical dosing data. The empirical results show that with
three batches (hence only two opportunities to adapt), our algorithm already
performs comparably (in terms of statistical performance) to the
state-of-the-art fully online high-dimensional linear contextual bandits
algorithm. As an added bonus, since our algorithm operates in batches, it is
orders of magnitudes faster than fully online learning algorithms. As such, our
algorithm provides a desirable candidate for practical data-driven personalized
decision making problems, where limited adaptivity is often a hard constraint.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Tight Communication Lower Bounds for Distributed Optimisation. (arXiv:2010.08222v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_J/0/1/0/all/0/1">Janne H. Korhonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08222">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a standard distributed optimisation setting where $N$ machines,
each holding a $d$-dimensional function $f_i$, aim to jointly minimise the sum
of the functions $\sum_{i &#x3D; 1}^N f_i (x)$. This problem arises naturally in
large-scale distributed optimisation, where a standard solution is to apply
variants of (stochastic) gradient descent. We focus on the communication
complexity of this problem: our main result provides the first fully
unconditional bounds on total number of bits which need to be sent and received
by the $N$ machines to solve this problem under point-to-point communication,
within a given error-tolerance. Specifically, we show that $\Omega( Nd \log d /
N\varepsilon)$ total bits need to be communicated between the machines to find
an additive $\epsilon$-approximation to the minimum of $\sum_{i &#x3D; 1}^N f_i
(x)$. The result holds for both deterministic and randomised algorithms, and,
importantly, requires no assumptions on the algorithm structure. The lower
bound is tight under certain restrictions on parameter values, and is matched
within constant factors for quadratic objectives by a new variant of quantised
gradient descent, which we describe and analyse. Our results bring over tools
from communication complexity to distributed optimisation, which has potential
for further applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A first look into the carbon footprint of federated learning. (arXiv:2102.07627v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xinchi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Marques_J/0/1/0/all/0/1">Javier Fernandez-Marques</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusmao_P/0/1/0/all/0/1">Pedro Porto Buarque de Gusmao</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_D/0/1/0/all/0/1">Daniel J. Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Topal_T/0/1/0/all/0/1">Taner Topal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1">Akhil Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07627">
                                    <div class="article-summary-box-inner">
                                        <span>Despite impressive results, deep learning-based technologies also raise
severe privacy and environmental concerns induced by the training procedure
often conducted in datacenters. In response, alternatives to centralized
training such as Federated Learning (FL) have emerged. Perhaps unexpectedly,
FL, in particular, is starting to be deployed at a global scale by companies
that must adhere to new legal demands and policies originating from governments
and civil society for privacy protection. However, the potential environmental
impact related to FL remains unclear and unexplored. This paper offers the
first-ever systematic study of the carbon footprint of FL. First, we propose a
rigorous model to quantify the carbon footprint, hence facilitating the
investigation of the relationship between FL design and carbon emissions. Then,
we compare the carbon footprint of FL to traditional centralized learning. Our
findings show that FL, despite being slower to converge in some cases, may
result in a comparatively greener impact than a centralized equivalent setup.
We performed extensive experiments across different types of datasets,
settings, and various deep learning models with FL. Finally, we highlight and
connect the reported results to the future challenges and trends in FL to
reduce its environmental impact, including algorithms efficiency, hardware
capabilities, and stronger industry transparency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Distributed Learning for Crisis Management. (arXiv:2104.12876v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Priyanshu_A/0/1/0/all/0/1">Aman Priyanshu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_M/0/1/0/all/0/1">Mudit Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1">Shreyans Mehta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12876">
                                    <div class="article-summary-box-inner">
                                        <span>Social media platforms such as Twitter, Facebook etc can be utilised as an
important source of information during disaster events. This information can be
used for disaster response and crisis management if processed accurately and
quickly. However, the data present in such situations is ever-changing, and
using considerable resources during such a crisis is not feasible. Therefore,
we have to develop a low resource and continually learning system that
incorporates text classification models which are robust against noisy and
unordered data. We utilised Distributed learning which enabled us to learn on
resource-constrained devices, then to alleviate catastrophic forgetting in our
target neural networks we utilized regularization. We then applied federated
averaging for distributed learning and to aggregate the central model for
continual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced training. (arXiv:2104.09376v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chuxiong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Hongming Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09376">
                                    <div class="article-summary-box-inner">
                                        <span>It is hard to directly implement Graph Neural Networks (GNNs) on large scaled
graphs. Besides of existed neighbor sampling techniques, scalable methods
decoupling graph convolutions and other learnable transformations into
preprocessing and post classifier allow normal minibatch training. By replacing
redundant concatenation operation with attention mechanism in SIGN, we propose
Scalable and Adaptive Graph Neural Networks (SAGN). SAGN can adaptively gather
neighborhood information among different hops. To further improve scalable
models on semi-supervised learning tasks, we propose Self-Label-Enhance (SLE)
framework combining self-training approach and label propagation in depth. We
add base model with a scalable node label module. Then we iteratively train
models and enhance train set in several stages. To generate input of node label
module, we directly apply label propagation based on one-hot encoded label
vectors without inner random masking. We find out that empirically the label
leakage has been effectively alleviated after graph convolutions. The hard
pseudo labels in enhanced train set participate in label propagation with true
labels. Experiments on both inductive and transductive datasets demonstrate
that, compared with other sampling-based and sampling-free methods, SAGN
achieves better or comparable results and SLE can further improve performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Informed Neural Networks for Minimising Worst-Case Violations in DC Optimal Power Flow. (arXiv:2107.00465v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nellikkath_R/0/1/0/all/0/1">Rahul Nellikkath</a>, <a href="http://arxiv.org/find/eess/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1">Spyros Chatzivasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00465">
                                    <div class="article-summary-box-inner">
                                        <span>Physics-informed neural networks exploit the existing models of the
underlying physical systems to generate higher accuracy results with fewer
data. Such approaches can help drastically reduce the computation time and
generate a good estimate of computationally intensive processes in power
systems, such as dynamic security assessment or optimal power flow. Combined
with the extraction of worst-case guarantees for the neural network
performance, such neural networks can be applied in safety-critical
applications in power systems and build a high level of trust among power
system operators. This paper takes the first step and applies, for the first
time to our knowledge, Physics-Informed Neural Networks with Worst-Case
Guarantees for the DC Optimal Power Flow problem. We look for guarantees
related to (i) maximum constraint violations, (ii) maximum distance between
predicted and optimal decision variables, and (iii) maximum sub-optimality in
the entire input domain. In a range of PGLib-OPF networks, we demonstrate how
physics-informed neural networks can be supplied with worst-case guarantees and
how they can lead to reduced worst-case violations compared with conventional
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Fusion Networks for Image Denoising. (arXiv:2011.14196v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hosseini_S/0/1/0/all/0/1">Seyed Mohsen Hosseini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14196">
                                    <div class="article-summary-box-inner">
                                        <span>A novel method for feature fusion in convolutional neural networks is
proposed in this paper. Different feature fusion techniques are suggested to
facilitate the flow of information and improve the training of deep neural
networks. Some of these techniques as well as the proposed network can be
considered a type of Directed Acyclic Graph (DAG) Network, where a layer can
receive inputs from other layers and have outputs to other layers. In the
proposed general framework of Lattice Fusion Network (LFNet), feature maps of
each convolutional layer are passed to other layers based on a lattice graph
structure, where nodes are convolutional layers. To evaluate the performance of
the proposed architecture, different designs based on the general framework of
LFNet are implemented for the task of image denoising. This task is used as an
example where training deep convolutional networks is needed. Results are
compared with state of the art methods. The proposed network is able to achieve
better results with far fewer learnable parameters, which shows the
effectiveness of LFNets for training of deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Arindam Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayer_A/0/1/0/all/0/1">Artun Bayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1">Santiago Segarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10424">
                                    <div class="article-summary-box-inner">
                                        <span>The graph convolutional network (GCN) is a go-to solution for machine
learning on graphs, but its training is notoriously difficult to scale both in
terms of graph size and the number of model parameters. Although some work has
explored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we
pioneer efficient training of large-scale GCN models (i.e., ultra-wide,
overparameterized models) with the proposal of a novel, distributed training
framework. Our proposed training methodology, called GIST, disjointly
partitions the parameters of a GCN model into several, smaller sub-GCNs that
are trained independently and in parallel. In addition to being compatible with
any GCN architecture, GIST improves model performance, scales to training on
arbitrarily large graphs, significantly decreases wall-clock training time, and
enables the training of markedly overparameterized GCN models. Remarkably, with
GIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which
exceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on
the Amazon2M dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows. (arXiv:2107.00652v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00652">
                                    <div class="article-summary-box-inner">
                                        <span>We present CSWin Transformer, an efficient and effective Transformer-based
backbone for general-purpose vision tasks. A challenging issue in Transformer
design is that global self-attention is very expensive to compute whereas local
self-attention often limits the field of interactions of each token. To address
this issue, we develop the Cross-Shaped Window self-attention mechanism for
computing self-attention in the horizontal and vertical stripes in parallel
that form a cross-shaped window, with each stripe obtained by splitting the
input feature into stripes of equal width. We provide a detailed mathematical
analysis of the effect of the stripe width and vary the stripe width for
different layers of the Transformer network which achieves strong modeling
capability while limiting the computation cost. We also introduce
Locally-enhanced Positional Encoding (LePE), which handles the local positional
information better than existing encoding schemes. LePE naturally supports
arbitrary input resolutions, and is thus especially effective and friendly for
downstream tasks. Incorporated with these designs and a hierarchical structure,
CSWin Transformer demonstrates competitive performance on common vision tasks.
Specifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra
training data or label, 53.9 box AP and 46.4 mask AP on the COCO detection
task, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing
previous state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and
+2.0 respectively under the similar FLOPs setting. By further pretraining on
the larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K
and state-of-the-art segmentation performance on ADE20K with 55.2 mIoU. The
code and models will be available at
https://github.com/microsoft/CSWin-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact Remediation: Optimal Interventions to Reduce Inequality. (arXiv:2107.00593v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bynum_L/0/1/0/all/0/1">Lucius E.J. Bynum</a>, <a href="http://arxiv.org/find/cs/1/au:+Loftus_J/0/1/0/all/0/1">Joshua R. Loftus</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanovich_J/0/1/0/all/0/1">Julia Stoyanovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00593">
                                    <div class="article-summary-box-inner">
                                        <span>A significant body of research in the data sciences considers unfair
discrimination against social categories such as race or gender that could
occur or be amplified as a result of algorithmic decisions. Simultaneously,
real-world disparities continue to exist, even before algorithmic decisions are
made. In this work, we draw on insights from the social sciences and humanistic
studies brought into the realm of causal modeling and constrained optimization,
and develop a novel algorithmic framework for tackling pre-existing real-world
disparities. The purpose of our framework, which we call the &quot;impact
remediation framework,&quot; is to measure real-world disparities and discover the
optimal intervention policies that could help improve equity or access to
opportunity for those who are underserved with respect to an outcome of
interest. We develop a disaggregated approach to tackling pre-existing
disparities that relaxes the typical set of assumptions required for the use of
social categories in structural causal models. Our approach flexibly
incorporates counterfactuals and is compatible with various ontological
assumptions about the nature of social categories. We demonstrate impact
remediation with a real-world case study and compare our disaggregated approach
to an existing state-of-the-art approach, comparing its structure and resulting
policy recommendations. In contrast to most work on optimal policy learning, we
explore disparity reduction itself as an objective, explicitly focusing the
power of algorithms on reducing inequality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method using Gaussian Processes. (arXiv:2008.03534v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gautier_R/0/1/0/all/0/1">Raphael Gautier</a>, <a href="http://arxiv.org/find/stat/1/au:+Pandita_P/0/1/0/all/0/1">Piyush Pandita</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1">Sayan Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Mavris_D/0/1/0/all/0/1">Dimitri Mavris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03534">
                                    <div class="article-summary-box-inner">
                                        <span>Modern day engineering problems are ubiquitously characterized by
sophisticated computer codes that map parameters or inputs to an underlying
physical process. In other situations, experimental setups are used to model
the physical process in a laboratory, ensuring high precision while being
costly in materials and logistics. In both scenarios, only limited amount of
data can be generated by querying the expensive information source at a finite
number of inputs or designs. This problem is compounded further in the presence
of a high-dimensional input space. State-of-the-art parameter space dimension
reduction methods, such as active subspace, aim to identify a subspace of the
original input space that is sufficient to explain the output response. These
methods are restricted by their reliance on gradient evaluations or copious
data, making them inadequate to expensive problems without direct access to
gradients. The proposed methodology is gradient-free and fully Bayesian, as it
quantifies uncertainty in both the low-dimensional subspace and the surrogate
model parameters. This enables a full quantification of epistemic uncertainty
and robustness to limited data availability. It is validated on multiple
datasets from engineering and science and compared to two other
state-of-the-art methods based on four aspects: a) recovery of the active
subspace, b) deterministic prediction accuracy, c) probabilistic prediction
accuracy, and d) training time. The comparison shows that the proposed method
improves the active subspace recovery and predictive accuracy, in both the
deterministic and probabilistic sense, when only few model observations are
available for training, at the cost of increased training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Particle Filters through Conditional Normalizing Flow. (arXiv:2107.00488v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hao Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00488">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable particle filters provide a flexible mechanism to adaptively
train dynamic and measurement models by learning from observed data. However,
most existing differentiable particle filters are within the bootstrap particle
filtering framework and fail to incorporate the information from latest
observations to construct better proposals. In this paper, we utilize
conditional normalizing flows to construct proposal distributions for
differentiable particle filters, enriching the distribution families that the
proposal distributions can represent. In addition, normalizing flows are
incorporated in the construction of the dynamic model, resulting in a more
expressive dynamic model. We demonstrate the performance of the proposed
conditional normalizing flow-based differentiable particle filters in a visual
tracking task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets. (arXiv:2107.00472v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhou_B/0/1/0/all/0/1">Baojian Zhou</a>, <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00472">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose approximate Frank-Wolfe (FW) algorithms to solve
convex optimization problems over graph-structured support sets where the
\textit{linear minimization oracle} (LMO) cannot be efficiently obtained in
general. We first demonstrate that two popular approximation assumptions
(\textit{additive} and \textit{multiplicative gap errors)}, are not valid for
our problem, in that no cheap gap-approximate LMO oracle exists in general.
Instead, a new \textit{approximate dual maximization oracle} (DMO) is proposed,
which approximates the inner product rather than the gap. When the objective is
$L$-smooth, we prove that the standard FW method using a $\delta$-approximate
DMO converges as $\mathcal{O}(L / \delta t + (1-\delta)(\delta^{-1} +
\delta^{-2}))$ in general, and as $\mathcal{O}(L/(\delta^2(t+2)))$ over a
$\delta$-relaxation of the constraint set. Additionally, when the objective is
$\mu$-strongly convex and the solution is unique, a variant of FW converges to
$\mathcal{O}(L^2\log(t)/(\mu \delta^6 t^2))$ with the same per-iteration
complexity. Our empirical results suggest that even these improved bounds are
pessimistic, with significant improvement in recovering real-world images with
graph-structured sparsity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Training with Highly Incomplete Datasets. (arXiv:2107.00429v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yu-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Natali_L/0/1/0/all/0/1">Laura Natali</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamialahmadi_O/0/1/0/all/0/1">Oveis Jamialahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Romeo_S/0/1/0/all/0/1">Stefano Romeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1">Joana B. Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Volpe_G/0/1/0/all/0/1">Giovanni Volpe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00429">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network training and validation rely on the availability of large
high-quality datasets. However, in many cases only incomplete datasets are
available, particularly in health care applications, where each patient
typically undergoes different clinical procedures or can drop out of a study.
Since the data to train the neural networks need to be complete, most studies
discard the incomplete datapoints, which reduces the size of the training data,
or impute the missing features, which can lead to artefacts. Alas, both
approaches are inadequate when a large portion of the data is missing. Here, we
introduce GapNet, an alternative deep-learning training approach that can use
highly incomplete datasets. First, the dataset is split into subsets of samples
containing all values for a certain cluster of features. Then, these subsets
are used to train individual neural networks. Finally, this ensemble of neural
networks is combined into a single neural network whose training is fine-tuned
using all complete datapoints. Using two highly incomplete real-world medical
datasets, we show that GapNet improves the identification of patients with
underlying Alzheimer&#x27;s disease pathology and of patients at risk of
hospitalization due to Covid-19. By distilling the information available in
incomplete datasets without having to reduce their size or to impute missing
values, GapNet will permit to extract valuable information from a wide range of
datasets, benefiting diverse fields from medicine to engineering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1">Andrea Dittadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papa_S/0/1/0/all/0/1">Samuele Papa</a>, <a href="http://arxiv.org/find/cs/1/au:+Vita_M/0/1/0/all/0/1">Michele De Vita</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00637">
                                    <div class="article-summary-box-inner">
                                        <span>The idea behind object-centric representation learning is that natural scenes
can better be modeled as compositions of objects and their relations as opposed
to distributed representations. This inductive bias can be injected into neural
networks to potentially improve systematic generalization and learning
efficiency of downstream tasks in scenes with multiple objects. In this paper,
we train state-of-the-art unsupervised models on five common multi-object
datasets and evaluate segmentation accuracy and downstream object property
prediction. In addition, we study systematic generalization and robustness by
investigating the settings where either single objects are out-of-distribution
-- e.g., having unseen colors, textures, and shapes -- or global properties of
the scene are altered -- e.g., by occlusions, cropping, or increasing the
number of objects. From our experimental study, we find object-centric
representations to be generally useful for downstream tasks and robust to
shifts in the data distribution, especially if shifts affect single objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reparameterized Sampling for Generative Adversarial Networks. (arXiv:2107.00352v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yifei Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1">Jiansheng Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00352">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, sampling methods have been successfully applied to enhance the
sample quality of Generative Adversarial Networks (GANs). However, in practice,
they typically have poor sample efficiency because of the independent proposal
sampling from the generator. In this work, we propose REP-GAN, a novel sampling
method that allows general dependent proposals by REParameterizing the Markov
chains into the latent space of the generator. Theoretically, we show that our
reparameterized proposal admits a closed-form Metropolis-Hastings acceptance
ratio. Empirically, extensive experiments on synthetic and real datasets
demonstrate that our REP-GAN largely improves the sample efficiency and obtains
better sample quality simultaneously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning based iterative learning control for non-repetitive time-varying systems. (arXiv:2107.00421v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yiyang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiang_W/0/1/0/all/0/1">Wei Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Charalambous_T/0/1/0/all/0/1">Themistoklis Charalambous</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00421">
                                    <div class="article-summary-box-inner">
                                        <span>The repetitive tracking task for time-varying systems (TVSs) with
non-repetitive time-varying parameters, which is also called non-repetitive
TVSs, is realized in this paper using iterative learning control (ILC). A
machine learning (ML) based nominal model update mechanism, which utilizes the
linear regression technique to update the nominal model at each ILC trial only
using the current trial information, is proposed for non-repetitive TVSs in
order to enhance the ILC performance. Given that the ML mechanism forces the
model uncertainties to remain within the ILC robust tolerance, an ILC update
law is proposed to deal with non-repetitive TVSs. How to tune parameters inside
ML and ILC algorithms to achieve the desired aggregate performance is also
provided. The robustness and reliability of the proposed method are verified by
simulations. Comparison with current state-of-the-art demonstrates its superior
control performance in terms of controlling precision. This paper broadens ILC
applications from time-invariant systems to non-repetitive TVSs, adopts ML
regression technique to estimate non-repetitive time-varying parameters between
two ILC trials and proposes a detailed parameter tuning mechanism to achieve
desired performance, which are the main contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in Edge Industrial IoT. (arXiv:2107.00481v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wanlu Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yu Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Ming Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoglund_M/0/1/0/all/0/1">Mikael Skoglund</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00481">
                                    <div class="article-summary-box-inner">
                                        <span>Edge computing provides a promising paradigm to support the implementation of
Industrial Internet of Things (IIoT) by offloading tasks to nearby edge nodes.
Meanwhile, the increasing network size makes it impractical for centralized
data processing due to limited bandwidth, and consequently a decentralized
learning scheme is preferable. Reinforcement learning (RL) has been widely
investigated and shown to be a promising solution for decision-making and
optimal control processes. For RL in a decentralized setup, edge nodes (agents)
connected through a communication network aim to work collaboratively to find a
policy to optimize the global reward as the sum of local rewards. However,
communication costs, scalability and adaptation in complex environments with
heterogeneous agents may significantly limit the performance of decentralized
RL. Alternating direction method of multipliers (ADMM) has a structure that
allows for decentralized implementation, and has shown faster convergence than
gradient descent based methods. Therefore, we propose an adaptive stochastic
incremental ADMM (asI-ADMM) algorithm and apply the asI-ADMM to decentralized
RL with edge-computing-empowered IIoT networks. We provide convergence
properties for proposed algorithms by designing a Lyapunov function and prove
that the asI-ADMM has $O(\frac{1}{k}) +O(\frac{1}{M})$ convergence rate where
$k$ and $ M$ are the number of iterations and batch samples, respectively.
Then, we test our algorithm with two supervised learning problems. For
performance evaluation, we simulate two applications in decentralized RL
settings with homogeneous and heterogeneous agents. The experiment results show
that our proposed algorithms outperform the state of the art in terms of
communication costs and scalability, and can well adapt to complex IoT
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Diffusion Models. (arXiv:2107.00630v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kingma_D/0/1/0/all/0/1">Diederik P. Kingma</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>, <a href="http://arxiv.org/find/cs/1/au:+Poole_B/0/1/0/all/0/1">Ben Poole</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00630">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion-based generative models have demonstrated a capacity for
perceptually impressive synthesis, but can they also be great likelihood-based
models? We answer this in the affirmative, and introduce a family of
diffusion-based generative models that obtain state-of-the-art likelihoods on
standard image density estimation benchmarks. Unlike other diffusion-based
models, our method allows for efficient optimization of the noise schedule
jointly with the rest of the model. We show that the variational lower bound
(VLB) simplifies to a remarkably short expression in terms of the
signal-to-noise ratio of the diffused data, thereby improving our theoretical
understanding of this model class. Using this insight, we prove an equivalence
between several models proposed in the literature. In addition, we show that
the continuous-time VLB is invariant to the noise schedule, except for the
signal-to-noise ratio at its endpoints. This enables us to learn a noise
schedule that minimizes the variance of the resulting VLB estimator, leading to
faster optimization. Combining these advances with architectural improvements,
we obtain state-of-the-art likelihoods on image density estimation benchmarks,
outperforming autoregressive models that have dominated these benchmarks for
many years, with often significantly faster optimization. In addition, we show
how to turn the model into a bits-back compression scheme, and demonstrate
lossless compression rates close to the theoretical optimum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Margin Maximization via Dual Acceleration. (arXiv:2107.00595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Ziwei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>, <a href="http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1">Matus Telgarsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00595">
                                    <div class="article-summary-box-inner">
                                        <span>We present and analyze a momentum-based gradient method for training linear
classifiers with an exponentially-tailed loss (e.g., the exponential or
logistic loss), which maximizes the classification margin on separable data at
a rate of $\widetilde{\mathcal{O}}(1/t^2)$. This contrasts with a rate of
$\mathcal{O}(1/\log(t))$ for standard gradient descent, and $\mathcal{O}(1/t)$
for normalized gradient descent. This momentum-based method is derived via the
convex dual of the maximum-margin problem, and specifically by applying
Nesterov acceleration to this dual, which manages to result in a simple and
intuitive method in the primal. This dual view can also be used to derive a
stochastic variant, which performs adaptive non-uniform sampling via the dual
variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinGAN-Seg: Synthetic Training Data Generation for Medical Image Segmentation. (arXiv:2107.00471v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Salehi_P/0/1/0/all/0/1">Pegah Salehi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sheshkal_S/0/1/0/all/0/1">Sajad Amouei Sheshkal</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Hammer_H/0/1/0/all/0/1">Hugo L.Hammer</a>, <a href="http://arxiv.org/find/eess/1/au:+Parasa_S/0/1/0/all/0/1">Sravanthi Parasa</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00471">
                                    <div class="article-summary-box-inner">
                                        <span>Processing medical data to find abnormalities is a time-consuming and costly
task, requiring tremendous efforts from medical experts. Therefore, Ai has
become a popular tool for the automatic processing of medical data, acting as a
supportive tool for doctors. AI tools highly depend on data for training the
models. However, there are several constraints to access to large amounts of
medical data to train machine learning algorithms in the medical domain, e.g.,
due to privacy concerns and the costly, time-consuming medical data annotation
process. To address this, in this paper we present a novel synthetic data
generation pipeline called SinGAN-Seg to produce synthetic medical data with
the corresponding annotated ground truth masks. We show that these synthetic
data generation pipelines can be used as an alternative to bypass privacy
concerns and as an alternative way to produce artificial segmentation datasets
with corresponding ground truth masks to avoid the tedious medical data
annotation process. As a proof of concept, we used an open polyp segmentation
dataset. By training UNet++ using both the real polyp segmentation dataset and
the corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we
show that the synthetic data can achieve a very close performance to the real
data when the real segmentation datasets are large enough. In addition, we show
that synthetic data generated from the SinGAN-Seg pipeline improving the
performance of segmentation algorithms when the training dataset is very small.
Since our SinGAN-Seg pipeline is applicable for any medical dataset, this
pipeline can be used with any other segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Stochastic Extragradient for Bilinear Games with Restarted Iteration Averaging. (arXiv:2107.00464v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1">Chris Junchi Li</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1">Nicolas Loizou</a>, <a href="http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>, <a href="http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>, <a href="http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00464">
                                    <div class="article-summary-box-inner">
                                        <span>We study the stochastic bilinear minimax optimization problem, presenting an
analysis of the Stochastic ExtraGradient (SEG) method with constant step size,
and presenting variations of the method that yield favorable convergence. We
first note that the last iterate of the basic SEG method only contracts to a
fixed neighborhood of the Nash equilibrium, independent of the step size. This
contrasts sharply with the standard setting of minimization where standard
stochastic algorithms converge to a neighborhood that vanishes in proportion to
the square-root (constant) step size. Under the same setting, however, we prove
that when augmented with iteration averaging, SEG provably converges to the
Nash equilibrium, and such a rate is provably accelerated by incorporating a
scheduled restarting procedure. In the interpolation setting, we achieve an
optimal convergence rate up to tight constants. We present numerical
experiments that validate our theoretical findings and demonstrate the
effectiveness of the SEG method when equipped with iteration averaging and
restarting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-MATD3:Self-attention-based multi-agent continuous control method in cooperative environments. (arXiv:2107.00284v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuyang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00284">
                                    <div class="article-summary-box-inner">
                                        <span>Cooperative problems under continuous control have always been the focus of
multi-agent reinforcement learning. Existing algorithms suffer from the problem
of uneven learning degree with the increase of the number of agents. In this
paper, a new structure for a multi-agent actor critic is proposed, and the
self-attention mechanism is applied in the critic network and the value
decomposition method used to solve the uneven problem. The proposed algorithm
makes full use of the samples in the replay memory buffer to learn the behavior
of a class of agents. First, a new update method is proposed for policy
networks that promotes learning efficiency. Second, the utilization of samples
is improved, at the same time reflecting the ability of perspective-taking
among groups. Finally, the &quot;deceptive signal&quot; in training is eliminated and the
learning degree among agents is more uniform than in the existing methods.
Multiple experiments were conducted in two typical scenarios of a multi-agent
particle environment. Experimental results show that the proposed algorithm can
perform better than the state-of-the-art ones, and that it exhibits higher
learning efficiency with an increasing number of agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft&#x27;s Submission to SwissText 2021. (arXiv:2106.08126v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1">Yuriy Arabskyy</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1">Aashish Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1">Subhadeep Dey</a>, <a href="http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1">Oscar Koller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08126">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the winning approach in the Shared Task 3 at SwissText
2021 on Swiss German Speech to Standard German Text, a public competition on
dialect recognition and translation. Swiss German refers to the multitude of
Alemannic dialects spoken in the German-speaking parts of Switzerland. Swiss
German differs significantly from standard German in pronunciation, word
inventory and grammar. It is mostly incomprehensible to native German speakers.
Moreover, it lacks a standardized written script. To solve the challenging
task, we propose a hybrid automatic speech recognition system with a lexicon
that incorporates translations, a 1st pass language model that deals with Swiss
German particularities, a transfer-learned acoustic model and a strong neural
language model for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a
blind conversational test set and outperforms the second best competitor by a
12% relative margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algebraic Neural Networks: Stability to Deformations. (arXiv:2009.01433v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parada_Mayorga_A/0/1/0/all/0/1">Alejandro Parada-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.01433">
                                    <div class="article-summary-box-inner">
                                        <span>We study algebraic neural networks (AlgNNs) with commutative algebras which
unify diverse architectures such as Euclidean convolutional neural networks,
graph neural networks, and group neural networks under the umbrella of
algebraic signal processing. An AlgNN is a stacked layered information
processing structure where each layer is conformed by an algebra, a vector
space and a homomorphism between the algebra and the space of endomorphisms of
the vector space. Signals are modeled as elements of the vector space and are
processed by convolutional filters that are defined as the images of the
elements of the algebra under the action of the homomorphism. We analyze
stability of algebraic filters and AlgNNs to deformations of the homomorphism
and derive conditions on filters that lead to Lipschitz stable operators. We
conclude that stable algebraic filters have frequency responses -- defined as
eigenvalue domain representations -- whose derivative is inversely proportional
to the frequency -- defined as eigenvalue magnitudes. It follows that for a
given level of discriminability, AlgNNs are more stable than algebraic filters,
thereby explaining their better empirical performance. This same phenomenon has
been proven for Euclidean convolutional neural networks and graph neural
networks. Our analysis shows that this is a deep algebraic property shared by a
number of architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor. (arXiv:2107.00401v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Viale_A/0/1/0/all/0/1">Alberto Viale</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00401">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous Driving (AD) related features provide new forms of mobility that
are also beneficial for other kind of intelligent and autonomous systems like
robots, smart transportation, and smart industries. For these applications, the
decisions need to be made fast and in real-time. Moreover, in the quest for
electric mobility, this task must follow low power policy, without affecting
much the autonomy of the mean of transport or the robot. These two challenges
can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed
on a specialized neuromorphic hardware, SNNs can achieve high performance with
low latency and low power consumption. In this paper, we use an SNN connected
to an event-based camera for facing one of the key problems for AD, i.e., the
classification between cars and other objects. To consume less power than
traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The
experiments are made following an offline supervised learning rule, followed by
mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our
best experiment achieves an accuracy on offline implementation of 86%, that
drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware
implementation has maximum 0.72 ms of latency for every sample, and consumes
only 310 mW. To the best of our knowledge, this work is the first
implementation of an event-based car classifier on a Neuromorphic Chip.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mandoline: Model Evaluation under Distribution Shift. (arXiv:2107.00643v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mayee Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_K/0/1/0/all/0/1">Karan Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohoni_N/0/1/0/all/0/1">Nimit Sohoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Poms_F/0/1/0/all/0/1">Fait Poms</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatahalian_K/0/1/0/all/0/1">Kayvon Fatahalian</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1">Christopher R&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00643">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models are often deployed in different settings than they
were trained and validated on, posing a challenge to practitioners who wish to
predict how well the deployed model will perform on a target distribution. If
an unlabeled sample from the target distribution is available, along with a
labeled sample from a possibly different source distribution, standard
approaches such as importance weighting can be applied to estimate performance
on the target. However, importance weighting struggles when the source and
target distributions have non-overlapping support or are high-dimensional.
Taking inspiration from fields such as epidemiology and polling, we develop
Mandoline, a new evaluation framework that mitigates these issues. Our key
insight is that practitioners may have prior knowledge about the ways in which
the distribution shifts, which we can use to better guide the importance
weighting procedure. Specifically, users write simple &quot;slicing functions&quot; -
noisy, potentially correlated binary functions intended to capture possible
axes of distribution shift - to compute reweighted performance estimates. We
further describe a density ratio estimation framework for the slices and show
how its estimation error scales with slice quality and dataset size. Empirical
validation on NLP and vision tasks shows that \name can estimate performance on
the target distribution up to $3\times$ more accurately compared to standard
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Expected Complexity of Maxout Networks. (arXiv:2107.00379v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tseran_H/0/1/0/all/0/1">Hanna Tseran</a>, <a href="http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1">Guido Mont&#xfa;far</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00379">
                                    <div class="article-summary-box-inner">
                                        <span>Learning with neural networks relies on the complexity of the representable
functions, but more importantly, the particular assignment of typical
parameters to functions of different complexity. Taking the number of
activation regions as a complexity measure, recent works have shown that the
practical complexity of deep ReLU networks is often far from the theoretical
maximum. In this work we show that this phenomenon also occurs in networks with
maxout (multi-argument) activation functions and when considering the decision
boundaries in classification tasks. We also show that the parameter space has a
multitude of full-dimensional regions with widely different complexity, and
obtain nontrivial lower bounds on the expected complexity. Finally, we
investigate different parameter initialization procedures and show that they
can increase the speed of convergence in training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Large DAGs by Combining Continuous Optimization and Feedback Arc Set Heuristics. (arXiv:2107.00571v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gillot_P/0/1/0/all/0/1">Pierre Gillot</a>, <a href="http://arxiv.org/find/cs/1/au:+Parviainen_P/0/1/0/all/0/1">Pekka Parviainen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00571">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian networks represent relations between variables using a directed
acyclic graph (DAG). Learning the DAG is an NP-hard problem and exact learning
algorithms are feasible only for small sets of variables. We propose two
scalable heuristics for learning DAGs in the linear structural equation case.
Our methods learn the DAG by alternating between unconstrained gradient
descent-based step to optimize an objective function and solving a maximum
acyclic subgraph problem to enforce acyclicity. Thanks to this decoupling, our
methods scale up beyond thousands of variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Acceleration and Feature Learning inInfinitely Wide Neural Networks with Bottlenecks. (arXiv:2107.00364v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1">Etai Littwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_O/0/1/0/all/0/1">Omid Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1">Shuangfei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Thilak_V/0/1/0/all/0/1">Vimal Thilak</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_H/0/1/0/all/0/1">Hanlin Goh</a>, <a href="http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1">Joshua M. Susskind</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Greg Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00364">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze the learning dynamics of infinitely wide neural networks with a
finite sized bottle-neck. Unlike the neural tangent kernel limit, a bottleneck
in an otherwise infinite width network al-lows data dependent feature learning
in its bottle-neck representation. We empirically show that a single bottleneck
in infinite networks dramatically accelerates training when compared to purely
in-finite networks, with an improved overall performance. We discuss the
acceleration phenomena by drawing similarities to infinitely wide deep linear
models, where the acceleration effect of a bottleneck can be understood
theoretically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Sound Event Classification by Increasing Shift Invariance in Convolutional Neural Networks. (arXiv:2107.00623v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1">Eduardo Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_A/0/1/0/all/0/1">Andres Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1">Xavier Serra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00623">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have put into question the commonly assumed shift invariance
property of convolutional networks, showing that small shifts in the input can
affect the output predictions substantially. In this paper, we ask whether lack
of shift invariance is a problem in sound event classification, and whether
there are benefits in addressing it. Specifically, we evaluate two pooling
methods to improve shift invariance in CNNs, based on low-pass filtering and
adaptive sampling of incoming feature maps. These methods are implemented via
small architectural modifications inserted into the pooling layers of CNNs. We
evaluate the effect of these architectural changes on the FSD50K dataset using
models of different capacity and in presence of strong regularization. We show
that these modifications consistently improve sound event classification in all
cases considered, without adding any (or adding very few) trainable parameters,
which makes them an appealing alternative to conventional pooling layers. The
outcome is a new state-of-the-art mAP of 0.541 on the FSD50K classification
benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Feature and Instance Attribution to Detect Artifacts. (arXiv:2107.00323v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1">Pouya Pezeshkpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sarthak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00323">
                                    <div class="article-summary-box-inner">
                                        <span>Training the large deep neural networks that dominate NLP requires large
datasets. Many of these are collected automatically or via crowdsourcing, and
may exhibit systematic biases or annotation artifacts. By the latter, we mean
correlations between inputs and outputs that are spurious, insofar as they do
not represent a generally held causal relationship between features and
classes; models that exploit such correlations may appear to perform a given
task well, but fail on out of sample data. In this paper we propose methods to
facilitate identification of training data artifacts, using new hybrid
approaches that combine saliency maps (which highlight important input
features) with instance attribution methods (which retrieve training samples
influential to a given prediction). We show that this proposed training-feature
attribution approach can be used to uncover artifacts in training data, and use
it to identify previously unreported artifacts in a few standard NLP datasets.
We execute a small user study to evaluate whether these methods are useful to
NLP researchers in practice, with promising results. We make code for all
methods and experiments in this paper available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Inverse Problems with a Flow-based Noise Model. (arXiv:2003.08089v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1">Jay Whang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08089">
                                    <div class="article-summary-box-inner">
                                        <span>We study image inverse problems with a normalizing flow prior. Our
formulation views the solution as the maximum a posteriori estimate of the
image conditioned on the measurements. This formulation allows us to use noise
models with arbitrary dependencies as well as non-linear forward operators. We
empirically validate the efficacy of our method on various inverse problems,
including compressed sensing with quantized measurements and denoising with
highly structured noise patterns. We also present initial theoretical recovery
guarantees for solving inverse problems with a flow prior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Filter Networks for Image Classification. (arXiv:2107.00645v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00645">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-attention and pure multi-layer perceptrons (MLP)
models for vision have shown great potential in achieving promising performance
with fewer inductive biases. These models are generally based on learning
interaction among spatial locations from raw data. The complexity of
self-attention and MLP grows quadratically as the image size increases, which
makes these models hard to scale up when high-resolution features are required.
In this paper, we present the Global Filter Network (GFNet), a conceptually
simple yet computationally efficient architecture, that learns long-term
spatial dependencies in the frequency domain with log-linear complexity. Our
architecture replaces the self-attention layer in vision transformers with
three key operations: a 2D discrete Fourier transform, an element-wise
multiplication between frequency-domain features and learnable global filters,
and a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity
trade-offs of our models on both ImageNet and downstream tasks. Our results
demonstrate that GFNet can be a very competitive alternative to
transformer-style models and CNNs in efficiency, generalization ability and
robustness. Code is available at https://github.com/raoyongming/GFNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention. (arXiv:2103.15722v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chengdong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Menglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15722">
                                    <div class="article-summary-box-inner">
                                        <span>Self-attention (SA), which encodes vector sequences according to their
pairwise similarity, is widely used in speech recognition due to its strong
context modeling ability. However, when applied to long sequence data, its
accuracy is reduced. This is caused by the fact that its weighted average
operator may lead to the dispersion of the attention distribution, which
results in the relationship between adjacent signals ignored. To address this
issue, in this paper, we introduce relative-position-awareness self-attention
(RPSA). It not only maintains the global-range dependency modeling ability of
self-attention, but also improves the localness modeling ability. Because the
local window length of the original RPSA is fixed and sensitive to different
test data, here we propose Gaussian-based self-attention (GSA) whose window
length is learnable and adaptive to the test data automatically. We further
generalize GSA to a new residual Gaussian self-attention (resGSA) for the
performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based
speech recognition respectively. Experimental results on the AISHELL-1 Mandarin
speech recognition corpus demonstrate the effectiveness of the proposed
methods. For example, the resGSA-Transformer achieves a character error rate
(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the
SA-Transformer. Although the performance of the proposed resGSA-Transformer is
only slightly better than that of the RPSA-Transformer, it does not have to
tune the window length manually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classical Planning in Deep Latent Space. (arXiv:2107.00110v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asai_M/0/1/0/all/0/1">Masataro Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1">Hiroshi Kajino</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukunaga_A/0/1/0/all/0/1">Alex Fukunaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Muise_C/0/1/0/all/0/1">Christian Muise</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00110">
                                    <div class="article-summary-box-inner">
                                        <span>Current domain-independent, classical planners require symbolic models of the
problem domain and instance as input, resulting in a knowledge acquisition
bottleneck. Meanwhile, although deep learning has achieved significant success
in many fields, the knowledge is encoded in a subsymbolic representation which
is incompatible with symbolic systems such as planners. We propose Latplan, an
unsupervised architecture combining deep learning and classical planning. Given
only an unlabeled set of image pairs showing a subset of transitions allowed in
the environment (training inputs), Latplan learns a complete propositional PDDL
action model of the environment. Later, when a pair of images representing the
initial and the goal states (planning inputs) is given, Latplan finds a plan to
the goal state in a symbolic latent space and returns a visualized plan
execution. We evaluate Latplan using image-based versions of 6 planning
domains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of
LightsOut.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossless Coding of Point Cloud Geometry using a Deep Generative Model. (arXiv:2107.00400v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1">Dat Thanh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Quach_M/0/1/0/all/0/1">Maurice Quach</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenzise_G/0/1/0/all/0/1">Giuseppe Valenzise</a>, <a href="http://arxiv.org/find/eess/1/au:+Duhamel_P/0/1/0/all/0/1">Pierre Duhamel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00400">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a lossless point cloud (PC) geometry compression method
that uses neural networks to estimate the probability distribution of voxel
occupancy. First, to take into account the PC sparsity, our method adaptively
partitions a point cloud into multiple voxel block sizes. This partitioning is
signalled via an octree. Second, we employ a deep auto-regressive generative
model to estimate the occupancy probability of each voxel given the previously
encoded ones. We then employ the estimated probabilities to code efficiently a
block using a context-based arithmetic coder. Our context has variable size and
can expand beyond the current block to learn more accurate probabilities. We
also consider using data augmentation techniques to increase the generalization
capability of the learned probability models, in particular in the presence of
noise and lower-density point clouds. Experimental evaluation, performed on a
variety of point clouds from four different datasets and with diverse
characteristics, demonstrates that our method reduces significantly (by up to
30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoLightFormer: Lightweight Action Recognition using Transformers. (arXiv:2107.00451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient video action recognition remains a challenging problem. One large
model after another takes the place of the state-of-the-art on the Kinetics
dataset, but real-world efficiency evaluations are often lacking. In this work,
we fill this gap and investigate the use of transformers for efficient action
recognition. We propose a novel, lightweight action recognition architecture,
VideoLightFormer. In a factorized fashion, we carefully extend the 2D
convolutional Temporal Segment Network with transformers, while maintaining
spatial and temporal video structure throughout the entire model. Existing
methods often resort to one of the two extremes, where they either apply huge
transformers to video features, or minimal transformers on highly pooled video
features. Our method differs from them by keeping the transformer models small,
but leveraging full spatiotemporal feature structure. We evaluate
VideoLightFormer in a high-efficiency setting on the temporally-demanding
EPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it
achieves a better mix of efficiency and accuracy than existing state-of-the-art
models, apart from the Temporal Shift Module on SSV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MHER: Model-based Hindsight Experience Replay. (arXiv:2107.00306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Feng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00306">
                                    <div class="article-summary-box-inner">
                                        <span>Solving multi-goal reinforcement learning (RL) problems with sparse rewards
is generally challenging. Existing approaches have utilized goal relabeling on
collected experiences to alleviate issues raised from sparse rewards. However,
these methods are still limited in efficiency and cannot make full use of
experiences. In this paper, we propose Model-based Hindsight Experience Replay
(MHER), which exploits experiences more efficiently by leveraging environmental
dynamics to generate virtual achieved goals. Replacing original goals with
virtual goals generated from interaction with a trained dynamics model leads to
a novel relabeling method, \emph{model-based relabeling} (MBR). Based on MBR,
MHER performs both reinforcement learning and supervised learning for efficient
policy improvement. Theoretically, we also prove the supervised part in MHER,
i.e., goal-conditioned supervised learning with MBR data, optimizes a lower
bound on the multi-goal RL objective. Experimental results in several
point-based tasks and simulated robotics environments show that MHER achieves
significantly higher sample efficiency than previous state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Hierarchical Super-Resolution for Scientific Data Reduction and Visualization. (arXiv:2107.00462v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wurster_S/0/1/0/all/0/1">Skylar W. Wurster</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_H/0/1/0/all/0/1">Hanqi Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Peterka_T/0/1/0/all/0/1">Thomas Peterka</a>, <a href="http://arxiv.org/find/eess/1/au:+Raj_M/0/1/0/all/0/1">Mukund Raj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jiayi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00462">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for hierarchical super resolution (SR) using neural
networks on an octree data representation. We train a hierarchy of neural
networks, each capable of 2x upscaling in each spatial dimension between two
levels of detail, and use these networks in tandem to facilitate large scale
factor super resolution, scaling with the number of trained networks. We
utilize these networks in a hierarchical super resolution algorithm that
upscales multiresolution data to a uniform high resolution without introducing
seam artifacts on octree node boundaries. We evaluate application of this
algorithm in a data reduction framework by dynamically downscaling input data
to an octree-based data structure to represent the multiresolution data before
compressing for additional storage reduction. We demonstrate that our approach
avoids seam artifacts common to multiresolution data formats, and show how
neural network super resolution assisted data reduction can preserve global
features better than compressors alone at the same compression ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training. (arXiv:2009.12064v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kitada_S/0/1/0/all/0/1">Shunsuke Kitada</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12064">
                                    <div class="article-summary-box-inner">
                                        <span>Although attention mechanisms have been applied to a variety of deep learning
models and have been shown to improve the prediction performance, it has been
reported to be vulnerable to perturbations to the mechanism. To overcome the
vulnerability to perturbations in the mechanism, we are inspired by adversarial
training (AT), which is a powerful regularization technique for enhancing the
robustness of the models. In this paper, we propose a general training
technique for natural language processing tasks, including AT for attention
(Attention AT) and more interpretable AT for attention (Attention iAT). The
proposed techniques improved the prediction performance and the model
interpretability by exploiting the mechanisms with AT. In particular, Attention
iAT boosts those advantages by introducing adversarial perturbation, which
enhances the difference in the attention of the sentences. Evaluation
experiments with ten open datasets revealed that AT for attention mechanisms,
especially Attention iAT, demonstrated (1) the best performance in nine out of
ten tasks and (2) more interpretable attention (i.e., the resulting attention
correlated more strongly with gradient-based word importance) for all tasks.
Additionally, the proposed techniques are (3) much less dependent on
perturbation size in AT. Our code is available at
https://github.com/shunk031/attention-meets-perturbation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spotting adversarial samples for speaker verification by neural vocoders. (arXiv:2107.00309v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_P/0/1/0/all/0/1">Po-chun Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Ji Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanshan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jian Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00309">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speaker verification (ASV), one of the most important technology
for biometric identification, has been widely adopted in security-critic
applications, including transaction authentication and access control. However,
previous works have shown ASV is seriously vulnerable to recently emerged
adversarial attacks, yet effective countermeasures against them are limited. In
this paper, we adopt neural vocoders to spot adversarial samples for ASV. We
use neural vocoder to re-synthesize audio and find that the difference between
the ASV scores for the original and re-synthesized audio is a good indicator to
distinguish genuine and adversarial samples. As the very beginning work in this
direction of detecting adversarial samples for ASV, there is no reliable
baseline for comparison. So we first implement Griffin-Lim for detection and
set it as our baseline. The proposed method accomplishes effective detection
performance and outperforms all the baselines in all the settings. We also show
the neural vocoder adopted in the detection framework is dataset independent.
Our codes will be made open-source for future works to do comparison.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BASGD: Buffered Asynchronous SGD for Byzantine Learning. (arXiv:2003.00937v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Rui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wu-Jun Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00937">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed learning has become a hot research topic, due to its wide
application in cluster-based large-scale learning, federated learning, edge
computing and so on. Most distributed learning methods assume no error and
attack on the workers. However, many unexpected cases, such as communication
error and even malicious attack, may happen in real applications. Hence,
Byzantine learning (BL), which refers to distributed learning with attack or
error, has recently attracted much attention. Most existing BL methods are
synchronous, which will result in slow convergence when there exist
heterogeneous workers. Furthermore, in some applications like federated
learning and edge computing, synchronization cannot even be performed most of
the time due to the online workers (clients or edge servers). Hence,
asynchronous BL (ABL) is more general and practical than synchronous BL (SBL).
To the best of our knowledge, there exist only two ABL methods. One of them
cannot resist malicious attack. The other needs to store some training
instances on the server, which has the privacy leak problem. In this paper, we
propose a novel method, called buffered asynchronous stochastic gradient
descent (BASGD), for BL. BASGD is an asynchronous method. Furthermore, BASGD
has no need to store any training instances on the server, and hence can
preserve privacy in ABL. BASGD is theoretically proved to have the ability of
resisting against error and malicious attack. Moreover, BASGD has a similar
theoretical convergence rate to that of vanilla asynchronous SGD (ASGD), with
an extra constant variance. Empirical results show that BASGD can significantly
outperform vanilla ASGD and other ABL baselines, when there exists error or
attack on workers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological classification of compact and extended radio galaxies using convolutional neural networks and data augmentation techniques. (arXiv:2107.00385v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Maslej_Kresnakova_V/0/1/0/all/0/1">Viera Maslej-Kre&#x161;&#x148;&#xe1;kov&#xe1;</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bouchefry_K/0/1/0/all/0/1">Khadija El Bouchefry</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Butka_P/0/1/0/all/0/1">Peter Butka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00385">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques have been increasingly used in astronomical
applications and have proven to successfully classify objects in image data
with high accuracy. The current work uses archival data from the Faint Images
of the Radio Sky at Twenty Centimeters (FIRST) to classify radio galaxies into
four classes: Fanaroff-Riley Class I (FRI), Fanaroff-Riley Class II (FRII),
Bent-Tailed (BENT), and Compact (COMPT). The model presented in this work is
based on Convolutional Neural Networks (CNNs). The proposed architecture
comprises three parallel blocks of convolutional layers combined and processed
for final classification by two feed-forward layers. Our model classified
selected classes of radio galaxy sources on an independent testing subset with
an average of 96\% for precision, recall, and F1 score. The best selected
augmentation techniques were rotations, horizontal or vertical flips, and
increase of brightness. Shifts, zoom and decrease of brightness worsened the
performance of the model. The current results show that model developed in this
work is able to identify different morphological classes of radio galaxies with
a high efficiency and performance</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Learning with Missing Values Imputation. (arXiv:2106.01708v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Buliao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yunhui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1">Muhammad Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01708">
                                    <div class="article-summary-box-inner">
                                        <span>Incomplete instances with various missing attributes in many real-world
applications have brought challenges to the classification tasks. Missing
values imputation methods are often employed to replace the missing values with
substitute values. However, this process often separates the imputation and
classification, which may lead to inferior performance since label information
are often ignored during imputation. Moreover, traditional methods may rely on
improper assumptions to initialize the missing values, whereas the
unreliability of such initialization might lead to inferior performance. To
address these problems, a novel semi-supervised conditional normalizing flow
(SSCFlow) is proposed in this paper. SSCFlow explicitly utilizes the label
information to facilitate the imputation and classification simultaneously by
estimating the conditional distribution of incomplete instances with a novel
semi-supervised normalizing flow. Moreover, SSCFlow treats the initialized
missing values as corrupted initial imputation and iteratively reconstructs
their latent representations with an overcomplete denoising autoencoder to
approximate their true conditional distribution. Experiments on real-world
datasets demonstrate the robustness and effectiveness of the proposed
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse GCA and Thresholded Gradient Descent. (arXiv:2107.00371v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Sheng Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_Z/0/1/0/all/0/1">Zongming Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00371">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized correlation analysis (GCA) is concerned with uncovering linear
relationships across multiple datasets. It generalizes canonical correlation
analysis that is designed for two datasets. We study sparse GCA when there are
potentially multiple generalized correlation tuples in data and the loading
matrix has a small number of nonzero rows. It includes sparse CCA and sparse
PCA of correlation matrices as special cases. We first formulate sparse GCA as
generalized eigenvalue problems at both population and sample levels via a
careful choice of normalization constraints. Based on a Lagrangian form of the
sample optimization problem, we propose a thresholded gradient descent
algorithm for estimating GCA loading vectors and matrices in high dimensions.
We derive tight estimation error bounds for estimators generated by the
algorithm with proper initialization. We also demonstrate the prowess of the
algorithm on a number of synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Visual Exploration of Relations in Data Sets. (arXiv:1905.02515v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1">Kai Puolam&#xe4;ki</a>, <a href="http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1">Emilia Oikarinen</a>, <a href="http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1">Andreas Henelius</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.02515">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient explorative data analysis systems must take into account both what
a user knows and wants to know. This paper proposes a principled framework for
interactive visual exploration of relations in data, through views most
informative given the user&#x27;s current knowledge and objectives. The user can
input pre-existing knowledge of relations in the data and also formulate
specific exploration interests, which are then taken into account in the
exploration. The idea is to steer the exploration process towards the interests
of the user, instead of showing uninteresting or already known relations. The
user&#x27;s knowledge is modelled by a distribution over data sets parametrised by
subsets of rows and columns of data, called tile constraints. We provide a
computationally efficient implementation of this concept based on constrained
randomisation. Furthermore, we describe a novel dimensionality reduction method
for finding the views most informative to the user, which at the limit of no
background knowledge and with generic objectives reduces to PCA. We show that
the method is suitable for interactive use and is robust to noise, outperforms
standard projection pursuit visualisation methods, and gives understandable and
useful results in analysis of real-world data. We provide an open-source
implementation of the framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Never Go Full Batch (in Stochastic Convex Optimization). (arXiv:2107.00469v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Amir_I/0/1/0/all/0/1">Idan Amir</a>, <a href="http://arxiv.org/find/math/1/au:+Carmon_Y/0/1/0/all/0/1">Yair Carmon</a>, <a href="http://arxiv.org/find/math/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/math/1/au:+Livni_R/0/1/0/all/0/1">Roi Livni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00469">
                                    <div class="article-summary-box-inner">
                                        <span>We study the generalization performance of $\text{full-batch}$ optimization
algorithms for stochastic convex optimization: these are first-order methods
that only access the exact gradient of the empirical risk (rather than
gradients with respect to individual data points), that include a wide range of
algorithms such as gradient descent, mirror descent, and their regularized
and/or accelerated variants. We provide a new separation result showing that,
while algorithms such as stochastic gradient descent can generalize and
optimize the population risk to within $\epsilon$ after $O(1/\epsilon^2)$
iterations, full-batch methods either need at least $\Omega(1/\epsilon^4)$
iterations or exhibit a dimension-dependent sample complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auto-encoding brain networks with applications to analyzing large-scale brain imaging datasets. (arXiv:1911.02728v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_M/0/1/0/all/0/1">Meimei Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1">David B. Dunson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.02728">
                                    <div class="article-summary-box-inner">
                                        <span>There has been huge interest in studying human brain connectomes inferred
from different imaging modalities and exploring their relationship with human
traits, such as cognition. Brain connectomes are usually represented as
networks, with nodes corresponding to different regions of interest (ROIs) and
edges to connection strengths between ROIs. Due to the high-dimensionality and
non-Euclidean nature of networks, it is challenging to depict their population
distribution and relate them to human traits. Current approaches focus on
summarizing the network using either pre-specified topological features or
principal components analysis (PCA). In this paper, building on recent advances
in deep learning, we develop a nonlinear latent factor model to characterize
the population distribution of brain graphs and infer the relationships between
brain structural connectomes and human traits. We refer to our method as Graph
AuTo-Encoding (GATE). We applied GATE to two large-scale brain imaging
datasets, the Adolescent Brain Cognitive Development (ABCD) study and the Human
Connectome Project (HCP) for adults, to understand the structural brain
connectome and its relationship with cognition. Numerical results demonstrate
huge advantages of GATE over competitors in terms of prediction accuracy,
statistical inference and computing efficiency. We found that structural
connectomes have a stronger association with a wide range of human cognitive
traits than was apparent using previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential prediction under log-loss and misspecification. (arXiv:2102.00050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feder_M/0/1/0/all/0/1">Meir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Polyanskiy_Y/0/1/0/all/0/1">Yury Polyanskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00050">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the question of sequential prediction under the log-loss in terms
of cumulative regret. Namely, given a hypothesis class of distributions,
learner sequentially predicts the (distribution of the) next letter in sequence
and its performance is compared to the baseline of the best constant predictor
from the hypothesis class. The well-specified case corresponds to an additional
assumption that the data-generating distribution belongs to the hypothesis
class as well. Here we present results in the more general misspecified case.
Due to special properties of the log-loss, the same problem arises in the
context of competitive-optimality in density estimation, and model selection.
For the $d$-dimensional Gaussian location hypothesis class, we show that
cumulative regrets in the well-specified and misspecified cases asymptotically
coincide. In other words, we provide an $o(1)$ characterization of the
distribution-free (or PAC) regret in this case -- the first such result as far
as we know. We recall that the worst-case (or individual-sequence) regret in
this case is larger by an additive constant ${d\over 2} + o(1)$. Surprisingly,
neither the traditional Bayesian estimators, nor the Shtarkov&#x27;s normalized
maximum likelihood achieve the PAC regret and our estimator requires special
&quot;robustification&quot; against heavy-tailed data. In addition, we show two general
results for misspecified regret: the existence and uniqueness of the optimal
estimator, and the bound sandwiching the misspecified regret between
well-specified regrets with (asymptotically) close hypotheses classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Consistency-Based Loss for Deep Odometry Through Uncertainty Propagation. (arXiv:2107.00366v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damirchi_H/0/1/0/all/0/1">Hamed Damirchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khorrambakht_R/0/1/0/all/0/1">Rooholla Khorrambakht</a>, <a href="http://arxiv.org/find/cs/1/au:+Taghirad_H/0/1/0/all/0/1">Hamid D. Taghirad</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshiri_B/0/1/0/all/0/1">Behzad Moshiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00366">
                                    <div class="article-summary-box-inner">
                                        <span>The incremental poses computed through odometry can be integrated over time
to calculate the pose of a device with respect to an initial location. The
resulting global pose may be used to formulate a second, consistency based,
loss term in a deep odometry setting. In such cases where multiple losses are
imposed on a network, the uncertainty over each output can be derived to weigh
the different loss terms in a maximum likelihood setting. However, when
imposing a constraint on the integrated transformation, due to how only
odometry is estimated at each iteration of the algorithm, there is no
information about the uncertainty associated with the global pose to weigh the
global loss term. In this paper, we associate uncertainties with the output
poses of a deep odometry network and propagate the uncertainties through each
iteration. Our goal is to use the estimated covariance matrix at each
incremental step to weigh the loss at the corresponding step while weighting
the global loss term using the compounded uncertainty. This formulation
provides an adaptive method to weigh the incremental and integrated loss terms
against each other, noting the increase in uncertainty as new estimates arrive.
We provide quantitative and qualitative analysis of pose estimates and show
that our method surpasses the accuracy of the state-of-the-art Visual Odometry
approaches. Then, uncertainty estimates are evaluated and comparisons against
fixed baselines are provided. Finally, the uncertainty values are used in a
realistic example to show the effectiveness of uncertainty quantification for
localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Well-calibrated prediction intervals for regression problems. (arXiv:2107.00363v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dewolf_N/0/1/0/all/0/1">Nicolas Dewolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Baets_B/0/1/0/all/0/1">Bernard De Baets</a>, <a href="http://arxiv.org/find/stat/1/au:+Waegeman_W/0/1/0/all/0/1">Willem Waegeman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00363">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, various methods have been proposed for estimating
prediction intervals in regression settings, including Bayesian methods,
ensemble methods, direct interval estimation methods and conformal prediction
methods. An important issue is the calibration of these methods: the generated
prediction intervals should have a predefined coverage level, without being
overly conservative. In this work, we review the above four classes of methods
from a conceptual and experimental point of view. Results on benchmark data
sets from various domains highlight large fluctuations in performance from one
data set to another. These observations can be attributed to the violation of
certain assumptions that are inherent to some classes of methods. We illustrate
how conformal prediction can be used as a general calibration procedure for
methods that deliver poor results without a calibration step.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mesh-based graph convolutional neural network models of processes with complex initial states. (arXiv:2107.00090v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frankel_A/0/1/0/all/0/1">Ari Frankel</a>, <a href="http://arxiv.org/find/cs/1/au:+Safta_C/0/1/0/all/0/1">Cosmin Safta</a>, <a href="http://arxiv.org/find/cs/1/au:+Alleman_C/0/1/0/all/0/1">Coleman Alleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1">Reese Jones</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00090">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the evolution of a representative sample of a material with
microstructure is a fundamental problem in homogenization. In this work we
propose a graph convolutional neural network that utilizes the discretized
representation of the initial microstructure directly, without segmentation or
clustering. Compared to feature-based and pixel-based convolutional neural
network models, the proposed method has a number of advantages: (a) it is deep
in that it does not require featurization but can benefit from it, (b) it has a
simple implementation with standard convolutional filters and layers, (c) it
works natively on unstructured and structured grid data without interpolation
(unlike pixel-based convolutional neural networks), and (d) it preserves
rotational invariance like other graph-based convolutional neural networks. We
demonstrate the performance of the proposed network and compare it to
traditional pixel-based convolution neural network models and feature-based
graph convolutional neural networks on three large datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Metadata Extraction Incorporating Visual Features from Scanned Electronic Theses and Dissertations. (arXiv:2107.00516v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1">Muntabir Hasan Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanetti_H/0/1/0/all/0/1">Himarsha R. Jayanetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingram_W/0/1/0/all/0/1">William A. Ingram</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1">Edward A. Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00516">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic Theses and Dissertations (ETDs) contain domain knowledge that can
be used for many digital library tasks, such as analyzing citation networks and
predicting research trends. Automatic metadata extraction is important to build
scalable digital library search engines. Most existing methods are designed for
born-digital documents, so they often fail to extract metadata from scanned
documents such as for ETDs. Traditional sequence tagging methods mainly rely on
text-based features. In this paper, we propose a conditional random field (CRF)
model that combines text-based and visual features. To verify the robustness of
our model, we extended an existing corpus and created a new ground truth corpus
consisting of 500 ETD cover pages with human validated metadata. Our
experiments show that CRF with visual features outperformed both a heuristic
and a CRF model with only text-based features. The proposed model achieved
81.3%-96% F1 measure on seven metadata fields. The data and source code are
publicly available on Google Drive (https://tinyurl.com/y8kxzwrp) and a GitHub
repository (https://github.com/lamps-lab/ETDMiner/tree/master/etd_crf),
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compression Implies Generalization. (arXiv:2106.07989v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gronlund_A/0/1/0/all/0/1">Allan Gr&#xf8;nlund</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogsgaard_M/0/1/0/all/0/1">Mikael H&#xf8;gsgaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamma_L/0/1/0/all/0/1">Lior Kamma</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07989">
                                    <div class="article-summary-box-inner">
                                        <span>Explaining the surprising generalization performance of deep neural networks
is an active and important line of research in theoretical machine learning.
Influential work by Arora et al. (ICML&#x27;18) showed that, noise stability
properties of deep nets occurring in practice can be used to provably compress
model representations. They then argued that the small representations of
compressed networks imply good generalization performance albeit only of the
compressed nets. Extending their compression framework to yield generalization
bounds for the original uncompressed networks remains elusive.

Our main contribution is the establishment of a compression-based framework
for proving generalization bounds. The framework is simple and powerful enough
to extend the generalization bounds by Arora et al. to also hold for the
original network. To demonstrate the flexibility of the framework, we also show
that it allows us to give simple proofs of the strongest known generalization
bounds for other popular machine learning models, namely Support Vector
Machines and Boosting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circuit Complexity of Visual Search. (arXiv:2107.00223v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uchizawa_K/0/1/0/all/0/1">Kei Uchizawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_H/0/1/0/all/0/1">Haruki Abe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00223">
                                    <div class="article-summary-box-inner">
                                        <span>We study computational hardness of feature and conjunction search through the
lens of circuit complexity. Let $x &#x3D; (x_1, ... , x_n)$ (resp., $y &#x3D; (y_1, ... ,
y_n)$) be Boolean variables each of which takes the value one if and only if a
neuron at place $i$ detects a feature (resp., another feature). We then simply
formulate the feature and conjunction search as Boolean functions ${\rm
FTR}_n(x) &#x3D; \bigvee_{i&#x3D;1}^n x_i$ and ${\rm CONJ}_n(x, y) &#x3D; \bigvee_{i&#x3D;1}^n x_i
\wedge y_i$, respectively. We employ a threshold circuit or a discretized
circuit (such as a sigmoid circuit or a ReLU circuit with discretization) as
our models of neural networks, and consider the following four computational
resources: [i] the number of neurons (size), [ii] the number of levels (depth),
[iii] the number of active neurons outputting non-zero values (energy), and
[iv] synaptic weight resolution (weight).

We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy
$e$ and weight $w$ satisfies $\log rk(M_C) \le ed (\log s + \log w + \log n)$,
where $rk(M_C)$ is the rank of the communication matrix $M_C$ of a
$2n$-variable Boolean function that $C$ computes. Since ${\rm CONJ}_n$ has rank
$2^n$, we have $n \le ed (\log s + \log w + \log n)$. Thus, an exponential
lower bound on the size of even sublinear-depth threshold circuits exists if
the energy and weight are sufficiently small. Since ${\rm FTR}_n$ is computable
independently of $n$, our result suggests that computational capacity for the
feature and conjunction search are different. We also show that the inequality
is tight up to a constant factor if $ed &#x3D; o(n/ \log n)$. We next show that a
similar inequality holds for any discretized circuit. Thus, if we regard the
number of gates outputting non-zero values as a measure for sparse activity,
our results suggest that larger depth helps neural networks to acquire sparse
activity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotically Exact and Fast Gaussian Copula Models for Imputation of Mixed Data Types. (arXiv:2102.02642v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Christoffersen_B/0/1/0/all/0/1">Benjamin Christoffersen</a>, <a href="http://arxiv.org/find/stat/1/au:+Clements_M/0/1/0/all/0/1">Mark Clements</a>, <a href="http://arxiv.org/find/stat/1/au:+Humphreys_K/0/1/0/all/0/1">Keith Humphreys</a>, <a href="http://arxiv.org/find/stat/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02642">
                                    <div class="article-summary-box-inner">
                                        <span>Missing values with mixed data types is a common problem in a large number of
machine learning applications such as processing of surveys and in different
medical applications. Recently, Gaussian copula models have been suggested as a
means of performing imputation of missing values using a probabilistic
framework. While the present Gaussian copula models have shown to yield state
of the art performance, they have two limitations: they are based on an
approximation that is fast but may be imprecise and they do not support
unordered multinomial variables. We address the first limitation using direct
and arbitrarily precise approximations both for model estimation and imputation
by using randomized quasi-Monte Carlo procedures. The method we provide has
lower errors for the estimated model parameters and the imputed values,
compared to previously proposed methods. We also extend the previous Gaussian
copula models to include unordered multinomial variables in addition to the
present support of ordinal, binary, and continuous variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hsiang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1">Mario Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1">Flavio P. Calmon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04788">
                                    <div class="article-summary-box-inner">
                                        <span>Disparate treatment occurs when a machine learning model yields different
decisions for individuals based on a sensitive attribute (e.g., age, sex). In
domains where prediction accuracy is paramount, it could potentially be
acceptable to fit a model which exhibits disparate treatment. To evaluate the
effect of disparate treatment, we compare the performance of split classifiers
(i.e., classifiers trained and deployed separately on each group) with
group-blind classifiers (i.e., classifiers which do not use a sensitive
attribute). We introduce the benefit-of-splitting for quantifying the
performance improvement by splitting classifiers. Computing the
benefit-of-splitting directly from its definition could be intractable since it
involves solving optimization problems over an infinite-dimensional functional
space. Under different performance measures, we (i) prove an equivalent
expression for the benefit-of-splitting which can be efficiently computed by
solving small-scale convex programs; (ii) provide sharp upper and lower bounds
for the benefit-of-splitting which reveal precise conditions where a
group-blind classifier will always suffer from a non-trivial performance gap
from the split classifiers. In the finite sample regime, splitting is not
necessarily beneficial and we provide data-dependent bounds to understand this
effect. Finally, we validate our theoretical results through numerical
experiments on both synthetic and real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overhead-MNIST: Machine Learning Baselines for Image Classification. (arXiv:2107.00436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Larsen_E/0/1/0/all/0/1">Erik Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+MacVittie_K/0/1/0/all/0/1">Korey MacVittie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lilly_J/0/1/0/all/0/1">John Lilly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00436">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-three machine learning algorithms were trained then scored to
establish baseline comparison metrics and to select an image classification
algorithm worthy of embedding into mission-critical satellite imaging systems.
The Overhead-MNIST dataset is a collection of satellite images similar in style
to the ubiquitous MNIST hand-written digits found in the machine learning
literature. The CatBoost classifier, Light Gradient Boosting Machine, and
Extreme Gradient Boosting models produced the highest accuracies, Areas Under
the Curve (AUC), and F1 scores in a PyCaret general comparison. Separate
evaluations showed that a deep convolutional architecture was the most
promising. We present results for the overall best performing algorithm as a
baseline for edge deployability and future performance improvement: a
convolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen
test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focal Self-attention for Local-Global Interactions in Vision Transformers. (arXiv:2107.00641v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformer and its variants have shown great promise on
various computer vision tasks. The ability of capturing short- and long-range
visual dependencies through self-attention is arguably the main source for the
success. But it also brings challenges due to quadratic computational overhead,
especially for the high-resolution vision tasks (e.g., object detection). In
this paper, we present focal self-attention, a new mechanism that incorporates
both fine-grained local and coarse-grained global interactions. Using this new
mechanism, each token attends the closest surrounding tokens at fine
granularity but the tokens far away at coarse granularity, and thus can capture
both short- and long-range visual dependencies efficiently and effectively.
With focal self-attention, we propose a new variant of Vision Transformer
models, called Focal Transformer, which achieves superior performance over the
state-of-the-art vision Transformers on a range of public image classification
and object detection benchmarks. In particular, our Focal Transformer models
with a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8
Top-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.
Using Focal Transformers as the backbones, we obtain consistent and substantial
improvements over the current state-of-the-art Swin Transformers for 6
different object detection methods trained with standard 1x and 3x schedules.
Our largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs
on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,
creating new SoTA on three of the most challenging computer vision tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Diabetic Retinopathy Detection and Retinal Image Generation. (arXiv:2107.00296v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Niu_Y/0/1/0/all/0/1">Yuhao Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_L/0/1/0/all/0/1">Lin Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yitian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00296">
                                    <div class="article-summary-box-inner">
                                        <span>Though deep learning has shown successful performance in classifying the
label and severity stage of certain diseases, most of them give few
explanations on how to make predictions. Inspired by Koch&#x27;s Postulates, the
foundation in evidence-based medicine (EBM) to identify the pathogen, we
propose to exploit the interpretability of deep learning application in medical
diagnosis. By determining and isolating the neuron activation patterns on which
diabetic retinopathy (DR) detector relies to make decisions, we demonstrate the
direct relation between the isolated neuron activation and lesions for a
pathological explanation. To be specific, we first define novel pathological
descriptors using activated neurons of the DR detector to encode both spatial
and appearance information of lesions. Then, to visualize the symptom encoded
in the descriptor, we propose Patho-GAN, a new network to synthesize medically
plausible retinal images. By manipulating these descriptors, we could even
arbitrarily control the position, quantity, and categories of generated
lesions. We also show that our synthesized images carry the symptoms directly
related to diabetic retinopathy diagnosis. Our generated images are both
qualitatively and quantitatively superior to the ones by previous methods.
Besides, compared to existing methods that take hours to generate an image, our
second level speed endows the potential to be an effective solution for data
augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-facet Contextual Bandits: A Neural Network Perspective. (arXiv:2106.03039v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ban_Y/0/1/0/all/0/1">Yikun Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingrui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cook_C/0/1/0/all/0/1">Curtiss B. Cook</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03039">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual multi-armed bandit has shown to be an effective tool in
recommender systems. In this paper, we study a novel problem of multi-facet
bandits involving a group of bandits, each characterizing the users&#x27; needs from
one unique aspect. In each round, for the given user, we need to select one arm
from each bandit, such that the combination of all arms maximizes the final
reward. This problem can find immediate applications in E-commerce, healthcare,
etc. To address this problem, we propose a novel algorithm, named MuFasa, which
utilizes an assembled neural network to jointly learn the underlying reward
functions of multiple bandits. It estimates an Upper Confidence Bound (UCB)
linked with the expected reward to balance between exploitation and
exploration. Under mild assumptions, we provide the regret analysis of MuFasa.
It can achieve the near-optimal $\widetilde{ \mathcal{O}}((K+1)\sqrt{T})$
regret bound where $K$ is the number of bandits and $T$ is the number of played
rounds. Furthermore, we conduct extensive experiments to show that MuFasa
outperforms strong baselines on real-world data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_L/0/1/0/all/0/1">Lu Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00197">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to train a strong classifier using limited
labeled examples. Many existing works take the meta-learning approach, sampling
few-shot tasks in turn and optimizing the few-shot learner&#x27;s performance on
classifying the query examples. In this paper, we point out two potential
weaknesses of this approach. First, the sampled query examples may not provide
sufficient supervision for the few-shot learner. Second, the effectiveness of
meta-learning diminishes sharply with increasing shots (i.e., the number of
training examples per class). To resolve these issues, we propose a novel
objective to directly train the few-shot learner to perform like a strong
classifier. Concretely, we associate each sampled few-shot task with a strong
classifier, which is learned with ample labeled examples. The strong classifier
has a better generalization ability and we use it to supervise the few-shot
learner. We present an efficient way to construct the strong classifier, making
our proposed objective an easily plug-and-play term to existing meta-learning
based FSL methods. We validate our approach in combinations with many
representative meta-learning methods. On several benchmark datasets including
miniImageNet and tiredImageNet, our approach leads to a notable improvement
across a variety of tasks. More importantly, with our approach, meta-learning
based FSL methods can consistently outperform non-meta-learning based ones,
even in a many-shot setting, greatly strengthening their applicability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imitation Learning from Pixel-Level Demonstrations by HashReward. (arXiv:1909.03773v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xin-Qiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yao-Xiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03773">
                                    <div class="article-summary-box-inner">
                                        <span>One of the key issues for imitation learning lies in making policy learned
from limited samples to generalize well in the whole state-action space. This
problem is much more severe in high-dimensional state environments, such as
game playing with raw pixel inputs. Under this situation, even state-of-the-art
adversary-based imitation learning algorithms fail. Through empirical studies,
we find that the main cause lies in the failure of training a powerful
discriminator to generate meaningful rewards in high-dimensional environments.
Although it seems that dimensionality reduction can help, a straightforward
application of off-the-shelf methods cannot achieve good performance. In this
work, we show in theory that the balance between dimensionality reduction and
discriminative training is essential for effective learning. To achieve this
target, we propose HashReward, which utilizes the idea of supervised hashing to
realize such an ideal balance. Experimental results show that HashReward could
outperform state-of-the-art methods for a large gap under the challenging
high-dimensional environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Biased Graph Neural Network Sampler with Near-Optimal Regret. (arXiv:2103.01089v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1">David Wipf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Q/0/1/0/all/0/1">Quan Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Le Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01089">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNN) have recently emerged as a vehicle for applying
deep network architectures to graph and relational data. However, given the
increasing size of industrial datasets, in many practical situations the
message passing computations required for sharing information across GNN layers
are no longer scalable. Although various sampling methods have been introduced
to approximate full-graph training within a tractable budget, there remain
unresolved complications such as high variances and limited theoretical
guarantees. To address these issues, we build upon existing work and treat GNN
neighbor sampling as a multi-armed bandit problem but with a newly-designed
reward function that introduces some degree of bias designed to reduce variance
and avoid unstable, possibly-unbounded pay outs. And unlike prior bandit-GNN
use cases, the resulting policy leads to near-optimal regret while accounting
for the GNN training dynamics introduced by SGD. From a practical standpoint,
this translates into lower variance estimates and competitive or superior test
accuracy across several benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Transfer across Visual and Dynamics Domain Gaps via Iterative Grounding. (arXiv:2107.00339v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Grace Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Linghan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Youngwoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1">Joseph J. Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00339">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to transfer a policy from one environment to another is a
promising avenue for efficient robot learning in realistic settings where task
supervision is not available. This can allow us to take advantage of
environments well suited for training, such as simulators or laboratories, to
learn a policy for a real robot in a home or office. To succeed, such policy
transfer must overcome both the visual domain gap (e.g. different illumination
or background) and the dynamics domain gap (e.g. different robot calibration or
modelling error) between source and target environments. However, prior policy
transfer approaches either cannot handle a large domain gap or can only address
one type of domain gap at a time. In this paper, we propose a novel policy
transfer method with iterative &quot;environment grounding&quot;, IDAPT, that alternates
between (1) directly minimizing both visual and dynamics domain gaps by
grounding the source environment in the target environment domains, and (2)
training a policy on the grounded source environment. This iterative training
progressively aligns the domains between the two environments and adapts the
policy to the target environment. Once trained, the policy can be directly
executed on the target environment. The empirical results on locomotion and
robotic manipulation tasks demonstrate that our approach can effectively
transfer a policy across visual and dynamics domain gaps with minimal
supervision and interaction with the target environment. Videos and code are
available at https://clvrai.com/idapt .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When does gradient descent with logistic loss find interpolating two-layer networks?. (arXiv:2012.02409v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02409">
                                    <div class="article-summary-box-inner">
                                        <span>We study the training of finite-width two-layer smoothed ReLU networks for
binary classification using the logistic loss. We show that gradient descent
drives the training loss to zero if the initial loss is small enough. When the
data satisfies certain cluster and separation conditions and the network is
wide enough, we show that one step of gradient descent reduces the loss
sufficiently that the first result applies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Difference Uncertainties as a Signal for Exploration. (arXiv:2010.02255v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1">Sebastian Flennerhag</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jane X. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1">Pablo Sprechmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Visin_F/0/1/0/all/0/1">Francesco Visin</a>, <a href="http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1">Alexandre Galashov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapturowski_S/0/1/0/all/0/1">Steven Kapturowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Borsa_D/0/1/0/all/0/1">Diana L. Borsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1">Nicolas Heess</a>, <a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1">Andre Barreto</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02255">
                                    <div class="article-summary-box-inner">
                                        <span>An effective approach to exploration in reinforcement learning is to rely on
an agent&#x27;s uncertainty over the optimal policy, which can yield near-optimal
exploration strategies in tabular settings. However, in non-tabular settings
that involve function approximators, obtaining accurate uncertainty estimates
is almost as challenging a problem. In this paper, we highlight that value
estimates are easily biased and temporally inconsistent. In light of this, we
propose a novel method for estimating uncertainty over the value function that
relies on inducing a distribution over temporal difference errors. This
exploration signal controls for state-action transitions so as to isolate
uncertainty in value that is due to uncertainty over the agent&#x27;s parameters.
Because our measure of uncertainty conditions on state-action transitions, we
cannot act on this measure directly. Instead, we incorporate it as an intrinsic
reward and treat exploration as a separate learning problem, induced by the
agent&#x27;s temporal difference uncertainties. We introduce a distinct exploration
policy that learns to collect data with high estimated uncertainty, which gives
rise to a curriculum that smoothly changes throughout learning and vanishes in
the limit of perfect value estimates. We evaluate our method on hard
exploration tasks, including Deep Sea and Atari 2600 environments and find that
our proposed form of exploration facilitates both diverse and deep exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Learning for Channel Allocation in IoT Networks over Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game. (arXiv:2003.13314v3 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Leshem_A/0/1/0/all/0/1">Amir Leshem</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13314">
                                    <div class="article-summary-box-inner">
                                        <span>We study a decentralized channel allocation problem in an ad-hoc Internet of
Things network underlaying on the spectrum licensed to a primary cellular
network. In the considered network, the impoverished channel sensing/probing
capability and computational resource on the IoT devices make them difficult to
acquire the detailed Channel State Information (CSI) for the shared multiple
channels. In practice, the unknown patterns of the primary users&#x27; transmission
activities and the time-varying CSI (e.g., due to small-scale fading or device
mobility) also cause stochastic changes in the channel quality. Decentralized
IoT links are thus expected to learn channel conditions online based on partial
observations, while acquiring no information about the channels that they are
not operating on. They also have to reach an efficient, collision-free solution
of channel allocation with limited coordination. Our study maps this problem
into a contextual multi-player, multi-armed bandit game, and proposes a purely
decentralized, three-stage policy learning algorithm through trial-and-error.
Theoretical analyses shows that the proposed scheme guarantees the IoT links to
jointly converge to the social optimal channel allocation with a sub-linear
(i.e., polylogarithmic) regret with respect to the operational time.
Simulations demonstrate that it strikes a good balance between efficiency and
network scalability when compared with the other state-of-the-art decentralized
bandit algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When does gradient descent with logistic loss interpolate using deep networks with smoothed ReLU activations?. (arXiv:2102.04998v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04998">
                                    <div class="article-summary-box-inner">
                                        <span>We establish conditions under which gradient descent applied to fixed-width
deep networks drives the logistic loss to zero, and prove bounds on the rate of
convergence. Our analysis applies for smoothed approximations to the ReLU, such
as Swish and the Huberized ReLU, proposed in previous applied work. We provide
two sufficient conditions for convergence. The first is simply a bound on the
loss at initialization. The second is a data separation condition used in prior
analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information-theoretic Task Selection for Meta-Reinforcement Learning. (arXiv:2011.01054v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1">Ricardo Luna Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonetti_M/0/1/0/all/0/1">Matteo Leonetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01054">
                                    <div class="article-summary-box-inner">
                                        <span>In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of
tasks to prepare for and learn faster in new, unseen, but related tasks. The
training tasks are usually hand-crafted to be representative of the expected
distribution of test tasks and hence all used in training. We show that given a
set of training tasks, learning can be both faster and more effective (leading
to better performance in the test tasks), if the training tasks are
appropriately selected. We propose a task selection algorithm,
Information-Theoretic Task Selection (ITTS), based on information theory, which
optimizes the set of tasks used for training in meta-RL, irrespectively of how
they are generated. The algorithm establishes which training tasks are both
sufficiently relevant for the test tasks, and different enough from one
another. We reproduce different meta-RL experiments from the literature and
show that ITTS improves the final performance in all of them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08812">
                                    <div class="article-summary-box-inner">
                                        <span>While theoretically appealing, the application of the Wasserstein distance to
large-scale machine learning problems has been hampered by its prohibitive
computational cost. The sliced Wasserstein distance and its variants improve
the computational efficiency through the random projection, yet they suffer
from low accuracy if the number of projections is not sufficiently large,
because the majority of projections result in trivially small values. In this
work, we propose a new family of distance metrics, called augmented sliced
Wasserstein distances (ASWDs), constructed by first mapping samples to
higher-dimensional hypersurfaces parameterized by neural networks. It is
derived from a key observation that (random) linear projections of samples
residing on these hypersurfaces would translate to much more flexible nonlinear
projections in the original sample space, so they can capture complex
structures of the data distribution. We show that the hypersurfaces can be
optimized by gradient ascent efficiently. We provide the condition under which
the ASWD is a valid metric and show that this can be obtained by an injective
neural network architecture. Numerical results demonstrate that the ASWD
significantly outperforms other Wasserstein variants for both synthetic and
real-world problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An error analysis of generative adversarial networks for learning distributions. (arXiv:2105.13010v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yunfei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13010">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies how well generative adversarial networks (GANs) learn
probability distributions from finite samples. Our main results establish the
convergence rates of GANs under a collection of integral probability metrics
defined through H\&quot;older classes, including the Wasserstein distance as a
special case. We also show that GANs are able to adaptively learn data
distributions with low-dimensional structures or have H\&quot;older densities, when
the network architectures are chosen properly. In particular, for distributions
concentrated around a low-dimensional set, we show that the learning rates of
GANs do not depend on the high ambient dimension, but on the lower intrinsic
dimension. Our analysis is based on a new oracle inequality decomposing the
estimation error into the generator and discriminator approximation error and
the statistical error, which may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive Modeling in the Presence of Nuisance-Induced Spurious Correlations. (arXiv:2107.00520v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1">Aahlad Puli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lily H. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Oermann_E/0/1/0/all/0/1">Eric K. Oermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1">Rajesh Ranganath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00520">
                                    <div class="article-summary-box-inner">
                                        <span>Deep predictive models often make use of spurious correlations between the
label and the covariates that differ between training and test distributions.
In many classification tasks, spurious correlations are induced by a changing
relationship between the label and some nuisance variables correlated with the
covariates. For example, in classifying animals in natural images, the
background, which is the nuisance, can predict the type of animal, but this
nuisance label relationship does not always hold. This nuisance-label
relationship does not always hold. We formalize a family of distributions that
only differ in the nuisance-label relationship and and introduce a distribution
where this relationship is broken called the nuisance-randomized distribution.
We introduce a set of predictive models built from the nuisance-randomized
distribution with representations, that when conditioned on, do not correlate
the label and the nuisance. For models in this set, we lower bound the
performance for any member of the family with the mutual information between
the representation and the label under the nuisance-randomized distribution. To
build predictive models that maximize the performance lower bound, we develop
Nuisance-Randomized Distillation (NURD). We evaluate NURD on a synthetic
example, colored-MNIST, and classifying chest X-rays. When using non-lung
patches as the nuisance in classifying chest X-rays, NURD produces models that
predict pneumonia under strong spurious correlations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Anomaly Feature Vectors for Detecting, Classifying and Warning of Outlier Adversarial Examples. (arXiv:2107.00561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manohar_Alers_N/0/1/0/all/0/1">Nelson Manohar-Alers</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ryan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sahib Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jiguo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_A/0/1/0/all/0/1">Atul Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00561">
                                    <div class="article-summary-box-inner">
                                        <span>We present DeClaW, a system for detecting, classifying, and warning of
adversarial inputs presented to a classification neural network. In contrast to
current state-of-the-art methods that, given an input, detect whether an input
is clean or adversarial, we aim to also identify the types of adversarial
attack (e.g., PGD, Carlini-Wagner or clean). To achieve this, we extract
statistical profiles, which we term as anomaly feature vectors, from a set of
latent features. Preliminary findings suggest that AFVs can help distinguish
among several types of adversarial attacks (e.g., PGD versus Carlini-Wagner)
with close to 93% accuracy on the CIFAR-10 dataset. The results open the door
to using AFV-based methods for exploring not only adversarial attack detection
but also classification of the attack type and then design of attack-specific
mitigation strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable nonlinear modelling of multiple time series with invertible neural networks. (arXiv:2107.00391v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lopez_Ramos_L/0/1/0/all/0/1">Luis Miguel Lopez-Ramos</a>, <a href="http://arxiv.org/find/eess/1/au:+Roy_K/0/1/0/all/0/1">Kevin Roy</a>, <a href="http://arxiv.org/find/eess/1/au:+Beferull_Lozano_B/0/1/0/all/0/1">Baltasar Beferull-Lozano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00391">
                                    <div class="article-summary-box-inner">
                                        <span>A method for nonlinear topology identification is proposed, based on the
assumption that a collection of time series are generated in two steps: i) a
vector autoregressive process in a latent space, and ii) a nonlinear,
component-wise, monotonically increasing observation mapping. The latter
mappings are assumed invertible, and are modelled as shallow neural networks,
so that their inverse can be numerically evaluated, and their parameters can be
learned using a technique inspired in deep learning. Due to the function
inversion, the back-propagation step is not straightforward, and this paper
explains the steps needed to calculate the gradients applying implicit
differentiation. Whereas the model explainability is the same as that for
linear VAR processes, preliminary numerical tests show that the prediction
error becomes smaller.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Theoretical Framework for Fast and Accurate Online Decision-Making. (arXiv:1905.11797v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1">Nicol&#xf2; Cesa-Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1">Tommaso R. Cesari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11797">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel theoretical framework for Return On Investment (ROI)
maximization in repeated decision-making. Our setting is motivated by the use
case of companies that regularly receive proposals for technological
innovations and want to quickly decide whether they are worth implementing. We
design an algorithm for learning ROI-maximizing decision-making policies over a
sequence of innovation proposals. Our algorithm provably converges to an
optimal policy in class $\Pi$ at a rate of order
$\min\big\{1/(N\Delta^2),N^{-1/3}\}$, where $N$ is the number of innovations
and $\Delta$ is the suboptimality gap in $\Pi$. A significant hurdle of our
formulation, which sets it aside from other online learning problems such as
bandits, is that running a policy does not provide an unbiased estimate of its
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sequential Design for a Single Time-Series. (arXiv:2102.00102v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Malenica_I/0/1/0/all/0/1">Ivana Malenica</a>, <a href="http://arxiv.org/find/math/1/au:+Bibaut_A/0/1/0/all/0/1">Aurelien Bibaut</a>, <a href="http://arxiv.org/find/math/1/au:+Laan_M/0/1/0/all/0/1">Mark J. van der Laan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00102">
                                    <div class="article-summary-box-inner">
                                        <span>The current work is motivated by the need for robust statistical methods for
precision medicine; as such, we address the need for statistical methods that
provide actionable inference for a single unit at any point in time. We aim to
learn an optimal, unknown choice of the controlled components of the design in
order to optimize the expected outcome; with that, we adapt the randomization
mechanism for future time-point experiments based on the data collected on the
individual over time. Our results demonstrate that one can learn the optimal
rule based on a single sample, and thereby adjust the design at any point t
with valid inference for the mean target parameter. This work provides several
contributions to the field of statistical precision medicine. First, we define
a general class of averages of conditional causal parameters defined by the
current context for the single unit time-series data. We define a nonparametric
model for the probability distribution of the time-series under few
assumptions, and aim to fully utilize the sequential randomization in the
estimation procedure via the double robust structure of the efficient influence
curve of the proposed target parameter. We present multiple
exploration-exploitation strategies for assigning treatment, and methods for
estimating the optimal rule. Lastly, we present the study of the data-adaptive
inference on the mean under the optimal treatment rule, where the target
parameter adapts over time in response to the observed context of the
individual. Our target parameter is pathwise differentiable with an efficient
influence function that is doubly robust - which makes it easier to estimate
than previously proposed variations. We characterize the limit distribution of
our estimator under a Donsker condition expressed in terms of a notion of
bracketing entropy adapted to martingale settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Limit Order Book Recreation Model (LOBRM): An Extended Analysis. (arXiv:2107.00534v1 [q-fin.TR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Shi_Z/0/1/0/all/0/1">Zijian Shi</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Cartlidge_J/0/1/0/all/0/1">John Cartlidge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00534">
                                    <div class="article-summary-box-inner">
                                        <span>The limit order book (LOB) depicts the fine-grained demand and supply
relationship for financial assets and is widely used in market microstructure
studies. Nevertheless, the availability and high cost of LOB data restrict its
wider application. The LOB recreation model (LOBRM) was recently proposed to
bridge this gap by synthesizing the LOB from trades and quotes (TAQ) data.
However, in the original LOBRM study, there were two limitations: (1)
experiments were conducted on a relatively small dataset containing only one
day of LOB data; and (2) the training and testing were performed in a
non-chronological fashion, which essentially re-frames the task as
interpolation and potentially introduces lookahead bias. In this study, we
extend the research on LOBRM and further validate its use in real-world
application scenarios. We first advance the workflow of LOBRM by (1) adding a
time-weighted z-score standardization for the LOB and (2) substituting the
ordinary differential equation kernel with an exponential decay kernel to lower
computation complexity. Experiments are conducted on the extended LOBSTER
dataset in a chronological fashion, as it would be used in a real-world
application. We find that (1) LOBRM with decay kernel is superior to
traditional non-linear models, and module ensembling is effective; (2)
prediction accuracy is negatively related to the volatility of order volumes
resting in the LOB; (3) the proposed sparse encoding method for TAQ exhibits
good generalization ability and can facilitate manifold tasks; and (4) the
influence of stochastic drift on prediction accuracy can be alleviated by
increasing historical samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving black-box optimization in VAE latent space using decoder uncertainty. (arXiv:2107.00096v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Notin_P/0/1/0/all/0/1">Pascal Notin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00096">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization in the latent space of variational autoencoders is a promising
approach to generate high-dimensional discrete objects that maximize an
expensive black-box property (e.g., drug-likeness in molecular generation,
function approximation with arithmetic expressions). However, existing methods
lack robustness as they may decide to explore areas of the latent space for
which no data was available during training and where the decoder can be
unreliable, leading to the generation of unrealistic or invalid objects. We
propose to leverage the epistemic uncertainty of the decoder to guide the
optimization process. This is not trivial though, as a naive estimation of
uncertainty in the high-dimensional and structured settings we consider would
result in high estimator variance. To solve this problem, we introduce an
importance sampling-based estimator that provides more robust estimates of
epistemic uncertainty. Our uncertainty-guided optimization approach does not
require modifications of the model architecture nor the training process. It
produces samples with a better trade-off between black-box objective and
validity of the generated samples, sometimes improving both simultaneously. We
illustrate these advantages across several experimental settings in digit
generation, arithmetic expression approximation and molecule generation for
drug design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Byzantine-Robust Learning on Heterogeneous Datasets via Resampling. (arXiv:2006.09365v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09365">
                                    <div class="article-summary-box-inner">
                                        <span>In Byzantine robust distributed or federated learning, a central server wants
to train a machine learning model over data distributed across multiple
workers. However, a fraction of these workers may deviate from the prescribed
algorithm and send arbitrary messages. While this problem has received
significant attention recently, most current defenses assume that the workers
have identical data. For realistic cases when the data across workers are
heterogeneous (non-iid), we design new attacks which circumvent current
defenses, leading to significant loss of performance. We then propose a simple
resampling scheme that adapts existing robust algorithms to heterogeneous
datasets at a negligible computational cost. We also theoretically and
experimentally validate our approach, showing that combining resampling with
existing robust algorithms is effective against challenging attacks. Our work
is the first to establish guaranteed convergence for the non-iid Byzantine
robust problem under realistic assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Dependency Parsing for Semi-Structured Document Information Extraction. (arXiv:2005.00642v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonseok Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yim_J/0/1/0/all/0/1">Jinyeong Yim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sohee Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minjoon Seo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00642">
                                    <div class="article-summary-box-inner">
                                        <span>Information Extraction (IE) for semi-structured document images is often
approached as a sequence tagging problem by classifying each recognized input
token into one of the IOB (Inside, Outside, and Beginning) categories. However,
such problem setup has two inherent limitations that (1) it cannot easily
handle complex spatial relationships and (2) it is not suitable for highly
structured information, which are nevertheless frequently observed in
real-world document images. To tackle these issues, we first formulate the IE
task as spatial dependency parsing problem that focuses on the relationship
among text tokens in the documents. Under this setup, we then propose SPADE
(SPAtial DEpendency parser) that models highly complex spatial relationships
and an arbitrary number of information layers in the documents in an end-to-end
manner. We evaluate it on various kinds of documents such as receipts, name
cards, forms, and invoices, and show that it achieves a similar or better
performance compared to strong baselines including BERT-based IOB taggger.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Which Echo Chamber? Regions of Attraction in Learning with Decision-Dependent Distributions. (arXiv:2107.00055v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1">Roy Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1">Lillian J. Ratliff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00055">
                                    <div class="article-summary-box-inner">
                                        <span>As data-driven methods are deployed in real-world settings, the processes
that generate the observed data will often react to the decisions of the
learner. For example, a data source may have some incentive for the algorithm
to provide a particular label (e.g. approve a bank loan), and manipulate their
features accordingly. Work in strategic classification and decision-dependent
distributions seeks to characterize the closed-loop behavior of deploying
learning algorithms by explicitly considering the effect of the classifier on
the underlying data distribution. More recently, works in performative
prediction seek to classify the closed-loop behavior by considering general
properties of the mapping from classifier to data distribution, rather than an
explicit form. Building on this notion, we analyze repeated risk minimization
as the perturbed trajectories of the gradient flows of performative risk
minimization. We consider the case where there may be multiple local minimizers
of performative risk, motivated by real world situations where the initial
conditions may have significant impact on the long-term behavior of the system.
As a motivating example, we consider a company whose current employee
demographics affect the applicant pool they interview: the initial demographics
of the company can affect the long-term hiring policies of the company. We
provide sufficient conditions to characterize the region of attraction for the
various equilibria in this settings. Additionally, we introduce the notion of
performative alignment, which provides a geometric condition on the convergence
of repeated risk minimization to performative risk minimizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Asymmetric Learning in POMDPs. (arXiv:2012.15566v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Warrington_A/0/1/0/all/0/1">Andrew Warrington</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavington_J/0/1/0/all/0/1">J. Wilder Lavington</a>, <a href="http://arxiv.org/find/cs/1/au:+Scibior_A/0/1/0/all/0/1">Adam &#x15a;cibior</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1">Mark Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15566">
                                    <div class="article-summary-box-inner">
                                        <span>Policies for partially observed Markov decision processes can be efficiently
learned by imitating policies for the corresponding fully observed Markov
decision processes. Unfortunately, existing approaches for this kind of
imitation learning have a serious flaw: the expert does not know what the
trainee cannot see, and so may encourage actions that are sub-optimal, even
unsafe, under partial information. We derive an objective to instead train the
expert to maximize the expected reward of the imitating agent policy, and use
it to construct an efficient algorithm, adaptive asymmetric DAgger (A2D), that
jointly trains the expert and the agent. We show that A2D produces an expert
policy that the agent can safely imitate, in turn outperforming policies
learned by imitating a fixed expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Markov Decision Process modeled with Bandits for Sequential Decision Making in Linear-flow. (arXiv:2107.00204v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00204">
                                    <div class="article-summary-box-inner">
                                        <span>In membership/subscriber acquisition and retention, we sometimes need to
recommend marketing content for multiple pages in sequence. Different from
general sequential decision making process, the use cases have a simpler flow
where customers per seeing recommended content on each page can only return
feedback as moving forward in the process or dropping from it until a
termination state. We refer to this type of problems as sequential decision
making in linear--flow. We propose to formulate the problem as an MDP with
Bandits where Bandits are employed to model the transition probability matrix.
At recommendation time, we use Thompson sampling (TS) to sample the transition
probabilities and allocate the best series of actions with analytical solution
through exact dynamic programming. The way that we formulate the problem allows
us to leverage TS&#x27;s efficiency in balancing exploration and exploitation and
Bandit&#x27;s convenience in modeling actions&#x27; incompatibility. In the simulation
study, we observe the proposed MDP with Bandits algorithm outperforms
Q-learning with $\epsilon$-greedy and decreasing $\epsilon$, independent
Bandits, and interaction Bandits. We also find the proposed algorithm&#x27;s
performance is the most robust to changes in the across-page interdependence
strength.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Riemannian Manifolds for Geodesic Motion Skills. (arXiv:2106.04315v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1">Hadi Beik-Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1">Georgios Arvanitidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1">Leonel Rozo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04315">
                                    <div class="article-summary-box-inner">
                                        <span>For robots to work alongside humans and perform in unstructured environments,
they must learn new motion skills and adapt them to unseen situations on the
fly. This demands learning models that capture relevant motion patterns, while
offering enough flexibility to adapt the encoded skills to new requirements,
such as dynamic obstacle avoidance. We introduce a Riemannian manifold
perspective on this problem, and propose to learn a Riemannian manifold from
human demonstrations on which geodesics are natural motion skills. We realize
this with a variational autoencoder (VAE) over the space of position and
orientations of the robot end-effector. Geodesic motion skills let a robot plan
movements from and to arbitrary points on the data manifold. They also provide
a straightforward method to avoid obstacles by redefining the ambient metric in
an online fashion. Moreover, geodesics naturally exploit the manifold resulting
from multiple--mode tasks to design motions that were not explicitly
demonstrated previously. We test our learning framework using a 7-DoF robotic
manipulator, where the robot satisfactorily learns and reproduces realistic
skills featuring elaborated motion patterns, avoids previously unseen
obstacles, and generates novel movements in multiple-mode settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth Games: Convergence Analysis under Expected Co-coercivity. (arXiv:2107.00052v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loizou_N/0/1/0/all/0/1">Nicolas Loizou</a>, <a href="http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1">Hugo Berard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1">Ioannis Mitliagkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00052">
                                    <div class="article-summary-box-inner">
                                        <span>Two of the most prominent algorithms for solving unconstrained smooth games
are the classical stochastic gradient descent-ascent (SGDA) and the recently
introduced stochastic consensus optimization (SCO) (Mescheder et al., 2017).
SGDA is known to converge to a stationary point for specific classes of games,
but current convergence analyses require a bounded variance assumption. SCO is
used successfully for solving large-scale adversarial problems, but its
convergence guarantees are limited to its deterministic variant. In this work,
we introduce the expected co-coercivity condition, explain its benefits, and
provide the first last-iterate convergence guarantees of SGDA and SCO under
this condition for solving a class of stochastic variational inequality
problems that are potentially non-monotone. We prove linear convergence of both
methods to a neighborhood of the solution when they use constant step-size, and
we propose insightful stepsize-switching rules to guarantee convergence to the
exact solution. In addition, our convergence guarantees hold under the
arbitrary sampling paradigm, and as such, we give insights into the complexity
of minibatching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Measuring Bias in Image Classification. (arXiv:2107.00360v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaaf_N/0/1/0/all/0/1">Nina Schaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitri_O/0/1/0/all/0/1">Omar de Mitri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hang Beom Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Windberger_A/0/1/0/all/0/1">Alexander Windberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1">Marco F. Huber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00360">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNN) have become de fact state-of-the-art for
the main computer vision tasks. However, due to the complex underlying
structure their decisions are hard to understand which limits their use in some
context of the industrial world. A common and hard to detect challenge in
machine learning (ML) tasks is data bias. In this work, we present a systematic
approach to uncover data bias by means of attribution maps. For this purpose,
first an artificial dataset with a known bias is created and used to train
intentionally biased CNNs. The networks&#x27; decisions are then inspected using
attribution maps. Finally, meaningful metrics are used to measure the
attribution maps&#x27; representativeness with respect to the known bias. The
proposed study shows that some attribution map techniques highlight the
presence of bias in the data better than others and metrics can support the
identification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Generative Network. (arXiv:2106.09330v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nissani_D/0/1/0/all/0/1">Daniel N. Nissani</a> (Nissensohn)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09330">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural networks are able to mimic intricate probability
distributions such as those of handwritten text, natural images, etc. Since
their inception several models were proposed. The most successful of these were
based on adversarial (GAN), auto-encoding (VAE) and maximum mean discrepancy
(MMD) relatively complex architectures and schemes. Surprisingly, a very simple
architecture (a single feed-forward neural network) in conjunction with an
obvious optimization goal (Kullback_Leibler divergence) was apparently
overlooked. This paper demonstrates that such a model (denoted SGN for its
simplicity) is able to generate samples visually and quantitatively competitive
as compared with the fore-mentioned state of the art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gym-$\mu$RTS: Toward Affordable Full Game Real-time Strategy Games Research with Deep Reinforcement Learning. (arXiv:2105.13807v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamford_C/0/1/0/all/0/1">Chris Bamford</a>, <a href="http://arxiv.org/find/cs/1/au:+Grela_L/0/1/0/all/0/1">Lukasz Grela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13807">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, researchers have achieved great success in applying Deep
Reinforcement Learning (DRL) algorithms to Real-time Strategy (RTS) games,
creating strong autonomous agents that could defeat professional players in
StarCraft~II. However, existing approaches to tackle full games have high
computational costs, usually requiring the use of thousands of GPUs and CPUs
for weeks. This paper has two main contributions to address this issue: 1) We
introduce Gym-$\mu$RTS (pronounced &quot;gym-micro-RTS&quot;) as a fast-to-run RL
environment for full-game RTS research and 2) we present a collection of
techniques to scale DRL to play full-game $\mu$RTS as well as ablation studies
to demonstrate their empirical importance. Our best-trained bot can defeat
every $\mu$RTS bot we tested from the past $\mu$RTS competitions when working
in a single-map setting, resulting in a state-of-the-art DRL agent while only
taking about 60 hours of training using a single machine (one GPU, three vCPU,
16GB RAM).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Reversible Embedding Mapping using Bi-Directional Manifold Alignment. (arXiv:2107.00124v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_A/0/1/0/all/0/1">Ashwinkumar Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1">Francis Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1">Tim Oates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00124">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a Bi-Directional Manifold Alignment (BDMA) that learns a
non-linear mapping between two manifolds by explicitly training it to be
bijective. We demonstrate BDMA by training a model for a pair of languages
rather than individual, directed source and target combinations, reducing the
number of models by 50%. We show that models trained with BDMA in the &quot;forward&quot;
(source to target) direction can successfully map words in the &quot;reverse&quot;
(target to source) direction, yielding equivalent (or better) performance to
standard unidirectional translation models where the source and target language
is flipped. We also show how BDMA reduces the overall size of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Predictive Entropy Search for Multi-objective Bayesian Optimization with Constraints. (arXiv:2004.00601v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Garrido_Merchan_E/0/1/0/all/0/1">Eduardo C. Garrido-Merch&#xe1;n</a>, <a href="http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1">Daniel Hern&#xe1;ndez-Lobato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.00601">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world problems often involve the optimization of several objectives
under multiple constraints. An example is the hyper-parameter tuning problem of
machine learning algorithms. In particular, the minimization of the estimation
of the generalization error of a deep neural network and at the same time the
minimization of its prediction time. We may also consider as a constraint that
the deep neural network must be implemented in a chip with an area below some
size. Here, both the objectives and the constraint are black boxes, i.e.,
functions whose analytical expressions are unknown and are expensive to
evaluate. Bayesian optimization (BO) methodologies have given state-of-the-art
results for the optimization of black-boxes. Nevertheless, most BO methods are
sequential and evaluate the objectives and the constraints at just one input
location, iteratively. Sometimes, however, we may have resources to evaluate
several configurations in parallel. Notwithstanding, no parallel BO method has
been proposed to deal with the optimization of multiple objectives under
several constraints. If the expensive evaluations can be carried out in
parallel (as when a cluster of computers is available), sequential evaluations
result in a waste of resources. This article introduces PPESMOC, Parallel
Predictive Entropy Search for Multi-objective Bayesian Optimization with
Constraints, an information-based batch method for the simultaneous
optimization of multiple expensive-to-evaluate black-box functions under the
presence of several constraints. Iteratively, PPESMOC selects a batch of input
locations at which to evaluate the black-boxes so as to maximally reduce the
entropy of the Pareto set of the optimization problem. We present empirical
evidence in the form of synthetic, benchmark and real-world experiments that
illustrate the effectiveness of PPESMOC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Certified $\ell_\infty$ Robustness with EMA Method and Ensemble Model. (arXiv:2107.00230v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Binghui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_S/0/1/0/all/0/1">Shiji Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qizhe Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00230">
                                    <div class="article-summary-box-inner">
                                        <span>The neural network with $1$-Lipschitz property based on $\ell_\infty$-dist
neuron has a theoretical guarantee in certified $\ell_\infty$ robustness.
However, due to the inherent difficulties in the training of the network, the
certified accuracy of previous work is limited. In this paper, we propose two
approaches to deal with these difficuties. Aiming at the characteristics of the
training process based on $\ell_\infty$-norm neural network, we introduce the
EMA method to improve the training process. Considering the randomness of the
training algorithm, we propose an ensemble method based on trained base models
that have the $1$-Lipschitz property and gain significant improvement in the
small parameter network. Moreover, we give the theoretical analysis of the
ensemble method based on the $1$-Lipschitz property on the certified
robustness, which ensures the effectiveness and stability of the algorithm. Our
code is available at
https://github.com/Theia-4869/EMA-and-Ensemble-Lip-Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From DNNs to GANs: Review of efficient hardware architectures for deep learning. (arXiv:2107.00092v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_G/0/1/0/all/0/1">Gaurab Bhattacharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00092">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, the trend in very large scale integration (VLSI) industry is
multi-dimensional, for example, reduction of energy consumption, occupancy of
less space, precise result, less power dissipation, faster response. To meet
these needs, the hardware architecture should be reliable and robust to these
problems. Recently, neural network and deep learning has been started to impact
the present research paradigm significantly which consists of parameters in the
order of millions, nonlinear function for activation, convolutional operation
for feature extraction, regression for classification, generative adversarial
networks. These operations involve huge calculation and memory overhead.
Presently available DSP processors are incapable of performing these operations
and they mostly face the problems, for example, memory overhead, performance
drop and compromised accuracy. Moreover, if a huge silicon area is powered to
accelerate the operation using parallel computation, the ICs will be having
significant chance of burning out due to the considerable generation of heat.
Hence, novel dark silicon constraint is developed to reduce the heat
dissipation without sacrificing the accuracy. Similarly, different algorithms
have been adapted to design a DSP processor compatible for fast performance in
neural network, activation function, convolutional neural network and
generative adversarial network. In this review, we illustrate the recent
developments in hardware for accelerating the efficient implementation of deep
learning networks with enhanced performance. The techniques investigated in
this review are expected to direct future research challenges of hardware
optimization for high-performance computations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Graph-Based Deep Learning for Computational Histopathology. (arXiv:2107.00272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmedt_Aristizabal_D/0/1/0/all/0/1">David Ahmedt-Aristizabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Armin_M/0/1/0/all/0/1">Mohammad Ali Armin</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00272">
                                    <div class="article-summary-box-inner">
                                        <span>With the remarkable success of representation learning for prediction
problems, we have witnessed a rapid expansion of the use of machine learning
and deep learning for the analysis of digital pathology and biopsy image
patches. However, traditional learning over patch-wise features using
convolutional neural networks limits the model when attempting to capture
global contextual information. The phenotypical and topological distribution of
constituent histological entities play a critical role in tissue diagnosis. As
such, graph data representations and deep learning have attracted significant
attention for encoding tissue representations, and capturing intra- and inter-
entity level interactions. In this review, we provide a conceptual grounding of
graph-based deep learning and discuss its current success for tumor
localization and classification, tumor invasion and staging, image retrieval,
and survival prediction. We provide an overview of these methods in a
systematic manner organized by the graph representation of the input image
including whole slide images and tissue microarrays. We also outline the
limitations of existing techniques, and suggest potential future advances in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Execution for Neural Program Synthesis Beyond Domain-Specific Languages. (arXiv:2107.00101v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00101">
                                    <div class="article-summary-box-inner">
                                        <span>Program synthesis from input-output examples has been a long-standing
challenge, and recent works have demonstrated some success in designing deep
neural networks for program synthesis. However, existing efforts in
input-output neural program synthesis have been focusing on domain-specific
languages, thus the applicability of previous approaches to synthesize code in
full-fledged popular programming languages, such as C, remains a question. The
main challenges lie in two folds. On the one hand, the program search space
grows exponentially when the syntax and semantics of the programming language
become more complex, which poses higher requirements on the synthesis
algorithm. On the other hand, increasing the complexity of the programming
language also imposes more difficulties on data collection, since building a
large-scale training set for input-output program synthesis require random
program generators to sample programs and input-output examples. In this work,
we take the first step to synthesize C programs from input-output examples. In
particular, we propose LaSynth, which learns the latent representation to
approximate the execution of partially generated programs, even if their
semantics are not well-defined. We demonstrate the possibility of synthesizing
elementary C code from input-output examples, and leveraging learned execution
significantly improves the prediction performance over existing approaches.
Meanwhile, compared to the randomly generated ground-truth programs, LaSynth
synthesizes more concise programs that resemble human-written code. We show
that training on these synthesized programs further improves the prediction
performance for both Karel and C program synthesis, indicating the promise of
leveraging the learned program synthesizer to improve the dataset quality for
input-output program synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Certified Segmentation via Randomized Smoothing. (arXiv:2107.00228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1">Marc Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1">Maximilian Baader</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00228">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new certification method for image and point cloud segmentation
based on randomized smoothing. The method leverages a novel scalable algorithm
for prediction and certification that correctly accounts for multiple testing,
necessary for ensuring statistical guarantees. The key to our approach is
reliance on established multiple-testing correction mechanisms as well as the
ability to abstain from classifying single pixels or points while still
robustly segmenting the overall input. Our experimental evaluation on synthetic
data and challenging datasets, such as Pascal Context, Cityscapes, and
ShapeNet, shows that our algorithm can achieve, for the first time, competitive
accuracy and certification guarantees on real-world segmentation tasks. We
provide an implementation at https://github.com/eth-sri/segmentation-smoothing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency Modeling. (arXiv:2107.00070v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00070">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks with an $L_0$ regularization is one of the
prominent approaches for network pruning or sparsification. The method prunes
the network during training by encouraging weights to become exactly zero.
However, recent work of Gale et al. reveals that although this method yields
high compression rates on smaller datasets, it performs inconsistently on
large-scale learning tasks, such as ResNet50 on ImageNet. We analyze this
phenomenon through the lens of variational inference and find that it is likely
due to the independent modeling of binary gates, the mean-field approximation,
which is known in Bayesian statistics for its poor performance due to the crude
approximation. To mitigate this deficiency, we propose a dependency modeling of
binary gates, which can be modeled effectively as a multi-layer perceptron
(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a
dependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,
CIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$
outperforms the original $L_0$-HC algorithm of Louizos et al. by a significant
margin, especially on ImageNet. Compared with the state-of-the-arts network
sparsification algorithms, our dependency modeling makes the $L_0$-based
sparsification once again very competitive on large-scale learning tasks. Our
source code is available at https://github.com/leo-yangli/dep-l0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-parametric Active Learning and Rate Reduction in Many-body Hilbert Space with Rescaled Logarithmic Fidelity. (arXiv:2107.00195v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Li_W/0/1/0/all/0/1">Wei-Ming Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00195">
                                    <div class="article-summary-box-inner">
                                        <span>In quantum and quantum-inspired machine learning, the very first step is to
embed the data in quantum space known as Hilbert space. Developing quantum
kernel function (QKF), which defines the distances among the samples in the
Hilbert space, belongs to the fundamental topics for machine learning. In this
work, we propose the rescaled logarithmic fidelity (RLF) and a non-parametric
active learning in the quantum space, which we name as RLF-NAL. The rescaling
takes advantage of the non-linearity of the kernel to tune the mutual distances
of samples in the Hilbert space, and meanwhile avoids the exponentially-small
fidelities between quantum many-qubit states. We compare RLF-NAL with several
well-known non-parametric algorithms including naive Bayes classifiers,
$k$-nearest neighbors, and spectral clustering. Our method exhibits excellent
accuracy particularly for the unsupervised case with no labeled samples and the
few-shot cases with small numbers of labeled samples. With the visualizations
by t-SNE, our results imply that the machine learning in the Hilbert space
complies with the principles of maximal coding rate reduction, where the
low-dimensional data exhibit within-class compressibility, between-class
discrimination, and overall diversity. Our proposals can be applied to other
quantum and quantum-inspired machine learning, including the methods using the
parametric models such as tensor networks, quantum circuits, and quantum neural
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reducing the Variance of Gaussian Process Hyperparameter Optimization with Preconditioning. (arXiv:2107.00243v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wenger_J/0/1/0/all/0/1">Jonathan Wenger</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1">Jacob R. Gardner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00243">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes remain popular as a flexible and expressive model class,
but the computational cost of kernel hyperparameter optimization stands as a
major limiting factor to their scaling and broader adoption. Recent work has
made great strides combining stochastic estimation with iterative numerical
techniques, essentially boiling down GP inference to the cost of (many)
matrix-vector multiplies. Preconditioning -- a highly effective step for any
iterative method involving matrix-vector multiplication -- can be used to
accelerate convergence and thus reduce bias in hyperparameter optimization.
Here, we prove that preconditioning has an additional benefit that has been
previously unexplored. It not only reduces the bias of the $\log$-marginal
likelihood estimator and its derivatives, but it also simultaneously can reduce
variance at essentially negligible cost. We leverage this result to derive
sample-efficient algorithms for GP hyperparameter optimization requiring as few
as $\mathcal{O}(\log(\varepsilon^{-1}))$ instead of
$\mathcal{O}(\varepsilon^{-2})$ samples to achieve error $\varepsilon$. Our
theoretical results enable provably efficient and scalable optimization of
kernel hyperparameters, which we validate empirically on a set of large-scale
benchmark problems. There, variance reduction via preconditioning results in an
order of magnitude speedup in hyperparameter optimization of exact GPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained SDPs. (arXiv:2106.08775v1 [math.OC] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kim_J/0/1/0/all/0/1">Junhyung Lyle Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Benitez_J/0/1/0/all/0/1">Jose Antonio Lara Benitez</a>, <a href="http://arxiv.org/find/math/1/au:+Toghani_M/0/1/0/all/0/1">Mohammad Taha Toghani</a>, <a href="http://arxiv.org/find/math/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron Wolfe</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08775">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel, practical, and provable approach for solving diagonally
constrained semi-definite programming (SDP) problems at scale using accelerated
non-convex programming. Our algorithm non-trivially combines acceleration
motions from convex optimization with coordinate power iteration and matrix
factorization techniques. The algorithm is extremely simple to implement, and
adds only a single extra hyperparameter -- momentum. We prove that our method
admits local linear convergence in the neighborhood of the optimum and always
converges to a first-order critical point. Experimentally, we showcase the
merits of our method on three major application domains: MaxCut, MaxSAT, and
MIMO signal detection. In all cases, our methodology provides significant
speedups over non-convex and convex SDP solvers -- 5X faster than
state-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP
solvers -- with comparable or improved solution quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ControlBurn: Feature Selection by Sparse Forests. (arXiv:2107.00219v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Brian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Miaolan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1">Madeleine Udell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00219">
                                    <div class="article-summary-box-inner">
                                        <span>Tree ensembles distribute feature importance evenly amongst groups of
correlated features. The average feature ranking of the correlated group is
suppressed, which reduces interpretability and complicates feature selection.
In this paper we present ControlBurn, a feature selection algorithm that uses a
weighted LASSO-based feature selection method to prune unnecessary features
from tree ensembles, just as low-intensity fire reduces overgrown vegetation.
Like the linear LASSO, ControlBurn assigns all the feature importance of a
correlated group of features to a single feature. Moreover, the algorithm is
efficient and only requires a single training iteration to run, unlike
iterative wrapper-based feature selection methods. We show that ControlBurn
performs substantially better than feature selection methods with comparable
computational costs on datasets with correlated features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Knowledge Distillation: An Inheritance and Exploration Framework. (arXiv:2107.00181v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1">Jun Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Bing Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00181">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) is a popular technique to transfer knowledge from
a teacher model or ensemble to a student model. Its success is generally
attributed to the privileged information on similarities/consistency between
the class distributions or intermediate feature representations of the teacher
model and the student model. However, directly pushing the student model to
mimic the probabilities/features of the teacher model to a large extent limits
the student model in learning undiscovered knowledge/features. In this paper,
we propose a novel inheritance and exploration knowledge distillation framework
(IE-KD), in which a student model is split into two parts - inheritance and
exploration. The inheritance part is learned with a similarity loss to transfer
the existing learned knowledge from the teacher model to the student model,
while the exploration part is encouraged to learn representations different
from the inherited ones with a dis-similarity loss. Our IE-KD framework is
generic and can be easily combined with existing distillation or mutual
learning methods for training deep neural networks. Extensive experiments
demonstrate that these two parts can jointly push the student model to learn
more diversified and effective representations, and our IE-KD can be a general
technique to improve the student network to achieve SOTA performance.
Furthermore, by applying our IE-KD to the training of two networks, the
performance of both can be improved w.r.t. deep mutual learning. The code and
models of IE-KD will be make publicly available at
https://github.com/yellowtownhz/IE-KD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Coreset for Continuous-and-Bounded Learning (with Outliers). (arXiv:2107.00068v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zixiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiwen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Hu Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00068">
                                    <div class="article-summary-box-inner">
                                        <span>In this big data era, we often confront large-scale data in many machine
learning tasks. A common approach for dealing with large-scale data is to build
a small summary, {\em e.g.,} coreset, that can efficiently represent the
original input. However, real-world datasets usually contain outliers and most
existing coreset construction methods are not resilient against outliers (in
particular, the outliers can be located arbitrarily in the space by an
adversarial attacker). In this paper, we propose a novel robust coreset method
for the {\em continuous-and-bounded learning} problem (with outliers) which
includes a broad range of popular optimization objectives in machine learning,
like logistic regression and $ k $-means clustering. Moreover, our robust
coreset can be efficiently maintained in fully-dynamic environment. To the best
of our knowledge, this is the first robust and fully-dynamic coreset
construction method for these optimization problems. We also conduct the
experiments to evaluate the effectiveness of our robust coreset in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time Delays Using Reinforcement Learning. (arXiv:2107.00359v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1">Hadi Beik-Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerzel_M/0/1/0/all/0/1">Matthias Kerzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleintinger_B/0/1/0/all/0/1">Benedikt Pleintinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hulin_T/0/1/0/all/0/1">Thomas Hulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Reisich_P/0/1/0/all/0/1">Philipp Reisich</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_A/0/1/0/all/0/1">Annika Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_A/0/1/0/all/0/1">Aaron Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1">Stefan Wermter</a>, <a href="http://arxiv.org/find/cs/1/au:+Lii_N/0/1/0/all/0/1">Neal Y. Lii</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00359">
                                    <div class="article-summary-box-inner">
                                        <span>Telerobotic systems must adapt to new environmental conditions and deal with
high uncertainty caused by long-time delays. As one of the best alternatives to
human-level intelligence, Reinforcement Learning (RL) may offer a solution to
cope with these issues. This paper proposes to integrate RL with the Model
Mediated Teleoperation (MMT) concept. The teleoperator interacts with a
simulated virtual environment, which provides instant feedback. Whereas
feedback from the real environment is delayed, feedback from the model is
instantaneous, leading to high transparency. The MMT is realized in combination
with an intelligent system with two layers. The first layer utilizes Dynamic
Movement Primitives (DMP) which accounts for certain changes in the avatar
environment. And, the second layer addresses the problems caused by uncertainty
in the model using RL methods. Augmented reality was also provided to fuse the
avatar device and virtual environment models for the teleoperator. Implemented
on DLR&#x27;s Exodex Adam hand-arm haptic exoskeleton, the results show RL methods
are able to find different solutions when changes are applied to the object
position after the demonstration. The results also show DMPs to be effective at
adapting to new conditions where there is no uncertainty involved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivergentNets: Medical Image Segmentation by Network Ensemble. (arXiv:2107.00283v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00283">
                                    <div class="article-summary-box-inner">
                                        <span>Detection of colon polyps has become a trending topic in the intersecting
fields of machine learning and gastrointestinal endoscopy. The focus has mainly
been on per-frame classification. More recently, polyp segmentation has gained
attention in the medical community. Segmentation has the advantage of being
more accurate than per-frame classification or object detection as it can show
the affected area in greater detail. For our contribution to the EndoCV 2021
segmentation challenge, we propose two separate approaches. First, a
segmentation model named TriUNet composed of three separate UNet models.
Second, we combine TriUNet with an ensemble of well-known segmentation models,
namely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called
DivergentNets to produce more generalizable medical image segmentation masks.
In addition, we propose a modified Dice loss that calculates loss only for a
single class when performing multiclass segmentation, forcing the model to
focus on what is most important. Overall, the proposed methods achieved the
best average scores for each respective round in the challenge, with TriUNet
being the winning model in Round I and DivergentNets being the winning model in
Round II of the segmentation generalization challenge at EndoCV 2021. The
implementation of our approach is made publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning and Deep Learning for Fixed-Text Keystroke Dynamics. (arXiv:2107.00507v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Han-Chih Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Ching-Seh Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00507">
                                    <div class="article-summary-box-inner">
                                        <span>Keystroke dynamics can be used to analyze the way that users type by
measuring various aspects of keyboard input. Previous work has demonstrated the
feasibility of user authentication and identification utilizing keystroke
dynamics. In this research, we consider a wide variety of machine learning and
deep learning techniques based on fixed-text keystroke-derived features, we
optimize the resulting models, and we compare our results to those obtained in
related research. We find that models based on extreme gradient boosting
(XGBoost) and multi-layer perceptrons (MLP)perform well in our experiments. Our
best models outperform previous comparable research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Conditioned Reinforcement Learning with Imagined Subgoals. (arXiv:2107.00541v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chane_Sane_E/0/1/0/all/0/1">Elliot Chane-Sane</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00541">
                                    <div class="article-summary-box-inner">
                                        <span>Goal-conditioned reinforcement learning endows an agent with a large variety
of skills, but it often struggles to solve tasks that require more temporally
extended reasoning. In this work, we propose to incorporate imagined subgoals
into policy learning to facilitate learning of complex tasks. Imagined subgoals
are predicted by a separate high-level policy, which is trained simultaneously
with the policy and its critic. This high-level policy predicts intermediate
states halfway to the goal using the value function as a reachability metric.
We don&#x27;t require the policy to reach these subgoals explicitly. Instead, we use
them to define a prior policy, and incorporate this prior into a KL-constrained
policy iteration scheme to speed up and regularize learning. Imagined subgoals
are used during policy learning, but not during test time, where we only apply
the learned policy. We evaluate our approach on complex robotic navigation and
manipulation tasks and show that it outperforms existing methods by a large
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Interplay between Distribution Parameters and the Accuracy-Robustness Tradeoff in Classification. (arXiv:2107.00247v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosseini_A/0/1/0/all/0/1">Alireza Mousavi Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Abouei_A/0/1/0/all/0/1">Amir Mohammad Abouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohban_M/0/1/0/all/0/1">Mohammad Hossein Rohban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00247">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training tends to result in models that are less accurate on
natural (unperturbed) examples compared to standard models. This can be
attributed to either an algorithmic shortcoming or a fundamental property of
the training data distribution, which admits different solutions for optimal
standard and adversarial classifiers. In this work, we focus on the latter case
under a binary Gaussian mixture classification problem. Unlike earlier work, we
aim to derive the natural accuracy gap between the optimal Bayes and
adversarial classifiers, and study the effect of different distributional
parameters, namely separation between class centroids, class proportions, and
the covariance matrix, on the derived gap. We show that under certain
conditions, the natural error of the optimal adversarial classifier, as well as
the gap, are locally minimized when classes are balanced, contradicting the
performance of the Bayes classifier where perfect balance induces the worst
accuracy. Moreover, we show that with an $\ell_\infty$ bounded perturbation and
an adversarial budget of $\epsilon$, this gap is $\Theta(\epsilon^2)$ for the
worst-case parameters, which for suitably small $\epsilon$ indicates the
theoretical possibility of achieving robust classifiers with near-perfect
accuracy, which is rarely reflected in practical algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Graph Learning for Disease Prediction. (arXiv:2107.00206v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00206">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from the powerful expressive capability of graphs, graph-based
approaches have achieved impressive performance in various biomedical
applications. Most existing methods tend to define the adjacency matrix among
samples manually based on meta-features, and then obtain the node embeddings
for downstream tasks by Graph Representation Learning (GRL). However, it is not
easy for these approaches to generalize to unseen samples. Meanwhile, the
complex correlation between modalities is also ignored. As a result, these
factors inevitably yield the inadequacy of providing valid information about
the patient&#x27;s condition for a reliable diagnosis. In this paper, we propose an
end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.
To effectively exploit the rich information across multi-modality associated
with diseases, amodal-attentional multi-modal fusion is proposed to integrate
the features of each modality by leveraging the correlation and complementarity
between the modalities. Furthermore, instead of defining the adjacency matrix
manually as existing methods, the latent graph structure can be captured
through a novel way of adaptive graph learning. It could be jointly optimized
with the prediction model, thus revealing the intrinsic connections among
samples. Unlike the previous transductive methods, our model is also applicable
to the scenario of inductive learning for those unseen data. An extensive group
of experiments on two disease prediction problems is then carefully designed
and presented, demonstrating that MMGL obtains more favorable performances. In
addition, we also visualize and analyze the learned graph structure to provide
more reliable decision support for doctors in real medical applications and
inspiration for disease research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SparseBERT: Rethinking the Importance Analysis in Self-attention. (arXiv:2102.12871v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Han Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiahui Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1">James T. Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12871">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based models are popularly used in natural language processing
(NLP). Its core component, self-attention, has aroused widespread interest. To
understand the self-attention mechanism, a direct method is to visualize the
attention map of a pre-trained model. Based on the patterns observed, a series
of efficient Transformers with different sparse attention masks have been
proposed. From a theoretical perspective, universal approximability of
Transformer-based models is also recently proved. However, the above
understanding and analysis of self-attention is based on a pre-trained model.
To rethink the importance analysis in self-attention, we study the significance
of different positions in attention matrix during pre-training. A surprising
result is that diagonal elements in the attention map are the least important
compared with other attention positions. We provide a proof showing that these
diagonal elements can indeed be removed without deteriorating model
performance. Furthermore, we propose a Differentiable Attention Mask (DAM)
algorithm, which further guides the design of the SparseBERT. Extensive
experiments verify our interesting findings and illustrate the effect of the
proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forecasting directional movements of stock prices for intraday trading using LSTM and random forests. (arXiv:2004.10178v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1">Pushpendu Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Neufeld_A/0/1/0/all/0/1">Ariel Neufeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahoo_J/0/1/0/all/0/1">Jajati Keshari Sahoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.10178">
                                    <div class="article-summary-box-inner">
                                        <span>We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as
training methodologies to analyze their effectiveness in forecasting
out-of-sample directional movements of constituent stocks of the S&amp;P 500 from
January 1993 till December 2018 for intraday trading. We introduce a
multi-feature setting consisting not only of the returns with respect to the
closing prices, but also with respect to the opening prices and intraday
returns. As trading strategy, we use Krauss et al. (2017) and Fischer &amp; Krauss
(2018) as benchmark. On each trading day, we buy the 10 stocks with the highest
probability and sell short the 10 stocks with the lowest probability to
outperform the market in terms of intraday returns -- all with equal monetary
weight. Our empirical results show that the multi-feature setting provides a
daily return, prior to transaction costs, of 0.64% using LSTM networks, and
0.54% using random forests. Hence we outperform the single-feature setting in
Fischer &amp; Krauss (2018) and Krauss et al. (2017) consisting only of the daily
returns with respect to the closing prices, having corresponding daily returns
of 0.41% and of 0.39% with respect to LSTM and random forests, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Adversarial Examples Through Deep Neural Network&#x27;s Response Surface and Uncertainty Regions. (arXiv:2107.00003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1">Juan Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamhoua_C/0/1/0/all/0/1">Charles Kamhoua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00003">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network (DNN) is a popular model implemented in many systems to
handle complex tasks such as image classification, object recognition, natural
language processing etc. Consequently DNN structural vulnerabilities become
part of the security vulnerabilities in those systems. In this paper we study
the root cause of DNN adversarial examples. We examine the DNN response surface
to understand its classification boundary. Our study reveals the structural
problem of DNN classification boundary that leads to the adversarial examples.
Existing attack algorithms can generate from a handful to a few hundred
adversarial examples given one clean image. We show there are infinitely many
adversarial images given one clean sample, all within a small neighborhood of
the clean sample. We then define DNN uncertainty regions and show
transferability of adversarial examples is not universal. We also argue that
generalization error, the large sample theoretical guarantee established for
DNN, cannot adequately capture the phenomenon of adversarial examples. We need
new theory to measure DNN robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online learning of windmill time series using Long Short-term Cognitive Networks. (arXiv:2107.00425v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morales_Hernandez_A/0/1/0/all/0/1">Alejandro Morales-Hern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Napoles_G/0/1/0/all/0/1">Gonzalo N&#xe1;poles</a>, <a href="http://arxiv.org/find/cs/1/au:+Jastrzebska_A/0/1/0/all/0/1">Agnieszka Jastrzebska</a>, <a href="http://arxiv.org/find/cs/1/au:+Salgueiro_Y/0/1/0/all/0/1">Yamisleydi Salgueiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanhoof_K/0/1/0/all/0/1">Koen Vanhoof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00425">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting windmill time series is often the basis of other processes such
as anomaly detection, health monitoring, or maintenance scheduling. The amount
of data generated on windmill farms makes online learning the most viable
strategy to follow. Such settings require retraining the model each time a new
batch of data is available. However, update the model with the new information
is often very expensive to perform using traditional Recurrent Neural Networks
(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to
forecast windmill time series in online settings. These recently introduced
neural systems consist of chained Short-term Cognitive Network blocks, each
processing a temporal data chunk. The learning algorithm of these blocks is
based on a very fast, deterministic learning rule that makes LSTCNs suitable
for online learning tasks. The numerical simulations using a case study with
four windmills showed that our approach reported the lowest forecasting errors
with respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,
and a Hidden Markov Model. What is perhaps more important is that the LSTCN
approach is significantly faster than these state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection. (arXiv:1907.09693v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zeyi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhaomin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Sixu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Naibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bingsheng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.09693">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has been a hot research topic in enabling the
collaborative training of machine learning models among different organizations
under the privacy restrictions. As researchers try to support more machine
learning models with different privacy-preserving approaches, there is a
requirement in developing systems and infrastructures to ease the development
of various federated learning algorithms. Similar to deep learning systems such
as PyTorch and TensorFlow that boost the development of deep learning,
federated learning systems (FLSs) are equivalently important, and face
challenges from various aspects such as effectiveness, efficiency, and privacy.
In this survey, we conduct a comprehensive review on federated learning
systems. To achieve smooth flow and guide future research, we introduce the
definition of federated learning systems and analyze the system components.
Moreover, we provide a thorough categorization for federated learning systems
according to six different aspects, including data distribution, machine
learning model, privacy mechanism, communication architecture, scale of
federation and motivation of federation. The categorization can help the design
of federated learning systems as shown in our case studies. By systematically
summarizing the existing federated learning systems, we present the design
factors, case studies, and future research opportunities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Dirichlet-process-means for $f$-separable distortion measures. (arXiv:1901.11331v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_M/0/1/0/all/0/1">Masahiro Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_K/0/1/0/all/0/1">Kazuho Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.11331">
                                    <div class="article-summary-box-inner">
                                        <span>DP-means clustering was obtained as an extension of $K$-means clustering.
While it is implemented with a simple and efficient algorithm, it can estimate
the number of clusters simultaneously. However, DP-means is specifically
designed for the average distortion measure. Therefore, it is vulnerable to
outliers in data, and can cause large maximum distortion in clusters. In this
work, we extend the objective function of the DP-means to $f$-separable
distortion measures and propose a unified learning algorithm to overcome the
above problems by selecting the function $f$. Further, the influence function
of the estimated cluster center is analyzed to evaluate the robustness against
outliers. We demonstrate the performance of the generalized method by numerical
experiments using real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble. (arXiv:2107.00591v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1">Younggyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00591">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advance in deep offline reinforcement learning (RL) has made it
possible to train strong robotic agents from offline datasets. However,
depending on the quality of the trained agents and the application being
considered, it is often desirable to fine-tune such agents via further online
interactions. In this paper, we observe that state-action distribution shift
may lead to severe bootstrap error during fine-tuning, which destroys the good
initial policy obtained via offline RL. To address this issue, we first propose
a balanced replay scheme that prioritizes samples encountered online while also
encouraging the use of near-on-policy samples from the offline dataset.
Furthermore, we leverage multiple Q-functions trained pessimistically offline,
thereby preventing overoptimism concerning unfamiliar actions at novel states
during the initial training phase. We show that the proposed method improves
sample-efficiency and final performance of the fine-tuned robotic agents on
various locomotion and manipulation tasks. Our code is available at:
https://github.com/shlee94/Off2OnRL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and Graph Prediction. (arXiv:1910.11390v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Daniel T. Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.11390">
                                    <div class="article-summary-box-inner">
                                        <span>Tiered graph autoencoders provide the architecture and mechanisms for
learning tiered latent representations and latent spaces for molecular graphs
that explicitly represent and utilize groups (e.g., functional groups). This
enables the utilization and exploration of tiered molecular latent spaces,
either individually - the node (atom) tier, the group tier, or the graph
(molecule) tier - or jointly, as well as navigation across the tiers. In this
paper, we discuss the use of tiered graph autoencoders together with graph
prediction for molecular graphs. We show features of molecular graphs used, and
groups in molecular graphs identified for some sample molecules. We briefly
review graph prediction and the QM9 dataset for background information, and
discuss the use of tiered graph embeddings for graph prediction, particularly
weighted group pooling. We find that functional groups and ring groups
effectively capture and represent the chemical essence of molecular graphs
(structures). Further, tiered graph autoencoders and graph prediction together
provide effective, efficient and interpretable deep learning for molecular
graphs, with the former providing unsupervised, transferable learning and the
latter providing supervised, task-optimized learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demon: Improved Neural Network Training with Momentum Decay. (arXiv:1910.04952v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.04952">
                                    <div class="article-summary-box-inner">
                                        <span>Momentum is a widely used technique for gradient-based optimizers in deep
learning. In this paper, we propose a decaying momentum (\textsc{Demon}) rule.
We conduct the first large-scale empirical analysis of momentum decay methods
for modern neural network optimization, in addition to the most popular
learning rate decay schedules. Across 28 relevant combinations of models,
epochs, datasets, and optimizers, \textsc{Demon} achieves the highest number of
Top-1 and Top-3 finishes at 39\% and 85\% respectively, almost doubling the
second-placed learning rate cosine schedule at 17\% and 60\%, respectively.
\textsc{Demon} also outperforms other widely used schedulers including, but not
limited to, the learning rate step schedule, linear schedule, OneCycle
schedule, and exponential schedule. Compared with the widely used learning rate
step schedule, \textsc{Demon} is observed to be less sensitive to parameter
tuning, which is critical to training neural networks in practice. Results are
demonstrated across a variety of settings and architectures, including image
classification, generative models, and language models. \textsc{Demon} is easy
to implement, requires no additional tuning, and incurs almost no extra
computational overhead compared to the vanilla counterparts. Code is readily
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation. (arXiv:2107.00644v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00644">
                                    <div class="article-summary-box-inner">
                                        <span>While agents trained by Reinforcement Learning (RL) can solve increasingly
challenging tasks directly from visual observations, generalizing learned
skills to novel environments remains very challenging. Extensive use of data
augmentation is a promising technique for improving generalization in RL, but
it is often found to decrease sample efficiency and can even lead to
divergence. In this paper, we investigate causes of instability when using data
augmentation in common off-policy RL algorithms. We identify two problems, both
rooted in high-variance Q-targets. Based on our findings, we propose a simple
yet effective technique for stabilizing this class of algorithms under
augmentation. We perform extensive empirical evaluation of image-based RL using
both ConvNets and Vision Transformers (ViT) on a family of benchmarks based on
DeepMind Control Suite, as well as in robotic manipulation tasks. Our method
greatly improves stability and sample efficiency of ConvNets under
augmentation, and achieves generalization results competitive with
state-of-the-art methods for image-based RL. We further show that our method
scales to RL with ViT-based architectures, and that data augmentation may be
especially important in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Sparsification for Deep Neural Networks. (arXiv:1910.03201v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yognjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.03201">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have relieved a great deal of burden on human experts in
relation to feature engineering. However, comparable efforts are instead
required to determine effective architectures. In addition, as the sizes of
networks have grown overly large, a considerable amount of resources is also
invested in reducing the sizes. The sparsification of an over-complete model
addresses these problems as it removes redundant components and connections. In
this study, we propose a fully differentiable sparsification method for deep
neural networks which allows parameters to be zero during training via
stochastic gradient descent. Thus, the proposed method can learn the sparsified
structure and weights of a network in an end-to-end manner. The method is
directly applicable to various modern deep neural networks and imposes minimum
modification to existing models. To the best of our knowledge, this is the
first fully [sub-]differentiable sparsification method that zeroes out
parameters. It provides a foundation for future structure learning and model
compression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1">Salah Zaiem</a>, <a href="http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1">Slim Essid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00594">
                                    <div class="article-summary-box-inner">
                                        <span>Through solving pretext tasks, self-supervised learning leverages unlabeled
data to extract useful latent representations replacing traditional input
features in the downstream task. In various application domains, including
computer vision, natural language processing and audio/speech signal
processing, a wide range of features where engineered through decades of
research efforts. As it turns out, learning to predict such features has proven
to be a particularly relevant pretext task leading to building useful
self-supervised representations that prove to be effective for downstream
tasks. However, methods and common practices for combining such pretext tasks,
where each task targets a different group of features for better performance on
the downstream task have not been explored and understood properly. In fact,
the process relies almost exclusively on a computationally heavy experimental
procedure, which becomes intractable with the increase of the number of pretext
tasks. This paper introduces a method to select a group of pretext tasks among
a set of candidates. The method we propose estimates properly calibrated
weights for the partial losses corresponding to the considered pretext tasks
during the self-supervised training process. The experiments conducted on
speaker recognition and automatic speech recognition validate our approach, as
the groups selected and weighted with our method perform better than classic
baselines, thus facilitating the selection and combination of relevant
pseudo-labels for self-supervised representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks. (arXiv:2107.00415v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Pira_G/0/1/0/all/0/1">Giacomo Pira</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00415">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs), despite being energy-efficient when
implemented on neuromorphic hardware and coupled with event-based Dynamic
Vision Sensors (DVS), are vulnerable to security threats, such as adversarial
attacks, i.e., small perturbations added to the input for inducing a
misclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet
efficient adversarial attack methodologies targeted to perturb the event
sequences that compose the input of the SNNs. First, we show that noise filters
for DVS can be used as defense mechanisms against adversarial attacks.
Afterwards, we implement several attacks and test them in the presence of two
types of noise filters for DVS cameras. The experimental results show that the
filters can only partially defend the SNNs against our proposed DVS-Attacks.
Using the best settings for the noise filters, our proposed Mask Filter-Aware
Dash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset
and by more than 65% on the MNIST dataset, compared to the original clean
frames. The source code of all the proposed DVS-Attacks and noise filters is
released at https://github.com/albertomarchisio/DVS-Attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Quantized Training for Deep Learning. (arXiv:2107.00501v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_M/0/1/0/all/0/1">Marcel Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Ke Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00501">
                                    <div class="article-summary-box-inner">
                                        <span>We have implemented training of neural networks in secure multi-party
computation (MPC) using quantization commonly used in the said setting. To the
best of our knowledge, we are the first to present an MNIST classifier purely
trained in MPC that comes within 0.2 percent of the accuracy of the same
convolutional neural network trained via plaintext computation. More
concretely, we have trained a network with two convolution and two dense layers
to 99.2% accuracy in 25 epochs. This took 3.5 hours in our MPC implementation
(under one hour for 99% accuracy).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Networks as Geometric Chaotic Maps. (arXiv:1912.05081v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravela_S/0/1/0/all/0/1">Sai Ravela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.05081">
                                    <div class="article-summary-box-inner">
                                        <span>The use of artificial neural networks as models of chaotic dynamics has been
rapidly expanding. Still, a theoretical understanding of how neural networks
learn chaos is lacking. Here, we employ a geometric perspective to show that
neural networks can efficiently model chaotic dynamics by becoming structurally
chaotic themselves. We first confirm neural network&#x27;s efficiency in emulating
chaos by showing that a parsimonious neural network trained only on few data
points can reconstruct strange attractors, extrapolate outside training data
boundaries, and accurately predict local divergence rates. We then posit that
the trained network&#x27;s map comprises sequential geometric stretching, rotation,
and compression operations. These geometric operations indicate topological
mixing and chaos, explaining why neural networks are naturally suitable to
emulate chaotic dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using AntiPatterns to avoid MLOps Mistakes. (arXiv:2107.00079v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidhar_N/0/1/0/all/0/1">Nikhil Muralidhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Muthiah_S/0/1/0/all/0/1">Sathappah Muthiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Butler_P/0/1/0/all/0/1">Patrick Butler</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1">Manish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Burne_K/0/1/0/all/0/1">Katy Burne</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weipeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1">David Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Arunachalam_P/0/1/0/all/0/1">Prakash Arunachalam</a>, <a href="http://arxiv.org/find/cs/1/au:+McCormick_H/0/1/0/all/0/1">Hays &#x27;Skip&#x27; McCormick</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_N/0/1/0/all/0/1">Naren Ramakrishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00079">
                                    <div class="article-summary-box-inner">
                                        <span>We describe lessons learned from developing and deploying machine learning
models at scale across the enterprise in a range of financial analytics
applications. These lessons are presented in the form of antipatterns. Just as
design patterns codify best software engineering practices, antipatterns
provide a vocabulary to describe defective practices and methodologies. Here we
catalog and document numerous antipatterns in financial ML operations (MLOps).
Some antipatterns are due to technical errors, while others are due to not
having sufficient knowledge of the surrounding context in which ML results are
used. By providing a common vocabulary to discuss these situations, our intent
is that antipatterns will support better documentation of issues, rapid
communication between stakeholders, and faster resolution of problems. In
addition to cataloging antipatterns, we describe solutions, best practices, and
future directions toward MLOps maturity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Model Drift Estimation with Batch Normalization Statistics for Dataset Shift Detection and Model Selection. (arXiv:2107.00191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wonju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_S/0/1/0/all/0/1">Seok-Yong Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jooeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Minje Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechil_K/0/1/0/all/0/1">Kirill Chechil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00191">
                                    <div class="article-summary-box-inner">
                                        <span>While many real-world data streams imply that they change frequently in a
nonstationary way, most of deep learning methods optimize neural networks on
training data, and this leads to severe performance degradation when dataset
shift happens. However, it is less possible to annotate or inspect newly
streamed data by humans, and thus it is desired to measure model drift at
inference time in an unsupervised manner. In this paper, we propose a novel
method of model drift estimation by exploiting statistics of batch
normalization layer on unlabeled test data. To remedy possible sampling error
of streamed input data, we adopt low-rank approximation to each
representational layer. We show the effectiveness of our method not only on
dataset shift detection but also on model selection when there are multiple
candidate models among model zoo or training trajectories in an unsupervised
way. We further demonstrate the consistency of our method by comparing model
drift scores between different network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Background Knowledge in Schema Matching: Strategy vs. Data. (arXiv:2107.00001v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portisch_J/0/1/0/all/0/1">Jan Portisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hladik_M/0/1/0/all/0/1">Michael Hladik</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00001">
                                    <div class="article-summary-box-inner">
                                        <span>The use of external background knowledge can be beneficial for the task of
matching schemas or ontologies automatically. In this paper, we exploit six
general-purpose knowledge graphs as sources of background knowledge for the
matching task. The background sources are evaluated by applying three different
exploitation strategies. We find that explicit strategies still outperform
latent ones and that the choice of the strategy has a greater impact on the
final alignment than the actual background dataset on which the strategy is
applied. While we could not identify a universally superior resource, BabelNet
achieved consistently good results. Our best matcher configuration with
BabelNet performs very competitively when compared to other matching systems
even though no dataset-specific optimizations were made.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning. (arXiv:2107.00088v1 [physics.comp-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Hooten_S/0/1/0/all/0/1">Sean Hooten</a>, <a href="http://arxiv.org/find/physics/1/au:+Vaerenbergh_T/0/1/0/all/0/1">Thomas Van Vaerenbergh</a>, <a href="http://arxiv.org/find/physics/1/au:+Beausoleil_R/0/1/0/all/0/1">Raymond G. Beausoleil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00088">
                                    <div class="article-summary-box-inner">
                                        <span>We present a proof-of-concept technique for the inverse design of
electromagnetic devices motivated by the policy gradient method in
reinforcement learning, named PHORCED (PHotonic Optimization using REINFORCE
Criteria for Enhanced Design). This technique uses a probabilistic generative
neural network interfaced with an electromagnetic solver to assist in the
design of photonic devices, such as grating couplers. We show that PHORCED
obtains better performing grating coupler designs than local gradient-based
inverse design via the adjoint method, while potentially providing faster
convergence over competing state-of-the-art generative methods. Furthermore, we
implement transfer learning with PHORCED, demonstrating that a neural network
trained to optimize 8$^\circ$ grating couplers can then be re-trained on
grating couplers with alternate scattering angles while requiring &gt;$10\times$
fewer simulations than control cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audiovisual Singing Voice Separation. (arXiv:2107.00231v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bochen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00231">
                                    <div class="article-summary-box-inner">
                                        <span>Separating a song into vocal and accompaniment components is an active
research topic, and recent years witnessed an increased performance from
supervised training using deep learning techniques. We propose to apply the
visual information corresponding to the singers&#x27; vocal activities to further
improve the quality of the separated vocal signals. The video frontend model
takes the input of mouth movement and fuses it into the feature embeddings of
an audio-based separation framework. To facilitate the network to learn
audiovisual correlation of singing activities, we add extra vocal signals
irrelevant to the mouth movement to the audio mixture during training. We
create two audiovisual singing performance datasets for training and
evaluation, respectively, one curated from audition recordings on the Internet,
and the other recorded in house. The proposed method outperforms audio-based
methods in terms of separation quality on most test recordings. This advantage
is especially pronounced when there are backing vocals in the accompaniment,
which poses a great challenge for audio-only methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Generative Adversarial Imitation Learning via Local Lipschitzness. (arXiv:2107.00116v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Memarian_F/0/1/0/all/0/1">Farzan Memarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_A/0/1/0/all/0/1">Abolfazl Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00116">
                                    <div class="article-summary-box-inner">
                                        <span>We explore methodologies to improve the robustness of generative adversarial
imitation learning (GAIL) algorithms to observation noise. Towards this
objective, we study the effect of local Lipschitzness of the discriminator and
the generator on the robustness of policies learned by GAIL. In many robotics
applications, the learned policies by GAIL typically suffer from a degraded
performance at test time since the observations from the environment might be
corrupted by noise. Hence, robustifying the learned policies against the
observation noise is of critical importance. To this end, we propose a
regularization method to induce local Lipschitzness in the generator and the
discriminator of adversarial imitation learning methods. We show that the
modified objective leads to learning significantly more robust policies.
Moreover, we demonstrate -- both theoretically and experimentally -- that
training a locally Lipschitz discriminator leads to a locally Lipschitz
generator, thereby improving the robustness of the resultant policy. We perform
extensive experiments on simulated robot locomotion environments from the
MuJoCo suite that demonstrate the proposed method learns policies that
significantly outperform the state-of-the-art generative adversarial imitation
learning algorithm when applied to test scenarios with noise-corrupted
observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Nonparametric Function Estimation: Optimal Rate of Convergence and Cost of Adaptation. (arXiv:2107.00179v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cai_T/0/1/0/all/0/1">T. Tony Cai</a>, <a href="http://arxiv.org/find/math/1/au:+Wei_H/0/1/0/all/0/1">Hongji Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00179">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed minimax estimation and distributed adaptive estimation under
communication constraints for Gaussian sequence model and white noise model are
studied. The minimax rate of convergence for distributed estimation over a
given Besov class, which serves as a benchmark for the cost of adaptation, is
established. We then quantify the exact communication cost for adaptation and
construct an optimally adaptive procedure for distributed estimation over a
range of Besov classes. The results demonstrate significant differences between
nonparametric function estimation in the distributed setting and the
conventional centralized setting. For global estimation, adaptation in general
cannot be achieved for free in the distributed setting. The new technical tools
to obtain the exact characterization for the cost of adaptation can be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?. (arXiv:2107.00166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00166">
                                    <div class="article-summary-box-inner">
                                        <span>There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the &quot;winning ticket&quot; in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FCMI: Feature Correlation based Missing Data Imputation. (arXiv:2107.00100v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1">Prateek Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mani_K/0/1/0/all/0/1">Kumar Divya Mani</a>, <a href="http://arxiv.org/find/cs/1/au:+Johri_P/0/1/0/all/0/1">Prashant Johri</a>, <a href="http://arxiv.org/find/cs/1/au:+Arya_D/0/1/0/all/0/1">Dikhsa Arya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00100">
                                    <div class="article-summary-box-inner">
                                        <span>Processed data are insightful, and crude data are obtuse. A serious threat to
data reliability is missing values. Such data leads to inaccurate analysis and
wrong predictions. We propose an efficient technique to impute the missing
value in the dataset based on correlation called FCMI (Feature Correlation
based Missing Data Imputation). We have considered the correlation of the
attributes of the dataset, and that is our central idea. Our proposed algorithm
picks the highly correlated attributes of the dataset and uses these attributes
to build a regression model whose parameters are optimized such that the
correlation of the dataset is maintained. Experiments conducted on both
classification and regression datasets show that the proposed imputation
technique outperforms existing imputation algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressing Location on Text for Probabilistic Geocoding. (arXiv:2107.00080v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radford_B/0/1/0/all/0/1">Benjamin J. Radford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00080">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are an important source of detailed information about social and
political events. Automated systems parse large volumes of text data to infer
or extract structured information that describes actors, actions, dates, times,
and locations. One of these sub-tasks is geocoding: predicting the geographic
coordinates associated with events or locations described by a given text. We
present an end-to-end probabilistic model for geocoding text data.
Additionally, we collect a novel data set for evaluating the performance of
geocoding systems. We compare the model-based solution, called ELECTRo-map, to
the current state-of-the-art open source system for geocoding texts for event
data. Finally, we discuss the benefits of end-to-end model-based geocoding,
including principled uncertainty estimation and the ability of these models to
leverage contextual information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedMix: Approximation of Mixup under Mean Augmented Federated Learning. (arXiv:2107.00233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1">Tehrim Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Sumin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00233">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) allows edge devices to collectively learn a model
without directly sharing data within each device, thus preserving privacy and
eliminating the need to store data globally. While there are promising results
under the assumption of independent and identically distributed (iid) local
data, current state-of-the-art algorithms suffer from performance degradation
as the heterogeneity of local data across clients increases. To resolve this
issue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),
where clients send and receive averaged local data, subject to the privacy
requirements of target applications. Under our framework, we propose a new
augmentation algorithm, named FedMix, which is inspired by a phenomenal yet
simple data augmentation method, Mixup, but does not require local raw data to
be directly shared among devices. Our method shows greatly improved performance
in the standard benchmark datasets of FL, under highly non-iid federated
settings, compared to conventional algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Knowledge Distillation in Federated Learning. (arXiv:2107.00051v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wanning Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00051">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation has caught a lot of attention in Federated Learning
(FL) recently. It has the advantage for FL to train on heterogeneous clients
which have different data size and data structure. However, data samples across
all devices are usually not independent and identically distributed
(non-i.i.d), posing additional challenges to the convergence and speed of
federated learning. As FL randomly asks the clients to join the training
process and each client only learns from local non-i.i.d data, which makes
learning processing even slower. In order to solve this problem, an intuitive
idea is using the global model to guide local training. In this paper, we
propose a novel global knowledge distillation method, named FedGKD, which
learns the knowledge from past global models to tackle down the local bias
training problem. By learning from global knowledge and consistent with current
local models, FedGKD learns a global knowledge model in FL. To demonstrate the
effectiveness of the proposed method, we conduct extensive experiments on
various CV datasets (CIFAR-10/100) and settings (non-i.i.d data). The
evaluation results show that FedGKD outperforms previous state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaXpert: Adapting Neural Architecture for Growing Data. (arXiv:2107.00254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiaxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guanghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00254">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications, data often come in a growing manner, where the
data volume and the number of classes may increase dynamically. This will bring
a critical challenge for learning: given the increasing data volume or the
number of classes, one has to instantaneously adjust the neural model capacity
to obtain promising performance. Existing methods either ignore the growing
nature of data or seek to independently search an optimal architecture for a
given dataset, and thus are incapable of promptly adjusting the architectures
for the changed data. To address this, we present a neural architecture
adaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust
previous architectures on the growing data. Specifically, we introduce an
architecture adjuster to generate a suitable architecture for each data
snapshot, based on the previous architecture and the different extent between
current and previous data distributions. Furthermore, we propose an adaptation
condition to determine the necessity of adjustment, thereby avoiding
unnecessary and time-consuming adjustments. Extensive experiments on two growth
scenarios (increasing data volume and number of classes) demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascade Decoders-Based Autoencoders for Image Reconstruction. (arXiv:2107.00002v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Honggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Galayko_D/0/1/0/all/0/1">Dimitri Galayko</a>, <a href="http://arxiv.org/find/cs/1/au:+Trocan_M/0/1/0/all/0/1">Maria Trocan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sawan_M/0/1/0/all/0/1">Mohamad Sawan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00002">
                                    <div class="article-summary-box-inner">
                                        <span>Autoencoders are composed of coding and decoding units, hence they hold the
inherent potential of high-performance data compression and signal compressed
sensing. The main disadvantages of current autoencoders comprise the following
several aspects: the research objective is not data reconstruction but feature
representation; the performance evaluation of data recovery is neglected; it is
hard to achieve lossless data reconstruction by pure autoencoders, even by pure
deep learning. This paper aims for image reconstruction of autoencoders,
employs cascade decoders-based autoencoders, perfects the performance of image
reconstruction, approaches gradually lossless image recovery, and provides
solid theory and application basis for autoencoders-based image compression and
compressed sensing. The proposed serial decoders-based autoencoders include the
architectures of multi-level decoders and the related optimization algorithms.
The cascade decoders consist of general decoders, residual decoders,
adversarial decoders and their combinations. It is evaluated by the
experimental results that the proposed autoencoders outperform the classical
autoencoders in the performance of image reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP-It! Language-Guided Video Summarization. (arXiv:2107.00650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_M/0/1/0/all/0/1">Medhini Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00650">
                                    <div class="article-summary-box-inner">
                                        <span>A generic video summary is an abridged version of a video that conveys the
whole story and features the most important scenes. Yet the importance of
scenes in a video is often subjective, and users should have the option of
customizing the summary by using natural language to specify what is important
to them. Further, existing models for fully automatic generic summarization
have not exploited available language models, which can serve as an effective
prior for saliency. This work introduces CLIP-It, a single framework for
addressing both generic and query-focused video summarization, typically
approached separately in the literature. We propose a language-guided
multimodal transformer that learns to score frames in a video based on their
importance relative to one another and their correlation with a user-defined
query (for query-focused summarization) or an automatically generated dense
video caption (for generic video summarization). Our model can be extended to
the unsupervised setting by training without ground-truth supervision. We
outperform baselines and prior work by a significant margin on both standard
video summarization datasets (TVSum and SumMe) and a query-focused video
summarization dataset (QFVS). Particularly, we achieve large improvements in
the transfer setting, attesting to our method&#x27;s strong generalization
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Compression Towards Machine Vision: Network Architecture Design and Optimization. (arXiv:2107.00328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shurun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00328">
                                    <div class="article-summary-box-inner">
                                        <span>The research of visual signal compression has a long history. Fueled by deep
learning, exciting progress has been made recently. Despite achieving better
compression performance, existing end-to-end compression algorithms are still
designed towards better signal quality in terms of rate-distortion
optimization. In this paper, we show that the design and optimization of
network architecture could be further improved for compression towards machine
vision. We propose an inverted bottleneck structure for end-to-end compression
towards machine vision, which specifically accounts for efficient
representation of the semantic information. Moreover, we quest the capability
of optimization by incorporating the analytics accuracy into the optimization
process, and the optimality is further explored with generalized rate-accuracy
optimization in an iterative manner. We use object detection as a showcase for
end-to-end compression towards machine vision, and extensive experiments show
that the proposed scheme achieves significant BD-rate savings in terms of
analysis performance. Moreover, the promise of the scheme is also demonstrated
with strong generalization capability towards other machine vision tasks, due
to the enabling of signal-level reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-01">2021-07-01</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin Information. (arXiv:2106.16038v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zijun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoya Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiaofei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yuxian Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1">Xiang Ao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qing He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiwei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16038">
                                    <div class="article-summary-box-inner">
                                        <span>Recent pretraining models in Chinese neglect two important aspects specific
to the Chinese language: glyph and pinyin, which carry significant syntax and
semantic information for language understanding. In this work, we propose
ChineseBERT, which incorporates both the {\it glyph} and {\it pinyin}
information of Chinese characters into language model pretraining. The glyph
embedding is obtained based on different fonts of a Chinese character, being
able to capture character semantics from the visual features, and the pinyin
embedding characterizes the pronunciation of Chinese characters, which handles
the highly prevalent heteronym phenomenon in Chinese (the same character has
different pronunciations with different meanings). Pretrained on large-scale
unlabeled Chinese corpus, the proposed ChineseBERT model yields significant
performance boost over baseline models with fewer training steps. The porpsoed
model achieves new SOTA performances on a wide range of Chinese NLP tasks,
including machine reading comprehension, natural language inference, text
classification, sentence pair matching, and competitive performances in named
entity recognition. Code and pretrained models are publicly available at
https://github.com/ShannonAI/ChineseBert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoLAW: Augmented Legal Reasoning through Legal Precedent Prediction. (arXiv:2106.16034v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahari_R/0/1/0/all/0/1">Robert Zev Mahari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16034">
                                    <div class="article-summary-box-inner">
                                        <span>This paper demonstrate how NLP can be used to address an unmet need of the
legal community and increase access to justice. The paper introduces Legal
Precedent Prediction (LPP), the task of predicting relevant passages from
precedential court decisions given the context of a legal argument. To this
end, the paper showcases a BERT model, trained on 530,000 examples of legal
arguments made by U.S. federal judges, to predict relevant passages from
precedential court decisions given the context of a legal argument. In 96% of
unseen test examples the correct target passage is among the top-10 predicted
passages. The same model is able to predict relevant precedent given a short
summary of a complex and unseen legal brief, predicting the precedent that was
actually cited by the brief&#x27;s co-author, former U.S. Solicitor General and
current U.S. Supreme Court Justice Elena Kagan.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CIDER: Commonsense Inference for Dialogue Explanation and Reasoning. (arXiv:2106.00510v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosal_D/0/1/0/all/0/1">Deepanway Ghosal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1">Pengfei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Siqi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00510">
                                    <div class="article-summary-box-inner">
                                        <span>Commonsense inference to understand and explain human language is a
fundamental research problem in natural language processing. Explaining human
conversations poses a great challenge as it requires contextual understanding,
planning, inference, and several aspects of reasoning including causal,
temporal, and commonsense reasoning. In this work, we introduce CIDER -- a
manually curated dataset that contains dyadic dialogue explanations in the form
of implicit and explicit knowledge triplets inferred using contextual
commonsense inference. Extracting such rich explanations from conversations can
be conducive to improving several downstream applications. The annotated
triplets are categorized by the type of commonsense knowledge present (e.g.,
causal, conditional, temporal). We set up three different tasks conditioned on
the annotated dataset: Dialogue-level Natural Language Inference, Span
Extraction, and Multi-choice Span Selection. Baseline results obtained with
transformer-based models reveal that the tasks are difficult, paving the way
for promising future research. The dataset and the baseline implementations are
publicly available at https://cider-task.github.io/cider/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IMS&#x27; Systems for the IWSLT 2021 Low-Resource Speech Translation Task. (arXiv:2106.16055v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Denisov_P/0/1/0/all/0/1">Pavel Denisov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mager_M/0/1/0/all/0/1">Manuel Mager</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1">Ngoc Thang Vu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16055">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the submission to the IWSLT 2021 Low-Resource Speech
Translation Shared Task by IMS team. We utilize state-of-the-art models
combined with several data augmentation, multi-task and transfer learning
approaches for the automatic speech recognition (ASR) and machine translation
(MT) steps of our cascaded system. Moreover, we also explore the feasibility of
a full end-to-end speech translation (ST) model in the case of very constrained
amount of ground truth labeled data. Our best system achieves the best
performance among all submitted systems for Congolese Swahili to English and
French with BLEU scores 7.7 and 13.7 respectively, and the second best result
for Coastal Swahili to English with BLEU score 14.9.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Genre determining prediction: Non-standard TAM marking in football language. (arXiv:2106.15872v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Egetenmeyer_J/0/1/0/all/0/1">Jakob Egetenmeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15872">
                                    <div class="article-summary-box-inner">
                                        <span>German and French football language display tense-aspect-mood (TAM) forms
which differ from the TAM use in other genres. In German football talk, the
present indicative may replace the pluperfect subjunctive. In French reports of
football matches, the imperfective past may occur instead of a perfective past
tense-aspect form. We argue that the two phenomena share a functional core and
are licensed in the same way, which is a direct result of the genre they occur
in. More precisely, football match reports adhere to a precise script and
specific events are temporally determined in terms of objective time. This
allows speakers to exploit a secondary function of TAM forms, namely, they
shift the temporal perspective. We argue that it is on the grounds of the genre
that comprehenders predict the deviating forms and are also able to decode
them. We present various corpus studies where we explore the functioning of
these phenomena in order to gain insights into their distribution,
grammaticalization and their functioning in discourse. Relevant factors are
Aktionsart properties, rhetorical relations and their interaction with other
TAM forms. This allows us to discuss coping mechanisms on the part of the
comprehender. We broaden our understanding of the phenomena, which have only
been partly covered for French and up to now seem to have been ignored in
German.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Whose Opinions Matter? Perspective-aware Models to Identify Opinions of Hate Speech Victims in Abusive Language Detection. (arXiv:2106.15896v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhtar_S/0/1/0/all/0/1">Sohail Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Basile_V/0/1/0/all/0/1">Valerio Basile</a>, <a href="http://arxiv.org/find/cs/1/au:+Patti_V/0/1/0/all/0/1">Viviana Patti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15896">
                                    <div class="article-summary-box-inner">
                                        <span>Social media platforms provide users the freedom of expression and a medium
to exchange information and express diverse opinions. Unfortunately, this has
also resulted in the growth of abusive content with the purpose of
discriminating people and targeting the most vulnerable communities such as
immigrants, LGBT, Muslims, Jews and women. Because abusive language is
subjective in nature, there might be highly polarizing topics or events
involved in the annotation of abusive contents such as hate speech (HS).
Therefore, we need novel approaches to model conflicting perspectives and
opinions coming from people with different personal and demographic
backgrounds. In this paper, we present an in-depth study to model polarized
opinions coming from different communities under the hypothesis that similar
characteristics (ethnicity, social background, culture etc.) can influence the
perspectives of annotators on a certain phenomenon. We believe that by relying
on this information, we can divide the annotators into groups sharing similar
perspectives. We can create separate gold standards, one for each group, to
train state-of-the-art deep learning models. We can employ an ensemble approach
to combine the perspective-aware classifiers from different groups to an
inclusive model. We also propose a novel resource, a multi-perspective English
language dataset annotated according to different sub-categories relevant for
characterising online abuse: hate speech, aggressiveness, offensiveness and
stereotype. By training state-of-the-art deep learning models on this novel
resource, we show how our approach improves the prediction performance of a
state-of-the-art supervised classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Modeling with Reduced Densities. (arXiv:2007.03834v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bradley_T/0/1/0/all/0/1">Tai-Danae Bradley</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlassopoulos_Y/0/1/0/all/0/1">Yiannis Vlassopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03834">
                                    <div class="article-summary-box-inner">
                                        <span>This work originates from the observation that today&#x27;s state of the art
statistical language models are impressive not only for their performance, but
also - and quite crucially - because they are built entirely from correlations
in unstructured text data. The latter observation prompts a fundamental
question that lies at the heart of this paper: What mathematical structure
exists in unstructured text data? We put forth enriched category theory as a
natural answer. We show that sequences of symbols from a finite alphabet, such
as those found in a corpus of text, form a category enriched over
probabilities. We then address a second fundamental question: How can this
information be stored and modeled in a way that preserves the categorical
structure? We answer this by constructing a functor from our enriched category
of text to a particular enriched category of reduced density operators. The
latter leverages the Loewner order on positive semidefinite operators, which
can further be interpreted as a toy example of entailment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XLM-E: Cross-lingual Language Model Pre-training via ELECTRA. (arXiv:2106.16138v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1">Zewen Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaohan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Li Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shuming Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Singhal_S/0/1/0/all/0/1">Saksham Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1">Payal Bajaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xia Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16138">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce ELECTRA-style tasks to cross-lingual language
model pre-training. Specifically, we present two pre-training tasks, namely
multilingual replaced token detection, and translation replaced token
detection. Besides, we pretrain the model, named as XLM-E, on both multilingual
and parallel corpora. Our model outperforms the baseline models on various
cross-lingual understanding tasks with much less computation cost. Moreover,
analysis shows that XLM-E tends to obtain better cross-lingual transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">O2D2: Out-Of-Distribution Detector to Capture Undecidable Trials in Authorship Verification. (arXiv:2106.15825v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boenninghoff_B/0/1/0/all/0/1">Benedikt Boenninghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Nickel_R/0/1/0/all/0/1">Robert M. Nickel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1">Dorothea Kolossa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15825">
                                    <div class="article-summary-box-inner">
                                        <span>The PAN 2021 authorship verification (AV) challenge is part of a three-year
strategy, moving from a cross-topic/closed-set to a cross-topic/open-set AV
task over a collection of fanfiction texts. In this work, we present our
modified hybrid neural-probabilistic framework. It is based on our 2020 winning
submission, with updates to significantly reduce sensitivities to topical
variations and to further improve the system&#x27;s calibration by means of an
uncertainty-adaptation layer. Our framework additionally includes an
Out-Of-Distribution Detector (O2D2) for defining non-responses, outperforming
all other systems that participated in the PAN 2021 AV task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SaRoCo: Detecting Satire in a Novel Romanian Corpus of News Articles. (arXiv:2105.06456v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaman_M/0/1/0/all/0/1">Mihaela Gaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06456">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce a corpus for satire detection in Romanian news. We
gathered 55,608 public news articles from multiple real and satirical news
sources, composing one of the largest corpora for satire detection regardless
of language and the only one for the Romanian language. We provide an official
split of the text samples, such that training news articles belong to different
sources than test news articles, thus ensuring that models do not achieve high
performance simply due to overfitting. We conduct experiments with two
state-of-the-art deep neural models, resulting in a set of strong baselines for
our novel corpus. Our results show that the machine-level accuracy for satire
detection in Romanian is quite low (under 73% on the test set) compared to the
human-level accuracy (87%), leaving enough room for improvement in future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Assessment of Dialog Evaluation Metrics. (arXiv:2106.03706v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeh_Y/0/1/0/all/0/1">Yi-Ting Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Eskenazi_M/0/1/0/all/0/1">Maxine Eskenazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehri_S/0/1/0/all/0/1">Shikib Mehri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03706">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic evaluation metrics are a crucial component of dialog systems
research. Standard language evaluation metrics are known to be ineffective for
evaluating dialog. As such, recent research has proposed a number of novel,
dialog-specific metrics that correlate better with human judgements. Due to the
fast pace of research, many of these metrics have been assessed on different
datasets and there has as yet been no time for a systematic comparison between
them. To this end, this paper provides a comprehensive assessment of recently
proposed dialog evaluation metrics on a number of datasets. In this paper, 17
different automatic evaluation metrics are evaluated on 10 different datasets.
Furthermore, the metrics are assessed in different settings, to better qualify
their respective strengths and weaknesses. Metrics are assessed (1) on both the
turn level and the dialog level, (2) for different dialog lengths, (3) for
different dialog qualities (e.g., coherence, engaging), (4) for different types
of response generation models (i.e., generative, retrieval, simple models and
state-of-the-art models), (5) taking into account the similarity of different
metrics and (6) exploring combinations of different metrics. This comprehensive
assessment offers several takeaways pertaining to dialog evaluation metrics in
general. It also suggests how to best assess evaluation metrics and indicates
promising directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">News Article Retrieval in Context for Event-centric Narrative Creation. (arXiv:2106.16053v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voskarides_N/0/1/0/all/0/1">Nikos Voskarides</a>, <a href="http://arxiv.org/find/cs/1/au:+Meij_E/0/1/0/all/0/1">Edgar Meij</a>, <a href="http://arxiv.org/find/cs/1/au:+Sauer_S/0/1/0/all/0/1">Sabrina Sauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16053">
                                    <div class="article-summary-box-inner">
                                        <span>Writers such as journalists often use automatic tools to find relevant
content to include in their narratives. In this paper, we focus on supporting
writers in the news domain to develop event-centric narratives. Given an
incomplete narrative that specifies a main event and a context, we aim to
retrieve news articles that discuss relevant events that would enable the
continuation of the narrative. We formally define this task and propose a
retrieval dataset construction procedure that relies on existing news articles
to simulate incomplete narratives and relevant articles. Experiments on two
datasets derived from this procedure show that state-of-the-art lexical and
semantic rankers are not sufficient for this task. We show that combining those
with a ranker that ranks articles by reverse chronological order outperforms
those rankers alone. We also perform an in-depth quantitative and qualitative
analysis of the results that sheds light on the characteristics of this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Conditional Splitting Framework for Efficient Constituency Parsing. (arXiv:2106.15760v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thanh-Tung Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1">Xuan-Phi Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15760">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a generic seq2seq parsing framework that casts constituency
parsing problems (syntactic and discourse parsing) into a series of conditional
splitting decisions. Our parsing model estimates the conditional probability
distribution of possible splitting points in a given text span and supports
efficient top-down decoding, which is linear in number of nodes. The
conditional splitting formulation together with efficient beam search inference
facilitate structural consistency without relying on expensive structured
inference. Crucially, for discourse analysis we show that in our formulation,
discourse segmentation can be framed as a special case of parsing which allows
us to perform discourse parsing without requiring segmentation as a
pre-requisite. Experiments show that our model achieves good results on the
standard syntactic parsing tasks under settings with/without pre-trained
representations and rivals state-of-the-art (SoTA) methods that are more
computationally expensive than ours. In discourse parsing, our method
outperforms SoTA by a good margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AVLnet: Learning Audio-Visual Language Representations from Instructional Videos. (arXiv:2006.09199v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1">Andrew Rouditchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boggust_A/0/1/0/all/0/1">Angie Boggust</a>, <a href="http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1">David Harwath</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Brian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_D/0/1/0/all/0/1">Dhiraj Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1">Samuel Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1">Kartik Audhkhasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehne_H/0/1/0/all/0/1">Hilde Kuehne</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1">Rameswar Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1">Rogerio Feris</a>, <a href="http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1">Brian Kingsbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1">Michael Picheny</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09199">
                                    <div class="article-summary-box-inner">
                                        <span>Current methods for learning visually grounded language from videos often
rely on text annotation, such as human generated captions or machine generated
automatic speech recognition (ASR) transcripts. In this work, we introduce the
Audio-Video Language Network (AVLnet), a self-supervised network that learns a
shared audio-visual embedding space directly from raw video inputs. To
circumvent the need for text annotation, we learn audio-visual representations
from randomly segmented video clips and their raw audio waveforms. We train
AVLnet on HowTo100M, a large corpus of publicly available instructional videos,
and evaluate on image retrieval and video retrieval tasks, achieving
state-of-the-art performance. We perform analysis of AVLnet&#x27;s learned
representations, showing our model utilizes speech and natural sounds to learn
audio-visual concepts. Further, we propose a tri-modal model that jointly
processes raw audio, video, and text captions from videos to learn a
multi-modal semantic embedding space useful for text-video retrieval. Our code,
data, and trained models will be released at avlnet.csail.mit.edu</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAT Based Analogy Evaluation Framework for Persian Word Embeddings. (arXiv:2106.15674v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmoudi_S/0/1/0/all/0/1">Seyyed Ehsan Mahmoudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsfard_M/0/1/0/all/0/1">Mehrnoush Shamsfard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15674">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years there has been a special interest in word embeddings as a new
approach to convert words to vectors. It has been a focal point to understand
how much of the semantics of the the words has been transferred into embedding
vectors. This is important as the embedding is going to be used as the basis
for downstream NLP applications and it will be costly to evaluate the
application end-to-end in order to identify quality of the used embedding
model. Generally the word embeddings are evaluated through a number of tests,
including analogy test. In this paper we propose a test framework for Persian
embedding models. Persian is a low resource language and there is no rich
semantic benchmark to evaluate word embedding models for this language. In this
paper we introduce an evaluation framework including a hand crafted Persian SAT
based analogy dataset, a colliquial test set (specific to Persian) and a
benchmark to study the impact of various parameters on the semantic evaluation
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Ask Conversational Questions by Optimizing Levenshtein Distance. (arXiv:2106.15903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhongkun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengjie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaochun Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Ming Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15903">
                                    <div class="article-summary-box-inner">
                                        <span>Conversational Question Simplification (CQS) aims to simplify self-contained
questions into conversational ones by incorporating some conversational
characteristics, e.g., anaphora and ellipsis. Existing maximum likelihood
estimation (MLE) based methods often get trapped in easily learned tokens as
all tokens are treated equally during training. In this work, we introduce a
Reinforcement Iterative Sequence Editing (RISE) framework that optimizes the
minimum Levenshtein distance (MLD) through explicit editing actions. RISE is
able to pay attention to tokens that are related to conversational
characteristics. To train RISE, we devise an Iterative Reinforce Training (IRT)
algorithm with a Dynamic Programming based Sampling (DPS) process to improve
exploration. Experimental results on two benchmark datasets show that RISE
significantly outperforms state-of-the-art methods and generalizes well on
unseen data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Risk Detection of Pathological Gambling, Self-Harm and Depression Using BERT. (arXiv:2106.16175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bucur_A/0/1/0/all/0/1">Ana-Maria Bucur</a>, <a href="http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1">Adrian Cosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinu_L/0/1/0/all/0/1">Liviu P. Dinu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16175">
                                    <div class="article-summary-box-inner">
                                        <span>Early risk detection of mental illnesses has a massive positive impact upon
the well-being of people. The eRisk workshop has been at the forefront of
enabling interdisciplinary research in developing computational methods to
automatically estimate early risk factors for mental issues such as depression,
self-harm, anorexia and pathological gambling. In this paper, we present the
contributions of the BLUE team in the 2021 edition of the workshop, in which we
tackle the problems of early detection of gambling addiction, self-harm and
estimating depression severity from social media posts. We employ pre-trained
BERT transformers and data crawled automatically from mental health subreddits
and obtain reasonable results on all three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers. (arXiv:2106.15772v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miao_S/0/1/0/all/0/1">Shen-Yun Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chao-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_K/0/1/0/all/0/1">Keh-Yih Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15772">
                                    <div class="article-summary-box-inner">
                                        <span>We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms
of both language patterns and problem types) English math word problem (MWP)
corpus for evaluating the capability of various MWP solvers. Existing MWP
corpora for studying AI progress remain limited either in language usage
patterns or in problem types. We thus present a new English MWP corpus with
2,305 MWPs that cover more text patterns and most problem types taught in
elementary school. Each MWP is annotated with its problem type and grade level
(for indicating the level of difficulty). Furthermore, we propose a metric to
measure the lexicon usage diversity of a given MWP corpus, and demonstrate that
ASDiv is more diverse than existing corpora. Experiments show that our proposed
corpus reflects the true capability of MWP solvers more faithfully.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed Cross Entropy Loss for Neural Machine Translation. (arXiv:2106.15880v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15880">
                                    <div class="article-summary-box-inner">
                                        <span>In neural machine translation, cross entropy (CE) is the standard loss
function in two training methods of auto-regressive models, i.e., teacher
forcing and scheduled sampling. In this paper, we propose mixed cross entropy
loss (mixed CE) as a substitute for CE in both training approaches. In teacher
forcing, the model trained with CE regards the translation problem as a
one-to-one mapping process, while in mixed CE this process can be relaxed to
one-to-many. In scheduled sampling, we show that mixed CE has the potential to
encourage the training and testing behaviours to be similar to each other, more
effectively mitigating the exposure bias problem. We demonstrate the
superiority of mixed CE over CE on several machine translation datasets, WMT&#x27;16
Ro-En, WMT&#x27;16 Ru-En, and WMT&#x27;14 En-De in both teacher forcing and scheduled
sampling setups. Furthermore, in WMT&#x27;14 En-De, we also find mixed CE
consistently outperforms CE on a multi-reference set as well as a challenging
paraphrased reference set. We also found the model trained with mixed CE is
able to provide a better probability distribution defined over the translation
output space. Our code is available at https://github.com/haorannlp/mix.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Analysis of the Recent Visibility of the SigDial Conference. (arXiv:2106.16196v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kennington_C/0/1/0/all/0/1">Casey Kennington</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenson_M/0/1/0/all/0/1">McKenzie Steenson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16196">
                                    <div class="article-summary-box-inner">
                                        <span>Automated speech and text interfaces are continuing to improve, resulting in
increased research in the area of dialogue systems. Moreover, conferences and
workshops from various fields are focusing more on language through speech and
text mediums as candidates for interaction with applications such as search
interfaces and robots. In this paper, we explore how visible the SigDial
conference is to outside conferences by analysing papers from top Natural
Langauge Processing conferences since 2015 to determine the popularity of
certain SigDial-related topics, as well as analysing what SigDial papers are
being cited by others outside of SigDial. We find that despite a dramatic
increase in dialogue-related research, SigDial visibility has not increased. We
conclude by offering some suggestions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Power of Saturated Transformers: A View from Circuit Complexity. (arXiv:2106.16213v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1">William Merrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1">Roy Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16213">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become a standard architecture for many NLP problems. This
has motivated theoretically analyzing their capabilities as models of language,
in order to understand what makes them successful, and what their potential
weaknesses might be. Recent work has shown that transformers with hard
attention are quite limited in capacity, and in fact can be simulated by
constant-depth circuits. However, hard attention is a restrictive assumption,
which may complicate the relevance of these results for practical transformers.
In this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We show that saturated
transformers transcend the limitations of hard-attention transformers. With
some minor assumptions, we prove that the number of bits needed to represent a
saturated transformer memory vector is $O(\log n)$, which implies saturated
transformers can be simulated by log-depth circuits. Thus, the jump from hard
to saturated attention can be understood as increasing the transformer&#x27;s
effective circuit depth by a factor of $O(\log n)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Thematic Coherence in Microblogs. (arXiv:2106.15971v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bilal_I/0/1/0/all/0/1">Iman Munire Bilal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liakata_M/0/1/0/all/0/1">Maria Liakata</a>, <a href="http://arxiv.org/find/cs/1/au:+Procter_R/0/1/0/all/0/1">Rob Procter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1">Adam Tsakalidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15971">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting together microblogs representing opinions about the same topics
within the same timeframe is useful to a number of different tasks and
practitioners. A major question is how to evaluate the quality of such thematic
clusters. Here we create a corpus of microblog clusters from three different
domains and time windows and define the task of evaluating thematic coherence.
We provide annotation guidelines and human annotations of thematic coherence by
journalist experts. We subsequently investigate the efficacy of different
automated evaluation metrics for the task. We consider a range of metrics
including surface level metrics, ones for topic model coherence and text
generation metrics (TGMs). While surface level metrics perform well,
outperforming topic coherence metrics, they are not as consistent as TGMs. TGMs
are more reliable than all other metrics considered for capturing thematic
coherence in microblog clusters due to being less sensitive to the effect of
time windows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Factual Consistency of Abstractive Summarization on Customer Feedback. (arXiv:2106.16188v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yifei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1">Vincent Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16188">
                                    <div class="article-summary-box-inner">
                                        <span>E-commerce stores collect customer feedback to let sellers learn about
customer concerns and enhance customer order experience. Because customer
feedback often contains redundant information, a concise summary of the
feedback can be generated to help sellers better understand the issues causing
customer dissatisfaction. Previous state-of-the-art abstractive text
summarization models make two major types of factual errors when producing
summaries from customer feedback, which are wrong entity detection (WED) and
incorrect product-defect description (IPD). In this work, we introduce a set of
methods to enhance the factual consistency of abstractive summarization on
customer feedback. We augment the training data with artificially corrupted
summaries, and use them as counterparts of the target summaries. We add a
contrastive loss term into the training objective so that the model learns to
avoid certain factual errors. Evaluation results show that a large portion of
WED and IPD errors are alleviated for BART and T5. Furthermore, our approaches
do not depend on the structure of the summarization model and thus are
generalizable to any abstractive summarization systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiSubs: A Large-scale Multimodal and Multilingual Dataset. (arXiv:2103.01910v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Josiah Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhyastha_P/0/1/0/all/0/1">Pranava Madhyastha</a>, <a href="http://arxiv.org/find/cs/1/au:+Figueiredo_J/0/1/0/all/0/1">Josiel Figueiredo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lala_C/0/1/0/all/0/1">Chiraag Lala</a>, <a href="http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1">Lucia Specia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01910">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a large-scale multimodal and multilingual dataset that
aims to facilitate research on grounding words to images in their contextual
usage in language. The dataset consists of images selected to unambiguously
illustrate concepts expressed in sentences from movie subtitles. The dataset is
a valuable resource as (i) the images are aligned to text fragments rather than
whole sentences; (ii) multiple images are possible for a text fragment and a
sentence; (iii) the sentences are free-form and real-world like; (iv) the
parallel texts are multilingual. We set up a fill-in-the-blank game for humans
to evaluate the quality of the automatic image selection process of our
dataset. We show the utility of the dataset on two automatic tasks: (i)
fill-in-the blank; (ii) lexical translation. Results of the human evaluation
and automatic models demonstrate that images can be a useful complement to the
textual context. The dataset will benefit research on visual grounding of words
especially in the context of free-form sentences, and can be obtained from
https://doi.org/10.5281/zenodo.5034604 under a Creative Commons licence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatically Select Emotion for Response via Personality-affected Emotion Transition. (arXiv:2106.15846v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhiyuan_W/0/1/0/all/0/1">Wen Zhiyuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiannong_C/0/1/0/all/0/1">Cao Jiannong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruosong_Y/0/1/0/all/0/1">Yang Ruosong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shuaiqi_L/0/1/0/all/0/1">Liu Shuaiqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiaxing_S/0/1/0/all/0/1">Shen Jiaxing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15846">
                                    <div class="article-summary-box-inner">
                                        <span>To provide consistent emotional interaction with users, dialog systems should
be capable to automatically select appropriate emotions for responses like
humans. However, most existing works focus on rendering specified emotions in
responses or empathetically respond to the emotion of users, yet the individual
difference in emotion expression is overlooked. This may lead to inconsistent
emotional expressions and disinterest users. To tackle this issue, we propose
to equip the dialog system with personality and enable it to automatically
select emotions in responses by simulating the emotion transition of humans in
conversation. In detail, the emotion of the dialog system is transitioned from
its preceding emotion in context. The transition is triggered by the preceding
dialog context and affected by the specified personality trait. To achieve
this, we first model the emotion transition in the dialog system as the
variation between the preceding emotion and the response emotion in the
Valence-Arousal-Dominance (VAD) emotion space. Then, we design neural networks
to encode the preceding dialog context and the specified personality traits to
compose the variation. Finally, the emotion for response is selected from the
sum of the preceding emotion and the variation. We construct a dialog dataset
with emotion and personality labels and conduct emotion prediction tasks for
evaluation. Experimental results validate the effectiveness of the
personality-affected emotion transition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Volctrans Neural Speech Translation System for IWSLT 2021. (arXiv:2105.07319v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chengqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_J/0/1/0/all/0/1">Jian Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rong Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qianqian Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07319">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the systems submitted to IWSLT 2021 by the Volctrans
team. We participate in the offline speech translation and text-to-text
simultaneous translation tracks. For offline speech translation, our best
end-to-end model achieves 8.1 BLEU improvements over the benchmark on the
MuST-C test set and is even approaching the results of a strong cascade
solution. For text-to-text simultaneous translation, we explore the best
practice to optimize the wait-k model. As a result, our final submitted systems
exceed the benchmark at around 7 BLEU on the same latency regime. We will
publish our code and model to facilitate both future research works and
industrial applications.

This paper describes the systems submitted to IWSLT 2021 by the Volctrans
team. We participate in the offline speech translation and text-to-text
simultaneous translation tracks. For offline speech translation, our best
end-to-end model achieves 7.9 BLEU improvements over the benchmark on the
MuST-C test set and is even approaching the results of a strong cascade
solution. For text-to-text simultaneous translation, we explore the best
practice to optimize the wait-k model. As a result, our final submitted systems
exceed the benchmark at around 7 BLEU on the same latency regime. We release
our code and model at
\url{https://github.com/bytedance/neurst/tree/master/examples/iwslt21} to
facilitate both future research works and industrial applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Can Unsupervised Machine Translation Contribute to High-Resource Language Pairs?. (arXiv:2106.15818v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchisio_K/0/1/0/all/0/1">Kelly Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1">Markus Freitag</a>, <a href="http://arxiv.org/find/cs/1/au:+Grangier_D/0/1/0/all/0/1">David Grangier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15818">
                                    <div class="article-summary-box-inner">
                                        <span>Whereas existing literature on unsupervised machine translation (MT) focuses
on exploiting unsupervised techniques for low-resource language pairs where
bilingual training data is scare or unavailable, we investigate whether
unsupervised MT can also improve translation quality of high-resource language
pairs where sufficient bitext does exist. We compare the style of correct
translations generated by either supervised or unsupervised MT and find that
the unsupervised output is less monotonic and more natural than supervised
output. We demonstrate a way to combine the benefits of unsupervised and
supervised MT into a single system, resulting in better human evaluation of
quality and fluency. Our results open the door to discussions about the
potential contributions of unsupervised MT in high-resource settings, and how
supervised and unsupervised systems might be mutually-beneficial.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Domain Knowledge for Extractive Summarization of Legal Case Documents. (arXiv:2106.15876v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1">Paheli Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Poddar_S/0/1/0/all/0/1">Soham Poddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudra_K/0/1/0/all/0/1">Koustav Rudra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1">Kripabandhu Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Saptarshi Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15876">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic summarization of legal case documents is an important and practical
challenge. Apart from many domain-independent text summarization algorithms
that can be used for this purpose, several algorithms have been developed
specifically for summarizing legal case documents. However, most of the
existing algorithms do not systematically incorporate domain knowledge that
specifies what information should ideally be present in a legal case document
summary. To address this gap, we propose an unsupervised summarization
algorithm DELSumm which is designed to systematically incorporate guidelines
from legal experts into an optimization setup. We conduct detailed experiments
over case documents from the Indian Supreme Court. The experiments show that
our proposed unsupervised method outperforms several strong baselines in terms
of ROUGE scores, including both general summarization algorithms and
legal-specific ones. In fact, though our proposed algorithm is unsupervised, it
outperforms several supervised summarization models that are trained over
thousands of document-summary pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-Shot Estimation of Base Models&#x27; Weights in Ensemble of Machine Reading Comprehension Systems for Robust Generalization. (arXiv:2106.16013v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baradaran_R/0/1/0/all/0/1">Razieh Baradaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirkhani_H/0/1/0/all/0/1">Hossein Amirkhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16013">
                                    <div class="article-summary-box-inner">
                                        <span>One of the main challenges of the machine reading comprehension (MRC) models
is their fragile out-of-domain generalization, which makes these models not
properly applicable to real-world general-purpose question answering problems.
In this paper, we leverage a zero-shot weighted ensemble method for improving
the robustness of out-of-domain generalization in MRC models. In the proposed
method, a weight estimation module is used to estimate out-of-domain weights,
and an ensemble module aggregate several base models&#x27; predictions based on
their weights. The experiments indicate that the proposed method not only
improves the final accuracy, but also is robust against domain changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-lingual alignments of ELMo contextual embeddings. (arXiv:2106.15986v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ulcar_M/0/1/0/all/0/1">Matej Ul&#x10d;ar</a>, <a href="http://arxiv.org/find/cs/1/au:+Robnik_Sikonja_M/0/1/0/all/0/1">Marko Robnik-&#x160;ikonja</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15986">
                                    <div class="article-summary-box-inner">
                                        <span>Building machine learning prediction models for a specific NLP task requires
sufficient training data, which can be difficult to obtain for low-resource
languages. Cross-lingual embeddings map word embeddings from a low-resource
language to a high-resource language so that a prediction model trained on data
from the high-resource language can also be used in the low-resource language.
To produce cross-lingual mappings of recent contextual embeddings, anchor
points between the embedding spaces have to be words in the same context. We
address this issue with a new method for creating datasets for cross-lingual
contextual alignments. Based on that, we propose novel cross-lingual mapping
methods for ELMo embeddings. Our linear mapping methods use existing vecmap and
MUSE alignments on contextual ELMo embeddings. Our new nonlinear ELMoGAN
mapping method is based on GANs and does not assume isomorphic embedding
spaces. We evaluate the proposed mapping methods on nine languages, using two
downstream tasks, NER and dependency parsing. The ELMoGAN method performs well
on the NER task, with low cross-lingual loss compared to direct training on
some languages. In the dependency parsing, linear alignment variants are more
successful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HySPA: Hybrid Span Generation for Scalable Text-to-Graph Extraction. (arXiv:2106.15838v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1">Liliang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chenkai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Hockenmaier_J/0/1/0/all/0/1">Julia Hockenmaier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15838">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-Graph extraction aims to automatically extract information graphs
consisting of mentions and types from natural language texts. Existing
approaches, such as table filling and pairwise scoring, have shown impressive
performance on various information extraction tasks, but they are difficult to
scale to datasets with longer input texts because of their second-order
space/time complexities with respect to the input length. In this work, we
propose a Hybrid Span Generator (HySPA) that invertibly maps the information
graph to an alternating sequence of nodes and edge types, and directly
generates such sequences via a hybrid span decoder which can decode both the
spans and the types recurrently in linear time and space complexities.
Extensive experiments on the ACE05 dataset show that our approach also
significantly outperforms state-of-the-art on the joint entity and relation
extraction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoding Time Lexical Domain Adaptation for Neural Machine Translation. (arXiv:2101.00421v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bogoychev_N/0/1/0/all/0/1">Nikolay Bogoychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pinzhen Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00421">
                                    <div class="article-summary-box-inner">
                                        <span>Machine translation systems are vulnerable to domain mismatch, especially
when the task is low-resource. In this setting, out of domain translations are
often of poor quality and prone to hallucinations, due to the translation model
preferring to predict common words it has seen during training, as opposed to
the more uncommon ones from a different domain. We present two simple methods
for improving translation quality in this particular setting: First, we use
lexical shortlisting in order to restrict the neural network predictions by IBM
model computed alignments. Second, we perform $n$-best list reordering by
reranking all translations based on the amount they overlap with each other.
Our methods are computationally simpler and faster than alternative approaches,
and show a moderate success on low-resource settings with explicit out of
domain test sets. However, our methods lose their effectiveness when the domain
mismatch is too great, or in high resource setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The MultiBERTs: BERT Reproductions for Robustness Analysis. (arXiv:2106.16163v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sellam_T/0/1/0/all/0/1">Thibault Sellam</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadlowsky_S/0/1/0/all/0/1">Steve Yadlowsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1">Naomi Saphra</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1">Alexander D&#x27;Amour</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1">Tal Linzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastings_J/0/1/0/all/0/1">Jasmijn Bastings</a>, <a href="http://arxiv.org/find/cs/1/au:+Turc_I/0/1/0/all/0/1">Iulia Turc</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1">Jacob Eisenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1">Dipanjan Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenney_I/0/1/0/all/0/1">Ian Tenney</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1">Ellie Pavlick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16163">
                                    <div class="article-summary-box-inner">
                                        <span>Experiments with pretrained models such as BERT are often based on a single
checkpoint. While the conclusions drawn apply to the artifact (i.e., the
particular instance of the model), it is not always clear whether they hold for
the more general procedure (which includes the model architecture, training
data, initialization scheme, and loss function). Recent work has shown that
re-running pretraining can lead to substantially different conclusions about
performance, suggesting that alternative evaluations are needed to make
principled statements about procedures. To address this question, we introduce
MultiBERTs: a set of 25 BERT-base checkpoints, trained with similar
hyper-parameters as the original BERT model but differing in random
initialization and data shuffling. The aim is to enable researchers to draw
robust and statistically justified conclusions about pretraining procedures.
The full release includes 25 fully trained checkpoints, as well as statistical
guidelines and a code library implementing our recommended hypothesis testing
methods. Finally, for five of these models we release a set of 28 intermediate
checkpoints in order to support research on learning dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Spoken Language Understanding using RNN-Transducer ASR. (arXiv:2106.15919v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raju_A/0/1/0/all/0/1">Anirudh Raju</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_G/0/1/0/all/0/1">Gautam Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1">Milind Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dheram_P/0/1/0/all/0/1">Pranav Dheram</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Bryan Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_B/0/1/0/all/0/1">Bach Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1">Ariya Rastrow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15919">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an end-to-end trained spoken language understanding (SLU) system
that extracts transcripts, intents and slots from an input speech utterance. It
consists of a streaming recurrent neural network transducer (RNNT) based
automatic speech recognition (ASR) model connected to a neural natural language
understanding (NLU) model through a neural interface. This interface allows for
end-to-end training using multi-task RNNT and NLU losses. Additionally, we
introduce semantic sequence loss training for the joint RNNT-NLU system that
allows direct optimization of non-differentiable SLU metrics. This end-to-end
SLU model paradigm can leverage state-of-the-art advancements and pretrained
models in both ASR and NLU research communities, outperforming recently
proposed direct speech-to-semantics models, and conventional pipelined ASR and
NLU systems. We show that this method improves both ASR and NLU metrics on both
public SLU datasets and large proprietary datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs. (arXiv:2106.15684v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rohanian_M/0/1/0/all/0/1">Morteza Rohanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hough_J/0/1/0/all/0/1">Julian Hough</a>, <a href="http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1">Matthew Purver</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15684">
                                    <div class="article-summary-box-inner">
                                        <span>We present two multimodal fusion-based deep learning models that consume ASR
transcribed speech and acoustic data simultaneously to classify whether a
speaker in a structured diagnostic task has Alzheimer&#x27;s Disease and to what
degree, evaluating the ADReSSo challenge 2021 data. Our best model, a BiLSTM
with highway layers using words, word probabilities, disfluency features, pause
information, and a variety of acoustic features, achieves an accuracy of 84%
and RSME error prediction of 4.26 on MMSE cognitive scores. While predicting
cognitive decline is more challenging, our models show improvement using the
multimodal approach and word probabilities, disfluency and pause information
over word-only models. We show considerable gains for AD classification using
multimodal fusion and gating, which can effectively deal with noisy inputs from
acoustic features and ASR hypotheses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting the Primacy of English in Zero-shot Cross-lingual Transfer. (arXiv:2106.16171v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turc_I/0/1/0/all/0/1">Iulia Turc</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kenton Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1">Jacob Eisenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Ming-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Toutanova_K/0/1/0/all/0/1">Kristina Toutanova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16171">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their success, large pre-trained multilingual models have not
completely alleviated the need for labeled data, which is cumbersome to collect
for all target languages. Zero-shot cross-lingual transfer is emerging as a
practical solution: pre-trained models later fine-tuned on one transfer
language exhibit surprising performance when tested on many target languages.
English is the dominant source language for transfer, as reinforced by popular
zero-shot benchmarks. However, this default choice has not been systematically
vetted. In our study, we compare English against other transfer languages for
fine-tuning, on two pre-trained multilingual models (mBERT and mT5) and
multiple classification and question answering tasks. We find that other
high-resource languages such as German and Russian often transfer more
effectively, especially when the set of target languages is diverse or unknown
a priori. Unexpectedly, this can be true even when the training sets were
automatically translated from English. This finding can have immediate impact
on multilingual zero-shot systems, and should inform future benchmark designs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source Domain Adaptation for Object Detection. (arXiv:2106.15793v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xingxu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sicheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pengfei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jufeng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15793">
                                    <div class="article-summary-box-inner">
                                        <span>To reduce annotation labor associated with object detection, an increasing
number of studies focus on transferring the learned knowledge from a labeled
source domain to another unlabeled target domain. However, existing methods
assume that the labeled data are sampled from a single source domain, which
ignores a more generalized scenario, where labeled data are from multiple
source domains. For the more challenging task, we propose a unified Faster
R-CNN based framework, termed Divide-and-Merge Spindle Network (DMSN), which
can simultaneously enhance domain invariance and preserve discriminative power.
Specifically, the framework contains multiple source subnets and a pseudo
target subnet. First, we propose a hierarchical feature alignment strategy to
conduct strong and weak alignments for low- and high-level features,
respectively, considering their different effects for object detection. Second,
we develop a novel pseudo subnet learning algorithm to approximate optimal
parameters of pseudo target subset by weighted combination of parameters in
different source subnets. Finally, a consistency regularization for region
proposal network is proposed to facilitate each subnet to learn more abstract
invariances. Extensive experiments on different adaptation scenarios
demonstrate the effectiveness of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">10-mega pixel snapshot compressive imaging with a hybrid coded aperture. (arXiv:2106.15765v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihong Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_C/0/1/0/all/0/1">Chao Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_X/0/1/0/all/0/1">Xin Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Suo_J/0/1/0/all/0/1">Jinli Suo</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_Q/0/1/0/all/0/1">Qionghai Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15765">
                                    <div class="article-summary-box-inner">
                                        <span>High resolution images are widely used in our daily life, whereas high-speed
video capture is challenging due to the low frame rate of cameras working at
the high resolution mode. Digging deeper, the main bottleneck lies in the low
throughput of existing imaging systems. Towards this end, snapshot compressive
imaging (SCI) was proposed as a promising solution to improve the throughput of
imaging systems by compressive sampling and computational reconstruction.
During acquisition, multiple high-speed images are encoded and collapsed to a
single measurement. After this, algorithms are employed to retrieve the video
frames from the coded snapshot. Recently developed Plug-and-Play (PnP)
algorithms make it possible for SCI reconstruction in large-scale problems.
However, the lack of high-resolution encoding systems still precludes SCI&#x27;s
wide application. In this paper, we build a novel hybrid coded aperture
snapshot compressive imaging (HCA-SCI) system by incorporating a dynamic liquid
crystal on silicon and a high-resolution lithography mask. We further implement
a PnP reconstruction algorithm with cascaded denoisers for high quality
reconstruction. Based on the proposed HCA-SCI system and algorithm, we achieve
a 10-mega pixel SCI system to capture high-speed scenes, leading to a high
throughput of 4.6G voxels per second. Both simulation and real data experiments
verify the feasibility and performance of our proposed HCA-SCI scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recognizing Facial Expressions in the Wild using Multi-Architectural Representations based Ensemble Learning with Distillation. (arXiv:2106.16126v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Momin_R/0/1/0/all/0/1">Rauf Momin</a>, <a href="http://arxiv.org/find/cs/1/au:+Momin_A/0/1/0/all/0/1">Ali Shan Momin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_K/0/1/0/all/0/1">Khalid Rasheed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16126">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expressions are the most universal forms of body language and
automatic facial expression recognition is one of the challenging tasks due to
different uncertainties. However, it has been an active field of research for
many years. Nevertheless, efficiency and performance are yet essential aspects
for building robust systems. We proposed two models, EmoXNet which is an
ensemble learning technique for learning convoluted facial representations, and
EmoXNetLite which is a distillation technique that is useful for transferring
the knowledge from our ensemble model to an efficient deep neural network using
label-smoothen soft labels for able to effectively detect expressions in
real-time. Both of the techniques performed quite well, where the ensemble
model (EmoXNet) helped to achieve 85.07% test accuracy on FER2013 with FER+
annotations and 86.25% test accuracy on RAF-DB. Moreover, the distilled model
(EmoXNetLite) showed 82.07% test accuracy on FER2013 with FER+ annotations and
81.78% test accuracy on RAF-DB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning. (arXiv:2106.05953v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1">Adrian Spurr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahiya_A/0/1/0/all/0/1">Aneesh Dahiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xucong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05953">
                                    <div class="article-summary-box-inner">
                                        <span>Acquiring accurate 3D annotated data for hand pose estimation is a
notoriously difficult problem. This typically requires complex multi-camera
setups and controlled conditions, which in turn creates a domain gap that is
hard to bridge to fully unconstrained settings. Encouraged by the success of
contrastive learning on image classification tasks, we propose a new
self-supervised method for the structured regression task of 3D hand pose
estimation. Contrastive learning makes use of unlabeled data for the purpose of
representation learning via a loss formulation that encourages the learned
feature representations to be invariant under any image transformation. For 3D
hand pose estimation, it too is desirable to have invariance to appearance
transformation such as color jitter. However, the task requires equivariance
under affine transformations, such as rotation and translation. To address this
issue, we propose an equivariant contrastive objective and demonstrate its
effectiveness in the context of 3D hand pose estimation. We experimentally
investigate the impact of invariant and equivariant contrastive objectives and
show that learning equivariant features leads to better representations for the
task of 3D hand pose estimation. Furthermore, we show that a standard
ResNet-152, trained on additional unlabeled data, attains an improvement of
$7.6\%$ in PA-EPE on FreiHAND and thus achieves state-of-the-art performance
without any task specific, specialized architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Align Yourself: Self-supervised Pre-training for Fine-grained Recognition via Saliency Alignment. (arXiv:2106.15788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1">Zelin Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Lei Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Baigui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15788">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised contrastive learning has demonstrated great potential in
learning visual representations. Despite their success on various downstream
tasks such as image classification and object detection, self-supervised
pre-training for fine-grained scenarios is not fully explored. In this paper,
we first point out that current contrastive methods are prone to memorizing
background/foreground texture and therefore have a limitation in localizing the
foreground object. Analysis suggests that learning to extract discriminative
texture information and localization are equally crucial for self-supervised
pre-training under fine-grained scenarios. Based on our findings, we introduce
Cross-view Saliency Alignment (CVSA), a contrastive learning framework that
first crops and swaps saliency regions of images as a novel view generation and
then guides the model to localize on the foreground object via a cross-view
alignment loss. Extensive experiments on four popular fine-grained
classification benchmarks show that CVSA significantly improves the learned
representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AVLnet: Learning Audio-Visual Language Representations from Instructional Videos. (arXiv:2006.09199v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1">Andrew Rouditchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boggust_A/0/1/0/all/0/1">Angie Boggust</a>, <a href="http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1">David Harwath</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Brian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_D/0/1/0/all/0/1">Dhiraj Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1">Samuel Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1">Kartik Audhkhasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehne_H/0/1/0/all/0/1">Hilde Kuehne</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1">Rameswar Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1">Rogerio Feris</a>, <a href="http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1">Brian Kingsbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1">Michael Picheny</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09199">
                                    <div class="article-summary-box-inner">
                                        <span>Current methods for learning visually grounded language from videos often
rely on text annotation, such as human generated captions or machine generated
automatic speech recognition (ASR) transcripts. In this work, we introduce the
Audio-Video Language Network (AVLnet), a self-supervised network that learns a
shared audio-visual embedding space directly from raw video inputs. To
circumvent the need for text annotation, we learn audio-visual representations
from randomly segmented video clips and their raw audio waveforms. We train
AVLnet on HowTo100M, a large corpus of publicly available instructional videos,
and evaluate on image retrieval and video retrieval tasks, achieving
state-of-the-art performance. We perform analysis of AVLnet&#x27;s learned
representations, showing our model utilizes speech and natural sounds to learn
audio-visual concepts. Further, we propose a tri-modal model that jointly
processes raw audio, video, and text captions from videos to learn a
multi-modal semantic embedding space useful for text-video retrieval. Our code,
data, and trained models will be released at avlnet.csail.mit.edu</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Famous Companies Use More Letters in Logo:A Large-Scale Analysis of Text Area in Logo. (arXiv:2104.00327v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nishi_S/0/1/0/all/0/1">Shintaro Nishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadota_T/0/1/0/all/0/1">Takeaki Kadota</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00327">
                                    <div class="article-summary-box-inner">
                                        <span>This paper analyzes a large number of logo images from the LLD-logo dataset,
by recent deep learning-based techniques, to understand not only design trends
of logo images and but also the correlation to their owner company. Especially,
we focus on three correlations between logo images and their text areas,
between the text areas and the number of followers on Twitter, and between the
logo images and the number of followers. Various findings include the weak
positive correlation between the text area ratio and the number of followers of
the company. In addition, deep regression and deep ranking methods can catch
correlations between the logo images and the number of followers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">STRESS: Super-Resolution for Dynamic Fetal MRI using Self-Supervised Learning. (arXiv:2106.12407v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Junshen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Turk_E/0/1/0/all/0/1">Esra Abaci Turk</a>, <a href="http://arxiv.org/find/eess/1/au:+Grant_P/0/1/0/all/0/1">P. Ellen Grant</a>, <a href="http://arxiv.org/find/eess/1/au:+Golland_P/0/1/0/all/0/1">Polina Golland</a>, <a href="http://arxiv.org/find/eess/1/au:+Adalsteinsson_E/0/1/0/all/0/1">Elfar Adalsteinsson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12407">
                                    <div class="article-summary-box-inner">
                                        <span>Fetal motion is unpredictable and rapid on the scale of conventional MR scan
times. Therefore, dynamic fetal MRI, which aims at capturing fetal motion and
dynamics of fetal function, is limited to fast imaging techniques with
compromises in image quality and resolution. Super-resolution for dynamic fetal
MRI is still a challenge, especially when multi-oriented stacks of image slices
for oversampling are not available and high temporal resolution for recording
the dynamics of the fetus or placenta is desired. Further, fetal motion makes
it difficult to acquire high-resolution images for supervised learning methods.
To address this problem, in this work, we propose STRESS (Spatio-Temporal
Resolution Enhancement with Simulated Scans), a self-supervised
super-resolution framework for dynamic fetal MRI with interleaved slice
acquisitions. Our proposed method simulates an interleaved slice acquisition
along the high-resolution axis on the originally acquired data to generate
pairs of low- and high-resolution images. Then, it trains a super-resolution
network by exploiting both spatial and temporal correlations in the MR time
series, which is used to enhance the resolution of the original data.
Evaluations on both simulated and in utero data show that our proposed method
outperforms other self-supervised super-resolution methods and improves image
quality, which is beneficial to other downstream tasks and evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiAdam: Fast Adaptive Bilevel Optimization Methods. (arXiv:2106.11396v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1">Feihu Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11396">
                                    <div class="article-summary-box-inner">
                                        <span>Bilevel optimization recently has attracted increased interest in machine
learning due to its many applications such as hyper-parameter optimization and
policy optimization. Although some methods recently have been proposed to solve
the bilevel problems, these methods do not consider using adaptive learning
rates. To fill this gap, in the paper, we propose a class of fast and effective
adaptive methods for solving bilevel optimization problems that the outer
problem is possibly nonconvex and the inner problem is strongly-convex.
Specifically, we propose a fast single-loop BiAdam algorithm based on the basic
momentum technique, which achieves a sample complexity of
$\tilde{O}(\epsilon^{-4})$ for finding an $\epsilon$-stationary point. At the
same time, we propose an accelerated version of BiAdam algorithm (VR-BiAdam) by
using variance reduced technique, which reaches the best known sample
complexity of $\tilde{O}(\epsilon^{-3})$. To further reduce computation in
estimating derivatives, we propose a fast single-loop stochastic approximated
BiAdam algorithm (saBiAdam) by avoiding the Hessian inverse, which still
achieves a sample complexity of $\tilde{O}(\epsilon^{-4})$ without large
batches. We further present an accelerated version of saBiAdam algorithm
(VR-saBiAdam), which also reaches the best known sample complexity of
$\tilde{O}(\epsilon^{-3})$. We apply the unified adaptive matrices to our
methods as the SUPER-ADAM \citep{huang2021super}, which including many types of
adaptive learning rates. Moreover, our framework can flexibly use the momentum
and variance reduced techniques. In particular, we provide a useful convergence
analysis framework for both the constrained and unconstrained bilevel
optimization. To the best of our knowledge, we first study the adaptive bilevel
optimization methods with adaptive learning rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Zero-Shot Hashing for Multilabel Image Retrieval. (arXiv:1911.07192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_Q/0/1/0/all/0/1">Qin Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Ling Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Song Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.07192">
                                    <div class="article-summary-box-inner">
                                        <span>Hash coding has been widely used in approximate nearest neighbor search for
large-scale image retrieval. Given semantic annotations such as class labels
and pairwise similarities of the training data, hashing methods can learn and
generate effective and compact binary codes. While some newly introduced images
may contain undefined semantic labels, which we call unseen images, zeor-shot
hashing techniques have been studied. However, existing zeor-shot hashing
methods focus on the retrieval of single-label images, and cannot handle
multi-label images. In this paper, for the first time, a novel transductive
zero-shot hashing method is proposed for multi-label unseen image retrieval. In
order to predict the labels of the unseen/target data, a visual-semantic bridge
is built via instance-concept coherence ranking on the seen/source data. Then,
pairwise similarity loss and focal quantization loss are constructed for
training a hashing model using both the seen/source and unseen/target data.
Extensive evaluations on three popular multi-label datasets demonstrate that,
the proposed hashing method achieves significantly better results than the
competing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Muti-view Mouse Social Behaviour Recognition with Deep Graphical Model. (arXiv:2011.02451v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zheheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feixiang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1">Aite Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Ling Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuelong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02451">
                                    <div class="article-summary-box-inner">
                                        <span>Home-cage social behaviour analysis of mice is an invaluable tool to assess
therapeutic efficacy of neurodegenerative diseases. Despite tremendous efforts
made within the research community, single-camera video recordings are mainly
used for such analysis. Because of the potential to create rich descriptions of
mouse social behaviors, the use of multi-view video recordings for rodent
observations is increasingly receiving much attention. However, identifying
social behaviours from various views is still challenging due to the lack of
correspondence across data sources. To address this problem, we here propose a
novel multiview latent-attention and dynamic discriminative model that jointly
learns view-specific and view-shared sub-structures, where the former captures
unique dynamics of each view whilst the latter encodes the interaction between
the views. Furthermore, a novel multi-view latent-attention variational
autoencoder model is introduced in learning the acquired features, enabling us
to learn discriminative features in each view. Experimental results on the
standard CRMI13 and our multi-view Parkinson&#x27;s Disease Mouse Behaviour (PDMB)
datasets demonstrate that our model outperforms the other state of the arts
technologies and effectively deals with the imbalanced data problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Adversarial Training of Self-Attention Based Networks for Land Cover Classification using Multi-temporal Sentinel-2 Satellite Imagery. (arXiv:2104.00564v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martini_M/0/1/0/all/0/1">Mauro Martini</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Khaliq_A/0/1/0/all/0/1">Aleem Khaliq</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00564">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing availability of large-scale remote sensing labeled data has
prompted researchers to develop increasingly precise and accurate data-driven
models for land cover and crop classification (LC&amp;CC). Moreover, with the
introduction of self-attention and introspection mechanisms, deep learning
approaches have shown promising results in processing long temporal sequences
in the multi-spectral domain with a contained computational request.
Nevertheless, most practical applications cannot rely on labeled data, and in
the field, surveys are a time consuming solution that poses strict limitations
to the number of collected samples. Moreover, atmospheric conditions and
specific geographical region characteristics constitute a relevant domain gap
that does not allow direct applicability of a trained model on the available
dataset to the area of interest. In this paper, we investigate adversarial
training of deep neural networks to bridge the domain discrepancy between
distinct geographical zones. In particular, we perform a thorough analysis of
domain adaptation applied to challenging multi-spectral, multi-temporal data,
accurately highlighting the advantages of adapting state-of-the-art
self-attention based models for LC&amp;CC to different target zones where labeled
data are not available. Extensive experimentation demonstrated significant
performance and generalization gain in applying domain-adversarial training to
source and target regions with marked dissimilarities between the distribution
of extracted features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning More for Free - A Multi Task Learning Approach for Improved Pathology Classification in Capsule Endoscopy. (arXiv:2106.16162v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vats_A/0/1/0/all/0/1">Anuja Vats</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_M/0/1/0/all/0/1">Marius Pedersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammed_A/0/1/0/all/0/1">Ahmed Mohammed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovde_O/0/1/0/all/0/1">&#xd8;istein Hovde</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16162">
                                    <div class="article-summary-box-inner">
                                        <span>The progress in Computer Aided Diagnosis (CADx) of Wireless Capsule Endoscopy
(WCE) is thwarted by the lack of data. The inadequacy in richly representative
healthy and abnormal conditions results in isolated analyses of pathologies,
that can not handle realistic multi-pathology scenarios. In this work, we
explore how to learn more for free, from limited data through solving a WCE
multicentric, multi-pathology classification problem. Learning more implies to
learning more than full supervision would allow with the same data. This is
done by combining self supervision with full supervision, under multi task
learning. Additionally, we draw inspiration from the Human Visual System (HVS)
in designing self supervision tasks and investigate if seemingly ineffectual
signals within the data itself can be exploited to gain performance, if so,
which signals would be better than others. Further, we present our analysis of
the high level features as a stepping stone towards more robust multi-pathology
CADx in WCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I Want This Product but Different : Multimodal Retrieval with Synthetic Query Expansion. (arXiv:2102.08871v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tautkute_I/0/1/0/all/0/1">Ivona Tautkute</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzcinski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08871">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of media retrieval using a multimodal query
(a query which combines visual input with additional semantic information in
natural language feedback). We propose a SynthTriplet GAN framework which
resolves this task by expanding the multimodal query with a synthetically
generated image that captures semantic information from both image and text
input. We introduce a novel triplet mining method that uses a synthetic image
as an anchor to directly optimize for embedding distances of generated and
target images. We demonstrate that apart from the added value of retrieval
illustration with synthetic image with the focus on customization and user
feedback, the proposed method greatly surpasses other multimodal generation
methods and achieves state of the art results in the multimodal retrieval task.
We also show that in contrast to other retrieval methods, our method provides
explainable embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular 3D Object Detection: An Extrinsic Parameter Free Approach. (arXiv:2106.15796v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yunsong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongzi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1">Qinhong Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15796">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular 3D object detection is an important task in autonomous driving. It
can be easily intractable where there exists ego-car pose change w.r.t. ground
plane. This is common due to the slight fluctuation of road smoothness and
slope. Due to the lack of insight in industrial application, existing methods
on open datasets neglect the camera pose information, which inevitably results
in the detector being susceptible to camera extrinsic parameters. The
perturbation of objects is very popular in most autonomous driving cases for
industrial products. To this end, we propose a novel method to capture camera
pose to formulate the detector free from extrinsic perturbation. Specifically,
the proposed framework predicts camera extrinsic parameters by detecting
vanishing point and horizon change. A converter is designed to rectify
perturbative features in the latent space. By doing so, our 3D detector works
independent of the extrinsic parameter variations and produces accurate results
in realistic cases, e.g., potholed and uneven roads, where almost all existing
monocular detectors fail to handle. Experiments demonstrate our method yields
the best performance compared with the other state-of-the-arts by a large
margin on both KITTI 3D and nuScenes datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source domain adaptation via supervised contrastive learning and confident consistency regularization. (arXiv:2106.16093v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scalbert_M/0/1/0/all/0/1">Marin Scalbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Couzinie_Devy_F/0/1/0/all/0/1">Florent Couzini&#xe9;-Devy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16093">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-Source Unsupervised Domain Adaptation (multi-source UDA) aims to learn
a model from several labeled source domains while performing well on a
different target domain where only unlabeled data are available at training
time. To align source and target features distributions, several recent works
use source and target explicit statistics matching such as features moments or
class centroids. Yet, these approaches do not guarantee class conditional
distributions alignment across domains. In this work, we propose a new
framework called Contrastive Multi-Source Domain Adaptation (CMSDA) for
multi-source UDA that addresses this limitation. Discriminative features are
learned from interpolated source examples via cross entropy minimization and
from target examples via consistency regularization and hard pseudo-labeling.
Simultaneously, interpolated source examples are leveraged to align source
class conditional distributions through an interpolated version of the
supervised contrastive loss. This alignment leads to more general and
transferable features which further improve the generalization on the target
domain. Extensive experiments have been carried out on three standard
multi-source UDA datasets where our method reports state-of-the-art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Reconstruction Methods from RGB Images to Hyperspectral Imaging: A Survey. (arXiv:2106.15944v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jingang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Su_R/0/1/0/all/0/1">Runmu Su</a>, <a href="http://arxiv.org/find/eess/1/au:+Ren_W/0/1/0/all/0/1">Wenqi Ren</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_Q/0/1/0/all/0/1">Qiang Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Nie_Y/0/1/0/all/0/1">Yunfeng Nie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15944">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral imaging enables versatile applications due to its competence in
capturing abundant spatial and spectral information, which are crucial for
identifying substances. However, the devices for acquiring hyperspectral images
are expensive and complicated. Therefore, many alternative spectral imaging
methods have been proposed by directly reconstructing the hyperspectral
information from lower-cost, more available RGB images. We present a thorough
investigation of these state-of-the-art spectral reconstruction methods from
the widespread RGB images. A systematic study and comparison of more than 25
methods has revealed that most of the data-driven deep learning methods are
superior to prior-based methods in terms of reconstruction accuracy and quality
despite lower speeds. This comprehensive review can serve as a fruitful
reference source for peer researchers, thus further inspiring future
development directions in related domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Reweighting Domain Generalization for Face Presentation Attack Detection. (arXiv:2106.16128v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shubao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Ke-Yue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Taiping Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_K/0/1/0/all/0/1">Kekai Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shouhong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16128">
                                    <div class="article-summary-box-inner">
                                        <span>Face anti-spoofing approaches based on domain generalization (DG) have drawn
growing attention due to their robustness for unseen scenarios. Previous
methods treat each sample from multiple domains indiscriminately during the
training process, and endeavor to extract a common feature space to improve the
generalization. However, due to complex and biased data distribution, directly
treating them equally will corrupt the generalization ability. To settle the
issue, we propose a novel Dual Reweighting Domain Generalization (DRDG)
framework which iteratively reweights the relative importance between samples
to further improve the generalization. Concretely, Sample Reweighting Module is
first proposed to identify samples with relatively large domain bias, and
reduce their impact on the overall optimization. Afterwards, Feature
Reweighting Module is introduced to focus on these samples and extract more
domain-irrelevant features via a self-distilling mechanism. Combined with the
domain discriminator, the iteration of the two modules promotes the extraction
of generalized features. Extensive experiments and visualizations are presented
to demonstrate the effectiveness and interpretability of our method against the
state-of-the-art competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Adversarial Image Synthesis. (arXiv:2106.16056v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_W/0/1/0/all/0/1">William Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_G/0/1/0/all/0/1">Glen Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Leer_R/0/1/0/all/0/1">Robert Leer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricardo_F/0/1/0/all/0/1">Frederick Ricardo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16056">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have been extremely successful in
various application domains. Adversarial image synthesis has drawn increasing
attention and made tremendous progress in recent years because of its wide
range of applications in many computer vision and image processing problems.
Among the many applications of GAN, image synthesis is the most well-studied
one, and research in this area has already demonstrated the great potential of
using GAN in image synthesis. In this paper, we provide a taxonomy of methods
used in image synthesis, review different models for text-to-image synthesis
and image-to-image translation, and discuss some evaluation metrics as well as
possible future research directions in image synthesis with GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid Detection in Three-Dimensional Fluorescence Microscopy Images. (arXiv:2106.15753v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_L/0/1/0/all/0/1">Liming Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_S/0/1/0/all/0/1">Shuo Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1">Alain Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Salama_P/0/1/0/all/0/1">Paul Salama</a>, <a href="http://arxiv.org/find/eess/1/au:+Dunn_K/0/1/0/all/0/1">Kenneth W. Dunn</a>, <a href="http://arxiv.org/find/eess/1/au:+Delp_E/0/1/0/all/0/1">Edward J. Delp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15753">
                                    <div class="article-summary-box-inner">
                                        <span>Robust and accurate nuclei centroid detection is important for the
understanding of biological structures in fluorescence microscopy images.
Existing automated nuclei localization methods face three main challenges: (1)
Most of object detection methods work only on 2D images and are difficult to
extend to 3D volumes; (2) Segmentation-based models can be used on 3D volumes
but it is computational expensive for large microscopy volumes and they have
difficulty distinguishing different instances of objects; (3) Hand annotated
ground truth is limited for 3D microscopy volumes. To address these issues, we
present a scalable approach for nuclei centroid detection of 3D microscopy
volumes. We describe the RCNN-SliceNet to detect 2D nuclei centroids for each
slice of the volume from different directions and 3D agglomerative hierarchical
clustering (AHC) is used to estimate the 3D centroids of nuclei in a volume.
The model was trained with the synthetic microscopy data generated using
Spatially Constrained Cycle-Consistent Adversarial Networks (SpCycleGAN) and
tested on different types of real 3D microscopy data. Extensive experimental
results demonstrate that our proposed method can accurately count and detect
the nuclei centroids in a 3D microscopy volume.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning-based Lie Detector applied to a Novel Annotated Game Dataset. (arXiv:2104.12345v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Diaz_N/0/1/0/all/0/1">Nuria Rodriguez-Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Aspandi_D/0/1/0/all/0/1">Decky Aspandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukno_F/0/1/0/all/0/1">Federico Sukno</a>, <a href="http://arxiv.org/find/cs/1/au:+Binefa_X/0/1/0/all/0/1">Xavier Binefa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12345">
                                    <div class="article-summary-box-inner">
                                        <span>Lie detection is considered a concern for everyone in their day to day life
given its impact on human interactions. Thus, people normally pay attention to
both what their interlocutors are saying and also to their visual appearances,
including faces, to try to find any signs that indicate whether the person is
telling the truth or not. While automatic lie detection may help us to
understand this lying characteristics, current systems are still fairly
limited, partly due to lack of adequate datasets to evaluate their performance
in realistic scenarios. In this work, we have collected an annotated dataset of
facial images, comprising both 2D and 3D information of several participants
during a card game that encourages players to lie. Using our collected dataset,
We evaluated several types of machine learning-based lie detectors in terms of
their generalization, person-specific and cross-domain experiments. Our results
show that models based on deep learning achieve the best accuracy, reaching up
to 57\% for the generalization task and 63\% when dealing with a single
participant. Finally, we also highlight the limitation of the deep learning
based lie detector when dealing with cross-domain lie detection tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimNet: Enabling Robust Unknown Object Manipulation from Pure Synthetic Data via Stereo. (arXiv:2106.16118v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kollar_T/0/1/0/all/0/1">Thomas Kollar</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskey_M/0/1/0/all/0/1">Michael Laskey</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_K/0/1/0/all/0/1">Kevin Stone</a>, <a href="http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1">Brijen Thananjeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tjersland_M/0/1/0/all/0/1">Mark Tjersland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16118">
                                    <div class="article-summary-box-inner">
                                        <span>Robot manipulation of unknown objects in unstructured environments is a
challenging problem due to the variety of shapes, materials, arrangements and
lighting conditions. Even with large-scale real-world data collection, robust
perception and manipulation of transparent and reflective objects across
various lighting conditions remain challenging. To address these challenges we
propose an approach to performing sim-to-real transfer of robotic perception.
The underlying model, SimNet, is trained as a single multi-headed neural
network using simulated stereo data as input and simulated object segmentation
masks, 3D oriented bounding boxes (OBBs), object keypoints, and disparity as
output. A key component of SimNet is the incorporation of a learned stereo
sub-network that predicts disparity. SimNet is evaluated on 2D car detection,
unknown object detection, and deformable object keypoint detection and
significantly outperforms a baseline that uses a structured light RGB-D sensor.
By inferring grasp positions using the OBB and keypoint predictions, SimNet can
be used to perform end-to-end manipulation of unknown objects in both easy and
hard scenarios using our fleet of Toyota HSR robots in four home environments.
In unknown object grasping experiments, the predictions from the baseline RGB-D
network and SimNet enable successful grasps of most of the easy objects.
However, the RGB-D baseline only grasps 35% of the hard (e.g., transparent)
objects, while SimNet grasps 95%, suggesting that SimNet can enable robust
manipulation of unknown objects, including transparent objects, in unknown
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented Shortcuts for Vision Transformers. (arXiv:2106.15941v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">An Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yiping Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15941">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer models have achieved great progress on computer vision tasks
recently. The rapid development of vision transformers is mainly contributed by
their high representation ability for extracting informative features from
input images. However, the mainstream transformer models are designed with deep
architectures, and the feature diversity will be continuously reduced as the
depth increases, i.e., feature collapse. In this paper, we theoretically
analyze the feature collapse phenomenon and study the relationship between
shortcuts and feature diversity in these transformer models. Then, we present
an augmented shortcut scheme, which inserts additional paths with learnable
parameters in parallel on the original shortcuts. To save the computational
costs, we further explore an efficient approach that uses the block-circulant
projection to implement augmented shortcuts. Extensive experiments conducted on
benchmark datasets demonstrate the effectiveness of the proposed method, which
brings about 1% accuracy increase of the state-of-the-art visual transformers
without obviously increasing their parameters and FLOPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Hidden Structure in Self-Supervised Learning. (arXiv:2106.16060v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sansone_E/0/1/0/all/0/1">Emanuele Sansone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16060">
                                    <div class="article-summary-box-inner">
                                        <span>This work considers the problem of learning structured representations from
raw images using self-supervised learning. We propose a principled framework
based on a mutual information objective, which integrates self-supervised and
structure learning. Furthermore, we devise a post-hoc procedure to interpret
the meaning of the learnt representations. Preliminary experiments on CIFAR-10
show that the proposed framework achieves higher generalization performance in
downstream classification tasks and provides more interpretable representations
compared to the ones learnt through traditional self-supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Looking Outside the Window: Wider-Context Transformer for the Semantic Segmentation of High-Resolution Remote Sensing Images. (arXiv:2106.15754v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Lei Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shaofu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1">Xiaojie Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuebin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruzzone_L/0/1/0/all/0/1">Lorenzo Bruzzone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15754">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range context information is crucial for the semantic segmentation of
High-Resolution (HR) Remote Sensing Images (RSIs). The image cropping
operations, commonly used for training neural networks, limit the perception of
long-range context information in large RSIs. To break this limitation, we
propose a Wider-Context Network (WiCNet) for the semantic segmentation of HR
RSIs. In the WiCNet, apart from a conventional feature extraction network to
aggregate the local information, an extra context branch is designed to
explicitly model the context information in a larger image area. The
information between the two branches is communicated through a Context
Transformer, which is a novel design derived from the Vision Transformer to
model the long-range context correlations. Ablation studies and comparative
experiments conducted on several benchmark datasets prove the effectiveness of
the proposed method. Additionally, we present a new Beijing Land-Use (BLU)
dataset. This is a large-scale HR satellite dataset provided with high-quality
and fine-grained reference labels, which we hope will boost future studies in
this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word-level Sign Language Recognition with Multi-stream Neural Networks Focusing on Local Regions. (arXiv:2106.15989v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maruyama_M/0/1/0/all/0/1">Mizuki Maruyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1">Shuvozit Ghose</a>, <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Katsufumi Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1">Partha Pratim Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwamura_M/0/1/0/all/0/1">Masakazu Iwamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshioka_M/0/1/0/all/0/1">Michifumi Yoshioka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15989">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Word-level Sign Language Recognition (WSLR) research has
gained popularity in the computer vision community, and thus various approaches
have been proposed. Among these approaches, the method using I3D network
achieves the highest recognition accuracy on large public datasets for WSLR.
However, the method with I3D only utilizes appearance information of the upper
body of the signers to recognize sign language words. On the other hand, in
WSLR, the information of local regions, such as the hand shape and facial
expression, and the positional relationship among the body and both hands are
important. Thus in this work, we utilized local region images of both hands and
face, along with skeletal information to capture local information and the
positions of both hands relative to the body, respectively. In other words, we
propose a novel multi-stream WSLR framework, in which a stream with local
region images and a stream with skeletal information are introduced by
extending I3D network to improve the recognition accuracy of WSLR. From the
experimental results on WLASL dataset, it is evident that the proposed method
has achieved about 15% improvement in the Top-1 accuracy than the existing
conventional methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-stream Network for Visual Recognition. (arXiv:2105.14734v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1">Mingyuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Renrui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Honghui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Teli Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baochang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shumin Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14734">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers with remarkable global representation capacities achieve
competitive results for visual tasks, but fail to consider high-level local
pattern information in input images. In this paper, we present a generic
Dual-stream Network (DS-Net) to fully explore the representation capacity of
local and global pattern features for image classification. Our DS-Net can
simultaneously calculate fine-grained and integrated features and efficiently
fuse them. Specifically, we propose an Intra-scale Propagation module to
process two different resolutions in each block and an Inter-Scale Alignment
module to perform information interaction across features at dual scales.
Besides, we also design a Dual-stream FPN (DS-FPN) to further enhance
contextual information for downstream dense predictions. Without bells and
whistles, the propsed DS-Net outperforms Deit-Small by 2.4% in terms of top-1
accuracy on ImageNet-1k and achieves state-of-the-art performance over other
Vision Transformers and ResNets. For object detection and instance
segmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4% and 5.5 %
in terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art
scheme, which significantly demonstrates its potential to be a general backbone
in vision tasks. The code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Transferability Estimation for Image Classification Tasks. (arXiv:2106.10479v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shao-Lun Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10479">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability estimation is an essential problem in transfer learning to
predict how good the performance is when transferring a source model (or source
task) to a target task. Recent analytical transferability metrics have been
widely used for source model selection and multi-task learning. A major
challenge is how to make transfereability estimation robust under the
cross-domain cross-task settings. The recently proposed OTCE score solves this
problem by considering both domain and task differences, with the help of
transfer experiences on auxiliary tasks, which causes an efficiency overhead.
In this work, we propose a practical transferability metric called JC-NCE score
that dramatically improves the robustness of the task difference estimation in
OTCE, thus removing the need for auxiliary tasks. Specifically, we build the
joint correspondences between source and target data via solving an optimal
transport problem with a ground cost considering both the sample distance and
label distance, and then compute the transferability score as the negative
conditional entropy of the matched labels. Extensive validations under the
intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE
score outperforms the auxiliary-task free version of OTCE for 7% and 12%,
respectively, and is also more robust than other existing transferability
metrics on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2C2 - An orthogonal method for Semi-Supervised Learning on fuzzy labels. (arXiv:2106.16209v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmarje_L/0/1/0/all/0/1">Lars Schmarje</a>, <a href="http://arxiv.org/find/cs/1/au:+Santarossa_M/0/1/0/all/0/1">Monty Santarossa</a>, <a href="http://arxiv.org/find/cs/1/au:+Schroder_S/0/1/0/all/0/1">Simon-Martin Schr&#xf6;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelenka_C/0/1/0/all/0/1">Claudius Zelenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiko_R/0/1/0/all/0/1">Rainer Kiko</a>, <a href="http://arxiv.org/find/cs/1/au:+Stracke_J/0/1/0/all/0/1">Jenny Stracke</a>, <a href="http://arxiv.org/find/cs/1/au:+Volkmann_N/0/1/0/all/0/1">Nina Volkmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_R/0/1/0/all/0/1">Reinhard Koch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16209">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-Supervised Learning (SSL) can decrease the amount of required labeled
image data and thus the cost for deep learning. Most SSL methods only consider
a clear distinction between classes but in many real-world datasets, this clear
distinction is not given due to intra- or interobserver variability. This
variability can lead to different annotations per image. Thus many images have
ambiguous annotations and their label needs to be considered &quot;fuzzy&quot;. This
fuzziness of labels must be addressed as it will limit the performance of
Semi-Supervised Learning (SSL) and deep learning in general. We propose
Semi-Supervised Classification &amp; Clustering (S2C2) which can extend many deep
SSL algorithms. S2C2 can estimate the fuzziness of a label and applies SSL as a
classification to certainly labeled data while creating distinct clusters for
images with similar but fuzzy labels. We show that S2C2 results in median 7.4%
better F1-score for classifications and 5.4% lower inner distance of clusters
across multiple SSL algorithms and datasets while being more interpretable due
to the fuzziness estimation of our method. Overall, a combination of
Semi-Supervised Learning with our method S2C2 leads to better handling of the
fuzziness of labels and thus real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Onychomycosis Detection Using Deep Neural Networks. (arXiv:2106.16139v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_A/0/1/0/all/0/1">Abdurrahim Yilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Varol_R/0/1/0/all/0/1">Rahmetullah Varol</a>, <a href="http://arxiv.org/find/cs/1/au:+Goktay_F/0/1/0/all/0/1">Fatih Goktay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gencoglan_G/0/1/0/all/0/1">Gulsum Gencoglan</a>, <a href="http://arxiv.org/find/cs/1/au:+Demircali_A/0/1/0/all/0/1">Ali Anil Demircali</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilsizoglu_B/0/1/0/all/0/1">Berk Dilsizoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Uvet_H/0/1/0/all/0/1">Huseyin Uvet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16139">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical dermatology, still relies heavily on manual introspection of fungi
within a Potassium Hydroxide (KOH) solution using a brightfield microscope.
However, this method takes a long time, is based on the experience of the
clinician, and has a low accuracy. With the increase of neural network
applications in the field of clinical microscopy it is now possible to automate
such manual processes increasing both efficiency and accuracy. This study
presents a deep neural network structure that enables the rapid solutions for
these problems and can perform automatic fungi detection in grayscale images
without colorants. Microscopic images of 81 fungi and 235 ceratine were
collected. Then, smaller patches were extracted containing 2062 fungi and 2142
ceratine. In order to detect fungus and ceratine, two models were created one
of which was a custom neural network and the other was based on the VGG16
architecture. The developed custom model had 99.84% accuracy, and an area under
the curve (AUC) value of 1.00, while the VGG16 model had 98.89% accuracy and an
AUC value of 0.99. However, average accuracy and AUC value of clinicians is
72.8% and 0.87 respectively. This deep learning model allows the development of
an automated system that can detect fungi within microscopic images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Temporal Adjacent Network for Language Grounding. (arXiv:2106.16136v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuechen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiajun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16136">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal language grounding (TLG) is a fundamental and challenging problem
for vision and language understanding. Existing methods mainly focus on fully
supervised setting with temporal boundary labels for training, which, however,
suffers expensive cost of annotation. In this work, we are dedicated to weakly
supervised TLG, where multiple description sentences are given to an untrimmed
video without temporal boundary labels. In this task, it is critical to learn a
strong cross-modal semantic alignment between sentence semantics and visual
content. To this end, we introduce a novel weakly supervised temporal adjacent
network (WSTAN) for temporal language grounding. Specifically, WSTAN learns
cross-modal semantic alignment by exploiting temporal adjacent network in a
multiple instance learning (MIL) paradigm, with a whole description paragraph
as input. Moreover, we integrate a complementary branch into the framework,
which explicitly refines the predictions with pseudo supervision from the MIL
stage. An additional self-discriminating loss is devised on both the MIL branch
and the complementary branch, aiming to enhance semantic discrimination by
self-supervising. Extensive experiments are conducted on three widely used
benchmark datasets, \emph{i.e.}, ActivityNet-Captions, Charades-STA, and
DiDeMo, and the results demonstrate the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Video Classification Meets Incremental Classes. (arXiv:2106.15827v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hanbin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xin Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1">Shihao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zibo Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15827">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of social media, tremendous videos with new
classes are generated daily, which raise an urgent demand for video
classification methods that can continuously update new classes while
maintaining the knowledge of old videos with limited storage and computing
resources. In this paper, we summarize this task as \textit{Class-Incremental
Video Classification (CIVC)} and propose a novel framework to address it. As a
subarea of incremental learning tasks, the challenge of \textit{catastrophic
forgetting} is unavoidable in CIVC. To better alleviate it, we utilize some
characteristics of videos. First, we decompose the spatio-temporal knowledge
before distillation rather than treating it as a whole in the knowledge
transfer process; trajectory is also used to refine the decomposition. Second,
we propose a dual granularity exemplar selection method to select and store
representative video instances of old classes and key-frames inside videos
under a tight storage budget. We benchmark our method and previous SOTA
class-incremental learning methods on Something-Something V2 and Kinetics
datasets, and our method outperforms previous methods significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth. (arXiv:2012.10133v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xingxing Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Merrill_N/0/1/0/all/0/1">Nathaniel Merrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guoquan Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10133">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present a lightweight, tightly-coupled deep depth network
and visual-inertial odometry (VIO) system, which can provide accurate state
estimates and dense depth maps of the immediate surroundings. Leveraging the
proposed lightweight Conditional Variational Autoencoder (CVAE) for depth
inference and encoding, we provide the network with previously marginalized
sparse features from VIO to increase the accuracy of initial depth prediction
and generalization capability. The compact encoded depth maps are then updated
jointly with navigation states in a sliding window estimator in order to
provide the dense local scene geometry. We additionally propose a novel method
to obtain the CVAE&#x27;s Jacobian which is shown to be more than an order of
magnitude faster than previous works, and we additionally leverage
First-Estimate Jacobian (FEJ) to avoid recalculation. As opposed to previous
works relying on completely dense residuals, we propose to only provide sparse
measurements to update the depth code and show through careful experimentation
that our choice of sparse measurements and FEJs can still significantly improve
the estimated depth maps. Our full system also exhibits state-of-the-art pose
estimation accuracy, and we show that it can run in real-time with
single-thread execution while utilizing GPU acceleration only for the network
and code Jacobian.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resolution learning in deep convolutional networks using scale-space theory. (arXiv:2106.03412v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pintea_S/0/1/0/all/0/1">Silvia L.Pintea</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomen_N/0/1/0/all/0/1">Nergis Tomen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goes_S/0/1/0/all/0/1">Stanley F. Goes</a>, <a href="http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1">Marco Loog</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03412">
                                    <div class="article-summary-box-inner">
                                        <span>Resolution in deep convolutional neural networks (CNNs) is typically bounded
by the receptive field size through filter sizes, and subsampling layers or
strided convolutions on feature maps. The optimal resolution may vary
significantly depending on the dataset. Modern CNNs hard-code their resolution
hyper-parameters in the network architecture which makes tuning such
hyper-parameters cumbersome. We propose to do away with hard-coded resolution
hyper-parameters and aim to learn the appropriate resolution from data. We use
scale-space theory to obtain a self-similar parametrization of filters and make
use of the N-Jet: a truncated Taylor series to approximate a filter by a
learned combination of Gaussian derivative filters. The parameter sigma of the
Gaussian basis controls both the amount of detail the filter encodes and the
spatial extent of the filter. Since sigma is a continuous parameter, we can
optimize it with respect to the loss. The proposed N-Jet layer achieves
comparable performance when used in state-of-the art architectures, while
learning the correct resolution in each layer automatically. We evaluate our
N-Jet layer on both classification and segmentation, and we show that learning
sigma is especially beneficial for inputs at multiple sizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring. (arXiv:2106.16028v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhihang Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Ye Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yinqiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Imari Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16028">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time video deblurring still remains a challenging task due to the
complexity of spatially and temporally varying blur itself and the requirement
of low computational cost. To improve the network efficiency, we adopt residual
dense blocks into RNN cells, so as to efficiently extract the spatial features
of the current frame. Furthermore, a global spatio-temporal attention module is
proposed to fuse the effective hierarchical features from past and future
frames to help better deblur the current frame. Another issue needs to be
addressed urgently is the lack of a real-world benchmark dataset. Thus, we
contribute a novel dataset (BSD) to the community, by collecting paired
blurry/sharp video clips using a co-axis beam splitter acquisition system.
Experimental results show that the proposed method (ESTRNN) can achieve better
deblurring performance both quantitatively and qualitatively with less
computational cost against state-of-the-art video deblurring methods. In
addition, cross-validation experiments between datasets illustrate the high
generality of BSD over the synthetic datasets. The code and dataset are
released at https://github.com/zzh-tech/ESTRNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrently Estimating Reflective Symmetry Planes from Partial Pointclouds. (arXiv:2106.16129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stoian_M/0/1/0/all/0/1">Mihaela C&#x103;t&#x103;lina Stoian</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallari_T/0/1/0/all/0/1">Tommaso Cavallari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16129">
                                    <div class="article-summary-box-inner">
                                        <span>Many man-made objects are characterised by a shape that is symmetric along
one or more planar directions. Estimating the location and orientation of such
symmetry planes can aid many tasks such as estimating the overall orientation
of an object of interest or performing shape completion, where a partial scan
of an object is reflected across the estimated symmetry plane in order to
obtain a more detailed shape. Many methods processing 3D data rely on expensive
3D convolutions. In this paper we present an alternative novel encoding that
instead slices the data along the height dimension and passes it sequentially
to a 2D convolutional recurrent regression scheme. The method also comprises a
differentiable least squares step, allowing for end-to-end accurate and fast
processing of both full and partial scans of symmetric objects. We use this
approach to efficiently handle 3D inputs to design a method to estimate planar
reflective symmetries. We show that our approach has an accuracy comparable to
state-of-the-art techniques on the task of planar reflective symmetry
estimation on full synthetic objects. Additionally, we show that it can be
deployed on partial scans of objects in a real-world pipeline to improve the
outputs of a 3D object detector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diff2Dist: Learning Spectrally Distinct Edge Functions, with Applications to Cell Morphology Analysis. (arXiv:2106.15716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scott_C/0/1/0/all/0/1">Cory Braker Scott</a>, <a href="http://arxiv.org/find/cs/1/au:+Mjolsness_E/0/1/0/all/0/1">Eric Mjolsness</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyen_D/0/1/0/all/0/1">Diane Oyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodera_C/0/1/0/all/0/1">Chie Kodera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchez_D/0/1/0/all/0/1">David Bouchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Uyttewaal_M/0/1/0/all/0/1">Magalie Uyttewaal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15716">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for learning &quot;spectrally descriptive&quot; edge weights for
graphs. We generalize a previously known distance measure on graphs (Graph
Diffusion Distance), thereby allowing it to be tuned to minimize an arbitrary
loss function. Because all steps involved in calculating this modified GDD are
differentiable, we demonstrate that it is possible for a small neural network
model to learn edge weights which minimize loss. GDD alone does not effectively
discriminate between graphs constructed from shoot apical meristem images of
wild-type vs. mutant \emph{Arabidopsis thaliana} specimens. However, training
edge weights and kernel parameters with contrastive loss produces a learned
distance metric with large margins between these graph categories. We
demonstrate this by showing improved performance of a simple
k-nearest-neighbors classifier on the learned distance matrix. We also
demonstrate a further application of this method to biological image analysis:
once trained, we use our model to compute the distance between the biological
graphs and a set of graphs output by a cell division simulator. This allows us
to identify simulation parameter regimes which are similar to each class of
graph in our original dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain adaptation for person re-identification on new unlabeled data using AlignedReID++. (arXiv:2106.15693v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_T/0/1/0/all/0/1">Tiago de C. G. Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Campos_T/0/1/0/all/0/1">Teofilo E. de Campos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15693">
                                    <div class="article-summary-box-inner">
                                        <span>In the world where big data reigns and there is plenty of hardware prepared
to gather a huge amount of non structured data, data acquisition is no longer a
problem. Surveillance cameras are ubiquitous and they capture huge numbers of
people walking across different scenes. However, extracting value from this
data is challenging, specially for tasks that involve human images, such as
face recognition and person re-identification. Annotation of this kind of data
is a challenging and expensive task. In this work we propose a domain
adaptation workflow to allow CNNs that were trained in one domain to be applied
to another domain without the need for new annotation of the target data. Our
method uses AlignedReID++ as the baseline, trained using a Triplet loss with
batch hard. Domain adaptation is done by using pseudo-labels generated using an
unsupervised learning strategy. Our results show that domain adaptation
techniques really improve the performance of the CNN when applied in the target
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cyclist Trajectory Forecasts by Incorporation of Multi-View Video Information. (arXiv:2106.15991v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1">Stefan Zernetsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Trupp_O/0/1/0/all/0/1">Oliver Trupp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kress_V/0/1/0/all/0/1">Viktor Kress</a>, <a href="http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1">Konrad Doll</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15991">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents a novel approach to incorporate visual cues from
video-data from a wide-angle stereo camera system mounted at an urban
intersection into the forecast of cyclist trajectories. We extract features
from image and optical flow (OF) sequences using 3D convolutional neural
networks (3D-ConvNet) and combine them with features extracted from the
cyclist&#x27;s past trajectory to forecast future cyclist positions. By the use of
additional information, we are able to improve positional accuracy by about 7.5
% for our test dataset and by up to 22 % for specific motion types compared to
a method solely based on past trajectories. Furthermore, we compare the use of
image sequences to the use of OF sequences as additional information, showing
that OF alone leads to significant improvements in positional accuracy. By
training and testing our methods using a real-world dataset recorded at a
heavily frequented public intersection and evaluating the methods&#x27; runtimes, we
demonstrate the applicability in real traffic scenarios. Our code and parts of
our dataset are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Map for Active Semantic Goal Navigation. (arXiv:2106.15648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Georgakis_G/0/1/0/all/0/1">Georgios Georgakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucher_B/0/1/0/all/0/1">Bernadette Bucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmeckpeper_K/0/1/0/all/0/1">Karl Schmeckpeper</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Siddharth Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1">Kostas Daniilidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15648">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of object goal navigation in unseen environments. In
our view, solving this problem requires learning of contextual semantic priors,
a challenging endeavour given the spatial and semantic variability of indoor
environments. Current methods learn to implicitly encode these priors through
goal-oriented navigation policy functions operating on spatial representations
that are limited to the agent&#x27;s observable areas. In this work, we propose a
novel framework that actively learns to generate semantic maps outside the
field of view of the agent and leverages the uncertainty over the semantic
classes in the unobserved areas to decide on long term goals. We demonstrate
that through this spatial prediction strategy, we are able to learn semantic
priors in scenes that can be leveraged in unknown environments. Additionally,
we show how different objectives can be defined by balancing exploration with
exploitation during searching for semantic targets. Our method is validated in
the visually realistic environments offered by the Matterport3D dataset and
show state of the art results on the object goal navigation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1">Feihu Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1">Junyi Li</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08208">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive gradient methods have shown excellent performance for solving many
machine learning problems. Although multiple adaptive methods were recently
studied, they mainly focus on either empirical or theoretical aspects and also
only work for specific problems by using specific adaptive learning rates. It
is desired to design a universal framework for practical algorithms of adaptive
gradients with theoretical guarantee to solve general problems. To fill this
gap, we propose a faster and universal framework of adaptive gradients (i.e.,
SUPER-ADAM) by introducing a universal adaptive matrix that includes most
existing adaptive gradient forms. Moreover, our framework can flexibly
integrates the momentum and variance reduced techniques. In particular, our
novel framework provides the convergence analysis support for adaptive gradient
methods under the nonconvex setting. In theoretical analysis, we prove that our
new algorithm can achieve the best known complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Vision Transformers for Fine-grained Classification. (arXiv:2106.10587v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1">Marcos V. Conde</a>, <a href="http://arxiv.org/find/cs/1/au:+Turgutlu_K/0/1/0/all/0/1">Kerem Turgutlu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10587">
                                    <div class="article-summary-box-inner">
                                        <span>Existing computer vision research in categorization struggles with
fine-grained attributes recognition due to the inherently high intra-class
variances and low inter-class variances. SOTA methods tackle this challenge by
locating the most informative image regions and rely on them to classify the
complete image. The most recent work, Vision Transformer (ViT), shows its
strong performance in both traditional and fine-grained classification tasks.
In this work, we propose a multi-stage ViT framework for fine-grained image
classification tasks, which localizes the informative image regions without
requiring architectural changes using the inherent multi-head self-attention
mechanism. We also introduce attention-guided augmentations for improving the
model&#x27;s capabilities. We demonstrate the value of our approach by experimenting
with four popular fine-grained benchmarks: CUB-200-2011, Stanford Cars,
Stanford Dogs, and FGVC7 Plant Pathology. We also prove our model&#x27;s
interpretability via qualitative results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demographic Fairness in Face Identification: The Watchlist Imbalance Effect. (arXiv:2106.08049v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drozdowski_P/0/1/0/all/0/1">Pawel Drozdowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathgeb_C/0/1/0/all/0/1">Christian Rathgeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1">Christoph Busch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08049">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, different researchers have found that the gallery composition of a
face database can induce performance differentials to facial identification
systems in which a probe image is compared against up to all stored reference
images to reach a biometric decision. This negative effect is referred to as
&quot;watchlist imbalance effect&quot;. In this work, we present a method to
theoretically estimate said effect for a biometric identification system given
its verification performance across demographic groups and the composition of
the used gallery. Further, we report results for identification experiments on
differently composed demographic subsets, i.e. females and males, of the public
academic MORPH database using the open-source ArcFace face recognition system.
It is shown that the database composition has a huge impact on performance
differentials in biometric identification systems, even if performance
differentials are less pronounced in the verification scenario. This study
represents the first detailed analysis of the watchlist imbalance effect which
is expected to be of high interest for future research in the field of facial
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1">Marcos Vendramini</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1">Alexei Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10013">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification methods are usually trained to perform predictions
taking into account a predefined group of known classes. Real-world problems,
however, may not allow for a full knowledge of the input and label spaces,
making failures in recognition a hazard to deep visual learning. Open set
recognition methods are characterized by the ability to correctly identify
inputs of known and unknown classes. In this context, we propose GeMOS: simple
and plug-and-play open set recognition modules that can be attached to
pretrained Deep Neural Networks for visual recognition. The GeMOS framework
pairs pre-trained Convolutional Neural Networks with generative models for open
set recognition to extract open set scores for each sample, allowing for
failure recognition in object recognition tasks. We conduct a thorough
evaluation of the proposed method in comparison with state-of-the-art open set
algorithms, finding that GeMOS either outperforms or is statistically
indistinguishable from more complex and costly models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Operator-valued formulas for Riemannian Gradient and Hessian and families of tractable metrics. (arXiv:2009.10159v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nguyen_D/0/1/0/all/0/1">Du Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10159">
                                    <div class="article-summary-box-inner">
                                        <span>We provide an explicit formula for the Levi-Civita connection and Riemannian
Hessian for a Riemannian manifold that is a quotient of a manifold embedded in
an inner product space with a non-constant metric function. Together with a
classical formula for projection, this allows us to evaluate Riemannian
gradient and Hessian for several families of metrics on classical manifolds,
including a family of metrics on Stiefel manifolds connecting both the constant
and canonical ambient metrics with closed-form geodesics. Using these formulas,
we derive Riemannian optimization frameworks on quotients of Stiefel manifolds,
including flag manifolds, and a new family of complete quotient metrics on the
manifold of positive-semidefinite matrices of fixed rank, considered as a
quotient of a product of Stiefel and positive-definite matrix manifold with
affine-invariant metrics. The method is procedural, and in many instances, the
Riemannian gradient and Hessian formulas could be derived by symbolic calculus.
The method extends the list of potential metrics that could be used in manifold
optimization and machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAttANet: Global attention agreement for convolutional neural networks. (arXiv:2104.05575v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1">Andrea Alamia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05575">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer attention architectures, similar to those developed for natural
language processing, have recently proved efficient also in vision, either in
conjunction with or as a replacement for convolutional layers. Typically,
visual attention is inserted in the network architecture as a (series of)
feedforward self-attention module(s), with mutual key-query agreement as the
main selection and routing operation. However efficient, this strategy is only
vaguely compatible with the way that attention is implemented in biological
brains: as a separate and unified network of attentional selection regions,
receiving inputs from and exerting modulatory influence on the entire hierarchy
of visual regions. Here, we report experiments with a simple such attention
system that can improve the performance of standard convolutional networks,
with relatively few additional parameters. Each spatial position in each layer
of the network produces a key-query vector pair; all queries are then pooled
into a global attention query. On the next iteration, the match between each
key and the global attention query modulates the network&#x27;s activations --
emphasizing or silencing the locations that agree or disagree (respectively)
with the global attention system. We demonstrate the usefulness of this
brain-inspired Global Attention Agreement network (GAttANet) for various
convolutional backbones (from a simple 5-layer toy model to a standard ResNet50
architecture) and datasets (CIFAR10, CIFAR100, Imagenet-1k). Each time, our
global attention system improves accuracy over the corresponding baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of the Vision-based Approaches for Dietary Assessment. (arXiv:2106.11776v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tahir_G/0/1/0/all/0/1">Ghalib Tahir</a>, <a href="http://arxiv.org/find/cs/1/au:+Loo_C/0/1/0/all/0/1">Chu Kiong Loo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11776">
                                    <div class="article-summary-box-inner">
                                        <span>Last ten years have witnessed the growth of many computer vision applications
for food recognition. Dietary studies showed that dietary-related problem such
as obesity is associated with other chronic diseases like hypertension,
irregular blood sugar levels, and increased risk of heart attacks. The primary
cause of these problems is poor lifestyle choices and unhealthy dietary habits,
which are manageable by using interactive mHealth apps that use automatic
visual-based methods to assess dietary intake. This review discusses the most
performing methodologies that have been developed so far for automatic food
recognition. First, we will present the rationale of visual-based methods for
food recognition. The core of the paper is the presentation, discussion and
evaluation of these methods on popular food image databases. We also discussed
the mobile applications that are implementing these methods. The review ends
with a discussion of research gaps and future challenges in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Learning with Class Description Regularization. (arXiv:2106.16108v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kousha_S/0/1/0/all/0/1">Shayan Kousha</a>, <a href="http://arxiv.org/find/cs/1/au:+Brubaker_M/0/1/0/all/0/1">Marcus A. Brubaker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16108">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of generative Zero-shot learning (ZSL) is to learning from seen
classes, transfer the learned knowledge, and create samples of unseen classes
from the description of these unseen categories. To achieve better ZSL
accuracies, models need to better understand the descriptions of unseen
classes. We introduce a novel form of regularization that encourages generative
ZSL models to pay more attention to the description of each category. Our
empirical results demonstrate improvements over the performance of multiple
state-of-the-art models on the task of generalized zero-shot recognition and
classification when trained on textual description-based datasets like CUB and
NABirds and attribute-based datasets like AWA2, aPY and SUN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Super-Resolution via Iterative Refinement. (arXiv:2104.07636v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/eess/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>, <a href="http://arxiv.org/find/eess/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/eess/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07636">
                                    <div class="article-summary-box-inner">
                                        <span>We present SR3, an approach to image Super-Resolution via Repeated
Refinement. SR3 adapts denoising diffusion probabilistic models to conditional
image generation and performs super-resolution through a stochastic denoising
process. Inference starts with pure Gaussian noise and iteratively refines the
noisy output using a U-Net model trained on denoising at various noise levels.
SR3 exhibits strong performance on super-resolution tasks at different
magnification factors, on faces and natural images. We conduct human evaluation
on a standard 8X face super-resolution task on CelebA-HQ, comparing with SOTA
GAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic
outputs, while GANs do not exceed a fool rate of 34%. We further show the
effectiveness of SR3 in cascaded image generation, where generative models are
chained with super-resolution models, yielding a competitive FID score of 11.3
on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pros and Cons of GAN Evaluation Measures: New Developments. (arXiv:2103.09396v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1">Ali Borji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09396">
                                    <div class="article-summary-box-inner">
                                        <span>This work is an update of a previous paper on the same topic published a few
years ago. With the dramatic progress in generative modeling, a suite of new
quantitative and qualitative techniques to evaluate models has emerged.
Although some measures such as Inception Score, Frechet Inception Distance,
Precision-Recall, and Perceptual Path Length are relatively more popular, GAN
evaluation is not a settled issue and there is still room for improvement.
Here, I describe new dimensions that are becoming important in assessing models
(e.g. bias and fairness) and discuss the connection between GAN evaluation and
deepfakes. These are important areas of concern in the machine learning
community today and progress in GAN evaluation can help mitigate them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Assays for the Latent Space of Autoencoders. (arXiv:2106.16091v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1">Felix Leeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16091">
                                    <div class="article-summary-box-inner">
                                        <span>The encoders and decoders of autoencoders effectively project the input onto
learned manifolds in the latent space and data space respectively. We propose a
framework, called latent responses, for probing the learned data manifold using
interventions in the latent space. Using this framework, we investigate &quot;holes&quot;
in the representation to quantitatively ascertain to what extent the latent
space of a trained VAE is consistent with the chosen prior. Furthermore, we use
the identified structure to improve interpolation between latent vectors. We
evaluate how our analyses improve the quality of the generated samples using
the VAE on a variety of benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoder-side Cross Resolution Synthesis for Video Compression Enhancement. (arXiv:2012.00650v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Ming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_z/0/1/0/all/0/1">zhenyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">Dandan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhan Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00650">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a decoder-side Cross Resolution Synthesis (CRS) module to
pursue better compression efficiency beyond the latest Versatile Video Coding
(VVC), where we encode intra frames at original high resolution (HR), compress
inter frames at a lower resolution (LR), and then super-resolve decoded LR
inter frames with the help from preceding HR intra and neighboring LR inter
frames. For a LR inter frame, a motion alignment and aggregation network (MAN)
is devised to produce temporally aggregated motion representation (AMR) for the
guarantee of temporal smoothness; Another texture compensation network (TCN)
inputs decoded HR intra frame, re-sampled HR intra frame, and this LR inter
frame to generate multiscale affinity map (MAM) and multiscale texture
representation (MTR) for better augmenting spatial details; Finally,
similarity-driven fusion synthesizes AMR, MTR, MAM to upscale LR inter frame
for the removal of compression and resolution re-sampling noises. We enhance
the VVC using proposed CRS, showing averaged 8.76% and 11.93% Bj{\o}ntegaard
Delta Rate (BD-Rate) gains against the latest VVC anchor in Random Access (RA)
and Low-delay P (LDP) settings respectively. In addition, experimental
comparisons to the state-of-the-art super-resolution (SR) based VVC enhancement
methods, and ablation studies are conducted to further report superior
efficiency and generalization of proposed algorithm. All materials will be made
to public at https://njuvision.github.io/CRS for reproducible research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MissFormer: (In-)attention-based handling of missing observations for trajectory filtering and prediction. (arXiv:2106.16009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">Stefan Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1">Ronny Hug</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1">Wolfgang H&#xfc;bner</a>, <a href="http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1">Michael Arens</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan T. Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16009">
                                    <div class="article-summary-box-inner">
                                        <span>In applications such as object tracking, time-series data inevitably carry
missing observations. Following the success of deep learning-based models for
various sequence learning tasks, these models increasingly replace classic
approaches in object tracking applications for inferring the object motions
state. While traditional tracking approaches can deal with missing
observations, most of their deep counterparts are, by default, not suited for
this.

Towards this end, this paper introduces a transformer-based approach for
handling missing observations in variable input length trajectory data. The
model is formed indirectly by successively increasing the complexity of the
demanded inference tasks. Starting from reproducing noise-free trajectories,
the model then learns to infer trajectories from noisy inputs. By providing
missing tokens, binary-encoded missing events, the model learns to in-attend to
missing data and infers a complete trajectory conditioned on the remaining
inputs. In the case of a sequence of successive missing events, the model then
acts as a pure prediction model. The model&#x27;s abilities are demonstrated on
synthetic data and real-world data reflecting prototypical object tracking
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mutual-GAN: Towards Unsupervised Cross-Weather Adaptation with Mutual Information Constraint. (arXiv:2106.16000v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuexiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16000">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural network (CNN) have proven its success for semantic
segmentation, which is a core task of emerging industrial applications such as
autonomous driving. However, most progress in semantic segmentation of urban
scenes is reported on standard scenarios, i.e., daytime scenes with favorable
illumination conditions. In practical applications, the outdoor weather and
illumination are changeable, e.g., cloudy and nighttime, which results in a
significant drop of semantic segmentation accuracy of CNN only trained with
daytime data. In this paper, we propose a novel generative adversarial network
(namely Mutual-GAN) to alleviate the accuracy decline when daytime-trained
neural network is applied to videos captured under adverse weather conditions.
The proposed Mutual-GAN adopts mutual information constraint to preserve
image-objects during cross-weather adaptation, which is an unsolved problem for
most unsupervised image-to-image translation approaches (e.g., CycleGAN). The
proposed Mutual-GAN is evaluated on two publicly available driving video
datasets (i.e., CamVid and SYNTHIA). The experimental results demonstrate that
our Mutual-GAN can yield visually plausible translated images and significantly
improve the semantic segmentation accuracy of daytime-trained deep learning
network while processing videos under challenging weathers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast whole-slide cartography in colon cancer histology using superpixels and CNN classification. (arXiv:2106.15893v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wilm_F/0/1/0/all/0/1">Frauke Wilm</a>, <a href="http://arxiv.org/find/eess/1/au:+Benz_M/0/1/0/all/0/1">Michaela Benz</a>, <a href="http://arxiv.org/find/eess/1/au:+Bruns_V/0/1/0/all/0/1">Volker Bruns</a>, <a href="http://arxiv.org/find/eess/1/au:+Baghdadlian_S/0/1/0/all/0/1">Serop Baghdadlian</a>, <a href="http://arxiv.org/find/eess/1/au:+Dexl_J/0/1/0/all/0/1">Jakob Dexl</a>, <a href="http://arxiv.org/find/eess/1/au:+Hartmann_D/0/1/0/all/0/1">David Hartmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuritcyn_P/0/1/0/all/0/1">Petr Kuritcyn</a>, <a href="http://arxiv.org/find/eess/1/au:+Weidenfeller_M/0/1/0/all/0/1">Martin Weidenfeller</a>, <a href="http://arxiv.org/find/eess/1/au:+Wittenberg_T/0/1/0/all/0/1">Thomas Wittenberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Merkel_S/0/1/0/all/0/1">Susanne Merkel</a>, <a href="http://arxiv.org/find/eess/1/au:+Hartmann_A/0/1/0/all/0/1">Arndt Hartmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Eckstein_M/0/1/0/all/0/1">Markus Eckstein</a>, <a href="http://arxiv.org/find/eess/1/au:+Geppert_C/0/1/0/all/0/1">Carol I. Geppert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15893">
                                    <div class="article-summary-box-inner">
                                        <span>Whole-slide-image cartography is the process of automatically detecting and
outlining different tissue types in digitized histological specimen. This
semantic segmentation provides a basis for many follow-up analyses and can
potentially guide subsequent medical decisions. Due to their large size,
whole-slide-images typically have to be divided into smaller patches which are
then analyzed individually using machine learning-based approaches. Thereby,
local dependencies of image regions get lost and since a whole-slide-image
comprises many thousands of such patches this process is inherently slow. We
propose to subdivide the image into coherent regions prior to classification by
grouping visually similar adjacent image pixels into larger segments, i.e.
superpixels. Afterwards, only a random subset of patches per superpixel is
classified and patch labels are combined into a single superpixel label. The
algorithm has been developed and validated on a dataset of 159 hand-annotated
whole-slide-images of colon resections and its performance has been compared to
a standard patch-based approach. The algorithm shows an average speed-up of 41%
on the test data and the overall accuracy is increased from 93.8% to 95.7%. We
additionally propose a metric for identifying superpixels with an uncertain
classification so they can be excluded from further analysis. Finally, we
evaluate two potential medical applications, namely tumor area estimation
including tumor invasive margin generation and tumor composition analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Structured Analysis of the Video Degradation Effects on the Performance of a Machine Learning-enabled Pedestrian Detector. (arXiv:2106.15889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berger_C/0/1/0/all/0/1">Christian Berger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15889">
                                    <div class="article-summary-box-inner">
                                        <span>ML-enabled software systems have been incorporated in many public
demonstrations for automated driving (AD) systems. Such solutions have also
been considered as a crucial approach to aim at SAE Level 5 systems, where the
passengers in such vehicles do not have to interact with the system at all
anymore. Already in 2016, Nvidia demonstrated a complete end-to-end approach
for training the complete software stack covering perception, planning and
decision making, and the actual vehicle control. While such approaches show the
great potential of such ML-enabled systems, there have also been demonstrations
where already changes to single pixels in a video frame can potentially lead to
completely different decisions with dangerous consequences. In this paper, a
structured analysis has been conducted to explore video degradation effects on
the performance of an ML-enabled pedestrian detector. Firstly, a baseline of
applying YOLO to 1,026 frames with pedestrian annotations in the KITTI Vision
Benchmark Suite has been established. Next, video degradation candidates for
each of these frames were generated using the leading video codecs libx264,
libx265, Nvidia HEVC, and AV1: 52 frames for the various compression presets
for color and gray-scale frames resulting in 104 degradation candidates per
original KITTI frame and 426,816 images in total. YOLO was applied to each
image to compute the intersection-over-union (IoU) metric to compare the
performance with the original baseline. While aggressively lossy compression
settings result in significant performance drops as expected, it was also
observed that some configurations actually result in slightly better IoU
results compared to the baseline. The findings show that carefully chosen lossy
video configurations preserve a decent performance of particular ML-enabled
systems while allowing for substantial savings when storing or transmitting
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RICE: Refining Instance Masks in Cluttered Environments with Graph Neural Networks. (arXiv:2106.15711v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Christopher Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yu Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15711">
                                    <div class="article-summary-box-inner">
                                        <span>Segmenting unseen object instances in cluttered environments is an important
capability that robots need when functioning in unstructured environments.
While previous methods have exhibited promising results, they still tend to
provide incorrect results in highly cluttered scenes. We postulate that a
network architecture that encodes relations between objects at a high-level can
be beneficial. Thus, in this work, we propose a novel framework that refines
the output of such methods by utilizing a graph-based representation of
instance masks. We train deep networks capable of sampling smart perturbations
to the segmentations, and a graph neural network, which can encode relations
between objects, to evaluate the perturbed segmentations. Our proposed method
is orthogonal to previous works and achieves state-of-the-art performance when
combined with them. We demonstrate an application that uses uncertainty
estimates generated by our method to guide a manipulator, leading to efficient
understanding of cluttered scenes. Code, models, and video can be found at
https://github.com/chrisdxie/rice .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images. (arXiv:2103.03423v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guansong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fengbei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+chen_Y/0/1/0/all/0/1">Yuanhong chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seon Ho Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Verjans_J/0/1/0/all/0/1">Johan W. Verjans</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rajvinder Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03423">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively
with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy)
samples that do not conform to the expected normal patterns. UAD has two main
advantages over its fully supervised counterpart. Firstly, it is able to
directly leverage large datasets available from health screening programs that
contain mostly normal image samples, avoiding the costly manual labelling of
abnormal samples and the subsequent issues involved in training with extremely
class-imbalanced data. Further, UAD approaches can potentially detect and
localise any type of lesions that deviate from the normal patterns. One
significant challenge faced by UAD methods is how to learn effective
low-dimensional image representations to detect and localise subtle
abnormalities, generally consisting of small lesions. To address this
challenge, we propose a novel self-supervised representation learning method,
called Constrained Contrastive Distribution learning for anomaly detection
(CCD), which learns fine-grained feature representations by simultaneously
predicting the distribution of augmented data and image contexts using
contrastive learning with pretext constraints. The learned representations can
be leveraged to train more anomaly-sensitive detection models. Extensive
experiment results show that our method outperforms current state-of-the-art
UAD approaches on three different colonoscopy and fundus screening datasets.
Our code is available at https://github.com/tianyu0207/CCD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distill on the Go: Online knowledge distillation in self-supervised learning. (arXiv:2104.09866v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhat_P/0/1/0/all/0/1">Prashant Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09866">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning solves pretext prediction tasks that do not require
annotations to learn feature representations. For vision tasks, pretext tasks
such as predicting rotation, solving jigsaw are solely created from the input
data. Yet, predicting this known information helps in learning representations
useful for downstream tasks. However, recent works have shown that wider and
deeper models benefit more from self-supervised learning than smaller models.
To address the issue of self-supervised pre-training of smaller models, we
propose Distill-on-the-Go (DoGo), a self-supervised learning paradigm using
single-stage online knowledge distillation to improve the representation
quality of the smaller models. We employ deep mutual learning strategy in which
two models collaboratively learn from each other to improve one another.
Specifically, each model is trained using self-supervised learning along with
distillation that aligns each model&#x27;s softmax probabilities of similarity
scores with that of the peer model. We conduct extensive experiments on
multiple benchmark datasets, learning objectives, and architectures to
demonstrate the potential of our proposed method. Our results show significant
performance gain in the presence of noisy and limited labels and generalization
to out-of-distribution data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Small in-distribution changes in 3D perspective and lighting fool both CNNs and Transformers. (arXiv:2106.16198v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1">Tomotake Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tzu-Mao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1">Xavier Boix</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1">Hanspeter Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16198">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are susceptible to small transformations including 2D
rotations and shifts, image crops, and even changes in object colors. This is
often attributed to biases in the training dataset, and the lack of 2D
shift-invariance due to not respecting the sampling theorem. In this paper, we
challenge this hypothesis by training and testing on unbiased datasets, and
showing that networks are brittle to both small 3D perspective changes and
lighting variations which cannot be explained by dataset bias or lack of
shift-invariance. To find these in-distribution errors, we introduce an
evolution strategies (ES) based approach, which we call CMA-Search. Despite
training with a large-scale (0.5 million images), unbiased dataset of camera
and light variations, in over 71% cases CMA-Search can find camera parameters
in the vicinity of a correctly classified image which lead to in-distribution
misclassifications with &lt; 3.6% change in parameters. With lighting changes,
CMA-Search finds misclassifications in 33% cases with &lt; 11.6% change in
parameters. Finally, we extend this method to find misclassifications in the
vicinity of ImageNet images for both ResNet and OpenAI&#x27;s CLIP model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets. Our model eliminates the requirement
for class token and positional embeddings through a novel sequence pooling
strategy and the use of convolutions. We show that compared to CNNs, our
compact transformers have fewer parameters and MACs, while obtaining similar
accuracies. Our method is flexible in terms of model size, and can have as
little as 0.28M parameters and achieve reasonable results. It can reach an
accuracy of 95.29 % when training from scratch on CIFAR-10, which is comparable
with modern CNN based approaches, and a significant improvement over previous
Transformer based models. Our simple and compact design democratizes
transformers by making them accessible to those equipped with basic computing
resources and/or dealing with important small datasets. Our method works on
larger datasets, such as ImageNet (80.28% accuracy with 29% parameters of ViT),
and NLP tasks as well. Our code and pre-trained models are publicly available
at https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Train Your MAML to Excel in Few-Shot Classification. (arXiv:2106.16245v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16245">
                                    <div class="article-summary-box-inner">
                                        <span>Model-agnostic meta-learning (MAML) is arguably the most popular
meta-learning algorithm nowadays, given its flexibility to incorporate various
model architectures and to be applied to different problems. Nevertheless, its
performance on few-shot classification is far behind many recent algorithms
dedicated to the problem. In this paper, we point out several key facets of how
to train MAML to excel in few-shot classification. First, we find that a large
number of gradient steps are needed for the inner loop update, which
contradicts the common usage of MAML for few-shot classification. Second, we
find that MAML is sensitive to the permutation of class assignments in
meta-testing: for a few-shot task of $N$ classes, there are exponentially many
ways to assign the learned initialization of the $N$-way classifier to the $N$
classes, leading to an unavoidably huge variance. Third, we investigate several
ways for permutation invariance and find that learning a shared classifier
initialization for all the classes performs the best. On benchmark datasets
such as MiniImageNet and TieredImageNet, our approach, which we name
UNICORN-MAML, performs on a par with or even outperforms state-of-the-art
algorithms, while keeping the simplicity of MAML without adding any extra
sub-networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Temporal Modeling for Efficient Action Recognition. (arXiv:2106.15787v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Can Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15787">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient long-short temporal modeling is key for enhancing the performance
of action recognition task. In this paper, we propose a new two-stream action
recognition network, termed as MENet, consisting of a Motion Enhancement (ME)
module and a Video-level Aggregation (VLA) module to achieve long-short
temporal modeling. Specifically, motion representations have been proved
effective in capturing short-term and high-frequency action. However, current
motion representations are calculated from adjacent frames, which may have poor
interpretation and bring useless information (noisy or blank). Thus, for
short-term motions, we design an efficient ME module to enhance the short-term
motions by mingling the motion saliency among neighboring segments. As for
long-term aggregations, VLA is adopted at the top of the appearance branch to
integrate the long-term dependencies across all segments. The two components of
MENet are complementary in temporal modeling. Extensive experiments are
conducted on UCF101 and HMDB51 benchmarks, which verify the effectiveness and
efficiency of our proposed MENet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation of Periocular Near-Infra-Red Eye Images Under Alcohol Effects. (arXiv:2106.15828v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tapia_J/0/1/0/all/0/1">Juan Tapia</a>, <a href="http://arxiv.org/find/cs/1/au:+Droguett_E/0/1/0/all/0/1">Enrique Lopez Droguett</a>, <a href="http://arxiv.org/find/cs/1/au:+Valenzuela_A/0/1/0/all/0/1">Andres Valenzuela</a>, <a href="http://arxiv.org/find/cs/1/au:+Benalcazar_D/0/1/0/all/0/1">Daniel Benalcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Causa_L/0/1/0/all/0/1">Leonardo Causa</a>, <a href="http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1">Christoph Busch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15828">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a new framework to detect, segment, and estimate the
localization of the eyes from a periocular Near-Infra-Red iris image under
alcohol consumption. The purpose of the system is to measure the fitness for
duty. Fitness systems allow us to determine whether a person is physically or
psychologically able to perform their tasks. Our framework is based on an
object detector trained from scratch to detect both eyes from a single image.
Then, two efficient networks were used for semantic segmentation; a Criss-Cross
attention network and DenseNet10, with only 122,514 and 210,732 parameters,
respectively. These networks can find the pupil, iris, and sclera. In the end,
the binary output eye mask is used for pupil and iris diameter estimation with
high precision. Five state-of-the-art algorithms were used for this purpose. A
mixed proposal reached the best results. A second contribution is establishing
an alcohol behavior curve to detect the alcohol presence utilizing a stream of
images captured from an iris instance. Also, a manually labeled database with
more than 20k images was created. Our best method obtains a mean
Intersection-over-Union of 94.54% with DenseNet10 with only 210,732 parameters
and an error of only 1-pixel on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOLO: A Simple Framework for Instance Segmentation. (arXiv:2106.15947v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinlong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rufeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1">Tao Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15947">
                                    <div class="article-summary-box-inner">
                                        <span>Compared to many other dense prediction tasks, e.g., semantic segmentation,
it is the arbitrary number of instances that has made instance segmentation
much more challenging. In order to predict a mask for each instance, mainstream
approaches either follow the &#x27;detect-then-segment&#x27; strategy (e.g., Mask R-CNN),
or predict embedding vectors first then cluster pixels into individual
instances. In this paper, we view the task of instance segmentation from a
completely new perspective by introducing the notion of &quot;instance categories&quot;,
which assigns categories to each pixel within an instance according to the
instance&#x27;s location. With this notion, we propose segmenting objects by
locations (SOLO), a simple, direct, and fast framework for instance
segmentation with strong performance. We derive a few SOLO variants (e.g.,
Vanilla SOLO, Decoupled SOLO, Dynamic SOLO) following the basic principle. Our
method directly maps a raw input image to the desired object categories and
instance masks, eliminating the need for the grouping post-processing or the
bounding box detection. Our approach achieves state-of-the-art results for
instance segmentation in terms of both speed and accuracy, while being
considerably simpler than the existing methods. Besides instance segmentation,
our method yields state-of-the-art results in object detection (from our mask
byproduct) and panoptic segmentation. We further demonstrate the flexibility
and high-quality segmentation of SOLO by extending it to perform one-stage
instance-level image matting. Code is available at: https://git.io/AdelaiDet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Positive-unlabeled Learning for Cell Detection in Histopathology Images with Incomplete Annotations. (arXiv:2106.15918v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zipei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_F/0/1/0/all/0/1">Fengqian Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1">Chuyang Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15918">
                                    <div class="article-summary-box-inner">
                                        <span>Cell detection in histopathology images is of great value in clinical
practice. \textit{Convolutional neural networks} (CNNs) have been applied to
cell detection to improve the detection accuracy, where cell annotations are
required for network training. However, due to the variety and large number of
cells, complete annotations that include every cell of interest in the training
images can be challenging. Usually, incomplete annotations can be achieved,
where positive labeling results are carefully examined to ensure their
reliability but there can be other positive instances, i.e., cells of interest,
that are not included in the annotations. This annotation strategy leads to a
lack of knowledge about true negative samples. Most existing methods simply
treat instances that are not labeled as positive as truly negative during
network training, which can adversely affect the network performance. In this
work, to address the problem of incomplete annotations, we formulate the
training of detection networks as a positive-unlabeled learning problem.
Specifically, the classification loss in network training is revised to take
into account incomplete annotations, where the terms corresponding to negative
samples are approximated with the true positive samples and the other samples
of which the labels are unknown. To evaluate the proposed method, experiments
were performed on a publicly available dataset for mitosis detection in breast
cancer cells, and the experimental results show that our method improves the
performance of cell detection given incomplete annotations for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shape Completion via IMLE. (arXiv:2106.16237v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_H/0/1/0/all/0/1">Himanshu Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Saurabh Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1">Ali Mahdavi-Amiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16237">
                                    <div class="article-summary-box-inner">
                                        <span>Shape completion is the problem of completing partial input shapes such as
partial scans. This problem finds important applications in computer vision and
robotics due to issues such as occlusion or sparsity in real-world data.
However, most of the existing research related to shape completion has been
focused on completing shapes by learning a one-to-one mapping which limits the
diversity and creativity of the produced results. We propose a novel multimodal
shape completion technique that is effectively able to learn a one-to-many
mapping and generates diverse complete shapes. Our approach is based on the
conditional Implicit MaximumLikelihood Estimation (IMLE) technique wherein we
condition our inputs on partial 3D point clouds. We extensively evaluate our
approach by comparing it to various baselines both quantitatively and
qualitatively. We show that our method is superior to alternatives in terms of
completeness and diversity of shapes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Phenotyping and Graph Modeling of Spatial Architecture in Lymphoid Neoplasms. (arXiv:2106.16174v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chen_P/0/1/0/all/0/1">Pingjun Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Aminu_M/0/1/0/all/0/1">Muhammad Aminu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hussein_S/0/1/0/all/0/1">Siba El Hussein</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khoury_J/0/1/0/all/0/1">Joseph Khoury</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_J/0/1/0/all/0/1">Jia Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16174">
                                    <div class="article-summary-box-inner">
                                        <span>The cells and their spatial patterns in the tumor microenvironment (TME) play
a key role in tumor evolution, and yet remains an understudied topic in
computational pathology. This study, to the best of our knowledge, is among the
first to hybrid local and global graph methods to profile orchestration and
interaction of cellular components. To address the challenge in hematolymphoid
cancers where the cell classes in TME are unclear, we first implemented cell
level unsupervised learning and identified two new cell subtypes. Local cell
graphs or supercells were built for each image by considering the individual
cell&#x27;s geospatial location and classes. Then, we applied supercell level
clustering and identified two new cell communities. In the end, we built global
graphs to abstract spatial interaction patterns and extract features for
disease diagnosis. We evaluate the proposed algorithm on H\&amp;E slides of 60
hematolymphoid neoplasm patients and further compared it with three cell level
graph-based algorithms, including the global cell graph, cluster cell graph,
and FLocK. The proposed algorithm achieves a mean diagnosis accuracy of 0.703
with the repeated 5-fold cross-validation scheme. In conclusion, our algorithm
shows superior performance over the existing methods and can be potentially
applied to other cancer types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResViT: Residual vision transformers for multi-modal medical image synthesis. (arXiv:2106.16031v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dalmaz_O/0/1/0/all/0/1">Onat Dalmaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Yurt_M/0/1/0/all/0/1">Mahmut Yurt</a>, <a href="http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1">Tolga &#xc7;ukur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16031">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-modal imaging is a key healthcare technology in the diagnosis and
management of disease, but it is often underutilized due to costs associated
with multiple separate scans. This limitation yields the need for synthesis of
unacquired modalities from the subset of available modalities. In recent years,
generative adversarial network (GAN) models with superior depiction of
structural details have been established as state-of-the-art in numerous
medical image synthesis tasks. However, GANs are characteristically based on
convolutional neural network (CNN) backbones that perform local processing with
compact filters. This inductive bias, in turn, compromises learning of
long-range spatial dependencies. While attention maps incorporated in GANs can
multiplicatively modulate CNN features to emphasize critical image regions,
their capture of global context is mostly implicit. Here, we propose a novel
generative adversarial approach for medical image synthesis, ResViT, to combine
local precision of convolution operators with contextual sensitivity of vision
transformers. Based on an encoder-decoder architecture, ResViT employs a
central bottleneck comprising novel aggregated residual transformer (ART)
blocks that synergistically combine convolutional and transformer modules.
Comprehensive demonstrations are performed for synthesizing missing sequences
in multi-contrast MRI and CT images from MRI. Our results indicate the
superiority of ResViT against competing methods in terms of qualitative
observations and quantitative metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Content-Aware Convolutional Neural Networks. (arXiv:2106.15797v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yaofo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15797">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) have achieved great success due to the
powerful feature learning ability of convolution layers. Specifically, the
standard convolution traverses the input images/features using a sliding window
scheme to extract features. However, not all the windows contribute equally to
the prediction results of CNNs. In practice, the convolutional operation on
some of the windows (e.g., smooth windows that contain very similar pixels) can
be very redundant and may introduce noises into the computation. Such
redundancy may not only deteriorate the performance but also incur the
unnecessary computational cost. Thus, it is important to reduce the
computational redundancy of convolution to improve the performance. To this
end, we propose a Content-aware Convolution (CAC) that automatically detects
the smooth windows and applies a 1x1 convolutional kernel to replace the
original large kernel. In this sense, we are able to effectively avoid the
redundant computation on similar pixels. By replacing the standard convolution
in CNNs with our CAC, the resultant models yield significantly better
performance and lower computational cost than the baseline models with the
standard convolution. More critically, we are able to dynamically allocate
suitable computation resources according to the data smoothness of different
images, making it possible for content-aware computation. Extensive experiments
on various computer vision tasks demonstrate the superiority of our method over
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic Data Are as Good as the Real for Association Knowledge Learning in Multi-object Tracking. (arXiv:2106.16100v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuchi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongdao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiangxin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16100">
                                    <div class="article-summary-box-inner">
                                        <span>Association, aiming to link bounding boxes of the same identity in a video
sequence, is a central component in multi-object tracking (MOT). To train
association modules, e.g., parametric networks, real video data are usually
used. However, annotating person tracks in consecutive video frames is
expensive, and such real data, due to its inflexibility, offer us limited
opportunities to evaluate the system performance w.r.t changing tracking
scenarios. In this paper, we study whether 3D synthetic data can replace
real-world videos for association training. Specifically, we introduce a
large-scale synthetic data engine named MOTX, where the motion characteristics
of cameras and objects are manually configured to be similar to those in
real-world datasets. We show that compared with real data, association
knowledge obtained from synthetic data can achieve very similar performance on
real-world test sets without domain adaption techniques. Our intriguing
observation is credited to two factors. First and foremost, 3D engines can well
simulate motion factors such as camera movement, camera view and object
movement, so that the simulated videos can provide association modules with
effective motion features. Second, experimental results show that the
appearance domain gap hardly harms the learning of association knowledge. In
addition, the strong customization ability of MOTX allows us to quantitatively
assess the impact of motion factors on MOT, which brings new insights to the
community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affective Image Content Analysis: Two Decades Review and New Perspectives. (arXiv:2106.16125v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sicheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xingxu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jufeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_G/0/1/0/all/0/1">Guoli Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guiguang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16125">
                                    <div class="article-summary-box-inner">
                                        <span>Images can convey rich semantics and induce various emotions in viewers.
Recently, with the rapid advancement of emotional intelligence and the
explosive growth of visual data, extensive research efforts have been dedicated
to affective image content analysis (AICA). In this survey, we will
comprehensively review the development of AICA in the recent two decades,
especially focusing on the state-of-the-art methods with respect to three main
challenges -- the affective gap, perception subjectivity, and label noise and
absence. We begin with an introduction to the key emotion representation models
that have been widely employed in AICA and description of available datasets
for performing evaluation with quantitative comparison of label noise and
dataset bias. We then summarize and compare the representative approaches on
(1) emotion feature extraction, including both handcrafted and deep features,
(2) learning methods on dominant emotion recognition, personalized emotion
prediction, emotion distribution learning, and learning from noisy data or few
labels, and (3) AICA based applications. Finally, we discuss some challenges
and promising research directions in the future, such as image content and
context understanding, group emotion clustering, and viewer-image interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Step Adversarial Training for Semantic Segmentation. (arXiv:2106.15998v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wiens_D/0/1/0/all/0/1">Daniel Wiens</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1">Barbara Hammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15998">
                                    <div class="article-summary-box-inner">
                                        <span>Even though deep neural networks succeed on many different tasks including
semantic segmentation, they lack on robustness against adversarial examples. To
counteract this exploit, often adversarial training is used. However, it is
known that adversarial training with weak adversarial attacks (e.g. using the
Fast Gradient Method) does not improve the robustness against stronger attacks.
Recent research shows that it is possible to increase the robustness of such
single-step methods by choosing an appropriate step size during the training.
Finding such a step size, without increasing the computational effort of
single-step adversarial training, is still an open challenge. In this work we
address the computationally particularly demanding task of semantic
segmentation and propose a new step size control algorithm that increases the
robustness of single-step adversarial training. The proposed algorithm does not
increase the computational effort of single-step adversarial training
considerably and also simplifies training, because it is free of
meta-parameter. We show that the robustness of our approach can compete with
multi-step adversarial training on two popular benchmarks for semantic
segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BLNet: A Fast Deep Learning Framework for Low-Light Image Enhancement with Noise Removal and Color Restoration. (arXiv:2106.15953v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wei_X/0/1/0/all/0/1">Xinxu Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xianshi Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shisen Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheng_C/0/1/0/all/0/1">Cheng Cheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1">Yanlin Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_K/0/1/0/all/0/1">Kaifu Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yongjie Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15953">
                                    <div class="article-summary-box-inner">
                                        <span>Images obtained in real-world low-light conditions are not only low in
brightness, but they also suffer from many other types of degradation, such as
color bias, unknown noise, detail loss and halo artifacts. In this paper, we
propose a very fast deep learning framework called Bringing the Lightness
(denoted as BLNet) that consists of two U-Nets with a series of well-designed
loss functions to tackle all of the above degradations. Based on Retinex
Theory, the decomposition net in our model can decompose low-light images into
reflectance and illumination and remove noise in the reflectance during the
decomposition phase. We propose a Noise and Color Bias Control module (NCBC
Module) that contains a convolutional neural network and two loss functions
(noise loss and color loss). This module is only used to calculate the loss
functions during the training phase, so our method is very fast during the test
phase. This module can smooth the reflectance to achieve the purpose of noise
removal while preserving details and edge information and controlling color
bias. We propose a network that can be trained to learn the mapping between
low-light and normal-light illumination and enhance the brightness of images
taken in low-light illumination. We train and evaluate the performance of our
proposed model over the real-world Low-Light (LOL) dataset), and we also test
our model over several other frequently used datasets (LIME, DICM and MEF
datasets). We conduct extensive experiments to demonstrate that our approach
achieves a promising effect with good rubustness and generalization and
outperforms many other state-of-the-art methods qualitatively and
quantitatively. Our method achieves high speed because we use loss functions
instead of introducing additional denoisers for noise removal and color
correction. The code and model are available at
https://github.com/weixinxu666/BLNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMPL: Generating Synthetic Overhead Imagery to Address Zero-shot and Few-Shot Detection Problems. (arXiv:2106.15681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Bohao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bradbury_K/0/1/0/all/0/1">Kyle Bradbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Malof_J/0/1/0/all/0/1">Jordan M. Malof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15681">
                                    <div class="article-summary-box-inner">
                                        <span>Recently deep neural networks (DNNs) have achieved tremendous success for
object detection in overhead (e.g., satellite) imagery. One ongoing challenge
however is the acquisition of training data, due to high costs of obtaining
satellite imagery and annotating objects in it. In this work we present a
simple approach - termed Synthetic object IMPLantation (SIMPL) - to easily and
rapidly generate large quantities of synthetic overhead training data for
custom target objects. We demonstrate the effectiveness of using SIMPL
synthetic imagery for training DNNs in zero-shot scenarios where no real
imagery is available; and few-shot learning scenarios, where limited real-world
imagery is available. We also conduct experiments to study the sensitivity of
SIMPL&#x27;s effectiveness to some key design parameters, providing users for
insights when designing synthetic imagery for custom objects. We release a
software implementation of our SIMPL approach so that others can build upon it,
or use it for their own custom problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Efficiency of Transformers for Resource-Constrained Devices. (arXiv:2106.16006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tabani_H/0/1/0/all/0/1">Hamid Tabani</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramaniam_A/0/1/0/all/0/1">Ajay Balasubramaniam</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1">Shabbir Marzban</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16006">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers provide promising accuracy and have become popular and used in
various domains such as natural language processing and computer vision.
However, due to their massive number of model parameters, memory and
computation requirements, they are not suitable for resource-constrained
low-power devices. Even with high-performance and specialized devices, the
memory bandwidth can become a performance-limiting bottleneck. In this paper,
we present a performance analysis of state-of-the-art vision transformers on
several devices. We propose to reduce the overall memory footprint and memory
transfers by clustering the model parameters. We show that by using only 64
clusters to represent model parameters, it is possible to reduce the data
transfer from the main memory by more than 4x, achieve up to 22% speedup and
39% energy savings on mobile devices with less than 0.1% accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dense Graph Convolutional Neural Networks on 3D Meshes for 3D Object Segmentation and Classification. (arXiv:2106.15778v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Wenming Tang Guoping Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15778">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents new designs of graph convolutional neural networks (GCNs)
on 3D meshes for 3D object segmentation and classification. We use the faces of
the mesh as basic processing units and represent a 3D mesh as a graph where
each node corresponds to a face. To enhance the descriptive power of the graph,
we introduce a 1-ring face neighbourhood structure to derive novel
multi-dimensional spatial and structure features to represent the graph nodes.
Based on this new graph representation, we then design a densely connected
graph convolutional block which aggregates local and regional features as the
key construction component to build effective and efficient practical GCN
models for 3D object classification and segmentation. We will present
experimental results to show that our new technique outperforms state of the
art where our models are shown to have the smallest number of parameters and
consietently achieve the highest accuracies across a number of benchmark
datasets. We will also present ablation studies to demonstrate the soundness of
our design principles and the effectiveness of our practical models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning. (arXiv:2106.15831v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andreassen_A/0/1/0/all/0/1">Anders Andreassen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_Y/0/1/0/all/0/1">Yasaman Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Neyshabur_B/0/1/0/all/0/1">Behnam Neyshabur</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15831">
                                    <div class="article-summary-box-inner">
                                        <span>Although machine learning models typically experience a drop in performance
on out-of-distribution data, accuracies on in- versus out-of-distribution data
are widely observed to follow a single linear trend when evaluated across a
testbed of models. Models that are more accurate on the out-of-distribution
data relative to this baseline exhibit &quot;effective robustness&quot; and are
exceedingly rare. Identifying such models, and understanding their properties,
is key to improving out-of-distribution performance. We conduct a thorough
empirical investigation of effective robustness during fine-tuning and
surprisingly find that models pre-trained on larger datasets exhibit effective
robustness during training that vanishes at convergence. We study how
properties of the data influence effective robustness, and we show that it
increases with the larger size, more diversity, and higher example difficulty
of the dataset. We also find that models that display effective robustness are
able to correctly classify 10% of the examples that no other current testbed
model gets correct. Finally, we discuss several strategies for scaling
effective robustness to the high-accuracy regime to improve the
out-of-distribution accuracy of state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Aware Wavelet-based Detection of Morphed Face Images. (arXiv:2106.15686v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aghdaie_P/0/1/0/all/0/1">Poorya Aghdaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_B/0/1/0/all/0/1">Baaria Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15686">
                                    <div class="article-summary-box-inner">
                                        <span>Morphed images have exploited loopholes in the face recognition checkpoints,
e.g., Credential Authentication Technology (CAT), used by Transportation
Security Administration (TSA), which is a non-trivial security concern. To
overcome the risks incurred due to morphed presentations, we propose a
wavelet-based morph detection methodology which adopts an end-to-end trainable
soft attention mechanism . Our attention-based deep neural network (DNN)
focuses on the salient Regions of Interest (ROI) which have the most spatial
support for morph detector decision function, i.e, morph class binary softmax
output. A retrospective of morph synthesizing procedure aids us to speculate
the ROI as regions around facial landmarks , particularly for the case of
landmark-based morphing techniques. Moreover, our attention-based DNN is
adapted to the wavelet space, where inputs of the network are coarse-to-fine
spectral representations, 48 stacked wavelet sub-bands to be exact. We evaluate
performance of the proposed framework using three datasets, VISAPP17, LMA, and
MorGAN. In addition, as attention maps can be a robust indicator whether a
probe image under investigation is genuine or counterfeit, we analyze the
estimated attention maps for both a bona fide image and its corresponding
morphed image. Finally, we present an ablation study on the efficacy of
utilizing attention mechanism for the sake of morph detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recent Advances in Fibrosis and Scar Segmentation from Cardiac MRI: A State-of-the-Art Review and Future Perspectives. (arXiv:2106.15707v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1">Yinzhe Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Z/0/1/0/all/0/1">Zeyu Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1">Binghuan Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Firmin_D/0/1/0/all/0/1">David Firmin</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15707">
                                    <div class="article-summary-box-inner">
                                        <span>Segmentation of cardiac fibrosis and scar are essential for clinical
diagnosis and can provide invaluable guidance for the treatment of cardiac
diseases. Late Gadolinium enhancement (LGE) cardiovascular magnetic resonance
(CMR) has been successful for its efficacy in guiding the clinical diagnosis
and treatment reliably. For LGE CMR, many methods have demonstrated success in
accurately segmenting scarring regions. Co-registration with other
non-contrast-agent (non-CA) modalities, balanced steady-state free precession
(bSSFP) and cine magnetic resonance imaging (MRI) for example, can further
enhance the efficacy of automated segmentation of cardiac anatomies. Many
conventional methods have been proposed to provide automated or semi-automated
segmentation of scars. With the development of deep learning in recent years,
we can also see more advanced methods that are more efficient in providing more
accurate segmentations. This paper conducts a state-of-the-art review of
conventional and current state-of-the-art approaches utilising different
modalities for accurate cardiac fibrosis and scar segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Reading of Hypotheses for Organizational Research Reviews and Pre-trained Models via R Shiny App for Non-Programmers. (arXiv:2106.16102v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1">Victor Zitian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Montano_Campos_F/0/1/0/all/0/1">Felipe Montano-Campos</a>, <a href="http://arxiv.org/find/cs/1/au:+Zadrozny_W/0/1/0/all/0/1">Wlodek Zadrozny</a>, <a href="http://arxiv.org/find/cs/1/au:+Canfield_E/0/1/0/all/0/1">Evan Canfield</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16102">
                                    <div class="article-summary-box-inner">
                                        <span>The volume of scientific publications in organizational research becomes
exceedingly overwhelming for human researchers who seek to timely extract and
review knowledge. This paper introduces natural language processing (NLP)
models to accelerate the discovery, extraction, and organization of theoretical
developments (i.e., hypotheses) from social science publications. We illustrate
and evaluate NLP models in the context of a systematic review of stakeholder
value constructs and hypotheses. Specifically, we develop NLP models to
automatically 1) detect sentences in scholarly documents as hypotheses or not
(Hypothesis Detection), 2) deconstruct the hypotheses into nodes (constructs)
and links (causal/associative relationships) (Relationship Deconstruction ),
and 3) classify the features of links in terms causality (versus association)
and direction (positive, negative, versus nonlinear) (Feature Classification).
Our models have reported high performance metrics for all three tasks. While
our models are built in Python, we have made the pre-trained models fully
accessible for non-programmers. We have provided instructions on installing and
using our pre-trained models via an R Shiny app graphic user interface (GUI).
Finally, we suggest the next paths to extend our methodology for
computer-assisted knowledge synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Networks for Spatio-temporal Data: A Survey. (arXiv:2008.08903v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1">Nan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sichen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_K/0/1/0/all/0/1">Kyle Kai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabowo_A/0/1/0/all/0/1">Arian Prabowo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahaman_M/0/1/0/all/0/1">Mohammad Saiedur Rahaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1">Flora D. Salim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08903">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have shown remarkable success in
producing realistic-looking images in the computer vision area. Recently,
GAN-based techniques are shown to be promising for spatio-temporal-based
applications such as trajectory prediction, events generation and time-series
data imputation. While several reviews for GANs in computer vision have been
presented, no one has considered addressing the practical applications and
challenges relevant to spatio-temporal data. In this paper, we have conducted a
comprehensive review of the recent developments of GANs for spatio-temporal
data. We summarise the application of popular GAN architectures for
spatio-temporal data and the common practices for evaluating the performance of
spatio-temporal applications with GANs. Finally, we point out future research
directions to benefit researchers in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Chorus Recognition for Improving Song Search. (arXiv:2106.16153v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhixu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1">Binbin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tingyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingsheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhigang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16153">
                                    <div class="article-summary-box-inner">
                                        <span>We discuss a novel task, Chorus Recognition, which could potentially benefit
downstream tasks such as song search and music summarization. Different from
the existing tasks such as music summarization or lyrics summarization relying
on single-modal information, this paper models chorus recognition as a
multi-modal one by utilizing both the lyrics and the tune information of songs.
We propose a multi-modal Chorus Recognition model that considers diverse
features. Besides, we also create and publish the first Chorus Recognition
dataset containing 627 songs for public use. Our empirical study performed on
the dataset demonstrates that our approach outperforms several baselines in
chorus recognition. In addition, our approach also helps to improve the
accuracy of its downstream task - song search by more than 10.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Evaluation of Rating Systems in Team-based Battle Royale Games. (arXiv:2105.14069v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dehpanah_A/0/1/0/all/0/1">Arman Dehpanah</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghori_M/0/1/0/all/0/1">Muheeb Faizan Ghori</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemmell_J/0/1/0/all/0/1">Jonathan Gemmell</a>, <a href="http://arxiv.org/find/cs/1/au:+Mobasher_B/0/1/0/all/0/1">Bamshad Mobasher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14069">
                                    <div class="article-summary-box-inner">
                                        <span>Online competitive games have become a mainstream entertainment platform. To
create a fair and exciting experience, these games use rating systems to match
players with similar skills. While there has been an increasing amount of
research on improving the performance of these systems, less attention has been
paid to how their performance is evaluated. In this paper, we explore the
utility of several metrics for evaluating three popular rating systems on a
real-world dataset of over 25,000 team battle royale matches. Our results
suggest considerable differences in their evaluation patterns. Some metrics
were highly impacted by the inclusion of new players. Many could not capture
the real differences between certain groups of players. Among all metrics
studied, normalized discounted cumulative gain (NDCG) demonstrated more
reliable performance and more flexibility. It alleviated most of the challenges
faced by the other metrics while adding the freedom to adjust the focus of the
evaluations on different groups of players.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Ask Conversational Questions by Optimizing Levenshtein Distance. (arXiv:2106.15903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhongkun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengjie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaochun Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Ming Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15903">
                                    <div class="article-summary-box-inner">
                                        <span>Conversational Question Simplification (CQS) aims to simplify self-contained
questions into conversational ones by incorporating some conversational
characteristics, e.g., anaphora and ellipsis. Existing maximum likelihood
estimation (MLE) based methods often get trapped in easily learned tokens as
all tokens are treated equally during training. In this work, we introduce a
Reinforcement Iterative Sequence Editing (RISE) framework that optimizes the
minimum Levenshtein distance (MLD) through explicit editing actions. RISE is
able to pay attention to tokens that are related to conversational
characteristics. To train RISE, we devise an Iterative Reinforce Training (IRT)
algorithm with a Dynamic Programming based Sampling (DPS) process to improve
exploration. Experimental results on two benchmark datasets show that RISE
significantly outperforms state-of-the-art methods and generalizes well on
unseen data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">News Article Retrieval in Context for Event-centric Narrative Creation. (arXiv:2106.16053v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voskarides_N/0/1/0/all/0/1">Nikos Voskarides</a>, <a href="http://arxiv.org/find/cs/1/au:+Meij_E/0/1/0/all/0/1">Edgar Meij</a>, <a href="http://arxiv.org/find/cs/1/au:+Sauer_S/0/1/0/all/0/1">Sabrina Sauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16053">
                                    <div class="article-summary-box-inner">
                                        <span>Writers such as journalists often use automatic tools to find relevant
content to include in their narratives. In this paper, we focus on supporting
writers in the news domain to develop event-centric narratives. Given an
incomplete narrative that specifies a main event and a context, we aim to
retrieve news articles that discuss relevant events that would enable the
continuation of the narrative. We formally define this task and propose a
retrieval dataset construction procedure that relies on existing news articles
to simulate incomplete narratives and relevant articles. Experiments on two
datasets derived from this procedure show that state-of-the-art lexical and
semantic rankers are not sufficient for this task. We show that combining those
with a ranker that ranks articles by reverse chronological order outperforms
those rankers alone. We also perform an in-depth quantitative and qualitative
analysis of the results that sheds light on the characteristics of this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphFM: Graph Factorization Machines for Feature Interaction Modeling. (arXiv:2105.11866v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zekun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zeyu Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11866">
                                    <div class="article-summary-box-inner">
                                        <span>Factorization machine (FM) is a prevalent approach to modeling pairwise
(second-order) feature interactions when dealing with high-dimensional sparse
data. However, on the one hand, FM fails to capture higher-order feature
interactions suffering from combinatorial expansion, on the other hand, taking
into account interaction between every pair of features may introduce noise and
degrade prediction accuracy. To solve the problems, we propose a novel approach
Graph Factorization Machine (GraphFM) by naturally representing features in the
graph structure. In particular, a novel mechanism is designed to select the
beneficial feature interactions and formulate them as edges between features.
Then our proposed model which integrates the interaction function of FM into
the feature aggregation strategy of Graph Neural Network (GNN), can model
arbitrary-order feature interactions on the graph-structured features by
stacking layers. Experimental results on several real-world datasets has
demonstrated the rationality and effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Aware Attention-Based Data Augmentation for POI Recommendation. (arXiv:2106.15984v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yadan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadiq_S/0/1/0/all/0/1">Shazia W. Sadiq</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1">Peng Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15984">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of location-based social networks (LBSNs),
Point-Of-Interest (POI) recommendation has been broadly studied in this decade.
Recently, the next POI recommendation, a natural extension of POI
recommendation, has attracted much attention. It aims at suggesting the next
POI to a user in spatial and temporal context, which is a practical yet
challenging task in various applications. Existing approaches mainly model the
spatial and temporal information, and memorize historical patterns through
user&#x27;s trajectories for recommendation. However, they suffer from the negative
impact of missing and irregular check-in data, which significantly influences
the model performance. In this paper, we propose an attention-based
sequence-to-sequence generative model, namely POI-Augmentation Seq2Seq
(PA-Seq2Seq), to address the sparsity of training set by making check-in
records to be evenly-spaced. Specifically, the encoder summarises each check-in
sequence and the decoder predicts the possible missing check-ins based on the
encoded information. In order to learn time-aware correlation among user
history, we employ local attention mechanism to help the decoder focus on a
specific range of context information when predicting a certain missing
check-in point. Extensive experiments have been conducted on two real-world
check-in datasets, Gowalla and Brightkite, for performance and effectiveness
evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Domain Knowledge for Extractive Summarization of Legal Case Documents. (arXiv:2106.15876v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1">Paheli Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Poddar_S/0/1/0/all/0/1">Soham Poddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudra_K/0/1/0/all/0/1">Koustav Rudra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1">Kripabandhu Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Saptarshi Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15876">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic summarization of legal case documents is an important and practical
challenge. Apart from many domain-independent text summarization algorithms
that can be used for this purpose, several algorithms have been developed
specifically for summarizing legal case documents. However, most of the
existing algorithms do not systematically incorporate domain knowledge that
specifies what information should ideally be present in a legal case document
summary. To address this gap, we propose an unsupervised summarization
algorithm DELSumm which is designed to systematically incorporate guidelines
from legal experts into an optimization setup. We conduct detailed experiments
over case documents from the Indian Supreme Court. The experiments show that
our proposed unsupervised method outperforms several strong baselines in terms
of ROUGE scores, including both general summarization algorithms and
legal-specific ones. In fact, though our proposed algorithm is unsupervised, it
outperforms several supervised summarization models that are trained over
thousands of document-summary pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Adversarial Variational Embedding for Robust Recommendation. (arXiv:2106.15779v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1">Qiaomin Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1">Ning Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15779">
                                    <div class="article-summary-box-inner">
                                        <span>Robust recommendation aims at capturing true preference of users from noisy
data, for which there are two lines of methods have been proposed. One is based
on noise injection, and the other is to adopt the generative model Variational
Auto-encoder (VAE). However, the existing works still face two challenges.
First, the noise injection based methods often draw the noise from a fixed
noise distribution given in advance, while in real world, the noise
distributions of different users and items may differ from each other due to
personal behaviors and item usage patterns. Second, the VAE based models are
not expressive enough to capture the true preference since VAE often yields an
embedding space of a single modal, while in real world, user-item interactions
usually exhibit multi-modality on user preference distribution. In this paper,
we propose a novel model called Dual Adversarial Variational Embedding (DAVE)
for robust recommendation, which can provide personalized noise reduction for
different users and items, and capture the multi-modality of the embedding
space, by combining the advantages of VAE and adversarial training between the
introduced auxiliary discriminators and the variational inference networks. The
extensive experiments conducted on real datasets verify the effectiveness of
DAVE on robust recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering Collaborative Signals for Next POI Recommendation with Iterative Seq2Graph Augmentation. (arXiv:2106.15814v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15814">
                                    <div class="article-summary-box-inner">
                                        <span>Being an indispensable component in location-based social networks, next
point-of-interest (POI) recommendation recommends users unexplored POIs based
on their recent visiting histories. However, existing work mainly models
check-in data as isolated POI sequences, neglecting the crucial collaborative
signals from cross-sequence check-in information. Furthermore, the sparse
POI-POI transitions restrict the ability of a model to learn effective
sequential patterns for recommendation. In this paper, we propose
Sequence-to-Graph (Seq2Graph) augmentation for each POI sequence, allowing
collaborative signals to be propagated from correlated POIs belonging to other
sequences. We then devise a novel Sequence-to-Graph POI Recommender (SGRec),
which jointly learns POI embeddings and infers a user&#x27;s temporal preferences
from the graph-augmented POI sequence. To overcome the sparsity of POI-level
interactions, we further infuse category-awareness into SGRec with a multi-task
learning scheme that captures the denser category-wise transitions. As such,
SGRec makes full use of the collaborative signals for learning expressive POI
representations, and also comprehensively uncovers multi-level sequential
patterns for user preference modelling. Extensive experiments on two real-world
datasets demonstrate the superiority of SGRec against state-of-the-art methods
in next POI recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretrained Transformers as Universal Computation Engines. (arXiv:2103.05247v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Kevin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05247">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the capability of a transformer pretrained on natural language
to generalize to other modalities with minimal finetuning -- in particular,
without finetuning of the self-attention and feedforward layers of the residual
blocks. We consider such a model, which we call a Frozen Pretrained Transformer
(FPT), and study finetuning it on a variety of sequence classification tasks
spanning numerical computation, vision, and protein fold prediction. In
contrast to prior works which investigate finetuning on the same modality as
the pretraining dataset, we show that pretraining on natural language can
improve performance and compute efficiency on non-language downstream tasks.
Additionally, we perform an analysis of the architecture, comparing the
performance of a random initialized transformer to a random LSTM. Combining the
two insights, we find language-pretrained transformers can obtain strong
performance on a variety of non-language tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear-Mapping based Variational Ensemble Kalman Filter. (arXiv:2103.06315v3 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wen_L/0/1/0/all/0/1">Linjie Wen</a>, <a href="http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1">Jinglai Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06315">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a linear-mapping based variational Ensemble Kalman filter for
sequential Bayesian filtering problems with generic observation models.
Specifically, the proposed method is formulated as to construct a linear
mapping from the prior ensemble to the posterior one, and the linear mapping is
computed via a variational Bayesian formulation, i.e., by minimizing the
Kullback-Leibler divergence between the transformed distribution by the linear
mapping and the actual posterior. A gradient descent scheme is proposed to
solve the resulting optimization problem. With numerical examples we
demonstrate that the method has competitive performance against existing
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Utility of Gradient Compression in Distributed Training Systems. (arXiv:2103.00543v3 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Saurabh Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_S/0/1/0/all/0/1">Shivaram Venkataraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Papailiopoulos_D/0/1/0/all/0/1">Dimitris Papailiopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00543">
                                    <div class="article-summary-box-inner">
                                        <span>A rich body of prior work has highlighted the existence of communication
bottlenecks in synchronous data-parallel training. To alleviate these
bottlenecks, a long line of recent work proposes gradient and model compression
methods. In this work, we evaluate the efficacy of gradient compression methods
and compare their scalability with optimized implementations of synchronous
data-parallel SGD across more than 200 different setups. Surprisingly, we
observe that only in 6 cases out of more than 200, gradient compression methods
provide speedup over optimized synchronous data-parallel training in the
typical data-center setting. We conduct an extensive investigation to identify
the root causes of this phenomenon, and offer a performance model that can be
used to identify the benefits of gradient compression for a variety of system
setups. Based on our analysis, we propose a list of desirable properties that
gradient compression methods should satisfy, in order for them to provide a
meaningful end-to-end speedup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gym-ANM: Reinforcement Learning Environments for Active Network Management Tasks in Electricity Distribution Systems. (arXiv:2103.07932v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Henry_R/0/1/0/all/0/1">Robin Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1">Damien Ernst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07932">
                                    <div class="article-summary-box-inner">
                                        <span>Active network management (ANM) of electricity distribution networks include
many complex stochastic sequential optimization problems. These problems need
to be solved for integrating renewable energies and distributed storage into
future electrical grids. In this work, we introduce Gym-ANM, a framework for
designing reinforcement learning (RL) environments that model ANM tasks in
electricity distribution networks. These environments provide new playgrounds
for RL research in the management of electricity networks that do not require
an extensive knowledge of the underlying dynamics of such systems. Along with
this work, we are releasing an implementation of an introductory
toy-environment, ANM6-Easy, designed to emphasize common challenges in ANM. We
also show that state-of-the-art RL algorithms can already achieve good
performance on ANM6-Easy when compared against a model predictive control (MPC)
approach. Finally, we provide guidelines to create new Gym-ANM environments
differing in terms of (a) the distribution network topology and parameters, (b)
the observation space, (c) the modelling of the stochastic processes present in
the system, and (d) a set of hyperparameters influencing the reward signal.
Gym-ANM can be downloaded at https://github.com/robinhenry/gym-anm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Power of Saturated Transformers: A View from Circuit Complexity. (arXiv:2106.16213v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1">William Merrill</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1">Roy Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16213">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become a standard architecture for many NLP problems. This
has motivated theoretically analyzing their capabilities as models of language,
in order to understand what makes them successful, and what their potential
weaknesses might be. Recent work has shown that transformers with hard
attention are quite limited in capacity, and in fact can be simulated by
constant-depth circuits. However, hard attention is a restrictive assumption,
which may complicate the relevance of these results for practical transformers.
In this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We show that saturated
transformers transcend the limitations of hard-attention transformers. With
some minor assumptions, we prove that the number of bits needed to represent a
saturated transformer memory vector is $O(\log n)$, which implies saturated
transformers can be simulated by log-depth circuits. Thus, the jump from hard
to saturated attention can be understood as increasing the transformer&#x27;s
effective circuit depth by a factor of $O(\log n)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cautiously Optimistic Policy Optimization and Exploration with Linear Function Approximation. (arXiv:2103.12923v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zanette_A/0/1/0/all/0/1">Andrea Zanette</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Alekh Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12923">
                                    <div class="article-summary-box-inner">
                                        <span>Policy optimization methods are popular reinforcement learning algorithms,
because their incremental and on-policy nature makes them more stable than the
value-based counterparts. However, the same properties also make them slow to
converge and sample inefficient, as the on-policy requirement precludes data
reuse and the incremental updates couple large iteration complexity into the
sample complexity. These characteristics have been observed in experiments as
well as in theory in the recent work of~\citet{agarwal2020pc}, which provides a
policy optimization method PCPG that can robustly find near optimal polices for
approximately linear Markov decision processes but suffers from an extremely
poor sample complexity compared with value-based techniques.

In this paper, we propose a new algorithm, COPOE, that overcomes the sample
complexity issue of PCPG while retaining its robustness to model
misspecification. Compared with PCPG, COPOE makes several important algorithmic
enhancements, such as enabling data reuse, and uses more refined analysis
techniques, which we expect to be more broadly applicable to designing new
reinforcement learning algorithms. The result is an improvement in sample
complexity from $\widetilde{O}(1/\epsilon^{11})$ for PCPG to
$\widetilde{O}(1/\epsilon^3)$ for PCPG, nearly bridging the gap with
value-based techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nearly-Tight and Oblivious Algorithms for Explainable Clustering. (arXiv:2106.16147v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gamlath_B/0/1/0/all/0/1">Buddhima Gamlath</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xinrui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Polak_A/0/1/0/all/0/1">Adam Polak</a>, <a href="http://arxiv.org/find/cs/1/au:+Svensson_O/0/1/0/all/0/1">Ola Svensson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16147">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of explainable clustering in the setting first
formalized by Moshkovitz, Dasgupta, Rashtchian, and Frost (ICML 2020). A
$k$-clustering is said to be explainable if it is given by a decision tree
where each internal node splits data points with a threshold cut in a single
dimension (feature), and each of the $k$ leaves corresponds to a cluster. We
give an algorithm that outputs an explainable clustering that loses at most a
factor of $O(\log^2 k)$ compared to an optimal (not necessarily explainable)
clustering for the $k$-medians objective, and a factor of $O(k \log^2 k)$ for
the $k$-means objective. This improves over the previous best upper bounds of
$O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\Omega(\log
k)$ lower bound for $k$-medians and our new $\Omega(k)$ lower bound for
$k$-means. The algorithm is remarkably simple. In particular, given an initial
not necessarily explainable clustering in $\mathbb{R}^d$, it is oblivious to
the data points and runs in time $O(dk \log^2 k)$, independent of the number of
data points $n$. Our upper and lower bounds also generalize to objectives given
by higher $\ell_p$-norms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAGIC: Learning Macro-Actions for Online POMDP Planning. (arXiv:2011.03813v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yiyuan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1">Panpan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1">David Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03813">
                                    <div class="article-summary-box-inner">
                                        <span>The partially observable Markov decision process (POMDP) is a principled
general framework for robot decision making under uncertainty, but POMDP
planning suffers from high computational complexity, when long-term planning is
required. While temporally-extended macro-actions help to cut down the
effective planning horizon and significantly improve computational efficiency,
how do we acquire good macro-actions? This paper proposes Macro-Action
Generator-Critic (MAGIC), which performs offline learning of macro-actions
optimized for online POMDP planning. Specifically, MAGIC learns a macro-action
generator end-to-end, using an online planner&#x27;s performance as the feedback.
During online planning, the generator generates on the fly situation-aware
macro-actions conditioned on the robot&#x27;s belief and the environment context. We
evaluated MAGIC on several long-horizon planning tasks both in simulation and
on a real robot. The experimental results show that the learned macro-actions
offer significant benefits in online planning performance, compared with
primitive actions and handcrafted macro-actions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SGD Generalizes Better Than GD (And Regularization Doesn&#x27;t Help). (arXiv:2102.01117v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amir_I/0/1/0/all/0/1">Idan Amir</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Livni_R/0/1/0/all/0/1">Roi Livni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01117">
                                    <div class="article-summary-box-inner">
                                        <span>We give a new separation result between the generalization performance of
stochastic gradient descent (SGD) and of full-batch gradient descent (GD) in
the fundamental stochastic convex optimization model. While for SGD it is
well-known that $O(1/\epsilon^2)$ iterations suffice for obtaining a solution
with $\epsilon$ excess expected risk, we show that with the same number of
steps GD may overfit and emit a solution with $\Omega(1)$ generalization error.
Moreover, we show that in fact $\Omega(1/\epsilon^4)$ iterations are necessary
for GD to match the generalization performance of SGD, which is also tight due
to recent work by Bassily et al. (2020). We further discuss how regularizing
the empirical risk minimized by GD essentially does not change the above
result, and revisit the concepts of stability, implicit bias and the role of
the learning algorithm in generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges and Opportunities in High-dimensional Variational Inference. (arXiv:2103.01085v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhaka_A/0/1/0/all/0/1">Akash Kumar Dhaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Catalina_A/0/1/0/all/0/1">Alejandro Catalina</a>, <a href="http://arxiv.org/find/cs/1/au:+Welandawe_M/0/1/0/all/0/1">Manushi Welandawe</a>, <a href="http://arxiv.org/find/cs/1/au:+Andersen_M/0/1/0/all/0/1">Michael Riis Andersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huggins_J/0/1/0/all/0/1">Jonathan Huggins</a>, <a href="http://arxiv.org/find/cs/1/au:+Vehtari_A/0/1/0/all/0/1">Aki Vehtari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01085">
                                    <div class="article-summary-box-inner">
                                        <span>Current black-box variational inference (BBVI) methods require the user to
make numerous design choices -- such as the selection of variational objective
and approximating family -- yet there is little principled guidance on how to
do so. We develop a conceptual framework and set of experimental tools to
understand the effects of these choices, which we leverage to propose best
practices for maximizing posterior approximation accuracy. Our approach is
based on studying the pre-asymptotic tail behavior of the density ratios
between the joint distribution and the variational approximation, then
exploiting insights and tools from the importance sampling literature. Our
framework and supporting experiments help to distinguish between the behavior
of BBVI methods for approximating low-dimensional versus
moderate-to-high-dimensional posteriors. In the latter case, we show that
mass-covering variational objectives are difficult to optimize and do not
improve accuracy, but flexible variational families can improve accuracy and
the effectiveness of importance sampling -- at the cost of additional
optimization challenges. Therefore, for moderate-to-high-dimensional posteriors
we recommend using the (mode-seeking) exclusive KL divergence since it is the
easiest to optimize, and improving the variational family or using model
parameter transformations to make the posterior and optimal variational
approximation more similar. On the other hand, in low-dimensional settings, we
show that heavy-tailed variational families and mass-covering divergences are
effective and can increase the chances that the approximation can be improved
by importance sampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">1-bit Adam: Communication Efficient Large-Scale Training with Adam&#x27;s Convergence Speed. (arXiv:2102.02888v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hanlin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_S/0/1/0/all/0/1">Shaoduo Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1">Ammar Ahmad Awan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1">Samyam Rajbhandari</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Conglong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1">Xiangru Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuxiong He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02888">
                                    <div class="article-summary-box-inner">
                                        <span>Scalable training of large models (like BERT and GPT-3) requires careful
optimization rooted in model design, architecture, and system capabilities.
From a system standpoint, communication has become a major bottleneck,
especially on commodity systems with standard TCP interconnects that offer
limited network bandwidth. Communication compression is an important technique
to reduce training time on such systems. One of the most effective methods is
error-compensated compression, which offers robust convergence speed even under
1-bit compression. However, state-of-the-art error compensation techniques only
work with basic optimizers like SGD and momentum SGD, which are linearly
dependent on the gradients. They do not work with non-linear gradient-based
optimizers like Adam, which offer state-of-the-art convergence efficiency and
accuracy for models like BERT. In this paper, we propose 1-bit Adam that
reduces the communication volume by up to $5\times$, offers much better
scalability, and provides the same convergence speed as uncompressed Adam. Our
key finding is that Adam&#x27;s variance (non-linear term) becomes stable (after a
warmup phase) and can be used as a fixed precondition for the rest of the
training (compression phase). Experiments on up to 256 GPUs show that 1-bit
Adam enables up to $3.3\times$ higher throughput for BERT-Large pre-training
and up to $2.9\times$ higher throughput for SQuAD fine-tuning. In addition, we
provide theoretical analysis for our proposed work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long Short-term Cognitive Networks. (arXiv:2106.16233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Napoles_G/0/1/0/all/0/1">Gonzalo N&#xe1;poles</a>, <a href="http://arxiv.org/find/cs/1/au:+Grau_I/0/1/0/all/0/1">Isel Grau</a>, <a href="http://arxiv.org/find/cs/1/au:+Jastrzebska_A/0/1/0/all/0/1">Agnieszka Jastrzebska</a>, <a href="http://arxiv.org/find/cs/1/au:+Salgueiro_Y/0/1/0/all/0/1">Yamisleydi Salgueiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16233">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a recurrent neural system named Long Short-term
Cognitive Networks (LSTCNs) as a generalisation of the Short-term Cognitive
Network (STCN) model. Such a generalisation is motivated by the difficulty of
forecasting very long time series in an efficient, greener fashion. The LSTCN
model can be defined as a collection of STCN blocks, each processing a specific
time patch of the (multivariate) time series being modelled. In this neural
ensemble, each block passes information to the subsequent one in the form of a
weight matrix referred to as the prior knowledge matrix. As a second
contribution, we propose a deterministic learning algorithm to compute the
learnable weights while preserving the prior knowledge resulting from previous
learning processes. As a third contribution, we introduce a feature influence
score as a proxy to explain the forecasting process in multivariate time
series. The simulations using three case studies show that our neural system
reports small forecasting errors while being up to thousands of times faster
than state-of-the-art recurrent models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for MU-MIMO Receive Processing in OFDM Systems. (arXiv:2012.08177v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goutay_M/0/1/0/all/0/1">Mathieu Goutay</a>, <a href="http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1">Fay&#xe7;al Ait Aoudia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1">Jakob Hoydis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorce_J/0/1/0/all/0/1">Jean-Marie Gorce</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08177">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) starts to be widely used to enhance the performance of
multi-user multiple-input multiple-output (MU-MIMO) receivers. However, it is
still unclear if such methods are truly competitive with respect to
conventional methods in realistic scenarios and under practical constraints. In
addition to enabling accurate signal reconstruction on realistic channel
models, MU-MIMO receive algorithms must allow for easy adaptation to a varying
number of users without the need for retraining. In contrast to existing work,
we propose an ML-enhanced MU-MIMO receiver that builds on top of a conventional
linear minimum mean squared error (LMMSE) architecture. It preserves the
interpretability and scalability of the LMMSE receiver, while improving its
accuracy in two ways. First, convolutional neural networks (CNNs) are used to
compute an approximation of the second-order statistics of the channel
estimation error which are required for accurate equalization. Second, a
CNN-based demapper jointly processes a large number of orthogonal
frequency-division multiplexing (OFDM) symbols and subcarriers, which allows it
to compute better log likelihood ratios (LLRs) by compensating for channel
aging. The resulting architecture can be used in the up- and downlink and is
trained in an end-to-end manner, removing the need for hard-to-get perfect
channel state information (CSI) during the training phase. Simulation results
demonstrate consistent performance improvements over the baseline which are
especially pronounced in high mobility scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational VAE: A Continuous Latent Variable Model for Graph Structured Data. (arXiv:2106.16049v1 [cs.CE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mylonas_C/0/1/0/all/0/1">Charilaos Mylonas</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdallah_I/0/1/0/all/0/1">Imad Abdallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzi_E/0/1/0/all/0/1">Eleni Chatzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16049">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Networks (GNs) enable the fusion of prior knowledge and relational
reasoning with flexible function approximations. In this work, a general
GN-based model is proposed which takes full advantage of the relational
modeling capabilities of GNs and extends these to probabilistic modeling with
Variational Bayes (VB). To that end, we combine complementary pre-existing
approaches on VB for graph data and propose an approach that relies on
graph-structured latent and conditioning variables. It is demonstrated that
Neural Processes can also be viewed through the lens of the proposed model. We
show applications on the problem of structured probability density modeling for
simulated and real wind farm monitoring data, as well as on the meta-learning
of simulated Gaussian Process data. We release the source code, along with the
simulated datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Koopman Spectrum Nonlinear Regulator and Provably Efficient Online Learning. (arXiv:2106.15775v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ohnishi_M/0/1/0/all/0/1">Motoya Ohnishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1">Isao Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lowrey_K/0/1/0/all/0/1">Kendall Lowrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1">Masahiro Ikeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_Y/0/1/0/all/0/1">Yoshinobu Kawahara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15775">
                                    <div class="article-summary-box-inner">
                                        <span>Most modern reinforcement learning algorithms optimize a cumulative
single-step cost along a trajectory. The optimized motions are often
&#x27;unnatural&#x27;, representing, for example, behaviors with sudden accelerations
that waste energy and lack predictability. In this work, we present a novel
paradigm of controlling nonlinear systems via the minimization of the Koopman
spectrum cost: a cost over the Koopman operator of the controlled dynamics.
This induces a broader class of dynamical behaviors that evolve over stable
manifolds such as nonlinear oscillators, closed loops, and smooth movements. We
demonstrate that some dynamics realizations that are not possible with a
cumulative cost are feasible in this paradigm. Moreover, we present a provably
efficient online learning algorithm for our problem that enjoys a sub-linear
regret bound under some structural assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ppAURORA: Privacy Preserving Area Under Receiver Operating Characteristic and Precision-Recall Curves with Secure 3-Party Computation. (arXiv:2102.08788v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Unal_A/0/1/0/all/0/1">Ali Burak &#xdc;nal</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfeifer_N/0/1/0/all/0/1">Nico Pfeifer</a>, <a href="http://arxiv.org/find/cs/1/au:+Akgun_M/0/1/0/all/0/1">Mete Akg&#xfc;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08788">
                                    <div class="article-summary-box-inner">
                                        <span>Computing an AUC as a performance measure to compare the quality of different
machine learning models is one of the final steps of many research projects.
Many of these methods are trained on privacy-sensitive data and there are
several different approaches like $\epsilon$-differential privacy, federated
machine learning and methods based on cryptographic approaches if the datasets
cannot be shared or evaluated jointly at one place. In this setting, it can
also be a problem to compute the global performance measure like an AUC, since
the labels might also contain privacy-sensitive information. There have been
approaches based on $\epsilon$-differential privacy to deal with this problem,
but to the best of our knowledge, no exact privacy preserving solution has been
introduced. In this paper, we propose an MPC-based framework, called \fw{},
with private merging of sorted lists and novel methods for comparing two
secret-shared values, selecting between two secret-shared values, converting
the modulus, and performing division to compute the exact AUC as one could
obtain on the pooled original test samples. With \fw{} computation of the exact
area under precision-recall curve and receiver operating characteristic curve
is even possible when ties between prediction confidence values exist. To show
the applicability of \fw{}, we use it to evaluate a model trained to predict
acute myeloid leukemia therapy response and we also assess its scalability via
experiments on synthetic data. The experiments show that we efficiently compute
exactly the same AUC with both evaluation metrics in a privacy preserving
manner as one can obtain on the pooled test samples in the plaintext domain.
Our solution provides security against semi-honest corruption of at most one of
the servers performing the secure computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Particle Filtering via Entropy-Regularized Optimal Transport. (arXiv:2102.07850v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Corenflos_A/0/1/0/all/0/1">Adrien Corenflos</a>, <a href="http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1">James Thornton</a>, <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07850">
                                    <div class="article-summary-box-inner">
                                        <span>Particle Filtering (PF) methods are an established class of procedures for
performing inference in non-linear state-space models. Resampling is a key
ingredient of PF, necessary to obtain low variance likelihood and states
estimates. However, traditional resampling methods result in PF-based loss
functions being non-differentiable with respect to model and PF parameters. In
a variational inference context, resampling also yields high variance gradient
estimates of the PF-based evidence lower bound. By leveraging optimal transport
ideas, we introduce a principled differentiable particle filter and provide
convergence results. We demonstrate this novel method on a variety of
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Reinforcement Learning Approach to the Orienteering Problem with Time Windows. (arXiv:2011.03647v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_R/0/1/0/all/0/1">Ricardo Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_H/0/1/0/all/0/1">Hugo L. Fernandes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03647">
                                    <div class="article-summary-box-inner">
                                        <span>The Orienteering Problem with Time Windows (OPTW) is a combinatorial
optimization problem where the goal is to maximize the total score collected
from different visited locations. The application of neural network models to
combinatorial optimization has recently shown promising results in dealing with
similar problems, like the Travelling Salesman Problem. A neural network allows
learning solutions using reinforcement learning or supervised learning,
depending on the available data. After the learning stage, it can be
generalized and quickly fine-tuned to further improve performance and
personalization. The advantages are evident since, for real-world applications,
solution quality, personalization, and execution times are all important
factors that should be taken into account.

This study explores the use of Pointer Network models trained using
reinforcement learning to solve the OPTW problem. We propose a modified
architecture that leverages Pointer Networks to better address problems related
with dynamic time-dependent constraints. Among its various applications, the
OPTW can be used to model the Tourist Trip Design Problem (TTDP). We train the
Pointer Network with the TTDP problem in mind, by sampling variables that can
change across tourists visiting a particular instance-region: starting
position, starting time, available time, and the scores given to each point of
interest. Once a model-region is trained, it can infer a solution for a
particular tourist using beam search. We based the assessment of our approach
on several existing benchmark OPTW instances. We show that it generalizes
across different tourists that visit each region and that it generally
outperforms the most commonly used heuristic, while computing the solution in
realistic times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Savings in Agnostic Active Learning through Abstention. (arXiv:2102.00451v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchkin_N/0/1/0/all/0/1">Nikita Puchkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhivotovskiy_N/0/1/0/all/0/1">Nikita Zhivotovskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00451">
                                    <div class="article-summary-box-inner">
                                        <span>We show that in pool-based active classification without assumptions on the
underlying distribution, if the learner is given the power to abstain from some
predictions by paying the price marginally smaller than the average loss $1/2$
of a random guess, exponential savings in the number of label requests are
possible whenever they are possible in the corresponding realizable problem. We
extend this result to provide a necessary and sufficient condition for
exponential savings in pool-based active classification under the model
misspecification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fixed points of monotonic and (weakly) scalable neural networks. (arXiv:2106.16239v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Piotrowski_T/0/1/0/all/0/1">Tomasz Piotrowski</a>, <a href="http://arxiv.org/find/stat/1/au:+Cavalcante_R/0/1/0/all/0/1">Renato L. G. Cavalcante</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16239">
                                    <div class="article-summary-box-inner">
                                        <span>We derive conditions for the existence of fixed points of neural networks, an
important research objective to understand their behavior in modern
applications involving autoencoders and loop unrolling techniques, among
others. In particular, we focus on networks with nonnegative inputs and
nonnegative network parameters, as often considered in the literature. We show
that such networks can be recognized as monotonic and (weakly) scalable
functions within the framework of nonlinear Perron-Frobenius theory. This fact
enables us to derive conditions for the existence of a nonempty fixed point set
of the neural networks, and these conditions are weaker than those obtained
recently using arguments in convex analysis, which are typically based on the
assumption of nonexpansivity of the activation functions. Furthermore, we prove
that the shape of the fixed point set of monotonic and weakly scalable neural
networks is often an interval, which degenerates to a point for the case of
scalable networks. The chief results of this paper are verified in numerical
simulations, where we consider an autoencoder-type network that first
compresses angular power spectra in massive MIMO systems, and, second,
reconstruct the input spectra from the compressed signal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Context Modeling Techniques on the Spatiotemporal Crowd Flow Prediction. (arXiv:2106.16046v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liyue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Leye Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16046">
                                    <div class="article-summary-box-inner">
                                        <span>In the big data and AI era, context is widely exploited as extra information
which makes it easier to learn a more complex pattern in machine learning
systems. However, most of the existing related studies seldom take context into
account. The difficulty lies in the unknown generalization ability of both
context and its modeling techniques across different scenarios. To fill the
above gaps, we conduct a large-scale analytical and empirical study on the
spatiotemporal crowd prediction (STCFP) problem that is a widely-studied and
hot research topic. We mainly make three efforts:(i) we develop new taxonomy
about both context features and context modeling techniques based on extensive
investigations in prevailing STCFP research; (ii) we conduct extensive
experiments on seven datasets with hundreds of millions of records to
quantitatively evaluate the generalization ability of both distinct context
features and context modeling techniques; (iii) we summarize some guidelines
for researchers to conveniently utilize context in diverse applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Refinement for Importance Sampling Using the Forward Kullback-Leibler Divergence. (arXiv:2106.15980v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Jerfel_G/0/1/0/all/0/1">Ghassen Jerfel</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Serena Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Fannjiang_C/0/1/0/all/0/1">Clara Fannjiang</a>, <a href="http://arxiv.org/find/stat/1/au:+Heller_K/0/1/0/all/0/1">Katherine A. Heller</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1">Yian Ma</a>, <a href="http://arxiv.org/find/stat/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15980">
                                    <div class="article-summary-box-inner">
                                        <span>Variational Inference (VI) is a popular alternative to asymptotically exact
sampling in Bayesian inference. Its main workhorse is optimization over a
reverse Kullback-Leibler divergence (RKL), which typically underestimates the
tail of the posterior leading to miscalibration and potential degeneracy.
Importance sampling (IS), on the other hand, is often used to fine-tune and
de-bias the estimates of approximate Bayesian inference procedures. The quality
of IS crucially depends on the choice of the proposal distribution. Ideally,
the proposal distribution has heavier tails than the target, which is rarely
achievable by minimizing the RKL. We thus propose a novel combination of
optimization and sampling techniques for approximate Bayesian inference by
constructing an IS proposal distribution through the minimization of a forward
KL (FKL) divergence. This approach guarantees asymptotic consistency and a fast
convergence towards both the optimal IS estimator and the optimal variational
approximation. We empirically demonstrate on real data that our method is
competitive with variational boosting and MCMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Assays for the Latent Space of Autoencoders. (arXiv:2106.16091v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1">Felix Leeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16091">
                                    <div class="article-summary-box-inner">
                                        <span>The encoders and decoders of autoencoders effectively project the input onto
learned manifolds in the latent space and data space respectively. We propose a
framework, called latent responses, for probing the learned data manifold using
interventions in the latent space. Using this framework, we investigate &quot;holes&quot;
in the representation to quantitatively ascertain to what extent the latent
space of a trained VAE is consistent with the chosen prior. Furthermore, we use
the identified structure to improve interpolation between latent vectors. We
evaluate how our analyses improve the quality of the generated samples using
the VAE on a variety of benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Hidden Structure in Self-Supervised Learning. (arXiv:2106.16060v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sansone_E/0/1/0/all/0/1">Emanuele Sansone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16060">
                                    <div class="article-summary-box-inner">
                                        <span>This work considers the problem of learning structured representations from
raw images using self-supervised learning. We propose a principled framework
based on a mutual information objective, which integrates self-supervised and
structure learning. Furthermore, we devise a post-hoc procedure to interpret
the meaning of the learnt representations. Preliminary experiments on CIFAR-10
show that the proposed framework achieves higher generalization performance in
downstream classification tasks and provides more interpretable representations
compared to the ones learnt through traditional self-supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotically Optimal Information-Directed Sampling. (arXiv:2011.05944v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kirschner_J/0/1/0/all/0/1">Johannes Kirschner</a>, <a href="http://arxiv.org/find/stat/1/au:+Lattimore_T/0/1/0/all/0/1">Tor Lattimore</a>, <a href="http://arxiv.org/find/stat/1/au:+Vernade_C/0/1/0/all/0/1">Claire Vernade</a>, <a href="http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05944">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a simple and efficient algorithm for stochastic linear bandits
with finitely many actions that is asymptotically optimal and (nearly)
worst-case optimal in finite time. The approach is based on the frequentist
information-directed sampling (IDS) framework, with a surrogate for the
information gain that is informed by the optimization problem that defines the
asymptotic lower bound. Our analysis sheds light on how IDS balances the
trade-off between regret and information and uncovers a surprising connection
between the recently proposed primal-dual methods and the IDS algorithm. We
demonstrate empirically that IDS is competitive with UCB in finite-time, and
can be significantly better in the asymptotic regime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reservoir Based Edge Training on RF Data To Deliver Intelligent and Efficient IoT Spectrum Sensors. (arXiv:2106.16087v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kokalj_Filipovic_S/0/1/0/all/0/1">Silvija Kokalj-Filipovic</a>, <a href="http://arxiv.org/find/eess/1/au:+Toliver_P/0/1/0/all/0/1">Paul Toliver</a>, <a href="http://arxiv.org/find/eess/1/au:+Johnson_W/0/1/0/all/0/1">William Johnson</a>, <a href="http://arxiv.org/find/eess/1/au:+Miller_R/0/1/0/all/0/1">Rob Miller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16087">
                                    <div class="article-summary-box-inner">
                                        <span>Current radio frequency (RF) sensors at the Edge lack the computational
resources to support practical, in-situ training for intelligent spectrum
monitoring, and sensor data classification in general. We propose a solution
via Deep Delay Loop Reservoir Computing (DLR), a processing architecture that
supports general machine learning algorithms on compact mobile devices by
leveraging delay-loop reservoir computing in combination with innovative
electrooptical hardware. With both digital and photonic realizations of our
design of the loops, DLR delivers reductions in form factor, hardware
complexity and latency, compared to the State-of-the-Art (SoA). The main impact
of the reservoir is to project the input data into a higher dimensional space
of reservoir state vectors in order to linearly separate the input classes.
Once the classes are well separated, traditionally complex, power-hungry
classification models are no longer needed for the learning process. Yet, even
with simple classifiers based on Ridge regression (RR), the complexity grows at
least quadratically with the input size. Hence, the hardware reduction required
for training on compact devices is in contradiction with the large dimension of
state vectors. DLR employs a RR-based classifier to exceed the SoA accuracy,
while further reducing power consumption by leveraging the architecture of
parallel (split) loops. We present DLR architectures composed of multiple
smaller loops whose state vectors are linearly combined to create a lower
dimensional input into Ridge regression. We demonstrate the advantages of using
DLR for two distinct applications: RF Specific Emitter Identification (SEI) for
IoT authentication, and wireless protocol recognition for IoT situational
awareness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Factual Consistency of Abstractive Summarization on Customer Feedback. (arXiv:2106.16188v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yifei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1">Vincent Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16188">
                                    <div class="article-summary-box-inner">
                                        <span>E-commerce stores collect customer feedback to let sellers learn about
customer concerns and enhance customer order experience. Because customer
feedback often contains redundant information, a concise summary of the
feedback can be generated to help sellers better understand the issues causing
customer dissatisfaction. Previous state-of-the-art abstractive text
summarization models make two major types of factual errors when producing
summaries from customer feedback, which are wrong entity detection (WED) and
incorrect product-defect description (IPD). In this work, we introduce a set of
methods to enhance the factual consistency of abstractive summarization on
customer feedback. We augment the training data with artificially corrupted
summaries, and use them as counterparts of the target summaries. We add a
contrastive loss term into the training objective so that the model learns to
avoid certain factual errors. Evaluation results show that a large portion of
WED and IPD errors are alleviated for BART and T5. Furthermore, our approaches
do not depend on the structure of the summarization model and thus are
generalizable to any abstractive summarization systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COKE: Communication-Censored Decentralized Kernel Learning. (arXiv:2001.10133v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Ping Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.10133">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the decentralized optimization and learning problem where
multiple interconnected agents aim to learn an optimal decision function
defined over a reproducing kernel Hilbert space by jointly minimizing a global
objective function, with access to their own locally observed dataset. As a
non-parametric approach, kernel learning faces a major challenge in distributed
implementation: the decision variables of local objective functions are
data-dependent and thus cannot be optimized under the decentralized consensus
framework without any raw data exchange among agents. To circumvent this major
challenge, we leverage the random feature (RF) approximation approach to enable
consensus on the function modeled in the RF space by data-independent
parameters across different agents. We then design an iterative algorithm,
termed DKLA, for fast-convergent implementation via ADMM. Based on DKLA, we
further develop a communication-censored kernel learning (COKE) algorithm that
reduces the communication load of DKLA by preventing an agent from transmitting
at every iteration unless its local updates are deemed informative. Theoretical
results in terms of linear convergence guarantee and generalization performance
analysis of DKLA and COKE are provided. Comprehensive tests on both synthetic
and real datasets are conducted to verify the communication efficiency and
learning effectiveness of COKE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HybridDeepRx: Deep Learning Receiver for High-EVM Signals. (arXiv:2106.16079v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pihlajasalo_J/0/1/0/all/0/1">Jaakko Pihlajasalo</a>, <a href="http://arxiv.org/find/eess/1/au:+Korpi_D/0/1/0/all/0/1">Dani Korpi</a>, <a href="http://arxiv.org/find/eess/1/au:+Honkala_M/0/1/0/all/0/1">Mikko Honkala</a>, <a href="http://arxiv.org/find/eess/1/au:+Huttunen_J/0/1/0/all/0/1">Janne M.J. Huttunen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riihonen_T/0/1/0/all/0/1">Taneli Riihonen</a>, <a href="http://arxiv.org/find/eess/1/au:+Talvitie_J/0/1/0/all/0/1">Jukka Talvitie</a>, <a href="http://arxiv.org/find/eess/1/au:+Brihuega_A/0/1/0/all/0/1">Alberto Brihuega</a>, <a href="http://arxiv.org/find/eess/1/au:+Uusitalo_M/0/1/0/all/0/1">Mikko A. Uusitalo</a>, <a href="http://arxiv.org/find/eess/1/au:+Valkama_M/0/1/0/all/0/1">Mikko Valkama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16079">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a machine learning (ML) based physical layer
receiver solution for demodulating OFDM signals that are subject to a high
level of nonlinear distortion. Specifically, a novel deep learning based
convolutional neural network receiver is devised, containing layers in both
time- and frequency domains, allowing to demodulate and decode the transmitted
bits reliably despite the high error vector magnitude (EVM) in the transmit
signal. Extensive set of numerical results is provided, in the context of 5G NR
uplink incorporating also measured terminal power amplifier characteristics.
The obtained results show that the proposed receiver system is able to clearly
outperform classical linear receivers as well as existing ML receiver
approaches, especially when the EVM is high in comparison with modulation
order. The proposed ML receiver can thus facilitate pushing the terminal power
amplifier (PA) systems deeper into saturation, and thereon improve the terminal
power-efficiency, radiated power and network coverage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analytic Insights into Structure and Rank of Neural Network Hessian Maps. (arXiv:2106.16225v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sidak Pal Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1">Gregor Bachmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1">Thomas Hofmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16225">
                                    <div class="article-summary-box-inner">
                                        <span>The Hessian of a neural network captures parameter interactions through
second-order derivatives of the loss. It is a fundamental object of study,
closely tied to various problems in deep learning, including model design,
optimization, and generalization. Most prior work has been empirical, typically
focusing on low-rank approximations and heuristics that are blind to the
network structure. In contrast, we develop theoretical tools to analyze the
range of the Hessian map, providing us with a precise understanding of its rank
deficiency as well as the structural reasons behind it. This yields exact
formulas and tight upper bounds for the Hessian rank of deep linear networks,
allowing for an elegant interpretation in terms of rank deficiency. Moreover,
we demonstrate that our bounds remain faithful as an estimate of the numerical
Hessian rank, for a larger class of models such as rectified and hyperbolic
tangent networks. Further, we also investigate the implications of model
architecture (e.g.~width, depth, bias) on the rank deficiency. Overall, our
work provides novel insights into the source and extent of redundancy in
overparameterized networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified View of Stochastic Hamiltonian Sampling. (arXiv:2106.16200v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Franzese_G/0/1/0/all/0/1">Giulio Franzese</a>, <a href="http://arxiv.org/find/cs/1/au:+Milios_D/0/1/0/all/0/1">Dimitrios Milios</a>, <a href="http://arxiv.org/find/cs/1/au:+Filippone_M/0/1/0/all/0/1">Maurizio Filippone</a>, <a href="http://arxiv.org/find/cs/1/au:+Michiardi_P/0/1/0/all/0/1">Pietro Michiardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16200">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we revisit the theoretical properties of Hamiltonian stochastic
differential equations (SDEs) for Bayesian posterior sampling, and we study the
two types of errors that arise from numerical SDE simulation: the
discretization error and the error due to noisy gradient estimates in the
context of data subsampling. We consider overlooked results describing the
ergodic convergence rates of numerical integration schemes, and we produce a
novel analysis for the effect of mini-batches through the lens of differential
operator splitting. In our analysis, the stochastic component of the proposed
Hamiltonian SDE is decoupled from the gradient noise, for which we make no
normality assumptions. This allows us to derive interesting connections among
different sampling schemes, including the original Hamiltonian Monte Carlo
(HMC) algorithm, and explain their performance. We show that for a careful
selection of numerical integrators, both errors vanish at a rate
$\mathcal{O}(\eta^2)$, where $\eta$ is the integrator step size. Our
theoretical results are supported by an empirical study on a variety of
regression and classification tasks for Bayesian neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL. (arXiv:2106.15883v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Vu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1">Shaan Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15883">
                                    <div class="article-summary-box-inner">
                                        <span>Despite a series of recent successes in reinforcement learning (RL), many RL
algorithms remain sensitive to hyperparameters. As such, there has recently
been interest in the field of AutoRL, which seeks to automate design decisions
to create more general algorithms. Recent work suggests that population based
approaches may be effective AutoRL algorithms, by learning hyperparameter
schedules on the fly. In particular, the PB2 algorithm is able to achieve
strong performance in RL tasks by formulating online hyperparameter
optimization as time varying GP-bandit problem, while also providing
theoretical guarantees. However, PB2 is only designed to work for continuous
hyperparameters, which severely limits its utility in practice. In this paper
we introduce a new (provably) efficient hierarchical approach for optimizing
both continuous and categorical variables, using a new time-varying bandit
algorithm specifically designed for the population based training regime. We
evaluate our approach on the challenging Procgen benchmark, where we show that
explicitly modelling dependence between data augmentation and other
hyperparameters improves generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Efficiency of Transformers for Resource-Constrained Devices. (arXiv:2106.16006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tabani_H/0/1/0/all/0/1">Hamid Tabani</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramaniam_A/0/1/0/all/0/1">Ajay Balasubramaniam</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1">Shabbir Marzban</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16006">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers provide promising accuracy and have become popular and used in
various domains such as natural language processing and computer vision.
However, due to their massive number of model parameters, memory and
computation requirements, they are not suitable for resource-constrained
low-power devices. Even with high-performance and specialized devices, the
memory bandwidth can become a performance-limiting bottleneck. In this paper,
we present a performance analysis of state-of-the-art vision transformers on
several devices. We propose to reduce the overall memory footprint and memory
transfers by clustering the model parameters. We show that by using only 64
clusters to represent model parameters, it is possible to reduce the data
transfer from the main memory by more than 4x, achieve up to 22% speedup and
39% energy savings on mobile devices with less than 0.1% accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Space Model for Higher-order Networks and Generalized Tensor Decomposition. (arXiv:2106.16042v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zhongyuan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_D/0/1/0/all/0/1">Dong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16042">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a unified framework, formulated as general latent space models,
to study complex higher-order network interactions among multiple entities. Our
framework covers several popular models in recent network analysis literature,
including mixture multi-layer latent space model and hypergraph latent space
model. We formulate the relationship between the latent positions and the
observed data via a generalized multilinear kernel as the link function. While
our model enjoys decent generality, its maximum likelihood parameter estimation
is also convenient via a generalized tensor decomposition procedure.We propose
a novel algorithm using projected gradient descent on Grassmannians. We also
develop original theoretical guarantees for our algorithm. First, we show its
linear convergence under mild conditions. Second, we establish finite-sample
statistical error rates of latent position estimation, determined by the signal
strength, degrees of freedom and the smoothness of link function, for both
general and specific latent space models. We demonstrate the effectiveness of
our method on synthetic data. We also showcase the merit of our method on two
real-world datasets that are conventionally described by different specific
models in producing meaningful and interpretable parameter estimations and
accurate link prediction. We demonstrate the effectiveness of our method on
synthetic data. We also showcase the merit of our method on two real-world
datasets that are conventionally described by different specific models in
producing meaningful and interpretable parameter estimations and accurate link
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Minimize Age of Information over an Unreliable Channel with Energy Harvesting. (arXiv:2106.16037v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ceran_E/0/1/0/all/0/1">Elif Tugce Ceran</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz Gunduz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1">Andras Gyorgy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16037">
                                    <div class="article-summary-box-inner">
                                        <span>The time average expected age of information (AoI) is studied for status
updates sent over an error-prone channel from an energy-harvesting transmitter
with a finite-capacity battery. Energy cost of sensing new status updates is
taken into account as well as the transmission energy cost better capturing
practical systems. The optimal scheduling policy is first studied under the
hybrid automatic repeat request (HARQ) protocol when the channel and energy
harvesting statistics are known, and the existence of a threshold-based optimal
policy is shown. For the case of unknown environments, average-cost
reinforcement-learning algorithms are proposed that learn the system parameters
and the status update policy in real-time. The effectiveness of the proposed
methods is demonstrated through numerical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resilient UAV Swarm Communications with Graph Convolutional Neural Network. (arXiv:2106.16048v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mou_Z/0/1/0/all/0/1">Zhiyu Mou</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_F/0/1/0/all/0/1">Feifei Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Q/0/1/0/all/0/1">Qihui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16048">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the self-healing problem of unmanned aerial vehicle
(UAV) swarm network (USNET) that is required to quickly rebuild the
communication connectivity under unpredictable external disruptions (UEDs).
Firstly, to cope with the one-off UEDs, we propose a graph convolutional neural
network (GCN) and find the recovery topology of the USNET in an on-line manner.
Secondly, to cope with general UEDs, we develop a GCN based trajectory planning
algorithm that can make UAVs rebuild the communication connectivity during the
self-healing process. We also design a meta learning scheme to facilitate the
on-line executions of the GCN. Numerical results show that the proposed
algorithms can rebuild the communication connectivity of the USNET more quickly
than the existing algorithms under both one-off UEDs and general UEDs. The
simulation results also show that the meta learning scheme can not only enhance
the performance of the GCN but also reduce the time complexity of the on-line
executions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Likelihoods and Parameter Priors for Bayesian Networks. (arXiv:2105.06241v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heckerman_D/0/1/0/all/0/1">David Heckerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_D/0/1/0/all/0/1">Dan Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06241">
                                    <div class="article-summary-box-inner">
                                        <span>We develop simple methods for constructing likelihoods and parameter priors
for learning about the parameters and structure of a Bayesian network. In
particular, we introduce several assumptions that permit the construction of
likelihoods and parameter priors for a large number of Bayesian-network
structures from a small set of assessments. The most notable assumption is that
of likelihood equivalence, which says that data can not help to discriminate
network structures that encode the same assertions of conditional independence.
We describe the constructions that follow from these assumptions, and also
present a method for directly computing the marginal likelihood of a random
sample with no missing observations. Also, we show how these assumptions lead
to a general framework for characterizing parameter priors of multivariate
distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CIDER: Commonsense Inference for Dialogue Explanation and Reasoning. (arXiv:2106.00510v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosal_D/0/1/0/all/0/1">Deepanway Ghosal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1">Pengfei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Siqi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00510">
                                    <div class="article-summary-box-inner">
                                        <span>Commonsense inference to understand and explain human language is a
fundamental research problem in natural language processing. Explaining human
conversations poses a great challenge as it requires contextual understanding,
planning, inference, and several aspects of reasoning including causal,
temporal, and commonsense reasoning. In this work, we introduce CIDER -- a
manually curated dataset that contains dyadic dialogue explanations in the form
of implicit and explicit knowledge triplets inferred using contextual
commonsense inference. Extracting such rich explanations from conversations can
be conducive to improving several downstream applications. The annotated
triplets are categorized by the type of commonsense knowledge present (e.g.,
causal, conditional, temporal). We set up three different tasks conditioned on
the annotated dataset: Dialogue-level Natural Language Inference, Span
Extraction, and Multi-choice Span Selection. Baseline results obtained with
transformer-based models reveal that the tasks are difficult, paving the way
for promising future research. The dataset and the baseline implementations are
publicly available at https://cider-task.github.io/cider/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monte Carlo Variational Auto-Encoders. (arXiv:2106.15921v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Thin_A/0/1/0/all/0/1">Achille Thin</a>, <a href="http://arxiv.org/find/stat/1/au:+Kotelevskii_N/0/1/0/all/0/1">Nikita Kotelevskii</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>, <a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1">Eric Moulines</a>, <a href="http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1">Maxim Panov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15921">
                                    <div class="article-summary-box-inner">
                                        <span>Variational auto-encoders (VAE) are popular deep latent variable models which
are trained by maximizing an Evidence Lower Bound (ELBO). To obtain tighter
ELBO and hence better variational approximations, it has been proposed to use
importance sampling to get a lower variance estimate of the evidence. However,
importance sampling is known to perform poorly in high dimensions. While it has
been suggested many times in the literature to use more sophisticated
algorithms such as Annealed Importance Sampling (AIS) and its Sequential
Importance Sampling (SIS) extensions, the potential benefits brought by these
advanced techniques have never been realized for VAE: the AIS estimate cannot
be easily differentiated, while SIS requires the specification of carefully
chosen backward Markov kernels. In this paper, we address both issues and
demonstrate the performance of the resulting Monte Carlo VAEs on a variety of
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grey-box models for wave loading prediction. (arXiv:2105.13813v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pitchforth_D/0/1/0/all/0/1">Daniel J Pitchforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_T/0/1/0/all/0/1">Timothy J Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Tygesen_U/0/1/0/all/0/1">Ulf T Tygesen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_E/0/1/0/all/0/1">Elizabeth J Cross</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13813">
                                    <div class="article-summary-box-inner">
                                        <span>The quantification of wave loading on offshore structures and components is a
crucial element in the assessment of their useful remaining life. In many
applications the well-known Morison&#x27;s equation is employed to estimate the
forcing from waves with assumed particle velocities and accelerations. This
paper develops a grey-box modelling approach to improve the predictions of the
force on structural members. A grey-box model intends to exploit the enhanced
predictive capabilities of data-based modelling whilst retaining physical
insight into the behaviour of the system; in the context of the work carried
out here, this can be considered as physics-informed machine learning. There
are a number of possible approaches to establish a grey-box model. This paper
demonstrates two means of combining physics (white box) and data-based (black
box) components; one where the model is a simple summation of the two
components, the second where the white-box prediction is fed into the black box
as an additional input. Here Morison&#x27;s equation is used as the physics-based
component in combination with a data-based Gaussian process NARX - a dynamic
variant of the more well-known Gaussian process regression. Two key challenges
with employing the GP-NARX formulation that are addressed here are the
selection of appropriate lag terms and the proper treatment of uncertainty
propagation within the dynamic GP. The best performing grey-box model, the
residual modelling GP-NARX, was able to achieve a 29.13\% and 5.48\% relative
reduction in NMSE over Morison&#x27;s Equation and a black-box GP-NARX respectively,
alongside significant benefits in extrapolative capabilities of the model, in
circumstances of low dataset coverage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1">Carles Domingo-Enrich</a>, <a href="http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05739">
                                    <div class="article-summary-box-inner">
                                        <span>Several works in implicit and explicit generative modeling empirically
observed that feature-learning discriminators outperform fixed-kernel
discriminators in terms of the sample quality of the models. We provide
separation results between probability metrics with fixed-kernel and
feature-learning discriminators using the function classes $\mathcal{F}_2$ and
$\mathcal{F}_1$ respectively, which were developed to study overparametrized
two-layer neural networks. In particular, we construct pairs of distributions
over hyper-spheres that can not be discriminated by fixed kernel
$(\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)
in high dimensions, but that can be discriminated by their feature learning
($\mathcal{F}_1$) counterparts. To further study the separation we provide
links between the $\mathcal{F}_1$ and $\mathcal{F}_2$ IPMs with sliced
Wasserstein distances. Our work suggests that fixed-kernel discriminators
perform worse than their feature learning counterparts because their
corresponding metrics are weaker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Broadcasted Residual Learning for Efficient Keyword Spotting. (arXiv:2106.04140v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Byeonggeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Simyung Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinkyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_D/0/1/0/all/0/1">Dooyong Sung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04140">
                                    <div class="article-summary-box-inner">
                                        <span>Keyword spotting is an important research field because it plays a key role
in device wake-up and user interaction on smart devices. However, it is
challenging to minimize errors while operating efficiently in devices with
limited resources such as mobile phones. We present a broadcasted residual
learning method to achieve high accuracy with small model size and
computational load. Our method configures most of the residual functions as 1D
temporal convolution while still allows 2D convolution together using a
broadcasted-residual connection that expands temporal output to
frequency-temporal dimension. This residual mapping enables the network to
effectively represent useful audio features with much less computation than
conventional convolutional neural networks. We also propose a novel network
architecture, Broadcasting-residual network (BC-ResNet), based on broadcasted
residual learning and describe how to scale up the model according to the
target device&#x27;s resources. BC-ResNets achieve state-of-the-art 98.0% and 98.7%
top-1 accuracy on Google speech command datasets v1 and v2, respectively, and
consistently outperform previous approaches, using fewer computations and
parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimNet: Enabling Robust Unknown Object Manipulation from Pure Synthetic Data via Stereo. (arXiv:2106.16118v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kollar_T/0/1/0/all/0/1">Thomas Kollar</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskey_M/0/1/0/all/0/1">Michael Laskey</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_K/0/1/0/all/0/1">Kevin Stone</a>, <a href="http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1">Brijen Thananjeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tjersland_M/0/1/0/all/0/1">Mark Tjersland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16118">
                                    <div class="article-summary-box-inner">
                                        <span>Robot manipulation of unknown objects in unstructured environments is a
challenging problem due to the variety of shapes, materials, arrangements and
lighting conditions. Even with large-scale real-world data collection, robust
perception and manipulation of transparent and reflective objects across
various lighting conditions remain challenging. To address these challenges we
propose an approach to performing sim-to-real transfer of robotic perception.
The underlying model, SimNet, is trained as a single multi-headed neural
network using simulated stereo data as input and simulated object segmentation
masks, 3D oriented bounding boxes (OBBs), object keypoints, and disparity as
output. A key component of SimNet is the incorporation of a learned stereo
sub-network that predicts disparity. SimNet is evaluated on 2D car detection,
unknown object detection, and deformable object keypoint detection and
significantly outperforms a baseline that uses a structured light RGB-D sensor.
By inferring grasp positions using the OBB and keypoint predictions, SimNet can
be used to perform end-to-end manipulation of unknown objects in both easy and
hard scenarios using our fleet of Toyota HSR robots in four home environments.
In unknown object grasping experiments, the predictions from the baseline RGB-D
network and SimNet enable successful grasps of most of the easy objects.
However, the RGB-D baseline only grasps 35% of the hard (e.g., transparent)
objects, while SimNet grasps 95%, suggesting that SimNet can enable robust
manipulation of unknown objects, including transparent objects, in unknown
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Application of deep reinforcement learning for Indian stock trading automation. (arXiv:2106.16088v1 [q-fin.TR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Bajpai_S/0/1/0/all/0/1">Supriya Bajpai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16088">
                                    <div class="article-summary-box-inner">
                                        <span>In stock trading, feature extraction and trading strategy design are the two
important tasks to achieve long-term benefits using machine learning
techniques. Several methods have been proposed to design trading strategy by
acquiring trading signals to maximize the rewards. In the present paper the
theory of deep reinforcement learning is applied for stock trading strategy and
investment decisions to Indian markets. The experiments are performed
systematically with three classical Deep Reinforcement Learning models Deep
Q-Network, Double Deep Q-Network and Dueling Double Deep Q-Network on ten
Indian stock datasets. The performance of the models are evaluated and
comparison is made.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Protein-Ligand Docking Surrogate Models: A SARS-CoV-2 Benchmark for Deep Learning Accelerated Virtual Screening. (arXiv:2106.07036v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Clyde_A/0/1/0/all/0/1">Austin Clyde</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Brettin_T/0/1/0/all/0/1">Thomas Brettin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Partin_A/0/1/0/all/0/1">Alexander Partin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yoo_H/0/1/0/all/0/1">Hyunseung Yoo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Babuji_Y/0/1/0/all/0/1">Yadu Babuji</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Blaiszik_B/0/1/0/all/0/1">Ben Blaiszik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Merzky_A/0/1/0/all/0/1">Andre Merzky</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Turilli_M/0/1/0/all/0/1">Matteo Turilli</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jha_S/0/1/0/all/0/1">Shantenu Jha</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramanathan_A/0/1/0/all/0/1">Arvind Ramanathan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Stevens_R/0/1/0/all/0/1">Rick Stevens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07036">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a benchmark to study surrogate model accuracy for protein-ligand
docking. We share a dataset consisting of 200 million 3D complex structures and
2D structure scores across a consistent set of 13 million &quot;in-stock&quot; molecules
over 15 receptors, or binding sites, across the SARS-CoV-2 proteome. Our work
shows surrogate docking models have six orders of magnitude more throughput
than standard docking protocols on the same supercomputer node types. We
demonstrate the power of high-speed surrogate models by running each target
against 1 billion molecules in under a day (50k predictions per GPU seconds).
We showcase a workflow for docking utilizing surrogate ML models as a
pre-filter. Our workflow is ten times faster at screening a library of
compounds than the standard technique, with an error rate less than 0.01\% of
detecting the underlying best scoring 0.1\% of compounds. Our analysis of the
speedup explains that to screen more molecules under a docking paradigm,
another order of magnitude speedup must come from model accuracy rather than
computing speed (which, if increased, will not anymore alter our throughput to
screen molecules). We believe this is strong evidence for the community to
begin focusing on improving the accuracy of surrogate models to improve the
ability to screen massive compound libraries 100x or even 1000x faster than
current techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection. (arXiv:2104.03123v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Wanying Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Panariello_M/0/1/0/all/0/1">Michele Panariello</a>, <a href="http://arxiv.org/find/cs/1/au:+Patino_J/0/1/0/all/0/1">Jose Patino</a>, <a href="http://arxiv.org/find/cs/1/au:+Todisco_M/0/1/0/all/0/1">Massimiliano Todisco</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1">Nicholas Evans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03123">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reports the first successful application of a differentiable
architecture search (DARTS) approach to the deepfake and spoofing detection
problems. An example of neural architecture search, DARTS operates upon a
continuous, differentiable search space which enables both the architecture and
parameters to be optimised via gradient descent. Solutions based on
partially-connected DARTS use random channel masking in the search space to
reduce GPU time and automatically learn and optimise complex neural
architectures composed of convolutional operations and residual blocks. Despite
being learned quickly with little human effort, the resulting networks are
competitive with the best performing systems reported in the literature. Some
are also far less complex, containing 85% fewer parameters than a Res2Net
competitor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning on a Budget via Teacher Imitation. (arXiv:2104.08440v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilhan_E/0/1/0/all/0/1">Ercument Ilhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gow_J/0/1/0/all/0/1">Jeremy Gow</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1">Diego Perez-Liebana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08440">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Reinforcement Learning (RL) techniques can benefit greatly from
leveraging prior experience, which can be either self-generated or acquired
from other entities. Action advising is a framework that provides a flexible
way to transfer such knowledge in the form of actions between teacher-student
peers. However, due to the realistic concerns, the number of these interactions
is limited with a budget; therefore, it is crucial to perform these in the most
appropriate moments. There have been several promising studies recently that
address this problem setting especially from the student&#x27;s perspective. Despite
their success, they have some shortcomings when it comes to the practical
applicability and integrity as an overall solution to the learning from advice
challenge. In this paper, we extend the idea of advice reusing via teacher
imitation to construct a unified approach that addresses both advice collection
and advice utilisation problems. We also propose a method to automatically tune
the relevant hyperparameters of these components on-the-fly to make it able to
adapt to any task with minimal human intervention. The experiments we performed
in 5 different Atari games verify that our algorithm either surpasses or
performs on-par with its top competitors while being far simpler to be
employed. Furthermore, its individual components are also found to be providing
significant advantages alone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Human-Machine Teaming for Medical Prognosis Through Neural Ordinary Differential Equations (NODEs). (arXiv:2102.04121v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fompeyrine_D/0/1/0/all/0/1">D. Fompeyrine</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorm_E/0/1/0/all/0/1">E. S. Vorm</a>, <a href="http://arxiv.org/find/cs/1/au:+Ricka_N/0/1/0/all/0/1">N. Ricka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rose_F/0/1/0/all/0/1">F. Rose</a>, <a href="http://arxiv.org/find/cs/1/au:+Pellegrin_G/0/1/0/all/0/1">G. Pellegrin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04121">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning (ML) has recently been demonstrated to rival expert-level
human accuracy in prediction and detection tasks in a variety of domains,
including medicine. Despite these impressive findings, however, a key barrier
to the full realization of ML&#x27;s potential in medical prognoses is technology
acceptance. Recent efforts to produce explainable AI (XAI) have made progress
in improving the interpretability of some ML models, but these efforts suffer
from limitations intrinsic to their design: they work best at identifying why a
system fails, but do poorly at explaining when and why a model&#x27;s prediction is
correct. We posit that the acceptability of ML predictions in expert domains is
limited by two key factors: the machine&#x27;s horizon of prediction that extends
beyond human capability, and the inability for machine predictions to
incorporate human intuition into their models. We propose the use of a novel ML
architecture, Neural Ordinary Differential Equations (NODEs) to enhance human
understanding and encourage acceptability. Our approach prioritizes human
cognitive intuition at the center of the algorithm design, and offers a
distribution of predictions rather than single outputs. We explain how this
approach may significantly improve human-machine collaboration in prediction
tasks in expert domains such as medical prognoses. We propose a model and
demonstrate, by expanding a concrete example from the literature, how our model
advances the vision of future hybrid Human-AI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets. Our model eliminates the requirement
for class token and positional embeddings through a novel sequence pooling
strategy and the use of convolutions. We show that compared to CNNs, our
compact transformers have fewer parameters and MACs, while obtaining similar
accuracies. Our method is flexible in terms of model size, and can have as
little as 0.28M parameters and achieve reasonable results. It can reach an
accuracy of 95.29 % when training from scratch on CIFAR-10, which is comparable
with modern CNN based approaches, and a significant improvement over previous
Transformer based models. Our simple and compact design democratizes
transformers by making them accessible to those equipped with basic computing
resources and/or dealing with important small datasets. Our method works on
larger datasets, such as ImageNet (80.28% accuracy with 29% parameters of ViT),
and NLP tasks as well. Our code and pre-trained models are publicly available
at https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Transferability Estimation for Image Classification Tasks. (arXiv:2106.10479v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shao-Lun Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10479">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability estimation is an essential problem in transfer learning to
predict how good the performance is when transferring a source model (or source
task) to a target task. Recent analytical transferability metrics have been
widely used for source model selection and multi-task learning. A major
challenge is how to make transfereability estimation robust under the
cross-domain cross-task settings. The recently proposed OTCE score solves this
problem by considering both domain and task differences, with the help of
transfer experiences on auxiliary tasks, which causes an efficiency overhead.
In this work, we propose a practical transferability metric called JC-NCE score
that dramatically improves the robustness of the task difference estimation in
OTCE, thus removing the need for auxiliary tasks. Specifically, we build the
joint correspondences between source and target data via solving an optimal
transport problem with a ground cost considering both the sample distance and
label distance, and then compute the transferability score as the negative
conditional entropy of the matched labels. Extensive validations under the
intra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE
score outperforms the auxiliary-task free version of OTCE for 7% and 12%,
respectively, and is also more robust than other existing transferability
metrics on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Regular Conditional Distributions. (arXiv:2105.07743v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kratsios_A/0/1/0/all/0/1">Anastasis Kratsios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07743">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a general framework for approximating regular conditional
distributions (RCDs). Our approximations of these RCDs are implemented by a new
class of geometric deep learning models with inputs in $\mathbb{R}^d$ and
outputs in the Wasserstein-$1$ space $\mathcal{P}_1(\mathbb{R}^D)$. We find
that the models built using our framework can approximate any continuous
functions from $\mathbb{R}^d$ to $\mathcal{P}_1(\mathbb{R}^D)$ uniformly on
compacts, and quantitative rates are obtained. We identify two methods for
avoiding the &quot;curse of dimensionality&quot;; i.e.: the number of parameters
determining the approximating neural network depends only polynomially on the
involved dimension and the approximation error. The first solution describes
functions in $C(\mathbb{R}^d,\mathcal{P}_1(\mathbb{R}^D))$ which can be
efficiently approximated on any compact subset of $\mathbb{R}^d$. Conversely,
the second approach describes sets in $\mathbb{R}^d$, on which any function in
$C(\mathbb{R}^d,\mathcal{P}_1(\mathbb{R}^D))$ can be efficiently approximated.
Our framework is used to obtain an affirmative answer to the open conjecture of
Bishop (1994); namely: mixture density networks are universal regular
conditional distributions. The predictive performance of the proposed models is
evaluated against comparable learning models on various probabilistic
predictions tasks in the context of ELMs, model uncertainty, and
heteroscedastic regression. All the results are obtained for more general input
and output spaces and thus apply to geometric deep learning contexts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Joint Chance Constrained Optimization: Approximations and Statistical Consistency. (arXiv:2106.12199v2 [math.ST] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jaiswal_P/0/1/0/all/0/1">Prateek Jaiswal</a>, <a href="http://arxiv.org/find/math/1/au:+Honnappa_H/0/1/0/all/0/1">Harsha Honnappa</a>, <a href="http://arxiv.org/find/math/1/au:+Rao_V/0/1/0/all/0/1">Vinayak A. Rao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12199">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers data-driven chance-constrained stochastic optimization
problems in a Bayesian framework. Bayesian posteriors afford a principled
mechanism to incorporate data and prior knowledge into stochastic optimization
problems. However, the computation of Bayesian posteriors is typically an
intractable problem, and has spawned a large literature on approximate Bayesian
computation. Here, in the context of chance-constrained optimization, we focus
on the question of statistical consistency (in an appropriate sense) of the
optimal value, computed using an approximate posterior distribution. To this
end, we rigorously prove a frequentist consistency result demonstrating the
convergence of the optimal value to the optimal value of a fixed, parameterized
constrained optimization problem. We augment this by also establishing a
probabilistic rate of convergence of the optimal value. We also prove the
convex feasibility of the approximate Bayesian stochastic optimization problem.
Finally, we demonstrate the utility of our approach on an optimal staffing
problem for an M/M/c queueing model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiAdam: Fast Adaptive Bilevel Optimization Methods. (arXiv:2106.11396v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1">Feihu Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11396">
                                    <div class="article-summary-box-inner">
                                        <span>Bilevel optimization recently has attracted increased interest in machine
learning due to its many applications such as hyper-parameter optimization and
policy optimization. Although some methods recently have been proposed to solve
the bilevel problems, these methods do not consider using adaptive learning
rates. To fill this gap, in the paper, we propose a class of fast and effective
adaptive methods for solving bilevel optimization problems that the outer
problem is possibly nonconvex and the inner problem is strongly-convex.
Specifically, we propose a fast single-loop BiAdam algorithm based on the basic
momentum technique, which achieves a sample complexity of
$\tilde{O}(\epsilon^{-4})$ for finding an $\epsilon$-stationary point. At the
same time, we propose an accelerated version of BiAdam algorithm (VR-BiAdam) by
using variance reduced technique, which reaches the best known sample
complexity of $\tilde{O}(\epsilon^{-3})$. To further reduce computation in
estimating derivatives, we propose a fast single-loop stochastic approximated
BiAdam algorithm (saBiAdam) by avoiding the Hessian inverse, which still
achieves a sample complexity of $\tilde{O}(\epsilon^{-4})$ without large
batches. We further present an accelerated version of saBiAdam algorithm
(VR-saBiAdam), which also reaches the best known sample complexity of
$\tilde{O}(\epsilon^{-3})$. We apply the unified adaptive matrices to our
methods as the SUPER-ADAM \citep{huang2021super}, which including many types of
adaptive learning rates. Moreover, our framework can flexibly use the momentum
and variance reduced techniques. In particular, we provide a useful convergence
analysis framework for both the constrained and unconstrained bilevel
optimization. To the best of our knowledge, we first study the adaptive bilevel
optimization methods with adaptive learning rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual GNNs: Graph Neural Network Learning with Limited Supervision. (arXiv:2106.15755v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alchihabi_A/0/1/0/all/0/1">Abdullah Alchihabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuhong Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15755">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) require a relatively large number of labeled
nodes and a reliable/uncorrupted graph connectivity structure in order to
obtain good performance on the semi-supervised node classification task. The
performance of GNNs can degrade significantly as the number of labeled nodes
decreases or the graph connectivity structure is corrupted by adversarial
attacks or due to noises in data measurement /collection. Therefore, it is
important to develop GNN models that are able to achieve good performance when
there is limited supervision knowledge -- a few labeled nodes and noisy graph
structures. In this paper, we propose a novel Dual GNN learning framework to
address this challenge task. The proposed framework has two GNN based node
prediction modules. The primary module uses the input graph structure to induce
regular node embeddings and predictions with a regular GNN baseline, while the
auxiliary module constructs a new graph structure through fine-grained spectral
clusterings and learns new node embeddings and predictions. By integrating the
two modules in a dual GNN learning framework, we perform joint learning in an
end-to-end fashion. This general framework can be applied on many GNN baseline
models. The experimental results validate that the proposed dual GNN framework
can greatly outperform the GNN baseline methods when the labeled nodes are
scarce and the graph connectivity structure is noisy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weight Divergence Driven Divide-and-Conquer Approach for Optimal Federated Learning from non-IID Data. (arXiv:2106.14503v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandran_P/0/1/0/all/0/1">Pravin Chandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1">Raghavendra Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_A/0/1/0/all/0/1">Avinash Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Srikanth Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14503">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning allows training of data stored in distributed devices
without the need for centralizing training data, thereby maintaining data
privacy. Addressing the ability to handle data heterogeneity (non-identical and
independent distribution or non-IID) is a key enabler for the wider deployment
of Federated Learning. In this paper, we propose a novel Divide-and-Conquer
training methodology that enables the use of the popular FedAvg aggregation
algorithm by overcoming the acknowledged FedAvg limitations in non-IID
environments. We propose a novel use of Cosine-distance based Weight Divergence
metric to determine the exact point where a Deep Learning network can be
divided into class agnostic initial layers and class-specific deep layers for
performing a Divide and Conquer training. We show that the methodology achieves
trained model accuracy at par (and in certain cases exceeding) with numbers
achieved by state-of-the-art Aggregation algorithms like FedProx, FedMA, etc.
Also, we show that this methodology leads to compute and bandwidth
optimizations under certain documented conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Vision Transformers for Fine-grained Classification. (arXiv:2106.10587v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1">Marcos V. Conde</a>, <a href="http://arxiv.org/find/cs/1/au:+Turgutlu_K/0/1/0/all/0/1">Kerem Turgutlu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10587">
                                    <div class="article-summary-box-inner">
                                        <span>Existing computer vision research in categorization struggles with
fine-grained attributes recognition due to the inherently high intra-class
variances and low inter-class variances. SOTA methods tackle this challenge by
locating the most informative image regions and rely on them to classify the
complete image. The most recent work, Vision Transformer (ViT), shows its
strong performance in both traditional and fine-grained classification tasks.
In this work, we propose a multi-stage ViT framework for fine-grained image
classification tasks, which localizes the informative image regions without
requiring architectural changes using the inherent multi-head self-attention
mechanism. We also introduce attention-guided augmentations for improving the
model&#x27;s capabilities. We demonstrate the value of our approach by experimenting
with four popular fine-grained benchmarks: CUB-200-2011, Stanford Cars,
Stanford Dogs, and FGVC7 Plant Pathology. We also prove our model&#x27;s
interpretability via qualitative results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust and Interpretable Temporal Convolution Network for Event Detection in Lung Sound Recordings. (arXiv:2106.15835v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1">Tharindu Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaemmaghami_H/0/1/0/all/0/1">Houman Ghaemmaghami</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15835">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel framework for lung sound event detection,
segmenting continuous lung sound recordings into discrete events and performing
recognition on each event. Exploiting the lightweight nature of Temporal
Convolution Networks (TCNs) and their superior results compared to their
recurrent counterparts, we propose a lightweight, yet robust, and completely
interpretable framework for lung sound event detection. We propose the use of a
multi-branch TCN architecture and exploit a novel fusion strategy to combine
the resultant features from these branches. This not only allows the network to
retain the most salient information across different temporal granularities and
disregards irrelevant information, but also allows our network to process
recordings of arbitrary length. Results: The proposed method is evaluated on
multiple public and in-house benchmarks of irregular and noisy recordings of
the respiratory auscultation process for the identification of numerous
auscultation events including inhalation, exhalation, crackles, wheeze,
stridor, and rhonchi. We exceed the state-of-the-art results in all
evaluations. Furthermore, we empirically analyse the effect of the proposed
multi-branch TCN architecture and the feature fusion strategy and provide
quantitative and qualitative evaluations to illustrate their efficiency.
Moreover, we provide an end-to-end model interpretation pipeline that
interprets the operations of all the components of the proposed framework. Our
analysis of different feature fusion strategies shows that the proposed feature
concatenation method leads to better suppression of non-informative features,
which drastically reduces the classifier overhead resulting in a robust
lightweight network.The lightweight nature of our model allows it to be
deployed in end-user devices such as smartphones, and it has the ability to
generate predictions in real-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Networks for Spatio-temporal Data: A Survey. (arXiv:2008.08903v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1">Nan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sichen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_K/0/1/0/all/0/1">Kyle Kai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabowo_A/0/1/0/all/0/1">Arian Prabowo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahaman_M/0/1/0/all/0/1">Mohammad Saiedur Rahaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1">Flora D. Salim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08903">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have shown remarkable success in
producing realistic-looking images in the computer vision area. Recently,
GAN-based techniques are shown to be promising for spatio-temporal-based
applications such as trajectory prediction, events generation and time-series
data imputation. While several reviews for GANs in computer vision have been
presented, no one has considered addressing the practical applications and
challenges relevant to spatio-temporal data. In this paper, we have conducted a
comprehensive review of the recent developments of GANs for spatio-temporal
data. We summarise the application of popular GAN architectures for
spatio-temporal data and the common practices for evaluating the performance of
spatio-temporal applications with GANs. Finally, we point out future research
directions to benefit researchers in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep generative modeling for probabilistic forecasting in power systems. (arXiv:2106.09370v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanaspeze_A/0/1/0/all/0/1">Antoine Wehenkel Damien Lanaspeze</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornelusse_B/0/1/0/all/0/1">Bertrand Corn&#xe9;lusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutera_A/0/1/0/all/0/1">Antonio Sutera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09370">
                                    <div class="article-summary-box-inner">
                                        <span>Greater direct electrification of end-use sectors with a higher share of
renewables is one of the pillars to power a carbon-neutral society by 2050.
This study uses a recent deep learning technique, the normalizing flows, to
produce accurate probabilistic forecasts that are crucial for decision-makers
to face the new challenges in power systems applications. Through comprehensive
empirical evaluations using the open data of the Global Energy Forecasting
Competition 2014, we demonstrate that our methodology is competitive with other
state-of-the-art deep learning generative models: generative adversarial
networks and variational autoencoders. The models producing weather-based wind,
solar power, and load scenarios are properly compared both in terms of forecast
value, by considering the case study of an energy retailer, and quality using
several complementary metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Numerical Composition of Differential Privacy. (arXiv:2106.02848v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1">Sivakanth Gopi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1">Lukas Wutschitz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02848">
                                    <div class="article-summary-box-inner">
                                        <span>We give a fast algorithm to optimally compose privacy guarantees of
differentially private (DP) algorithms to arbitrary accuracy. Our method is
based on the notion of privacy loss random variables to quantify the privacy
loss of DP algorithms. The running time and memory needed for our algorithm to
approximate the privacy curve of a DP algorithm composed with itself $k$ times
is $\tilde{O}(\sqrt{k})$. This improves over the best prior method by Koskela
et al. (2020) which requires $\tilde{\Omega}(k^{1.5})$ running time. We
demonstrate the utility of our algorithm by accurately computing the privacy
loss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm
speeds up the privacy computations by a few orders of magnitude compared to
prior work, while maintaining similar accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Normalizing Flows for Permutation Invariant Densities. (arXiv:2010.03242v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1">Marin Bilo&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03242">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling sets is an important problem in machine learning since this type of
data can be found in many domains. A promising approach defines a family of
permutation invariant densities with continuous normalizing flows. This allows
us to maximize the likelihood directly and sample new realizations with ease.
In this work, we demonstrate how calculating the trace, a crucial step in this
method, raises issues that occur both during training and inference, limiting
its practicality. We propose an alternative way of defining permutation
equivariant transformations that give closed form trace. This leads not only to
improvements while training, but also to better final performance. We
demonstrate the benefits of our approach on point processes and general set
modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration. (arXiv:1809.11165v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1">Jacob R. Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Bindel_D/0/1/0/all/0/1">David Bindel</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1">Kilian Q. Weinberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1">Andrew Gordon Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1809.11165">
                                    <div class="article-summary-box-inner">
                                        <span>Despite advances in scalable models, the inference tools used for Gaussian
processes (GPs) have yet to fully capitalize on developments in computing
hardware. We present an efficient and general approach to GP inference based on
Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified
batched version of the conjugate gradients algorithm to derive all terms for
training and inference in a single call. BBMM reduces the asymptotic complexity
of exact GP inference from $O(n^3)$ to $O(n^2)$. Adapting this algorithm to
scalable approximations and complex GP models simply requires a routine for
efficient matrix-matrix multiplication with the kernel and its derivative. In
addition, BBMM uses a specialized preconditioner to substantially speed up
convergence. In experiments we show that BBMM effectively uses GPU hardware to
dramatically accelerate both exact GP inference and scalable approximations.
Additionally, we provide GPyTorch, a software platform for scalable GP
inference via BBMM, built on PyTorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Operator-valued formulas for Riemannian Gradient and Hessian and families of tractable metrics. (arXiv:2009.10159v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nguyen_D/0/1/0/all/0/1">Du Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10159">
                                    <div class="article-summary-box-inner">
                                        <span>We provide an explicit formula for the Levi-Civita connection and Riemannian
Hessian for a Riemannian manifold that is a quotient of a manifold embedded in
an inner product space with a non-constant metric function. Together with a
classical formula for projection, this allows us to evaluate Riemannian
gradient and Hessian for several families of metrics on classical manifolds,
including a family of metrics on Stiefel manifolds connecting both the constant
and canonical ambient metrics with closed-form geodesics. Using these formulas,
we derive Riemannian optimization frameworks on quotients of Stiefel manifolds,
including flag manifolds, and a new family of complete quotient metrics on the
manifold of positive-semidefinite matrices of fixed rank, considered as a
quotient of a product of Stiefel and positive-definite matrix manifold with
affine-invariant metrics. The method is procedural, and in many instances, the
Riemannian gradient and Hessian formulas could be derived by symbolic calculus.
The method extends the list of potential metrics that could be used in manifold
optimization and machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning-enhanced Receive Processing for MU-MIMO OFDM Systems. (arXiv:2106.16074v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goutay_M/0/1/0/all/0/1">Mathieu Goutay</a>, <a href="http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1">Fay&#xe7;al Ait Aoudia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1">Jakob Hoydis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorce_J/0/1/0/all/0/1">Jean-Marie Gorce</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16074">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) can be used in various ways to improve multi-user
multiple-input multiple-output (MU-MIMO) receive processing. Typical approaches
either augment a single processing step, such as symbol detection, or replace
multiple steps jointly by a single neural network (NN). These techniques
demonstrate promising results but often assume perfect channel state
information (CSI) or fail to satisfy the interpretability and scalability
constraints imposed by practical systems. In this paper, we propose a new
strategy which preserves the benefits of a conventional receiver, but enhances
specific parts with ML components. The key idea is to exploit the orthogonal
frequency-division multiplexing (OFDM) signal structure to improve both the
demapping and the computation of the channel estimation error statistics.
Evaluation results show that the proposed ML-enhanced receiver beats practical
baselines on all considered scenarios, with significant gains at high speeds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distill on the Go: Online knowledge distillation in self-supervised learning. (arXiv:2104.09866v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhat_P/0/1/0/all/0/1">Prashant Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09866">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning solves pretext prediction tasks that do not require
annotations to learn feature representations. For vision tasks, pretext tasks
such as predicting rotation, solving jigsaw are solely created from the input
data. Yet, predicting this known information helps in learning representations
useful for downstream tasks. However, recent works have shown that wider and
deeper models benefit more from self-supervised learning than smaller models.
To address the issue of self-supervised pre-training of smaller models, we
propose Distill-on-the-Go (DoGo), a self-supervised learning paradigm using
single-stage online knowledge distillation to improve the representation
quality of the smaller models. We employ deep mutual learning strategy in which
two models collaboratively learn from each other to improve one another.
Specifically, each model is trained using self-supervised learning along with
distillation that aligns each model&#x27;s softmax probabilities of similarity
scores with that of the peer model. We conduct extensive experiments on
multiple benchmark datasets, learning objectives, and architectures to
demonstrate the potential of our proposed method. Our results show significant
performance gain in the presence of noisy and limited labels and generalization
to out-of-distribution data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Inertial Newton Algorithm for Deep Learning. (arXiv:1905.12278v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castera_C/0/1/0/all/0/1">Camille Castera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Bolte</a> (UT1), <a href="http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1">C&#xe9;dric F&#xe9;votte</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1">Edouard Pauwels</a> (UT3)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.12278">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new second-order inertial optimization method for machine
learning called INNA. It exploits the geometry of the loss function while only
requiring stochastic approximations of the function values and the generalized
gradients. This makes INNA fully implementable and adapted to large-scale
optimization problems such as the training of deep neural networks. The
algorithm combines both gradient-descent and Newton-like behaviors as well as
inertia. We prove the convergence of INNA for most deep learning problems. To
do so, we provide a well-suited framework to analyze deep learning loss
functions involving tame optimization in which we study a continuous dynamical
system together with its discrete stochastic approximations. We prove sublinear
convergence for the continuous-time differential inclusion which underlies our
algorithm. Additionally, we also show how standard optimization mini-batch
methods applied to non-smooth non-convex problems can yield a certain type of
spurious stationary points never discussed before. We address this issue by
providing a theoretical framework around the new idea of $D$-criticality; we
then give a simple asymptotic analysis of INNA. Our algorithm allows for using
an aggressive learning rate of $o(1/\log k)$. From an empirical viewpoint, we
show that INNA returns competitive results with respect to state of the art
(stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias-reduced Multi-step Hindsight Experience Replay for Efficient Multi-goal Reinforcement Learning. (arXiv:2102.12962v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_J/0/1/0/all/0/1">Jiafei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ya_J/0/1/0/all/0/1">Jiangpeng Ya</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Feng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1">Dijun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lanqing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12962">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-goal reinforcement learning is widely applied in planning and robot
manipulation. Two main challenges in multi-goal reinforcement learning are
sparse rewards and sample inefficiency. Hindsight Experience Replay (HER) aims
to tackle the two challenges via goal relabeling. However, HER-related works
still need millions of samples and a huge computation. In this paper, we
propose Multi-step Hindsight Experience Replay (MHER), incorporating multi-step
relabeled returns based on $n$-step relabeling to improve sample efficiency.
Despite the advantages of $n$-step relabeling, we theoretically and
experimentally prove the off-policy $n$-step bias introduced by $n$-step
relabeling may lead to poor performance in many environments. To address the
above issue, two bias-reduced MHER algorithms, MHER($\lambda$) and Model-based
MHER (MMHER) are presented. MHER($\lambda$) exploits the $\lambda$ return while
MMHER benefits from model-based value expansions. Experimental results on
numerous multi-goal robotic tasks show that our solutions can successfully
alleviate off-policy $n$-step bias and achieve significantly higher sample
efficiency than HER and Curriculum-guided HER with little additional
computation beyond HER.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1">Feihu Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1">Junyi Li</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08208">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive gradient methods have shown excellent performance for solving many
machine learning problems. Although multiple adaptive methods were recently
studied, they mainly focus on either empirical or theoretical aspects and also
only work for specific problems by using specific adaptive learning rates. It
is desired to design a universal framework for practical algorithms of adaptive
gradients with theoretical guarantee to solve general problems. To fill this
gap, we propose a faster and universal framework of adaptive gradients (i.e.,
SUPER-ADAM) by introducing a universal adaptive matrix that includes most
existing adaptive gradient forms. Moreover, our framework can flexibly
integrates the momentum and variance reduced techniques. In particular, our
novel framework provides the convergence analysis support for adaptive gradient
methods under the nonconvex setting. In theoretical analysis, we prove that our
new algorithm can achieve the best known complexity of
$\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of
nonconvex optimization, which matches the lower bound for stochastic smooth
nonconvex optimization. In numerical experiments, we employ various deep
learning tasks to validate that our algorithm consistently outperforms the
existing adaptive algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal Algorithm Escaping the Curse of Horizon. (arXiv:2009.13503v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zihan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xiangyang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13503">
                                    <div class="article-summary-box-inner">
                                        <span>Episodic reinforcement learning and contextual bandits are two widely studied
sequential decision-making problems. Episodic reinforcement learning
generalizes contextual bandits and is often perceived to be more difficult due
to long planning horizon and unknown state-dependent transitions. The current
paper shows that the long planning horizon and the unknown state-dependent
transitions (at most) pose little additional difficulty on sample complexity.

We consider the episodic reinforcement learning with $S$ states, $A$ actions,
planning horizon $H$, total reward bounded by $1$, and the agent plays for $K$
episodes. We propose a new algorithm, \textbf{M}onotonic \textbf{V}alue
\textbf{P}ropagation (MVP), which relies on a new Bernstein-type bonus.
Compared to existing bonus constructions, the new bonus is tighter since it is
based on a well-designed monotonic value function. In particular, the
\emph{constants} in the bonus should be subtly setting to ensure optimism and
monotonicity.

We show MVP enjoys an $O\left(\left(\sqrt{SAK} + S^2A\right) \poly\log
\left(SAHK\right)\right)$ regret, approaching the
$\Omega\left(\sqrt{SAK}\right)$ lower bound of \emph{contextual bandits} up to
logarithmic terms. Notably, this result 1) \emph{exponentially} improves the
state-of-the-art polynomial-time algorithms by Dann et al. [2019] and Zanette
et al. [2019] in terms of the dependency on $H$, and 2) \emph{exponentially}
improves the running time in [Wang et al. 2020] and significantly improves the
dependency on $S$, $A$ and $K$ in sample complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CatBoost model with synthetic features in application to loan risk assessment of small businesses. (arXiv:2106.07954v3 [cs.CE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoxue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Liexin Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07954">
                                    <div class="article-summary-box-inner">
                                        <span>Loan risk for small businesses has long been a complex problem worthy of
exploring. Predicting the loan risk can benefit entrepreneurship by developing
more jobs for the society. CatBoost (Categorical Boosting) is a powerful
machine learning algorithm suitable for dataset with many categorical variables
like the dataset for forecasting loan risk. In this paper, we identify the
important risk factors that contribute to loan status classification problem.
Then we compare the performance between boosting-type algorithms(especially
CatBoost) with other traditional yet popular ones. The dataset we adopt in the
research comes from the U.S. Small Business Administration (SBA) and holds a
very large sample size (899,164 observations and 27 features). In order to make
the best use of the important features in the dataset, we propose a technique
named &quot;synthetic generation&quot; to develop more combined features based on
arithmetic operation, which ends up improving the accuracy and AUC of the
original CatBoost model. We obtain a high accuracy of 95.84% and well-performed
AUC of 98.80% compared with the existent literature of related research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invertible Manifold Learning for Dimension Reduction. (arXiv:2010.04012v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haitao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1">Zelin Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04012">
                                    <div class="article-summary-box-inner">
                                        <span>Dimension reduction (DR) aims to learn low-dimensional representations of
high-dimensional data with the preservation of essential information. In the
context of manifold learning, we define that the representation after
information-lossless DR preserves the topological and geometric properties of
data manifolds formally, and propose a novel two-stage DR method, called
invertible manifold learning (inv-ML) to bridge the gap between theoretical
information-lossless and practical DR. The first stage includes a homeomorphic
sparse coordinate transformation to learn low-dimensional representations
without destroying topology and a local isometry constraint to preserve local
geometry. In the second stage, a linear compression is implemented for the
trade-off between the target dimension and the incurred information loss in
excessive DR scenarios. Experiments are conducted on seven datasets with a
neural network implementation of inv-ML, called i-ML-Enc. Empirically, i-ML-Enc
achieves invertible DR in comparison with typical existing methods as well as
reveals the characteristics of the learned manifolds. Through latent space
interpolation on real-world datasets, we find that the reliability of tangent
space approximated by the local neighborhood is the key to the success of
manifold-based DR algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributionally Robust Learning with Stable Adversarial Training. (arXiv:2106.15791v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiashuo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zheyan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1">Peng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Linjun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1">Kun Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15791">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning algorithms with empirical risk minimization are vulnerable
under distributional shifts due to the greedy adoption of all the correlations
found in training data. There is an emerging literature on tackling this
problem by minimizing the worst-case risk over an uncertainty set. However,
existing methods mostly construct ambiguity sets by treating all variables
equally regardless of the stability of their correlations with the target,
resulting in the overwhelmingly-large uncertainty set and low confidence of the
learner. In this paper, we propose a novel Stable Adversarial Learning (SAL)
algorithm that leverages heterogeneous data sources to construct a more
practical uncertainty set and conduct differentiated robustness optimization,
where covariates are differentiated according to the stability of their
correlations with the target. We theoretically show that our method is
tractable for stochastic gradient-based optimization and provide the
performance guarantees for our method. Empirical studies on both simulation and
real datasets validate the effectiveness of our method in terms of uniformly
good performance across unknown distributional shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reducing Representation Drift in Online Continual Learning. (arXiv:2104.05025v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Aljundi_R/0/1/0/all/0/1">Rahaf Aljundi</a>, <a href="http://arxiv.org/find/cs/1/au:+Asadi_N/0/1/0/all/0/1">Nader Asadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1">Tinne Tuytelaars</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1">Eugene Belilovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05025">
                                    <div class="article-summary-box-inner">
                                        <span>In the online continual learning paradigm, agents must learn from a changing
distribution while respecting memory and compute constraints. Previous work in
this setting often tries to reduce catastrophic forgetting by limiting changes
in the space of model parameters. In this work we instead focus on the change
in representations of observed data that arises when previously unobserved
classes appear in the incoming data stream, and new classes must be
distinguished from previous ones. Starting from a popular approach, experience
replay, we consider metric learning based loss functions which, when adjusted
to appropriately select negative samples, can effectively nudge the learned
representations to be more robust to new future classes. We show that this
selection of negatives is in fact critical for reducing representation drift of
previously observed data. Motivated by this we further introduce a simple
adjustment to the standard cross entropy loss used in prior experience replay
that achieves similar effect. Our approach directly improves the performance of
experience replay for this setting, obtaining state-of-the-art results on
several existing benchmarks in online continual learning, while remaining
efficient in both memory and compute. We release an implementation of our
experiments at https://github.com/naderAsadi/AML</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Linear Networks Dynamics: Low-Rank Biases Induced by Initialization Scale and L2 Regularization. (arXiv:2106.15933v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Jacot_A/0/1/0/all/0/1">Arthur Jacot</a>, <a href="http://arxiv.org/find/stat/1/au:+Ged_F/0/1/0/all/0/1">Fran&#xe7;ois Ged</a>, <a href="http://arxiv.org/find/stat/1/au:+Gabriel_F/0/1/0/all/0/1">Franck Gabriel</a>, <a href="http://arxiv.org/find/stat/1/au:+Simsek_B/0/1/0/all/0/1">Berfin &#x15e;im&#x15f;ek</a>, <a href="http://arxiv.org/find/stat/1/au:+Hongler_C/0/1/0/all/0/1">Cl&#xe9;ment Hongler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15933">
                                    <div class="article-summary-box-inner">
                                        <span>For deep linear networks (DLN), various hyperparameters alter the dynamics of
training dramatically. We investigate how the rank of the linear map found by
gradient descent is affected by (1) the initialization norm and (2) the
addition of $L_{2}$ regularization on the parameters. For (1), we study two
regimes: (1a) the linear/lazy regime, for large norm initialization; (1b) a
\textquotedbl saddle-to-saddle\textquotedbl{} regime for small initialization
norm. In the (1a) setting, the dynamics of a DLN of any depth is similar to
that of a standard linear model, without any low-rank bias. In the (1b)
setting, we conjecture that throughout training, gradient descent approaches a
sequence of saddles, each corresponding to linear maps of increasing rank,
until reaching a minimal rank global minimum. We support this conjecture with a
partial proof and some numerical experiments. For (2), we show that adding a
$L_{2}$ regularization on the parameters corresponds to the addition to the
cost of a $L_{p}$-Schatten (quasi)norm on the linear map with $p&#x3D;\frac{2}{L}$
(for a depth-$L$ network), leading to a stronger low-rank bias as $L$ grows.
The effect of $L_{2}$ regularization on the loss surface depends on the depth:
for shallow networks, all critical points are either strict saddles or global
minima, whereas for deep networks, some local minima appear. We numerically
observe that these local minima can generalize better than global ones in some
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter Priors for Directed Acyclic Graphical Models and the Characterization of Several Probability Distributions. (arXiv:1301.6697v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_D/0/1/0/all/0/1">Dan Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Heckerman_D/0/1/0/all/0/1">David Heckerman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1301.6697">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the only parameter prior for complete Gaussian DAG models that
satisfies global parameter independence, complete model equivalence, and some
weak regularity assumptions, is the normal-Wishart distribution. Our analysis
is based on the following new characterization of the Wishart distribution: let
W be an n x n, n &gt;&#x3D; 3, positive-definite symmetric matrix of random variables
and f(W) be a pdf of W. Then, f(W) is a Wishart distribution if and only if
W_{11}-W_{12}W_{22}^{-1}W_{12}&#x27; is independent of {W_{12}, W_{22}} for every
block partitioning W_{11}, W_{12}, W_{12}&#x27;, W_{22} of W. Similar
characterizations of the normal and normal-Wishart distributions are provided
as well. We also show how to construct a prior for every DAG model over X from
the prior of a single regression model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphFM: Graph Factorization Machines for Feature Interaction Modeling. (arXiv:2105.11866v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zekun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zeyu Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11866">
                                    <div class="article-summary-box-inner">
                                        <span>Factorization machine (FM) is a prevalent approach to modeling pairwise
(second-order) feature interactions when dealing with high-dimensional sparse
data. However, on the one hand, FM fails to capture higher-order feature
interactions suffering from combinatorial expansion, on the other hand, taking
into account interaction between every pair of features may introduce noise and
degrade prediction accuracy. To solve the problems, we propose a novel approach
Graph Factorization Machine (GraphFM) by naturally representing features in the
graph structure. In particular, a novel mechanism is designed to select the
beneficial feature interactions and formulate them as edges between features.
Then our proposed model which integrates the interaction function of FM into
the feature aggregation strategy of Graph Neural Network (GNN), can model
arbitrary-order feature interactions on the graph-structured features by
stacking layers. Experimental results on several real-world datasets has
demonstrated the rationality and effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cyclist Trajectory Forecasts by Incorporation of Multi-View Video Information. (arXiv:2106.15991v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1">Stefan Zernetsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Trupp_O/0/1/0/all/0/1">Oliver Trupp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kress_V/0/1/0/all/0/1">Viktor Kress</a>, <a href="http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1">Konrad Doll</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15991">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents a novel approach to incorporate visual cues from
video-data from a wide-angle stereo camera system mounted at an urban
intersection into the forecast of cyclist trajectories. We extract features
from image and optical flow (OF) sequences using 3D convolutional neural
networks (3D-ConvNet) and combine them with features extracted from the
cyclist&#x27;s past trajectory to forecast future cyclist positions. By the use of
additional information, we are able to improve positional accuracy by about 7.5
% for our test dataset and by up to 22 % for specific motion types compared to
a method solely based on past trajectories. Furthermore, we compare the use of
image sequences to the use of OF sequences as additional information, showing
that OF alone leads to significant improvements in positional accuracy. By
training and testing our methods using a real-world dataset recorded at a
heavily frequented public intersection and evaluating the methods&#x27; runtimes, we
demonstrate the applicability in real traffic scenarios. Our code and parts of
our dataset are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Phenotyping and Graph Modeling of Spatial Architecture in Lymphoid Neoplasms. (arXiv:2106.16174v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chen_P/0/1/0/all/0/1">Pingjun Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Aminu_M/0/1/0/all/0/1">Muhammad Aminu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hussein_S/0/1/0/all/0/1">Siba El Hussein</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khoury_J/0/1/0/all/0/1">Joseph Khoury</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_J/0/1/0/all/0/1">Jia Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16174">
                                    <div class="article-summary-box-inner">
                                        <span>The cells and their spatial patterns in the tumor microenvironment (TME) play
a key role in tumor evolution, and yet remains an understudied topic in
computational pathology. This study, to the best of our knowledge, is among the
first to hybrid local and global graph methods to profile orchestration and
interaction of cellular components. To address the challenge in hematolymphoid
cancers where the cell classes in TME are unclear, we first implemented cell
level unsupervised learning and identified two new cell subtypes. Local cell
graphs or supercells were built for each image by considering the individual
cell&#x27;s geospatial location and classes. Then, we applied supercell level
clustering and identified two new cell communities. In the end, we built global
graphs to abstract spatial interaction patterns and extract features for
disease diagnosis. We evaluate the proposed algorithm on H\&amp;E slides of 60
hematolymphoid neoplasm patients and further compared it with three cell level
graph-based algorithms, including the global cell graph, cluster cell graph,
and FLocK. The proposed algorithm achieves a mean diagnosis accuracy of 0.703
with the repeated 5-fold cross-validation scheme. In conclusion, our algorithm
shows superior performance over the existing methods and can be potentially
applied to other cancer types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented Shortcuts for Vision Transformers. (arXiv:2106.15941v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">An Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yiping Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15941">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer models have achieved great progress on computer vision tasks
recently. The rapid development of vision transformers is mainly contributed by
their high representation ability for extracting informative features from
input images. However, the mainstream transformer models are designed with deep
architectures, and the feature diversity will be continuously reduced as the
depth increases, i.e., feature collapse. In this paper, we theoretically
analyze the feature collapse phenomenon and study the relationship between
shortcuts and feature diversity in these transformer models. Then, we present
an augmented shortcut scheme, which inserts additional paths with learnable
parameters in parallel on the original shortcuts. To save the computational
costs, we further explore an efficient approach that uses the block-circulant
projection to implement augmented shortcuts. Extensive experiments conducted on
benchmark datasets demonstrate the effectiveness of the proposed method, which
brings about 1% accuracy increase of the state-of-the-art visual transformers
without obviously increasing their parameters and FLOPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Scale Spectrogram Modelling for Neural Text-to-Speech. (arXiv:2106.15649v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Abbas_A/0/1/0/all/0/1">Ammar Abbas</a>, <a href="http://arxiv.org/find/eess/1/au:+Bollepalli_B/0/1/0/all/0/1">Bajibabu Bollepalli</a>, <a href="http://arxiv.org/find/eess/1/au:+Moinet_A/0/1/0/all/0/1">Alexis Moinet</a>, <a href="http://arxiv.org/find/eess/1/au:+Joly_A/0/1/0/all/0/1">Arnaud Joly</a>, <a href="http://arxiv.org/find/eess/1/au:+Karanasou_P/0/1/0/all/0/1">Penny Karanasou</a>, <a href="http://arxiv.org/find/eess/1/au:+Makarov_P/0/1/0/all/0/1">Peter Makarov</a>, <a href="http://arxiv.org/find/eess/1/au:+Slangens_S/0/1/0/all/0/1">Simon Slangens</a>, <a href="http://arxiv.org/find/eess/1/au:+Karlapati_S/0/1/0/all/0/1">Sri Karlapati</a>, <a href="http://arxiv.org/find/eess/1/au:+Drugman_T/0/1/0/all/0/1">Thomas Drugman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15649">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel Multi-Scale Spectrogram (MSS) modelling approach to
synthesise speech with an improved coarse and fine-grained prosody. We present
a generic multi-scale spectrogram prediction mechanism where the system first
predicts coarser scale mel-spectrograms that capture the suprasegmental
information in speech, and later uses these coarser scale mel-spectrograms to
predict finer scale mel-spectrograms capturing fine-grained prosody.

We present details for two specific versions of MSS called Word-level MSS and
Sentence-level MSS where the scales in our system are motivated by the
linguistic units. The Word-level MSS models word, phoneme, and frame-level
spectrograms while Sentence-level MSS models sentence-level spectrogram in
addition.

Subjective evaluations show that Word-level MSS performs statistically
significantly better compared to the baseline on two voices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faithful Edge Federated Learning: Scalability and Privacy. (arXiv:2106.15905v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Meng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_E/0/1/0/all/0/1">Ermin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Berry_R/0/1/0/all/0/1">Randall Berry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15905">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning enables machine learning algorithms to be trained over a
network of multiple decentralized edge devices without requiring the exchange
of local datasets. Successfully deploying federated learning requires ensuring
that agents (e.g., mobile devices) faithfully execute the intended algorithm,
which has been largely overlooked in the literature. In this study, we first
use risk bounds to analyze how the key feature of federated learning,
unbalanced and non-i.i.d. data, affects agents&#x27; incentives to voluntarily
participate and obediently follow traditional federated learning algorithms.

To be more specific, our analysis reveals that agents with less typical data
distributions and relatively more samples are more likely to opt out of or
tamper with federated learning algorithms. To this end, we formulate the first
faithful implementation problem of federated learning and design two faithful
federated learning mechanisms which satisfy economic properties, scalability,
and privacy. Further, the time complexity of computing all agents&#x27; payments in
the number of agents is $\mathcal{O}(1)$. First, we design a Faithful Federated
Learning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG)
payments via an incremental computation. We show that it achieves (probably
approximate) optimality, faithful implementation, voluntary participation, and
some other economic properties (such as budget balance). Second, by
partitioning agents into several subsets, we present a scalable VCG mechanism
approximation. We further design a scalable and Differentially Private FFL
(DP-FFL) mechanism, the first differentially private faithful mechanism, that
maintains the economic properties. Our mechanism enables one to make three-way
performance tradeoffs among privacy, the iterations needed, and payment
accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Generative Utility of Cyclic Conditionals. (arXiv:2106.15962v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoyue Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jintao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15962">
                                    <div class="article-summary-box-inner">
                                        <span>We study whether and how can we model a joint distribution $p(x,z)$ using two
conditional models $p(x|z)$ and $q(z|x)$ that form a cycle. This is motivated
by the observation that deep generative models, in addition to a likelihood
model $p(x|z)$, often also use an inference model $q(z|x)$ for data
representation, but they rely on a usually uninformative prior distribution
$p(z)$ to define a joint distribution, which may render problems like posterior
collapse and manifold mismatch. To explore the possibility to model a joint
distribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and
determinacy, corresponding to the existence and uniqueness of a joint
distribution whose conditional distributions coincide with them. We develop a
general theory for novel and operable equivalence criteria for compatibility,
and sufficient conditions for determinacy. Based on the theory, we propose the
CyGen framework for cyclic-conditional generative modeling, including methods
to enforce compatibility and use the determined distribution to fit and
generate data. With the prior constraint removed, CyGen better fits data and
captures more representative features, supported by experiments showing better
generation and downstream classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1">Marcos Vendramini</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1">Alexei Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10013">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification methods are usually trained to perform predictions
taking into account a predefined group of known classes. Real-world problems,
however, may not allow for a full knowledge of the input and label spaces,
making failures in recognition a hazard to deep visual learning. Open set
recognition methods are characterized by the ability to correctly identify
inputs of known and unknown classes. In this context, we propose GeMOS: simple
and plug-and-play open set recognition modules that can be attached to
pretrained Deep Neural Networks for visual recognition. The GeMOS framework
pairs pre-trained Convolutional Neural Networks with generative models for open
set recognition to extract open set scores for each sample, allowing for
failure recognition in object recognition tasks. We conduct a thorough
evaluation of the proposed method in comparison with state-of-the-art open set
algorithms, finding that GeMOS either outperforms or is statistically
indistinguishable from more complex and costly models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Super-Resolution via Iterative Refinement. (arXiv:2104.07636v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/eess/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>, <a href="http://arxiv.org/find/eess/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/eess/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07636">
                                    <div class="article-summary-box-inner">
                                        <span>We present SR3, an approach to image Super-Resolution via Repeated
Refinement. SR3 adapts denoising diffusion probabilistic models to conditional
image generation and performs super-resolution through a stochastic denoising
process. Inference starts with pure Gaussian noise and iteratively refines the
noisy output using a U-Net model trained on denoising at various noise levels.
SR3 exhibits strong performance on super-resolution tasks at different
magnification factors, on faces and natural images. We conduct human evaluation
on a standard 8X face super-resolution task on CelebA-HQ, comparing with SOTA
GAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic
outputs, while GANs do not exceed a fool rate of 34%. We further show the
effectiveness of SR3 in cascaded image generation, where generative models are
chained with super-resolution models, yielding a competitive FID score of 11.3
on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter Priors for Directed Acyclic Graphical Models and the Characterization of Several Probability Distributions. (arXiv:2105.03248v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Geiger_D/0/1/0/all/0/1">Dan Geiger</a>, <a href="http://arxiv.org/find/stat/1/au:+Heckerman_D/0/1/0/all/0/1">David Heckerman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03248">
                                    <div class="article-summary-box-inner">
                                        <span>We develop simple methods for constructing parameter priors for model choice
among Directed Acyclic Graphical (DAG) models. In particular, we introduce
several assumptions that permit the construction of parameter priors for a
large number of DAG models from a small set of assessments. We then present a
method for directly computing the marginal likelihood of every DAG model given
a random sample with no missing observations. We apply this methodology to
Gaussian DAG models which consist of a recursive set of linear regression
models. We show that the only parameter prior for complete Gaussian DAG models
that satisfies our assumptions is the normal-Wishart distribution. Our analysis
is based on the following new characterization of the Wishart distribution: let
$W$ be an $n \times n$, $n \ge 3$, positive-definite symmetric matrix of random
variables and $f(W)$ be a pdf of $W$. Then, f$(W)$ is a Wishart distribution if
and only if $W_{11} - W_{12} W_{22}^{-1} W&#x27;_{12}$ is independent of
$\{W_{12},W_{22}\}$ for every block partitioning $W_{11},W_{12}, W&#x27;_{12},
W_{22}$ of $W$. Similar characterizations of the normal and normal-Wishart
distributions are provided as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DAEMA: Denoising Autoencoder with Mask Attention. (arXiv:2106.16057v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tihon_S/0/1/0/all/0/1">Simon Tihon</a>, <a href="http://arxiv.org/find/cs/1/au:+Javaid_M/0/1/0/all/0/1">Muhammad Usama Javaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Fourure_D/0/1/0/all/0/1">Damien Fourure</a>, <a href="http://arxiv.org/find/cs/1/au:+Posocco_N/0/1/0/all/0/1">Nicolas Posocco</a>, <a href="http://arxiv.org/find/cs/1/au:+Peel_T/0/1/0/all/0/1">Thomas Peel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16057">
                                    <div class="article-summary-box-inner">
                                        <span>Missing data is a recurrent and challenging problem, especially when using
machine learning algorithms for real-world applications. For this reason,
missing data imputation has become an active research area, in which recent
deep learning approaches have achieved state-of-the-art results. We propose
DAEMA (Denoising Autoencoder with Mask Attention), an algorithm based on a
denoising autoencoder architecture with an attention mechanism. While most
imputation algorithms use incomplete inputs as they would use complete data -
up to basic preprocessing (e.g. mean imputation) - DAEMA leverages a mask-based
attention mechanism to focus on the observed values of its inputs. We evaluate
DAEMA both in terms of reconstruction capabilities and downstream prediction
and show that it achieves superior performance to state-of-the-art algorithms
on several publicly available real-world datasets under various missingness
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Signal Restoration Using Nested Deep Algorithm Unrolling. (arXiv:2106.15910v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nagahama_M/0/1/0/all/0/1">Masatoshi Nagahama</a>, <a href="http://arxiv.org/find/eess/1/au:+Yamada_K/0/1/0/all/0/1">Koki Yamada</a>, <a href="http://arxiv.org/find/eess/1/au:+Tanaka_Y/0/1/0/all/0/1">Yuichi Tanaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_S/0/1/0/all/0/1">Stanley H. Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+Eldar_Y/0/1/0/all/0/1">Yonina C. Eldar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15910">
                                    <div class="article-summary-box-inner">
                                        <span>Graph signal processing is a ubiquitous task in many applications such as
sensor, social, transportation and brain networks, point cloud processing, and
graph neural networks. Graph signals are often corrupted through sensing
processes, and need to be restored for the above applications. In this paper,
we propose two graph signal restoration methods based on deep algorithm
unrolling (DAU). First, we present a graph signal denoiser by unrolling
iterations of the alternating direction method of multiplier (ADMM). We then
propose a general restoration method for linear degradation by unrolling
iterations of Plug-and-Play ADMM (PnP-ADMM). In the second method, the unrolled
ADMM-based denoiser is incorporated as a submodule. Therefore, our restoration
method has a nested DAU structure. Thanks to DAU, parameters in the proposed
denoising/restoration methods are trainable in an end-to-end manner. Since the
proposed restoration methods are based on iterations of a (convex) optimization
algorithm, the method is interpretable and keeps the number of parameters small
because we only need to tune graph-independent regularization parameters. We
solve two main problems in existing graph signal restoration methods: 1)
limited performance of convex optimization algorithms due to fixed parameters
which are often determined manually. 2) large number of parameters of graph
neural networks that result in difficulty of training. Several experiments for
graph signal denoising and interpolation are performed on synthetic and
real-world data. The proposed methods show performance improvements to several
existing methods in terms of root mean squared error in both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SaRoCo: Detecting Satire in a Novel Romanian Corpus of News Articles. (arXiv:2105.06456v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaman_M/0/1/0/all/0/1">Mihaela Gaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06456">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce a corpus for satire detection in Romanian news. We
gathered 55,608 public news articles from multiple real and satirical news
sources, composing one of the largest corpora for satire detection regardless
of language and the only one for the Romanian language. We provide an official
split of the text samples, such that training news articles belong to different
sources than test news articles, thus ensuring that models do not achieve high
performance simply due to overfitting. We conduct experiments with two
state-of-the-art deep neural models, resulting in a set of strong baselines for
our novel corpus. Our results show that the machine-level accuracy for satire
detection in Romanian is quite low (under 73% on the test set) compared to the
human-level accuracy (87%), leaving enough room for improvement in future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Informants: Relations between Learning Success Criteria. (arXiv:1801.10502v5 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aschenbach_M/0/1/0/all/0/1">Martin Aschenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotzing_T/0/1/0/all/0/1">Timo K&#xf6;tzing</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_K/0/1/0/all/0/1">Karen Seidel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1801.10502">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from positive and negative information, so-called \emph{informants},
being one of the models for human and machine learning introduced by
E.~M.~Gold, is investigated. Particularly, naturally arising questions about
this learning setting, originating in results on learning from solely positive
information, are answered. By a carefully arranged argument learners can be
assumed to only change their hypothesis in case it is inconsistent with the
data (such a learning behavior is called \emph{conservative}). The deduced main
theorem states the relations between the most important delayable learning
success criteria, being the ones not ruined by a delayed in time hypothesis
output. Additionally, our investigations concerning the non-delayable
requirement of consistent learning underpin the claim for \emph{delayability}
being the right structural property to gain a deeper understanding concerning
the nature of learning success criteria. Moreover, we obtain an anomalous
\emph{hierarchy} when allowing for an increasing finite number of
\emph{anomalies} of the hypothesized language by the learner compared with the
language to be learned. In contrast to the vacillatory hierarchy for learning
from solely positive information, we observe a \emph{duality} depending on
whether infinitely many \emph{vacillations} between different (almost) correct
hypotheses are still considered a successful learning behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ATOM: Robustifying Out-of-distribution Detection Using Outlier Mining. (arXiv:2006.15207v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiefeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Somesh Jha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15207">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting out-of-distribution (OOD) inputs is critical for safely deploying
deep learning models in an open-world setting. However, existing OOD detection
solutions can be brittle in the open world, facing various types of adversarial
OOD inputs. While methods leveraging auxiliary OOD data have emerged, our
analysis on illuminative examples reveals a key insight that the majority of
auxiliary OOD examples may not meaningfully improve or even hurt the decision
boundary of the OOD detector, which is also observed in empirical results on
real data. In this paper, we provide a theoretically motivated method,
Adversarial Training with informative Outlier Mining (ATOM), which improves the
robustness of OOD detection. We show that, by mining informative auxiliary OOD
data, one can significantly improve OOD detection performance, and somewhat
surprisingly, generalize to unseen adversarial attacks. ATOM achieves
state-of-the-art performance under a broad family of classic and adversarial
OOD evaluation tasks. For example, on the CIFAR-10 in-distribution dataset,
ATOM reduces the FPR (at TPR 95%) by up to 57.99% under adversarial OOD inputs,
surpassing the previous best baseline by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Adversarial Attacks on Observations in Deep Reinforcement Learning. (arXiv:2106.15860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiaoben_Y/0/1/0/all/0/1">You Qiaoben</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1">Chengyang Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xinning Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15860">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works demonstrate that deep reinforcement learning (DRL) models are
vulnerable to adversarial attacks which can decrease the victim&#x27;s total reward
by manipulating the observations. Compared with adversarial attacks in
supervised learning, it is much more challenging to deceive a DRL model since
the adversary has to infer the environmental dynamics. To address this issue,
we reformulate the problem of adversarial attacks in function space and
separate the previous gradient based attacks into several subspace. Following
the analysis of the function space, we design a generic two-stage framework in
the subspace where the adversary lures the agent to a target trajectory or a
deceptive policy. In the first stage, we train a deceptive policy by hacking
the environment, and discover a set of trajectories routing to the lowest
reward. The adversary then misleads the victim to imitate the deceptive policy
by perturbing the observations. Our method provides a tighter theoretical upper
bound for the attacked agent&#x27;s performance than the existing approaches.
Extensive experiments demonstrate the superiority of our method and we achieve
the state-of-the-art performance on both Atari and MuJoCo environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Zero-Shot Hashing for Multilabel Image Retrieval. (arXiv:1911.07192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_Q/0/1/0/all/0/1">Qin Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Ling Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Song Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.07192">
                                    <div class="article-summary-box-inner">
                                        <span>Hash coding has been widely used in approximate nearest neighbor search for
large-scale image retrieval. Given semantic annotations such as class labels
and pairwise similarities of the training data, hashing methods can learn and
generate effective and compact binary codes. While some newly introduced images
may contain undefined semantic labels, which we call unseen images, zeor-shot
hashing techniques have been studied. However, existing zeor-shot hashing
methods focus on the retrieval of single-label images, and cannot handle
multi-label images. In this paper, for the first time, a novel transductive
zero-shot hashing method is proposed for multi-label unseen image retrieval. In
order to predict the labels of the unseen/target data, a visual-semantic bridge
is built via instance-concept coherence ranking on the seen/source data. Then,
pairwise similarity loss and focal quantization loss are constructed for
training a hashing model using both the seen/source and unseen/target data.
Extensive evaluations on three popular multi-label datasets demonstrate that,
the proposed hashing method achieves significantly better results than the
competing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group Testing under Superspreading Dynamics. (arXiv:2106.15988v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tsirtsis_S/0/1/0/all/0/1">Stratis Tsirtsis</a>, <a href="http://arxiv.org/find/stat/1/au:+De_A/0/1/0/all/0/1">Abir De</a>, <a href="http://arxiv.org/find/stat/1/au:+Lorch_L/0/1/0/all/0/1">Lars Lorch</a>, <a href="http://arxiv.org/find/stat/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1">Manuel Gomez-Rodriguez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15988">
                                    <div class="article-summary-box-inner">
                                        <span>Testing is recommended for all close contacts of confirmed COVID-19 patients.
However, existing group testing methods are oblivious to the circumstances of
contagion provided by contact tracing. Here, we build upon a well-known
semi-adaptive pool testing method, Dorfman&#x27;s method with imperfect tests, and
derive a simple group testing method based on dynamic programming that is
specifically designed to use the information provided by contact tracing.
Experiments using a variety of reproduction numbers and dispersion levels,
including those estimated in the context of the COVID-19 pandemic, show that
the pools found using our method result in a significantly lower number of
tests than those found using standard Dorfman&#x27;s method, especially when the
number of contacts of an infected individual is small. Moreover, our results
show that our method can be more beneficial when the secondary infections are
highly overdispersed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advantages and Bottlenecks of Quantum Machine Learning for Remote Sensing. (arXiv:2101.10657v3 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Zaidenberg_D/0/1/0/all/0/1">Daniela A. Zaidenberg</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Spiller_D/0/1/0/all/0/1">Dario Spiller</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Saux_B/0/1/0/all/0/1">Bertrand Le Saux</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10657">
                                    <div class="article-summary-box-inner">
                                        <span>This concept paper aims to provide a brief outline of quantum computers,
explore existing methods of quantum image classification techniques, so
focusing on remote sensing applications, and discuss the bottlenecks of
performing these algorithms on currently available open source platforms.
Initial results demonstrate feasibility. Next steps include expanding the size
of the quantum hidden layer and increasing the variety of output image options.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Belief Learning. (arXiv:2103.04000v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hengyuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1">Adam Lerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Brandon Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">David Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1">Luis Pineda</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1">Noam Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04000">
                                    <div class="article-summary-box-inner">
                                        <span>The standard problem setting in Dec-POMDPs is self-play, where the goal is to
find a set of policies that play optimally together. Policies learned through
self-play may adopt arbitrary conventions and implicitly rely on multi-step
reasoning based on fragile assumptions about other agents&#x27; actions and thus
fail when paired with humans or independently trained agents at test time. To
address this, we present off-belief learning (OBL). At each timestep OBL agents
follow a policy $\pi_1$ that is optimized assuming past actions were taken by a
given, fixed policy ($\pi_0$), but assuming that future actions will be taken
by $\pi_1$. When $\pi_0$ is uniform random, OBL converges to an optimal policy
that does not rely on inferences based on other agents&#x27; behavior (an optimal
grounded policy). OBL can be iterated in a hierarchy, where the optimal policy
from one level becomes the input to the next, thereby introducing multi-level
cognitive reasoning in a controlled manner. Unlike existing approaches, which
may converge to any equilibrium policy, OBL converges to a unique policy,
making it suitable for zero-shot coordination (ZSC). OBL can be scaled to
high-dimensional settings with a fictitious transition mechanism and shows
strong performance in both a toy-setting and the benchmark human-AI &amp; ZSC
problem Hanabi.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Modeling with Reduced Densities. (arXiv:2007.03834v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bradley_T/0/1/0/all/0/1">Tai-Danae Bradley</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlassopoulos_Y/0/1/0/all/0/1">Yiannis Vlassopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03834">
                                    <div class="article-summary-box-inner">
                                        <span>This work originates from the observation that today&#x27;s state of the art
statistical language models are impressive not only for their performance, but
also - and quite crucially - because they are built entirely from correlations
in unstructured text data. The latter observation prompts a fundamental
question that lies at the heart of this paper: What mathematical structure
exists in unstructured text data? We put forth enriched category theory as a
natural answer. We show that sequences of symbols from a finite alphabet, such
as those found in a corpus of text, form a category enriched over
probabilities. We then address a second fundamental question: How can this
information be stored and modeled in a way that preserves the categorical
structure? We answer this by constructing a functor from our enriched category
of text to a particular enriched category of reduced density operators. The
latter leverages the Loewner order on positive semidefinite operators, which
can further be interpreted as a toy example of entailment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Train Your MAML to Excel in Few-Shot Classification. (arXiv:2106.16245v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16245">
                                    <div class="article-summary-box-inner">
                                        <span>Model-agnostic meta-learning (MAML) is arguably the most popular
meta-learning algorithm nowadays, given its flexibility to incorporate various
model architectures and to be applied to different problems. Nevertheless, its
performance on few-shot classification is far behind many recent algorithms
dedicated to the problem. In this paper, we point out several key facets of how
to train MAML to excel in few-shot classification. First, we find that a large
number of gradient steps are needed for the inner loop update, which
contradicts the common usage of MAML for few-shot classification. Second, we
find that MAML is sensitive to the permutation of class assignments in
meta-testing: for a few-shot task of $N$ classes, there are exponentially many
ways to assign the learned initialization of the $N$-way classifier to the $N$
classes, leading to an unavoidably huge variance. Third, we investigate several
ways for permutation invariance and find that learning a shared classifier
initialization for all the classes performs the best. On benchmark datasets
such as MiniImageNet and TieredImageNet, our approach, which we name
UNICORN-MAML, performs on a par with or even outperforms state-of-the-art
algorithms, while keeping the simplicity of MAML without adding any extra
sub-networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What can linear interpolation of neural network loss landscapes tell us?. (arXiv:2106.16004v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vlaar_T/0/1/0/all/0/1">Tiffany Vlaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1">Jonathan Frankle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16004">
                                    <div class="article-summary-box-inner">
                                        <span>Studying neural network loss landscapes provides insights into the nature of
the underlying optimization problems. Unfortunately, loss landscapes are
notoriously difficult to visualize in a human-comprehensible fashion. One
common way to address this problem is to plot linear slices of the landscape,
for example from the initial state of the network to the final state after
optimization. On the basis of this analysis, prior work has drawn broader
conclusions about the difficulty of the optimization problem. In this paper, we
put inferences of this kind to the test, systematically evaluating how linear
interpolation and final performance vary when altering the data, choice of
initialization, and other optimizer and architecture design choices. Further,
we use linear interpolation to study the role played by individual layers and
substructures of the network. We find that certain layers are more sensitive to
the choice of initialization and optimizer hyperparameter settings, and we
exploit these observations to design custom optimization schemes. However, our
results cast doubt on the broader intuition that the presence or absence of
barriers when interpolating necessarily relates to the success of optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Small in-distribution changes in 3D perspective and lighting fool both CNNs and Transformers. (arXiv:2106.16198v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1">Tomotake Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tzu-Mao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1">Xavier Boix</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1">Hanspeter Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16198">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are susceptible to small transformations including 2D
rotations and shifts, image crops, and even changes in object colors. This is
often attributed to biases in the training dataset, and the lack of 2D
shift-invariance due to not respecting the sampling theorem. In this paper, we
challenge this hypothesis by training and testing on unbiased datasets, and
showing that networks are brittle to both small 3D perspective changes and
lighting variations which cannot be explained by dataset bias or lack of
shift-invariance. To find these in-distribution errors, we introduce an
evolution strategies (ES) based approach, which we call CMA-Search. Despite
training with a large-scale (0.5 million images), unbiased dataset of camera
and light variations, in over 71% cases CMA-Search can find camera parameters
in the vicinity of a correctly classified image which lead to in-distribution
misclassifications with &lt; 3.6% change in parameters. With lighting changes,
CMA-Search finds misclassifications in 33% cases with &lt; 11.6% change in
parameters. Finally, we extend this method to find misclassifications in the
vicinity of ImageNet images for both ResNet and OpenAI&#x27;s CLIP model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FROCC: Fast Random projection-based One-Class Classification. (arXiv:2011.14317v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Arindam Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Varambally_S/0/1/0/all/0/1">Sumanth Varambally</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagchi_A/0/1/0/all/0/1">Amitabha Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedathur_S/0/1/0/all/0/1">Srikanta Bedathur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14317">
                                    <div class="article-summary-box-inner">
                                        <span>We present Fast Random projection-based One-Class Classification (FROCC), an
extremely efficient method for one-class classification. Our method is based on
a simple idea of transforming the training data by projecting it onto a set of
random unit vectors that are chosen uniformly and independently from the unit
sphere, and bounding the regions based on separation of the data. FROCC can be
naturally extended with kernels. We theoretically prove that FROCC generalizes
well in the sense that it is stable and has low bias. FROCC achieves up to 3.1
percent points better ROC, with 1.2--67.8x speedup in training and test times
over a range of state-of-the-art benchmarks including the SVM and the deep
learning based models for the OCC task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Metric Learning for Incremental and Decremental Features. (arXiv:2006.15334v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jiahua Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1">Yang Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Gan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaowei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15334">
                                    <div class="article-summary-box-inner">
                                        <span>Online metric learning has been widely exploited for large-scale data
classification due to the low computational cost. However, amongst online
practical scenarios where the features are evolving (e.g., some features are
vanished and some new features are augmented), most metric learning models
cannot be successfully applied to these scenarios, although they can tackle the
evolving instances efficiently. To address the challenge, we develop a new
online Evolving Metric Learning (EML) model for incremental and decremental
features, which can handle the instance and feature evolutions simultaneously
by incorporating with a smoothed Wasserstein metric distance. Specifically, our
model contains two essential stages: a Transforming stage (T-stage) and a
Inheriting stage (I-stage). For the T-stage, we propose to extract important
information from vanished features while neglecting non-informative knowledge,
and forward it into survived features by transforming them into a low-rank
discriminative metric space. It further explores the intrinsic low-rank
structure of heterogeneous samples to reduce the computation and memory burden
especially for highly-dimensional large-scale data. For the I-stage, we inherit
the metric performance of survived features from the T-stage and then expand to
include the new augmented features. Moreover, a smoothed Wasserstein distance
is utilized to characterize the similarity relationships among the
heterogeneous and complex samples, since the evolving features are not strictly
aligned in the different stages. In addition to tackling the challenges in
one-shot case, we also extend our model into multishot scenario. After deriving
an efficient optimization strategy for both T-stage and I-stage, extensive
experiments on several datasets verify the superior performance of our EML
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concentration of Non-Isotropic Random Tensors with Applications to Learning and Empirical Risk Minimization. (arXiv:2102.04259v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Even_M/0/1/0/all/0/1">Mathieu Even</a>, <a href="http://arxiv.org/find/stat/1/au:+Massoulie_L/0/1/0/all/0/1">Laurent Massouli&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04259">
                                    <div class="article-summary-box-inner">
                                        <span>Dimension is an inherent bottleneck to some modern learning tasks, where
optimization methods suffer from the size of the data. In this paper, we study
non-isotropic distributions of data and develop tools that aim at reducing
these dimensional costs by a dependency on an effective dimension rather than
the ambient one. Based on non-asymptotic estimates of the metric entropy of
ellipsoids -- that prove to generalize to infinite dimensions -- and on a
chaining argument, our uniform concentration bounds involve an effective
dimension instead of the global dimension, improving over existing results. We
show the importance of taking advantage of non-isotropic properties in learning
problems with the following applications: i) we improve state-of-the-art
results in statistical preconditioning for communication-efficient distributed
optimization, ii) we introduce a non-isotropic randomized smoothing for
non-smooth optimization. Both applications cover a class of functions that
encompasses empirical risk minization (ERM) for linear models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pros and Cons of GAN Evaluation Measures: New Developments. (arXiv:2103.09396v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1">Ali Borji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09396">
                                    <div class="article-summary-box-inner">
                                        <span>This work is an update of a previous paper on the same topic published a few
years ago. With the dramatic progress in generative modeling, a suite of new
quantitative and qualitative techniques to evaluate models has emerged.
Although some measures such as Inception Score, Frechet Inception Distance,
Precision-Recall, and Perceptual Path Length are relatively more popular, GAN
evaluation is not a settled issue and there is still room for improvement.
Here, I describe new dimensions that are becoming important in assessing models
(e.g. bias and fairness) and discuss the connection between GAN evaluation and
deepfakes. These are important areas of concern in the machine learning
community today and progress in GAN evaluation can help mitigate them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explanation-Guided Diagnosis of Machine Learning Evasion Attacks. (arXiv:2106.15820v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amich_A/0/1/0/all/0/1">Abderrahmen Amich</a>, <a href="http://arxiv.org/find/cs/1/au:+Eshete_B/0/1/0/all/0/1">Birhanu Eshete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15820">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning (ML) models are susceptible to evasion attacks. Evasion
accuracy is typically assessed using aggregate evasion rate, and it is an open
question whether aggregate evasion rate enables feature-level diagnosis on the
effect of adversarial perturbations on evasive predictions. In this paper, we
introduce a novel framework that harnesses explainable ML methods to guide
high-fidelity assessment of ML evasion attacks. Our framework enables
explanation-guided correlation analysis between pre-evasion perturbations and
post-evasion explanations. Towards systematic assessment of ML evasion attacks,
we propose and evaluate a novel suite of model-agnostic metrics for
sample-level and dataset-level correlation analysis. Using malware and image
classifiers, we conduct comprehensive evaluations across diverse model
architectures and complementary feature representations. Our explanation-guided
correlation analysis reveals correlation gaps between adversarial samples and
the corresponding perturbations performed on them. Using a case study on
explanation-guided evasion, we show the broader usage of our methodology for
assessing robustness of ML models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge Proposal Sets for Link Prediction. (arXiv:2106.15810v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Abhay Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Sijia Linda Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhalerao_O/0/1/0/all/0/1">Omkar Bhalerao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Horace He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Benson_A/0/1/0/all/0/1">Austin R. Benson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15810">
                                    <div class="article-summary-box-inner">
                                        <span>Graphs are a common model for complex relational data such as social networks
and protein interactions, and such data can evolve over time (e.g., new
friendships) and be noisy (e.g., unmeasured interactions). Link prediction aims
to predict future edges or infer missing edges in the graph, and has diverse
applications in recommender systems, experimental design, and complex systems.
Even though link prediction algorithms strongly depend on the set of edges in
the graph, existing approaches typically do not modify the graph topology to
improve performance. Here, we demonstrate how simply adding a set of edges,
which we call a \emph{proposal set}, to the graph as a pre-processing step can
improve the performance of several link prediction algorithms. The underlying
idea is that if the edges in the proposal set generally align with the
structure of the graph, link prediction algorithms are further guided towards
predicting the right edges; in other words, adding a proposal set of edges is a
signal-boosting pre-processing step. We show how to use existing link
prediction algorithms to generate effective proposal sets and evaluate this
approach on various synthetic and empirical datasets. We find that proposal
sets meaningfully improve the accuracy of link prediction algorithms based on
both neighborhood heuristics and graph neural networks. Code is available at
\url{https://github.com/CUAI/Edge-Proposal-Sets}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Threat of Offensive AI to Organizations. (arXiv:2106.15764v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1">Yisroel Mirsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1">Ambra Demontis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotak_J/0/1/0/all/0/1">Jaidip Kotak</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_R/0/1/0/all/0/1">Ram Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelei_D/0/1/0/all/0/1">Deng Gelei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wenke Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1">Yuval Elovici</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15764">
                                    <div class="article-summary-box-inner">
                                        <span>AI has provided us with the ability to automate tasks, extract information
from vast amounts of data, and synthesize media that is nearly
indistinguishable from the real thing. However, positive tools can also be used
for negative purposes. In particular, cyber adversaries can use AI (such as
machine learning) to enhance their attacks and expand their campaigns.

Although offensive AI has been discussed in the past, there is a need to
analyze and understand the threat in the context of organizations. For example,
how does an AI-capable adversary impact the cyber kill chain? Does AI benefit
the attacker more than the defender? What are the most significant AI threats
facing organizations today and what will be their impact on the future?

In this survey, we explore the threat of offensive AI on organizations.
First, we present the background and discuss how AI changes the adversary&#x27;s
methods, strategies, goals, and overall attack model. Then, through a
literature review, we identify 33 offensive AI capabilities which adversaries
can use to enhance their attacks. Finally, through a user study spanning
industry and academia, we rank the AI threats and provide insights on the
adversaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Aspect Self-Attention based on Transformer for Remaining Useful Life Prediction. (arXiv:2106.15842v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1">Zhizheng Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Song_W/0/1/0/all/0/1">Wen Song</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1">Qiqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15842">
                                    <div class="article-summary-box-inner">
                                        <span>Remaining useful life prediction (RUL) is one of the key technologies of
condition-based maintenance, which is important to maintain the reliability and
safety of industrial equipments. While deep learning has achieved great success
in RUL prediction, existing methods have difficulties in processing long
sequences and extracting information from the sensor and time step aspects. In
this paper, we propose Dual Aspect Self-attention based on Transformer (DAST),
a novel deep RUL prediction method. DAST consists of two encoders, which work
in parallel to simultaneously extract features of different sensors and time
steps. Solely based on self-attention, the DAST encoders are more effective in
processing long data sequences, and are capable of adaptively learning to focus
on more important parts of input. Moreover, the parallel feature extraction
design avoids mutual influence of information from two aspects. Experimental
results on two real turbofan engine datasets show that our method significantly
outperforms state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PSD Representations for Effective Probability Models. (arXiv:2106.16116v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciliberto_C/0/1/0/all/0/1">Carlo Ciliberto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16116">
                                    <div class="article-summary-box-inner">
                                        <span>Finding a good way to model probability densities is key to probabilistic
inference. An ideal model should be able to concisely approximate any
probability, while being also compatible with two main operations:
multiplications of two models (product rule) and marginalization with respect
to a subset of the random variables (sum rule). In this work, we show that a
recently proposed class of positive semi-definite (PSD) models for non-negative
functions is particularly suited to this end. In particular, we characterize
both approximation and generalization capabilities of PSD models, showing that
they enjoy strong theoretical guarantees. Moreover, we show that we can perform
efficiently both sum and product rule in closed form via matrix operations,
enjoying the same versatility of mixture models. Our results open the way to
applications of PSD models to density estimation, decision theory and
inference. Preliminary empirical evaluation supports our findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge-Based Learning of Nonlinear Dynamics and Chaos. (arXiv:2010.03415v3 [nlin.CD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/nlin/1/au:+Jiahao_T/0/1/0/all/0/1">Tom Z. Jiahao</a>, <a href="http://arxiv.org/find/nlin/1/au:+Hsieh_M/0/1/0/all/0/1">M. Ani Hsieh</a>, <a href="http://arxiv.org/find/nlin/1/au:+Forgoston_E/0/1/0/all/0/1">Eric Forgoston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03415">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting predictive models from nonlinear systems is a central task in
scientific machine learning. One key problem is the reconciliation between
modern data-driven approaches and first principles. Despite rapid advances in
machine learning techniques, embedding domain knowledge into data-driven models
remains a challenge. In this work, we present a universal learning framework
for extracting predictive models from nonlinear systems based on observations.
Our framework can readily incorporate first principle knowledge because it
naturally models nonlinear systems as continuous-time systems. This both
improves the extracted models&#x27; extrapolation power and reduces the amount of
data needed for training. In addition, our framework has the advantages of
robustness to observational noise and applicability to irregularly sampled
data. We demonstrate the effectiveness of our scheme by learning predictive
models for a wide variety of systems including a stiff Van der Pol oscillator,
the Lorenz system, and the Kuramoto-Sivashinsky equation. For the Lorenz
system, different types of domain knowledge are incorporated to demonstrate the
strength of knowledge embedding in data-driven system identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering conservation laws from trajectories via machine learning. (arXiv:2102.04008v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ha_S/0/1/0/all/0/1">Seungwoong Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hawoong Jeong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04008">
                                    <div class="article-summary-box-inner">
                                        <span>Invariants and conservation laws convey critical information about the
underlying dynamics of a system, yet it is generally infeasible to find them
from large-scale data without any prior knowledge or human insight. We propose
ConservNet to achieve this goal, a neural network that spontaneously discovers
a conserved quantity from grouped data where the members of each group share
invariants, similar to a general experimental setting where trajectories from
different trials are observed. As a neural network trained with a novel and
intuitive loss function called noise-variance loss, ConservNet learns the
hidden invariants in each group of multi-dimensional observables in a
data-driven, end-to-end manner. Our model successfully discovers underlying
invariants from the simulated systems having invariants as well as a real-world
double pendulum trajectory. Since the model is robust to various noises and
data conditions compared to baseline, our approach is directly applicable to
experimental data for discovering hidden conservation laws and further, general
relationships between variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Priors In Variational Autoencoders. (arXiv:2106.15671v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wehenkel_A/0/1/0/all/0/1">Antoine Wehenkel</a>, <a href="http://arxiv.org/find/cs/1/au:+Louppe_G/0/1/0/all/0/1">Gilles Louppe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15671">
                                    <div class="article-summary-box-inner">
                                        <span>Among likelihood-based approaches for deep generative modelling, variational
autoencoders (VAEs) offer scalable amortized posterior inference and fast
sampling. However, VAEs are also more and more outperformed by competing models
such as normalizing flows (NFs), deep-energy models, or the new denoising
diffusion probabilistic models (DDPMs). In this preliminary work, we improve
VAEs by demonstrating how DDPMs can be used for modelling the prior
distribution of the latent variables. The diffusion prior model improves upon
Gaussian priors of classical VAEs and is competitive with NF-based priors.
Finally, we hypothesize that hierarchical VAEs could similarly benefit from the
enhanced capacity of diffusion priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning based Disease Progression Model for Alzheimer&#x27;s Disease. (arXiv:2106.16187v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saboo_K/0/1/0/all/0/1">Krishnakant V. Saboo</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_A/0/1/0/all/0/1">Anirudh Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yurui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Worrell_G/0/1/0/all/0/1">Gregory A. Worrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1">David T. Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Ravishankar K. Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16187">
                                    <div class="article-summary-box-inner">
                                        <span>We model Alzheimer&#x27;s disease (AD) progression by combining differential
equations (DEs) and reinforcement learning (RL) with domain knowledge. DEs
provide relationships between some, but not all, factors relevant to AD. We
assume that the missing relationships must satisfy general criteria about the
working of the brain, for e.g., maximizing cognition while minimizing the cost
of supporting cognition. This allows us to extract the missing relationships by
using RL to optimize an objective (reward) function that captures the above
criteria. We use our model consisting of DEs (as a simulator) and the trained
RL agent to predict individualized 10-year AD progression using baseline (year
0) features on synthetic and real data. The model was comparable or better at
predicting 10-year cognition trajectories than state-of-the-art learning-based
models. Our interpretable model demonstrated, and provided insights into,
&quot;recovery/compensatory&quot; processes that mitigate the effect of AD, even though
those processes were not explicitly encoded in the model. Our framework
combines DEs with RL for modelling AD progression and has broad applicability
for understanding other neurological disorders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Model for Raw Audio Using Transformer Architectures. (arXiv:2106.16036v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1">Prateek Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chafe_C/0/1/0/all/0/1">Chris Chafe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16036">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel way of doing audio synthesis at the waveform
level using Transformer architectures. We propose a deep neural network for
generating waveforms, similar to wavenet \cite{oord2016wavenet}. This is fully
probabilistic, auto-regressive, and causal, i.e. each sample generated depends
only on the previously observed samples. Our approach outperforms a widely used
wavenet architecture by up to 9\% on a similar dataset for predicting the next
step. Using the attention mechanism, we enable the architecture to learn which
audio samples are important for the prediction of the future sample. We show
how causal transformer generative models can be used for raw waveform
synthesis. We also show that this performance can be improved by another 2\% by
conditioning samples over a wider context. The flexibility of the current model
to synthesize audio from latent representations suggests a large number of
potential applications. The novel approach of using generative transformer
architectures for raw audio synthesis is, however, still far away from
generating any meaningful music, without using latent codes/meta-data to aid
the generation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Learning of OFDM Waveforms with PAPR and ACLR Constraints. (arXiv:2106.16039v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goutay_M/0/1/0/all/0/1">Mathieu Goutay</a>, <a href="http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1">Fay&#xe7;al Ait Aoudia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1">Jakob Hoydis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorce_J/0/1/0/all/0/1">Jean-Marie Gorce</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16039">
                                    <div class="article-summary-box-inner">
                                        <span>Orthogonal frequency-division multiplexing (OFDM) is widely used in modern
wireless networks thanks to its efficient handling of multipath environment.
However, it suffers from a poor peak-to-average power ratio (PAPR) which
requires a large power backoff, degrading the power amplifier (PA) efficiency.
In this work, we propose to use a neural network (NN) at the transmitter to
learn a high-dimensional modulation scheme allowing to control the PAPR and
adjacent channel leakage ratio (ACLR). On the receiver side, a NN-based
receiver is implemented to carry out demapping of the transmitted bits. The two
NNs operate on top of OFDM, and are jointly optimized in and end-to-end manner
using a training algorithm that enforces constraints on the PAPR and ACLR.
Simulation results show that the learned waveforms enable higher information
rates than a tone reservation baseline, while satisfying predefined PAPR and
ACLR targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Limited-Fronthaul Cell-Free Hybrid Beamforming with Distributed Deep Neural Network. (arXiv:2106.16194v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hojatian_H/0/1/0/all/0/1">Hamed Hojatian</a>, <a href="http://arxiv.org/find/eess/1/au:+Nadal_J/0/1/0/all/0/1">Jeremy Nadal</a>, <a href="http://arxiv.org/find/eess/1/au:+Frigon_J/0/1/0/all/0/1">Jean-Francois Frigon</a>, <a href="http://arxiv.org/find/eess/1/au:+Leduc_Primeau_F/0/1/0/all/0/1">Francois Leduc-Primeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16194">
                                    <div class="article-summary-box-inner">
                                        <span>Cell-free massive MIMO (CF-mMIMO) systems represent a promising approach to
increase the spectral efficiency of wireless communication systems. However,
near-optimal solutions require a large amount of signaling exchange between
access points (APs) and the network controller (NC). In addition, the use of
hybrid beamforming in each AP reduces the number of power hungry RF chains, but
imposes a large computational complexity to find near-optimal precoders. In
this letter, we propose two unsupervised deep neural networks (DNN)
architectures, fully and partially distributed, that can perform coordinated
hybrid beamforming with zero or limited communication overhead between APs and
NC, while achieving near-optimal sum-rate with a reduced computational
complexity compared to conventional near-optimal solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotions in Macroeconomic News and their Impact on the European Bond Market. (arXiv:2106.15698v1 [econ.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Consoli_S/0/1/0/all/0/1">Sergio Consoli</a>, <a href="http://arxiv.org/find/econ/1/au:+Pezzoli_L/0/1/0/all/0/1">Luca Tiozzo Pezzoli</a>, <a href="http://arxiv.org/find/econ/1/au:+Tosetti_E/0/1/0/all/0/1">Elisa Tosetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15698">
                                    <div class="article-summary-box-inner">
                                        <span>We show how emotions extracted from macroeconomic news can be used to explain
and forecast future behaviour of sovereign bond yield spreads in Italy and
Spain. We use a big, open-source, database known as Global Database of Events,
Language and Tone to construct emotion indicators of bond market affective
states. We find that negative emotions extracted from news improve the
forecasting power of government yield spread models during distressed periods
even after controlling for the number of negative words present in the text. In
addition, stronger negative emotions, such as panic, reveal useful information
for predicting changes in spread at the short-term horizon, while milder
emotions, such as distress, are useful at longer time horizons. Emotions
generated by the Italian political turmoil propagate to the Spanish news
affecting this neighbourhood market.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Landscape of One-hidden-layer Sparse Networks and Beyond. (arXiv:2009.07439v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dachao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Ruoyu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihua Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07439">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse neural networks have received increasing interests due to their small
size compared to dense networks. Nevertheless, most existing works on neural
network theory have focused on dense neural networks, and our understanding of
sparse networks is very limited. In this paper, we study the loss landscape of
one-hidden-layer sparse networks. We first consider sparse networks with linear
activations. We show that sparse linear networks can have spurious strict
minima, which is in sharp contrast to dense linear networks which do not even
have spurious minima. Second, we show that spurious valleys can exist for wide
sparse non-linear networks. This is different from wide dense networks which do
not have spurious valleys under mild assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection: How to Artificially Increase your F1-Score with a Biased Evaluation Protocol. (arXiv:2106.16020v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fourure_D/0/1/0/all/0/1">Damien Fourure</a>, <a href="http://arxiv.org/find/cs/1/au:+Javaid_M/0/1/0/all/0/1">Muhammad Usama Javaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Posocco_N/0/1/0/all/0/1">Nicolas Posocco</a>, <a href="http://arxiv.org/find/cs/1/au:+Tihon_S/0/1/0/all/0/1">Simon Tihon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16020">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection is a widely explored domain in machine learning. Many
models are proposed in the literature, and compared through different metrics
measured on various datasets. The most popular metrics used to compare
performances are F1-score, AUC and AVPR. In this paper, we show that F1-score
and AVPR are highly sensitive to the contamination rate. One consequence is
that it is possible to artificially increase their values by modifying the
train-test split procedure. This leads to misleading comparisons between
algorithms in the literature, especially when the evaluation protocol is not
well detailed. Moreover, we show that the F1-score and the AVPR cannot be used
to compare performances on different datasets as they do not reflect the
intrinsic difficulty of modeling such data. Based on these observations, we
claim that F1-score and AVPR should not be used as metrics for anomaly
detection. We recommend a generic evaluation procedure for unsupervised anomaly
detection, including the use of other metrics such as the AUC, which are more
robust to arbitrary choices in the evaluation protocol.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Robust Classification-autoencoder to Defend Outliers and Adversaries. (arXiv:2106.15927v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lijia Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiao-Shan Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15927">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a robust classification-autoencoder (CAE) which has
strong ability to recognize outliers and defend adversaries. The basic idea is
to change the autoencoder from an unsupervised learning method into a
classifier. The CAE is a modified autoencoder, where the encoder is used to
compress samples with different labels into disjoint compression spaces and the
decoder is used to recover a sample with a given label from the corresponding
compression space. The encoder is used as a classifier and the decoder is used
to decide whether the classification given by the encoder is correct by
comparing the input sample with the output. Since adversary samples are seeming
inevitable for the current DNN framework, we introduce the list classification
based on CAE to defend adversaries, which outputs several labels and the
corresponding samples recovered by the CAE. The CAE is evaluated using the
MNIST dataset in great detail. It is shown that the CAE network can recognize
almost all outliers and the list classification contains the correct label for
almost all adversaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Step Adversarial Training for Semantic Segmentation. (arXiv:2106.15998v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wiens_D/0/1/0/all/0/1">Daniel Wiens</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1">Barbara Hammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15998">
                                    <div class="article-summary-box-inner">
                                        <span>Even though deep neural networks succeed on many different tasks including
semantic segmentation, they lack on robustness against adversarial examples. To
counteract this exploit, often adversarial training is used. However, it is
known that adversarial training with weak adversarial attacks (e.g. using the
Fast Gradient Method) does not improve the robustness against stronger attacks.
Recent research shows that it is possible to increase the robustness of such
single-step methods by choosing an appropriate step size during the training.
Finding such a step size, without increasing the computational effort of
single-step adversarial training, is still an open challenge. In this work we
address the computationally particularly demanding task of semantic
segmentation and propose a new step size control algorithm that increases the
robustness of single-step adversarial training. The proposed algorithm does not
increase the computational effort of single-step adversarial training
considerably and also simplifies training, because it is free of
meta-parameter. We show that the robustness of our approach can compete with
multi-step adversarial training on two popular benchmarks for semantic
segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bounds for Open-Set Learning. (arXiv:2106.15792v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anjin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangquan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15792">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional supervised learning aims to train a classifier in the closed-set
world, where training and test samples share the same label space. In this
paper, we target a more challenging and realistic setting: open-set learning
(OSL), where there exist test samples from the classes that are unseen during
training. Although researchers have designed many methods from the algorithmic
perspectives, there are few methods that provide generalization guarantees on
their ability to achieve consistent performance on different training samples
drawn from the same distribution. Motivated by the transfer learning and
probably approximate correct (PAC) theory, we make a bold attempt to study OSL
by proving its generalization error-given training samples with size n, the
estimation error will get close to order O_p(1/\sqrt{n}). This is the first
study to provide a generalization bound for OSL, which we do by theoretically
investigating the risk of the target classifier on unknown classes. According
to our theory, a novel algorithm, called auxiliary open-set risk (AOSR) is
proposed to address the OSL problem. Experiments verify the efficacy of AOSR.
The code is available at github.com/Anjin-Liu/Openset_Learning_AOSR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Robustness of Neural Networks through Graph Measures. (arXiv:2106.15850v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waqas_A/0/1/0/all/0/1">Asim Waqas</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1">Ghulam Rasool</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Farooq_H/0/1/0/all/0/1">Hamza Farooq</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Bouaynaya_N/0/1/0/all/0/1">Nidhal C. Bouaynaya</a> (1), ((1) Rowan University, (2) University of Minnesota)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15850">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by graph theory, artificial neural networks (ANNs) are
traditionally structured as layers of neurons (nodes), which learn useful
information by the passage of data through interconnections (edges). In the
machine learning realm, graph structures (i.e., neurons and connections) of
ANNs have recently been explored using various graph-theoretic measures linked
to their predictive performance. On the other hand, in network science
(NetSci), certain graph measures including entropy and curvature are known to
provide insight into the robustness and fragility of real-world networks. In
this work, we use these graph measures to explore the robustness of various
ANNs to adversarial attacks. To this end, we (1) explore the design space of
inter-layer and intra-layers connectivity regimes of ANNs in the graph domain
and record their predictive performance after training under different types of
adversarial attacks, (2) use graph representations for both inter-layer and
intra-layers connectivity regimes to calculate various graph-theoretic
measures, including curvature and entropy, and (3) analyze the relationship
between these graph measures and the adversarial performance of ANNs. We show
that curvature and entropy, while operating in the graph domain, can quantify
the robustness of ANNs without having to train these ANNs. Our results suggest
that the real-world networks, including brain networks, financial networks, and
social networks may provide important clues to the neural architecture search
for robust ANNs. We propose a search strategy that efficiently finds robust
ANNs amongst a set of well-performing ANNs without having a need to train all
of these ANNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning. (arXiv:2106.15831v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andreassen_A/0/1/0/all/0/1">Anders Andreassen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_Y/0/1/0/all/0/1">Yasaman Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Neyshabur_B/0/1/0/all/0/1">Behnam Neyshabur</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15831">
                                    <div class="article-summary-box-inner">
                                        <span>Although machine learning models typically experience a drop in performance
on out-of-distribution data, accuracies on in- versus out-of-distribution data
are widely observed to follow a single linear trend when evaluated across a
testbed of models. Models that are more accurate on the out-of-distribution
data relative to this baseline exhibit &quot;effective robustness&quot; and are
exceedingly rare. Identifying such models, and understanding their properties,
is key to improving out-of-distribution performance. We conduct a thorough
empirical investigation of effective robustness during fine-tuning and
surprisingly find that models pre-trained on larger datasets exhibit effective
robustness during training that vanishes at convergence. We study how
properties of the data influence effective robustness, and we show that it
increases with the larger size, more diversity, and higher example difficulty
of the dataset. We also find that models that display effective robustness are
able to correctly classify 10% of the examples that no other current testbed
model gets correct. Finally, we discuss several strategies for scaling
effective robustness to the high-accuracy regime to improve the
out-of-distribution accuracy of state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaGDA: Faster Adaptive Gradient Descent Ascent Methods for Minimax Optimization. (arXiv:2106.16101v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1">Feihu Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16101">
                                    <div class="article-summary-box-inner">
                                        <span>In the paper, we propose a class of faster adaptive gradient descent ascent
methods for solving the nonconvex-strongly-concave minimax problems by using
unified adaptive matrices used in the SUPER-ADAM \citep{huang2021super}.
Specifically, we propose a fast adaptive gradient decent ascent (AdaGDA) method
based on the basic momentum technique, which reaches a low sample complexity of
$O(\kappa^4\epsilon^{-4})$ for finding an $\epsilon$-stationary point without
large batches, which improves the existing result of adaptive minimax
optimization method by a factor of $O(\sqrt{\kappa})$. Moreover, we present an
accelerated version of AdaGDA (VR-AdaGDA) method based on the momentum-based
variance reduced technique, which achieves the best known sample complexity of
$O(\kappa^3\epsilon^{-3})$ for finding an $\epsilon$-stationary point without
large batches. Further assume the bounded Lipschitz parameter of objective
function, we prove that our VR-AdaGDA method reaches a lower sample complexity
of $O(\kappa^{2.5}\epsilon^{-3})$ with the mini-batch size $O(\kappa)$. In
particular, we provide an effective convergence analysis framework for our
adaptive methods based on unified adaptive matrices, which include almost
existing adaptive learning rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex Envelopes. (arXiv:2002.00874v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zaiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00874">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic Approximation (SA) is a popular approach for solving fixed-point
equations where the information is corrupted by noise. In this paper, we
consider an SA involving a contraction mapping with respect to an arbitrary
norm, and show its finite-sample error bounds while using different stepsizes.
The idea is to construct a smooth Lyapunov function using the generalized
Moreau envelope, and show that the iterates of SA have negative drift with
respect to that Lyapunov function. Our result is applicable in Reinforcement
Learning (RL). In particular, we use it to establish the first-known
convergence rate of the V-trace algorithm for off-policy TD-learning. Moreover,
we also use it to study TD-learning in the on-policy setting, and recover the
existing state-of-the-art results for $Q$-learning. Importantly, our
construction results in only a logarithmic dependence of the convergence bound
on the size of the state-space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Reweighting for Adversarial Training. (arXiv:2106.15776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Ruize Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiwen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">James Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15776">
                                    <div class="article-summary-box-inner">
                                        <span>Instances-reweighted adversarial training (IRAT) can significantly boost the
robustness of trained models, where data being less/more vulnerable to the
given attack are assigned smaller/larger weights during training. However, when
tested on attacks different from the given attack simulated in training, the
robustness may drop significantly (e.g., even worse than no reweighting). In
this paper, we study this problem and propose our solution--locally reweighted
adversarial training (LRAT). The rationale behind IRAT is that we do not need
to pay much attention to an instance that is already safe under the attack. We
argue that the safeness should be attack-dependent, so that for the same
instance, its weight can change given different attacks based on the same
model. Thus, if the attack simulated in training is mis-specified, the weights
of IRAT are misleading. To this end, LRAT pairs each instance with its
adversarial variants and performs local reweighting inside each pair, while
performing no global reweighting--the rationale is to fit the instance itself
if it is immune to the attack, but not to skip the pair, in order to passively
defend different attacks in future. Experiments show that LRAT works better
than both IRAT (i.e., global reweighting) and the standard AT (i.e., no
reweighting) when trained with an attack and tested on different attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay. (arXiv:2106.15739v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1">Ekaterina Lobacheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodryan_M/0/1/0/all/0/1">Maxim Kodryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chirkova_N/0/1/0/all/0/1">Nadezhda Chirkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Malinin_A/0/1/0/all/0/1">Andrey Malinin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1">Dmitry Vetrov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15739">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the conventional wisdom that using batch normalization with weight
decay may improve neural network training, some recent works show their joint
usage may cause instabilities at the late stages of training. Other works, in
contrast, show convergence to the equilibrium, i.e., the stabilization of
training metrics. In this paper, we study this contradiction and show that
instead of converging to a stable equilibrium, the training dynamics converge
to consistent periodic behavior. That is, the training process regularly
exhibits instabilities which, however, do not lead to complete training
failure, but cause a new period of training. We rigorously investigate the
mechanism underlying this discovered periodic behavior both from an empirical
and theoretical point of view and show that this periodic behavior is indeed
caused by the interaction between batch normalization and weight decay.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding and Improving Early Stopping for Learning with Noisy Labels. (arXiv:2106.15853v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yingbin Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Erkun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yanhua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiatong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yinian Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15853">
                                    <div class="article-summary-box-inner">
                                        <span>The memorization effect of deep neural network (DNN) plays a pivotal role in
many state-of-the-art label-noise learning methods. To exploit this property,
the early stopping trick, which stops the optimization at the early stage of
training, is usually adopted. Current methods generally decide the early
stopping point by considering a DNN as a whole. However, a DNN can be
considered as a composition of a series of layers, and we find that the latter
layers in a DNN are much more sensitive to label noise, while their former
counterparts are quite robust. Therefore, selecting a stopping point for the
whole network may make different DNN layers antagonistically affected each
other, thus degrading the final performance. In this paper, we propose to
separate a DNN into different parts and progressively train them to address
this problem. Instead of the early stopping, which trains a whole DNN all at
once, we initially train former DNN layers by optimizing the DNN with a
relatively large number of epochs. During training, we progressively train the
latter DNN layers by using a smaller number of epochs with the preceding layers
fixed to counteract the impact of noisy labels. We term the proposed method as
progressive early stopping (PES). Despite its simplicity, compared with the
early stopping, PES can help to obtain more promising and stable results.
Furthermore, by combining PES with existing approaches on noisy label training,
we achieve state-of-the-art performance on image classification benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source Domain Adaptation for Object Detection. (arXiv:2106.15793v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xingxu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sicheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Pengfei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jufeng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15793">
                                    <div class="article-summary-box-inner">
                                        <span>To reduce annotation labor associated with object detection, an increasing
number of studies focus on transferring the learned knowledge from a labeled
source domain to another unlabeled target domain. However, existing methods
assume that the labeled data are sampled from a single source domain, which
ignores a more generalized scenario, where labeled data are from multiple
source domains. For the more challenging task, we propose a unified Faster
R-CNN based framework, termed Divide-and-Merge Spindle Network (DMSN), which
can simultaneously enhance domain invariance and preserve discriminative power.
Specifically, the framework contains multiple source subnets and a pseudo
target subnet. First, we propose a hierarchical feature alignment strategy to
conduct strong and weak alignments for low- and high-level features,
respectively, considering their different effects for object detection. Second,
we develop a novel pseudo subnet learning algorithm to approximate optimal
parameters of pseudo target subset by weighted combination of parameters in
different source subnets. Finally, a consistency regularization for region
proposal network is proposed to facilitate each subnet to learn more abstract
invariances. Extensive experiments on different adaptation scenarios
demonstrate the effectiveness of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unaware Fairness: Hierarchical Random Forest for Protected Classes. (arXiv:2106.15767v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xian Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15767">
                                    <div class="article-summary-box-inner">
                                        <span>Procedural fairness has been a public concern, which leads to controversy
when making decisions with respect to protected classes, such as race, social
status, and disability. Some protected classes can be inferred according to
some safe proxies like surname and geolocation for the race. Hence, implicitly
utilizing the predicted protected classes based on the related proxies when
making decisions is an efficient approach to circumvent this issue and seek
just decisions. In this article, we propose a hierarchical random forest model
for prediction without explicitly involving protected classes. Simulation
experiments are conducted to show the performance of the hierarchical random
forest model. An example is analyzed from Boston police interview records to
illustrate the usefulness of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Baihan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1">Djallel Bouneffouf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15808">
                                    <div class="article-summary-box-inner">
                                        <span>In light of the COVID-19 pandemic, it is an open challenge and critical
practical problem to find a optimal way to dynamically prescribe the best
policies that balance both the governmental resources and epidemic control in
different countries and regions. To solve this multi-dimensional tradeoff of
exploitation and exploration, we formulate this technical challenge as a
contextual combinatorial bandit problem that jointly optimizes a multi-criteria
reward function. Given the historical daily cases in a region and the past
intervention plans in place, the agent should generate useful intervention
plans that policy makers can implement in real time to minimizing both the
number of daily COVID-19 cases and the stringency of the recommended
interventions. We prove this concept with simulations of multiple realistic
policy making scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge Representation Learning with Hypergraphs. (arXiv:2106.15845v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1">Jaehyeong Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1">Jinheon Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seul Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongki Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Minki Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15845">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks have recently achieved remarkable success in
representing graph-structured data, with rapid progress in both the node
embedding and graph pooling methods. Yet, they mostly focus on capturing
information from the nodes considering their connectivity, and not much work
has been done in representing the edges, which are essential components of a
graph. However, for tasks such as graph reconstruction and generation, as well
as graph classification tasks for which the edges are important for
discrimination, accurately representing edges of a given graph is crucial to
the success of the graph representation learning. To this end, we propose a
novel edge representation learning framework based on Dual Hypergraph
Transformation (DHT), which transforms the edges of a graph into the nodes of a
hypergraph. This dual hypergraph construction allows us to apply message
passing techniques for node representations to edges. After obtaining edge
representations from the hypergraphs, we then cluster or drop edges to obtain
holistic graph-level edge representations. We validate our edge representation
learning method with hypergraphs on diverse graph datasets for graph
representation and generation performance, on which our method largely
outperforms existing graph representation learning methods. Moreover, our edge
representation learning and pooling method also largely outperforms
state-of-the-art graph pooling methods on graph classification, not only
because of its accurate edge representation learning, but also due to its
lossless compression of the nodes and removal of irrelevant edges for effective
message passing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UAV-assisted Online Machine Learning over Multi-Tiered Networks: A Hierarchical Nested Personalized Federated Learning Approach. (arXiv:2106.15734v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Su Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1">Seyyedali Hosseinalipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorlatova_M/0/1/0/all/0/1">Maria Gorlatova</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1">Christopher G. Brinton</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1">Mung Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15734">
                                    <div class="article-summary-box-inner">
                                        <span>We consider distributed machine learning (ML) through unmanned aerial
vehicles (UAVs) for geo-distributed device clusters. We propose five new
technologies/techniques: (i) stratified UAV swarms with leader, worker, and
coordinator UAVs, (ii) hierarchical nested personalized federated learning
(HN-PFL): a holistic distributed ML framework for personalized model training
across the worker-leader-core network hierarchy, (iii) cooperative UAV resource
pooling for distributed ML using the UAVs&#x27; local computational capabilities,
(iv) aerial data caching and relaying for efficient data relaying to conduct
ML, and (v) concept/model drift, capturing online data variations at the
devices. We split the UAV-enabled model training problem as two parts. (a)
Network-aware HN-PFL, where we optimize a tradeoff between energy consumption
and ML model performance by configuring data offloading among devices-UAVs and
UAV-UAVs, UAVs&#x27; CPU frequencies, and mini-batch sizes subject to
communication/computation network heterogeneity. We tackle this optimization
problem via the method of posynomial condensation and propose a distributed
algorithm with a performance guarantee. (b) Macro-trajectory and learning
duration design, which we formulate as a sequential decision making problem,
tackled via deep reinforcement learning. Our simulations demonstrate the
superiority of our methodology with regards to the distributed ML performance,
the optimization of network resources, and the swarm trajectory efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curvature Graph Neural Network. (arXiv:2106.15762v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiawei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guohua Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15762">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have achieved great success in many graph-based
tasks. Much work is dedicated to empowering GNNs with the adaptive locality
ability, which enables measuring the importance of neighboring nodes to the
target node by a node-specific mechanism. However, the current node-specific
mechanisms are deficient in distinguishing the importance of nodes in the
topology structure. We believe that the structural importance of neighboring
nodes is closely related to their importance in aggregation. In this paper, we
introduce discrete graph curvature (the Ricci curvature) to quantify the
strength of structural connection of pairwise nodes. And we propose Curvature
Graph Neural Network (CGNN), which effectively improves the adaptive locality
ability of GNNs by leveraging the structural property of graph curvature. To
improve the adaptability of curvature to various datasets, we explicitly
transform curvature into the weights of neighboring nodes by the necessary
Negative Curvature Processing Module and Curvature Normalization Module. Then,
we conduct numerous experiments on various synthetic datasets and real-world
datasets. The experimental results on synthetic datasets show that CGNN
effectively exploits the topology structure information, and the performance is
improved significantly. CGNN outperforms the baselines on 5 dense node
classification benchmark datasets. This study deepens the understanding of how
to utilize advanced topology information and assign the importance of
neighboring nodes from the perspective of graph curvature and encourages us to
bridge the gap between graph theory and neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Graphical Models and Tensor Networks: A Hybrid Framework. (arXiv:2106.15666v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1">Jacob Miller</a>, <a href="http://arxiv.org/find/stat/1/au:+Roeder_G/0/1/0/all/0/1">Geoffrey Roeder</a>, <a href="http://arxiv.org/find/stat/1/au:+Bradley_T/0/1/0/all/0/1">Tai-Danae Bradley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15666">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate a correspondence between two formalisms for discrete
probabilistic modeling: probabilistic graphical models (PGMs) and tensor
networks (TNs), a powerful modeling framework for simulating complex quantum
systems. The graphical calculus of PGMs and TNs exhibits many similarities,
with discrete undirected graphical models (UGMs) being a special case of TNs.
However, more general probabilistic TN models such as Born machines (BMs)
employ complex-valued hidden states to produce novel forms of correlation among
the probabilities. While representing a new modeling resource for capturing
structure in discrete probability distributions, this behavior also renders the
direct application of standard PGM tools impossible. We aim to bridge this gap
by introducing a hybrid PGM-TN formalism that integrates quantum-like
correlations into PGM models in a principled manner, using the
physically-motivated concept of decoherence. We first prove that applying
decoherence to the entirety of a BM model converts it into a discrete UGM, and
conversely, that any subgraph of a discrete UGM can be represented as a
decohered BM. This method allows a broad family of probabilistic TN models to
be encoded as partially decohered BMs, a fact we leverage to combine the
representational strengths of both model families. We experimentally verify the
performance of such hybrid models in a sequential modeling task, and identify
promising uses of our method within the context of existing applications of
graphical models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diff2Dist: Learning Spectrally Distinct Edge Functions, with Applications to Cell Morphology Analysis. (arXiv:2106.15716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scott_C/0/1/0/all/0/1">Cory Braker Scott</a>, <a href="http://arxiv.org/find/cs/1/au:+Mjolsness_E/0/1/0/all/0/1">Eric Mjolsness</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyen_D/0/1/0/all/0/1">Diane Oyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodera_C/0/1/0/all/0/1">Chie Kodera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchez_D/0/1/0/all/0/1">David Bouchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Uyttewaal_M/0/1/0/all/0/1">Magalie Uyttewaal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15716">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for learning &quot;spectrally descriptive&quot; edge weights for
graphs. We generalize a previously known distance measure on graphs (Graph
Diffusion Distance), thereby allowing it to be tuned to minimize an arbitrary
loss function. Because all steps involved in calculating this modified GDD are
differentiable, we demonstrate that it is possible for a small neural network
model to learn edge weights which minimize loss. GDD alone does not effectively
discriminate between graphs constructed from shoot apical meristem images of
wild-type vs. mutant \emph{Arabidopsis thaliana} specimens. However, training
edge weights and kernel parameters with contrastive loss produces a learned
distance metric with large margins between these graph categories. We
demonstrate this by showing improved performance of a simple
k-nearest-neighbors classifier on the learned distance matrix. We also
demonstrate a further application of this method to biological image analysis:
once trained, we use our model to compute the distance between the biological
graphs and a set of graphs output by a cell division simulator. This allows us
to identify simulation parameter regimes which are similar to each class of
graph in our original dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exponential Weights Algorithms for Selective Learning. (arXiv:2106.15662v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_M/0/1/0/all/0/1">Mingda Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1">Gregory Valiant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15662">
                                    <div class="article-summary-box-inner">
                                        <span>We study the selective learning problem introduced by Qiao and Valiant
(2019), in which the learner observes $n$ labeled data points one at a time. At
a time of its choosing, the learner selects a window length $w$ and a model
$\hat\ell$ from the model class $\mathcal{L}$, and then labels the next $w$
data points using $\hat\ell$. The excess risk incurred by the learner is
defined as the difference between the average loss of $\hat\ell$ over those $w$
data points and the smallest possible average loss among all models in
$\mathcal{L}$ over those $w$ data points.

We give an improved algorithm, termed the hybrid exponential weights
algorithm, that achieves an expected excess risk of $O((\log\log|\mathcal{L}| +
\log\log n)/\log n)$. This result gives a doubly exponential improvement in the
dependence on $|\mathcal{L}|$ over the best known bound of
$O(\sqrt{|\mathcal{L}|/\log n})$. We complement the positive result with an
almost matching lower bound, which suggests the worst-case optimality of the
algorithm.

We also study a more restrictive family of learning algorithms that are
bounded-recall in the sense that when a prediction window of length $w$ is
chosen, the learner&#x27;s decision only depends on the most recent $w$ data points.
We analyze an exponential weights variant of the ERM algorithm in Qiao and
Valiant (2019). This new algorithm achieves an expected excess risk of
$O(\sqrt{\log |\mathcal{L}|/\log n})$, which is shown to be nearly optimal
among all bounded-recall learners. Our analysis builds on a generalized version
of the selective mean prediction problem in Drucker (2013); Qiao and Valiant
(2019), which may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Errors and Estimating Accuracy on Unlabeled Data with Self-training Ensembles. (arXiv:2106.15728v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiefeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Frederick Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Avci_B/0/1/0/all/0/1">Besim Avci</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1">Somesh Jha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15728">
                                    <div class="article-summary-box-inner">
                                        <span>When a deep learning model is deployed in the wild, it can encounter test
data drawn from distributions different from the training data distribution and
suffer drop in performance. For safe deployment, it is essential to estimate
the accuracy of the pre-trained model on the test data. However, the labels for
the test inputs are usually not immediately available in practice, and
obtaining them can be expensive. This observation leads to two challenging
tasks: (1) unsupervised accuracy estimation, which aims to estimate the
accuracy of a pre-trained classifier on a set of unlabeled test inputs; (2)
error detection, which aims to identify mis-classified test inputs. In this
paper, we propose a principled and practically effective framework that
simultaneously addresses the two tasks. The proposed framework iteratively
learns an ensemble of models to identify mis-classified data points and
performs self-training to improve the ensemble with the identified points.
Theoretical analysis demonstrates that our framework enjoys provable guarantees
for both accuracy estimation and error detection under mild conditions readily
satisfied by practical deep learning models. Along with the framework, we
proposed and experimented with two instantiations and achieved state-of-the-art
results on 59 tasks. For example, on iWildCam, one instantiation reduces the
estimation error for unsupervised accuracy estimation by at least 70% and
improves the F1 score for error detection by at least 4.7% compared to existing
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiagent Deep Reinforcement Learning: Challenges and Directions Towards Human-Like Approaches. (arXiv:2106.15691v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Annie Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Back_T/0/1/0/all/0/1">Thomas B&#xe4;ck</a>, <a href="http://arxiv.org/find/cs/1/au:+Kononova_A/0/1/0/all/0/1">Anna V. Kononova</a>, <a href="http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1">Aske Plaat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15691">
                                    <div class="article-summary-box-inner">
                                        <span>This paper surveys the field of multiagent deep reinforcement learning. The
combination of deep neural networks with reinforcement learning has gained
increased traction in recent years and is slowly shifting the focus from
single-agent to multiagent environments. Dealing with multiple agents is
inherently more complex as (a) the future rewards depend on the joint actions
of multiple players and (b) the computational complexity of functions
increases. We present the most common multiagent problem representations and
their main challenges, and identify five research areas that address one or
more of these challenges: centralised training and decentralised execution,
opponent modelling, communication, efficient coordination, and reward shaping.
We find that many computational studies rely on unrealistic assumptions or are
not generalisable to other settings; they struggle to overcome the curse of
dimensionality or nonstationarity. Approaches from psychology and sociology
capture promising relevant behaviours such as communication and coordination.
We suggest that, for multiagent reinforcement learning to be successful, future
research addresses these challenges with an interdisciplinary approach to open
up new possibilities for more human-oriented solutions in multiagent
reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAT Based Analogy Evaluation Framework for Persian Word Embeddings. (arXiv:2106.15674v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmoudi_S/0/1/0/all/0/1">Seyyed Ehsan Mahmoudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsfard_M/0/1/0/all/0/1">Mehrnoush Shamsfard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15674">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years there has been a special interest in word embeddings as a new
approach to convert words to vectors. It has been a focal point to understand
how much of the semantics of the the words has been transferred into embedding
vectors. This is important as the embedding is going to be used as the basis
for downstream NLP applications and it will be costly to evaluate the
application end-to-end in order to identify quality of the used embedding
model. Generally the word embeddings are evaluated through a number of tests,
including analogy test. In this paper we propose a test framework for Persian
embedding models. Persian is a low resource language and there is no rich
semantic benchmark to evaluate word embedding models for this language. In this
paper we introduce an evaluation framework including a hand crafted Persian SAT
based analogy dataset, a colliquial test set (specific to Persian) and a
benchmark to study the impact of various parameters on the semantic evaluation
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Literature Review of Critical Features and General Issues of Freely Available mHealth Apps For Dietary Assessment. (arXiv:2008.09883v3 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tahir_G/0/1/0/all/0/1">Ghalib Ahmed Tahir</a>, <a href="http://arxiv.org/find/cs/1/au:+Loo_C/0/1/0/all/0/1">Chu Kiong Loo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moy_F/0/1/0/all/0/1">Foong Ming Moy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_N/0/1/0/all/0/1">Nadine Kong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09883">
                                    <div class="article-summary-box-inner">
                                        <span>Obesity is known to lower the quality of life substantially. It is often
associated with increased chances of non-communicable diseases such as
diabetes, cardiovascular problems, different types of cancers, etc. Evidence
suggests that diet-related mobile applications play a vital role in assisting
an individual in making healthier choices and keeping track of food intake.
However, due to an abundance of similar applications, it becomes pertinent to
evaluate each of them in terms of functionality, usability, and possible design
issues to truly determine state-of-the-art solutions for the future. Since
these applications involve implementing multiple user requirements and
recommendations from different dietitians, the evaluation becomes quite
complex. Therefore, this study aims to review existing dietary applications at
length to highlight key features and problems that enhance or undermine an
application&#x27;s usability. For this purpose, we have examined the published
literature from various scientific databases of the CINAHL, Science Direct, and
PUBMED. Out of our findings, fifty-six primary studies met our inclusion
criteria after filtering out titles, abstracts, and full text. A total of 35
apps are analyzed from the selected studies. Our detailed analysis concluded
the comprehensiveness of freely available mHealth applications from users and
dietitians&#x27; frames of reference. Furthermore, we have also specified potential
future challenges and stated recommendations to help develop clinically
accurate diet-related applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Multi-modal Fusion Hashing via Hadamard Matrix. (arXiv:2009.12148v3 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Donglin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_Z/0/1/0/all/0/1">Zhenqiu Shu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12148">
                                    <div class="article-summary-box-inner">
                                        <span>Hashing plays an important role in information retrieval, due to its low
storage and high speed of processing. Among the techniques available in the
literature, multi-modal hashing, which can encode heterogeneous multi-modal
features into compact hash codes, has received particular attention. Most of
the existing multi-modal hashing methods adopt the fixed weighting factors to
fuse multiple modalities for any query data, which cannot capture the variation
of different queries. Besides, many methods introduce hyper-parameters to
balance many regularization terms that make the optimization harder. Meanwhile,
it is time-consuming and labor-intensive to set proper parameter values. The
limitations may significantly hinder their promotion in real applications. In
this paper, we propose a simple, yet effective method that is inspired by the
Hadamard matrix. The proposed method captures the multi-modal feature
information in an adaptive manner and preserves the discriminative semantic
information in the hash codes. Our framework is flexible and involves a very
few hyper-parameters. Extensive experimental results show the method is
effective and achieves superior performance compared to state-of-the-art
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AVLnet: Learning Audio-Visual Language Representations from Instructional Videos. (arXiv:2006.09199v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1">Andrew Rouditchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Boggust_A/0/1/0/all/0/1">Angie Boggust</a>, <a href="http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1">David Harwath</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Brian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_D/0/1/0/all/0/1">Dhiraj Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1">Samuel Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1">Kartik Audhkhasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuehne_H/0/1/0/all/0/1">Hilde Kuehne</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1">Rameswar Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1">Rogerio Feris</a>, <a href="http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1">Brian Kingsbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1">Michael Picheny</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09199">
                                    <div class="article-summary-box-inner">
                                        <span>Current methods for learning visually grounded language from videos often
rely on text annotation, such as human generated captions or machine generated
automatic speech recognition (ASR) transcripts. In this work, we introduce the
Audio-Video Language Network (AVLnet), a self-supervised network that learns a
shared audio-visual embedding space directly from raw video inputs. To
circumvent the need for text annotation, we learn audio-visual representations
from randomly segmented video clips and their raw audio waveforms. We train
AVLnet on HowTo100M, a large corpus of publicly available instructional videos,
and evaluate on image retrieval and video retrieval tasks, achieving
state-of-the-art performance. We perform analysis of AVLnet&#x27;s learned
representations, showing our model utilizes speech and natural sounds to learn
audio-visual concepts. Further, we propose a tri-modal model that jointly
processes raw audio, video, and text captions from videos to learn a
multi-modal semantic embedding space useful for text-video retrieval. Our code,
data, and trained models will be released at avlnet.csail.mit.edu</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the contextual factors affecting multimodal emotion recognition in videos. (arXiv:2004.13274v5 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1">Prasanta Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Raj Kumar Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinping Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13274">
                                    <div class="article-summary-box-inner">
                                        <span>Emotional expressions form a key part of user behavior on today&#x27;s digital
platforms. While multimodal emotion recognition techniques are gaining research
attention, there is a lack of deeper understanding on how visual and non-visual
features can be used to better recognize emotions in certain contexts, but not
others. This study analyzes the interplay between the effects of multimodal
emotion features derived from facial expressions, tone and text in conjunction
with two key contextual factors: i) gender of the speaker, and ii) duration of
the emotional episode. Using a large public dataset of 2,176 manually annotated
YouTube videos, we found that while multimodal features consistently
outperformed bimodal and unimodal features, their performance varied
significantly across different emotions, gender and duration contexts.
Multimodal features performed particularly better for male speakers in
recognizing most emotions. Furthermore, multimodal features performed
particularly better for shorter than for longer videos in recognizing neutral
and happiness, but not sadness and anger. These findings offer new insights
towards the development of more context-aware emotion recognition and
empathetic systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Model for Raw Audio Using Transformer Architectures. (arXiv:2106.16036v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1">Prateek Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chafe_C/0/1/0/all/0/1">Chris Chafe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16036">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel way of doing audio synthesis at the waveform
level using Transformer architectures. We propose a deep neural network for
generating waveforms, similar to wavenet \cite{oord2016wavenet}. This is fully
probabilistic, auto-regressive, and causal, i.e. each sample generated depends
only on the previously observed samples. Our approach outperforms a widely used
wavenet architecture by up to 9\% on a similar dataset for predicting the next
step. Using the attention mechanism, we enable the architecture to learn which
audio samples are important for the prediction of the future sample. We show
how causal transformer generative models can be used for raw waveform
synthesis. We also show that this performance can be improved by another 2\% by
conditioning samples over a wider context. The flexibility of the current model
to synthesize audio from latent representations suggests a large number of
potential applications. The novel approach of using generative transformer
architectures for raw audio synthesis is, however, still far away from
generating any meaningful music, without using latent codes/meta-data to aid
the generation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word-level Sign Language Recognition with Multi-stream Neural Networks Focusing on Local Regions. (arXiv:2106.15989v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maruyama_M/0/1/0/all/0/1">Mizuki Maruyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1">Shuvozit Ghose</a>, <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Katsufumi Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1">Partha Pratim Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwamura_M/0/1/0/all/0/1">Masakazu Iwamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshioka_M/0/1/0/all/0/1">Michifumi Yoshioka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15989">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Word-level Sign Language Recognition (WSLR) research has
gained popularity in the computer vision community, and thus various approaches
have been proposed. Among these approaches, the method using I3D network
achieves the highest recognition accuracy on large public datasets for WSLR.
However, the method with I3D only utilizes appearance information of the upper
body of the signers to recognize sign language words. On the other hand, in
WSLR, the information of local regions, such as the hand shape and facial
expression, and the positional relationship among the body and both hands are
important. Thus in this work, we utilized local region images of both hands and
face, along with skeletal information to capture local information and the
positions of both hands relative to the body, respectively. In other words, we
propose a novel multi-stream WSLR framework, in which a stream with local
region images and a stream with skeletal information are introduced by
extending I3D network to improve the recognition accuracy of WSLR. From the
experimental results on WLASL dataset, it is evident that the proposed method
has achieved about 15% improvement in the Top-1 accuracy than the existing
conventional methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affective Image Content Analysis: Two Decades Review and New Perspectives. (arXiv:2106.16125v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sicheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xingxu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jufeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_G/0/1/0/all/0/1">Guoli Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guiguang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16125">
                                    <div class="article-summary-box-inner">
                                        <span>Images can convey rich semantics and induce various emotions in viewers.
Recently, with the rapid advancement of emotional intelligence and the
explosive growth of visual data, extensive research efforts have been dedicated
to affective image content analysis (AICA). In this survey, we will
comprehensively review the development of AICA in the recent two decades,
especially focusing on the state-of-the-art methods with respect to three main
challenges -- the affective gap, perception subjectivity, and label noise and
absence. We begin with an introduction to the key emotion representation models
that have been widely employed in AICA and description of available datasets
for performing evaluation with quantitative comparison of label noise and
dataset bias. We then summarize and compare the representative approaches on
(1) emotion feature extraction, including both handcrafted and deep features,
(2) learning methods on dominant emotion recognition, personalized emotion
prediction, emotion distribution learning, and learning from noisy data or few
labels, and (3) AICA based applications. Finally, we discuss some challenges
and promising research directions in the future, such as image content and
context understanding, group emotion clustering, and viewer-image interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-30">2021-06-30</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Recalibrated Aggregation Network for Medical Code Prediction. (arXiv:2104.00952v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shaoxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>, <a href="http://arxiv.org/find/cs/1/au:+Marttinen_P/0/1/0/all/0/1">Pekka Marttinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00952">
                                    <div class="article-summary-box-inner">
                                        <span>Medical coding translates professionally written medical reports into
standardized codes, which is an essential part of medical information systems
and health insurance reimbursement. Manual coding by trained human coders is
time-consuming and error-prone. Thus, automated coding algorithms have been
developed, building especially on the recent advances in machine learning and
deep neural networks. To solve the challenges of encoding lengthy and noisy
clinical documents and capturing code associations, we propose a multitask
recalibrated aggregation network. In particular, multitask learning shares
information across different coding schemes and captures the dependencies
between different medical codes. Feature recalibration and aggregation in
shared modules enhance representation learning for lengthy notes. Experiments
with a real-world MIMIC-III dataset show significantly improved predictive
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Span-based Joint Entity and Relation Extraction with Transformer Pre-training. (arXiv:1909.07755v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eberts_M/0/1/0/all/0/1">Markus Eberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulges_A/0/1/0/all/0/1">Adrian Ulges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.07755">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce SpERT, an attention model for span-based joint entity and
relation extraction. Our key contribution is a light-weight reasoning on BERT
embeddings, which features entity recognition and filtering, as well as
relation classification with a localized, marker-free context representation.
The model is trained using strong within-sentence negative samples, which are
efficiently extracted in a single BERT pass. These aspects facilitate a search
over all spans in the sentence.

In ablation studies, we demonstrate the benefits of pre-training, strong
negative sampling and localized context. Our model outperforms prior work by up
to 2.6% F1 score on several datasets for joint entity and relation extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning to Compositionally Generalize. (arXiv:2106.04252v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conklin_H/0/1/0/all/0/1">Henry Conklin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bailin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kenny Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1">Ivan Titov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04252">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language is compositional; the meaning of a sentence is a function of
the meaning of its parts. This property allows humans to create and interpret
novel sentences, generalizing robustly outside their prior experience. Neural
networks have been shown to struggle with this kind of generalization, in
particular performing poorly on tasks designed to assess compositional
generalization (i.e. where training and testing distributions differ in ways
that would be trivial for a compositional strategy to resolve). Their poor
performance on these tasks may in part be due to the nature of supervised
learning which assumes training and testing data to be drawn from the same
distribution. We implement a meta-learning augmented version of supervised
learning whose objective directly optimizes for out-of-distribution
generalization. We construct pairs of tasks for meta-learning by sub-sampling
existing training data. Each pair of tasks is constructed to contain relevant
examples, as determined by a similarity metric, in an effort to inhibit models
from memorizing their input. Experimental results on the COGS and SCAN datasets
show that our similarity-driven meta-learning can improve generalization
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Natural Language Understanding with Explanations as Latent Variables. (arXiv:2011.05268v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jinyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chenyan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05268">
                                    <div class="article-summary-box-inner">
                                        <span>Recently generating natural language explanations has shown very promising
results in not only offering interpretable explanations but also providing
additional information and supervision for prediction. However, existing
approaches usually require a large set of human annotated explanations for
training while collecting a large set of explanations is not only time
consuming but also expensive. In this paper, we develop a general framework for
interpretable natural language understanding that requires only a small set of
human annotated explanations for training. Our framework treats natural
language explanations as latent variables that model the underlying reasoning
process of a neural model. We develop a variational EM framework for
optimization where an explanation generation module and an
explanation-augmented prediction module are alternatively optimized and
mutually enhance each other. Moreover, we further propose an explanation-based
self-training method under this framework for semi-supervised learning. It
alternates between assigning pseudo-labels to unlabeled data and generating new
explanations to iteratively improve each other. Experiments on two natural
language understanding tasks demonstrate that our framework can not only make
effective predictions in both supervised and semi-supervised settings, but also
generate good natural language explanation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Arabic Speech Recognition by End-to-End, Modular Systems and Human. (arXiv:2101.08454v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hussein_A/0/1/0/all/0/1">Amir Hussein</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08454">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in automatic speech recognition (ASR) have achieved accuracy
levels comparable to human transcribers, which led researchers to debate if the
machine has reached human performance. Previous work focused on the English
language and modular hidden Markov model-deep neural network (HMM-DNN) systems.
In this paper, we perform a comprehensive benchmarking for end-to-end
transformer ASR, modular HMM-DNN ASR, and human speech recognition (HSR) on the
Arabic language and its dialects. For the HSR, we evaluate linguist performance
and lay-native speaker performance on a new dataset collected as a part of this
study. For ASR the end-to-end work led to 12.5%, 27.5%, 33.8% WER; a new
performance milestone for the MGB2, MGB3, and MGB5 challenges respectively. Our
results suggest that human performance in the Arabic language is still
considerably better than the machine with an absolute WER gap of 3.5% on
average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hate speech detection using static BERT embeddings. (arXiv:2106.15537v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajput_G/0/1/0/all/0/1">Gaurav Rajput</a>, <a href="http://arxiv.org/find/cs/1/au:+punn_N/0/1/0/all/0/1">Narinder Singh punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15537">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing popularity of social media platforms hate speech is emerging
as a major concern, where it expresses abusive speech that targets specific
group characteristics, such as gender, religion or ethnicity to spread
violence. Earlier people use to verbally deliver hate speeches but now with the
expansion of technology, some people are deliberately using social media
platforms to spread hate by posting, sharing, commenting, etc. Whether it is
Christchurch mosque shootings or hate crimes against Asians in west, it has
been observed that the convicts are very much influenced from hate text present
online. Even though AI systems are in place to flag such text but one of the
key challenges is to reduce the false positive rate (marking non hate as hate),
so that these systems can detect hate speech without undermining the freedom of
expression. In this paper, we use ETHOS hate speech detection dataset and
analyze the performance of hate speech detection classifier by replacing or
integrating the word embeddings (fastText (FT), GloVe (GV) or FT + GV) with
static BERT embeddings (BE). With the extensive experimental trails it is
observed that the neural network performed better with static BE compared to
using FT, GV or FT + GV as word embeddings. In comparison to fine-tuned BERT,
one metric that significantly improved is specificity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Electronic Health Record Coding through Graph Contrastive Learning. (arXiv:2106.15467v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shanshan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengjie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhaochun Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Huasheng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1">Qiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1">Evangelos Kanoulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15467">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic health record (EHR) coding is the task of assigning ICD codes to
each EHR. Most previous studies either only focus on the frequent ICD codes or
treat rare and frequent ICD codes in the same way. These methods perform well
on frequent ICD codes but due to the extremely unbalanced distribution of ICD
codes, the performance on rare ones is far from satisfactory. We seek to
improve the performance for both frequent and rare ICD codes by using a
contrastive graph-based EHR coding framework, CoGraph, which re-casts EHR
coding as a few-shot learning task. First, we construct a heterogeneous EHR
word-entity (HEWE) graph for each EHR, where the words and entities extracted
from an EHR serve as nodes and the relations between them serve as edges. Then,
CoGraph learns similarities and dissimilarities between HEWE graphs from
different ICD codes so that information can be transferred among them. In a
few-shot learning scenario, the model only has access to frequent ICD codes
during training, which might force it to encode features that are useful for
frequent ICD codes only. To mitigate this risk, CoGraph devises two graph
contrastive learning schemes, GSCL and GECL, that exploit the HEWE graph
structures so as to encode transferable features. GSCL utilizes the
intra-correlation of different sub-graphs sampled from HEWE graphs while GECL
exploits the inter-correlation among HEWE graphs at different clinical stages.
Experiments on the MIMIC-III benchmark dataset show that CoGraph significantly
outperforms state-of-the-art methods on EHR coding, not only on frequent ICD
codes, but also on rare codes, in terms of several evaluation indicators. On
frequent ICD codes, GSCL and GECL improve the classification accuracy and F1 by
1.31% and 0.61%, respectively, and on rare ICD codes CoGraph has more obvious
improvements by 2.12% and 2.95%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differential Privacy for Credit Risk Model. (arXiv:2106.15343v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maniar_T/0/1/0/all/0/1">Tabish Maniar</a>, <a href="http://arxiv.org/find/cs/1/au:+Akkinepally_A/0/1/0/all/0/1">Alekhya Akkinepally</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anantha Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15343">
                                    <div class="article-summary-box-inner">
                                        <span>The use of machine learning algorithms to model user behavior and drive
business decisions has become increasingly commonplace, specifically providing
intelligent recommendations to automated decision making. This has led to an
increase in the use of customers personal data to analyze customer behavior and
predict their interests in a companys products. Increased use of this customer
personal data can lead to better models but also to the potential of customer
data being leaked, reverse engineered, and mishandled. In this paper, we assess
differential privacy as a solution to address these privacy problems by
building privacy protections into the data engineering and model training
stages of predictive model development. Our interest is a pragmatic
implementation in an operational environment, which necessitates a general
purpose differentially private modeling framework, and we evaluate one such
tool from LeapYear as applied to the Credit Risk modeling domain. Credit Risk
Model is a major modeling methodology in banking and finance where user data is
analyzed to determine the total Expected Loss to the bank. We examine the
application of differential privacy on the credit risk model and evaluate the
performance of a Differentially Private Model with a Non Differentially Private
Model. Credit Risk Model is a major modeling methodology in banking and finance
where users data is analyzed to determine the total Expected Loss to the bank.
In this paper, we explore the application of differential privacy on the credit
risk model and evaluate the performance of a Non Differentially Private Model
with Differentially Private Model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scientific Credibility of Machine Translation Research: A Meta-Evaluation of 769 Papers. (arXiv:2106.15195v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marie_B/0/1/0/all/0/1">Benjamin Marie</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujita_A/0/1/0/all/0/1">Atsushi Fujita</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubino_R/0/1/0/all/0/1">Raphael Rubino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15195">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the first large-scale meta-evaluation of machine
translation (MT). We annotated MT evaluations conducted in 769 research papers
published from 2010 to 2020. Our study shows that practices for automatic MT
evaluation have dramatically changed during the past decade and follow
concerning trends. An increasing number of MT evaluations exclusively rely on
differences between BLEU scores to draw conclusions, without performing any
kind of statistical significance testing nor human evaluation, while at least
108 metrics claiming to be better than BLEU have been proposed. MT evaluations
in recent papers tend to copy and compare automatic metric scores from previous
work to claim the superiority of a method or an algorithm without confirming
neither exactly the same training, validating, and testing data have been used
nor the metric scores are comparable. Furthermore, tools for reporting
standardized metric scores are still far from being widely adopted by the MT
community. After showing how the accumulation of these pitfalls leads to
dubious evaluation, we propose a guideline to encourage better automatic MT
evaluation along with a simple meta-evaluation scoring method to assess its
credibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Static Models for Link Prediction in Temporal Knowledge Graphs. (arXiv:2106.15223v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radstok_W/0/1/0/all/0/1">Wessel Radstok</a>, <a href="http://arxiv.org/find/cs/1/au:+Chekol_M/0/1/0/all/0/1">Mel Chekol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15223">
                                    <div class="article-summary-box-inner">
                                        <span>The inclusion of temporal scopes of facts in knowledge graph embedding (KGE)
presents significant opportunities for improving the resulting embeddings, and
consequently for increased performance in downstream applications. Yet, little
research effort has focussed on this area and much of the carried out research
reports only marginally improved results compared to models trained without
temporal scopes (static models). Furthermore, rather than leveraging existing
work on static models, they introduce new models specific to temporal knowledge
graphs. We propose a novel perspective that takes advantage of the power of
existing static embedding models by focussing effort on manipulating the data
instead. Our method, SpliMe, draws inspiration from the field of signal
processing and early work in graph embedding. We show that SpliMe competes with
or outperforms the current state of the art in temporal KGE. Additionally, we
uncover issues with the procedure currently used to assess the performance of
static models on temporal graphs and introduce two ways to counteract them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hagerer_G/0/1/0/all/0/1">Gerhard Hagerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1">Wenbin Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Danner_H/0/1/0/all/0/1">Hannah Danner</a>, <a href="http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1">Georg Groh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15498">
                                    <div class="article-summary-box-inner">
                                        <span>Social media offer plenty of information to perform market research in order
to meet the requirements of customers. One way how this research is conducted
is that a domain expert gathers and categorizes user-generated content into a
complex and fine-grained class structure. In many of such cases, little data
meets complex annotations. It is not yet fully understood how this can be
leveraged successfully for classification. We examine the classification
accuracy of expert labels when used with a) many fine-grained classes and b)
few abstract classes. For scenario b) we compare abstract class labels given by
the domain expert as baseline and by automatic hierarchical clustering. We
compare this to another baseline where the entire class structure is given by a
completely unsupervised clustering approach. By doing so, this work can serve
as an example of how complex expert annotations are potentially beneficial and
can be utilized in the most optimal way for opinion mining in highly specific
domains. By exploring across a range of techniques and experiments, we find
that automated class abstraction approaches in particular the unsupervised
approach performs remarkably well against domain expert baseline on text
classification tasks. This has the potential to inspire opinion mining
applications in order to support market researchers in practice and to inspire
fine-grained automated content analysis on a large scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic Modeling Based Extractive Text Summarization. (arXiv:2106.15313v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Issam_K/0/1/0/all/0/1">Kalliath Abdul Rasheed Issam</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shivam Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+N_S/0/1/0/all/0/1">Subalalitha C. N</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15313">
                                    <div class="article-summary-box-inner">
                                        <span>Text summarization is an approach for identifying important information
present within text documents. This computational technique aims to generate
shorter versions of the source text, by including only the relevant and salient
information present within the source text. In this paper, we propose a novel
method to summarize a text document by clustering its contents based on latent
topics produced using topic modeling techniques and by generating extractive
summaries for each of the identified text clusters. All extractive
sub-summaries are later combined to generate a summary for any given source
document. We utilize the lesser used and challenging WikiHow dataset in our
approach to text summarization. This dataset is unlike the commonly used news
datasets which are available for text summarization. The well-known news
datasets present their most important information in the first few lines of
their source texts, which make their summarization a lesser challenging task
when compared to summarizing the WikiHow dataset. Contrary to these news
datasets, the documents in the WikiHow dataset are written using a generalized
approach and have lesser abstractedness and higher compression ratio, thus
proposing a greater challenge to generate summaries. A lot of the current
state-of-the-art text summarization techniques tend to eliminate important
information present in source documents in the favor of brevity. Our proposed
technique aims to capture all the varied information present in source
documents. Although the dataset proved challenging, after performing extensive
tests within our experimental setup, we have discovered that our model produces
encouraging ROUGE results and summaries when compared to the other published
extractive and abstractive text summarization models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Efficacy of Automatically Generated Counterfactuals for Sentiment Analysis. (arXiv:2106.15231v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Linyi_Y/0/1/0/all/0/1">Yang Linyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiazheng_L/0/1/0/all/0/1">Li Jiazheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Padraig_C/0/1/0/all/0/1">Cunningham P&#xe1;draig</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zhang Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Barry_S/0/1/0/all/0/1">Smyth Barry</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruihai_D/0/1/0/all/0/1">Dong Ruihai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15231">
                                    <div class="article-summary-box-inner">
                                        <span>While state-of-the-art NLP models have been achieving the excellent
performance of a wide range of tasks in recent years, important questions are
being raised about their robustness and their underlying sensitivity to
systematic biases that may exist in their training and test data. Such issues
come to be manifest in performance problems when faced with out-of-distribution
data in the field. One recent solution has been to use counterfactually
augmented datasets in order to reduce any reliance on spurious patterns that
may exist in the original data. Producing high-quality augmented data can be
costly and time-consuming as it usually needs to involve human feedback and
crowdsourcing efforts. In this work, we propose an alternative by describing
and evaluating an approach to automatically generating counterfactual data for
data augmentation and explanation. A comprehensive evaluation on several
different datasets and using a variety of state-of-the-art benchmarks
demonstrate how our approach can achieve significant improvements in model
performance when compared to models training on the original data and even when
compared to models trained with the benefit of human-generated augmented data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Interaction of Belief Bias and Explanations. (arXiv:2106.15355v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_A/0/1/0/all/0/1">Ana Valeria Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1">Anna Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1">Anders S&#xf8;gaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15355">
                                    <div class="article-summary-box-inner">
                                        <span>A myriad of explainability methods have been proposed in recent years, but
there is little consensus on how to evaluate them. While automatic metrics
allow for quick benchmarking, it isn&#x27;t clear how such metrics reflect human
interaction with explanations. Human evaluation is of paramount importance, but
previous protocols fail to account for belief biases affecting human
performance, which may lead to misleading conclusions. We provide an overview
of belief bias, its role in human evaluation, and ideas for NLP practitioners
on how to account for it. For two experimental paradigms, we present a case
study of gradient-based explainability introducing simple ways to account for
humans&#x27; prior beliefs: models of varying quality and adversarial examples. We
show that conclusions about the highest performing methods change when
introducing such controls, pointing to the importance of accounting for belief
bias in evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis. (arXiv:2106.15153v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1">Jinhyeok Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Bae_J/0/1/0/all/0/1">Jae-Sung Bae</a>, <a href="http://arxiv.org/find/eess/1/au:+Bak_T/0/1/0/all/0/1">Taejun Bak</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1">Youngik Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_H/0/1/0/all/0/1">Hoon-Young Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15153">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in neural multi-speaker text-to-speech (TTS) models have
enabled the generation of reasonably good speech quality with a single model
and made it possible to synthesize the speech of a speaker with limited
training data. Fine-tuning to the target speaker data with the multi-speaker
model can achieve better quality, however, there still exists a gap compared to
the real speech sample and the model depends on the speaker. In this work, we
propose GANSpeech, which is a high-fidelity multi-speaker TTS model that adopts
the adversarial training method to a non-autoregressive multi-speaker TTS
model. In addition, we propose simple but efficient automatic scaling methods
for feature matching loss used in adversarial training. In the subjective
listening tests, GANSpeech significantly outperformed the baseline
multi-speaker FastSpeech and FastSpeech2 models, and showed a better MOS score
than the speaker-specific fine-tuned FastSpeech2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Technique To Conversational Machine Reading. (arXiv:2106.15247v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ochieng_P/0/1/0/all/0/1">Peter Ochieng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mugambi_D/0/1/0/all/0/1">Dennis Mugambi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15247">
                                    <div class="article-summary-box-inner">
                                        <span>Conversational machine reading (CMR) tools have seen a rapid progress in the
recent past. The current existing tools rely on the supervised learning
technique which require labeled dataset for their training. The supervised
technique necessitates that for every new rule text, a manually labeled dataset
must be created. This is tedious and error prone. This paper introduces and
demonstrates how unsupervised learning technique can be applied in the
development of CMR. Specifically, we demonstrate how unsupervised learning can
be used in rule extraction and entailment modules of CMR. Compared to the
current best CMR tool, our developed framework reports 3.3% improvement in
micro averaged accuracy and 1.4 % improvement in macro averaged accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Arabic Medical Dataset for Diseases Classification. (arXiv:2106.15236v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hammoud_J/0/1/0/all/0/1">Jaafar Hammoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatian_A/0/1/0/all/0/1">Aleksandra Vatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobrenko_N/0/1/0/all/0/1">Natalia Dobrenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedernikov_N/0/1/0/all/0/1">Nikolai Vedernikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalyto_A/0/1/0/all/0/1">Anatoly Shalyto</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusarova_N/0/1/0/all/0/1">Natalia Gusarova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15236">
                                    <div class="article-summary-box-inner">
                                        <span>The Arabic language suffers from a great shortage of datasets suitable for
training deep learning models, and the existing ones include general
non-specialized classifications. In this work, we introduce a new Arab medical
dataset, which includes two thousand medical documents collected from several
Arabic medical websites, in addition to the Arab Medical Encyclopedia. The
dataset was built for the task of classifying texts and includes 10 classes
(Blood, Bone, Cardiovascular, Ear, Endocrine, Eye, Gastrointestinal, Immune,
Liver and Nephrological) diseases. Experiments on the dataset were performed by
fine-tuning three pre-trained models: BERT from Google, Arabert that based on
BERT with large Arabic corpus, and AraBioNER that based on Arabert with Arabic
medical corpus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Miscellaneous Other-Class Words for Few-shot Named Entity Recognition. (arXiv:2106.15167v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1">Meihan Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yixin Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minghui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Lei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanzi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15167">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot Named Entity Recognition (NER) exploits only a handful of
annotations to identify and classify named entity mentions. Prototypical
network shows superior performance on few-shot NER. However, existing
prototypical methods fail to differentiate rich semantics in other-class words,
which will aggravate overfitting under few shot scenario. To address the issue,
we propose a novel model, Mining Undefined Classes from Other-class (MUCO),
that can automatically induce different undefined classes from the other class
to improve few-shot NER. With these extra-labeled undefined classes, our method
will improve the discriminative ability of NER classifier and enhance the
understanding of predefined classes with stand-by semantic knowledge.
Experimental results demonstrate that our model outperforms five
state-of-the-art models in both 1-shot and 5-shots settings on four NER
benchmarks. We will release the code upon acceptance. The source code is
released on https: //github.com/shuaiwa16/OtherClassNER.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking the Evaluation of Neural Machine Translation. (arXiv:2106.15217v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jianhao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fandong Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15217">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of neural machine translation systems is usually built upon
generated translation of a certain decoding method (e.g., beam search) with
evaluation metrics over the generated translation (e.g., BLEU). However, this
evaluation framework suffers from high search errors brought by heuristic
search algorithms and is limited by its nature of evaluation over one best
candidate. In this paper, we propose a novel evaluation protocol, which not
only avoids the effect of search errors but provides a system-level evaluation
in the perspective of model ranking. In particular, our method is based on our
newly proposed exact top-$k$ decoding instead of beam search. Our approach
evaluates model errors by the distance between the candidate spaces scored by
the references and the model respectively. Extensive experiments on WMT&#x27;14
English-German demonstrate that bad ranking ability is connected to the
well-known beam search curse, and state-of-the-art Transformer models are
facing serious ranking errors. By evaluating various model architectures and
techniques, we provide several interesting findings. Finally, to effectively
approximate the exact search algorithm with same time cost as original beam
search, we present a minimum heap augmented beam search algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation based meta-learning for few-shot spoken intent recognition. (arXiv:2106.15238v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1">Ashish Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharadwaj_S/0/1/0/all/0/1">Samarth Bharadwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Khare_S/0/1/0/all/0/1">Shreya Khare</a>, <a href="http://arxiv.org/find/cs/1/au:+Chemmengath_S/0/1/0/all/0/1">Saneem Chemmengath</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_K/0/1/0/all/0/1">Karthik Sankaranarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1">Brian Kingsbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15238">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken intent detection has become a popular approach to interface with
various smart devices with ease. However, such systems are limited to the
preset list of intents-terms or commands, which restricts the quick
customization of personal devices to new intents. This paper presents a
few-shot spoken intent classification approach with task-agnostic
representations via meta-learning paradigm. Specifically, we leverage the
popular representation-based meta-learning learning to build a task-agnostic
representation of utterances, that then use a linear classifier for prediction.
We evaluate three such approaches on our novel experimental protocol developed
on two popular spoken intent classification datasets: Google Commands and the
Fluent Speech Commands dataset. For a 5-shot (1-shot) classification of novel
classes, the proposed framework provides an average classification accuracy of
88.6% (76.3%) on the Google Commands dataset, and 78.5% (64.2%) on the Fluent
Speech Commands dataset. The performance is comparable to traditionally
supervised classification models with abundant training samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple and Efficient Probabilistic Language model for Code-Mixed Text. (arXiv:2106.15102v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">M Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">M M Sufyan Beg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikram_A/0/1/0/all/0/1">Asma Ikram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15102">
                                    <div class="article-summary-box-inner">
                                        <span>The conventional natural language processing approaches are not accustomed to
the social media text due to colloquial discourse and non-homogeneous
characteristics. Significantly, the language identification in a multilingual
document is ascertained to be a preceding subtask in several information
extraction applications such as information retrieval, named entity
recognition, relation extraction, etc. The problem is often more challenging in
code-mixed documents wherein foreign languages words are drawn into base
language while framing the text. The word embeddings are powerful language
modeling tools for representation of text documents useful in obtaining
similarity between words or documents. We present a simple probabilistic
approach for building efficient word embedding for code-mixed text and
exemplifying it over language identification of Hindi-English short test
messages scrapped from Twitter. We examine its efficacy for the classification
task using bidirectional LSTMs and SVMs and observe its improved scores over
various existing code-mixed embeddings</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Machine Translation for Low-Resource Languages: A Survey. (arXiv:2106.15115v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ranathunga_S/0/1/0/all/0/1">Surangika Ranathunga</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">En-Shiun Annie Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Skenduli_M/0/1/0/all/0/1">Marjana Prifti Skenduli</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekhar_R/0/1/0/all/0/1">Ravi Shekhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1">Mehreen Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaur_R/0/1/0/all/0/1">Rishemjit Kaur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15115">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Machine Translation (NMT) has seen a tremendous spurt of growth in
less than ten years, and has already entered a mature phase. While considered
as the most widely used solution for Machine Translation, its performance on
low-resource language pairs still remains sub-optimal compared to the
high-resource counterparts, due to the unavailability of large parallel
corpora. Therefore, the implementation of NMT techniques for low-resource
language pairs has been receiving the spotlight in the recent NMT research
arena, thus leading to a substantial amount of research reported on this topic.
This paper presents a detailed survey of research advancements in low-resource
language NMT (LRL-NMT), along with a quantitative analysis aimed at identifying
the most popular solutions. Based on our findings from reviewing previous work,
this survey paper provides a set of guidelines to select the possible NMT
technique for a given LRL data setting. It also presents a holistic view of the
LRL-NMT research landscape and provides a list of recommendations to further
enhance the research efforts on LRL-NMT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Don&#x27;t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation. (arXiv:2106.15078v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zichao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_T/0/1/0/all/0/1">Tianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15078">
                                    <div class="article-summary-box-inner">
                                        <span>Neural text generation models are typically trained by maximizing
log-likelihood with the sequence cross entropy loss, which encourages an exact
token-by-token match between a target sequence with a generated sequence. Such
training objective is sub-optimal when the target sequence not perfect, e.g.,
when the target sequence is corrupted with noises, or when only weak sequence
supervision is available. To address this challenge, we propose a novel
Edit-Invariant Sequence Loss (EISL), which computes the matching loss of a
target n-gram with all n-grams in the generated sequence. EISL draws
inspirations from convolutional networks (ConvNets) which are shift-invariant
to images, hence is robust to the shift of n-grams to tolerate edits in the
target sequences. Moreover, the computation of EISL is essentially a
convolution operation with target n-grams as kernels, which is easy to
implement with existing libraries. To demonstrate the effectiveness of EISL, we
conduct experiments on three tasks: machine translation with noisy target
sequences, unsupervised text style transfer, and non-autoregressive machine
translation. Experimental results show our method significantly outperforms
cross entropy loss on these three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding. (arXiv:2106.15065v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1">Siddhant Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostapenko_A/0/1/0/all/0/1">Alissa Ostapenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1">Vijay Viswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1">Siddharth Dalmia</a>, <a href="http://arxiv.org/find/cs/1/au:+Metze_F/0/1/0/all/0/1">Florian Metze</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1">Alan W Black</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15065">
                                    <div class="article-summary-box-inner">
                                        <span>Decomposable tasks are complex and comprise of a hierarchy of sub-tasks.
Spoken intent prediction, for example, combines automatic speech recognition
and natural language understanding. Existing benchmarks, however, typically
hold out examples for only the surface-level sub-task. As a result, models with
similar performance on these benchmarks may have unobserved performance
differences on the other sub-tasks. To allow insightful comparisons between
competitive end-to-end architectures, we propose a framework to construct
robust test sets using coordinate ascent over sub-task specific utility
functions. Given a dataset for a decomposable task, our method optimally
creates a test set for each sub-task to individually assess sub-components of
the end-to-end model. Using spoken language understanding as a case study, we
generate new splits for the Fluent Speech Commands and Snips SmartLights
datasets. Each split has two test sets: one with held-out utterances assessing
natural language understanding abilities, and one with held-out speakers to
test speech processing skills. Our splits identify performance gaps up to 10%
between end-to-end systems that were within 1% of each other on the original
test sets. These performance gaps allow more realistic and actionable
comparisons between different architectures, driving future model development.
We release our splits and tools for the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Lexicons for Hindi-English Multilingual Text Processing. (arXiv:2106.15105v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohd Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Bari_N/0/1/0/all/0/1">Noaima Bari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15105">
                                    <div class="article-summary-box-inner">
                                        <span>Language Identification in textual documents is the process of automatically
detecting the language contained in a document based on its content. The
present Language Identification techniques presume that a document contains
text in one of the fixed set of languages, however, this presumption is
incorrect when dealing with multilingual document which includes content in
more than one possible language. Due to the unavailability of large standard
corpora for Hindi-English mixed lingual language processing tasks we propose
the language lexicons, a novel kind of lexical database that supports several
multilingual language processing tasks. These lexicons are built by learning
classifiers over transliterated Hindi and English vocabulary. The designed
lexicons possess richer quantitative characteristic than its primary source of
collection which is revealed using the visualization techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of BioASQ 2021: The ninth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering. (arXiv:2106.14885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1">Anastasios Nentidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsimpras_G/0/1/0/all/0/1">Georgios Katsimpras</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandorou_E/0/1/0/all/0/1">Eirini Vandorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1">Anastasia Krithara</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasco_L/0/1/0/all/0/1">Luis Gasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Krallinger_M/0/1/0/all/0/1">Martin Krallinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1">Georgios Paliouras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14885">
                                    <div class="article-summary-box-inner">
                                        <span>Advancing the state-of-the-art in large-scale biomedical semantic indexing
and question answering is the main focus of the BioASQ challenge. BioASQ
organizes respective tasks where different teams develop systems that are
evaluated on the same benchmark datasets that represent the real information
needs of experts in the biomedical domain. This paper presents an overview of
the ninth edition of the BioASQ challenge in the context of the Conference and
Labs of the Evaluation Forum (CLEF) 2021. In this year, a new question
answering task, named Synergy, is introduced to support researchers studying
the COVID-19 disease and measure the ability of the participating teams to
discern information while the problem is still developing. In total, 42 teams
with more than 170 systems were registered to participate in the four tasks of
the challenge. The evaluation results, similarly to previous years, show a
performance gain against the baselines which indicates the continuous
improvement of the state-of-the-art in this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TWAG: A Topic-Guided Wikipedia Abstract Generator. (arXiv:2106.15135v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fangwei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1">Shangqing Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiaxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanzi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Lei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_T/0/1/0/all/0/1">Tong Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15135">
                                    <div class="article-summary-box-inner">
                                        <span>Wikipedia abstract generation aims to distill a Wikipedia abstract from web
sources and has met significant success by adopting multi-document
summarization techniques. However, previous works generally view the abstract
as plain text, ignoring the fact that it is a description of a certain entity
and can be decomposed into different topics. In this paper, we propose a
two-stage model TWAG that guides the abstract generation with topical
information. First, we detect the topic of each input paragraph with a
classifier trained on existing Wikipedia articles to divide input documents
into different topics. Then, we predict the topic distribution of each abstract
sentence, and decode the sentence from topic-aware representations with a
Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and
the results show that \modelnames outperforms various existing baselines and is
capable of generating comprehensive abstracts. Our code and dataset can be
accessed at \url{https://github.com/THU-KEG/TWAG}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sexism in the Judiciary. (arXiv:2106.15103v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1">Noa Baker Gillis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15103">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze 6.7 million case law documents to determine the presence of gender
bias within our judicial system. We find that current bias detectino methods in
NLP are insufficient to determine gender bias in our case law database and
propose an alternative approach. We show that existing algorithms&#x27; inconsistent
results are consequences of prior research&#x27;s definition of biases themselves.
Bias detection algorithms rely on groups of words to represent bias (e.g.,
&#x27;salary,&#x27; &#x27;job,&#x27; and &#x27;boss&#x27; to represent employment as a potentially biased
theme against women in text). However, the methods to build these groups of
words have several weaknesses, primarily that the word lists are based on the
researchers&#x27; own intuitions. We suggest two new methods of automating the
creation of word lists to represent biases. We find that our methods outperform
current NLP bias detection methods. Our research improves the capabilities of
NLP technology to detect bias and highlights gender biases present in
influential case law. In order test our NLP bias detection method&#x27;s
performance, we regress our results of bias in case law against U.S census data
of women&#x27;s participation in the workforce in the last 100 years.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time-Aware Language Models as Temporal Knowledge Bases. (arXiv:2106.15110v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1">Bhuwan Dhingra</a>, <a href="http://arxiv.org/find/cs/1/au:+Cole_J/0/1/0/all/0/1">Jeremy R. Cole</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1">Julian Martin Eisenschlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gillick_D/0/1/0/all/0/1">Daniel Gillick</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1">Jacob Eisenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1">William W. Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15110">
                                    <div class="article-summary-box-inner">
                                        <span>Many facts come with an expiration date, from the name of the President to
the basketball team Lebron James plays for. But language models (LMs) are
trained on snapshots of data collected at a specific moment in time, and this
can limit their utility, especially in the closed-book setting where the
pretraining corpus must contain the facts the model should memorize. We
introduce a diagnostic dataset aimed at probing LMs for factual knowledge that
changes over time and highlight problems with LMs at either end of the spectrum
-- those trained on specific slices of temporal data, as well as those trained
on a wide range of temporal data. To mitigate these problems, we propose a
simple technique for jointly modeling text with its timestamp. This improves
memorization of seen facts from the training time period, as well as
calibration on predictions about unseen facts from future time periods. We also
show that models trained with temporal context can be efficiently &#x60;&#x60;refreshed&#x27;&#x27;
as new data arrives, without the need for retraining from scratch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic-to-Essay Generation with Comprehensive Knowledge Enhancement. (arXiv:2106.15142v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyue Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiahai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenghong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15142">
                                    <div class="article-summary-box-inner">
                                        <span>Generating high-quality and diverse essays with a set of topics is a
challenging task in natural language generation. Since several given topics
only provide limited source information, utilizing various topic-related
knowledge is essential for improving essay generation performance. However,
previous works cannot sufficiently use that knowledge to facilitate the
generation procedure. This paper aims to improve essay generation by extracting
information from both internal and external knowledge. Thus, a topic-to-essay
generation model with comprehensive knowledge enhancement, named TEGKE, is
proposed. For internal knowledge enhancement, both topics and related essays
are fed to a teacher network as source information. Then, informative features
would be obtained from the teacher network and transferred to a student network
which only takes topics as input but provides comparable information compared
with the teacher network. For external knowledge enhancement, a topic knowledge
graph encoder is proposed. Unlike the previous works only using the nearest
neighbors of topics in the commonsense base, our topic knowledge graph encoder
could exploit more structural and semantic information of the commonsense
knowledge graph to facilitate essay generation. Moreover, the adversarial
training based on the Wasserstein distance is proposed to improve generation
quality. Experimental results demonstrate that TEGKE could achieve
state-of-the-art performance on both automatic and human evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Construction of Enterprise Knowledge Base. (arXiv:2106.15085v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1">Junyi Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yujie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_H/0/1/0/all/0/1">Homa Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Parveen_D/0/1/0/all/0/1">Daraksha Parveen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapally_R/0/1/0/all/0/1">Ranganath Kondapally</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenjin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15085">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an automatic knowledge base construction system
from large scale enterprise documents with minimal efforts of human
intervention. In the design and deployment of such a knowledge mining system
for enterprise, we faced several challenges including data distributional
shift, performance evaluation, compliance requirements and other practical
issues. We leveraged state-of-the-art deep learning models to extract
information (named entities and definitions) at per document level, then
further applied classical machine learning techniques to process global
statistical information to improve the knowledge base. Experimental results are
reported on actual enterprise documents. This system is currently serving as
part of a Microsoft 365 service.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Image Restoration Network. (arXiv:2008.10796v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yue_Z/0/1/0/all/0/1">Zongsheng Yue</a>, <a href="http://arxiv.org/find/eess/1/au:+Yong_H/0/1/0/all/0/1">Hongwei Yong</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Q/0/1/0/all/0/1">Qian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10796">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have achieved significant success in image
restoration tasks by directly learning a powerful non-linear mapping from
corrupted images to their latent clean ones. However, there still exist two
major limitations for these deep learning (DL)-based methods. Firstly, the
noises contained in real corrupted images are very complex, usually neglected
and largely under-estimated in most current methods. Secondly, existing DL
methods are mostly trained on one pre-assumed degradation process for all of
the training image pairs, such as the widely used bicubic downsampling
assumption in the image super-resolution task, inevitably leading to poor
generalization performance when the true degradation does not match with such
assumed one. To address these issues, we propose a unified generative model for
the image restoration, which elaborately configures the degradation process
from the latent clean image to the observed corrupted one. Specifically,
different from most of current methods, the pixel-wisely non-i.i.d. Gaussian
distribution, being with more flexibility, is adopted in our method to fit the
complex real noises. Furthermore, the method is built on the general image
degradation process, making it capable of adapting diverse degradations under
one single model. Besides, we design a variational inference algorithm to learn
all parameters involved in the proposed model with explicit form of objective
loss. Specifically, beyond traditional variational methodology, two DNNs are
employed to parameterize the posteriori distributions, one to infer the
distribution of the latent clean image, and another to infer the distribution
of the image noise. Extensive experiments demonstrate the superiority of the
proposed method on three classical image restoration tasks, including image
denoising, image super-resolution and JPEG image deblocking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trinity: A No-Code AI platform for complex spatial datasets. (arXiv:2106.11756v4 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iyer_C/0/1/0/all/0/1">C.V.Krishnakumar Iyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_F/0/1/0/all/0/1">Feili Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Henry Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yonghong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1">Kay Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1">Swetava Ganguli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_V/0/1/0/all/0/1">Vipul Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11756">
                                    <div class="article-summary-box-inner">
                                        <span>We present a no-code Artificial Intelligence (AI) platform called Trinity
with the main design goal of enabling both machine learning researchers and
non-technical geospatial domain experts to experiment with domain-specific
signals and datasets for solving a variety of complex problems on their own.
This versatility to solve diverse problems is achieved by transforming complex
Spatio-temporal datasets to make them consumable by standard deep learning
models, in this case, Convolutional Neural Networks (CNNs), and giving the
ability to formulate disparate problems in a standard way, eg. semantic
segmentation. With an intuitive user interface, a feature store that hosts
derivatives of complex feature engineering, a deep learning kernel, and a
scalable data processing mechanism, Trinity provides a powerful platform for
domain experts to share the stage with scientists and engineers in solving
business-critical problems. It enables quick prototyping, rapid experimentation
and reduces the time to production by standardizing model building and
deployment. In this paper, we present our motivation behind Trinity and its
design along with showcasing sample applications to motivate the idea of
lowering the bar to using AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Adder Neural Networks. (arXiv:2105.14202v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14202">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with cheap addition operation, multiplication operation is of much
higher computation complexity. The widely-used convolutions in deep neural
networks are exactly cross-correlation to measure the similarity between input
feature and convolution filters, which involves massive multiplications between
float values. In this paper, we present adder networks (AdderNets) to trade
these massive multiplications in deep neural networks, especially convolutional
neural networks (CNNs), for much cheaper additions to reduce computation costs.
In AdderNets, we take the $\ell_1$-norm distance between filters and input
feature as the output response. We first develop a theoretical foundation for
AdderNets, by showing that both the single hidden layer AdderNet and the
width-bounded deep AdderNet with ReLU activation functions are universal
function approximators. An approximation bound for AdderNets with a single
hidden layer is also presented. We further analyze the influence of this new
similarity measure on the optimization of neural network and develop a special
training scheme for AdderNets. Based on the gradient magnitude, an adaptive
learning rate strategy is proposed to enhance the training procedure of
AdderNets. AdderNets can achieve a 75.7% Top-1 accuracy and a 92.3% Top-5
accuracy using ResNet-50 on the ImageNet dataset without any multiplication in
the convolutional layer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Features for training Support Vector Machine. (arXiv:2104.03488v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nanni_L/0/1/0/all/0/1">Loris Nanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidoni_S/0/1/0/all/0/1">Stefano Ghidoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahnam_S/0/1/0/all/0/1">Sheryl Brahnam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03488">
                                    <div class="article-summary-box-inner">
                                        <span>Features play a crucial role in computer vision. Initially designed to detect
salient elements by means of handcrafted algorithms, features are now often
learned by different layers in Convolutional Neural Networks (CNNs). This paper
develops a generic computer vision system based on features extracted from
trained CNNs. Multiple learned features are combined into a single structure to
work on different image classification tasks. The proposed system was
experimentally derived by testing several approaches for extracting features
from the inner layers of CNNs and using them as inputs to SVMs that are then
combined by sum rule. Dimensionality reduction techniques are used to reduce
the high dimensionality of inner layers. The resulting vision system is shown
to significantly boost the performance of standard CNNs across a large and
diverse collection of image data sets. An ensemble of different topologies
using the same approach obtains state-of-the-art results on a virus data set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACN: Adversarial Co-training Network for Brain Tumor Segmentation with Missing Modalities. (arXiv:2106.14591v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yixin Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_Z/0/1/0/all/0/1">Zihao Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Tian_J/0/1/0/all/0/1">Jiang Tian</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhong_C/0/1/0/all/0/1">Cheng Zhong</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1">Zhongchao Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_J/0/1/0/all/0/1">Jianping Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+He_Z/0/1/0/all/0/1">Zhiqiang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14591">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate segmentation of brain tumors from magnetic resonance imaging (MRI)
is clinically relevant in diagnoses, prognoses and surgery treatment, which
requires multiple modalities to provide complementary morphological and
physiopathologic information. However, missing modality commonly occurs due to
image corruption, artifacts, different acquisition protocols or allergies to
certain contrast agents in clinical practice. Though existing efforts
demonstrate the possibility of a unified model for all missing situations, most
of them perform poorly when more than one modality is missing. In this paper,
we propose a novel Adversarial Co-training Network (ACN) to solve this issue,
in which a series of independent yet related models are trained dedicated to
each missing situation with significantly better results. Specifically, ACN
adopts a novel co-training network, which enables a coupled learning process
for both full modality and missing modality to supplement each other&#x27;s domain
and feature representations, and more importantly, to recover the &#x60;missing&#x27;
information of absent modalities. Then, two unsupervised modules, i.e., entropy
and knowledge adversarial learning modules are proposed to minimize the domain
gap while enhancing prediction reliability and encouraging the alignment of
latent representations, respectively. We also adapt modality-mutual information
knowledge transfer learning to ACN to retain the rich mutual information among
modalities. Extensive experiments on BraTS2018 dataset show that our proposed
method significantly outperforms all state-of-the-art methods under any missing
situation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unmixing Convolutional Features for Crisp Edge Detection. (arXiv:2011.09808v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huan_L/0/1/0/all/0/1">Linxi Huan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_N/0/1/0/all/0/1">Nan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xianwei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1">Jianya Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Gui-Song Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09808">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a context-aware tracing strategy (CATS) for crisp edge
detection with deep edge detectors, based on an observation that the
localization ambiguity of deep edge detectors is mainly caused by the mixing
phenomenon of convolutional neural networks: feature mixing in edge
classification and side mixing during fusing side predictions. The CATS
consists of two modules: a novel tracing loss that performs feature unmixing by
tracing boundaries for better side edge learning, and a context-aware fusion
block that tackles the side mixing by aggregating the complementary merits of
learned side edges. Experiments demonstrate that the proposed CATS can be
integrated into modern deep edge detectors to improve localization accuracy.
With the vanilla VGG16 backbone, in terms of BSDS500 dataset, our CATS improves
the F-measure (ODS) of the RCF and BDCN deep edge detectors by 12% and 6%
respectively when evaluating without using the morphological non-maximal
suppression scheme for edge detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepFaceLab: Integrated, flexible and extensible face-swapping framework. (arXiv:2005.05535v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perov_I/0/1/0/all/0/1">Ivan Perov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1">Daiheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chervoniy_N/0/1/0/all/0/1">Nikolay Chervoniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kunlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marangonda_S/0/1/0/all/0/1">Sugasa Marangonda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ume_C/0/1/0/all/0/1">Chris Um&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Dpfks_M/0/1/0/all/0/1">Mr. Dpfks</a>, <a href="http://arxiv.org/find/cs/1/au:+Facenheim_C/0/1/0/all/0/1">Carl Shift Facenheim</a>, <a href="http://arxiv.org/find/cs/1/au:+RP_L/0/1/0/all/0/1">Luis RP</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Pingyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfake defense not only requires the research of detection but also
requires the efforts of generation methods. However, current deepfake methods
suffer the effects of obscure workflow and poor performance. To solve this
problem, we present DeepFaceLab, the current dominant deepfake framework for
face-swapping. It provides the necessary tools as well as an easy-to-use way to
conduct high-quality face-swapping. It also offers a flexible and loose
coupling structure for people who need to strengthen their pipeline with other
features without writing complicated boilerplate code. We detail the principles
that drive the implementation of DeepFaceLab and introduce its pipeline,
through which every aspect of the pipeline can be modified painlessly by users
to achieve their customization purpose. It is noteworthy that DeepFaceLab could
achieve cinema-quality results with high fidelity. We demonstrate the advantage
of our system by comparing our approach with other face-swapping methods.For
more information, please visit:https://github.com/iperov/DeepFaceLab/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Attraction and Contrastive Repulsion for Representation Learning. (arXiv:2105.03746v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Huangjie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiangchao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1">Ivor Tsang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03746">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning (CL) is effective in learning data representations
without label supervision, where the encoder needs to contrast each positive
sample over multiple negative samples via a one-vs-many softmax cross-entropy
loss. However, conventional CL is sensitive to how many negative samples are
included and how they are selected. Proposed in this paper is a doubly CL
strategy that contrasts positive samples and negative ones within themselves
separately. We realize this strategy with contrastive attraction and
contrastive repulsion (CACR) makes the query not only exert a greater force to
attract more distant positive samples but also do so to repel closer negative
samples. Theoretical analysis reveals the connection between CACR and CL from
the perspectives of both positive attraction and negative repulsion and shows
the benefits in both efficiency and robustness brought by separately
contrasting within the sampled positive and negative pairs. Extensive
large-scale experiments on standard vision tasks show that CACR not only
consistently outperforms existing CL methods on benchmark datasets in
representation learning, but also provides interpretable contrastive weights,
demonstrating the efficacy of the proposed doubly contrastive strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis and Applications of Class-wise Robustness in Adversarial Training. (arXiv:2105.14240v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1">Kun Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_K/0/1/0/all/0/1">Kelu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14240">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is one of the most effective approaches to improve model
robustness against adversarial examples. However, previous works mainly focus
on the overall robustness of the model, and the in-depth analysis on the role
of each class involved in adversarial training is still missing. In this paper,
we propose to analyze the class-wise robustness in adversarial training. First,
we provide a detailed diagnosis of adversarial training on six benchmark
datasets, i.e., MNIST, CIFAR-10, CIFAR-100, SVHN, STL-10 and ImageNet.
Surprisingly, we find that there are remarkable robustness discrepancies among
classes, leading to unbalance/unfair class-wise robustness in the robust
models. Furthermore, we keep investigating the relations between classes and
find that the unbalanced class-wise robustness is pretty consistent among
different attack and defense methods. Moreover, we observe that the stronger
attack methods in adversarial learning achieve performance improvement mainly
from a more successful attack on the vulnerable classes (i.e., classes with
less robustness). Inspired by these interesting findings, we design a simple
but effective attack method based on the traditional PGD attack, named
Temperature-PGD attack, which proposes to enlarge the robustness disparity
among classes with a temperature factor on the confidence distribution of each
image. Experiments demonstrate our method can achieve a higher attack rate than
the PGD attack. Furthermore, from the defense perspective, we also make some
modifications in the training and inference phase to improve the robustness of
the most vulnerable class, so as to mitigate the large difference in class-wise
robustness. We believe our work can contribute to a more comprehensive
understanding of adversarial training as well as rethinking the class-wise
properties in robust models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetry meets AI. (arXiv:2103.06115v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barenboim_G/0/1/0/all/0/1">Gabriela Barenboim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirn_J/0/1/0/all/0/1">Johannes Hirn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanz_V/0/1/0/all/0/1">Veronica Sanz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06115">
                                    <div class="article-summary-box-inner">
                                        <span>We explore whether Neural Networks (NNs) can {\it discover} the presence of
symmetries as they learn to perform a task. For this, we train hundreds of NNs
on a {\it decoy task} based on well-controlled Physics templates, where no
information on symmetry is provided. We use the output from the last hidden
layer of all these NNs, projected to fewer dimensions, as the input for a
symmetry classification task, and show that information on symmetry had indeed
been identified by the original NN without guidance. As an interdisciplinary
application of this procedure, we identify the presence and level of symmetry
in artistic paintings from different styles such as those of Picasso, Pollock
and Van Gogh.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Diffusion for Dense Depth Estimation from Multi-view Images. (arXiv:2106.08917v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Numair Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min H. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompkin_J/0/1/0/all/0/1">James Tompkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08917">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to estimate dense depth by optimizing a sparse set of
points such that their diffusion into a depth map minimizes a multi-view
reprojection error from RGB supervision. We optimize point positions, depths,
and weights with respect to the loss by differential splatting that models
points as Gaussians with analytic transmittance. Further, we develop an
efficient optimization routine that can simultaneously optimize the 50k+ points
required for complex scene reconstruction. We validate our routine using ground
truth data and show high reconstruction quality. Then, we apply this to light
field and wider baseline images via self supervision, and show improvements in
both average and outlier error for depth maps diffused from inaccurate sparse
points. Finally, we compare qualitative and quantitative results to image
processing and deep learning methods. this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Fidelity 3D Digital Human Head Creation from RGB-D Selfies. (arXiv:2010.05562v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xiangkai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yajing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoxian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_X/0/1/0/all/0/1">Xuefei Zhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1">Di Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haozhi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xinwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengyou Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05562">
                                    <div class="article-summary-box-inner">
                                        <span>We present a fully automatic system that can produce high-fidelity,
photo-realistic 3D digital human heads with a consumer RGB-D selfie camera. The
system only needs the user to take a short selfie RGB-D video while rotating
his/her head, and can produce a high quality head reconstruction in less than
30 seconds. Our main contribution is a new facial geometry modeling and
reflectance synthesis procedure that significantly improves the
state-of-the-art. Specifically, given the input video a two-stage frame
selection procedure is first employed to select a few high-quality frames for
reconstruction. Then a differentiable renderer based 3D Morphable Model (3DMM)
fitting algorithm is applied to recover facial geometries from multiview RGB-D
data, which takes advantages of a powerful 3DMM basis constructed with
extensive data generation and perturbation. Our 3DMM has much larger expressive
capacities than conventional 3DMM, allowing us to recover more accurate facial
geometry using merely linear basis. For reflectance synthesis, we present a
hybrid approach that combines parametric fitting and CNNs to synthesize
high-resolution albedo/normal maps with realistic hair/pore/wrinkle details.
Results show that our system can produce faithful 3D digital human faces with
extremely realistic details. The main code and the newly constructed 3DMM basis
is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MemX: An Attention-Aware Smart Eyewear System for Personalized Moment Auto-capture. (arXiv:2105.00916v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yuhu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yingying Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1">Mingzhi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yutian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1">Qin Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1">Ning Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Li Shang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00916">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents MemX: a biologically-inspired attention-aware eyewear
system developed with the goal of pursuing the long-awaited vision of a
personalized visual Memex. MemX captures human visual attention on the fly,
analyzes the salient visual content, and records moments of personal interest
in the form of compact video snippets. Accurate attentive scene detection and
analysis on resource-constrained platforms is challenging because these tasks
are computation and energy intensive. We propose a new temporal visual
attention network that unifies human visual attention tracking and salient
visual content analysis. Attention tracking focuses computation-intensive video
analysis on salient regions, while video analysis makes human attention
detection and tracking more accurate. Using the YouTube-VIS dataset and 30
participants, we experimentally show that MemX significantly improves the
attention tracking accuracy over the eye-tracking-alone method, while
maintaining high system energy efficiency. We have also conducted 11 in-field
pilot studies across a range of daily usage scenarios, which demonstrate the
feasibility and potential benefits of MemX.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image is Worth More Than a Thousand Words: Towards Disentanglement in the Wild. (arXiv:2106.15610v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gabbay_A/0/1/0/all/0/1">Aviv Gabbay</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15610">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised disentanglement has been shown to be theoretically impossible
without inductive biases on the models and the data. As an alternative
approach, recent methods rely on limited supervision to disentangle the factors
of variation and allow their identifiability. While annotating the true
generative factors is only required for a limited number of observations, we
argue that it is infeasible to enumerate all the factors of variation that
describe a real-world image distribution. To this end, we propose a method for
disentangling a set of factors which are only partially labeled, as well as
separating the complementary set of residual factors that are never explicitly
specified. Our success in this challenging setting, demonstrated on synthetic
benchmarks, gives rise to leveraging off-the-shelf image descriptors to
partially annotate a subset of attributes in real image domains (e.g. of human
faces) with minimal manual effort. Specifically, we use a recent language-image
embedding model (CLIP) to annotate a set of attributes of interest in a
zero-shot manner and demonstrate state-of-the-art disentangled image
manipulation results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Body Region Classification of MRI and CT examinations. (arXiv:2104.13826v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Raffy_P/0/1/0/all/0/1">Philippe Raffy</a>, <a href="http://arxiv.org/find/eess/1/au:+Pambrun_J/0/1/0/all/0/1">Jean-Fran&#xe7;ois Pambrun</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Ashish Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Dubois_D/0/1/0/all/0/1">David Dubois</a>, <a href="http://arxiv.org/find/eess/1/au:+Patti_J/0/1/0/all/0/1">Jay Waldron Patti</a>, <a href="http://arxiv.org/find/eess/1/au:+Cairns_R/0/1/0/all/0/1">Robyn Alexandra Cairns</a>, <a href="http://arxiv.org/find/eess/1/au:+Young_R/0/1/0/all/0/1">Ryan Young</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13826">
                                    <div class="article-summary-box-inner">
                                        <span>Standardized body region labelling of individual images provides data that
can improve human and computer use of medical images. A CNN-based classifier
was developed to identify body regions in CT and MRI. 17 CT (18 MRI) body
regions covering the entire human body were defined for the classification
task. Three retrospective databases were built for the AI model training,
validation, and testing, with a balanced distribution of studies per body
region. The test databases originated from a different healthcare network.
Accuracy, recall and precision of the classifier was evaluated for patient age,
patient gender, institution, scanner manufacturer, contrast, slice thickness,
MRI sequence, and CT kernel. The data included a retrospective cohort of 2,934
anonymized CT cases (training: 1,804 studies, validation: 602 studies, test:
528 studies) and 3,185 anonymized MRI cases (training: 1,911 studies,
validation: 636 studies, test: 638 studies). 27 institutions from primary care
hospitals, community hospitals and imaging centers contributed to the test
datasets. The data included cases of all genders in equal proportions and
subjects aged from a few months old to +90 years old. An image-level prediction
accuracy of 91.9% (90.2 - 92.1) for CT, and 94.2% (92.0 - 95.6) for MRI was
achieved. The classification results were robust across all body regions and
confounding factors. Due to limited data, performance results for subjects
under 10 years-old could not be reliably evaluated. We show that deep learning
models can classify CT and MRI images by body region including lower and upper
extremities with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The U-Net based GLOW for Optical-Flow-free Video Interframe Generation. (arXiv:2103.09576v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Saem Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Donghoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1">Nojun Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09576">
                                    <div class="article-summary-box-inner">
                                        <span>Video frame interpolation is the task of creating an interframe between two
adjacent frames along the time axis. So, instead of simply averaging two
adjacent frames to create an intermediate image, this operation should maintain
semantic continuity with the adjacent frames. Most conventional methods use
optical flow, and various tools such as occlusion handling and object smoothing
are indispensable. Since the use of these various tools leads to complex
problems, we tried to tackle the video interframe generation problem without
using problematic optical flow . To enable this , we have tried to use a deep
neural network with an invertible structure, and developed an U-Net based
Generative Flow which is a modified normalizing flow. In addition, we propose a
learning method with a new consistency loss in the latent space to maintain
semantic temporal consistency between frames. The resolution of the generated
image is guaranteed to be identical to that of the original images by using an
invertible network. Furthermore, as it is not a random image like the ones by
generative models, our network guarantees stable outputs without flicker.
Through experiments, we \sam {confirmed the feasibility of the proposed
algorithm and would like to suggest the U-Net based Generative Flow as a new
possibility for baseline in video frame interpolation. This paper is meaningful
in that it is the world&#x27;s first attempt to use invertible networks instead of
optical flows for video interpolation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Six-channel Image Representation for Cross-domain Object Detection. (arXiv:2101.00561v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wenchi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00561">
                                    <div class="article-summary-box-inner">
                                        <span>Most deep learning models are data-driven and the excellent performance is
highly dependent on the abundant and diverse datasets. However, it is very hard
to obtain and label the datasets of some specific scenes or applications. If we
train the detector using the data from one domain, it cannot perform well on
the data from another domain due to domain shift, which is one of the big
challenges of most object detection models. To address this issue, some
image-to-image translation techniques have been employed to generate some fake
data of some specific scenes to train the models. With the advent of Generative
Adversarial Networks (GANs), we could realize unsupervised image-to-image
translation in both directions from a source to a target domain and from the
target to the source domain. In this study, we report a new approach to making
use of the generated images. We propose to concatenate the original 3-channel
images and their corresponding GAN-generated fake images to form 6-channel
representations of the dataset, hoping to address the domain shift problem
while exploiting the success of available detection models. The idea of
augmented data representation may inspire further study on object detection and
other applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel lightweight Convolutional Neural Network, ExquisiteNetV2. (arXiv:2105.09008v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shyh_Yaw_J/0/1/0/all/0/1">Jou Shyh-Yaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_Yen_S/0/1/0/all/0/1">Su Chung-Yen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09008">
                                    <div class="article-summary-box-inner">
                                        <span>In the paper of ExquisiteNetV1, the ability of classification of
ExquisiteNetV1 is worse than DenseNet. In this article, we propose a faster and
better model ExquisiteNetV2. We conduct many experiments to evaluate its
performance. We test ExquisiteNetV2, ExquisiteNetV1 and other 9 well-known
models on 15 credible datasets under the same condition. According to the
experimental results, ExquisiteNetV2 gets the highest classification accuracy
over half of the datasets. Important of all, ExquisiteNetV2 has fewest amounts
of parameters. Besides, in most instances, ExquisiteNetV2 has fastest computing
speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syntactically Guided Generative Embeddings for Zero-Shot Skeleton Action Recognition. (arXiv:2101.11530v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Pranay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1">Divyanshu Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11530">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce SynSE, a novel syntactically guided generative approach for
Zero-Shot Learning (ZSL). Our end-to-end approach learns progressively refined
generative embedding spaces constrained within and across the involved
modalities (visual, language). The inter-modal constraints are defined between
action sequence embedding and embeddings of Parts of Speech (PoS) tagged words
in the corresponding action description. We deploy SynSE for the task of
skeleton-based action sequence recognition. Our design choices enable SynSE to
generalize compositionally, i.e., recognize sequences whose action descriptions
contain words not encountered during training. We also extend our approach to
the more challenging Generalized Zero-Shot Learning (GZSL) problem via a
confidence-based gating mechanism. We are the first to present zero-shot
skeleton action recognition results on the large-scale NTU-60 and NTU-120
skeleton action datasets with multiple splits. Our results demonstrate SynSE&#x27;s
state of the art performance in both ZSL and GZSL settings compared to strong
baselines on the NTU-60 and NTU-120 datasets. The code and pretrained models
are available at https://github.com/skelemoa/synse-zsl</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Joint Low-light Enhancement and Noise Removal for Raw Images. (arXiv:2106.14844v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1">Yucheng Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Jung_S/0/1/0/all/0/1">Seung-Won Jung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14844">
                                    <div class="article-summary-box-inner">
                                        <span>Low-light imaging on mobile devices is typically challenging due to
insufficient incident light coming through the relatively small aperture,
resulting in a low signal-to-noise ratio. Most of the previous works on
low-light image processing focus either only on a single task such as
illumination adjustment, color enhancement, or noise removal; or on a joint
illumination adjustment and denoising task that heavily relies on short-long
exposure image pairs collected from specific camera models, and thus these
approaches are less practical and generalizable in real-world settings where
camera-specific joint enhancement and restoration is required. To tackle this
problem, in this paper, we propose a low-light image processing framework that
performs joint illumination adjustment, color enhancement, and denoising.
Considering the difficulty in model-specific data collection and the ultra-high
definition of the captured images, we design two branches: a coefficient
estimation branch as well as a joint enhancement and denoising branch. The
coefficient estimation branch works in a low-resolution space and predicts the
coefficients for enhancement via bilateral learning, whereas the joint
enhancement and denoising branch works in a full-resolution space and performs
joint enhancement and denoising in a progressive manner. In contrast to
existing methods, our framework does not need to recollect massive data when
being adapted to another camera model, which significantly reduces the efforts
required to fine-tune our approach for practical usage. Through extensive
experiments, we demonstrate its great potential in real-world low-light imaging
applications when compared with current state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information-Theoretic Segmentation by Inpainting Error Maximization. (arXiv:2012.07287v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Savarese_P/0/1/0/all/0/1">Pedro Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sunnie S. Y. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Maire_M/0/1/0/all/0/1">Michael Maire</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakhnarovich_G/0/1/0/all/0/1">Greg Shakhnarovich</a>, <a href="http://arxiv.org/find/cs/1/au:+McAllester_D/0/1/0/all/0/1">David McAllester</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07287">
                                    <div class="article-summary-box-inner">
                                        <span>We study image segmentation from an information-theoretic perspective,
proposing a novel adversarial method that performs unsupervised segmentation by
partitioning images into maximally independent sets. More specifically, we
group image pixels into foreground and background, with the goal of minimizing
predictability of one set from the other. An easily computed loss drives a
greedy search process to maximize inpainting error over these partitions. Our
method does not involve training deep networks, is computationally cheap,
class-agnostic, and even applicable in isolation to a single unlabeled image.
Experiments demonstrate that it achieves a new state-of-the-art in unsupervised
segmentation quality, while being substantially faster and more general than
competing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery. (arXiv:2011.01619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yonghao Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Ying Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_B/0/1/0/all/0/1">Bo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yueming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yun-Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01619">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic surgical gesture recognition is fundamentally important to enable
intelligent cognitive assistance in robotic surgery. With recent advancement in
robot-assisted minimally invasive surgery, rich information including surgical
videos and robotic kinematics can be recorded, which provide complementary
knowledge for understanding surgical gestures. However, existing methods either
solely adopt uni-modal data or directly concatenate multi-modal
representations, which can not sufficiently exploit the informative
correlations inherent in visual and kinematics data to boost gesture
recognition accuracies. In this regard, we propose a novel online approach of
multi-modal relational graph network (i.e., MRG-Net) to dynamically integrate
visual and kinematics information through interactive message propagation in
the latent feature space. In specific, we first extract embeddings from video
and kinematics sequences with temporal convolutional networks and LSTM units.
Next, we identify multi-relations in these multi-modal embeddings and leverage
them through a hierarchical relational graph learning module. The effectiveness
of our method is demonstrated with state-of-the-art results on the public
JIGSAWS dataset, outperforming current uni-modal and multi-modal methods on
both suturing and knot typing tasks. Furthermore, we validated our method on
in-house visual-kinematics datasets collected with da Vinci Research Kit (dVRK)
platforms in two centers, with consistent promising performance achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdderNet: Do We Really Need Multiplications in Deep Learning?. (arXiv:1912.13200v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.13200">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with cheap addition operation, multiplication operation is of much
higher computation complexity. The widely-used convolutions in deep neural
networks are exactly cross-correlation to measure the similarity between input
feature and convolution filters, which involves massive multiplications between
float values. In this paper, we present adder networks (AdderNets) to trade
these massive multiplications in deep neural networks, especially convolutional
neural networks (CNNs), for much cheaper additions to reduce computation costs.
In AdderNets, we take the $\ell_1$-norm distance between filters and input
feature as the output response. The influence of this new similarity measure on
the optimization of neural network have been thoroughly analyzed. To achieve a
better performance, we develop a special back-propagation approach for
AdderNets by investigating the full-precision gradient. We then propose an
adaptive learning rate strategy to enhance the training procedure of AdderNets
according to the magnitude of each neuron&#x27;s gradient. As a result, the proposed
AdderNets can achieve 74.9% Top-1 accuracy 91.7% Top-5 accuracy using ResNet-50
on the ImageNet dataset without any multiplication in convolution layer. The
codes are publicly available at: https://github.com/huaweinoah/AdderNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hate speech detection using static BERT embeddings. (arXiv:2106.15537v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajput_G/0/1/0/all/0/1">Gaurav Rajput</a>, <a href="http://arxiv.org/find/cs/1/au:+punn_N/0/1/0/all/0/1">Narinder Singh punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15537">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing popularity of social media platforms hate speech is emerging
as a major concern, where it expresses abusive speech that targets specific
group characteristics, such as gender, religion or ethnicity to spread
violence. Earlier people use to verbally deliver hate speeches but now with the
expansion of technology, some people are deliberately using social media
platforms to spread hate by posting, sharing, commenting, etc. Whether it is
Christchurch mosque shootings or hate crimes against Asians in west, it has
been observed that the convicts are very much influenced from hate text present
online. Even though AI systems are in place to flag such text but one of the
key challenges is to reduce the false positive rate (marking non hate as hate),
so that these systems can detect hate speech without undermining the freedom of
expression. In this paper, we use ETHOS hate speech detection dataset and
analyze the performance of hate speech detection classifier by replacing or
integrating the word embeddings (fastText (FT), GloVe (GV) or FT + GV) with
static BERT embeddings (BE). With the extensive experimental trails it is
observed that the neural network performed better with static BE compared to
using FT, GV or FT + GV as word embeddings. In comparison to fine-tuned BERT,
one metric that significantly improved is specificity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking Unsupervised Object Representations for Video Sequences. (arXiv:2006.07034v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weis_M/0/1/0/all/0/1">Marissa A. Weis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitta_K/0/1/0/all/0/1">Kashyap Chitta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1">Matthias Bethge</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Andreas Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Ecker_A/0/1/0/all/0/1">Alexander S. Ecker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07034">
                                    <div class="article-summary-box-inner">
                                        <span>Perceiving the world in terms of objects and tracking them through time is a
crucial prerequisite for reasoning and scene understanding. Recently, several
methods have been proposed for unsupervised learning of object-centric
representations. However, since these models were evaluated on different
downstream tasks, it remains unclear how they compare in terms of basic
perceptual abilities such as detection, figure-ground segmentation and tracking
of objects. To close this gap, we design a benchmark with four data sets of
varying complexity and seven additional test sets featuring challenging
tracking scenarios relevant for natural videos. Using this benchmark, we
compare the perceptual abilities of four object-centric approaches: ViMON, a
video-extension of MONet, based on recurrent spatial attention, OP3, which
exploits clustering via spatial mixture models, as well as TBA and SCALOR,
which use explicit factorization via spatial transformers. Our results suggest
that the architectures with unconstrained latent representations learn more
powerful representations in terms of object detection, segmentation and
tracking than the spatial transformer based architectures. We also observe that
none of the methods are able to gracefully handle the most challenging tracking
scenarios despite their synthetic nature, suggesting that our benchmark may
provide fruitful guidance towards learning more robust object-centric video
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal End-to-End Learning for Autonomous Steering in Adverse Road and Weather Conditions. (arXiv:2010.14924v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maanpaa_J/0/1/0/all/0/1">Jyri Maanp&#xe4;&#xe4;</a>, <a href="http://arxiv.org/find/cs/1/au:+Taher_J/0/1/0/all/0/1">Josef Taher</a>, <a href="http://arxiv.org/find/cs/1/au:+Manninen_P/0/1/0/all/0/1">Petri Manninen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pakola_L/0/1/0/all/0/1">Leo Pakola</a>, <a href="http://arxiv.org/find/cs/1/au:+Melekhov_I/0/1/0/all/0/1">Iaroslav Melekhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyyppa_J/0/1/0/all/0/1">Juha Hyypp&#xe4;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14924">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous driving is challenging in adverse road and weather conditions in
which there might not be lane lines, the road might be covered in snow and the
visibility might be poor. We extend the previous work on end-to-end learning
for autonomous steering to operate in these adverse real-life conditions with
multimodal data. We collected 28 hours of driving data in several road and
weather conditions and trained convolutional neural networks to predict the car
steering wheel angle from front-facing color camera images and lidar range and
reflectance data. We compared the CNN model performances based on the different
modalities and our results show that the lidar modality improves the
performances of different multimodal sensor-fusion models. We also performed
on-road tests with different models and they support this observation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Framework for an Intelligent Affect Aware Smart Home Environment for Elderly People. (arXiv:2106.15599v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chia Y. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15599">
                                    <div class="article-summary-box-inner">
                                        <span>The population of elderly people has been increasing at a rapid rate over the
last few decades and their population is expected to further increase in the
upcoming future. Their increasing population is associated with their
increasing needs due to problems like physical disabilities, cognitive issues,
weakened memory and disorganized behavior, that elderly people face with
increasing age. To reduce their financial burden on the world economy and to
enhance their quality of life, it is essential to develop technology-based
solutions that are adaptive, assistive and intelligent in nature. Intelligent
Affect Aware Systems that can not only analyze but also predict the behavior of
elderly people in the context of their day to day interactions with technology
in an IoT-based environment, holds immense potential for serving as a long-term
solution for improving the user experience of elderly in smart homes. This work
therefore proposes the framework for an Intelligent Affect Aware environment
for elderly people that can not only analyze the affective components of their
interactions but also predict their likely user experience even before they
start engaging in any activity in the given smart home environment. This
forecasting of user experience would provide scope for enhancing the same,
thereby increasing the assistive and adaptive nature of such intelligent
systems. To uphold the efficacy of this proposed framework for improving the
quality of life of elderly people in smart homes, it has been tested on three
datasets and the results are presented and discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Realistic Data Generation Framework leveraging Deep Learning-based Human Digitization. (arXiv:2106.15409v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Symeonidis_C/0/1/0/all/0/1">C. Symeonidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nousi_P/0/1/0/all/0/1">P. Nousi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tosidis_P/0/1/0/all/0/1">P. Tosidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsampazis_K/0/1/0/all/0/1">K. Tsampazis</a>, <a href="http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1">N. Passalis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1">A. Tefas</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolaidis_N/0/1/0/all/0/1">N. Nikolaidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15409">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of supervised deep learning algorithms depends significantly
on the scale, quality and diversity of the data used for their training.
Collecting and manually annotating large amount of data can be both
time-consuming and costly tasks to perform. In the case of tasks related to
visual human-centric perception, the collection and distribution of such data
may also face restrictions due to legislation regarding privacy. In addition,
the design and testing of complex systems, e.g., robots, which often employ
deep learning-based perception models, may face severe difficulties as even
state-of-the-art methods trained on real and large-scale datasets cannot always
perform adequately as they have not adapted to the visual differences between
the virtual and the real world data. As an attempt to tackle and mitigate the
effect of these issues, we present a method that automatically generates
realistic synthetic data with annotations for a) person detection, b) face
recognition, and c) human pose estimation. The proposed method takes as input
real background images and populates them with human figures in various poses.
Instead of using hand-made 3D human models, we propose the use of models
generated through deep learning methods, further reducing the dataset creation
costs, while maintaining a high level of realism. In addition, we provide
open-source and easy to use tools that implement the proposed pipeline,
allowing for generating highly-realistic synthetic datasets for a variety of
tasks. A benchmarking and evaluation in the corresponding tasks shows that
synthetic data can be effectively used as a supplement to real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Automated Image Descriptions for Visually Impaired Students. (arXiv:2106.15553v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1">Anett Hoppe</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1">David Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15553">
                                    <div class="article-summary-box-inner">
                                        <span>Illustrations are widely used in education, and sometimes, alternatives are
not available for visually impaired students. Therefore, those students would
benefit greatly from an automatic illustration description system, but only if
those descriptions were complete, correct, and easily understandable using a
screenreader. In this paper, we report on a study for the assessment of
automated image descriptions. We interviewed experts to establish evaluation
criteria, which we then used to create an evaluation questionnaire for sighted
non-expert raters, and description templates. We used this questionnaire to
evaluate the quality of descriptions which could be generated with a
template-based automatic image describer. We present evidence that these
templates have the potential to generate useful descriptions, and that the
questionnaire identifies problems with description templates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logic could be learned from images. (arXiv:1908.01931v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yuhua Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xinyan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Y/0/1/0/all/0/1">Yanhong She</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Deyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jiye Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01931">
                                    <div class="article-summary-box-inner">
                                        <span>Logic reasoning is a significant ability of human intelligence and also an
important task in artificial intelligence. The existing logic reasoning
methods, quite often, need to design some reasoning patterns beforehand. This
has led to an interesting question: can logic reasoning patterns be directly
learned from given data? The problem is termed as a data concept logic. In this
study, a learning logic task from images, called a LiLi task, first is
proposed. This task is to learn and reason the logic relation from images,
without presetting any reasoning patterns. As a preliminary exploration, we
design six LiLi data sets (Bitwise And, Bitwise Or, Bitwise Xor, Addition,
Subtraction and Multiplication), in which each image is embedded with a n-digit
number. It is worth noting that a learning model beforehand does not know the
meaning of the n-digit numbers embedded in images and the relation between the
input images and the output image. In order to tackle the task, in this work we
use many typical neural network models and produce fruitful results. However,
these models have the poor performances on the difficult logic task. For
furthermore addressing this task, a novel network framework called a divide and
conquer model by adding some label information is designed, achieving a high
testing accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Cluster Matching for Change Detection of Structures from Satellite Imagery. (arXiv:2103.09787v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1">Anthony Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan M. Lavista Ferres</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Brandon Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09787">
                                    <div class="article-summary-box-inner">
                                        <span>Longitudinal studies are vital to understanding dynamic changes of the
planet, but labels (e.g., buildings, facilities, roads) are often available
only for a single point in time. We propose a general model, Temporal Cluster
Matching (TCM), for detecting building changes in time series of remotely
sensed imagery when footprint labels are observed only once. The intuition
behind the model is that the relationship between spectral values inside and
outside of building&#x27;s footprint will change when a building is constructed (or
demolished). For instance, in rural settings, the pre-construction area may
look similar to the surrounding environment until the building is constructed.
Similarly, in urban settings, the pre-construction areas will look different
from the surrounding environment until construction. We further propose a
heuristic method for selecting the parameters of our model which allows it to
be applied in novel settings without requiring data labeling efforts (to fit
the parameters). We apply our model over a dataset of poultry barns from
2016/2017 high-resolution aerial imagery in the Delmarva Peninsula and a
dataset of solar farms from a 2020 mosaic of Sentinel 2 imagery in India. Our
results show that our model performs as well when fit using the proposed
heuristic as it does when fit with labeled data, and further, that supervised
versions of our model perform the best among all the baselines we test against.
Finally, we show that our proposed approach can act as an effective data
augmentation strategy -- it enables researchers to augment existing structure
footprint labels along the time dimension and thus use imagery from multiple
points in time to train deep learning models. We show that this improves the
spatial generalization of such models when evaluated on the same change
detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Multi-View Stereo via Plane Sweep: A Survey. (arXiv:2106.15328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qingtian Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15328">
                                    <div class="article-summary-box-inner">
                                        <span>3D reconstruction has lately attracted increasing attention due to its wide
application in many areas, such as autonomous driving, robotics and virtual
reality. As a dominant technique in artificial intelligence, deep learning has
been successfully adopted to solve various computer vision problems. However,
deep learning for 3D reconstruction is still at its infancy due to its unique
challenges and varying pipelines. To stimulate future research, this paper
presents a review of recent progress in deep learning methods for Multi-view
Stereo (MVS), which is considered as a crucial task of image-based 3D
reconstruction. It also presents comparative results on several publicly
available datasets, with insightful observations and inspiring future research
directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Evaluation of Domain Adaptation in Facial Expression Recognition. (arXiv:2106.15453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1">Yan San Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_V/0/1/0/all/0/1">Varsha Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Soh_J/0/1/0/all/0/1">Jonathan Soh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_D/0/1/0/all/0/1">Desmond C. Ong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15453">
                                    <div class="article-summary-box-inner">
                                        <span>Facial Expression Recognition is a commercially important application, but
one common limitation is that applications often require making predictions on
out-of-sample distributions, where target images may have very different
properties from the images that the model was trained on. How well, or badly,
do these models do on unseen target domains? In this paper, we provide a
systematic evaluation of domain adaptation in facial expression recognition.
Using state-of-the-art transfer learning techniques and six commonly-used
facial expression datasets (three collected in the lab and three
&quot;in-the-wild&quot;), we conduct extensive round-robin experiments to examine the
classification accuracies for a state-of-the-art CNN model. We also perform
multi-source experiments where we examine a model&#x27;s ability to transfer from
multiple source datasets, including (i) within-setting (e.g., lab to lab), (ii)
cross-setting (e.g., in-the-wild to lab), (iii) mixed-setting (e.g., lab and
wild to lab) transfer learning experiments. We find sobering results that the
accuracy of transfer learning is not high, and varies idiosyncratically with
the target dataset, and to a lesser extent the source dataset. Generally, the
best settings for transfer include fine-tuning the weights of a pre-trained
model, and we find that training with more datasets, regardless of setting,
improves transfer performance. We end with a discussion of the need for more --
and regular -- systematic investigations into the generalizability of FER
models, especially for deployed applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Padding in CNNs for Quantitative Susceptibility Mapping. (arXiv:2106.15331v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Juan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15331">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep learning methods have been proposed for quantitative
susceptibility mapping (QSM) data processing: background field removal,
field-to-source inversion, and single-step QSM reconstruction. However, the
conventional padding mechanism used in convolutional neural networks (CNNs) can
introduce spatial artifacts, especially in QSM background field removal and
single-step QSM which requires inference from total fields with extreme large
values at the edge boundaries of volume of interest. To address this issue, we
propose an improved padding technique which utilizes the neighboring valid
voxels to estimate the invalid voxels of feature maps at volume boundaries in
the neural networks. Studies using simulated and in-vivo data show that the
proposed padding greatly improves estimation accuracy and reduces artifacts in
the results in the tasks of background field removal, field-to-source
inversion, and single-step QSM reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmentation with Multiple Acceptable Annotations: A Case Study of Myocardial Segmentation in Contrast Echocardiography. (arXiv:2106.15597v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Dewen Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mingqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yukun Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaowei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1">Qiu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruixue Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1">Hongwen Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Meiping Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jian Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yiyu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15597">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing deep learning-based frameworks for image segmentation assume
that a unique ground truth is known and can be used for performance evaluation.
This is true for many applications, but not all. Myocardial segmentation of
Myocardial Contrast Echocardiography (MCE), a critical task in automatic
myocardial perfusion analysis, is an example. Due to the low resolution and
serious artifacts in MCE data, annotations from different cardiologists can
vary significantly, and it is hard to tell which one is the best. In this case,
how can we find a good way to evaluate segmentation performance and how do we
train the neural network? In this paper, we address the first problem by
proposing a new extended Dice to effectively evaluate the segmentation
performance when multiple accepted ground truth is available. Then based on our
proposed metric, we solve the second problem by further incorporating the new
metric into a loss function that enables neural networks to flexibly learn
general features of myocardium. Experiment results on our clinical MCE data set
demonstrate that the neural network trained with the proposed loss function
outperforms those existing ones that try to obtain a unique ground truth from
multiple annotations, both quantitatively and qualitatively. Finally, our
grading study shows that using extended Dice as an evaluation metric can better
identify segmentation results that need manual correction compared with using
Dice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Behavior-aware Graph Convolution Network Model for Video Recommendation. (arXiv:2106.15402v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1">Wei Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kunchi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1">Taofeng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1">Beihong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xinzhou Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">He Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wenhai Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuejian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15402">
                                    <div class="article-summary-box-inner">
                                        <span>Interactions between users and videos are the major data source of performing
video recommendation. Despite lots of existing recommendation methods, user
behaviors on videos, which imply the complex relations between users and
videos, are still far from being fully explored. In the paper, we present a
model named Sagittarius. Sagittarius adopts a graph convolutional neural
network to capture the influence between users and videos. In particular,
Sagittarius differentiates between different user behaviors by weighting and
fuses the semantics of user behaviors into the embeddings of users and videos.
Moreover, Sagittarius combines multiple optimization objectives to learn user
and video embeddings and then achieves the video recommendation by the learned
user and video embeddings. The experimental results on multiple datasets show
that Sagittarius outperforms several state-of-the-art models in terms of
recall, unique recall and NDCG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Cattle and Elk in the Wild from Space. (arXiv:2106.15448v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1">Anthony Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughey_L/0/1/0/all/0/1">Lacey Hughey</a>, <a href="http://arxiv.org/find/cs/1/au:+Stabach_J/0/1/0/all/0/1">Jared A. Stabach</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan M. Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15448">
                                    <div class="article-summary-box-inner">
                                        <span>Localizing and counting large ungulates -- hoofed mammals like cows and elk
-- in very high-resolution satellite imagery is an important task for
supporting ecological studies. Prior work has shown that this is feasible with
deep learning based methods and sub-meter multi-spectral satellite imagery. We
extend this line of work by proposing a baseline method, CowNet, that
simultaneously estimates the number of animals in an image (counts), as well as
predicts their location at a pixel level (localizes). We also propose an
methodology for evaluating such models on counting and localization tasks
across large scenes that takes the uncertainty of noisy labels and the
information needed by stakeholders in ecological monitoring tasks into account.
Finally, we benchmark our baseline method with state of the art vision methods
for counting objects in scenes. We specifically test the temporal
generalization of the resulting models over a large landscape in Point Reyes
Seashore, CA. We find that the LC-FCN model performs the best and achieves an
average precision between 0.56 and 0.61 and an average recall between 0.78 and
0.92 over three held out test scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IMENet: Joint 3D Semantic Scene Completion and 2D Semantic Segmentation through Iterative Mutual Enhancement. (arXiv:2106.15413v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Laiyan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1">Rui Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15413">
                                    <div class="article-summary-box-inner">
                                        <span>3D semantic scene completion and 2D semantic segmentation are two tightly
correlated tasks that are both essential for indoor scene understanding,
because they predict the same semantic classes, using positively correlated
high-level features. Current methods use 2D features extracted from early-fused
RGB-D images for 2D segmentation to improve 3D scene completion. We argue that
this sequential scheme does not ensure these two tasks fully benefit each
other, and present an Iterative Mutual Enhancement Network (IMENet) to solve
them jointly, which interactively refines the two tasks at the late prediction
stage. Specifically, two refinement modules are developed under a unified
framework for the two tasks. The first is a 2D Deformable Context Pyramid (DCP)
module, which receives the projection from the current 3D predictions to refine
the 2D predictions. In turn, a 3D Deformable Depth Attention (DDA) module is
proposed to leverage the reprojected results from 2D predictions to update the
coarse 3D predictions. This iterative fusion happens to the stable high-level
features of both tasks at a late stage. Extensive experiments on NYU and NYUCAD
datasets verify the effectiveness of the proposed iterative late fusion scheme,
and our approach outperforms the state of the art on both 3D semantic scene
completion and 2D semantic segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Questioner Transformer for Descriptive Question Generation in Goal-Oriented Visual Dialogue. (arXiv:2106.15550v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matsumori_S/0/1/0/all/0/1">Shoya Matsumori</a>, <a href="http://arxiv.org/find/cs/1/au:+Shingyouchi_K/0/1/0/all/0/1">Kosuke Shingyouchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_Y/0/1/0/all/0/1">Yuki Abe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukuchi_Y/0/1/0/all/0/1">Yosuke Fukuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>, <a href="http://arxiv.org/find/cs/1/au:+Imai_M/0/1/0/all/0/1">Michita Imai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15550">
                                    <div class="article-summary-box-inner">
                                        <span>Building an interactive artificial intelligence that can ask questions about
the real world is one of the biggest challenges for vision and language
problems. In particular, goal-oriented visual dialogue, where the aim of the
agent is to seek information by asking questions during a turn-taking dialogue,
has been gaining scholarly attention recently. While several existing models
based on the GuessWhat?! dataset have been proposed, the Questioner typically
asks simple category-based questions or absolute spatial questions. This might
be problematic for complex scenes where the objects share attributes or in
cases where descriptive questions are required to distinguish objects. In this
paper, we propose a novel Questioner architecture, called Unified Questioner
Transformer (UniQer), for descriptive question generation with referring
expressions. In addition, we build a goal-oriented visual dialogue task called
CLEVR Ask. It synthesizes complex scenes that require the Questioner to
generate descriptive questions. We train our model with two variants of CLEVR
Ask datasets. The results of the quantitative and qualitative evaluations show
that UniQer outperforms the baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and Accurate Road Crack Detection Based on Adaptive Cost-Sensitive Loss Function. (arXiv:2106.15510v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yingjie Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhiquan Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15510">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous detection problems in computer vision, including road crack
detection, suffer from exceedingly foreground-background imbalance.
Fortunately, modification of loss function appears to solve this puzzle once
and for all. In this paper, we propose a pixel-based adaptive weighted
cross-entropy loss in conjunction with Jaccard distance to facilitate
high-quality pixel-level road crack detection. Our work profoundly demonstrates
the influence of loss functions on detection outcomes, and sheds light on the
sophisticated consecutive improvements in the realm of crack detection.
Specifically, to verify the effectiveness of the proposed loss, we conduct
extensive experiments on four public databases, i.e., CrackForest, AigleRN,
Crack360, and BJN260. Compared with the vanilla weighted cross-entropy, the
proposed loss significantly speeds up the training process while retaining the
test accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Does Heterogeneous Label Noise Impact Generalization in Neural Nets?. (arXiv:2106.15475v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khanal_B/0/1/0/all/0/1">Bidur Khanal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1">Christopher Kanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15475">
                                    <div class="article-summary-box-inner">
                                        <span>Incorrectly labeled examples, or label noise, is common in real-world
computer vision datasets. While the impact of label noise on learning in deep
neural networks has been studied in prior work, these studies have exclusively
focused on homogeneous label noise, i.e., the degree of label noise is the same
across all categories. However, in the real-world, label noise is often
heterogeneous, with some categories being affected to a greater extent than
others. Here, we address this gap in the literature. We hypothesized that
heterogeneous label noise would only affect the classes that had label noise
unless there was transfer from those classes to the classes without label
noise. To test this hypothesis, we designed a series of computer vision studies
using MNIST, CIFAR-10, CIFAR-100, and MS-COCO where we imposed heterogeneous
label noise during the training of multi-class, multi-task, and multi-label
systems. Our results provide evidence in support of our hypothesis: label noise
only affects the class affected by it unless there is transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Medical Imaging for Intelligent Medical Image Analysis: Concepts, Methods, and Applications. (arXiv:1903.04855v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gou_C/0/1/0/all/0/1">Chao Gou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1">Tianyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wenbo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Huadan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1">Qiang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhengyu Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei-Yue Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.04855">
                                    <div class="article-summary-box-inner">
                                        <span>There has been much progress in data-driven artificial intelligence
technology for medical image analysis in the last decades. However, it still
remains challenging due to its distinctive complexity of acquiring and
annotating image data, extracting medical domain knowledge, and explaining the
diagnostic decision for medical image analysis. In this paper, we propose a
data-knowledge-driven framework termed as Parallel Medical Imaging (PMI) for
intelligent medical image analysis based on the methodology of interactive
ACP-based parallel intelligence. In the PMI framework, computational
experiments with predictive learning in a data-driven way are conducted to
extract medical knowledge for diagnostic decision support. Artificial imaging
systems are introduced to select and prescriptively generate medical image data
in a knowledge-driven way to utilize medical domain knowledge. Through the
closed-loop optimization based on parallel execution, our proposed PMI
framework can boost the generalization ability and alleviate the limitation of
medical interpretation for diagnostic decisions. Furthermore, we illustrate the
preliminary implementation of PMI method through the case studies of mammogram
analysis and skin lesion image analysis. Experimental results on several public
medical image datasets demonstrate the effectiveness of proposed PMI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Mixed-Supervision Multilevel GAN Framework for Image Quality Enhancement. (arXiv:2106.15575v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Upadhyay_U/0/1/0/all/0/1">Uddeshya Upadhyay</a>, <a href="http://arxiv.org/find/eess/1/au:+Awate_S/0/1/0/all/0/1">Suyash Awate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15575">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks for image quality enhancement typically need large
quantities of highly-curated training data comprising pairs of low-quality
images and their corresponding high-quality images. While high-quality image
acquisition is typically expensive and time-consuming, medium-quality images
are faster to acquire, at lower equipment costs, and available in larger
quantities. Thus, we propose a novel generative adversarial network (GAN) that
can leverage training data at multiple levels of quality (e.g., high and medium
quality) to improve performance while limiting costs of data curation. We apply
our mixed-supervision GAN to (i) super-resolve histopathology images and (ii)
enhance laparoscopy images by combining super-resolution and surgical smoke
removal. Results on large clinical and pre-clinical datasets show the benefits
of our mixed-supervision GAN over the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Framework for Spectral Dimensionality Reduction, Maximum Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial and Survey. (arXiv:2106.15379v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15379">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper on unification of spectral dimensionality
reduction methods, kernel learning by Semidefinite Programming (SDP), Maximum
Variance Unfolding (MVU) or Semidefinite Embedding (SDE), and its variants. We
first explain how the spectral dimensionality reduction methods can be unified
as kernel Principal Component Analysis (PCA) with different kernels. This
unification can be interpreted as eigenfunction learning or representation of
kernel in terms of distance matrix. Then, since the spectral methods are
unified as kernel PCA, we say let us learn the best kernel for unfolding the
manifold of data to its maximum variance. We first briefly introduce kernel
learning by SDP for the transduction task. Then, we explain MVU in detail.
Various versions of supervised MVU using nearest neighbors graph, by class-wise
unfolding, by Fisher criterion, and by colored MVU are explained. We also
explain out-of-sample extension of MVU using eigenfunctions and kernel mapping.
Finally, we introduce other variants of MVU including action respecting
embedding, relaxed MVU, and landmark MVU for big data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Guided Progressive GANs for Medical Image Translation. (arXiv:2106.15542v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_U/0/1/0/all/0/1">Uddeshya Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanbei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hepp_T/0/1/0/all/0/1">Tobias Hepp</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1">Sergios Gatidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15542">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-image translation plays a vital role in tackling various medical
imaging tasks such as attenuation correction, motion correction, undersampled
reconstruction, and denoising. Generative adversarial networks have been shown
to achieve the state-of-the-art in generating high fidelity images for these
tasks. However, the state-of-the-art GAN-based frameworks do not estimate the
uncertainty in the predictions made by the network that is essential for making
informed medical decisions and subsequent revision by medical experts and has
recently been shown to improve the performance and interpretability of the
model. In this work, we propose an uncertainty-guided progressive learning
scheme for image-to-image translation. By incorporating aleatoric uncertainty
as attention maps for GANs trained in a progressive manner, we generate images
of increasing fidelity progressively. We demonstrate the efficacy of our model
on three challenging medical image translation tasks, including PET to CT
translation, undersampled MRI reconstruction, and MRI motion artefact
correction. Our model generalizes well in three different tasks and improves
performance over state of the art under full-supervision and weak-supervision
with limited data. Code is released here:
https://github.com/ExplainableML/UncerGuidedI2I</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wasserstein Adversarial Regularization (WAR) on label noise. (arXiv:1904.03936v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fatras_K/0/1/0/all/0/1">Kilian Fatras</a>, <a href="http://arxiv.org/find/cs/1/au:+Damodaran_B/0/1/0/all/0/1">Bharath Bhushan Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lobry_S/0/1/0/all/0/1">Sylvain Lobry</a>, <a href="http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1">R&#xe9;mi Flamary</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1">Devis Tuia</a>, <a href="http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1">Nicolas Courty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03936">
                                    <div class="article-summary-box-inner">
                                        <span>Noisy labels often occur in vision datasets, especially when they are
obtained from crowdsourcing or Web scraping. We propose a new regularization
method, which enables learning robust classifiers in presence of noisy data. To
achieve this goal, we propose a new adversarial regularization scheme based on
the Wasserstein distance. Using this distance allows taking into account
specific relations between classes by leveraging the geometric properties of
the labels space. Our Wasserstein Adversarial Regularization (WAR) encodes a
selective regularization, which promotes smoothness of the classifier between
some classes, while preserving sufficient complexity of the decision boundary
between others. We first discuss how and why adversarial regularization can be
used in the context of label noise and then show the effectiveness of our
method on five datasets corrupted with noisy labels: in both benchmarks and
real datasets, WAR outperforms the state-of-the-art competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Winner Team Mia at TextVQA Challenge 2021: Vision-and-Language Representation Learning with Pre-trained Sequence-to-Sequence Model. (arXiv:2106.15332v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yixuan Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yihao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xianbin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xianbiao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1">Guotong Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15332">
                                    <div class="article-summary-box-inner">
                                        <span>TextVQA requires models to read and reason about text in images to answer
questions about them. Specifically, models need to incorporate a new modality
of text present in the images and reason over it to answer TextVQA questions.
In this challenge, we use generative model T5 for TextVQA task. Based on
pre-trained checkpoint T5-3B from HuggingFace repository, two other
pre-training tasks including masked language modeling(MLM) and relative
position prediction(RPP) are designed to better align object feature and scene
text. In the stage of pre-training, encoder is dedicate to handle the fusion
among multiple modalities: question text, object text labels, scene text
labels, object visual features, scene visual features. After that decoder
generates the text sequence step-by-step, cross entropy loss is required by
default. We use a large-scale scene text dataset in pre-training and then
fine-tune the T5-3B with the TextVQA dataset only.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-Stage Self-Supervised Cycle-Consistency Network for Reconstruction of Thin-Slice MR Images. (arXiv:2106.15395v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lu_Z/0/1/0/all/0/1">Zhiyang Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+shi_J/0/1/0/all/0/1">Jun shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_D/0/1/0/all/0/1">Dinggang Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15395">
                                    <div class="article-summary-box-inner">
                                        <span>The thick-slice magnetic resonance (MR) images are often structurally blurred
in coronal and sagittal views, which causes harm to diagnosis and image
post-processing. Deep learning (DL) has shown great potential to re-construct
the high-resolution (HR) thin-slice MR images from those low-resolution (LR)
cases, which we refer to as the slice interpolation task in this work. However,
since it is generally difficult to sample abundant paired LR-HR MR images, the
classical fully supervised DL-based models cannot be effectively trained to get
robust performance. To this end, we propose a novel Two-stage Self-supervised
Cycle-consistency Network (TSCNet) for MR slice interpolation, in which a
two-stage self-supervised learning (SSL) strategy is developed for unsupervised
DL network training. The paired LR-HR images are synthesized along the sagittal
and coronal directions of input LR images for network pretraining in the
first-stage SSL, and then a cyclic in-terpolation procedure based on triplet
axial slices is designed in the second-stage SSL for further refinement. More
training samples with rich contexts along all directions are exploited as
guidance to guarantee the improved in-terpolation performance. Moreover, a new
cycle-consistency constraint is proposed to supervise this cyclic procedure,
which encourages the network to reconstruct more realistic HR images. The
experimental results on a real MRI dataset indicate that TSCNet achieves
superior performance over the conventional and other SSL-based algorithms, and
obtains competitive quali-tative and quantitative results compared with the
fully supervised algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple Graph Learning for Scalable Multi-view Clustering. (arXiv:2106.15382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tianyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Quanxue Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15382">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based multi-view clustering has become an active topic due to the
efficiency in characterizing both the complex structure and relationship
between multimedia data. However, existing methods have the following
shortcomings: (1) They are inefficient or even fail for graph learning in large
scale due to the graph construction and eigen-decomposition. (2) They cannot
well exploit both the complementary information and spatial structure embedded
in graphs of different views. To well exploit complementary information and
tackle the scalability issue plaguing graph-based multi-view clustering, we
propose an efficient multiple graph learning model via a small number of anchor
points and tensor Schatten p-norm minimization. Specifically, we construct a
hidden and tractable large graph by anchor graph for each view and well exploit
complementary information embedded in anchor graphs of different views by
tensor Schatten p-norm regularizer. Finally, we develop an efficient algorithm,
which scales linearly with the data size, to solve our proposed model.
Extensive experimental results on several datasets indicate that our proposed
method outperforms some state-of-the-art multi-view clustering algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TANet++: Triple Attention Network with Filtered Pointcloud on 3D Detection. (arXiv:2106.15366v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Cong Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15366">
                                    <div class="article-summary-box-inner">
                                        <span>TANet is one of state-of-the-art 3D object detection method on KITTI and JRDB
benchmark, the network contains a Triple Attention module and Coarse-to-Fine
Regression module to improve the robustness and accuracy of 3D Detection.
However, since the original input data (point clouds) contains a lot of noise
during collecting the data, which will further affect the training of the
model. For example, the object is far from the robot, the sensor is difficult
to obtain enough pointcloud. If the objects only contains few point clouds, and
the samples are fed into model with the normal samples together during
training, the detector will be difficult to distinguish the individual with few
pointcloud belong to object or background. In this paper, we propose TANet++ to
improve the performance on 3D Detection, which adopt a novel training strategy
on training the TANet. In order to reduce the negative impact by the weak
samples, the training strategy previously filtered the training data, and then
the TANet++ is trained by the rest of data. The experimental results shows that
AP score of TANet++ is 8.98\% higher than TANet on JRDB benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Where is the disease? Semi-supervised pseudo-normality synthesis from an abnormal image. (arXiv:2106.15345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yuanqi Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_Q/0/1/0/all/0/1">Quan Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">S. Kevin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15345">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-normality synthesis, which computationally generates a pseudo-normal
image from an abnormal one (e.g., with lesions), is critical in many
perspectives, from lesion detection, data augmentation to clinical surgery
suggestion. However, it is challenging to generate high-quality pseudo-normal
images in the absence of the lesion information. Thus, expensive lesion
segmentation data have been introduced to provide lesion information for the
generative models and improve the quality of the synthetic images. In this
paper, we aim to alleviate the need of a large amount of lesion segmentation
data when generating pseudo-normal images. We propose a Semi-supervised Medical
Image generative LEarning network (SMILE) which not only utilizes limited
medical images with segmentation masks, but also leverages massive medical
images without segmentation masks to generate realistic pseudo-normal images.
Extensive experiments show that our model outperforms the best state-of-the-art
model by up to 6% for data augmentation task and 3% in generating high-quality
images. Moreover, the proposed semi-supervised learning achieves comparable
medical image synthesis quality with supervised learning model, using only 50
of segmentation data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spiking-GAN: A Spiking Generative Adversarial Network Using Time-To-First-Spike Coding. (arXiv:2106.15420v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotariya_V/0/1/0/all/0/1">Vineet Kotariya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguly_U/0/1/0/all/0/1">Udayan Ganguly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15420">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs) have shown great potential in solving deep
learning problems in an energy-efficient manner. However, they are still
limited to simple classification tasks. In this paper, we propose Spiking-GAN,
the first spike-based Generative Adversarial Network (GAN). It employs a kind
of temporal coding scheme called time-to-first-spike coding. We train it using
approximate backpropagation in the temporal domain. We use simple
integrate-and-fire (IF) neurons with very high refractory period for our
network which ensures a maximum of one spike per neuron. This makes the model
much sparser than a spike rate-based system. Our modified temporal loss
function called &#x27;Aggressive TTFS&#x27; improves the inference time of the network by
over 33% and reduces the number of spikes in the network by more than 11%
compared to previous works. Our experiments show that on training the network
on the MNIST dataset using this approach, we can generate high quality samples.
Thereby demonstrating the potential of this framework for solving such problems
in the spiking domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-stage Optimization based Adversarial Training. (arXiv:2106.15357v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaosen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chuanbiao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15357">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of adversarial robustness, there is a common practice that
adopts the single-step adversarial training for quickly developing
adversarially robust models. However, the single-step adversarial training is
most likely to cause catastrophic overfitting, as after a few training epochs
it will be hard to generate strong adversarial examples to continuously boost
the adversarial robustness. In this work, we aim to avoid the catastrophic
overfitting by introducing multi-step adversarial examples during the
single-step adversarial training. Then, to balance the large training overhead
of generating multi-step adversarial examples, we propose a Multi-stage
Optimization based Adversarial Training (MOAT) method that periodically trains
the model on mixed benign examples, single-step adversarial examples, and
multi-step adversarial examples stage by stage. In this way, the overall
training overhead is reduced significantly, meanwhile, the model could avoid
catastrophic overfitting. Extensive experiments on CIFAR-10 and CIFAR-100
datasets demonstrate that under similar amount of training overhead, the
proposed MOAT exhibits better robustness than either single-step or multi-step
adversarial training methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LB-CNN: An Open Source Framework for Fast Training of Light Binary Convolutional Neural Networks using Chainer and Cupy. (arXiv:2106.15350v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dogaru_R/0/1/0/all/0/1">Radu Dogaru</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogaru_I/0/1/0/all/0/1">Ioana Dogaru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15350">
                                    <div class="article-summary-box-inner">
                                        <span>Light binary convolutional neural networks (LB-CNN) are particularly useful
when implemented in low-energy computing platforms as required in many
industrial applications. Herein, a framework for optimizing compact LB-CNN is
introduced and its effectiveness is evaluated. The framework is freely
available and may run on free-access cloud platforms, thus requiring no major
investments. The optimized model is saved in the standardized .h5 format and
can be used as input to specialized tools for further deployment into specific
technologies, thus enabling the rapid development of various intelligent image
sensors. The main ingredient in accelerating the optimization of our model,
particularly the selection of binary convolution kernels, is the Chainer/Cupy
machine learning library offering significant speed-ups for training the output
layer as an extreme-learning machine. Additional training of the output layer
using Keras/Tensorflow is included, as it allows an increase in accuracy.
Results for widely used datasets including MNIST, GTSRB, ORL, VGG show very
good compromise between accuracy and complexity. Particularly, for face
recognition problems a carefully optimized LB-CNN model provides up to 100%
accuracies. Such TinyML solutions are well suited for industrial applications
requiring image recognition with low energy consumption.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Attention for Interactive Segmentation. (arXiv:2106.15338v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gabbur_P/0/1/0/all/0/1">Prasad Gabbur</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilkhu_M/0/1/0/all/0/1">Manjot Bilkhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Movellan_J/0/1/0/all/0/1">Javier Movellan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15338">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a probabilistic interpretation of attention and show that the
standard dot-product attention in transformers is a special case of Maximum A
Posteriori (MAP) inference. The proposed approach suggests the use of
Expectation Maximization algorithms for online adaptation of key and value
model parameters. This approach is useful for cases in which external agents,
e.g., annotators, provide inference-time information about the correct values
of some tokens, e.g, the semantic category of some pixels, and we need for this
new information to propagate to other tokens in a principled manner. We
illustrate the approach on an interactive semantic segmentation task in which
annotators and models collaborate online to improve annotation efficiency.
Using standard benchmarks, we observe that key adaptation boosts model
performance ($\sim10\%$ mIoU) in the low feedback regime and value propagation
improves model responsiveness in the high feedback regime. A PyTorch layer
implementation of our probabilistic attention model will be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Study of visual processing techniques for dynamic speckles: a comparative analysis. (arXiv:2106.15507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1">Amit Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhanotiya_J/0/1/0/all/0/1">Jitendra Dhanotiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_V/0/1/0/all/0/1">Vimal Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1">Shashi Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15507">
                                    <div class="article-summary-box-inner">
                                        <span>Main visual techniques used to obtain information from speckle patterns are
Fujii method, generalized difference, weighted generalized difference, mean
windowed difference, structural function (SF), modified SF, etc. In this work,
a comparative analysis of major visual techniques for natural gum sample is
carried out. Obtained results conclusively establish SF based method as an
optimum tool for visual inspection of dynamic speckle data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text Prior Guided Scene Text Image Super-resolution. (arXiv:2106.15368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianqi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15368">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text image super-resolution (STISR) aims to improve the resolution and
visual quality of low-resolution (LR) scene text images, and consequently boost
the performance of text recognition. However, most of existing STISR methods
regard text images as natural scene images, ignoring the categorical
information of text. In this paper, we make an inspiring attempt to embed
categorical text prior into STISR model training. Specifically, we adopt the
character probability sequence as the text prior, which can be obtained
conveniently from a text recognition model. The text prior provides categorical
guidance to recover high-resolution (HR) text images. On the other hand, the
reconstructed HR image can refine the text prior in return. Finally, we present
a multi-stage text prior guided super-resolution (TPGSR) framework for STISR.
Our experiments on the benchmark TextZoom dataset show that TPGSR can not only
effectively improve the visual quality of scene text images, but also
significantly improve the text recognition accuracy over existing STISR
methods. Our model trained on TextZoom also demonstrates certain generalization
capability to the LR images in other datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying urban streetscapes with deep learning: focus on aesthetic evaluation. (arXiv:2106.15361v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumakoshi_Y/0/1/0/all/0/1">Yusuke Kumakoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoda_S/0/1/0/all/0/1">Shigeaki Onoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1">Tetsuya Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshimura_Y/0/1/0/all/0/1">Yuji Yoshimura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15361">
                                    <div class="article-summary-box-inner">
                                        <span>The disorder of urban streetscapes would negatively affect people&#x27;s
perception of their aesthetic quality. The presence of billboards on building
facades has been regarded as an important factor of the disorder, but its
quantification methodology has not yet been developed in a scalable manner. To
fill the gap, this paper reports the performance of our deep learning model on
a unique data set prepared in Tokyo to recognize the areas covered by facades
and billboards in streetscapes, respectively. The model achieved 63.17 % of
accuracy, measured by Intersection-over-Union (IoU), thus enabling researchers
and practitioners to obtain insights on urban streetscape design by combining
data of people&#x27;s preferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Inpainting Using Wasserstein Generative Adversarial Imputation Network. (arXiv:2106.15341v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasata_D/0/1/0/all/0/1">Daniel Va&#x161;ata</a>, <a href="http://arxiv.org/find/cs/1/au:+Halama_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Halama</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedjungova_M/0/1/0/all/0/1">Magda Friedjungov&#xe1;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15341">
                                    <div class="article-summary-box-inner">
                                        <span>Image inpainting is one of the important tasks in computer vision which
focuses on the reconstruction of missing regions in an image. The aim of this
paper is to introduce an image inpainting model based on Wasserstein Generative
Adversarial Imputation Network. The generator network of the model uses
building blocks of convolutional layers with different dilation rates, together
with skip connections that help the model reproduce fine details of the output.
This combination yields a universal imputation model that is able to handle
various scenarios of missingness with sufficient quality. To show this
experimentally, the model is simultaneously trained to deal with three
scenarios given by missing pixels at random, missing various smaller square
regions, and one missing square placed in the center of the image. It turns out
that our model achieves high-quality inpainting results on all scenarios.
Performance is evaluated using peak signal-to-noise ratio and structural
similarity index on two real-world benchmark datasets, CelebA faces and Paris
StreetView. The results of our model are compared to biharmonic imputation and
to some of the other state-of-the-art image inpainting methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Source-free Domain Adaptation via Avatar Prototype Generation and Adaptation. (arXiv:2106.15326v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1">Zhen Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongbin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yanxia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1">Qing Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15326">
                                    <div class="article-summary-box-inner">
                                        <span>We study a practical domain adaptation task, called source-free unsupervised
domain adaptation (UDA) problem, in which we cannot access source domain data
due to data privacy issues but only a pre-trained source model and unlabeled
target data are available. This task, however, is very difficult due to one key
challenge: the lack of source data and target domain labels makes model
adaptation very challenging. To address this, we propose to mine the hidden
knowledge in the source model and exploit it to generate source avatar
prototypes (i.e., representative features for each source class) as well as
target pseudo labels for domain alignment. To this end, we propose a
Contrastive Prototype Generation and Adaptation (CPGA) method. Specifically,
CPGA consists of two stages: (1) prototype generation: by exploring the
classification boundary information of the source model, we train a prototype
generator to generate avatar prototypes via contrastive learning. (2) prototype
adaptation: based on the generated source prototypes and target pseudo labels,
we develop a new robust contrastive prototype adaptation strategy to align each
pseudo-labeled target data to the corresponding source prototypes. Extensive
experiments on three UDA benchmark datasets demonstrate the effectiveness and
superiority of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Evaluation of Deep Active Learning on Image Classification Tasks. (arXiv:2106.15324v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1">Durga Sivasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Dani_A/0/1/0/all/0/1">Apurva Dani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15324">
                                    <div class="article-summary-box-inner">
                                        <span>With the goal of making deep learning more label-efficient, a growing number
of papers have been studying active learning (AL) for deep models. However,
there are a number of issues in the prevalent experimental settings, mainly
stemming from a lack of unified implementation and benchmarking. Issues in the
current literature include sometimes contradictory observations on the
performance of different AL algorithms, unintended exclusion of important
generalization approaches such as data augmentation and SGD for optimization, a
lack of study of evaluation facets like the labeling efficiency of AL, and
little or no clarity on the scenarios in which AL outperforms random sampling
(RS). In this work, we present a unified re-implementation of state-of-the-art
AL algorithms in the context of image classification, and we carefully study
these issues as facets of effective evaluation. On the positive side, we show
that AL techniques are 2x to 4x more label-efficient compared to RS with the
use of data augmentation. Surprisingly, when data augmentation is included,
there is no longer a consistent gain in using BADGE, a state-of-the-art
approach, over simple uncertainty sampling. We then do a careful analysis of
how existing approaches perform with varying amounts of redundancy and number
of examples per class. Finally, we provide several insights for AL
practitioners to consider in future work, such as the effect of the AL batch
size, the effect of initialization, the importance of retraining a new model at
every round, and other insights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patch-Based Image Restoration using Expectation Propagation. (arXiv:2106.15327v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1">Dan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+McLaughlin_S/0/1/0/all/0/1">Stephen McLaughlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Altmann_Y/0/1/0/all/0/1">Yoann Altmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15327">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new Expectation Propagation (EP) framework for image
restoration using patch-based prior distributions. While Monte Carlo techniques
are classically used to sample from intractable posterior distributions, they
can suffer from scalability issues in high-dimensional inference problems such
as image restoration. To address this issue, EP is used here to approximate the
posterior distributions using products of multivariate Gaussian densities.
Moreover, imposing structural constraints on the covariance matrices of these
densities allows for greater scalability and distributed computation. While the
method is naturally suited to handle additive Gaussian observation noise, it
can also be extended to non-Gaussian noise. Experiments conducted for
denoising, inpainting and deconvolution problems with Gaussian and Poisson
noise illustrate the potential benefits of such flexible approximate Bayesian
method for uncertainty quantification in imaging problems, at a reduced
computational cost compared to sampling techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cloud based Scalable Object Recognition from Video Streams using Orientation Fusion and Convolutional Neural Networks. (arXiv:2106.15329v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaseen_M/0/1/0/all/0/1">Muhammad Usman Yaseen</a>, <a href="http://arxiv.org/find/cs/1/au:+Anjum_A/0/1/0/all/0/1">Ashiq Anjum</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortino_G/0/1/0/all/0/1">Giancarlo Fortino</a>, <a href="http://arxiv.org/find/cs/1/au:+Liotta_A/0/1/0/all/0/1">Antonio Liotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1">Amir Hussain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15329">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition from live video streams comes with numerous challenges
such as the variation in illumination conditions and poses. Convolutional
neural networks (CNNs) have been widely used to perform intelligent visual
object recognition. Yet, CNNs still suffer from severe accuracy degradation,
particularly on illumination-variant datasets. To address this problem, we
propose a new CNN method based on orientation fusion for visual object
recognition. The proposed cloud-based video analytics system pioneers the use
of bi-dimensional empirical mode decomposition to split a video frame into
intrinsic mode functions (IMFs). We further propose these IMFs to endure Reisz
transform to produce monogenic object components, which are in turn used for
the training of CNNs. Past works have demonstrated how the object orientation
component may be used to pursue accuracy levels as high as 93\%. Herein we
demonstrate how a feature-fusion strategy of the orientation components leads
to further improving visual recognition accuracy to 97\%. We also assess the
scalability of our method, looking at both the number and the size of the video
streams under scrutiny. We carry out extensive experimentation on the publicly
available Yale dataset, including also a self generated video datasets, finding
significant improvements (both in accuracy and scale), in comparison to
AlexNet, LeNet and SE-ResNeXt, which are the three most commonly used deep
learning models for visual object recognition and classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TNCR: Table Net Detection and Classification Dataset. (arXiv:2106.15322v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1">Abdelrahman Abdallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Berendeyev_A/0/1/0/all/0/1">Alexander Berendeyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuradin_I/0/1/0/all/0/1">Islam Nuradin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nurseitov_D/0/1/0/all/0/1">Daniyar Nurseitov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15322">
                                    <div class="article-summary-box-inner">
                                        <span>We present TNCR, a new table dataset with varying image quality collected
from free websites. The TNCR dataset can be used for table detection in scanned
document images and their classification into 5 different classes. TNCR
contains 9428 high-quality labeled images. In this paper, we have implemented
state-of-the-art deep learning-based methods for table detection to create
several strong baselines. Cascade Mask R-CNN with ResNeXt-101-64x4d Backbone
Network achieves the highest performance compared to other methods with a
precision of 79.7%, recall of 89.8%, and f1 score of 84.4% on the TNCR dataset.
We have made TNCR open source in the hope of encouraging more deep learning
approaches to table detection, classification, and structure recognition. The
dataset and trained model checkpoints are available at
https://github.com/abdoelsayed2016/TNCR_Dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SE-MD: A Single-encoder multiple-decoder deep network for point cloud generation from 2D images. (arXiv:2106.15325v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hafiz_A/0/1/0/all/0/1">Abdul Mueed Hafiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1">Rouf Ul Alam Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Parah_S/0/1/0/all/0/1">Shabir Ahmad Parah</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassaballah_M/0/1/0/all/0/1">M. Hassaballah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15325">
                                    <div class="article-summary-box-inner">
                                        <span>3D model generation from single 2D RGB images is a challenging and actively
researched computer vision task. Various techniques using conventional network
architectures have been proposed for the same. However, the body of research
work is limited and there are various issues like using inefficient 3D
representation formats, weak 3D model generation backbones, inability to
generate dense point clouds, dependence of post-processing for generation of
dense point clouds, and dependence on silhouettes in RGB images. In this paper,
a novel 2D RGB image to point cloud conversion technique is proposed, which
improves the state of art in the field due to its efficient, robust and simple
model by using the concept of parallelization in network architecture. It not
only uses the efficient and rich 3D representation of point clouds, but also
uses a novel and robust point cloud generation backbone in order to address the
prevalent issues. This involves using a single-encoder multiple-decoder deep
network architecture wherein each decoder generates certain fixed viewpoints.
This is followed by fusing all the viewpoints to generate a dense point cloud.
Various experiments are conducted on the technique and its performance is
compared with those of other state of the art techniques and impressive gains
in performance are demonstrated. Code is available at
https://github.com/mueedhafiz1982/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Serial-EMD: Fast Empirical Mode Decomposition Method for Multi-dimensional Signals Based on Serialization. (arXiv:2106.15319v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Marti_Puig_P/0/1/0/all/0/1">Pere Marti-Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Caiafa_C/0/1/0/all/0/1">Cesar F. Caiafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhe Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_F/0/1/0/all/0/1">Feng Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sole_Casals_J/0/1/0/all/0/1">Jordi Sol&#xe9;-Casals</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15319">
                                    <div class="article-summary-box-inner">
                                        <span>Empirical mode decomposition (EMD) has developed into a prominent tool for
adaptive, scale-based signal analysis in various fields like robotics, security
and biomedical engineering. Since the dramatic increase in amount of data puts
forward higher requirements for the capability of real-time signal analysis, it
is difficult for existing EMD and its variants to trade off the growth of data
dimension and the speed of signal analysis. In order to decompose
multi-dimensional signals at a faster speed, we present a novel
signal-serialization method (serial-EMD), which concatenates multi-variate or
multi-dimensional signals into a one-dimensional signal and uses various
one-dimensional EMD algorithms to decompose it. To verify the effects of the
proposed method, synthetic multi-variate time series, artificial 2D images with
various textures and real-world facial images are tested. Compared with
existing multi-EMD algorithms, the decomposition time becomes significantly
reduced. In addition, the results of facial recognition with Intrinsic Mode
Functions (IMFs) extracted using our method can achieve a higher accuracy than
those obtained by existing multi-EMD algorithms, which demonstrates the
superior performance of our method in terms of the quality of IMFs.
Furthermore, this method can provide a new perspective to optimize the existing
EMD algorithms, that is, transforming the structure of the input signal rather
than being constrained by developing envelope computation techniques or signal
decomposition methods. In summary, the study suggests that the serial-EMD
technique is a highly competitive and fast alternative for multi-dimensional
signal analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in Minimally Invasive Interventional Treatment. (arXiv:2106.15306v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruijters_D/0/1/0/all/0/1">Daniel Ruijters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15306">
                                    <div class="article-summary-box-inner">
                                        <span>Minimally invasive image guided treatment procedures often employ advanced
image processing algorithms. The recent developments of artificial intelligence
algorithms harbor potential to further enhance this domain. In this article we
explore several application areas within the minimally invasive treatment space
and discuss the deployment of artificial intelligence within these areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Face Identification Proficiency Test Designed Using Item Response Theory. (arXiv:2106.15323v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeckeln_G/0/1/0/all/0/1">G&#xe9;raldine Jeckeln</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Ying Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavazos_J/0/1/0/all/0/1">Jacqueline G. Cavazos</a>, <a href="http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1">Amy N. Yates</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_C/0/1/0/all/0/1">Carina A. Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Larry Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1">Jonathon Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+OToole_A/0/1/0/all/0/1">Alice J. O&#x27;Toole</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15323">
                                    <div class="article-summary-box-inner">
                                        <span>Measures of face identification proficiency are essential to ensure accurate
and consistent performance by professional forensic face examiners and others
who perform face identification tasks in applied scenarios. Current proficiency
tests rely on static sets of stimulus items, and so, cannot be administered
validly to the same individual multiple times. To create a proficiency test, a
large number of items of &quot;known&quot; difficulty must be assembled. Multiple tests
of equal difficulty can be constructed then using subsets of items. Here, we
introduce a proficiency test, the Triad Identity Matching (TIM) test, based on
stimulus difficulty measures based on Item Response Theory (IRT). Participants
view face-image &quot;triads&quot; (N&#x3D;225) (two images of one identity and one image of a
different identity) and select the different identity. In Experiment 1,
university students (N&#x3D;197) showed wide-ranging accuracy on the TIM test.
Furthermore, IRT modeling demonstrated that the TIM test produces items of
various difficulty levels. In Experiment 2, IRT-based item difficulty measures
were used to partition the TIM test into three equally &quot;easy&quot; and three equally
&quot;difficult&quot; subsets. Simulation results indicated that the full set, as well as
curated subsets, of the TIM items yielded reliable estimates of subject
ability. In summary, the TIM test can provide a starting point for developing a
framework that is flexible, calibrated, and adaptive to measure proficiency
across various ability levels (e.g., professionals or populations with face
processing deficits)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boggart: Accelerating Retrospective Video Analytics via Model-Agnostic Ingest Processing. (arXiv:2106.15315v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1">Neil Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Netravali_R/0/1/0/all/0/1">Ravi Netravali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15315">
                                    <div class="article-summary-box-inner">
                                        <span>Delivering fast responses to retrospective queries on video datasets is
difficult due to the large number of frames to consider and the high costs of
running convolutional neural networks (CNNs) on each one. A natural solution is
to perform a subset of the necessary computations ahead of time, as video is
ingested. However, existing ingest-time systems require knowledge of the
specific CNN that will be used in future queries -- a challenging requisite
given the evergrowing space of CNN architectures and training
datasets/methodologies.

This paper presents Boggart, a retrospective video analytics system that
delivers ingest-time speedups in a model-agnostic manner. Our underlying
insight is that traditional computer vision (CV) algorithms are capable of
performing computations that can be used to accelerate diverse queries with
wide-ranging CNNs. Building on this, at ingest-time, Boggart carefully employs
a variety of motion tracking algorithms to identify potential objects and their
trajectories across frames. Then, at query-time, Boggart uses several novel
techniques to collect the smallest sample of CNN results required to meet the
target accuracy: (1) a clustering strategy to efficiently unearth the
inevitable discrepancies between CV- and CNN-generated outputs, and (2) a set
of accuracy-preserving propagation techniques to safely extend sampled results
along each trajectory. Across many videos, CNNs, and queries Boggart
consistently meets accuracy targets while using CNNs sparingly (on 3-54% of
frames).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Similarity Embedding Networks for Robust Human Activity Recognition. (arXiv:2106.15283v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_C/0/1/0/all/0/1">Carrie Lu Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Di Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xiao Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Lei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jian Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianming Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15283">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models for human activity recognition (HAR) based on sensor
data have been heavily studied recently. However, the generalization ability of
deep models on complex real-world HAR data is limited by the availability of
high-quality labeled activity data, which are hard to obtain. In this paper, we
design a similarity embedding neural network that maps input sensor signals
onto real vectors through carefully designed convolutional and LSTM layers. The
embedding network is trained with a pairwise similarity loss, encouraging the
clustering of samples from the same class in the embedded real space, and can
be effectively trained on a small dataset and even on a noisy dataset with
mislabeled samples. Based on the learned embeddings, we further propose both
nonparametric and parametric approaches for activity recognition. Extensive
evaluation based on two public datasets has shown that the proposed similarity
embedding network significantly outperforms state-of-the-art deep models on HAR
classification tasks, is robust to mislabeled samples in the training set, and
can also be used to effectively denoise a noisy dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MFR 2021: Masked Face Recognition Competition. (arXiv:2106.15288v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1">Fadi Boutros</a>, <a href="http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1">Naser Damer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolf_J/0/1/0/all/0/1">Jan Niklas Kolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Raja_K/0/1/0/all/0/1">Kiran Raja</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1">Florian Kirchbuchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandra_R/0/1/0/all/0/1">Raghavendra Ramachandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1">Arjan Kuijper</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_P/0/1/0/all/0/1">Pengcheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Montero_D/0/1/0/all/0/1">David Montero</a>, <a href="http://arxiv.org/find/cs/1/au:+Aginako_N/0/1/0/all/0/1">Naiara Aginako</a>, <a href="http://arxiv.org/find/cs/1/au:+Sierra_B/0/1/0/all/0/1">Basilio Sierra</a>, <a href="http://arxiv.org/find/cs/1/au:+Nieto_M/0/1/0/all/0/1">Marcos Nieto</a>, <a href="http://arxiv.org/find/cs/1/au:+Erakin_M/0/1/0/all/0/1">Mustafa Ekrem Erakin</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_U/0/1/0/all/0/1">Ugur Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemal_H/0/1/0/all/0/1">Hazim Kemal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekenel/0/1/0/all/0/1">Ekenel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kataoka_A/0/1/0/all/0/1">Asaki Kataoka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ichikawa_K/0/1/0/all/0/1">Kohei Ichikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubo_S/0/1/0/all/0/1">Shizuma Kubo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Mingjie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dan Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Grm_K/0/1/0/all/0/1">Klemen Grm</a>, <a href="http://arxiv.org/find/cs/1/au:+Struc_V/0/1/0/all/0/1">Vitomir &#x160;truc</a>, <a href="http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1">Sachith Seneviratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasthuriarachchi_N/0/1/0/all/0/1">Nuran Kasthuriarachchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasnayaka_S/0/1/0/all/0/1">Sanka Rasnayaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Neto_P/0/1/0/all/0/1">Pedro C. Neto</a>, <a href="http://arxiv.org/find/cs/1/au:+Sequeira_A/0/1/0/all/0/1">Ana F. Sequeira</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1">Joao Ribeiro Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Saffari_M/0/1/0/all/0/1">Mohsen Saffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Cardoso_J/0/1/0/all/0/1">Jaime S. Cardoso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15288">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a summary of the Masked Face Recognition Competitions
(MFR) held within the 2021 International Joint Conference on Biometrics (IJCB
2021). The competition attracted a total of 10 participating teams with valid
submissions. The affiliations of these teams are diverse and associated with
academia and industry in nine different countries. These teams successfully
submitted 18 valid solutions. The competition is designed to motivate solutions
aiming at enhancing the face recognition accuracy of masked faces. Moreover,
the competition considered the deployability of the proposed solutions by
taking the compactness of the face recognition models into account. A private
dataset representing a collaborative, multi-session, real masked, capture
scenario is used to evaluate the submitted solutions. In comparison to one of
the top-performing academic face recognition solutions, 10 out of the 18
submitted solutions did score higher masked face verification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ScanBank: A Benchmark Dataset for Figure Extraction from Scanned Electronic Theses and Dissertations. (arXiv:2106.15320v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kahu_S/0/1/0/all/0/1">Sampanna Yashwant Kahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingram_W/0/1/0/all/0/1">William A. Ingram</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1">Edward A. Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15320">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on electronic theses and dissertations (ETDs), aiming to improve
access and expand their utility, since more than 6 million are publicly
available, and they constitute an important corpus to aid research and
education across disciplines. The corpus is growing as new born-digital
documents are included, and since millions of older theses and dissertations
have been converted to digital form to be disseminated electronically in
institutional repositories. In ETDs, as with other scholarly works, figures and
tables can communicate a large amount of information in a concise way. Although
methods have been proposed for extracting figures and tables from born-digital
PDFs, they do not work well with scanned ETDs. Considering this problem, our
assessment of state-of-the-art figure extraction systems is that the reason
they do not function well on scanned PDFs is that they have only been trained
on born-digital documents. To address this limitation, we present ScanBank, a
new dataset containing 10 thousand scanned page images, manually labeled by
humans as to the presence of the 3.3 thousand figures or tables found therein.
We use this dataset to train a deep neural network model based on YOLOv5 to
accurately extract figures and tables from scanned ETDs. We pose and answer
important research questions aimed at finding better methods for figure
extraction from scanned documents. One of those concerns the value for
training, of data augmentation techniques applied to born-digital documents
which are used to train models better suited for figure extraction from scanned
documents. To the best of our knowledge, ScanBank is the first manually
annotated dataset for figure and table extraction for scanned ETDs. A
YOLOv5-based model, trained on ScanBank, outperforms existing comparable
open-source and freely available baseline methods by a considerable margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tackling Catastrophic Forgetting and Background Shift in Continual Semantic Segmentation. (arXiv:2106.15287v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douillard_A/0/1/0/all/0/1">Arthur Douillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yifu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dapogny_A/0/1/0/all/0/1">Arnaud Dapogny</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15287">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning approaches are nowadays ubiquitously used to tackle computer
vision tasks such as semantic segmentation, requiring large datasets and
substantial computational power. Continual learning for semantic segmentation
(CSS) is an emerging trend that consists in updating an old model by
sequentially adding new classes. However, continual learning methods are
usually prone to catastrophic forgetting. This issue is further aggravated in
CSS where, at each step, old classes from previous iterations are collapsed
into the background. In this paper, we propose Local POD, a multi-scale pooling
distillation scheme that preserves long- and short-range spatial relationships
at feature level. Furthermore, we design an entropy-based pseudo-labelling of
the background w.r.t. classes predicted by the old model to deal with
background shift and avoid catastrophic forgetting of the old classes. Finally,
we introduce a novel rehearsal method that is particularly suited for
segmentation. Our approach, called PLOP, significantly outperforms
state-of-the-art methods in existing CSS scenarios, as well as in newly
proposed challenging benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Soft Attention: Does it Actually Help to Learn Social Interactions in Pedestrian Trajectory Prediction?. (arXiv:2106.15321v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boucaud_L/0/1/0/all/0/1">Laurent Boucaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Aloise_D/0/1/0/all/0/1">Daniel Aloise</a>, <a href="http://arxiv.org/find/cs/1/au:+Saunier_N/0/1/0/all/0/1">Nicolas Saunier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15321">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of predicting the future path of a pedestrian using
its motion history and the motion history of the surrounding pedestrians,
called social information. Since the seminal paper on Social-LSTM,
deep-learning has become the main tool used to model the impact of social
interactions on a pedestrian&#x27;s motion. The demonstration that these models can
learn social interactions relies on an ablative study of these models. The
models are compared with and without their social interactions module on two
standard metrics, the Average Displacement Error and Final Displacement Error.
Yet, these complex models were recently outperformed by a simple
constant-velocity approach. This questions if they actually allow to model
social interactions as well as the validity of the proof. In this paper, we
focus on the deep-learning models with a soft-attention mechanism for social
interaction modeling and study whether they use social information at
prediction time. We conduct two experiments across four state-of-the-art
approaches on the ETH and UCY datasets, which were also used in previous work.
First, the models are trained by replacing the social information with random
noise and compared to model trained with actual social information. Second, we
use a gating mechanism along with a $L_0$ penalty, allowing models to shut down
their inner components. The models consistently learn to prune their
soft-attention mechanism. For both experiments, neither the course of the
convergence nor the prediction performance were altered. This demonstrates that
the soft-attention mechanism and therefore the social information are ignored
by the models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Semantic Similarity Learning for Image Captioning Evaluation with Intrinsic Auto-encoder. (arXiv:2106.15312v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1">Chao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tiesong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwong_S/0/1/0/all/0/1">Sam Kwong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15312">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically evaluating the quality of image captions can be very
challenging since human language is quite flexible that there can be various
expressions for the same meaning. Most of the current captioning metrics rely
on token level matching between candidate caption and the ground truth label
sentences. It usually neglects the sentence-level information. Motivated by the
auto-encoder mechanism and contrastive representation learning advances, we
propose a learning-based metric for image captioning, which we call Intrinsic
Image Captioning Evaluation($I^2CE$). We develop three progressive model
structures to learn the sentence level representations--single branch model,
dual branches model, and triple branches model. Our empirical tests show that
$I^2CE$ trained with dual branches structure achieves better consistency with
human judgments to contemporary image captioning evaluation metrics.
Furthermore, We select several state-of-the-art image captioning models and
test their performances on the MS COCO dataset concerning both contemporary
metrics and the proposed $I^2CE$. Experiment results show that our proposed
method can align well with the scores generated from other contemporary
metrics. On this concern, the proposed metric could serve as a novel indicator
of the intrinsic information between captions, which may be complementary to
the existing ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Semantic Scene Graphs for Holistic Modeling of Surgical Procedures. (arXiv:2106.15309v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozsoy_E/0/1/0/all/0/1">Ege &#xd6;zsoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ornek_E/0/1/0/all/0/1">Evin P&#x131;nar &#xd6;rnek</a>, <a href="http://arxiv.org/find/cs/1/au:+Eck_U/0/1/0/all/0/1">Ulrich Eck</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15309">
                                    <div class="article-summary-box-inner">
                                        <span>From a computer science viewpoint, a surgical domain model needs to be a
conceptual one incorporating both behavior and data. It should therefore model
actors, devices, tools, their complex interactions and data flow. To capture
and model these, we take advantage of the latest computer vision methodologies
for generating 3D scene graphs from camera views. We then introduce the
Multimodal Semantic Scene Graph (MSSG) which aims at providing a unified
symbolic, spatiotemporal and semantic representation of surgical procedures.
This methodology aims at modeling the relationship between different components
in surgical domain including medical staff, imaging systems, and surgical
devices, opening the path towards holistic understanding and modeling of
surgical procedures. We then use MSSG to introduce a dynamically generated
graphical user interface tool for surgical procedure analysis which could be
used for many applications including process optimization, OR design and
automatic report generation. We finally demonstrate that the proposed MSSGs
could also be used for synchronizing different complex surgical procedures.
While the system still needs to be integrated into real operating rooms before
getting validated, this conference paper aims mainly at providing the community
with the basic principles of this novel concept through a first prototypal
partial realization based on MVOR dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Fast and Accurate Multi-Person Pose Estimation on Mobile Devices. (arXiv:2106.15304v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1">Jiexiong Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhengang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15304">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid development of autonomous driving, abnormal behavior detection, and
behavior recognition makes an increasing demand for multi-person pose
estimation-based applications, especially on mobile platforms. However, to
achieve high accuracy, state-of-the-art methods tend to have a large model size
and complex post-processing algorithm, which costs intense computation and long
end-to-end latency. To solve this problem, we propose an architecture
optimization and weight pruning framework to accelerate inference of
multi-person pose estimation on mobile devices. With our optimization
framework, we achieve up to 2.51x faster model inference speed with higher
accuracy compared to representative lightweight multi-person pose estimator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysing Affective Behavior in the second ABAW2 Competition. (arXiv:2106.15318v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kollias_D/0/1/0/all/0/1">Dimitrios Kollias</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotsia_I/0/1/0/all/0/1">Irene Kotsia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajiyev_E/0/1/0/all/0/1">Elnar Hajiyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15318">
                                    <div class="article-summary-box-inner">
                                        <span>The Affective Behavior Analysis in-the-wild (ABAW2) 2021 Competition is the
second -- following the first very successful ABAW Competition held in
conjunction with IEEE FG 2020- Competition that aims at automatically analyzing
affect. ABAW2 is split into three Challenges, each one addressing one of the
three main behavior tasks of valence-arousal estimation, basic expression
classification and action unit detection. All three Challenges are based on a
common benchmark database, Aff-Wild2, which is a large scale in-the-wild
database and the first one to be annotated for all these three tasks. In this
paper, we describe this Competition, to be held in conjunction with ICCV 2021.
We present the three Challenges, with the utilized Competition corpora. We
outline the evaluation metrics and present the baseline system with its
results. More information regarding the Competition is provided in the
Competition site: https://ibug.doc.ic.ac.uk/resources/iccv-2021-2nd-abaw.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Class Correlation Decomposition for Generalizable Person Re-Identification. (arXiv:2106.15206v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiwen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15206">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization in person re-identification is a highly important
meaningful and practical task in which a model trained with data from several
source domains is expected to generalize well to unseen target domains. Domain
adversarial learning is a promising domain generalization method that aims to
remove domain information in the latent representation through adversarial
training. However, in person re-identification, the domain and class are
correlated, and we theoretically show that domain adversarial learning will
lose certain information about class due to this domain-class correlation.
Inspired by casual inference, we propose to perform interventions to the domain
factor $d$, aiming to decompose the domain-class correlation. To achieve this
goal, we proposed estimating the resulting representation $z^{*}$ caused by the
intervention through first- and second-order statistical characteristic
matching. Specifically, we build a memory bank to restore the statistical
characteristics of each domain. Then, we use the newly generated samples
$\{z^{*},y,d^{*}\}$ to compute the loss function. These samples are
domain-class correlation decomposed; thus, we can learn a domain-invariant
representation that can capture more class-related features. Extensive
experiments show that our model outperforms the state-of-the-art methods on the
large-scale domain generalization Re-ID benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Roof Damage Assessment from Automated 3D Building Models. (arXiv:2106.15294v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sugihara_K/0/1/0/all/0/1">Kenichi Sugihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_M/0/1/0/all/0/1">Martin Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Kongwen/0/1/0/all/0/1">Kongwen</a> (Frank) <a href="http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1">Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Khmelevsky_Y/0/1/0/all/0/1">Youry Khmelevsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15294">
                                    <div class="article-summary-box-inner">
                                        <span>The 3D building modelling is important in urban planning and related domains
that draw upon the content of 3D models of urban scenes. Such 3D models can be
used to visualize city images at multiple scales from individual buildings to
entire cities prior to and after a change has occurred. This ability is of
great importance in day-to-day work and special projects undertaken by
planners, geo-designers, and architects. In this research, we implemented a
novel approach to 3D building models for such matter, which included the
integration of geographic information systems (GIS) and 3D Computer Graphics
(3DCG) components that generate 3D house models from building footprints
(polygons), and the automated generation of simple and complex roof geometries
for rapid roof area damage reporting. These polygons (footprints) are usually
orthogonal. A complicated orthogonal polygon can be partitioned into a set of
rectangles. The proposed GIS and 3DCG integrated system partitions orthogonal
building polygons into a set of rectangles and places rectangular roofs and
box-shaped building bodies on these rectangles. Since technicians are drawing
these polygons manually with digitizers, depending on aerial photos, not all
building polygons are precisely orthogonal. But, when placing a set of boxes as
building bodies for creating the buildings, there may be gaps or overlaps
between these boxes if building polygons are not precisely orthogonal. In our
proposal, after approximately orthogonal building polygons are partitioned and
rectified into a set of mutually orthogonal rectangles, each rectangle knows
which rectangle is adjacent to and which edge of the rectangle is adjacent to,
which will avoid unwanted intersection of windows and doors when building
bodies combined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sample Selection for Robust Learning under Label Noise. (arXiv:2106.15292v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1">P.S. Sastry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15292">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have been shown to be susceptible to memorization
or overfitting in the presence of noisily labelled data. For the problem of
robust learning under such noisy data, several algorithms have been proposed. A
prominent class of algorithms rely on sample selection strategies, motivated by
curriculum learning. For example, many algorithms use the &#x60;small loss trick&#x27;
wherein a fraction of samples with loss values below a certain threshold are
selected for training. These algorithms are sensitive to such thresholds, and
it is difficult to fix or learn these thresholds. Often, these algorithms also
require information such as label noise rates which are typically unavailable
in practice. In this paper, we propose a data-dependent, adaptive sample
selection strategy that relies only on batch statistics of a given mini-batch
to provide robustness against label noise. The algorithm does not have any
additional hyperparameters for sample selection, does not need any information
on noise rates, and does not need access to separate data with clean labels. We
empirically demonstrate the effectiveness of our algorithm on benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic 2D-3D Registration without Contrast Agent during Neurovascular Interventions. (arXiv:2106.15308v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Homan_R/0/1/0/all/0/1">Robert Homan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijsselt_R/0/1/0/all/0/1">Ren&#xe9; van Rijsselt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruijters_D/0/1/0/all/0/1">Daniel Ruijters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15308">
                                    <div class="article-summary-box-inner">
                                        <span>Fusing live fluoroscopy images with a 3D rotational reconstruction of the
vasculature allows to navigate endovascular devices in minimally invasive
neuro-vascular treatment, while reducing the usage of harmful iodine contrast
medium. The alignment of the fluoroscopy images and the 3D reconstruction is
initialized using the sensor information of the X-ray C-arm geometry. Patient
motion is then corrected by an image-based registration algorithm, based on a
gradient difference similarity measure using digital reconstructed radiographs
of the 3D reconstruction. This algorithm does not require the vessels in the
fluoroscopy image to be filled with iodine contrast agent, but rather relies on
gradients in the image (bone structures, sinuses) as landmark features. This
paper investigates the accuracy, robustness and computation time aspects of the
image-based registration algorithm. Using phantom experiments 97% of the
registration attempts passed the success criterion of a residual registration
error of less than 1 mm translation and 3{\deg} rotation. The paper establishes
a new method for validation of 2D-3D registration without requiring changes to
the clinical workflow, such as attaching fiducial markers. As a consequence,
this method can be retrospectively applied to pre-existing clinical data. For
clinical data experiments, 87% of the registration attempts passed the
criterion of a residual translational error of &lt; 1 mm, and 84% possessed a
rotational error of &lt; 3{\deg}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Learning of Portrait Intrinsic Decomposition and Relighting. (arXiv:2106.15305v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zehni_M/0/1/0/all/0/1">Mona Zehni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Shaona Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_K/0/1/0/all/0/1">Krishna Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_S/0/1/0/all/0/1">Sethu Raman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15305">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse rendering is the problem of decomposing an image into its intrinsic
components, i.e. albedo, normal and lighting. To solve this ill-posed problem
from single image, state-of-the-art methods in shape from shading mostly resort
to supervised training on all the components on either synthetic or real
datasets. Here, we propose a new self-supervised training paradigm that 1)
reduces the need for full supervision on the decomposition task and 2) takes
into account the relighting task. We introduce new self-supervised loss terms
that leverage the consistencies between multi-lit images (images of the same
scene under different illuminations). Our approach is applicable to multi-lit
datasets. We apply our training approach in two settings: 1) train on a mixture
of synthetic and real data, 2) train on real datasets with limited supervision.
We show-case the effectiveness of our training paradigm on both intrinsic
decomposition and relighting and demonstrate how the model struggles in both
tasks without the self-supervised loss terms in limited supervision settings.
We provide results of comprehensive experiments on SfSNet, CelebA and Photoface
datasets and verify the performance of our approach on images in the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolterraNet: A higher order convolutional network with group equivariance for homogeneous manifolds. (arXiv:2106.15301v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_M/0/1/0/all/0/1">Monami Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_R/0/1/0/all/0/1">Rudrasis Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouza_J/0/1/0/all/0/1">Jose Bouza</a>, <a href="http://arxiv.org/find/cs/1/au:+Vemuri_B/0/1/0/all/0/1">Baba C. Vemuri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15301">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks have been highly successful in image-based
learning tasks due to their translation equivariance property. Recent work has
generalized the traditional convolutional layer of a convolutional neural
network to non-Euclidean spaces and shown group equivariance of the generalized
convolution operation. In this paper, we present a novel higher order Volterra
convolutional neural network (VolterraNet) for data defined as samples of
functions on Riemannian homogeneous spaces. Analagous to the result for
traditional convolutions, we prove that the Volterra functional convolutions
are equivariant to the action of the isometry group admitted by the Riemannian
homogeneous spaces, and under some restrictions, any non-linear equivariant
function can be expressed as our homogeneous space Volterra convolution,
generalizing the non-linear shift equivariant characterization of Volterra
expansions in Euclidean space. We also prove that second order functional
convolution operations can be represented as cascaded convolutions which leads
to an efficient implementation. Beyond this, we also propose a dilated
VolterraNet model. These advances lead to large parameter reductions relative
to baseline non-Euclidean CNNs. To demonstrate the efficacy of the VolterraNet
performance, we present several real data experiments involving classification
tasks on spherical-MNIST, atomic energy, Shrec17 data sets, and group testing
on diffusion MRI data. Performance comparisons to the state-of-the-art are also
presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Sparse Coding Fast Approximation with Application to Seismic Reflectivity Estimation. (arXiv:2106.15296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereg_D/0/1/0/all/0/1">Deborah Pereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_I/0/1/0/all/0/1">Israel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassiliou_A/0/1/0/all/0/1">Anthony A. Vassiliou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15296">
                                    <div class="article-summary-box-inner">
                                        <span>In sparse coding, we attempt to extract features of input vectors, assuming
that the data is inherently structured as a sparse superposition of basic
building blocks. Similarly, neural networks perform a given task by learning
features of the training data set. Recently both data-driven and model-driven
feature extracting methods have become extremely popular and have achieved
remarkable results. Nevertheless, practical implementations are often too slow
to be employed in real-life scenarios, especially for real-time applications.
We propose a speed-up upgraded version of the classic iterative thresholding
algorithm, that produces a good approximation of the convolutional sparse code
within 2-5 iterations. The speed advantage is gained mostly from the
observation that most solvers are slowed down by inefficient global
thresholding. The main idea is to normalize each data point by the local
receptive field energy, before applying a threshold. This way, the natural
inclination towards strong feature expressions is suppressed, so that one can
rely on a global threshold that can be easily approximated, or learned during
training. The proposed algorithm can be employed with a known predetermined
dictionary, or with a trained dictionary. The trained version is implemented as
a neural net designed as the unfolding of the proposed solver. The performance
of the proposed solution is demonstrated via the seismic inversion problem in
both synthetic and real data scenarios. We also provide theoretical guarantees
for a stable support recovery. Namely, we prove that under certain conditions
the true support is perfectly recovered within the first iteration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Solar Potential of Rooftops using Image Segmentation and Structured Data. (arXiv:2106.15268v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soares_D/0/1/0/all/0/1">Daniel de Barros Soares</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Andrieux_F/0/1/0/all/0/1">Fran&#xe7;ois Andrieux</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Hell_B/0/1/0/all/0/1">Bastien Hell</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lenhardt_J/0/1/0/all/0/1">Julien Lenhardt</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Badosa_J/0/1/0/all/0/1">Jordi Badosa</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Gavoille_S/0/1/0/all/0/1">Sylvain Gavoille</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gaiffas_S/0/1/0/all/0/1">St&#xe9;phane Gaiffas</a> (1, 4 and 5), <a href="http://arxiv.org/find/cs/1/au:+Bacry_E/0/1/0/all/0/1">Emmanuel Bacry</a> (1 and 6), ((1) namR, Paris, France, (2) ENSTA Paris, France, (3) LMD, Ecole polytechnique, IP Paris, Palaiseau, France, (4) LPSM, Universit&#xe9; de Paris, France, (5) DMA, Ecole normale sup&#xe9;rieure, Paris, France, (6) CEREMADE, Universit&#xe9; Paris Dauphine, Paris, France)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15268">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating the amount of electricity that can be produced by rooftop
photovoltaic systems is a time-consuming process that requires on-site
measurements, a difficult task to achieve on a large scale. In this paper, we
present an approach to estimate the solar potential of rooftops based on their
location and architectural characteristics, as well as the amount of solar
radiation they receive annually. Our technique uses computer vision to achieve
semantic segmentation of roof sections and roof objects on the one hand, and a
machine learning model based on structured building features to predict roof
pitch on the other hand. We then compute the azimuth and maximum number of
solar panels that can be installed on a rooftop with geometric approaches.
Finally, we compute precise shading masks and combine them with solar
irradiation data that enables us to estimate the yearly solar potential of a
rooftop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wrong Colored Vermeer: Color-Symmetric Image Distortion. (arXiv:2106.15179v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Richter_H/0/1/0/all/0/1">Hendrik Richter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15179">
                                    <div class="article-summary-box-inner">
                                        <span>Color symmetry implies that the colors of geometrical objects are assigned
according to their symmetry properties. It is defined by associating the
elements of the symmetry group with a color permutation. I use this concept for
generative art and apply symmetry-consistent color distortions to images of
paintings by Johannes Vermeer. The color permutations are realized as mappings
of the HSV color space onto itself.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cells are Actors: Social Network Analysis with Classical ML for SOTA Histology Image Classification. (arXiv:2106.15299v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zamanitajeddin_N/0/1/0/all/0/1">Neda Zamanitajeddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahanifar_M/0/1/0/all/0/1">Mostafa Jahanifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpoot_N/0/1/0/all/0/1">Nasir Rajpoot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15299">
                                    <div class="article-summary-box-inner">
                                        <span>Digitization of histology images and the advent of new computational methods,
like deep learning, have helped the automatic grading of colorectal
adenocarcinoma cancer (CRA). Present automated CRA grading methods, however,
usually use tiny image patches and thus fail to integrate the entire tissue
micro-architecture for grading purposes. To tackle these challenges, we propose
to use a statistical network analysis method to describe the complex structure
of the tissue micro-environment by modelling nuclei and their connections as a
network. We show that by analyzing only the interactions between the cells in a
network, we can extract highly discriminative statistical features for CRA
grading. Unlike other deep learning or convolutional graph-based approaches,
our method is highly scalable (can be used for cell networks consist of
millions of nodes), completely explainable, and computationally inexpensive. We
create cell networks on a broad CRC histology image dataset, experiment with
our method, and report state-of-the-art performance for the prediction of
three-class CRA grading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant Re-Identification. (arXiv:2106.15083v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulits_P/0/1/0/all/0/1">Peter Kulits</a>, <a href="http://arxiv.org/find/cs/1/au:+Wall_J/0/1/0/all/0/1">Jake Wall</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedetti_A/0/1/0/all/0/1">Anka Bedetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Henley_M/0/1/0/all/0/1">Michelle Henley</a>, <a href="http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1">Sara Beery</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15083">
                                    <div class="article-summary-box-inner">
                                        <span>African elephants are vital to their ecosystems, but their populations are
threatened by a rise in human-elephant conflict and poaching. Monitoring
population dynamics is essential in conservation efforts; however, tracking
elephants is a difficult task, usually relying on the invasive and sometimes
dangerous placement of GPS collars. Although there have been many recent
successes in the use of computer vision techniques for automated identification
of other species, identification of elephants is extremely difficult and
typically requires expertise as well as familiarity with elephants in the
population. We have built and deployed a web-based platform and database for
human-in-the-loop re-identification of elephants combining manual attribute
labeling and state-of-the-art computer vision algorithms, known as
ElephantBook. Our system is currently in use at the Mara Elephant Project,
helping monitor the protected and at-risk population of elephants in the
Greater Maasai Mara ecosystem. ElephantBook makes elephant re-identification
usable by non-experts and scalable for use by multiple conservation NGOs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Face Sketch Synthesis via Semantic-Driven Generative Adversarial Network. (arXiv:2106.15121v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xingqun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Muyi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weining Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoxiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_C/0/1/0/all/0/1">Caifeng Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15121">
                                    <div class="article-summary-box-inner">
                                        <span>Face sketch synthesis has made significant progress with the development of
deep neural networks in these years. The delicate depiction of sketch portraits
facilitates a wide range of applications like digital entertainment and law
enforcement. However, accurate and realistic face sketch generation is still a
challenging task due to the illumination variations and complex backgrounds in
the real scenes. To tackle these challenges, we propose a novel Semantic-Driven
Generative Adversarial Network (SDGAN) which embeds global structure-level
style injection and local class-level knowledge re-weighting. Specifically, we
conduct facial saliency detection on the input face photos to provide overall
facial texture structure, which could be used as a global type of prior
information. In addition, we exploit face parsing layouts as the semantic-level
spatial prior to enforce globally structural style injection in the generator
of SDGAN. Furthermore, to enhance the realistic effect of the details, we
propose a novel Adaptive Re-weighting Loss (ARLoss) which dedicates to balance
the contributions of different semantic classes. Experimentally, our extensive
experiments on CUFS and CUFSF datasets show that our proposed algorithm
achieves state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Not Deceive Your Employer with a Virtual Background: A Video Conferencing Manipulation-Detection System. (arXiv:2106.15130v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1">Mauro Conti</a>, <a href="http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1">Simone Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1">Ehsan Nowroozi</a>, <a href="http://arxiv.org/find/cs/1/au:+Orazi_G/0/1/0/all/0/1">Gabriele Orazi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15130">
                                    <div class="article-summary-box-inner">
                                        <span>The last-generation video conferencing software allows users to utilize a
virtual background to conceal their personal environment due to privacy
concerns, especially in official meetings with other employers. On the other
hand, users maybe want to fool people in the meeting by considering the virtual
background to conceal where they are. In this case, developing tools to
understand the virtual background utilize for fooling people in meeting plays
an important role. Besides, such detectors must prove robust against different
kinds of attacks since a malicious user can fool the detector by applying a set
of adversarial editing steps on the video to conceal any revealing footprint.
In this paper, we study the feasibility of an efficient tool to detect whether
a videoconferencing user background is real. In particular, we provide the
first tool which computes pixel co-occurrences matrices and uses them to search
for inconsistencies among spectral and spatial bands. Our experiments confirm
that cross co-occurrences matrices improve the robustness of the detector
against different kinds of attacks. This work&#x27;s performance is especially
noteworthy with regard to color SPAM features. Moreover, the performance
especially is significant with regard to robustness versus post-processing,
like geometric transformations, filtering, contrast enhancement, and JPEG
compression with different quality factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Deep Neural Networks for Image Document Enhancement. (arXiv:2106.15286v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirsten_L/0/1/0/all/0/1">Lucas N. Kirsten</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccoli_R/0/1/0/all/0/1">Ricardo Piccoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribani_R/0/1/0/all/0/1">Ricardo Ribani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15286">
                                    <div class="article-summary-box-inner">
                                        <span>This work evaluates six state-of-the-art deep neural network (DNN)
architectures applied to the problem of enhancing camera-captured document
images. The results from each network were evaluated both qualitatively and
quantitatively using Image Quality Assessment (IQA) metrics, and also compared
with an existing approach based on traditional computer vision techniques. The
best performing architectures generally produced good enhancement compared to
the existing algorithm, showing that it is possible to use DNNs for document
image enhancement. Furthermore, the best performing architectures could work as
a baseline for future investigations on document enhancement using deep
learning techniques. The main contributions of this paper are: a baseline of
deep learning techniques that can be further improved to provide better
results, and a evaluation methodology using IQA metrics for quantitatively
comparing the produced images from the neural networks to a ground truth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SRF-Net: Selective Receptive Field Network for Anchor-Free Temporal Action Detection. (arXiv:2106.15258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ning_R/0/1/0/all/0/1">Ranyu Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Can Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15258">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal action detection (TAD) is a challenging task which aims to
temporally localize and recognize the human action in untrimmed videos. Current
mainstream one-stage TAD approaches localize and classify action proposals
relying on pre-defined anchors, where the location and scale for action
instances are set by designers. Obviously, such an anchor-based TAD method
limits its generalization capability and will lead to performance degradation
when videos contain rich action variation. In this study, we explore to remove
the requirement of pre-defined anchors for TAD methods. A novel TAD model
termed as Selective Receptive Field Network (SRF-Net) is developed, in which
the location offsets and classification scores at each temporal location can be
directly estimated in the feature map and SRF-Net is trained in an end-to-end
manner. Innovatively, a building block called Selective Receptive Field
Convolution (SRFC) is dedicatedly designed which is able to adaptively adjust
its receptive field size according to multiple scales of input information at
each temporal location in the feature map. Extensive experiments are conducted
on the THUMOS14 dataset, and superior results are reported comparing to
state-of-the-art TAD approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Diffusion Models for High Fidelity Image Generation. (arXiv:2106.15282v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15282">
                                    <div class="article-summary-box-inner">
                                        <span>We show that cascaded diffusion models are capable of generating high
fidelity images on the class-conditional ImageNet generation challenge, without
any assistance from auxiliary image classifiers to boost sample quality. A
cascaded diffusion model comprises a pipeline of multiple diffusion models that
generate images of increasing resolution, beginning with a standard diffusion
model at the lowest resolution, followed by one or more super-resolution
diffusion models that successively upsample the image and add higher resolution
details. We find that the sample quality of a cascading pipeline relies
crucially on conditioning augmentation, our proposed method of data
augmentation of the lower resolution conditioning inputs to the
super-resolution models. Our experiments show that conditioning augmentation
prevents compounding error during sampling in a cascaded model, helping us to
train cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at
128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perception-aware Multi-sensor Fusion for 3D LiDAR Semantic Segmentation. (arXiv:2106.15277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhuangwei Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Rong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanqing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15277">
                                    <div class="article-summary-box-inner">
                                        <span>3D LiDAR (light detection and ranging) based semantic segmentation is
important in scene understanding for many applications, such as auto-driving
and robotics. For example, for autonomous cars equipped with RGB cameras and
LiDAR, it is crucial to fuse complementary information from different sensors
for robust and accurate segmentation. Existing fusion-based methods, however,
may not achieve promising performance due to the vast difference between two
modalities. In this work, we investigate a collaborative fusion scheme called
perception-aware multi-sensor fusion (PMF) to exploit perceptual information
from two modalities, namely, appearance information from RGB images and
spatio-depth information from point clouds. To this end, we first project point
clouds to the camera coordinates to provide spatio-depth information for RGB
images. Then, we propose a two-stream network to extract features from the two
modalities, separately, and fuse the features by effective residual-based
fusion modules. Moreover, we propose additional perception-aware losses to
measure the great perceptual difference between the two modalities. Extensive
experiments on two benchmark data sets show the superiority of our method. For
example, on nuScenes, our PMF outperforms the state-of-the-art method by 0.8%
in mIoU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Xihe: A 3D Vision-based Lighting Estimation Framework for Mobile Augmented Reality. (arXiv:2106.15280v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiqin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1">Tian Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15280">
                                    <div class="article-summary-box-inner">
                                        <span>Omnidirectional lighting provides the foundation for achieving
spatially-variant photorealistic 3D rendering, a desirable property for mobile
augmented reality applications. However, in practice, estimating
omnidirectional lighting can be challenging due to limitations such as partial
panoramas of the rendering positions, and the inherent environment lighting and
mobile user dynamics. A new opportunity arises recently with the advancements
in mobile 3D vision, including built-in high-accuracy depth sensors and deep
learning-powered algorithms, which provide the means to better sense and
understand the physical surroundings. Centering the key idea of 3D vision, in
this work, we design an edge-assisted framework called Xihe to provide mobile
AR applications the ability to obtain accurate omnidirectional lighting
estimation in real time. Specifically, we develop a novel sampling technique
that efficiently compresses the raw point cloud input generated at the mobile
device. This technique is derived based on our empirical analysis of a recent
3D indoor dataset and plays a key role in our 3D vision-based lighting
estimator pipeline design. To achieve the real-time goal, we develop a tailored
GPU pipeline for on-device point cloud processing and use an encoding technique
that reduces network transmitted bytes. Finally, we present an adaptive
triggering strategy that allows Xihe to skip unnecessary lighting estimations
and a practical way to provide temporal coherent rendering integration with the
mobile AR ecosystem. We evaluate both the lighting estimation accuracy and time
of Xihe using a reference mobile application developed with Xihe&#x27;s APIs. Our
results show that Xihe takes as fast as 20.67ms per lighting estimation and
achieves 9.4% better estimation accuracy than a state-of-the-art neural
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Depth from Semantic Segmentation using Game Engine Dataset. (arXiv:2106.15257v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kashi_M/0/1/0/all/0/1">Mohammad Amin Kashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15257">
                                    <div class="article-summary-box-inner">
                                        <span>Depth perception is fundamental for robots to understand the surrounding
environment. As the view of cognitive neuroscience, visual depth perception
methods are divided into three categories, namely binocular, active, and
pictorial. The first two categories have been studied for decades in detail.
However, research for the exploration of the third category is still in its
infancy and has got momentum by the advent of deep learning methods in recent
years. In cognitive neuroscience, it is known that pictorial depth perception
mechanisms are dependent on the perception of seen objects. Inspired by this
fact, in this thesis, we investigated the relation of perception of objects and
depth estimation convolutional neural networks. For this purpose, we developed
new network structures based on a simple depth estimation network that only
used a single image at its input. Our proposed structures use both an image and
a semantic label of the image as their input. We used semantic labels as the
output of object perception. The obtained results of performance comparison
between the developed network and original network showed that our novel
structures can improve the performance of depth estimation by 52\% of relative
error of distance in the examined cases. Most of the experimental studies were
carried out on synthetic datasets that were generated by game engines to
isolate the performance comparison from the effect of inaccurate depth and
semantic labels of non-synthetic datasets. It is shown that particular
synthetic datasets may be used for training of depth networks in cases that an
appropriate dataset is not available. Furthermore, we showed that in these
cases, usage of semantic labels improves the robustness of the network against
domain shift from synthetic training data to non-synthetic test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Spatial Features using Deep Learning. (arXiv:2106.15113v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Shenghua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiuli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shaoqun Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15113">
                                    <div class="article-summary-box-inner">
                                        <span>Digital gigapixel whole slide image (WSI) is widely used in clinical
diagnosis, and automated WSI analysis is key for computer-aided diagnosis.
Currently, analyzing the integrated descriptor of probabilities or feature maps
from massive local patches encoded by ResNet classifier is the main manner for
WSI-level prediction. Feature representations of the sparse and tiny lesion
cells in cervical slides, however, are still challengeable for the
under-promoted upstream encoders, while the unused spatial representations of
cervical cells are the available features to supply the semantics analysis. As
well as patches sampling with overlap and repetitive processing incur the
inefficiency and the unpredictable side effect. This study designs a novel
inline connection network (InCNet) by enriching the multi-scale connectivity to
build the lightweight model named You Only Look Cytopathology Once (YOLCO) with
the additional supervision of spatial information. The proposed model allows
the input size enlarged to megapixel that can stitch the WSI without any
overlap by the average repeats decreased from $10^3\sim10^4$ to $10^1\sim10^2$
for collecting features and predictions at two scales. Based on Transformer for
classifying the integrated multi-scale multi-task features, the experimental
results appear $0.872$ AUC score better and $2.51\times$ faster than the best
conventional method in WSI classification on multicohort datasets of 2,019
slides from four scanning devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IREM: High-Resolution Magnetic Resonance (MR) Image Reconstruction via Implicit Neural Representation. (arXiv:2106.15097v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_Q/0/1/0/all/0/1">Qing Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yuwei Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1">Lan Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Feng_R/0/1/0/all/0/1">Ruiming Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_H/0/1/0/all/0/1">Hongjiang Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1">Qing Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_B/0/1/0/all/0/1">Boliang Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xiaozhao Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yuyao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15097">
                                    <div class="article-summary-box-inner">
                                        <span>For collecting high-quality high-resolution (HR) MR image, we propose a novel
image reconstruction network named IREM, which is trained on multiple
low-resolution (LR) MR images and achieve an arbitrary up-sampling rate for HR
image reconstruction. In this work, we suppose the desired HR image as an
implicit continuous function of the 3D image spatial coordinate and the
thick-slice LR images as several sparse discrete samplings of this function.
Then the super-resolution (SR) task is to learn the continuous volumetric
function from a limited observations using an fully-connected neural network
combined with Fourier feature positional encoding. By simply minimizing the
error between the network prediction and the acquired LR image intensity across
each imaging plane, IREM is trained to represent a continuous model of the
observed tissue anatomy. Experimental results indicate that IREM succeeds in
representing high frequency image feature, and in real scene data collection,
IREM reduces scan time and achieves high-quality high-resolution MR imaging in
terms of SNR and local image detail.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TUCaN: Progressively Teaching Colourisation to Capsules. (arXiv:2106.15176v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pucci_R/0/1/0/all/0/1">Rita Pucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinel_N/0/1/0/all/0/1">Niki Martinel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15176">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic image colourisation is the computer vision research path that
studies how to colourise greyscale images (for restoration). Deep learning
techniques improved image colourisation yielding astonishing results. These
differ by various factors, such as structural differences, input types, user
assistance, etc. Most of them, base the architectural structure on
convolutional layers with no emphasis on layers specialised in object features
extraction. We introduce a novel downsampling upsampling architecture named
TUCaN (Tiny UCapsNet) that exploits the collaboration of convolutional layers
and capsule layers to obtain a neat colourisation of entities present in every
single image. This is obtained by enforcing collaboration among such layers by
skip and residual connections. We pose the problem as a per pixel colour
classification task that identifies colours as a bin in a quantized space. To
train the network, in contrast with the standard end to end learning method, we
propose the progressive learning scheme to extract the context of objects by
only manipulating the learning process without changing the model. In this
scheme, the upsampling starts from the reconstruction of low resolution images
and progressively grows to high resolution images throughout the training
phase. Experimental results on three benchmark datasets show that our approach
with ImageNet10k dataset outperforms existing methods on standard quality
metrics and achieves state of the art performances on image colourisation. We
performed a user study to quantify the perceptual realism of the colourisation
results demonstrating: that progressive learning let the TUCaN achieve better
colours than the end to end scheme; and pointing out the limitations of the
existing evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SDL: New data generation tools for full-level annotated document layout. (arXiv:2106.15117v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Son Nguyen Truong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15117">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel data generation tool for document processing. The tool
focuses on providing a maximal level of visual information in a normal type
document, ranging from character position to paragraph-level position. It also
enables working with a large dataset on low-resource languages as well as
providing a mean of processing thorough full-level information of the
documented text. The data generation tools come with a dataset of 320000
Vietnamese synthetic document images and an instruction to generate a dataset
of similar size in other languages. The repository can be found at:
https://github.com/tson1997/SDL-Document-Image-Generation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GuidedMix-Net: Learning to Improve Pseudo Masks Using Labeled Images as Reference. (arXiv:2106.15064v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tu_P/0/1/0/all/0/1">Peng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yawen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15064">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised learning is a challenging problem which aims to construct a
model by learning from a limited number of labeled examples. Numerous methods
have been proposed to tackle this problem, with most focusing on utilizing the
predictions of unlabeled instances consistency alone to regularize networks.
However, treating labeled and unlabeled data separately often leads to the
discarding of mass prior knowledge learned from the labeled examples, and
failure to mine the feature interaction between the labeled and unlabeled image
pairs. In this paper, we propose a novel method for semi-supervised semantic
segmentation named GuidedMix-Net, by leveraging labeled information to guide
the learning of unlabeled instances. Specifically, we first introduce a feature
alignment objective between labeled and unlabeled data to capture potentially
similar image pairs and then generate mixed inputs from them. The proposed
mutual information transfer (MITrans), based on the cluster assumption, is
shown to be a powerful knowledge module for further progressive refining
features of unlabeled data in the mixed data space. To take advantage of the
labeled examples and guide unlabeled data learning, we further propose a mask
generation module to generate high-quality pseudo masks for the unlabeled data.
Along with supervised learning for labeled data, the prediction of unlabeled
data is jointly learned with the generated pseudo masks from the mixed data.
Extensive experiments on PASCAL VOC 2012, PASCAL-Context and Cityscapes
demonstrate the effectiveness of our GuidedMix-Net, which achieves competitive
segmentation accuracy and significantly improves the mIoU by +7$\%$ compared to
previous state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructing Stronger and Faster Baselines for Skeleton-based Action Recognition. (arXiv:2106.15125v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Fan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_C/0/1/0/all/0/1">Caifeng Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15125">
                                    <div class="article-summary-box-inner">
                                        <span>One essential problem in skeleton-based action recognition is how to extract
discriminative features over all skeleton joints. However, the complexity of
the recent State-Of-The-Art (SOTA) models for this task tends to be exceedingly
sophisticated and over-parameterized. The low efficiency in model training and
inference has increased the validation costs of model architectures in
large-scale datasets. To address the above issue, recent advanced separable
convolutional layers are embedded into an early fused Multiple Input Branches
(MIB) network, constructing an efficient Graph Convolutional Network (GCN)
baseline for skeleton-based action recognition. In addition, based on such the
baseline, we design a compound scaling strategy to expand the model&#x27;s width and
depth synchronously, and eventually obtain a family of efficient GCN baselines
with high accuracies and small amounts of trainable parameters, termed
EfficientGCN-Bx, where &#x27;&#x27;x&#x27;&#x27; denotes the scaling coefficient. On two
large-scale datasets, i.e., NTU RGB+D 60 and 120, the proposed EfficientGCN-B4
baseline outperforms other SOTA methods, e.g., achieving 91.7% accuracy on the
cross-subject benchmark of NTU 60 dataset, while being 3.15x smaller and 3.21x
faster than MS-G3D, which is one of the best SOTA methods. The source code in
PyTorch version and the pretrained models are available at
https://github.com/yfsong0709/EfficientGCNv1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open-Set Representation Learning through Combinatorial Embedding. (arXiv:2106.15278v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Geeho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bohyung Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15278">
                                    <div class="article-summary-box-inner">
                                        <span>Visual recognition tasks are often limited to dealing with a small subset of
classes simply because the labels for the remaining classes are unavailable. We
are interested in identifying novel concepts in a dataset through
representation learning based on the examples in both labeled and unlabeled
classes, and extending the horizon of recognition to both known and novel
classes. To address this challenging task, we propose a combinatorial learning
approach, which naturally clusters the examples in unseen classes using the
compositional knowledge given by multiple supervised meta-classifiers on
heterogeneous label spaces. We also introduce a metric learning strategy to
estimate pairwise pseudo-labels for improving representations of unlabeled
examples, which preserves semantic relations across known and novel classes
effectively. The proposed algorithm discovers novel concepts via a joint
optimization of enhancing the discrimitiveness of unseen classes as well as
learning the representations of known classes generalizable to novel ones. Our
extensive experiments demonstrate remarkable performance gains by the proposed
approach in multiple image retrieval and novel class discovery benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">O2O-Afford: Annotation-Free Large-Scale Object-Object Affordance Learning. (arXiv:2106.15087v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_K/0/1/0/all/0/1">Kaichun Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yuzhe Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_F/0/1/0/all/0/1">Fanbo Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15087">
                                    <div class="article-summary-box-inner">
                                        <span>Contrary to the vast literature in modeling, perceiving, and understanding
agent-object (e.g., human-object, hand-object, robot-object) interaction in
computer vision and robotics, very few past works have studied the task of
object-object interaction, which also plays an important role in robotic
manipulation and planning tasks. There is a rich space of object-object
interaction scenarios in our daily life, such as placing an object on a messy
tabletop, fitting an object inside a drawer, pushing an object using a tool,
etc. In this paper, we propose a unified affordance learning framework to learn
object-object interaction for various tasks. By constructing four object-object
interaction task environments using physical simulation (SAPIEN) and thousands
of ShapeNet models with rich geometric diversity, we are able to conduct
large-scale object-object affordance learning without the need for human
annotations or demonstrations. At the core of technical contribution, we
propose an object-kernel point convolution network to reason about detailed
interaction between two objects. Experiments on large-scale synthetic data and
real-world data prove the effectiveness of the proposed approach. Please refer
to the project webpage for code, data, video, and more materials:
https://cs.stanford.edu/~kaichun/o2oafford</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inconspicuous Adversarial Patches for Fooling Image Recognition Systems on Mobile Devices. (arXiv:2106.15202v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Tao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jinqi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15202">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning based image recognition systems have been widely deployed on
mobile devices in today&#x27;s world. In recent studies, however, deep learning
models are shown vulnerable to adversarial examples. One variant of adversarial
examples, called adversarial patch, draws researchers&#x27; attention due to its
strong attack abilities. Though adversarial patches achieve high attack success
rates, they are easily being detected because of the visual inconsistency
between the patches and the original images. Besides, it usually requires a
large amount of data for adversarial patch generation in the literature, which
is computationally expensive and time-consuming. To tackle these challenges, we
propose an approach to generate inconspicuous adversarial patches with one
single image. In our approach, we first decide the patch locations basing on
the perceptual sensitivity of victim models, then produce adversarial patches
in a coarse-to-fine way by utilizing multiple-scale generators and
discriminators. The patches are encouraged to be consistent with the background
images with adversarial training while preserving strong attack abilities. Our
approach shows the strong attack abilities in white-box settings and the
excellent transferability in black-box settings through extensive experiments
on various models with different architectures and training methods. Compared
to other adversarial patches, our adversarial patches hold the most negligible
risks to be detected and can evade human observations, which is supported by
the illustrations of saliency maps and results of user evaluations. Lastly, we
show that our adversarial patches can be applied in the physical world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoNovel: Automatically Discovering and Learning Novel Visual Categories. (arXiv:2106.15252v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Rebuffi_S/0/1/0/all/0/1">Sylvestre-Alvise Rebuffi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehrhardt_S/0/1/0/all/0/1">S&#xe9;bastien Ehrhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1">Andrea Vedaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15252">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the problem of discovering novel classes in an image collection
given labelled examples of other classes. We present a new approach called
AutoNovel to address this problem by combining three ideas: (1) we suggest that
the common approach of bootstrapping an image representation using the labelled
data only introduces an unwanted bias, and that this can be avoided by using
self-supervised learning to train the representation from scratch on the union
of labelled and unlabelled data; (2) we use ranking statistics to transfer the
model&#x27;s knowledge of the labelled classes to the problem of clustering the
unlabelled images; and, (3) we train the data representation by optimizing a
joint objective function on the labelled and unlabelled subsets of the data,
improving both the supervised classification of the labelled data, and the
clustering of the unlabelled data. Moreover, we propose a method to estimate
the number of classes for the case where the number of new categories is not
known a priori. We evaluate AutoNovel on standard classification benchmarks and
substantially outperform current methods for novel category discovery. In
addition, we also show that AutoNovel can be used for fully unsupervised image
clustering, achieving promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-board Volcanic Eruption Detection through CNNs and Satellite Multispectral Imagery. (arXiv:2106.15281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosso_M/0/1/0/all/0/1">Maria Pia Del Rosso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiller_D/0/1/0/all/0/1">Dario Spiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_P/0/1/0/all/0/1">Pierre Philippe Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15281">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the growth of Machine Learning algorithms in a variety of
different applications has raised numerous studies on the applicability of
these algorithms in real scenarios. Among all, one of the hardest scenarios,
due to its physical requirements, is the aerospace one. In this context, the
authors of this work aim to propose a first prototype and a study of
feasibility for an AI model to be &#x27;loaded&#x27; on board. As a case study, the
authors decided to investigate the detection of volcanic eruptions as a method
to swiftly produce alerts. Two Convolutional Neural Networks have been proposed
and created, also showing how to correctly implement them on real hardware and
how the complexity of a CNN can be adapted to fit computational requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Exit Vision Transformer for Dynamic Inference. (arXiv:2106.15183v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bakhtiarnia_A/0/1/0/all/0/1">Arian Bakhtiarnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15183">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks can be converted to multi-exit architectures by
inserting early exit branches after some of their intermediate layers. This
allows their inference process to become dynamic, which is useful for time
critical IoT applications with stringent latency requirements, but with
time-variant communication and computation resources. In particular, in edge
computing systems and IoT networks where the exact computation time budget is
variable and not known beforehand. Vision Transformer is a recently proposed
architecture which has since found many applications across various domains of
computer vision. In this work, we propose seven different architectures for
early exit branches that can be used for dynamic inference in Vision
Transformer backbones. Through extensive experiments involving both
classification and regression problems, we show that each one of our proposed
architectures could prove useful in the trade-off between accuracy and speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Context for Action Detection. (arXiv:2106.15171v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caldero_M/0/1/0/all/0/1">Manuel Sarmiento Calder&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Varas_D/0/1/0/all/0/1">David Varas</a>, <a href="http://arxiv.org/find/cs/1/au:+Bou_Balust_E/0/1/0/all/0/1">Elisenda Bou-Balust</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15171">
                                    <div class="article-summary-box-inner">
                                        <span>Research in action detection has grown in the recentyears, as it plays a key
role in video understanding. Modelling the interactions (either spatial or
temporal) between actors and their context has proven to be essential for this
task. While recent works use spatial features with aggregated temporal
information, this work proposes to use non-aggregated temporal information.
This is done by adding an attention based method that leverages spatio-temporal
interactions between elements in the scene along the clip.The main contribution
of this work is the introduction of two cross attention blocks to effectively
model the spatial relations and capture short range temporal
interactions.Experiments on the AVA dataset show the advantages of the proposed
approach that models spatio-temporal relations between relevant elements in the
scene, outperforming other methods that model actor interactions with their
context by +0.31 mAP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomous Driving Implementation in an Experimental Environment. (arXiv:2106.15274v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aliyev_N/0/1/0/all/0/1">Namig Aliyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezer_O/0/1/0/all/0/1">Oguzhan Sezer</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzel_M/0/1/0/all/0/1">Mehmet Turan Guzel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15274">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous systems require identifying the environment and it has a long way
to go before putting it safely into practice. In autonomous driving systems,
the detection of obstacles and traffic lights are of importance as well as lane
tracking. In this study, an autonomous driving system is developed and tested
in the experimental environment designed for this purpose. In this system, a
model vehicle having a camera is used to trace the lanes and avoid obstacles to
experimentally study autonomous driving behavior. Convolutional Neural Network
models were trained for Lane tracking. For the vehicle to avoid obstacles,
corner detection, optical flow, focus of expansion, time to collision, balance
calculation, and decision mechanism were created, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Robust Regression to Find Font Usage Trends. (arXiv:2106.15232v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsuji_K/0/1/0/all/0/1">Kaigen Tsuji</a>, <a href="http://arxiv.org/find/cs/1/au:+Haraguchi_D/0/1/0/all/0/1">Daichi Haraguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1">Brian Kenji Iwana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15232">
                                    <div class="article-summary-box-inner">
                                        <span>Fonts have had trends throughout their history, not only in when they were
invented but also in their usage and popularity. In this paper, we attempt to
specifically find the trends in font usage using robust regression on a large
collection of text images. We utilize movie posters as the source of fonts for
this task because movie posters can represent time periods by using their
release date. In addition, movie posters are documents that are carefully
designed and represent a wide range of fonts. To understand the relationship
between the fonts of movie posters and time, we use a regression Convolutional
Neural Network (CNN) to estimate the release year of a movie using an isolated
title text image. Due to the difficulty of the task, we propose to use of a
hybrid training regimen that uses a combination of Mean Squared Error (MSE) and
Tukey&#x27;s biweight loss. Furthermore, we perform a thorough analysis on the
trends of fonts through time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding the Effectiveness of Attention Mechanism. (arXiv:2106.15067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15067">
                                    <div class="article-summary-box-inner">
                                        <span>Attention Mechanism is a widely used method for improving the performance of
convolutional neural networks (CNNs) on computer vision tasks. Despite its
pervasiveness, we have a poor understanding of what its effectiveness stems
from. It is popularly believed that its effectiveness stems from the visual
attention explanation, advocating focusing on the important part of input data
rather than ingesting the entire input. In this paper, we find that there is
only a weak consistency between the attention weights of features and their
importance. Instead, we verify the crucial role of feature map multiplication
in attention mechanism and uncover a fundamental impact of feature map
multiplication on the learned landscapes of CNNs: with the high order
non-linearity brought by the feature map multiplication, it played a
regularization role on CNNs, which made them learn smoother and more stable
landscapes near real samples compared to vanilla CNNs. This smoothness and
stability induce a more predictive and stable behavior in-between real samples,
and make CNNs generate better. Moreover, motivated by the proposed
effectiveness of feature map multiplication, we design feature map
multiplication network (FMMNet) by simply replacing the feature map addition in
ResNet with feature map multiplication. FMMNet outperforms ResNet on various
datasets, and this indicates that feature map multiplication plays a vital role
in improving the performance even without finely designed attention mechanism
in existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Trajectory Prediction Conditioned on Lane-Graph Traversals. (arXiv:2106.15004v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deo_N/0/1/0/all/0/1">Nachiket Deo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolff_E/0/1/0/all/0/1">Eric M. Wolff</a>, <a href="http://arxiv.org/find/cs/1/au:+Beijbom_O/0/1/0/all/0/1">Oscar Beijbom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15004">
                                    <div class="article-summary-box-inner">
                                        <span>Accurately predicting the future motion of surrounding vehicles requires
reasoning about the inherent uncertainty in goals and driving behavior. This
uncertainty can be loosely decoupled into lateral (e.g., keeping lane, turning)
and longitudinal (e.g., accelerating, braking). We present a novel method that
combines learned discrete policy rollouts with a focused decoder on subsets of
the lane graph. The policy rollouts explore different goals given our current
observations, ensuring that the model captures lateral variability. The
longitudinal variability is captured by our novel latent variable model decoder
that is conditioned on various subsets of the lane graph. Our model achieves
state-of-the-art performance on the nuScenes motion prediction dataset, and
qualitatively demonstrates excellent scene compliance. Detailed ablations
highlight the importance of both the policy rollouts and the decoder
architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are conditional GANs explicitly conditional?. (arXiv:2106.15011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boulahbal_H/0/1/0/all/0/1">Houssem-eddine Boulahbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Voicila_A/0/1/0/all/0/1">Adrian Voicila</a>, <a href="http://arxiv.org/find/cs/1/au:+Comport_A/0/1/0/all/0/1">Andrew Comport</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15011">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes two important contributions for conditional Generative
Adversarial Networks (cGANs) to improve the wide variety of applications that
exploit this architecture. The first main contribution is an analysis of cGANs
to show that they are not explicitly conditional. In particular, it will be
shown that the discriminator and subsequently the cGAN does not automatically
learn the conditionality between inputs. The second contribution is a new
method, called acontrario, that explicitly models conditionality for both parts
of the adversarial architecture via a novel acontrario loss that involves
training the discriminator to learn unconditional (adverse) examples. This
leads to a novel type of data augmentation approach for GANs (acontrario
learning) which allows to restrict the search space of the generator to
conditional outputs using adverse examples. Extensive experimentation is
carried out to evaluate the conditionality of the discriminator by proposing a
probability distribution analysis. Comparisons with the cGAN architecture for
different applications show significant improvements in performance on well
known datasets including, semantic image synthesis, image segmentation and
monocular depth prediction using different metrics including Fr\&#x27;echet
Inception Distance(FID), mean Intersection over Union (mIoU), Root Mean Square
Error log (RMSE log) and Number of statistically-Different Bins (NDB)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Transferability of Adversarial Patches on Face Recognition with Generative Models. (arXiv:2106.15058v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zihao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chilin Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15058">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition is greatly improved by deep convolutional neural networks
(CNNs). Recently, these face recognition models have been used for identity
authentication in security sensitive applications. However, deep CNNs are
vulnerable to adversarial patches, which are physically realizable and
stealthy, raising new security concerns on the real-world applications of these
models. In this paper, we evaluate the robustness of face recognition models
using adversarial patches based on transferability, where the attacker has
limited accessibility to the target models. First, we extend the existing
transfer-based attack techniques to generate transferable adversarial patches.
However, we observe that the transferability is sensitive to initialization and
degrades when the perturbation magnitude is large, indicating the overfitting
to the substitute models. Second, we propose to regularize the adversarial
patches on the low dimensional data manifold. The manifold is represented by
generative models pre-trained on legitimate human face images. Using face-like
features as adversarial perturbations through optimization on the manifold, we
show that the gaps between the responses of substitute models and the target
models dramatically decrease, exhibiting a better transferability. Extensive
digital world experiments are conducted to demonstrate the superiority of the
proposed method in the black-box setting. We apply the proposed method in the
physical world as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructing Forest Biomass Prediction Maps from Radar Backscatter by Sequential Regression with a Conditional Generative Adversarial Network. (arXiv:2106.15020v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bjork_S/0/1/0/all/0/1">Sara Bj&#xf6;rk</a>, <a href="http://arxiv.org/find/cs/1/au:+Anfinsen_S/0/1/0/all/0/1">Stian Normann Anfinsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Naesset_E/0/1/0/all/0/1">Erik N&#xe6;sset</a>, <a href="http://arxiv.org/find/cs/1/au:+Gobakken_T/0/1/0/all/0/1">Terje Gobakken</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahabu_E/0/1/0/all/0/1">Eliakimu Zahabu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15020">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies construction of above-ground biomass (AGB) prediction maps
from synthetic aperture radar (SAR) intensity images. The purpose is to improve
traditional regression models based on SAR intensity, trained with a limited
amount of AGB in situ measurements. Although it is costly to collect, data from
airborne laser scanning (ALS) sensors are highly correlated with AGB.
Therefore, we propose using AGB predictions based on ALS data as surrogate
response variables for SAR data in a sequential modelling fashion. This
increases the amount of training data dramatically. To model the regression
function between SAR intensity and ALS-predicted AGB we propose to utilise a
conditional generative adversarial network (cGAN), i.e. the Pix2Pix
convolutional neural network. This enables the recreation of existing ALS-based
AGB prediction maps. The generated synthesised ALS-based AGB predictions are
evaluated qualitatively and quantitatively against ALS-based AGB predictions
retrieved from a traditional non-sequential regression model trained in the
same area. Results show that the proposed architecture manages to capture
characteristics of the actual data. This suggests that the use of ALS-guided
generative models is a promising avenue for AGB prediction from SAR intensity.
Further research on this area has the potential of providing both large-scale
and low-cost predictions of AGB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Reach Real-Time AI on Consumer Devices? Solutions for Programmable and Custom Architectures. (arXiv:2106.15021v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1">Ioannis Panopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1">Ilias Leontiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1">Iakovos S. Venieris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15021">
                                    <div class="article-summary-box-inner">
                                        <span>The unprecedented performance of deep neural networks (DNNs) has led to large
strides in various Artificial Intelligence (AI) inference tasks, such as object
and speech recognition. Nevertheless, deploying such AI models across commodity
devices faces significant challenges: large computational cost, multiple
performance objectives, hardware heterogeneity and a common need for high
accuracy, together pose critical problems to the deployment of DNNs across the
various embedded and mobile devices in the wild. As such, we have yet to
witness the mainstream usage of state-of-the-art deep learning algorithms
across consumer devices. In this paper, we provide preliminary answers to this
potentially game-changing question by presenting an array of design techniques
for efficient AI systems. We start by examining the major roadblocks when
targeting both programmable processors and custom accelerators. Then, we
present diverse methods for achieving real-time performance following a
cross-stack approach. These span model-, system- and hardware-level techniques,
and their combination. Our findings provide illustrative examples of AI systems
that do not overburden mobile hardware, while also indicating how they can
improve inference accuracy. Moreover, we showcase how custom ASIC- and
FPGA-based accelerators can be an enabling factor for next-generation AI
applications, such as multi-DNN systems. Collectively, these results highlight
the critical need for further exploration as to how the various cross-stack
solutions can be best combined in order to bring the latest advances in deep
learning close to users, in a robust and efficient manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Detection Based Handwriting Localization. (arXiv:2106.14989v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuli Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yucheng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_S/0/1/0/all/0/1">Suting Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14989">
                                    <div class="article-summary-box-inner">
                                        <span>We present an object detection based approach to localize handwritten regions
from documents, which initially aims to enhance the anonymization during the
data transmission. The concatenated fusion of original and preprocessed images
containing both printed texts and handwritten notes or signatures are fed into
the convolutional neural network, where the bounding boxes are learned to
detect the handwriting. Afterwards, the handwritten regions can be processed
(e.g. replaced with redacted signatures) to conceal the personally identifiable
information (PII). This processing pipeline based on the deep learning network
Cascade R-CNN works at 10 fps on a GPU during the inference, which ensures the
enhanced anonymization with minimal computational overheads. Furthermore, the
impressive generalizability has been empirically showcased: the trained model
based on the English-dominant dataset works well on the fictitious unseen
invoices, even in Chinese. The proposed approach is also expected to facilitate
other tasks such as handwriting recognition and signature verification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing And Following. (arXiv:2106.15045v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sanket_N/0/1/0/all/0/1">Nitin J. Sanket</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1">Chahat Deep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Parameshwara_C/0/1/0/all/0/1">Chethan M. Parameshwara</a>, <a href="http://arxiv.org/find/cs/1/au:+Fermuller_C/0/1/0/all/0/1">Cornelia Ferm&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1">Guido C.H.E. de Croon</a>, <a href="http://arxiv.org/find/cs/1/au:+Aloimonos_Y/0/1/0/all/0/1">Yiannis Aloimonos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15045">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid rise of accessibility of unmanned aerial vehicles or drones pose a
threat to general security and confidentiality. Most of the commercially
available or custom-built drones are multi-rotors and are comprised of multiple
propellers. Since these propellers rotate at a high-speed, they are generally
the fastest moving parts of an image and cannot be directly &quot;seen&quot; by a
classical camera without severe motion blur. We utilize a class of sensors that
are particularly suitable for such scenarios called event cameras, which have a
high temporal resolution, low-latency, and high dynamic range.

In this paper, we model the geometry of a propeller and use it to generate
simulated events which are used to train a deep neural network called EVPropNet
to detect propellers from the data of an event camera. EVPropNet directly
transfers to the real world without any fine-tuning or retraining. We present
two applications of our network: (a) tracking and following an unmarked drone
and (b) landing on a near-hover drone. We successfully evaluate and demonstrate
the proposed approach in many real-world experiments with different propeller
shapes and sizes. Our network can detect propellers at a rate of 85.1% even
when 60% of the propeller is occluded and can run at upto 35Hz on a 2W power
budget. To our knowledge, this is the first deep learning-based solution for
detecting propellers (to detect drones). Finally, our applications also show an
impressive success rate of 92% and 90% for the tracking and landing tasks
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An End-to-End Autofocus Camera for Iris on the Move. (arXiv:2106.15069v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Leyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kunbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunlong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhenan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15069">
                                    <div class="article-summary-box-inner">
                                        <span>For distant iris recognition, a long focal length lens is generally used to
ensure the resolution ofiris images, which reduces the depth of field and leads
to potential defocus blur. To accommodate users at different distances, it is
necessary to control focus quickly and accurately. While for users in motion,
it is expected to maintain the correct focus on the iris area continuously. In
this paper, we introduced a novel rapid autofocus camera for active refocusing
ofthe iris area ofthe moving objects using a focus-tunable lens. Our end-to-end
computational algorithm can predict the best focus position from one single
blurred image and generate a lens diopter control signal automatically. This
scene-based active manipulation method enables real-time focus tracking of the
iris area ofa moving object. We built a testing bench to collect real-world
focal stacks for evaluation of the autofocus methods. Our camera has reached an
autofocus speed ofover 50 fps. The results demonstrate the advantages of our
proposed camera for biometric perception in static and dynamic scenes. The code
is available at https://github.com/Debatrix/AquulaCam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Uncertainty Estimation Framework for Probabilistic Object Detection. (arXiv:2106.15007v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1">Zongyao Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_N/0/1/0/all/0/1">Nolan B. Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Beksi_W/0/1/0/all/0/1">William J. Beksi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15007">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a new technique that combines two popular methods
to estimate uncertainty in object detection. Quantifying uncertainty is
critical in real-world robotic applications. Traditional detection models can
be ambiguous even when they provide a high-probability output. Robot actions
based on high-confidence, yet unreliable predictions, may result in serious
repercussions. Our framework employs deep ensembles and Monte Carlo dropout for
approximating predictive uncertainty, and it improves upon the uncertainty
estimation quality of the baseline method. The proposed approach is evaluated
on publicly available synthetic image datasets captured from sequences of
video.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cosmic-CoNN: A Cosmic Ray Detection Deep-Learning Framework, Dataset, and Toolkit. (arXiv:2106.14922v1 [astro-ph.IM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Xu_C/0/1/0/all/0/1">Chengyuan Xu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+McCully_C/0/1/0/all/0/1">Curtis McCully</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Dong_B/0/1/0/all/0/1">Boning Dong</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Howell_D/0/1/0/all/0/1">D. Andrew Howell</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sen_P/0/1/0/all/0/1">Pradeep Sen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14922">
                                    <div class="article-summary-box-inner">
                                        <span>Rejecting cosmic rays (CRs) is essential for scientific interpretation of
CCD-captured data, but detecting CRs in single-exposure images has remained
challenging. Conventional CR-detection algorithms require tuning multiple
parameters experimentally making it hard to automate across different
instruments or observation requests. Recent work using deep learning to train
CR-detection models has demonstrated promising results. However,
instrument-specific models suffer from performance loss on images from
ground-based facilities not included in the training data. In this work, we
present Cosmic-CoNN, a deep-learning framework designed to produce generic
CR-detection models. We build a large, diverse ground-based CR dataset
leveraging thousands of images from the Las Cumbres Observatory global
telescope network to produce a generic CR-detection model which achieves a
99.91% true-positive detection rate and maintains over 96.40% true-positive
rates on unseen data from Gemini GMOS-N/S, with a false-positive rate of 0.01%.
Apart from the open-source framework and dataset, we also build a suite of
tools including console commands, a web-based application, and Python APIs to
make automatic, robust CR detection widely accessible by the community of
astronomers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Striking the Right Balance: Recall Loss for Semantic Segmentation. (arXiv:2106.14917v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Junjiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Mithun_N/0/1/0/all/0/1">Niluthpol Mithun</a>, <a href="http://arxiv.org/find/cs/1/au:+Seymour_Z/0/1/0/all/0/1">Zach Seymour</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1">Han-Pang Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14917">
                                    <div class="article-summary-box-inner">
                                        <span>Class imbalance is a fundamental problem in computer vision applications such
as semantic segmentation. Specifically, uneven class distributions in a
training dataset often result in unsatisfactory performance on
under-represented classes. Many works have proposed to weight the standard
cross entropy loss function with pre-computed weights based on class
statistics, such as the number of samples and class margins. There are two
major drawbacks to these methods: 1) constantly up-weighting minority classes
can introduce excessive false positives in semantic segmentation; 2) a minority
class is not necessarily a hard class. The consequence is low precision due to
excessive false positives. In this regard, we propose a hard-class mining loss
by reshaping the vanilla cross entropy loss such that it weights the loss for
each class dynamically based on instantaneous recall performance. We show that
the novel recall loss changes gradually between the standard cross entropy loss
and the inverse frequency weighted loss. Recall loss also leads to improved
mean accuracy while offering competitive mean Intersection over Union (IoU)
performance. On Synthia dataset, recall loss achieves 9% relative improvement
on mean accuracy with competitive mean IoU using DeepLab-ResNet18 compared to
the cross entropy loss. Code available at
https://github.com/PotatoTian/recall-semseg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Face Anti-Spoofing: A Survey. (arXiv:2106.14948v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zitong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yunxiao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chenxu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhen Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guoying Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14948">
                                    <div class="article-summary-box-inner">
                                        <span>Face anti-spoofing (FAS) has lately attracted increasing attention due to its
vital role in securing face recognition systems from presentation attacks
(PAs). As more and more realistic PAs with novel types spring up, traditional
FAS methods based on handcrafted features become unreliable due to their
limited representation capacity. With the emergence of large-scale academic
datasets in the recent decade, deep learning based FAS achieves remarkable
performance and dominates this area. However, existing reviews in this field
mainly focus on the handcrafted features, which are outdated and uninspiring
for the progress of FAS community. In this paper, to stimulate future research,
we present the first comprehensive review of recent advances in deep learning
based FAS. It covers several novel and insightful components: 1) besides
supervision with binary label (e.g., &#x27;0&#x27; for bonafide vs. &#x27;1&#x27; for PAs), we also
investigate recent methods with pixel-wise supervision (e.g., pseudo depth
map); 2) in addition to traditional intra-dataset evaluation, we collect and
analyze the latest methods specially designed for domain generalization and
open-set FAS; and 3) besides commercial RGB camera, we summarize the deep
learning applications under multi-modal (e.g., depth and infrared) or
specialized (e.g., light field and flash) sensors. We conclude this survey by
emphasizing current open issues and highlighting potential prospects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Cognitive Fatigue from fMRI Scans with Self-supervised Learning. (arXiv:2106.15009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1">Ashish Jaiswal</a>, <a href="http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1">Ashwin Ramesh Babu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zadeh_M/0/1/0/all/0/1">Mohammad Zaki Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Makedon_F/0/1/0/all/0/1">Fillia Makedon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wylie_G/0/1/0/all/0/1">Glenn Wylie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15009">
                                    <div class="article-summary-box-inner">
                                        <span>Functional magnetic resonance imaging (fMRI) is a neuroimaging technique that
records neural activations in the brain by capturing the blood oxygen level in
different regions based on the task performed by a subject. Given fMRI data,
the problem of predicting the state of cognitive fatigue in a person has not
been investigated to its full extent. This paper proposes tackling this issue
as a multi-class classification problem by dividing the state of cognitive
fatigue into six different levels, ranging from no-fatigue to extreme fatigue
conditions. We built a spatio-temporal model that uses convolutional neural
networks (CNN) for spatial feature extraction and a long short-term memory
(LSTM) network for temporal modeling of 4D fMRI scans. We also applied a
self-supervised method called MoCo to pre-train our model on a public dataset
BOLD5000 and fine-tuned it on our labeled dataset to classify cognitive
fatigue. Our novel dataset contains fMRI scans from Traumatic Brain Injury
(TBI) patients and healthy controls (HCs) while performing a series of
cognitive tasks. This method establishes a state-of-the-art technique to
analyze cognitive fatigue from fMRI data and beats previous approaches to solve
this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Achieving Real-Time Object Detection on MobileDevices with Neural Pruning Search. (arXiv:2106.14943v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yuxuan Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14943">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection plays an important role in self-driving cars for security
development. However, mobile systems on self-driving cars with limited
computation resources lead to difficulties for object detection. To facilitate
this, we propose a compiler-aware neural pruning search framework to achieve
high-speed inference on autonomous vehicles for 2D and 3D object detection. The
framework automatically searches the pruning scheme and rate for each layer to
find a best-suited pruning for optimizing detection accuracy and speed
performance under compiler optimization. Our experiments demonstrate that for
the first time, the proposed method achieves (close-to) real-time, 55ms and
99ms inference times for YOLOv4 based 2D object detection and PointPillars
based 3D detection, respectively, on an off-the-shelf mobile phone with minor
(or no) accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation for deep learning based accelerated MRI reconstruction with limited data. (arXiv:2106.14947v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fabian_Z/0/1/0/all/0/1">Zalan Fabian</a>, <a href="http://arxiv.org/find/eess/1/au:+Heckel_R/0/1/0/all/0/1">Reinhard Heckel</a>, <a href="http://arxiv.org/find/eess/1/au:+Soltanolkotabi_M/0/1/0/all/0/1">Mahdi Soltanolkotabi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14947">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have emerged as very successful tools for image
restoration and reconstruction tasks. These networks are often trained
end-to-end to directly reconstruct an image from a noisy or corrupted
measurement of that image. To achieve state-of-the-art performance, training on
large and diverse sets of images is considered critical. However, it is often
difficult and/or expensive to collect large amounts of training images.
Inspired by the success of Data Augmentation (DA) for classification problems,
in this paper, we propose a pipeline for data augmentation for accelerated MRI
reconstruction and study its effectiveness at reducing the required training
data in a variety of settings. Our DA pipeline, MRAugment, is specifically
designed to utilize the invariances present in medical imaging measurements as
naive DA strategies that neglect the physics of the problem fail. Through
extensive studies on multiple datasets we demonstrate that in the low-data
regime DA prevents overfitting and can match or even surpass the state of the
art while using significantly fewer training data, whereas in the high-data
regime it has diminishing returns. Furthermore, our findings show that DA can
improve the robustness of the model against various shifts in the test
distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Training of Neural Lumigraph Representations using Meta Learning. (arXiv:2106.14942v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bergman_A/0/1/0/all/0/1">Alexander W. Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kellnhofer_P/0/1/0/all/0/1">Petr Kellnhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wetzstein_G/0/1/0/all/0/1">Gordon Wetzstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14942">
                                    <div class="article-summary-box-inner">
                                        <span>Novel view synthesis is a long-standing problem in machine learning and
computer vision. Significant progress has recently been made in developing
neural scene representations and rendering techniques that synthesize
photorealistic images from arbitrary views. These representations, however, are
extremely slow to train and often also slow to render. Inspired by neural
variants of image-based rendering, we develop a new neural rendering approach
with the goal of quickly learning a high-quality representation which can also
be rendered in real-time. Our approach, MetaNLR++, accomplishes this by using a
unique combination of a neural shape representation and 2D CNN-based image
feature extraction, aggregation, and re-projection. To push representation
convergence times down to minutes, we leverage meta learning to learn neural
shape and image feature priors which accelerate training. The optimized shape
and image features can then be extracted using traditional graphics techniques
and rendered in real time. We show that MetaNLR++ achieves similar or better
novel view synthesis results in a fraction of the time that competing methods
require.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic Modeling Based Extractive Text Summarization. (arXiv:2106.15313v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Issam_K/0/1/0/all/0/1">Kalliath Abdul Rasheed Issam</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1">Shivam Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+N_S/0/1/0/all/0/1">Subalalitha C. N</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15313">
                                    <div class="article-summary-box-inner">
                                        <span>Text summarization is an approach for identifying important information
present within text documents. This computational technique aims to generate
shorter versions of the source text, by including only the relevant and salient
information present within the source text. In this paper, we propose a novel
method to summarize a text document by clustering its contents based on latent
topics produced using topic modeling techniques and by generating extractive
summaries for each of the identified text clusters. All extractive
sub-summaries are later combined to generate a summary for any given source
document. We utilize the lesser used and challenging WikiHow dataset in our
approach to text summarization. This dataset is unlike the commonly used news
datasets which are available for text summarization. The well-known news
datasets present their most important information in the first few lines of
their source texts, which make their summarization a lesser challenging task
when compared to summarizing the WikiHow dataset. Contrary to these news
datasets, the documents in the WikiHow dataset are written using a generalized
approach and have lesser abstractedness and higher compression ratio, thus
proposing a greater challenge to generate summaries. A lot of the current
state-of-the-art text summarization techniques tend to eliminate important
information present in source documents in the favor of brevity. Our proposed
technique aims to capture all the varied information present in source
documents. Although the dataset proved challenging, after performing extensive
tests within our experimental setup, we have discovered that our model produces
encouraging ROUGE results and summaries when compared to the other published
extractive and abstractive text summarization models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-aware Heterogeneous Graph Attention Network for User Behavior Prediction in Local Consumer Service Platform. (arXiv:2106.14652v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Peiyuan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaofeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_Z/0/1/0/all/0/1">Zisen Sang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_A/0/1/0/all/0/1">Aiquan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_G/0/1/0/all/0/1">Guodong Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14652">
                                    <div class="article-summary-box-inner">
                                        <span>As a new type of e-commerce platform developed in recent years, local
consumer service platform provides users with software to consume service to
the nearby store or to the home, such as Groupon and Koubei. Different from
other common e-commerce platforms, the behavior of users on the local consumer
service platform is closely related to their real-time local context
information. Therefore, building a context-aware user behavior prediction
system is able to provide both merchants and users better service in local
consumer service platforms. However, most of the previous work just treats the
contextual information as an ordinary feature into the prediction model to
obtain the prediction list under a specific context, which ignores the fact
that the interest of a user in different contexts is often significantly
different. Hence, in this paper, we propose a context-aware heterogeneous graph
attention network (CHGAT) to dynamically generate the representation of the
user and to estimate the probability for future behavior. Specifically, we
first construct the meta-path based heterogeneous graphs with the historical
behaviors from multiple sources and comprehend heterogeneous vertices in the
graph with a novel unified knowledge representing approach. Next, a multi-level
attention mechanism is introduced for context-aware aggregation with graph
vertices, which contains the vertex-level attention network and the path-level
attention network. Both of them aim to capture the semantic correlation between
information contained in the graph and the outside real-time contextual
information in the search system. Then the model proposed in this paper
aggregates specific graphs with their corresponding context features and
obtains the representation of user interest under a specific context and input
it into the prediction network to finally obtain the predicted probability of
user behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hagerer_G/0/1/0/all/0/1">Gerhard Hagerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1">Wenbin Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Danner_H/0/1/0/all/0/1">Hannah Danner</a>, <a href="http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1">Georg Groh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15498">
                                    <div class="article-summary-box-inner">
                                        <span>Social media offer plenty of information to perform market research in order
to meet the requirements of customers. One way how this research is conducted
is that a domain expert gathers and categorizes user-generated content into a
complex and fine-grained class structure. In many of such cases, little data
meets complex annotations. It is not yet fully understood how this can be
leveraged successfully for classification. We examine the classification
accuracy of expert labels when used with a) many fine-grained classes and b)
few abstract classes. For scenario b) we compare abstract class labels given by
the domain expert as baseline and by automatic hierarchical clustering. We
compare this to another baseline where the entire class structure is given by a
completely unsupervised clustering approach. By doing so, this work can serve
as an example of how complex expert annotations are potentially beneficial and
can be utilized in the most optimal way for opinion mining in highly specific
domains. By exploring across a range of techniques and experiments, we find
that automated class abstraction approaches in particular the unsupervised
approach performs remarkably well against domain expert baseline on text
classification tasks. This has the potential to inspire opinion mining
applications in order to support market researchers in practice and to inspire
fine-grained automated content analysis on a large scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bytecode-based Approach for Smart Contract Classification. (arXiv:2106.15497v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chaochen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yong Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Doss_R/0/1/0/all/0/1">Robin Ram Mohan Doss</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiangshan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_K/0/1/0/all/0/1">Keshav Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Longxiang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15497">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of blockchain technologies, the number of smart
contracts deployed on blockchain platforms is growing exponentially, which
makes it difficult for users to find desired services by manual screening. The
automatic classification of smart contracts can provide blockchain users with
keyword-based contract searching and helps to manage smart contracts
effectively. Current research on smart contract classification focuses on
Natural Language Processing (NLP) solutions which are based on contract source
code. However, more than 94% of smart contracts are not open-source, so the
application scenarios of NLP methods are very limited. Meanwhile, NLP models
are vulnerable to adversarial attacks. This paper proposes a classification
model based on features from contract bytecode instead of source code to solve
these problems. We also use feature selection and ensemble learning to optimize
the model. Our experimental studies on over 3,300 real-world Ethereum smart
contracts show that our model can classify smart contracts without source code
and has better performance than baseline models. Our model also has good
resistance to adversarial attacks compared with NLP-based models. In addition,
our analysis reveals that account features used in many smart contract
classification models have little effect on classification and can be excluded.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A scalable solution to the nearest neighbor search problem through local-search methods on neighbor graphs. (arXiv:1705.10351v4 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tellez_E/0/1/0/all/0/1">Eric S. Tellez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_G/0/1/0/all/0/1">Guillermo Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavez_E/0/1/0/all/0/1">Edgar Chavez</a>, <a href="http://arxiv.org/find/cs/1/au:+Graff_M/0/1/0/all/0/1">Mario Graff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1705.10351">
                                    <div class="article-summary-box-inner">
                                        <span>Near neighbor search (NNS) is a powerful abstraction for data access;
however, data indexing is troublesome even for approximate indexes. For
intrinsically high-dimensional data, high-quality fast searches demand either
indexes with impractically large memory usage or preprocessing time.

In this paper, we introduce an algorithm to solve a nearest-neighbor query
$q$ by minimizing a kernel function defined by the distance from $q$ to each
object in the database. The minimization is performed using metaheuristics to
solve the problem rapidly; even when some methods in the literature use this
strategy behind the scenes, our approach is the first one using it explicitly.
We also provide two approaches to select edges in the graph&#x27;s construction
stage that limit memory footprint and reduce the number of free parameters
simultaneously.

We carry out a thorough experimental comparison with state-of-the-art indexes
through synthetic and real-world datasets; we found out that our contributions
achieve competitive performances regarding speed, accuracy, and memory in
almost any of our benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When standard network measures fail to rank journals: A theoretical and empirical analysis. (arXiv:2106.15541v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaccario_G/0/1/0/all/0/1">Giacomo Vaccario</a>, <a href="http://arxiv.org/find/cs/1/au:+Verginer_L/0/1/0/all/0/1">Luca Verginer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15541">
                                    <div class="article-summary-box-inner">
                                        <span>Journal rankings are widely used and are often based on citation data in
combination with a network perspective. We argue that some of these
network-based rankings can produce misleading results. From a theoretical point
of view, we show that the standard network modelling approach of citation data
at the journal level (i.e., the projection of paper citations onto journals)
introduces fictitious relations among journals. To overcome this problem, we
propose a citation path perspective, and empirically show that rankings based
on the network and the citation path perspective are very different. Based on
our theoretical and empirical analysis, we highlight the limitations of
standard network metrics, and propose a method to overcome these limitations
and compute journal rankings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Capacity of Quantum Private Information Retrieval from MDS-Coded and Colluding Servers. (arXiv:2106.14719v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allaix_M/0/1/0/all/0/1">Matteo Allaix</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Seunghoan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Holzbaur_L/0/1/0/all/0/1">Lukas Holzbaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Pllaha_T/0/1/0/all/0/1">Tefjol Pllaha</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_M/0/1/0/all/0/1">Masahito Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hollanti_C/0/1/0/all/0/1">Camilla Hollanti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14719">
                                    <div class="article-summary-box-inner">
                                        <span>In quantum private information retrieval (QPIR), a user retrieves a classical
file from multiple servers by downloading quantum systems without revealing the
identity of the file. The QPIR capacity is the maximal achievable ratio of the
retrieved file size to the total download size. In this paper, the capacity of
QPIR from MDS-coded and colluding servers is studied. Two classes of QPIR,
called stabilizer QPIR and dimension squared QPIR induced from classical
strongly linear PIR are defined, and the related QPIR capacities are derived.
For the non-colluding case, the general QPIR capacity is derived when the
number of files goes to infinity. The capacities of symmetric and non-symmetric
QPIR with coded and colluding servers are proved to coincide, being double to
their classical counterparts. A general statement on the converse bound for
QPIR with coded and colluding servers is derived showing that the capacities of
stabilizer QPIR and dimension squared QPIR induced from any class of PIR are
upper bounded by twice the classical capacity of the respective PIR class. The
proposed capacity-achieving scheme combines the star-product scheme by
Freij-Hollanti et al. and the stabilizer QPIR scheme by Song et al. by
employing (weakly) self-dual Reed--Solomon codes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of BioASQ 2021: The ninth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering. (arXiv:2106.14885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1">Anastasios Nentidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsimpras_G/0/1/0/all/0/1">Georgios Katsimpras</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandorou_E/0/1/0/all/0/1">Eirini Vandorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1">Anastasia Krithara</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasco_L/0/1/0/all/0/1">Luis Gasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Krallinger_M/0/1/0/all/0/1">Martin Krallinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1">Georgios Paliouras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14885">
                                    <div class="article-summary-box-inner">
                                        <span>Advancing the state-of-the-art in large-scale biomedical semantic indexing
and question answering is the main focus of the BioASQ challenge. BioASQ
organizes respective tasks where different teams develop systems that are
evaluated on the same benchmark datasets that represent the real information
needs of experts in the biomedical domain. This paper presents an overview of
the ninth edition of the BioASQ challenge in the context of the Conference and
Labs of the Evaluation Forum (CLEF) 2021. In this year, a new question
answering task, named Synergy, is introduced to support researchers studying
the COVID-19 disease and measure the ability of the participating teams to
discern information while the problem is still developing. In total, 42 teams
with more than 170 systems were registered to participate in the four tasks of
the challenge. The evaluation results, similarly to previous years, show a
performance gain against the baselines which indicates the continuous
improvement of the state-of-the-art in this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On component interactions in two-stage recommender systems. (arXiv:2106.14979v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hron_J/0/1/0/all/0/1">Jiri Hron</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauth_K/0/1/0/all/0/1">Karl Krauth</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1">Niki Kilbertus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14979">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to their scalability, two-stage recommenders are used by many of
today&#x27;s largest online platforms, including YouTube, LinkedIn, and Pinterest.
These systems produce recommendations in two steps: (i) multiple nominators --
tuned for low prediction latency -- preselect a small subset of candidates from
the whole item pool; (ii)~a slower but more accurate ranker further narrows
down the nominated items, and serves to the user. Despite their popularity, the
literature on two-stage recommenders is relatively scarce, and the algorithms
are often treated as the sum of their parts. Such treatment presupposes that
the two-stage performance is explained by the behavior of individual components
if they were deployed independently. This is not the case: using synthetic and
real-world data, we demonstrate that interactions between the ranker and the
nominators substantially affect the overall performance. Motivated by these
findings, we derive a generalization lower bound which shows that careful
choice of each nominator&#x27;s training set is sometimes the only difference
between a poor and an optimal two-stage recommender. Since searching for a good
choice manually is difficult, we learn one instead. In particular, using a
Mixture-of-Experts approach, we train the nominators (experts) to specialize on
different subsets of the item pool. This significantly improves performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Hypercomplex Embeddings for Link Prediction. (arXiv:2106.15230v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1">Caglar Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Moussallem_D/0/1/0/all/0/1">Diego Moussallem</a>, <a href="http://arxiv.org/find/cs/1/au:+Heindorf_S/0/1/0/all/0/1">Stefan Heindorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1">Axel-Cyrille Ngonga Ngomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15230">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge graph embedding research has mainly focused on the two smallest
normed division algebras, $\mathbb{R}$ and $\mathbb{C}$. Recent results suggest
that trilinear products of quaternion-valued embeddings can be a more effective
means to tackle link prediction. In addition, models based on convolutions on
real-valued embeddings often yield state-of-the-art results for link
prediction. In this paper, we investigate a composition of convolution
operations with hypercomplex multiplications. We propose the four approaches
QMult, OMult, ConvQ and ConvO to tackle the link prediction problem. QMult and
OMult can be considered as quaternion and octonion extensions of previous
state-of-the-art approaches, including DistMult and ComplEx. ConvQ and ConvO
build upon QMult and OMult by including convolution operations in a way
inspired by the residual learning framework. We evaluated our approaches on
seven link prediction datasets including WN18RR, FB15K-237 and YAGO3-10.
Experimental results suggest that the benefits of learning hypercomplex-valued
vector representations become more apparent as the size and complexity of the
knowledge graph grows. ConvO outperforms state-of-the-art approaches on
FB15K-237 in MRR, Hit@1 and Hit@3, while QMult, OMult, ConvQ and ConvO
outperform state-of-the-approaches on YAGO3-10 in all metrics. Results also
suggest that link prediction performances can be further improved via
prediction averaging. To foster reproducible research, we provide an
open-source implementation of approaches, including training and evaluation
scripts as well as pretrained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery. (arXiv:2011.01619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yonghao Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Ying Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_B/0/1/0/all/0/1">Bo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yueming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yun-Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01619">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic surgical gesture recognition is fundamentally important to enable
intelligent cognitive assistance in robotic surgery. With recent advancement in
robot-assisted minimally invasive surgery, rich information including surgical
videos and robotic kinematics can be recorded, which provide complementary
knowledge for understanding surgical gestures. However, existing methods either
solely adopt uni-modal data or directly concatenate multi-modal
representations, which can not sufficiently exploit the informative
correlations inherent in visual and kinematics data to boost gesture
recognition accuracies. In this regard, we propose a novel online approach of
multi-modal relational graph network (i.e., MRG-Net) to dynamically integrate
visual and kinematics information through interactive message propagation in
the latent feature space. In specific, we first extract embeddings from video
and kinematics sequences with temporal convolutional networks and LSTM units.
Next, we identify multi-relations in these multi-modal embeddings and leverage
them through a hierarchical relational graph learning module. The effectiveness
of our method is demonstrated with state-of-the-art results on the public
JIGSAWS dataset, outperforming current uni-modal and multi-modal methods on
both suturing and knot typing tasks. Furthermore, we validated our method on
in-house visual-kinematics datasets collected with da Vinci Research Kit (dVRK)
platforms in two centers, with consistent promising performance achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forest Fire Clustering: Iterative Label Propagation Clustering and Monte Carlo Validation For Single-cell Sequencing Analysis. (arXiv:2103.11802v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhanlin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1">Jeremy Goldwasser</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuckman_P/0/1/0/all/0/1">Philip Tuckman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gerstein_M/0/1/0/all/0/1">Mark Gerstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11802">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of single-cell sequencing technologies, there is a growing need
for robust clustering algorithms to extract deeper insights from data. Here, we
introduce an intuitive and efficient clustering method, Forest Fire Clustering,
for discovering and validating cell types in single-cell sequencing analysis.
Compared to existing methods, our clustering algorithm makes minimum prior
assumptions about the data distribution and can provide a point-wise
significance value via Monte Carlo simulations for internal validation.
Additionally, point-wise label entropies can highlight novel transition cell
types \emph{de novo} along developmental pseudo-time manifolds. Lastly, our
inductive algorithm has the ability to make robust inferences in an
online-learning context. In this paper, we describe the method, provide a
summary of its performance against common clustering benchmarks, and
demonstrate that Forest Fire Clustering is uniquely suitable for single-cell
sequencing analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetry meets AI. (arXiv:2103.06115v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barenboim_G/0/1/0/all/0/1">Gabriela Barenboim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirn_J/0/1/0/all/0/1">Johannes Hirn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanz_V/0/1/0/all/0/1">Veronica Sanz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06115">
                                    <div class="article-summary-box-inner">
                                        <span>We explore whether Neural Networks (NNs) can {\it discover} the presence of
symmetries as they learn to perform a task. For this, we train hundreds of NNs
on a {\it decoy task} based on well-controlled Physics templates, where no
information on symmetry is provided. We use the output from the last hidden
layer of all these NNs, projected to fewer dimensions, as the input for a
symmetry classification task, and show that information on symmetry had indeed
been identified by the original NN without guidance. As an interdisciplinary
application of this procedure, we identify the presence and level of symmetry
in artistic paintings from different styles such as those of Picasso, Pollock
and Van Gogh.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepFaceLab: Integrated, flexible and extensible face-swapping framework. (arXiv:2005.05535v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perov_I/0/1/0/all/0/1">Ivan Perov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1">Daiheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chervoniy_N/0/1/0/all/0/1">Nikolay Chervoniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kunlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marangonda_S/0/1/0/all/0/1">Sugasa Marangonda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ume_C/0/1/0/all/0/1">Chris Um&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Dpfks_M/0/1/0/all/0/1">Mr. Dpfks</a>, <a href="http://arxiv.org/find/cs/1/au:+Facenheim_C/0/1/0/all/0/1">Carl Shift Facenheim</a>, <a href="http://arxiv.org/find/cs/1/au:+RP_L/0/1/0/all/0/1">Luis RP</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Pingyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfake defense not only requires the research of detection but also
requires the efforts of generation methods. However, current deepfake methods
suffer the effects of obscure workflow and poor performance. To solve this
problem, we present DeepFaceLab, the current dominant deepfake framework for
face-swapping. It provides the necessary tools as well as an easy-to-use way to
conduct high-quality face-swapping. It also offers a flexible and loose
coupling structure for people who need to strengthen their pipeline with other
features without writing complicated boilerplate code. We detail the principles
that drive the implementation of DeepFaceLab and introduce its pipeline,
through which every aspect of the pipeline can be modified painlessly by users
to achieve their customization purpose. It is noteworthy that DeepFaceLab could
achieve cinema-quality results with high fidelity. We demonstrate the advantage
of our system by comparing our approach with other face-swapping methods.For
more information, please visit:https://github.com/iperov/DeepFaceLab/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wasserstein Adversarial Regularization (WAR) on label noise. (arXiv:1904.03936v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fatras_K/0/1/0/all/0/1">Kilian Fatras</a>, <a href="http://arxiv.org/find/cs/1/au:+Damodaran_B/0/1/0/all/0/1">Bharath Bhushan Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lobry_S/0/1/0/all/0/1">Sylvain Lobry</a>, <a href="http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1">R&#xe9;mi Flamary</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1">Devis Tuia</a>, <a href="http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1">Nicolas Courty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03936">
                                    <div class="article-summary-box-inner">
                                        <span>Noisy labels often occur in vision datasets, especially when they are
obtained from crowdsourcing or Web scraping. We propose a new regularization
method, which enables learning robust classifiers in presence of noisy data. To
achieve this goal, we propose a new adversarial regularization scheme based on
the Wasserstein distance. Using this distance allows taking into account
specific relations between classes by leveraging the geometric properties of
the labels space. Our Wasserstein Adversarial Regularization (WAR) encodes a
selective regularization, which promotes smoothness of the classifier between
some classes, while preserving sufficient complexity of the decision boundary
between others. We first discuss how and why adversarial regularization can be
used in the context of label noise and then show the effectiveness of our
method on five datasets corrupted with noisy labels: in both benchmarks and
real datasets, WAR outperforms the state-of-the-art competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Policy Gradients: Leveraging Structure for Efficient Learning in (Factored) MOMDPs. (arXiv:2102.10362v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spooner_T/0/1/0/all/0/1">Thomas Spooner</a>, <a href="http://arxiv.org/find/cs/1/au:+Vadori_N/0/1/0/all/0/1">Nelson Vadori</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesh_S/0/1/0/all/0/1">Sumitra Ganesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10362">
                                    <div class="article-summary-box-inner">
                                        <span>Policy gradient methods can solve complex tasks but often fail when the
dimensionality of the action-space or objective multiplicity grow very large.
This occurs, in part, because the variance on score-based gradient estimators
scales quadratically. In this paper, we address this problem through a causal
baseline which exploits independence structure encoded in a novel action-target
influence network. Causal policy gradients (CPGs), which follow, provide a
common framework for analysing key state-of-the-art algorithms, are shown to
generalise traditional policy gradients, and yield a principled way of
incorporating prior knowledge of a problem domain&#x27;s generative processes. We
provide an analysis of the proposed estimator and identify the conditions under
which variance is reduced. The algorithmic aspects of CPGs are discussed,
including optimal policy factorisation, as characterised by minimum biclique
coverings, and the implications for the bias-variance trade-off of incorrectly
specifying the network. Finally, we demonstrate the performance advantages of
our algorithm on large-scale bandit and traffic intersection problems,
providing a novel contribution to the latter in the form of a spatio-causal
approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning of Implicit and Explicit Control Flow in Instructions. (arXiv:2102.13195v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brooks_E/0/1/0/all/0/1">Ethan A. Brooks</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajendran_J/0/1/0/all/0/1">Janarthanan Rajendran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_R/0/1/0/all/0/1">Richard L. Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satinder Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13195">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to flexibly follow task instructions in dynamic environments poses
interesting challenges for reinforcement learning agents. We focus here on the
problem of learning control flow that deviates from a strict step-by-step
execution of instructions -- that is, control flow that may skip forward over
parts of the instructions or return backward to previously completed or skipped
steps. Demand for such flexible control arises in two fundamental ways:
explicitly when control is specified in the instructions themselves (such as
conditional branching and looping) and implicitly when stochastic environment
dynamics require re-completion of instructions whose effects have been
perturbed, or opportunistic skipping of instructions whose effects are already
present. We formulate an attention-based architecture that meets these
challenges by learning, from task reward only, to flexibly attend to and
condition behavior on an internal encoding of the instructions. We test the
architecture&#x27;s ability to learn both explicit and implicit control in two
illustrative domains -- one inspired by Minecraft and the other by StarCraft --
and show that the architecture exhibits zero-shot generalization to novel
instructions of length greater than those in a training set, at a performance
level unmatched by two baseline recurrent architectures and one ablation
architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-asymptotic Superlinear Convergence of Standard Quasi-Newton Methods. (arXiv:2003.13607v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jin_Q/0/1/0/all/0/1">Qiujiang Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1">Aryan Mokhtari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13607">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study and prove the non-asymptotic superlinear convergence
rate of the Broyden class of quasi-Newton methods including
Davidon--Fletcher--Powell (DFP) method and Broyden--Fletcher--Goldfarb--Shanno
(BFGS) method. The asymptotic superlinear convergence rate of these
quasi-Newton methods has been extensively studied, but their explicit finite
time local convergence rate is not fully investigated. In this paper, we
provide a finite time (non-asymptotic) convergence analysis for BFGS and DFP
methods under the assumptions that the objective function is strongly convex,
its gradient is Lipschitz continuous, and its Hessian is Lipschitz continuous
only in the direction of the optimal solution. We show that in a local
neighborhood of the optimal solution, the iterates generated by both DFP and
BFGS converge to the optimal solution at a superlinear rate of $(1/k)^{k/2}$,
where $k$ is the number of iterations. We also prove the same local superlinear
convergence rate in the case that the objective function is self-concordant.
Numerical experiments on different objective functions confirm our explicit
convergence rates. Our theoretical guarantee is one of the first results that
provide a non-asymptotic superlinear convergence rate for DFP and BFGS
quasi-Newton methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. (arXiv:2102.07868v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1">Idan Achituve</a>, <a href="http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1">Aviv Navon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yemini_Y/0/1/0/all/0/1">Yochai Yemini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1">Ethan Fetaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07868">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) are non-parametric, flexible, models that work well
in many tasks. Combining GPs with deep learning methods via deep kernel
learning (DKL) is especially compelling due to the strong representational
power induced by the network. However, inference in GPs, whether with or
without DKL, can be computationally challenging on large datasets. Here, we
propose GP-Tree, a novel method for multi-class classification with Gaussian
processes and DKL. We develop a tree-based hierarchical model in which each
internal node of the tree fits a GP to the data using the P\&#x27;olya Gamma
augmentation scheme. As a result, our method scales well with both the number
of classes and data size. We demonstrate the effectiveness of our method
against other Gaussian process training baselines, and we show how our general
GP approach achieves improved accuracy on standard incremental few-shot
learning benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias-Free Scalable Gaussian Processes via Randomized Truncations. (arXiv:2102.06695v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Potapczynski_A/0/1/0/all/0/1">Andres Potapczynski</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Luhuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biderman_D/0/1/0/all/0/1">Dan Biderman</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06695">
                                    <div class="article-summary-box-inner">
                                        <span>Scalable Gaussian Process methods are computationally attractive, yet
introduce modeling biases that require rigorous study. This paper analyzes two
common techniques: early truncated conjugate gradients (CG) and random Fourier
features (RFF). We find that both methods introduce a systematic bias on the
learned hyperparameters: CG tends to underfit while RFF tends to overfit. We
address these issues using randomized truncation estimators that eliminate bias
in exchange for increased variance. In the case of RFF, we show that the
bias-to-variance conversion is indeed a trade-off: the additional variance
proves detrimental to optimization. However, in the case of CG, our unbiased
learning procedure meaningfully outperforms its biased counterpart with minimal
additional computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm. (arXiv:2102.12238v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1">Meena Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Razenshteyn_I/0/1/0/all/0/1">Ilya Razenshteyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1">Suriya Gunasekar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12238">
                                    <div class="article-summary-box-inner">
                                        <span>We study the function space characterization of the inductive bias resulting
from controlling the $\ell_2$ norm of the weights in linear convolutional
networks. We view this in terms of an induced regularizer in the function space
given by the minimum norm of weights required to realize a linear function. For
two layer linear convolutional networks with $C$ output channels and kernel
size $K$, we show the following: (a) If the inputs to the network have a single
channel, the induced regularizer for any $K$ is a norm given by a semidefinite
program (SDP) that is independent of the number of output channels $C$. (b) In
contrast, for networks with multi-channel inputs, multiple output channels can
be necessary to merely realize all matrix-valued linear functions and thus the
inductive bias does depend on $C$. Further, for sufficiently large $C$, the
induced regularizer for $K&#x3D;1$ and $K&#x3D;D$ are the nuclear norm and the
$\ell_{2,1}$ group-sparse norm, respectively, of the Fourier coefficients. (c)
Complementing our theoretical results, we show through experiments on MNIST and
CIFAR-10 that our key findings extend to implicit biases from gradient descent
in overparameterized networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Approximation Theorems for Differentiable Geometric Deep Learning. (arXiv:2101.05390v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kratsios_A/0/1/0/all/0/1">Anastasis Kratsios</a>, <a href="http://arxiv.org/find/cs/1/au:+Papon_L/0/1/0/all/0/1">Leonie Papon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05390">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the growing need to process non-Euclidean data, by
introducing a geometric deep learning (GDL) framework for building universal
feedforward-type models compatible with differentiable manifold geometries. We
show that our GDL models can approximate any continuous target function
uniformly on compacts of a controlled maximum diameter. We obtain curvature
dependant lower-bounds on this maximum diameter and upper-bounds on the depth
of our approximating GDL models. Conversely, we find that there is always a
continuous function between any two non-degenerate compact manifolds that any
&quot;locally-defined&quot; GDL model cannot uniformly approximate. Our last main result
identifies data-dependent conditions guaranteeing that the GDL model
implementing our approximation breaks &quot;the curse of dimensionality.&quot; We find
that any &quot;real-world&quot; (i.e. finite) dataset always satisfies our condition and,
conversely, any dataset satisfies our requirement if the target function is
smooth. As applications, we confirm the universal approximation capabilities of
the following GDL models: Ganea et al. (2018)&#x27;s hyperbolic feedforward
networks, the architecture implementing Krishnan et al. (2015)&#x27;s deep
Kalman-Filter, and deep softmax classifiers. We build universal
extensions/variants of: the SPD-matrix regressor of Meyer et al. (2011), and
Fletcher et al. (2009)&#x27;s Procrustean regressor. In the Euclidean setting, our
results imply a quantitative version of Kidger and Lyons (2020)&#x27;s approximation
theorem and a data-dependent version of Yarotsky and Zhevnerchuk (2020)&#x27;s
uncursed approximation rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks. (arXiv:2102.11600v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwon_J/0/1/0/all/0/1">Jungmin Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jeongseop Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyunseo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_I/0/1/0/all/0/1">In Kwon Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11600">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, learning algorithms motivated from sharpness of loss surface as an
effective measure of generalization gap have shown state-of-the-art
performances. Nevertheless, sharpness defined in a rigid region with a fixed
radius, has a drawback in sensitivity to parameter re-scaling which leaves the
loss unaffected, leading to weakening of the connection between sharpness and
generalization gap. In this paper, we introduce the concept of adaptive
sharpness which is scale-invariant and propose the corresponding generalization
bound. We suggest a novel learning method, adaptive sharpness-aware
minimization (ASAM), utilizing the proposed generalization bound. Experimental
results in various benchmark datasets show that ASAM contributes to significant
improvement of model generalization performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Arabic Speech Recognition by End-to-End, Modular Systems and Human. (arXiv:2101.08454v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hussein_A/0/1/0/all/0/1">Amir Hussein</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08454">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in automatic speech recognition (ASR) have achieved accuracy
levels comparable to human transcribers, which led researchers to debate if the
machine has reached human performance. Previous work focused on the English
language and modular hidden Markov model-deep neural network (HMM-DNN) systems.
In this paper, we perform a comprehensive benchmarking for end-to-end
transformer ASR, modular HMM-DNN ASR, and human speech recognition (HSR) on the
Arabic language and its dialects. For the HSR, we evaluate linguist performance
and lay-native speaker performance on a new dataset collected as a part of this
study. For ASR the end-to-end work led to 12.5%, 27.5%, 33.8% WER; a new
performance milestone for the MGB2, MGB3, and MGB5 challenges respectively. Our
results suggest that human performance in the Arabic language is still
considerably better than the machine with an absolute WER gap of 3.5% on
average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid parameter estimation of discrete decaying signals using autoencoder networks. (arXiv:2103.08663v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Visschers_J/0/1/0/all/0/1">Jim C. Visschers</a>, <a href="http://arxiv.org/find/eess/1/au:+Budker_D/0/1/0/all/0/1">Dmitry Budker</a>, <a href="http://arxiv.org/find/eess/1/au:+Bougas_L/0/1/0/all/0/1">Lykourgos Bougas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08663">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we demonstrate the use of neural networks for rapid extraction
of signal parameters of discretely sampled signals. In particular, we use dense
autoencoder networks to extract the parameters of interest from exponentially
decaying signals and decaying oscillations. By using a three-stage training
method and careful choice of the neural network size, we are able to retrieve
the relevant signal parameters directly from the latent space of the
autoencoder network at significantly improved rates compared to traditional
algorithmic signal-analysis approaches. We show that the achievable precision
and accuracy of this method of analysis is similar to conventional
algorithm-based signal analysis methods, by demonstrating that the extracted
signal parameters are approaching their fundamental parameter estimation limit
as provided by the Cram\&#x27;er-Rao bound. Furthermore, we demonstrate that
autoencoder networks are able to achieve signal analysis, and, hence, parameter
extraction, at rates of 75 kHz, orders-of-magnitude faster than conventional
techniques with similar precision. Finally, we explore the limitations of our
approach, demonstrating that analysis rates of $&gt;$200 kHz are feasible with
further optimization of the transfer rate between the data-acquisition system
and data-analysis system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complexity of Stochastic Dual Dynamic Programming. (arXiv:1912.07702v6 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1">Guanghui Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.07702">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic dual dynamic programming is a cutting plane type algorithm for
multi-stage stochastic optimization originated about 30 years ago. In spite of
its popularity in practice, there does not exist any analysis on the
convergence rates of this method. In this paper, we first establish the number
of iterations, i.e., iteration complexity, required by a basic dynamic cutting
plane method for solving relatively simple multi-stage optimization problems,
by introducing novel mathematical tools including the saturation of search
points. We then refine these basic tools and establish the iteration complexity
for both deterministic and stochastic dual dynamic programming methods for
solving more general multi-stage stochastic optimization problems under the
standard stage-wise independence assumption. Our results indicate that the
complexity of these methods mildly increases with the number of stages $T$, in
fact linearly dependent on $T$ for discounted problems. Therefore, they are
efficient for strategic decision making which involves a large number of
stages, but with a relatively small number of decision variables in each stage.
Without explicitly discretizing the state and action spaces, these methods
might also be pertinent to the related reinforcement learning and stochastic
control areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing the Stability of Non-coplanar Circumbinary Planets using Machine Learning. (arXiv:2101.02316v2 [astro-ph.EP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Kong_Z/0/1/0/all/0/1">Zhihui Kong</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jiang_J/0/1/0/all/0/1">Jonathan H. Jiang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Zhu_Z/0/1/0/all/0/1">Zong-Hong Zhu</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Fahy_K/0/1/0/all/0/1">Kristen A. Fahy</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Burn_R/0/1/0/all/0/1">Remo Burn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02316">
                                    <div class="article-summary-box-inner">
                                        <span>Exoplanet detection in the past decade by efforts including NASA&#x27;s Kepler and
TESS missions has discovered many worlds that differ substantially from planets
in our own Solar system, including more than 400 exoplanets orbiting binary or
multi-star systems. This not only broadens our understanding of the diversity
of exoplanets, but also promotes our study of exoplanets in the complex binary
and multi-star systems and provides motivation to explore their habitability.
In this study, we analyze orbital stability of exoplanets in non-coplanar
circumbinary systems using a numerical simulation method, with which a large
number of circumbinary planet samples are generated in order to quantify the
effects of various orbital parameters on orbital stability. We also train a
machine learning model that can quickly determine the stability of the
circumbinary planetary systems. Our results indicate that larger inclinations
of the planet tend to increase the stability of its orbit, but change in the
planet&#x27;s mass range between Earth and Jupiter has little effect on the
stability of the system. In addition, we find that Deep Neural Networks (DNNs)
have higher accuracy and precision than other machine learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-Optimal Explainable $k$-Means for All Dimensions. (arXiv:2106.15566v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1">Moses Charikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lunjia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15566">
                                    <div class="article-summary-box-inner">
                                        <span>Many clustering algorithms are guided by certain cost functions such as the
widely-used $k$-means cost. These algorithms divide data points into clusters
with often complicated boundaries, creating difficulties in explaining the
clustering decision. In a recent work, Dasgupta, Frost, Moshkovitz, and
Rashtchian (ICML&#x27;20) introduced explainable clustering, where the cluster
boundaries are axis-parallel hyperplanes and the clustering is obtained by
applying a decision tree to the data. The central question here is: how much
does the explainability constraint increase the value of the cost function?

Given $d$-dimensional data points, we show an efficient algorithm that finds
an explainable clustering whose $k$-means cost is at most $k^{1 -
2/d}\mathrm{poly}(d\log k)$ times the minimum cost achievable by a clustering
without the explainability constraint, assuming $k,d\ge 2$. Combining this with
an independent work by Makarychev and Shan (ICML&#x27;21), we get an improved bound
of $k^{1 - 2/d}\mathrm{polylog}(k)$, which we show is optimal for every choice
of $k,d\ge 2$ up to a poly-logarithmic factor in $k$. For $d &#x3D; 2$ in
particular, we show an $O(\log k\log\log k)$ bound, improving exponentially
over the previous best bound of $\widetilde O(k)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Approximation Properties of Dictionaries and Applications to Neural Networks. (arXiv:2101.12365v6 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1">Jonathan W. Siegel</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jinchao Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12365">
                                    <div class="article-summary-box-inner">
                                        <span>This article addresses the problem of approximating a function in a Hilbert
space by an expansion over a dictionary $\mathbb{D}$. We introduce the notion
of a smoothly parameterized dictionary and give upper bounds on the
approximation rates, metric entropy and $n$-widths of the absolute convex hull,
which we denote $B_1(\mathbb{D})$, of such dictionaries. The upper bounds
depend upon the order of smoothness of the parameterization, and improve upon
existing results in many cases. The main applications of these results is to
the dictionaries $\mathbb{D} &#x3D; \{\sigma(\omega\cdot x + b)\}\subset L^2$
corresponding to shallow neural networks with activation function $\sigma$, and
to the dictionary of decaying Fourier modes corresponding to the spectral
Barron space. This improves upon existing approximation rates for shallow
neural networks when $\sigma &#x3D; \text{ReLU}^k$ for $k\geq 2$, sharpens bounds on
the metric entropy, and provides the first bounds on the Gelfand $n$-widths of
the Barron space and spectral Barron space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Classification Learning with Neural Networks and Conceptors for Speech Recognition and Car Driving Maneuvers. (arXiv:2102.05588v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krause_S/0/1/0/all/0/1">Stefanie Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Otto_O/0/1/0/all/0/1">Oliver Otto</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1">Frieder Stolzenburg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05588">
                                    <div class="article-summary-box-inner">
                                        <span>Recurrent neural networks are a powerful means in diverse applications. We
show that, together with so-called conceptors, they also allow fast learning,
in contrast to other deep learning methods. In addition, a relatively small
number of examples suffices to train neural networks with high accuracy. We
demonstrate this with two applications, namely speech recognition and detecting
car driving maneuvers. We improve the state of the art by application-specific
preparation techniques: For speech recognition, we use mel frequency cepstral
coefficients leading to a compact representation of the frequency spectra, and
detecting car driving maneuvers can be done without the commonly used
polynomial interpolation, as our evaluation suggests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Gradient Aggregation for Decentralized Learning from Non-IID data. (arXiv:2103.02051v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Esfandiari_Y/0/1/0/all/0/1">Yasaman Esfandiari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Sin Yong Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhanhong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Balu_A/0/1/0/all/0/1">Aditya Balu</a>, <a href="http://arxiv.org/find/cs/1/au:+Herron_E/0/1/0/all/0/1">Ethan Herron</a>, <a href="http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1">Chinmay Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1">Soumik Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02051">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized learning enables a group of collaborative agents to learn
models using a distributed dataset without the need for a central parameter
server. Recently, decentralized learning algorithms have demonstrated
state-of-the-art results on benchmark data sets, comparable with centralized
algorithms. However, the key assumption to achieve competitive performance is
that the data is independently and identically distributed (IID) among the
agents which, in real-life applications, is often not applicable. Inspired by
ideas from continual learning, we propose Cross-Gradient Aggregation (CGA), a
novel decentralized learning algorithm where (i) each agent aggregates
cross-gradient information, i.e., derivatives of its model with respect to its
neighbors&#x27; datasets, and (ii) updates its model using a projected gradient
based on quadratic programming (QP). We theoretically analyze the convergence
characteristics of CGA and demonstrate its efficiency on non-IID data
distributions sampled from the MNIST and CIFAR-10 datasets. Our empirical
comparisons show superior learning performance of CGA over existing
state-of-the-art decentralized learning algorithms, as well as maintaining the
improved performance under information compression to reduce peer-to-peer
communication overhead. The code is available here on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Muddling Label Regularization: Deep Learning for Tabular Datasets. (arXiv:2106.04462v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lounici_K/0/1/0/all/0/1">Karim Lounici</a>, <a href="http://arxiv.org/find/cs/1/au:+Meziani_K/0/1/0/all/0/1">Katia Meziani</a>, <a href="http://arxiv.org/find/cs/1/au:+Riu_B/0/1/0/all/0/1">Benjamin Riu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04462">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning (DL) is considered the state-of-the-art in computer vision,
speech recognition and natural language processing. Until recently, it was also
widely accepted that DL is irrelevant for learning tasks on tabular data,
especially in the small sample regime where ensemble methods are acknowledged
as the gold standard. We present a new end-to-end differentiable method to
train a standard FFNN. Our method, \textbf{Muddling labels for Regularization}
(\texttt{MLR}), penalizes memorization through the generation of uninformative
labels and the application of a differentiable close-form regularization scheme
on the last hidden layer during training. \texttt{MLR} outperforms classical NN
and the gold standard (GBDT, RF) for regression and classification tasks on
several datasets from the UCI database and Kaggle covering a large range of
sample sizes and feature to sample ratios. Researchers and practitioners can
use \texttt{MLR} on its own as an off-the-shelf \DL{} solution or integrate it
into the most advanced ML pipelines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Policy Risk Assessment in Contextual Bandits. (arXiv:2104.08977v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Audrey Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Leqi_L/0/1/0/all/0/1">Liu Leqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1">Kamyar Azizzadenesheli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08977">
                                    <div class="article-summary-box-inner">
                                        <span>Even when unable to run experiments, practitioners can evaluate prospective
policies, using previously logged data. However, while the bandits literature
has adopted a diverse set of objectives, most research on off-policy evaluation
to date focuses on the expected reward. In this paper, we introduce Lipschitz
risk functionals, a broad class of objectives that subsumes conditional
value-at-risk (CVaR), variance, mean-variance, many distorted risks, and CPT
risks, among others. We propose Off-Policy Risk Assessment (OPRA), a framework
that first estimates a target policy&#x27;s CDF and then generates plugin estimates
for any collection of Lipschitz risks, providing finite sample guarantees that
hold simultaneously over the entire class. We instantiate OPRA with both
importance sampling and doubly robust estimators. Our primary theoretical
contributions are (i) the first uniform concentration inequalities for both CDF
estimators in contextual bandits and (ii) error bounds on our Lipschitz risk
estimates, which all converge at a rate of $O(1/\sqrt{n})$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image is Worth More Than a Thousand Words: Towards Disentanglement in the Wild. (arXiv:2106.15610v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gabbay_A/0/1/0/all/0/1">Aviv Gabbay</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15610">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised disentanglement has been shown to be theoretically impossible
without inductive biases on the models and the data. As an alternative
approach, recent methods rely on limited supervision to disentangle the factors
of variation and allow their identifiability. While annotating the true
generative factors is only required for a limited number of observations, we
argue that it is infeasible to enumerate all the factors of variation that
describe a real-world image distribution. To this end, we propose a method for
disentangling a set of factors which are only partially labeled, as well as
separating the complementary set of residual factors that are never explicitly
specified. Our success in this challenging setting, demonstrated on synthetic
benchmarks, gives rise to leveraging off-the-shelf image descriptors to
partially annotate a subset of attributes in real image domains (e.g. of human
faces) with minimal manual effort. Specifically, we use a recent language-image
embedding model (CLIP) to annotate a set of attributes of interest in a
zero-shot manner and demonstrate state-of-the-art disentangled image
manipulation results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised learning with Bayesian Confidence Propagation Neural Network. (arXiv:2106.15546v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_N/0/1/0/all/0/1">Naresh Balaji Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lansner_A/0/1/0/all/0/1">Anders Lansner</a>, <a href="http://arxiv.org/find/cs/1/au:+Herman_P/0/1/0/all/0/1">Pawel Herman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15546">
                                    <div class="article-summary-box-inner">
                                        <span>Learning internal representations from data using no or few labels is useful
for machine learning research, as it allows using massive amounts of unlabeled
data. In this work, we use the Bayesian Confidence Propagation Neural Network
(BCPNN) model developed as a biologically plausible model of the cortex. Recent
work has demonstrated that these networks can learn useful internal
representations from data using local Bayesian-Hebbian learning rules. In this
work, we show how such representations can be leveraged in a semi-supervised
setting by introducing and comparing different classifiers. We also evaluate
and compare such networks with other popular semi-supervised classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The U-Net based GLOW for Optical-Flow-free Video Interframe Generation. (arXiv:2103.09576v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Saem Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Donghoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1">Nojun Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09576">
                                    <div class="article-summary-box-inner">
                                        <span>Video frame interpolation is the task of creating an interframe between two
adjacent frames along the time axis. So, instead of simply averaging two
adjacent frames to create an intermediate image, this operation should maintain
semantic continuity with the adjacent frames. Most conventional methods use
optical flow, and various tools such as occlusion handling and object smoothing
are indispensable. Since the use of these various tools leads to complex
problems, we tried to tackle the video interframe generation problem without
using problematic optical flow . To enable this , we have tried to use a deep
neural network with an invertible structure, and developed an U-Net based
Generative Flow which is a modified normalizing flow. In addition, we propose a
learning method with a new consistency loss in the latent space to maintain
semantic temporal consistency between frames. The resolution of the generated
image is guaranteed to be identical to that of the original images by using an
invertible network. Furthermore, as it is not a random image like the ones by
generative models, our network guarantees stable outputs without flicker.
Through experiments, we \sam {confirmed the feasibility of the proposed
algorithm and would like to suggest the U-Net based Generative Flow as a new
possibility for baseline in video frame interpolation. This paper is meaningful
in that it is the world&#x27;s first attempt to use invertible networks instead of
optical flows for video interpolation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HDMI: High-order Deep Multiplex Infomax. (arXiv:2102.07810v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jing_B/0/1/0/all/0/1">Baoyu Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1">Chanyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1">Hanghang Tong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07810">
                                    <div class="article-summary-box-inner">
                                        <span>Networks have been widely used to represent the relations between objects
such as academic networks and social networks, and learning embedding for
networks has thus garnered plenty of research attention. Self-supervised
network representation learning aims at extracting node embedding without
external supervision. Recently, maximizing the mutual information between the
local node embedding and the global summary (e.g. Deep Graph Infomax, or DGI
for short) has shown promising results on many downstream tasks such as node
classification. However, there are two major limitations of DGI. Firstly, DGI
merely considers the extrinsic supervision signal (i.e., the mutual information
between node embedding and global summary) while ignores the intrinsic signal
(i.e., the mutual dependence between node embedding and node attributes).
Secondly, nodes in a real-world network are usually connected by multiple edges
with different relations, while DGI does not fully explore the various
relations among nodes. To address the above-mentioned problems, we propose a
novel framework, called High-order Deep Multiplex Infomax (HDMI), for learning
node embedding on multiplex networks in a self-supervised way. To be more
specific, we first design a joint supervision signal containing both extrinsic
and intrinsic mutual information by high-order mutual information, and we
propose a High-order Deep Infomax (HDI) to optimize the proposed supervision
signal. Then we propose an attention based fusion module to combine node
embedding from different layers of the multiplex network. Finally, we evaluate
the proposed HDMI on various downstream tasks such as unsupervised clustering
and supervised classification. The experimental results show that HDMI achieves
state-of-the-art performance on these tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impossibility of Partial Recovery in the Graph Alignment Problem. (arXiv:2102.02685v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ganassali_L/0/1/0/all/0/1">Luca Ganassali</a>, <a href="http://arxiv.org/find/stat/1/au:+Massoulie_L/0/1/0/all/0/1">Laurent Massouli&#xe9;</a>, <a href="http://arxiv.org/find/stat/1/au:+Lelarge_M/0/1/0/all/0/1">Marc Lelarge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02685">
                                    <div class="article-summary-box-inner">
                                        <span>Random graph alignment refers to recovering the underlying vertex
correspondence between two random graphs with correlated edges. This can be
viewed as an average-case and noisy version of the well-known graph isomorphism
problem. For the correlated Erd\&quot;os-R\&#x27;enyi model, we prove an impossibility
result for partial recovery in the sparse regime, with constant average degree
and correlation, as well as a general bound on the maximal reachable overlap.
Our bound is tight in the noiseless case (the graph isomorphism problem) and we
conjecture that it is still tight with noise. Our proof technique relies on a
careful application of the probabilistic method to build automorphisms between
tree components of a subcritical Erd\&quot;os-R\&#x27;enyi graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated classification of plasma regions using 3D particle energy distributions. (arXiv:1908.05715v3 [physics.space-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Olshevsky_V/0/1/0/all/0/1">Vyacheslav Olshevsky</a>, <a href="http://arxiv.org/find/physics/1/au:+Khotyaintsev_Y/0/1/0/all/0/1">Yuri V. Khotyaintsev</a>, <a href="http://arxiv.org/find/physics/1/au:+Lalti_A/0/1/0/all/0/1">Ahmad Lalti</a>, <a href="http://arxiv.org/find/physics/1/au:+Divin_A/0/1/0/all/0/1">Andrey Divin</a>, <a href="http://arxiv.org/find/physics/1/au:+Delzanno_G/0/1/0/all/0/1">Gian Luca Delzanno</a>, <a href="http://arxiv.org/find/physics/1/au:+Anderzen_S/0/1/0/all/0/1">Sven Anderzen</a>, <a href="http://arxiv.org/find/physics/1/au:+Herman_P/0/1/0/all/0/1">Pawel Herman</a>, <a href="http://arxiv.org/find/physics/1/au:+Chien_S/0/1/0/all/0/1">Steven W.D. Chien</a>, <a href="http://arxiv.org/find/physics/1/au:+Avanov_L/0/1/0/all/0/1">Levon Avanov</a>, <a href="http://arxiv.org/find/physics/1/au:+Dimmock_A/0/1/0/all/0/1">Andrew P. Dimmock</a>, <a href="http://arxiv.org/find/physics/1/au:+Markidis_S/0/1/0/all/0/1">Stefano Markidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.05715">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the properties of the ion sky maps produced by the Dual Ion
Spectrometers (DIS) from the Fast Plasma Investigation (FPI). We have trained a
convolutional neural network classifier to predict four regions crossed by the
MMS on the dayside magnetosphere: solar wind, ion foreshock, magnetosheath, and
magnetopause using solely DIS spectrograms. The accuracy of the classifier is
&gt;98%. We use the classifier to detect mixed plasma regions, in particular to
find the bow shock regions. A similar approach can be used to identify the
magnetopause crossings and reveal regions prone to magnetic reconnection. Data
processing through the trained classifier is fast and efficient and thus can be
used for classification for the whole MMS database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Natural Language Understanding with Explanations as Latent Variables. (arXiv:2011.05268v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jinyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chenyan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05268">
                                    <div class="article-summary-box-inner">
                                        <span>Recently generating natural language explanations has shown very promising
results in not only offering interpretable explanations but also providing
additional information and supervision for prediction. However, existing
approaches usually require a large set of human annotated explanations for
training while collecting a large set of explanations is not only time
consuming but also expensive. In this paper, we develop a general framework for
interpretable natural language understanding that requires only a small set of
human annotated explanations for training. Our framework treats natural
language explanations as latent variables that model the underlying reasoning
process of a neural model. We develop a variational EM framework for
optimization where an explanation generation module and an
explanation-augmented prediction module are alternatively optimized and
mutually enhance each other. Moreover, we further propose an explanation-based
self-training method under this framework for semi-supervised learning. It
alternates between assigning pseudo-labels to unlabeled data and generating new
explanations to iteratively improve each other. Experiments on two natural
language understanding tasks demonstrate that our framework can not only make
effective predictions in both supervised and semi-supervised settings, but also
generate good natural language explanation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A function approximation approach to the prediction of blood glucose levels. (arXiv:2105.05893v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1">H.N. Mhaskar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereverzyev_S/0/1/0/all/0/1">S.V. Pereverzyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Walt_M/0/1/0/all/0/1">M.D. van der Walt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05893">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of real time prediction of blood glucose (BG) levels based on the
readings from a continuous glucose monitoring (CGM) device is a problem of
great importance in diabetes care, and therefore, has attracted a lot of
research in recent years, especially based on machine learning. An accurate
prediction with a 30, 60, or 90 minute prediction horizon has the potential of
saving millions of dollars in emergency care costs. In this paper, we treat the
problem as one of function approximation, where the value of the BG level at
time $t+h$ (where $h$ the prediction horizon) is considered to be an unknown
function of $d$ readings prior to the time $t$. This unknown function may be
supported in particular on some unknown submanifold of the $d$-dimensional
Euclidean space. While manifold learning is classically done in a
semi-supervised setting, where the entire data has to be known in advance, we
use recent ideas to achieve an accurate function approximation in a supervised
setting; i.e., construct a model for the target function. We use the
state-of-the-art clinically relevant PRED-EGA grid to evaluate our results, and
demonstrate that for a real life dataset, our method performs better than a
standard deep network, especially in hypoglycemic and hyperglycemic regimes.
One noteworthy aspect of this work is that the training data and test data may
come from different distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Approaches for Indoor Localization for Ambient Assisted Living in Smart Homes. (arXiv:2106.15606v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chia Y. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15606">
                                    <div class="article-summary-box-inner">
                                        <span>This work makes multiple scientific contributions to the field of Indoor
Localization for Ambient Assisted Living in Smart Homes. First, it presents a
Big-Data driven methodology that studies the multimodal components of user
interactions and analyzes the data from Bluetooth Low Energy (BLE) beacons and
BLE scanners to detect a user&#x27;s indoor location in a specific activity-based
zone during Activities of Daily Living. Second, it introduces a context
independent approach that can interpret the accelerometer and gyroscope data
from diverse behavioral patterns to detect the zone-based indoor location of a
user in any Internet of Things (IoT)-based environment. These two approaches
achieved performance accuracies of 81.36% and 81.13%, respectively, when tested
on a dataset. Third, it presents a methodology to detect the spatial
coordinates of a user&#x27;s indoor position that outperforms all similar works in
this field, as per the associated root mean squared error - one of the
performance evaluation metrics in ISO/IEC18305:2016- an international standard
for testing Localization and Tracking Systems. Finally, it presents a
comprehensive comparative study that includes Random Forest, Artificial Neural
Network, Decision Tree, Support Vector Machine, k-NN, Gradient Boosted Trees,
Deep Learning, and Linear Regression, to address the challenge of identifying
the optimal machine learning approach for Indoor Localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Partitioning and Sparse Matrix Ordering using Reinforcement Learning and Graph Neural Networks. (arXiv:2104.03546v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gatti_A/0/1/0/all/0/1">Alice Gatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhixiong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Smidt_T/0/1/0/all/0/1">Tess Smidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_E/0/1/0/all/0/1">Esmond G. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghysels_P/0/1/0/all/0/1">Pieter Ghysels</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03546">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for graph partitioning, based on reinforcement
learning and graph convolutional neural networks. Our approach is to
recursively partition coarser representations of a given graph. The neural
network is implemented using SAGE graph convolution layers, and trained using
an advantage actor critic (A2C) agent. We present two variants, one for finding
an edge separator that minimizes the normalized cut or quotient cut, and one
that finds a small vertex separator. The vertex separators are then used to
construct a nested dissection ordering to permute a sparse matrix so that its
triangular factorization will incur less fill-in. The partitioning quality is
compared with partitions obtained using METIS and SCOTCH, and the nested
dissection ordering is evaluated in the sparse solver SuperLU. Our results show
that the proposed method achieves similar partitioning quality as METIS and
SCOTCH. Furthermore, the method generalizes across different classes of graphs,
and works well on a variety of graphs from the SuiteSparse sparse matrix
collection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Graph Convolution for Resting-State fMRI Analysis. (arXiv:2003.10613v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gadgil_S/0/1/0/all/0/1">Soham Gadgil</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qingyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfefferbaum_A/0/1/0/all/0/1">Adolf Pfefferbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_E/0/1/0/all/0/1">Edith V. Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1">Kilian M. Pohl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.10613">
                                    <div class="article-summary-box-inner">
                                        <span>The Blood-Oxygen-Level-Dependent (BOLD) signal of resting-state fMRI
(rs-fMRI) records the temporal dynamics of intrinsic functional networks in the
brain. However, existing deep learning methods applied to rs-fMRI either
neglect the functional dependency between different brain regions in a network
or discard the information in the temporal dynamics of brain activity. To
overcome those shortcomings, we propose to formulate functional connectivity
networks within the context of spatio-temporal graphs. We train a
spatio-temporal graph convolutional network (ST-GCN) on short sub-sequences of
the BOLD time series to model the non-stationary nature of functional
connectivity. Simultaneously, the model learns the importance of graph edges
within ST-GCN to gain insight into the functional connectivities contributing
to the prediction. In analyzing the rs-fMRI of the Human Connectome Project
(HCP, N&#x3D;1,091) and the National Consortium on Alcohol and Neurodevelopment in
Adolescence (NCANDA, N&#x3D;773), ST-GCN is significantly more accurate than common
approaches in predicting gender and age based on BOLD signals. Furthermore, the
brain regions and functional connections significantly contributing to the
predictions of our model are important markers according to the neuroscience
literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from History for Byzantine Robust Optimization. (arXiv:2012.10333v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10333">
                                    <div class="article-summary-box-inner">
                                        <span>Byzantine robustness has received significant attention recently given its
importance for distributed and federated learning. In spite of this, we
identify severe flaws in existing algorithms even when the data across the
participants is identically distributed. First, we show realistic examples
where current state of the art robust aggregation rules fail to converge even
in the absence of any Byzantine attackers. Secondly, we prove that even if the
aggregation rules may succeed in limiting the influence of the attackers in a
single round, the attackers can couple their attacks across time eventually
leading to divergence. To address these issues, we present two surprisingly
simple strategies: a new robust iterative clipping procedure, and incorporating
worker momentum to overcome time-coupled attacks. This is the first provably
robust method for the standard stochastic optimization setting. Our code is
open sourced at https://github.com/epfml/byzantine-robust-optimizer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near field Acoustic Holography on arbitrary shapes using Convolutional Neural Network. (arXiv:2103.16935v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Olivieri_M/0/1/0/all/0/1">Marco Olivieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pezzoli_M/0/1/0/all/0/1">Mirco Pezzoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Antonacci_F/0/1/0/all/0/1">Fabio Antonacci</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarti_A/0/1/0/all/0/1">Augusto Sarti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16935">
                                    <div class="article-summary-box-inner">
                                        <span>Near-field Acoustic Holography (NAH) is a well-known problem aimed at
estimating the vibrational velocity field of a structure by means of acoustic
measurements. In this paper, we propose a NAH technique based on Convolutional
Neural Network (CNN). The devised CNN predicts the vibrational field on the
surface of arbitrary shaped plates (violin plates) with orthotropic material
properties from a limited number of measurements. In particular, the
architecture, named Super Resolution CNN (SRCNN), is able to estimate the
vibrational field with a higher spatial resolution compared to the input
pressure. The pressure and velocity datasets have been generated through Finite
Element Method simulations. We validate the proposed method by comparing the
estimates with the synthesized ground truth and with a state-of-the-art
technique. Moreover, we evaluate the robustness of the devised network against
noisy input data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poisson CNN: Convolutional neural networks for the solution of the Poisson equation on a Cartesian mesh. (arXiv:1910.08613v3 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Ozbay_A/0/1/0/all/0/1">Ali Girayhan &#xd6;zbay</a>, <a href="http://arxiv.org/find/physics/1/au:+Hamzehloo_A/0/1/0/all/0/1">Arash Hamzehloo</a>, <a href="http://arxiv.org/find/physics/1/au:+Laizet_S/0/1/0/all/0/1">Sylvain Laizet</a>, <a href="http://arxiv.org/find/physics/1/au:+Tzirakis_P/0/1/0/all/0/1">Panagiotis Tzirakis</a>, <a href="http://arxiv.org/find/physics/1/au:+Rizos_G/0/1/0/all/0/1">Georgios Rizos</a>, <a href="http://arxiv.org/find/physics/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn Schuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.08613">
                                    <div class="article-summary-box-inner">
                                        <span>The Poisson equation is commonly encountered in engineering, for instance in
computational fluid dynamics (CFD) where it is needed to compute corrections to
the pressure field to ensure the incompressibility of the velocity field. In
the present work, we propose a novel fully convolutional neural network (CNN)
architecture to infer the solution of the Poisson equation on a 2D Cartesian
grid with different resolutions given the right hand side term, arbitrary
boundary conditions and grid parameters. It provides unprecedented versatility
for a CNN approach dealing with partial differential equations. The boundary
conditions are handled using a novel approach by decomposing the original
Poisson problem into a homogeneous Poisson problem plus four inhomogeneous
Laplace sub-problems. The model is trained using a novel loss function
approximating the continuous $L^p$ norm between the prediction and the target.
Even when predicting on grids denser than previously encountered, our model
demonstrates encouraging capacity to reproduce the correct solution profile.
The proposed model, which outperforms well-known neural network models, can be
included in a CFD solver to help with solving the Poisson equation. Analytical
test cases indicate that our CNN architecture is capable of predicting the
correct solution of a Poisson problem with mean percentage errors below 10%, an
improvement by comparison to the first step of conventional iterative methods.
Predictions from our model, used as the initial guess to iterative algorithms
like Multigrid, can reduce the RMS error after a single iteration by more than
90% compared to a zero initial guess.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Generalization using Causal Matching. (arXiv:2006.07500v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1">Divyat Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1">Shruti Tople</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Amit Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07500">
                                    <div class="article-summary-box-inner">
                                        <span>In the domain generalization literature, a common objective is to learn
representations independent of the domain after conditioning on the class
label. We show that this objective is not sufficient: there exist
counter-examples where a model fails to generalize to unseen domains even after
satisfying class-conditional domain invariance. We formalize this observation
through a structural causal model and show the importance of modeling
within-class variations for generalization. Specifically, classes contain
objects that characterize specific causal features, and domains can be
interpreted as interventions on these objects that change non-causal features.
We highlight an alternative condition: inputs across domains should have the
same representation if they are derived from the same object. Based on this
objective, we propose matching-based algorithms when base objects are observed
(e.g., through data augmentation) and approximate the objective when objects
are not observed (MatchDG). Our simple matching-based algorithms are
competitive to prior work on out-of-domain accuracy for rotated MNIST,
Fashion-MNIST, PACS, and Chest-Xray datasets. Our method MatchDG also recovers
ground-truth object matches: on MNIST and Fashion-MNIST, top-10 matches from
MatchDG have over 50% overlap with ground-truth matches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Chain Rule and Bayes&#x27; Theorem to Compare Probability Distributions. (arXiv:2012.14100v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zheng_H/0/1/0/all/0/1">Huangjie Zheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14100">
                                    <div class="article-summary-box-inner">
                                        <span>To measure the difference between two probability distributions, referred to
as the source and target, respectively, we exploit both the chain rule and
Bayes&#x27; theorem to construct conditional transport (CT), which is constituted by
both a forward component and a backward one. The forward CT is the expected
cost of moving a source data point to a target one, with their joint
distribution defined by the product of the source probability density function
(PDF) and a source-dependent conditional distribution, which is related to the
target PDF via Bayes&#x27; theorem. The backward CT is defined by reversing the
direction. The CT cost can be approximated by replacing the source and target
PDFs with their discrete empirical distributions supported on mini-batches,
making it amenable to implicit distributions and stochastic gradient
descent-based optimization. When applied to train a generative model, CT is
shown to strike a good balance between mode-covering and mode-seeking behaviors
and strongly resist mode collapse. On a wide variety of benchmark datasets for
generative modeling, substituting the default statistical distance of an
existing generative adversarial network with CT is shown to consistently
improve the performance. PyTorch-style code is provided.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Contrastive Learning. (arXiv:2106.15499v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1">Sangmin Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungnyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jongwoo Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gihun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Noh_S/0/1/0/all/0/1">Seungjong Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Se-Young Yun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel contrastive learning framework, coined as
Self-Contrastive (SelfCon) Learning, that self-contrasts within multiple
outputs from the different levels of a network. We confirmed that SelfCon loss
guarantees the lower bound of mutual information (MI) between the intermediate
and last representations. Besides, we empirically showed, via various MI
estimators, that SelfCon loss highly correlates to the increase of MI and
better classification performance. In our experiments, SelfCon surpasses
supervised contrastive (SupCon) learning without the need for a multi-viewed
batch and with the cheaper computational cost. Especially on ResNet-18, we
achieved top-1 classification accuracy of 76.45% for the CIFAR-100 dataset,
which is 2.87% and 4.36% higher than SupCon and cross-entropy loss,
respectively. We found that mitigating both vanishing gradient and overfitting
issue makes our method outperform the counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Size and Depth Separation in Approximating Benign Functions with Neural Networks. (arXiv:2102.00314v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1">Gal Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichman_D/0/1/0/all/0/1">Daniel Reichman</a>, <a href="http://arxiv.org/find/cs/1/au:+Pitassi_T/0/1/0/all/0/1">Toniann Pitassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00314">
                                    <div class="article-summary-box-inner">
                                        <span>When studying the expressive power of neural networks, a main challenge is to
understand how the size and depth of the network affect its ability to
approximate real functions. However, not all functions are interesting from a
practical viewpoint: functions of interest usually have a polynomially-bounded
Lipschitz constant, and can be computed efficiently. We call functions that
satisfy these conditions &quot;benign&quot;, and explore the benefits of size and depth
for approximation of benign functions with ReLU networks. As we show, this
problem is more challenging than the corresponding problem for non-benign
functions. We give barriers to showing depth-lower-bounds: Proving existence of
a benign function that cannot be approximated by polynomial-size networks of
depth $4$ would settle longstanding open problems in computational complexity.
It implies that beyond depth $4$ there is a barrier to showing depth-separation
for benign functions, even between networks of constant depth and networks of
nonconstant depth. We also study size-separation, namely, whether there are
benign functions that can be approximated with networks of size $O(s(d))$, but
not with networks of size $O(s&#x27;(d))$. We show a complexity-theoretic barrier to
proving such results beyond size $O(d\log^2(d))$, but also show an explicit
benign function, that can be approximated with networks of size $O(d)$ and not
with networks of size $o(d/\log d)$. For approximation in $L_\infty$ we achieve
such separation already between size $O(d)$ and size $o(d)$. Moreover, we show
superpolynomial size lower bounds and barriers to such lower bounds, depending
on the assumptions on the function. Our size-separation results rely on an
analysis of size lower bounds for Boolean functions, which is of independent
interest: We show linear size lower bounds for computing explicit Boolean
functions with neural networks and threshold circuits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attack Transferability Characterization for Adversarially Robust Multi-label Classification. (arXiv:2106.15360v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yufei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangliang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15360">
                                    <div class="article-summary-box-inner">
                                        <span>Despite of the pervasive existence of multi-label evasion attack, it is an
open yet essential problem to characterize the origin of the adversarial
vulnerability of a multi-label learning system and assess its attackability. In
this study, we focus on non-targeted evasion attack against multi-label
classifiers. The goal of the threat is to cause miss-classification with
respect to as many labels as possible, with the same input perturbation. Our
work gains in-depth understanding about the multi-label adversarial attack by
first characterizing the transferability of the attack based on the functional
properties of the multi-label classifier. We unveil how the transferability
level of the attack determines the attackability of the classifier via
establishing an information-theoretic analysis of the adversarial risk.
Furthermore, we propose a transferability-centered attackability assessment,
named Soft Attackability Estimator (SAE), to evaluate the intrinsic
vulnerability level of the targeted multi-label classifier. This estimator is
then integrated as a transferability-tuning regularization term into the
multi-label learning paradigm to achieve adversarially robust classification.
The experimental study on real-world data echos the theoretical analysis and
verify the validity of the transferability-regularized multi-label learning
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On exploring practical potentials of quantum auto-encoder with advantages. (arXiv:2106.15432v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1">Yuxuan Du</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15432">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum auto-encoder (QAE) is a powerful tool to relieve the curse of
dimensionality encountered in quantum physics, celebrated by the ability to
extract low-dimensional patterns from quantum states living in the
high-dimensional space. Despite its attractive properties, little is known
about the practical applications of QAE with provable advantages. To address
these issues, here we prove that QAE can be used to efficiently calculate the
eigenvalues and prepare the corresponding eigenvectors of a high-dimensional
quantum state with the low-rank property. With this regard, we devise three
effective QAE-based learning protocols to solve the low-rank state fidelity
estimation, the quantum Gibbs state preparation, and the quantum metrology
tasks, respectively. Notably, all of these protocols are scalable and can be
readily executed on near-term quantum machines. Moreover, we prove that the
error bounds of the proposed QAE-based methods outperform those in previous
literature. Numerical simulations collaborate with our theoretical analysis.
Our work opens a new avenue of utilizing QAE to tackle various quantum physics
and quantum information processing problems in a scalable way.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Dimensionality Reduction for Comparative Analysis. (arXiv:2106.15481v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fujiwara_T/0/1/0/all/0/1">Takanori Fujiwara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xinhai Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kwan-Liu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15481">
                                    <div class="article-summary-box-inner">
                                        <span>Finding the similarities and differences between two or more groups of
datasets is a fundamental analysis task. For high-dimensional data,
dimensionality reduction (DR) methods are often used to find the
characteristics of each group. However, existing DR methods provide limited
capability and flexibility for such comparative analysis as each method is
designed only for a narrow analysis target, such as identifying factors that
most differentiate groups. In this work, we introduce an interactive DR
framework where we integrate our new DR method, called ULCA (unified linear
comparative analysis), with an interactive visual interface. ULCA unifies two
DR schemes, discriminant analysis and contrastive learning, to support various
comparative analysis tasks. To provide flexibility for comparative analysis, we
develop an optimization algorithm that enables analysts to interactively refine
ULCA results. Additionally, we provide an interactive visualization interface
to examine ULCA results with a rich set of analysis libraries. We evaluate ULCA
and the optimization algorithm to show their efficiency as well as present
multiple case studies using real-world datasets to demonstrate the usefulness
of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Gradient Methods for Convex Optimization with General Affine and Nonlinear Constraints. (arXiv:2007.00153v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1">Guanghui Lan</a>, <a href="http://arxiv.org/find/math/1/au:+Romeijn_E/0/1/0/all/0/1">Edwin Romeijn</a>, <a href="http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1">Zhiqiang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00153">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional gradient methods have attracted much attention in both machine
learning and optimization communities recently. These simple methods can
guarantee the generation of sparse solutions. In addition, without the
computation of full gradients, they can handle huge-scale problems sometimes
even with an exponentially increasing number of decision variables. This paper
aims to significantly expand the application areas of these methods by
presenting new conditional gradient methods for solving convex optimization
problems with general affine and nonlinear constraints. More specifically, we
first present a new constraint extrapolated condition gradient (CoexCG) method
that can achieve an ${\cal O}(1/\epsilon^2)$ iteration complexity for both
smooth and structured nonsmooth function constrained convex optimization. We
further develop novel variants of CoexCG, namely constraint extrapolated and
dual regularized conditional gradient (CoexDurCG) methods, that can achieve
similar iteration complexity to CoexCG but allow adaptive selection for
algorithmic parameters. We illustrate the effectiveness of these methods for
solving an important class of radiation therapy treatment planning problems
arising from healthcare industry. To the best of our knowledge, all the
algorithmic schemes and their complexity results are new in the area of
projection-free methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphAnoGAN: Detecting Anomalous Snapshots from Attributed Graphs. (arXiv:2106.15504v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1">Siddharth Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1">Bryan Hooi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1">Tanmoy Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15504">
                                    <div class="article-summary-box-inner">
                                        <span>Finding anomalous snapshots from a graph has garnered huge attention
recently. Existing studies address the problem using shallow learning
mechanisms such as subspace selection, ego-network, or community analysis.
These models do not take into account the multifaceted interactions between the
structure and attributes in the network. In this paper, we propose GraphAnoGAN,
an anomalous snapshot ranking framework, which consists of two core components
-- generative and discriminative models. Specifically, the generative model
learns to approximate the distribution of anomalous samples from the candidate
set of graph snapshots, and the discriminative model detects whether the
sampled snapshot is from the ground-truth or not. Experiments on 4 real-world
networks show that GraphAnoGAN outperforms 6 baselines with a significant
margin (28.29% and 22.01% higher precision and recall, respectively compared to
the best baseline, averaged across all datasets).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Off-Policy with Online Planning. (arXiv:2008.10066v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sikchi_H/0/1/0/all/0/1">Harshit Sikchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wenxuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1">David Held</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10066">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) in low-data and risk-sensitive domains requires
performant and flexible deployment policies that can readily incorporate
constraints during deployment. One such class of policies are the
semi-parametric H-step lookahead policies, which select actions using
trajectory optimization over a dynamics model for a fixed horizon with a
terminal value function. In this work, we investigate a novel instantiation of
H-step lookahead with a learned model and a terminal value function learned by
a model-free off-policy algorithm, named Learning Off-Policy with Online
Planning (LOOP). We provide a theoretical analysis of this method, suggesting a
tradeoff between model errors and value function errors and empirically
demonstrate this tradeoff to be beneficial in deep reinforcement learning.
Furthermore, we identify the &quot;Actor Divergence&quot; issue in this framework and
propose Actor Regularized Control (ARC), a modified trajectory optimization
procedure. We evaluate our method on a set of robotic tasks for Offline and
Online RL and demonstrate improved performance. We also show the flexibility of
LOOP to incorporate safety constraints during deployment with a set of
navigation environments. We demonstrate that LOOP is a desirable framework for
robotics applications based on its strong performance in various important RL
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bytecode-based Approach for Smart Contract Classification. (arXiv:2106.15497v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chaochen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yong Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Doss_R/0/1/0/all/0/1">Robin Ram Mohan Doss</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiangshan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_K/0/1/0/all/0/1">Keshav Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Longxiang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15497">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of blockchain technologies, the number of smart
contracts deployed on blockchain platforms is growing exponentially, which
makes it difficult for users to find desired services by manual screening. The
automatic classification of smart contracts can provide blockchain users with
keyword-based contract searching and helps to manage smart contracts
effectively. Current research on smart contract classification focuses on
Natural Language Processing (NLP) solutions which are based on contract source
code. However, more than 94% of smart contracts are not open-source, so the
application scenarios of NLP methods are very limited. Meanwhile, NLP models
are vulnerable to adversarial attacks. This paper proposes a classification
model based on features from contract bytecode instead of source code to solve
these problems. We also use feature selection and ensemble learning to optimize
the model. Our experimental studies on over 3,300 real-world Ethereum smart
contracts show that our model can classify smart contracts without source code
and has better performance than baseline models. Our model also has good
resistance to adversarial attacks compared with NLP-based models. In addition,
our analysis reveals that account features used in many smart contract
classification models have little effect on classification and can be excluded.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-dimensional separability for one- and few-shot learning. (arXiv:2106.15416v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1">Alexander N. Gorban</a>, <a href="http://arxiv.org/find/cs/1/au:+Grechuk_B/0/1/0/all/0/1">Bogdan Grechuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirkes_E/0/1/0/all/0/1">Evgeny M. Mirkes</a>, <a href="http://arxiv.org/find/cs/1/au:+Stasenko_S/0/1/0/all/0/1">Sergey V. Stasenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1">Ivan Y. Tyukin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15416">
                                    <div class="article-summary-box-inner">
                                        <span>This work is driven by a practical question, corrections of Artificial
Intelligence (AI) errors. Systematic re-training of a large AI system is hardly
possible. To solve this problem, special external devices, correctors, are
developed. They should provide quick and non-iterative system fix without
modification of a legacy AI system. A common universal part of the AI corrector
is a classifier that should separate undesired and erroneous behavior from
normal operation. Training of such classifiers is a grand challenge at the
heart of the one- and few-shot learning methods. Effectiveness of one- and
few-short methods is based on either significant dimensionality reductions or
the blessing of dimensionality effects. Stochastic separability is a blessing
of dimensionality phenomenon that allows one-and few-shot error correction: in
high-dimensional datasets under broad assumptions each point can be separated
from the rest of the set by simple and robust linear discriminant. The
hierarchical structure of data universe is introduced where each data cluster
has a granular internal structure, etc. New stochastic separation theorems for
the data distributions with fine-grained structure are formulated and proved.
Separation theorems in infinite-dimensional limits are proven under assumptions
of compact embedding of patterns into data space. New multi-correctors of AI
systems are presented and illustrated with examples of predicting errors and
learning new classes of objects by a deep convolutional neural network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Convergent and Efficient Deep Q Network Algorithm. (arXiv:2106.15419v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhikang T. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15419">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the empirical success of the deep Q network (DQN) reinforcement
learning algorithm and its variants, DQN is still not well understood and it
does not guarantee convergence. In this work, we show that DQN can diverge and
cease to operate in realistic settings. Although there exist gradient-based
convergent methods, we show that they actually have inherent problems in
learning behaviour and elucidate why they often fail in practice. To overcome
these problems, we propose a convergent DQN algorithm (C-DQN) by carefully
modifying DQN, and we show that the algorithm is convergent and can work with
large discount factors (0.9998). It learns robustly in difficult settings and
can learn several difficult games in the Atari 2600 benchmark where DQN fail,
within a moderate computational budget. Our codes have been publicly released
and can be used to reproduce our results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Mechanism for Producing Aligned Latent Spaces with Autoencoders. (arXiv:2106.15456v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saachi Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Adityanarayanan Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Uhler_C/0/1/0/all/0/1">Caroline Uhler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15456">
                                    <div class="article-summary-box-inner">
                                        <span>Aligned latent spaces, where meaningful semantic shifts in the input space
correspond to a translation in the embedding space, play an important role in
the success of downstream tasks such as unsupervised clustering and data
imputation. In this work, we prove that linear and nonlinear autoencoders
produce aligned latent spaces by stretching along the left singular vectors of
the data. We fully characterize the amount of stretching in linear autoencoders
and provide an initialization scheme to arbitrarily stretch along the top
directions using these networks. We also quantify the amount of stretching in
nonlinear autoencoders in a simplified setting. We use our theoretical results
to align drug signatures across cell types in gene expression space and
semantic shifts in word embedding spaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sounds of COVID-19: exploring realistic performance of audio-based digital testing. (arXiv:2106.15523v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jing Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Spathis_D/0/1/0/all/0/1">Dimitris Spathis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bondareva_E/0/1/0/all/0/1">Erika Bondareva</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_C/0/1/0/all/0/1">Chlo&#xeb; Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_J/0/1/0/all/0/1">Jagmohan Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1">Ting Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Grammenos_A/0/1/0/all/0/1">Andreas Grammenos</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasthanasombat_A/0/1/0/all/0/1">Apinan Hasthanasombat</a>, <a href="http://arxiv.org/find/cs/1/au:+Floto_A/0/1/0/all/0/1">Andres Floto</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicuta_P/0/1/0/all/0/1">Pietro Cicuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1">Cecilia Mascolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15523">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers have been battling with the question of how we can identify
Coronavirus disease (COVID-19) cases efficiently, affordably and at scale.
Recent work has shown how audio based approaches, which collect respiratory
audio data (cough, breathing and voice) can be used for testing, however there
is a lack of exploration of how biases and methodological decisions impact
these tools&#x27; performance in practice. In this paper, we explore the realistic
performance of audio-based digital testing of COVID-19. To investigate this, we
collected a large crowdsourced respiratory audio dataset through a mobile app,
alongside recent COVID-19 test result and symptoms intended as a ground truth.
Within the collected dataset, we selected 5,240 samples from 2,478 participants
and split them into different participant-independent sets for model
development and validation. Among these, we controlled for potential
confounding factors (such as demographics and language). The unbiased model
takes features extracted from breathing, coughs, and voice signals as
predictors and yields an AUC-ROC of 0.71 (95\% CI: 0.65$-$0.77). We further
explore different unbalanced distributions to show how biases and participant
splits affect performance. Finally, we discuss how the realistic model
presented could be integrated in clinical practice to realize continuous,
ubiquitous, sustainable and affordable testing at population scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining the Performance of Multi-label Classification Methods with Data Set Properties. (arXiv:2106.15411v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bogatinovski_J/0/1/0/all/0/1">Jasmin Bogatinovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Todorovski_L/0/1/0/all/0/1">Ljup&#x10d;o Todorovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Dzeroski_S/0/1/0/all/0/1">Sa&#x161;o D&#x17e;eroski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocev_D/0/1/0/all/0/1">Dragi Kocev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15411">
                                    <div class="article-summary-box-inner">
                                        <span>Meta learning generalizes the empirical experience with different learning
tasks and holds promise for providing important empirical insight into the
behaviour of machine learning algorithms. In this paper, we present a
comprehensive meta-learning study of data sets and methods for multi-label
classification (MLC). MLC is a practically relevant machine learning task where
each example is labelled with multiple labels simultaneously. Here, we analyze
40 MLC data sets by using 50 meta features describing different properties of
the data. The main findings of this study are as follows. First, the most
prominent meta features that describe the space of MLC data sets are the ones
assessing different aspects of the label space. Second, the meta models show
that the most important meta features describe the label space, and, the meta
features describing the relationships among the labels tend to occur a bit more
often than the meta features describing the distributions between and within
the individual labels. Third, the optimization of the hyperparameters can
improve the predictive performance, however, quite often the extent of the
improvements does not always justify the resource utilization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Survey of Incentive Mechanism for Federated Learning. (arXiv:2106.15406v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_R/0/1/0/all/0/1">Rongfei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1">Chao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaowen Chu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15406">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning utilizes various resources provided by participants to
collaboratively train a global model, which potentially address the data
privacy issue of machine learning. In such promising paradigm, the performance
will be deteriorated without sufficient training data and other resources in
the learning process. Thus, it is quite crucial to inspire more participants to
contribute their valuable resources with some payments for federated learning.
In this paper, we present a comprehensive survey of incentive schemes for
federate learning. Specifically, we identify the incentive problem in federated
learning and then provide a taxonomy for various schemes. Subsequently, we
summarize the existing incentive mechanisms in terms of the main techniques,
such as Stackelberg game, auction, contract theory, Shapley value,
reinforcement learning, blockchain. By reviewing and comparing some impressive
results, we figure out three directions for the future study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Short-Term Load Forecasting for Smart HomeAppliances with Sequence to Sequence Learning. (arXiv:2106.15348v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Razghandi_M/0/1/0/all/0/1">Mina Razghandi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Erol_Kantarci_M/0/1/0/all/0/1">Melike Erol-Kantarci</a>, <a href="http://arxiv.org/find/eess/1/au:+Turgut_D/0/1/0/all/0/1">Damla Turgut</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15348">
                                    <div class="article-summary-box-inner">
                                        <span>Appliance-level load forecasting plays a critical role in residential energy
management, besides having significant importance for ancillary services
performed by the utilities. In this paper, we propose to use an LSTM-based
sequence-to-sequence (seq2seq) learning model that can capture the load
profiles of appliances. We use a real dataset collected fromfour residential
buildings and compare our proposed schemewith three other techniques, namely
VARMA, Dilated One Dimensional Convolutional Neural Network, and an LSTM
model.The results show that the proposed LSTM-based seq2seq model outperforms
other techniques in terms of prediction error in most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-stage Optimization based Adversarial Training. (arXiv:2106.15357v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaosen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chuanbiao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15357">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of adversarial robustness, there is a common practice that
adopts the single-step adversarial training for quickly developing
adversarially robust models. However, the single-step adversarial training is
most likely to cause catastrophic overfitting, as after a few training epochs
it will be hard to generate strong adversarial examples to continuously boost
the adversarial robustness. In this work, we aim to avoid the catastrophic
overfitting by introducing multi-step adversarial examples during the
single-step adversarial training. Then, to balance the large training overhead
of generating multi-step adversarial examples, we propose a Multi-stage
Optimization based Adversarial Training (MOAT) method that periodically trains
the model on mixed benign examples, single-step adversarial examples, and
multi-step adversarial examples stage by stage. In this way, the overall
training overhead is reduced significantly, meanwhile, the model could avoid
catastrophic overfitting. Extensive experiments on CIFAR-10 and CIFAR-100
datasets demonstrate that under similar amount of training overhead, the
proposed MOAT exhibits better robustness than either single-step or multi-step
adversarial training methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zoo-Tuning: Adaptive Transfer from a Zoo of Models. (arXiv:2106.15434v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1">Yang Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kou_Z/0/1/0/all/0/1">Zhi Kou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhangjie Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianmin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1">Mingsheng Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15434">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of deep networks on various large-scale datasets, a
large zoo of pretrained models are available. When transferring from a model
zoo, applying classic single-model based transfer learning methods to each
source model suffers from high computational burden and cannot fully utilize
the rich knowledge in the zoo. We propose \emph{Zoo-Tuning} to address these
challenges, which learns to adaptively transfer the parameters of pretrained
models to the target task. With the learnable channel alignment layer and
adaptive aggregation layer, Zoo-Tuning \emph{adaptively aggregates channel
aligned pretrained parameters} to derive the target model, which promotes
knowledge transfer by simultaneously adapting multiple source models to
downstream tasks. The adaptive aggregation substantially reduces the
computation cost at both training and inference. We further propose lite
Zoo-Tuning with the temporal ensemble of batch average gating values to reduce
the storage cost at the inference time. We evaluate our approach on a variety
of tasks, including reinforcement learning, image classification, and facial
landmark detection. Experiment results demonstrate that the proposed adaptive
transfer learning approach can transfer knowledge from a zoo of models more
effectively and efficiently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple Graph Learning for Scalable Multi-view Clustering. (arXiv:2106.15382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tianyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Quanxue Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15382">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based multi-view clustering has become an active topic due to the
efficiency in characterizing both the complex structure and relationship
between multimedia data. However, existing methods have the following
shortcomings: (1) They are inefficient or even fail for graph learning in large
scale due to the graph construction and eigen-decomposition. (2) They cannot
well exploit both the complementary information and spatial structure embedded
in graphs of different views. To well exploit complementary information and
tackle the scalability issue plaguing graph-based multi-view clustering, we
propose an efficient multiple graph learning model via a small number of anchor
points and tensor Schatten p-norm minimization. Specifically, we construct a
hidden and tractable large graph by anchor graph for each view and well exploit
complementary information embedded in anchor graphs of different views by
tensor Schatten p-norm regularizer. Finally, we develop an efficient algorithm,
which scales linearly with the data size, to solve our proposed model.
Extensive experimental results on several datasets indicate that our proposed
method outperforms some state-of-the-art multi-view clustering algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Interaction Detection for Click-Through Rate Prediction. (arXiv:2106.15400v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qiuqiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chuanhou Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15400">
                                    <div class="article-summary-box-inner">
                                        <span>Click-Through Rate prediction aims to predict the ratio of clicks to
impressions of a specific link. This is a challenging task since (1) there are
usually categorical features, and the inputs will be extremely high-dimensional
if one-hot encoding is applied, (2) not only the original features but also
their interactions are important, (3) an effective prediction may rely on
different features and interactions in different time periods. To overcome
these difficulties, we propose a new interaction detection method, named Online
Random Intersection Chains. The method, which is based on the idea of frequent
itemset mining, detects informative interactions by observing the intersections
of randomly chosen samples. The discovered interactions enjoy high
interpretability as they can be comprehended as logical expressions. ORIC can
be updated every time new data is collected, without being retrained on
historical data. What&#x27;s more, the importance of the historical and latest data
can be controlled by a tuning parameter. A framework is designed to deal with
the streaming interactions, so almost all existing models for CTR prediction
can be applied after interaction detection. Empirical results demonstrate the
efficiency and effectiveness of ORIC on three benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Federated Learning with Gaussian Processes. (arXiv:2106.15482v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1">Idan Achituve</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsian_A/0/1/0/all/0/1">Aviv Shamsian</a>, <a href="http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1">Aviv Navon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1">Ethan Fetaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15482">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning aims to learn a global model that performs well on client
devices with limited cross-client communication. Personalized federated
learning (PFL) further extends this setup to handle data heterogeneity between
clients by learning personalized models. A key challenge in this setting is to
learn effectively across clients even though each client has unique data that
is often limited in size. Here we present pFedGP, a solution to PFL that is
based on Gaussian processes (GPs) with deep kernel learning. GPs are highly
expressive models that work well in the low data regime due to their Bayesian
nature. However, applying GPs to PFL raises multiple challenges. Mainly, GPs
performance depends heavily on access to a good kernel function, and learning a
kernel requires a large training set. Therefore, we propose learning a shared
kernel function across all clients, parameterized by a neural network, with a
personal GP classifier for each client. We further extend pFedGP to include
inducing points using two novel methods, the first helps to improve
generalization in the low data regime and the second reduces the computational
cost. We derive a PAC-Bayes generalization bound on novel clients and
empirically show that it gives non-vacuous guarantees. Extensive experiments on
standard PFL benchmarks with CIFAR-10, CIFAR-100, and CINIC-10, and on a new
setup of learning under input noise show that pFedGP achieves well-calibrated
predictions while significantly outperforming baseline methods, reaching up to
21% in accuracy gain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attentive Neural Processes and Batch Bayesian Optimization for Scalable Calibration of Physics-Informed Digital Twins. (arXiv:2106.15502v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_A/0/1/0/all/0/1">Ankush Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Wichern_G/0/1/0/all/0/1">Gordon Wichern</a>, <a href="http://arxiv.org/find/cs/1/au:+Laughman_C/0/1/0/all/0/1">Christopher Laughman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15502">
                                    <div class="article-summary-box-inner">
                                        <span>Physics-informed dynamical system models form critical components of digital
twins of the built environment. These digital twins enable the design of
energy-efficient infrastructure, but must be properly calibrated to accurately
reflect system behavior for downstream prediction and analysis. Dynamical
system models of modern buildings are typically described by a large number of
parameters and incur significant computational expenditure during simulations.
To handle large-scale calibration of digital twins without exorbitant
simulations, we propose ANP-BBO: a scalable and parallelizable batch-wise
Bayesian optimization (BBO) methodology that leverages attentive neural
processes (ANPs).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections. (arXiv:2106.15427v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nadjahi_K/0/1/0/all/0/1">Kimia Nadjahi</a>, <a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/stat/1/au:+Jacob_P/0/1/0/all/0/1">Pierre E. Jacob</a>, <a href="http://arxiv.org/find/stat/1/au:+Badeau_R/0/1/0/all/0/1">Roland Badeau</a>, <a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15427">
                                    <div class="article-summary-box-inner">
                                        <span>The Sliced-Wasserstein distance (SW) is being increasingly used in machine
learning applications as an alternative to the Wasserstein distance and offers
significant computational and statistical benefits. Since it is defined as an
expectation over random projections, SW is commonly approximated by Monte
Carlo. We adopt a new perspective to approximate SW by making use of the
concentration of measure phenomenon: under mild assumptions, one-dimensional
projections of a high-dimensional random vector are approximately Gaussian.
Based on this observation, we develop a simple deterministic approximation for
SW. Our method does not require sampling a number of random projections, and is
therefore both accurate and easy to use compared to the usual Monte Carlo
approximation. We derive nonasymptotical guarantees for our approach, and show
that the approximation error goes to zero as the dimension increases, under a
weak dependence condition on the data distribution. We validate our theoretical
findings on synthetic datasets, and illustrate the proposed approximation on a
generative modeling problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Task Informed Abstraction. (arXiv:2106.15612v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xiang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Ge Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1">Tommi Jaakkola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15612">
                                    <div class="article-summary-box-inner">
                                        <span>Current model-based reinforcement learning methods struggle when operating
from complex visual scenes due to their inability to prioritize task-relevant
features. To mitigate this problem, we propose learning Task Informed
Abstractions (TIA) that explicitly separates reward-correlated visual features
from distractors. For learning TIA, we introduce the formalism of Task Informed
MDP (TiMDP) that is realized by training two models that learn visual features
via cooperative reconstruction, but one model is adversarially dissociated from
the reward signal. Empirical evaluation shows that TIA leads to significant
performance gains over state-of-the-art methods on many visual control tasks
where natural and unconstrained visual distractions pose a formidable
challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Framework for an Intelligent Affect Aware Smart Home Environment for Elderly People. (arXiv:2106.15599v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chia Y. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15599">
                                    <div class="article-summary-box-inner">
                                        <span>The population of elderly people has been increasing at a rapid rate over the
last few decades and their population is expected to further increase in the
upcoming future. Their increasing population is associated with their
increasing needs due to problems like physical disabilities, cognitive issues,
weakened memory and disorganized behavior, that elderly people face with
increasing age. To reduce their financial burden on the world economy and to
enhance their quality of life, it is essential to develop technology-based
solutions that are adaptive, assistive and intelligent in nature. Intelligent
Affect Aware Systems that can not only analyze but also predict the behavior of
elderly people in the context of their day to day interactions with technology
in an IoT-based environment, holds immense potential for serving as a long-term
solution for improving the user experience of elderly in smart homes. This work
therefore proposes the framework for an Intelligent Affect Aware environment
for elderly people that can not only analyze the affective components of their
interactions but also predict their likely user experience even before they
start engaging in any activity in the given smart home environment. This
forecasting of user experience would provide scope for enhancing the same,
thereby increasing the assistive and adaptive nature of such intelligent
systems. To uphold the efficacy of this proposed framework for improving the
quality of life of elderly people in smart homes, it has been tested on three
datasets and the results are presented and discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Limited depth bandit-based strategy for Monte Carlo planning in continuous action spaces. (arXiv:2106.15594v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Quinteiro_R/0/1/0/all/0/1">Ricardo Quinteiro</a>, <a href="http://arxiv.org/find/math/1/au:+Melo_F/0/1/0/all/0/1">Francisco S. Melo</a>, <a href="http://arxiv.org/find/math/1/au:+Santos_P/0/1/0/all/0/1">Pedro A. Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15594">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of optimal control using search trees. We
start by considering multi-armed bandit problems with continuous action spaces
and propose LD-HOO, a limited depth variant of the hierarchical optimistic
optimization (HOO) algorithm. We provide a regret analysis for LD-HOO and show
that, asymptotically, our algorithm exhibits the same cumulative regret as the
original HOO while being faster and more memory efficient. We then propose a
Monte Carlo tree search algorithm based on LD-HOO for optimal control problems
and illustrate the resulting approach&#x27;s application in several optimal control
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Span-based Joint Entity and Relation Extraction with Transformer Pre-training. (arXiv:1909.07755v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eberts_M/0/1/0/all/0/1">Markus Eberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulges_A/0/1/0/all/0/1">Adrian Ulges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.07755">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce SpERT, an attention model for span-based joint entity and
relation extraction. Our key contribution is a light-weight reasoning on BERT
embeddings, which features entity recognition and filtering, as well as
relation classification with a localized, marker-free context representation.
The model is trained using strong within-sentence negative samples, which are
efficiently extracted in a single BERT pass. These aspects facilitate a search
over all spans in the sentence.

In ablation studies, we demonstrate the benefits of pre-training, strong
negative sampling and localized context. Our model outperforms prior work by up
to 2.6% F1 score on several datasets for joint entity and relation extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Latent Process Flows. (arXiv:2106.15580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1">Ruizhi Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Brubaker_M/0/1/0/all/0/1">Marcus A. Brubaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mori_G/0/1/0/all/0/1">Greg Mori</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehrmann_A/0/1/0/all/0/1">Andreas M. Lehrmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15580">
                                    <div class="article-summary-box-inner">
                                        <span>Partial observations of continuous time-series dynamics at arbitrary time
stamps exist in many disciplines. Fitting this type of data using statistical
models with continuous dynamics is not only promising at an intuitive level but
also has practical benefits, including the ability to generate continuous
trajectories and to perform inference on previously unseen time stamps. Despite
exciting progress in this area, the existing models still face challenges in
terms of their representational power and the quality of their variational
approximations. We tackle these challenges with continuous latent process flows
(CLPF), a principled architecture decoding continuous latent processes into
continuous observable processes using a time-dependent normalizing flow driven
by a stochastic differential equation. To optimize our model using maximum
likelihood, we propose a novel piecewise construction of a variational
posterior process and derive the corresponding variational lower bound using
trajectory re-weighting. Our ablation studies demonstrate the effectiveness of
our contributions in various inference tasks on irregular time grids.
Comparisons to state-of-the-art baselines show our model&#x27;s favourable
performance on both synthetic and real-world time-series data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Graph Neural Network Ensembles for Large-Scale Molecular Property Prediction. (arXiv:2106.15529v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kosasih_E/0/1/0/all/0/1">Edward Elson Kosasih</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabezas_J/0/1/0/all/0/1">Joaquin Cabezas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sumba_X/0/1/0/all/0/1">Xavier Sumba</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielak_P/0/1/0/all/0/1">Piotr Bielak</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagowski_K/0/1/0/all/0/1">Kamil Tagowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Idanwekhai_K/0/1/0/all/0/1">Kelvin Idanwekhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tjandra_B/0/1/0/all/0/1">Benedict Aaron Tjandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamasb_A/0/1/0/all/0/1">Arian Rokkum Jamasb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15529">
                                    <div class="article-summary-box-inner">
                                        <span>In order to advance large-scale graph machine learning, the Open Graph
Benchmark Large Scale Challenge (OGB-LSC) was proposed at the KDD Cup 2021. The
PCQM4M-LSC dataset defines a molecular HOMO-LUMO property prediction task on
about 3.8M graphs. In this short paper, we show our current work-in-progress
solution which builds an ensemble of three graph neural networks models based
on GIN, Bayesian Neural Networks and DiffPool. Our approach outperforms the
provided baseline by 7.6%. Moreover, using uncertainty in our ensemble&#x27;s
prediction, we can identify molecules whose HOMO-LUMO gaps are harder to
predict (with Pearson&#x27;s correlation of 0.5181). We anticipate that this will
facilitate active learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Mixed-Supervision Multilevel GAN Framework for Image Quality Enhancement. (arXiv:2106.15575v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Upadhyay_U/0/1/0/all/0/1">Uddeshya Upadhyay</a>, <a href="http://arxiv.org/find/eess/1/au:+Awate_S/0/1/0/all/0/1">Suyash Awate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15575">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks for image quality enhancement typically need large
quantities of highly-curated training data comprising pairs of low-quality
images and their corresponding high-quality images. While high-quality image
acquisition is typically expensive and time-consuming, medium-quality images
are faster to acquire, at lower equipment costs, and available in larger
quantities. Thus, we propose a novel generative adversarial network (GAN) that
can leverage training data at multiple levels of quality (e.g., high and medium
quality) to improve performance while limiting costs of data curation. We apply
our mixed-supervision GAN to (i) super-resolve histopathology images and (ii)
enhance laparoscopy images by combining super-resolution and surgical smoke
removal. Results on large clinical and pre-clinical datasets show the benefits
of our mixed-supervision GAN over the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry-aware Transformer for molecular property prediction. (arXiv:2106.15516v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwak_B/0/1/0/all/0/1">Bumju Kwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1">Jeonghee Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Byunghan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15516">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, graph neural networks (GNNs) have achieved remarkable performances
for quantum mechanical problems. However, a graph convolution can only cover a
localized region, and cannot capture long-range interactions of atoms. This
behavior is contrary to theoretical interatomic potentials, which is a
fundamental limitation of the spatial based GNNs. In this work, we propose a
novel attention-based framework for molecular property prediction tasks. We
represent a molecular conformation as a discrete atomic sequence combined by
atom-atom distance attributes, named Geometry-aware Transformer (GeoT). In
particular, we adopt a Transformer architecture, which has been widely used for
sequential data. Our proposed model trains sequential representations of
molecular graphs based on globally constructed attentions, maintaining all
spatial arrangements of atom pairs. Our method does not suffer from cost
intensive computations, such as angle calculations. The experimental results on
several public benchmarks and visualization maps verified that keeping the
long-range interatomic attributes can significantly improve the model
predictability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subgroup Generalization and Fairness of Graph Neural Networks. (arXiv:2106.15535v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiaqi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Junwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15535">
                                    <div class="article-summary-box-inner">
                                        <span>Despite enormous successful applications of graph neural networks (GNNs)
recently, theoretical understandings of their generalization ability,
especially for node-level tasks where data are not independent and
identically-distributed (IID), have been sparse. The theoretical investigation
of the generalization performance is beneficial for understanding fundamental
issues (such as fairness) of GNN models and designing better learning methods.
In this paper, we present a novel PAC-Bayesian analysis for GNNs under a
non-IID semi-supervised learning setup. Moreover, we analyze the generalization
performances on different subgroups of unlabeled nodes, which allows us to
further study an accuracy-(dis)parity-style (un)fairness of GNNs from a
theoretical perspective. Under reasonable assumptions, we demonstrate that the
distance between a test subgroup and the training set can be a key factor
affecting the GNN performance on that subgroup, which calls special attention
to the training node selection for fair learning. Experiments across multiple
GNN models and datasets support our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Cattle and Elk in the Wild from Space. (arXiv:2106.15448v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robinson_C/0/1/0/all/0/1">Caleb Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1">Anthony Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughey_L/0/1/0/all/0/1">Lacey Hughey</a>, <a href="http://arxiv.org/find/cs/1/au:+Stabach_J/0/1/0/all/0/1">Jared A. Stabach</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan M. Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15448">
                                    <div class="article-summary-box-inner">
                                        <span>Localizing and counting large ungulates -- hoofed mammals like cows and elk
-- in very high-resolution satellite imagery is an important task for
supporting ecological studies. Prior work has shown that this is feasible with
deep learning based methods and sub-meter multi-spectral satellite imagery. We
extend this line of work by proposing a baseline method, CowNet, that
simultaneously estimates the number of animals in an image (counts), as well as
predicts their location at a pixel level (localizes). We also propose an
methodology for evaluating such models on counting and localization tasks
across large scenes that takes the uncertainty of noisy labels and the
information needed by stakeholders in ecological monitoring tasks into account.
Finally, we benchmark our baseline method with state of the art vision methods
for counting objects in scenes. We specifically test the temporal
generalization of the resulting models over a large landscape in Point Reyes
Seashore, CA. We find that the LC-FCN model performs the best and achieves an
average precision between 0.56 and 0.61 and an average recall between 0.78 and
0.92 over three held out test scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning latent causal graphs via mixture oracles. (arXiv:2106.15563v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kivva_B/0/1/0/all/0/1">Bohdan Kivva</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajendran_G/0/1/0/all/0/1">Goutham Rajendran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Aragam_B/0/1/0/all/0/1">Bryon Aragam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15563">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of reconstructing a causal graphical model from data in
the presence of latent variables. The main problem of interest is recovering
the causal structure over the latent variables while allowing for general,
potentially nonlinear dependence between the variables. In many practical
problems, the dependence between raw observations (e.g. pixels in an image) is
much less relevant than the dependence between certain high-level, latent
features (e.g. concepts or objects), and this is the setting of interest. We
provide conditions under which both the latent representations and the
underlying latent causal model are identifiable by a reduction to a mixture
oracle. The proof is constructive, and leads to several algorithms for
explicitly reconstructing the full graphical model. We discuss efficient
algorithms and provide experiments illustrating the algorithms in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Evolutionary Approach for the Design of Composite Machine Learning Pipelines. (arXiv:2106.15397v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikitin_N/0/1/0/all/0/1">Nikolay O. Nikitin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vychuzhanin_P/0/1/0/all/0/1">Pavel Vychuzhanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarafanov_M/0/1/0/all/0/1">Mikhail Sarafanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Polonskaia_I/0/1/0/all/0/1">Iana S. Polonskaia</a>, <a href="http://arxiv.org/find/cs/1/au:+Revin_I/0/1/0/all/0/1">Ilia Revin</a>, <a href="http://arxiv.org/find/cs/1/au:+Barabanova_I/0/1/0/all/0/1">Irina V. Barabanova</a>, <a href="http://arxiv.org/find/cs/1/au:+Maximov_G/0/1/0/all/0/1">Gleb Maximov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalyuzhnaya_A/0/1/0/all/0/1">Anna V. Kalyuzhnaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhanovsky_A/0/1/0/all/0/1">Alexander Boukhanovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15397">
                                    <div class="article-summary-box-inner">
                                        <span>The effectiveness of the machine learning methods for real-world tasks
depends on the proper structure of the modeling pipeline. The proposed approach
is aimed to automate the design of composite machine learning pipelines, which
is equivalent to computation workflows that consist of models and data
operations. The approach combines key ideas of both automated machine learning
and workflow management systems. It designs the pipelines with a customizable
graph-based structure, analyzes the obtained results, and reproduces them. The
evolutionary approach is used for the flexible identification of pipeline
structure. The additional algorithms for sensitivity analysis, atomization, and
hyperparameter tuning are implemented to improve the effectiveness of the
approach. Also, the software implementation on this approach is presented as an
open-source framework. The set of experiments is conducted for the different
datasets and tasks (classification, regression, time series forecasting). The
obtained results confirm the correctness and effectiveness of the proposed
approach in the comparison with the state-of-the-art competitors and baseline
solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Realistic Data Generation Framework leveraging Deep Learning-based Human Digitization. (arXiv:2106.15409v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Symeonidis_C/0/1/0/all/0/1">C. Symeonidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nousi_P/0/1/0/all/0/1">P. Nousi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tosidis_P/0/1/0/all/0/1">P. Tosidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsampazis_K/0/1/0/all/0/1">K. Tsampazis</a>, <a href="http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1">N. Passalis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1">A. Tefas</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolaidis_N/0/1/0/all/0/1">N. Nikolaidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15409">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of supervised deep learning algorithms depends significantly
on the scale, quality and diversity of the data used for their training.
Collecting and manually annotating large amount of data can be both
time-consuming and costly tasks to perform. In the case of tasks related to
visual human-centric perception, the collection and distribution of such data
may also face restrictions due to legislation regarding privacy. In addition,
the design and testing of complex systems, e.g., robots, which often employ
deep learning-based perception models, may face severe difficulties as even
state-of-the-art methods trained on real and large-scale datasets cannot always
perform adequately as they have not adapted to the visual differences between
the virtual and the real world data. As an attempt to tackle and mitigate the
effect of these issues, we present a method that automatically generates
realistic synthetic data with annotations for a) person detection, b) face
recognition, and c) human pose estimation. The proposed method takes as input
real background images and populates them with human figures in various poses.
Instead of using hand-made 3D human models, we propose the use of models
generated through deep learning methods, further reducing the dataset creation
costs, while maintaining a high level of realism. In addition, we provide
open-source and easy to use tools that implement the proposed pipeline,
allowing for generating highly-realistic synthetic datasets for a variety of
tasks. A benchmarking and evaluation in the corresponding tasks shows that
synthetic data can be effectively used as a supplement to real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Batch Constrained Bayesian Optimization Approach for Analog Circuit Synthesis via Multi-objective Acquisition Ensemble. (arXiv:2106.15412v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Changhao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xuan Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15412">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization is a promising methodology for analog circuit
synthesis. However, the sequential nature of the Bayesian optimization
framework significantly limits its ability to fully utilize real-world
computational resources. In this paper, we propose an efficient parallelizable
Bayesian optimization algorithm via Multi-objective ACquisition function
Ensemble (MACE) to further accelerate the optimization procedure. By sampling
query points from the Pareto front of the probability of improvement (PI),
expected improvement (EI) and lower confidence bound (LCB), we combine the
benefits of state-of-the-art acquisition functions to achieve a delicate
tradeoff between exploration and exploitation for the unconstrained
optimization problem. Based on this batch design, we further adjust the
algorithm for the constrained optimization problem. By dividing the
optimization procedure into two stages and first focusing on finding an initial
feasible point, we manage to gain more information about the valid region and
can better avoid sampling around the infeasible area. After achieving the first
feasible point, we favor the feasible region by adopting a specially designed
penalization term to the acquisition function ensemble. The experimental
results quantitatively demonstrate that our proposed algorithm can reduce the
overall simulation time by up to 74 times compared to differential evolution
(DE) for the unconstrained optimization problem when the batch size is 15. For
the constrained optimization problem, our proposed algorithm can speed up the
optimization process by up to 15 times compared to the weighted expected
improvement based Bayesian optimization (WEIBO) approach, when the batch size
is 15.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAML is a Noisy Contrastive Learner. (arXiv:2106.15367v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kao_C/0/1/0/all/0/1">Chia-Hsiang Kao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1">Wei-Chen Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15367">
                                    <div class="article-summary-box-inner">
                                        <span>Model-agnostic meta-learning (MAML) is one of the most popular and
widely-adopted meta-learning algorithms nowadays, which achieves remarkable
success in various learning problems. Yet, with the unique design of nested
inner-loop and outer-loop updates which respectively govern the task-specific
and meta-model-centric learning, the underlying learning objective of MAML
still remains implicit and thus impedes a more straightforward understanding of
it. In this paper, we provide a new perspective to the working mechanism of
MAML and discover that: MAML is analogous to a meta-learner using a supervised
contrastive objective function, where the query features are pulled towards the
support features of the same class and against those of different classes, in
which such contrastiveness is experimentally verified via an analysis based on
the cosine similarity. Moreover, our analysis reveals that the vanilla MAML
algorithm has an undesirable interference term originating from the random
initialization and the cross-task interaction. We therefore propose a simple
but effective technique, zeroing trick, to alleviate such interference, where
the extensive experiments are then conducted on both miniImagenet and Omniglot
datasets to demonstrate the consistent improvement brought by our proposed
technique thus well validating its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curious Explorer: a provable exploration strategy in Policy Learning. (arXiv:2106.15503v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miani_M/0/1/0/all/0/1">Marco Miani</a>, <a href="http://arxiv.org/find/cs/1/au:+Parton_M/0/1/0/all/0/1">Maurizio Parton</a>, <a href="http://arxiv.org/find/cs/1/au:+Romito_M/0/1/0/all/0/1">Marco Romito</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15503">
                                    <div class="article-summary-box-inner">
                                        <span>Having access to an exploring restart distribution (the so-called wide
coverage assumption) is critical with policy gradient methods. This is due to
the fact that, while the objective function is insensitive to updates in
unlikely states, the agent may still need improvements in those states in order
to reach a nearly optimal payoff. For this reason, wide coverage is used in
some form when analyzing theoretical properties of practical policy gradient
methods. However, this assumption can be unfeasible in certain environments,
for instance when learning is online, or when restarts are possible only from a
fixed initial state. In these cases, classical policy gradient algorithms can
have very poor convergence properties and sample efficiency. In this paper, we
develop Curious Explorer, a novel and simple iterative state space exploration
strategy that can be used with any starting distribution $\rho$. Curious
Explorer starts from $\rho$, then using intrinsic rewards assigned to the set
of poorly visited states produces a sequence of policies, each one more
exploratory than the previous one in an informed way, and finally outputs a
restart model $\mu$ based on the state visitation distribution of the
exploratory policies. Curious Explorer is provable, in the sense that we
provide theoretical upper bounds on how often an optimal policy visits poorly
visited states. These bounds can be used to prove PAC convergence and sample
efficiency results when a PAC optimizer is plugged in Curious Explorer. This
allows to achieve global convergence and sample efficiency results without any
coverage assumption for REINFORCE, and potentially for any other policy
gradient method ensuring PAC convergence with wide coverage. Finally, we plug
(the output of) Curious Explorer into REINFORCE and TRPO, and show empirically
that it can improve performance in MDPs with challenging exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Globally Optimal Hierarchical Reinforcement Learning for Linearly-Solvable Markov Decision Processes. (arXiv:2106.15380v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Infante_G/0/1/0/all/0/1">Guillermo Infante</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonsso_A/0/1/0/all/0/1">Anders Jonsso</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_V/0/1/0/all/0/1">Vicen&#xe7; G&#xf3;mez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15380">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a novel approach to hierarchical reinforcement
learning for linearly-solvable Markov decision processes. Our approach assumes
that the state space is partitioned, and the subtasks consist in moving between
the partitions. We represent value functions on several levels of abstraction,
and use the compositionality of subtasks to estimate the optimal values of the
states in each partition. The policy is implicitly defined on these optimal
value estimates, rather than being decomposed among the subtasks. As a
consequence, our approach can learn the globally optimal policy, and does not
suffer from the non-stationarity of high-level decisions. If several partitions
have equivalent dynamics, the subtasks of those partitions can be shared. If
the set of boundary states is smaller than the entire state space, our approach
can have significantly smaller sample complexity than that of a flat learner,
and we validate this empirically in several experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SE-MD: A Single-encoder multiple-decoder deep network for point cloud generation from 2D images. (arXiv:2106.15325v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hafiz_A/0/1/0/all/0/1">Abdul Mueed Hafiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1">Rouf Ul Alam Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Parah_S/0/1/0/all/0/1">Shabir Ahmad Parah</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassaballah_M/0/1/0/all/0/1">M. Hassaballah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15325">
                                    <div class="article-summary-box-inner">
                                        <span>3D model generation from single 2D RGB images is a challenging and actively
researched computer vision task. Various techniques using conventional network
architectures have been proposed for the same. However, the body of research
work is limited and there are various issues like using inefficient 3D
representation formats, weak 3D model generation backbones, inability to
generate dense point clouds, dependence of post-processing for generation of
dense point clouds, and dependence on silhouettes in RGB images. In this paper,
a novel 2D RGB image to point cloud conversion technique is proposed, which
improves the state of art in the field due to its efficient, robust and simple
model by using the concept of parallelization in network architecture. It not
only uses the efficient and rich 3D representation of point clouds, but also
uses a novel and robust point cloud generation backbone in order to address the
prevalent issues. This involves using a single-encoder multiple-decoder deep
network architecture wherein each decoder generates certain fixed viewpoints.
This is followed by fusing all the viewpoints to generate a dense point cloud.
Various experiments are conducted on the technique and its performance is
compared with those of other state of the art techniques and impressive gains
in performance are demonstrated. Code is available at
https://github.com/mueedhafiz1982/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Gaussian Processes for Data-Driven Design using Big Data with Categorical Factors. (arXiv:2106.15356v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_A/0/1/0/all/0/1">Akshay Iyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yerramilli_S/0/1/0/all/0/1">Suraj Yerramilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Apley_D/0/1/0/all/0/1">Daniel Apley</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Ping Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15356">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific and engineering problems often require the use of artificial
intelligence to aid understanding and the search for promising designs. While
Gaussian processes (GP) stand out as easy-to-use and interpretable learners,
they have difficulties in accommodating big datasets, categorical inputs, and
multiple responses, which has become a common challenge for a growing number of
data-driven design applications. In this paper, we propose a GP model that
utilizes latent variables and functions obtained through variational inference
to address the aforementioned challenges simultaneously. The method is built
upon the latent variable Gaussian process (LVGP) model where categorical
factors are mapped into a continuous latent space to enable GP modeling of
mixed-variable datasets. By extending variational inference to LVGP models, the
large training dataset is replaced by a small set of inducing points to address
the scalability issue. Output response vectors are represented by a linear
combination of independent latent functions, forming a flexible kernel
structure to handle multiple responses that might have distinct behaviors.
Comparative studies demonstrate that the proposed method scales well for large
datasets with over 10^4 data points, while outperforming state-of-the-art
machine learning methods without requiring much hyperparameter tuning. In
addition, an interpretable latent space is obtained to draw insights into the
effect of categorical factors, such as those associated with building blocks of
architectures and element choices in metamaterial and materials design. Our
approach is demonstrated for machine learning of ternary oxide materials and
topology optimization of a multiscale compliant mechanism with aperiodic
microstructures and multiple materials.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differential Privacy for Credit Risk Model. (arXiv:2106.15343v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maniar_T/0/1/0/all/0/1">Tabish Maniar</a>, <a href="http://arxiv.org/find/cs/1/au:+Akkinepally_A/0/1/0/all/0/1">Alekhya Akkinepally</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anantha Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15343">
                                    <div class="article-summary-box-inner">
                                        <span>The use of machine learning algorithms to model user behavior and drive
business decisions has become increasingly commonplace, specifically providing
intelligent recommendations to automated decision making. This has led to an
increase in the use of customers personal data to analyze customer behavior and
predict their interests in a companys products. Increased use of this customer
personal data can lead to better models but also to the potential of customer
data being leaked, reverse engineered, and mishandled. In this paper, we assess
differential privacy as a solution to address these privacy problems by
building privacy protections into the data engineering and model training
stages of predictive model development. Our interest is a pragmatic
implementation in an operational environment, which necessitates a general
purpose differentially private modeling framework, and we evaluate one such
tool from LeapYear as applied to the Credit Risk modeling domain. Credit Risk
Model is a major modeling methodology in banking and finance where user data is
analyzed to determine the total Expected Loss to the bank. We examine the
application of differential privacy on the credit risk model and evaluate the
performance of a Differentially Private Model with a Non Differentially Private
Model. Credit Risk Model is a major modeling methodology in banking and finance
where users data is analyzed to determine the total Expected Loss to the bank.
In this paper, we explore the application of differential privacy on the credit
risk model and evaluate the performance of a Non Differentially Private Model
with Differentially Private Model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Learning of Portrait Intrinsic Decomposition and Relighting. (arXiv:2106.15305v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zehni_M/0/1/0/all/0/1">Mona Zehni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Shaona Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridhar_K/0/1/0/all/0/1">Krishna Sridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_S/0/1/0/all/0/1">Sethu Raman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15305">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse rendering is the problem of decomposing an image into its intrinsic
components, i.e. albedo, normal and lighting. To solve this ill-posed problem
from single image, state-of-the-art methods in shape from shading mostly resort
to supervised training on all the components on either synthetic or real
datasets. Here, we propose a new self-supervised training paradigm that 1)
reduces the need for full supervision on the decomposition task and 2) takes
into account the relighting task. We introduce new self-supervised loss terms
that leverage the consistencies between multi-lit images (images of the same
scene under different illuminations). Our approach is applicable to multi-lit
datasets. We apply our training approach in two settings: 1) train on a mixture
of synthetic and real data, 2) train on real datasets with limited supervision.
We show-case the effectiveness of our training paradigm on both intrinsic
decomposition and relighting and demonstrate how the model struggles in both
tasks without the self-supervised loss terms in limited supervision settings.
We provide results of comprehensive experiments on SfSNet, CelebA and Photoface
datasets and verify the performance of our approach on images in the wild.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpreadsheetCoder: Formula Prediction from Semi-structured Context. (arXiv:2106.15339v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Maniatis_P/0/1/0/all/0/1">Petros Maniatis</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rishabh Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1">Charles Sutton</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hanjun Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Max Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Denny Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15339">
                                    <div class="article-summary-box-inner">
                                        <span>Spreadsheet formula prediction has been an important program synthesis
problem with many real-world applications. Previous works typically utilize
input-output examples as the specification for spreadsheet formula synthesis,
where each input-output pair simulates a separate row in the spreadsheet.
However, this formulation does not fully capture the rich context in real-world
spreadsheets. First, spreadsheet data entries are organized as tables, thus
rows and columns are not necessarily independent from each other. In addition,
many spreadsheet tables include headers, which provide high-level descriptions
of the cell data. However, previous synthesis approaches do not consider
headers as part of the specification. In this work, we present the first
approach for synthesizing spreadsheet formulas from tabular context, which
includes both headers and semi-structured tabular data. In particular, we
propose SpreadsheetCoder, a BERT-based model architecture to represent the
tabular context in both row-based and column-based formats. We train our model
on a large dataset of spreadsheets, and demonstrate that SpreadsheetCoder
achieves top-1 prediction accuracy of 42.51%, which is a considerable
improvement over baselines that do not employ rich tabular context. Compared to
the rule-based system, SpreadsheetCoder assists 82% more users in composing
formulas on Google Sheets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning complex dependency structure of gene regulatory networks from high dimensional micro-array data with Gaussian Bayesian networks. (arXiv:2106.15365v1 [q-bio.MN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Graafland_C/0/1/0/all/0/1">Catharina Elisabeth Graafland</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gutierrez_J/0/1/0/all/0/1">Jos&#xe9; Manuel Guti&#xe9;rrez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15365">
                                    <div class="article-summary-box-inner">
                                        <span>Gene expression datasets consist of thousand of genes with relatively small
samplesizes (i.e. are large-$p$-small-$n$). Moreover, dependencies of various
orders co-exist in the datasets. In the Undirected probabilistic Graphical
Model (UGM) framework the Glasso algorithm has been proposed to deal with high
dimensional micro-array datasets forcing sparsity. Also, modifications of the
default Glasso algorithm are developed to overcome the problem of complex
interaction structure. In this work we advocate the use of a simple score-based
Hill Climbing algorithm (HC) that learns Gaussian Bayesian Networks (BNs)
leaning on Directed Acyclic Graphs (DAGs). We compare HC with Glasso and its
modifications in the UGM framework on their capability to reconstruct GRNs from
micro-array data belonging to the Escherichia Coli genome. We benefit from the
analytical properties of the Joint Probability Density (JPD) function on which
both directed and undirected PGMs build to convert DAGs to UGMs.

We conclude that dependencies in complex data are learned best by the HC
algorithm, presenting them most accurately and efficiently, simultaneously
modelling strong local and weaker but significant global connections coexisting
in the gene expression dataset. The HC algorithm adapts intrinsically to the
complex dependency structure of the dataset, without forcing a specific
structure in advance. On the contrary, Glasso and modifications model
unnecessary dependencies at the expense of the probabilistic information in the
network and of a structural bias in the JPD function that can only be relieved
including many parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRILL-- Deep Reinforcement Learning for Refinement Operators in $\mathcal{ALC}$. (arXiv:2106.15373v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1">Caglar Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1">Axel-Cyrille Ngonga Ngomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15373">
                                    <div class="article-summary-box-inner">
                                        <span>Approaches based on refinement operators have been successfully applied to
class expression learning on RDF knowledge graphs. These approaches often need
to explore a large number of concepts to find adequate hypotheses. This need
arguably stems from current approaches relying on myopic heuristic functions to
guide their search through an infinite concept space. In turn, deep
reinforcement learning provides effective means to address myopia by estimating
how much discounted cumulated future reward states promise. In this work, we
leverage deep reinforcement learning to accelerate the learning of concepts in
$\mathcal{ALC}$ by proposing DRILL -- a novel class expression learning
approach that uses a convolutional deep Q-learning model to steer its search.
By virtue of its architecture, DRILL is able to compute the expected discounted
cumulated future reward of more than $10^3$ class expressions in a second on
standard hardware. We evaluate DRILL on four benchmark datasets against
state-of-the-art approaches. Our results suggest that DRILL converges to goal
states at least 2.7$\times$ faster than state-of-the-art models on all
benchmark datasets. We provide an open-source implementation of our approach,
including training and evaluation scripts as well as pre-trained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning for Intrusion Detection in IoT Security: A Hybrid Ensemble Approach. (arXiv:2106.15349v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Sayan Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanawal_M/0/1/0/all/0/1">Manjesh K. Hanawal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15349">
                                    <div class="article-summary-box-inner">
                                        <span>Critical role of Internet of Things (IoT) in various domains like smart city,
healthcare, supply chain and transportation has made them the target of
malicious attacks. Past works in this area focused on centralized Intrusion
Detection System (IDS), assuming the existence of a central entity to perform
data analysis and identify threats. However, such IDS may not always be
feasible, mainly due to spread of data across multiple sources and gathering at
central node can be costly. Also, the earlier works primarily focused on
improving True Positive Rate (TPR) and ignored the False Positive Rate (FPR),
which is also essential to avoid unnecessary downtime of the systems. In this
paper, we first present an architecture for IDS based on hybrid ensemble model,
named PHEC, which gives improved performance compared to state-of-the-art
architectures. We then adapt this model to a federated learning framework that
performs local training and aggregates only the model parameters. Next, we
propose Noise-Tolerant PHEC in centralized and federated settings to address
the label-noise problem. The proposed idea uses classifiers using weighted
convex surrogate loss functions. Natural robustness of KNN classifier towards
noisy data is also used in the proposed architecture. Experimental results on
four benchmark datasets drawn from various security attacks show that our model
achieves high TPR while keeping FPR low on noisy and clean data. Further, they
also demonstrate that the hybrid ensemble models achieve performance in
federated settings close to that of the centralized settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Where is the disease? Semi-supervised pseudo-normality synthesis from an abnormal image. (arXiv:2106.15345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yuanqi Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_Q/0/1/0/all/0/1">Quan Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">S. Kevin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15345">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-normality synthesis, which computationally generates a pseudo-normal
image from an abnormal one (e.g., with lesions), is critical in many
perspectives, from lesion detection, data augmentation to clinical surgery
suggestion. However, it is challenging to generate high-quality pseudo-normal
images in the absence of the lesion information. Thus, expensive lesion
segmentation data have been introduced to provide lesion information for the
generative models and improve the quality of the synthetic images. In this
paper, we aim to alleviate the need of a large amount of lesion segmentation
data when generating pseudo-normal images. We propose a Semi-supervised Medical
Image generative LEarning network (SMILE) which not only utilizes limited
medical images with segmentation masks, but also leverages massive medical
images without segmentation masks to generate realistic pseudo-normal images.
Extensive experiments show that our model outperforms the best state-of-the-art
model by up to 6% for data augmentation task and 3% in generating high-quality
images. Moreover, the proposed semi-supervised learning achieves comparable
medical image synthesis quality with supervised learning model, using only 50
of segmentation data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Inpainting Using Wasserstein Generative Adversarial Imputation Network. (arXiv:2106.15341v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasata_D/0/1/0/all/0/1">Daniel Va&#x161;ata</a>, <a href="http://arxiv.org/find/cs/1/au:+Halama_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Halama</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedjungova_M/0/1/0/all/0/1">Magda Friedjungov&#xe1;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15341">
                                    <div class="article-summary-box-inner">
                                        <span>Image inpainting is one of the important tasks in computer vision which
focuses on the reconstruction of missing regions in an image. The aim of this
paper is to introduce an image inpainting model based on Wasserstein Generative
Adversarial Imputation Network. The generator network of the model uses
building blocks of convolutional layers with different dilation rates, together
with skip connections that help the model reproduce fine details of the output.
This combination yields a universal imputation model that is able to handle
various scenarios of missingness with sufficient quality. To show this
experimentally, the model is simultaneously trained to deal with three
scenarios given by missing pixels at random, missing various smaller square
regions, and one missing square placed in the center of the image. It turns out
that our model achieves high-quality inpainting results on all scenarios.
Performance is evaluated using peak signal-to-noise ratio and structural
similarity index on two real-world benchmark datasets, CelebA faces and Paris
StreetView. The results of our model are compared to biharmonic imputation and
to some of the other state-of-the-art image inpainting methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy Budget Scheduling. (arXiv:2106.15335v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_M/0/1/0/all/0/1">Mingen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tholoniat_P/0/1/0/all/0/1">Pierre Tholoniat</a>, <a href="http://arxiv.org/find/cs/1/au:+Cidon_A/0/1/0/all/0/1">Asaf Cidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Geambasu_R/0/1/0/all/0/1">Roxana Geambasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecuyer_M/0/1/0/all/0/1">Mathias L&#xe9;cuyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15335">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) models trained on personal data have been shown to leak
information about users. Differential privacy (DP) enables model training with
a guaranteed bound on this leakage. Each new model trained with DP increases
the bound on data leakage and can be seen as consuming part of a global privacy
budget that should not be exceeded. This budget is a scarce resource that must
be carefully managed to maximize the number of successfully trained models.

We describe PrivateKube, an extension to the popular Kubernetes datacenter
orchestrator that adds privacy as a new type of resource to be managed
alongside other traditional compute resources, such as CPU, GPU, and memory.
The abstractions we design for the privacy resource mirror those defined by
Kubernetes for traditional resources, but there are also major differences. For
example, traditional compute resources are replenishable while privacy is not:
a CPU can be regained after a model finishes execution while privacy budget
cannot. This distinction forces a re-design of the scheduler. We present DPF
(Dominant Private Block Fairness) -- a variant of the popular Dominant Resource
Fairness (DRF) algorithm -- that is geared toward the non-replenishable privacy
resource but enjoys similar theoretical properties as DRF.

We evaluate PrivateKube and DPF on microbenchmarks and an ML workload on
Amazon Reviews data. Compared to existing baselines, DPF allows training more
models under the same global privacy guarantee. This is especially true for DPF
over R\&#x27;enyi DP, a highly composable form of DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Attention for Interactive Segmentation. (arXiv:2106.15338v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gabbur_P/0/1/0/all/0/1">Prasad Gabbur</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilkhu_M/0/1/0/all/0/1">Manjot Bilkhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Movellan_J/0/1/0/all/0/1">Javier Movellan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15338">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a probabilistic interpretation of attention and show that the
standard dot-product attention in transformers is a special case of Maximum A
Posteriori (MAP) inference. The proposed approach suggests the use of
Expectation Maximization algorithms for online adaptation of key and value
model parameters. This approach is useful for cases in which external agents,
e.g., annotators, provide inference-time information about the correct values
of some tokens, e.g, the semantic category of some pixels, and we need for this
new information to propagate to other tokens in a principled manner. We
illustrate the approach on an interactive semantic segmentation task in which
annotators and models collaborate online to improve annotation efficiency.
Using standard benchmarks, we observe that key adaptation boosts model
performance ($\sim10\%$ mIoU) in the low feedback regime and value propagation
improves model responsiveness in the high feedback regime. A PyTorch layer
implementation of our probabilistic attention model will be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Sample-Optimal Compressive Phase Retrieval with Sparse and Generative Priors. (arXiv:2106.15358v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1">Zhaoqiang Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1">Subhroshekhar Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Scarlett_J/0/1/0/all/0/1">Jonathan Scarlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15358">
                                    <div class="article-summary-box-inner">
                                        <span>Compressive phase retrieval is a popular variant of the standard compressive
sensing problem, in which the measurements only contain magnitude information.
In this paper, motivated by recent advances in deep generative models, we
provide recovery guarantees with order-optimal sample complexity bounds for
phase retrieval with generative priors. We first show that when using i.i.d.
Gaussian measurements and an $L$-Lipschitz continuous generative model with
bounded $k$-dimensional inputs, roughly $O(k \log L)$ samples suffice to
guarantee that the signal is close to any vector that minimizes an
amplitude-based empirical loss function. Attaining this sample complexity with
a practical algorithm remains a difficult challenge, and a popular spectral
initialization method has been observed to pose a major bottleneck. To
partially address this, we further show that roughly $O(k \log L)$ samples
ensure sufficient closeness between the signal and any {\em globally optimal}
solution to an optimization problem designed for spectral initialization
(though finding such a solution may still be challenging). We adapt this result
to sparse phase retrieval, and show that $O(s \log n)$ samples are sufficient
for a similar guarantee when the underlying signal is $s$-sparse and
$n$-dimensional, matching an information-theoretic lower bound. While our
guarantees do not directly correspond to a practical algorithm, we propose a
practical spectral initialization method motivated by our findings, and
experimentally observe significant performance gains over various existing
spectral initialization methods of sparse phase retrieval.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Framework for Spectral Dimensionality Reduction, Maximum Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial and Survey. (arXiv:2106.15379v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15379">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper on unification of spectral dimensionality
reduction methods, kernel learning by Semidefinite Programming (SDP), Maximum
Variance Unfolding (MVU) or Semidefinite Embedding (SDE), and its variants. We
first explain how the spectral dimensionality reduction methods can be unified
as kernel Principal Component Analysis (PCA) with different kernels. This
unification can be interpreted as eigenfunction learning or representation of
kernel in terms of distance matrix. Then, since the spectral methods are
unified as kernel PCA, we say let us learn the best kernel for unfolding the
manifold of data to its maximum variance. We first briefly introduce kernel
learning by SDP for the transduction task. Then, we explain MVU in detail.
Various versions of supervised MVU using nearest neighbors graph, by class-wise
unfolding, by Fisher criterion, and by colored MVU are explained. We also
explain out-of-sample extension of MVU using eigenfunctions and kernel mapping.
Finally, we introduce other variants of MVU including action respecting
embedding, relaxed MVU, and landmark MVU for big data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hagerer_G/0/1/0/all/0/1">Gerhard Hagerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1">Wenbin Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Danner_H/0/1/0/all/0/1">Hannah Danner</a>, <a href="http://arxiv.org/find/cs/1/au:+Groh_G/0/1/0/all/0/1">Georg Groh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15498">
                                    <div class="article-summary-box-inner">
                                        <span>Social media offer plenty of information to perform market research in order
to meet the requirements of customers. One way how this research is conducted
is that a domain expert gathers and categorizes user-generated content into a
complex and fine-grained class structure. In many of such cases, little data
meets complex annotations. It is not yet fully understood how this can be
leveraged successfully for classification. We examine the classification
accuracy of expert labels when used with a) many fine-grained classes and b)
few abstract classes. For scenario b) we compare abstract class labels given by
the domain expert as baseline and by automatic hierarchical clustering. We
compare this to another baseline where the entire class structure is given by a
completely unsupervised clustering approach. By doing so, this work can serve
as an example of how complex expert annotations are potentially beneficial and
can be utilized in the most optimal way for opinion mining in highly specific
domains. By exploring across a range of techniques and experiments, we find
that automated class abstraction approaches in particular the unsupervised
approach performs remarkably well against domain expert baseline on text
classification tasks. This has the potential to inspire opinion mining
applications in order to support market researchers in practice and to inspire
fine-grained automated content analysis on a large scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Security Analysis of Camera-LiDAR Semantic-Level Fusion Against Black-Box Attacks on Autonomous Vehicles. (arXiv:2106.07098v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hallyburton_R/0/1/0/all/0/1">R. Spencer Hallyburton</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yupei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1">Miroslav Pajic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07098">
                                    <div class="article-summary-box-inner">
                                        <span>To enable safe and reliable decision-making, autonomous vehicles (AVs) feed
sensor data to perception algorithms to understand the environment. Sensor
fusion, and particularly semantic fusion, with multi-frame tracking is becoming
increasingly popular for detecting 3D objects. Recently, it was shown that
LiDAR-based perception built on deep neural networks is vulnerable to LiDAR
spoofing attacks. Thus, in this work, we perform the first analysis of
camera-LiDAR fusion under spoofing attacks and the first security analysis of
semantic fusion in any AV context. We find first that fusion is more successful
than existing defenses at guarding against naive spoofing. However, we then
define the frustum attack as a new class of attacks on AVs and find that
semantic camera-LiDAR fusion exhibits widespread vulnerability to frustum
attacks with between 70% and 90% success against target models. Importantly,
the attacker needs less than 20 random spoof points on average for successful
attacks - an order of magnitude less than established maximum capability.
Finally, we are the first to analyze the longitudinal impact of perception
attacks by showing the impact of multi-frame attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Prediction and Network Estimation Using the Monotone Single Index Multi-variate Autoregressive Model. (arXiv:2106.14630v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Raskutti_G/0/1/0/all/0/1">Garvesh Raskutti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14630">
                                    <div class="article-summary-box-inner">
                                        <span>Network estimation from multi-variate point process or time series data is a
problem of fundamental importance. Prior work has focused on parametric
approaches that require a known parametric model, which makes estimation
procedures less robust to model mis-specification, non-linearities and
heterogeneities. In this paper, we develop a semi-parametric approach based on
the monotone single-index multi-variate autoregressive model (SIMAM) which
addresses these challenges. We provide theoretical guarantees for dependent
data and an alternating projected gradient descent algorithm. Significantly we
do not explicitly assume mixing conditions on the process (although we do
require conditions analogous to restricted strong convexity) and we achieve
rates of the form $O(T^{-\frac{1}{3}} \sqrt{s\log(TM)})$ (optimal in the
independent design case) where $s$ is the threshold for the maximum in-degree
of the network that indicates the sparsity level, $M$ is the number of actors
and $T$ is the number of time points. In addition, we demonstrate the superior
performance both on simulated data and two real data examples where our SIMAM
approach out-performs state-of-the-art parametric methods both in terms of
prediction and network estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Look-Ahead Screening Rules for the Lasso. (arXiv:2105.05648v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Larsson_J/0/1/0/all/0/1">Johan Larsson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05648">
                                    <div class="article-summary-box-inner">
                                        <span>The lasso is a popular method to induce shrinkage and sparsity in the
solution vector (coefficients) of regression problems, particularly when there
are many predictors relative to the number of observations. Solving the lasso
in this high-dimensional setting can, however, be computationally demanding.
Fortunately, this demand can be alleviated via the use of screening rules that
discard predictors prior to fitting the model, leading to a reduced problem to
be solved. In this paper, we present a new screening strategy: look-ahead
screening. Our method uses safe screening rules to find a range of penalty
values for which a given predictor cannot enter the model, thereby screening
predictors along the remainder of the path. In experiments we show that these
look-ahead screening rules outperform the active warm-start version of the Gap
Safe rules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting. (arXiv:2106.06251v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Akiyama_S/0/1/0/all/0/1">Shunta Akiyama</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06251">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning empirically achieves high performance in many applications, but
its training dynamics has not been fully understood theoretically. In this
paper, we explore theoretical analysis on training two-layer ReLU neural
networks in a teacher-student regression model, in which a student network
learns an unknown teacher network through its outputs. We show that with a
specific regularization and sufficient over-parameterization, the student
network can identify the parameters of the teacher network with high
probability via gradient descent with a norm dependent stepsize even though the
objective function is highly non-convex. The key theoretical tool is the
measure representation of the neural networks and a novel application of a dual
certificate argument for sparse estimation on a measure space. We analyze the
global minima and global convergence property in the measure space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Finding Longer Proofs. (arXiv:1905.13100v2 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zombori_Z/0/1/0/all/0/1">Zsolt Zombori</a>, <a href="http://arxiv.org/find/cs/1/au:+Csiszarik_A/0/1/0/all/0/1">Adri&#xe1;n Csisz&#xe1;rik</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaliszyk_C/0/1/0/all/0/1">Cezary Kaliszyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Urban_J/0/1/0/all/0/1">Josef Urban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13100">
                                    <div class="article-summary-box-inner">
                                        <span>We present a reinforcement learning (RL) based guidance system for automated
theorem proving geared towards Finding Longer Proofs (FLoP). Unlike most
learning based approaches, we focus on generalising from very little training
data and achieving near complete confidence. We use several simple, structured
datasets with very long proofs to show that FLoP can successfully generalise a
single training proof to a large class of related problems. On these
benchmarks, FLoP is competitive with strong theorem provers despite using very
limited search, due to its ability to solve problems that are prohibitively
long for other systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adaptive Swarm System (SASS). (arXiv:2106.04679v2 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04679">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed artificial intelligence (DAI) studies artificial intelligence
entities working together to reason, plan, solve problems, organize behaviors
and strategies, make collective decisions and learn. This Ph.D. research
proposes a principled Multi-Agent Systems (MAS) cooperation framework,
Self-Adaptive Swarm System (SASS), to bridge the fourth level automation gap
between perception, communication, planning, execution, decision-making, and
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization of Reinforcement Learning with Policy-Aware Adversarial Data Augmentation. (arXiv:2106.15587v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuhong Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15587">
                                    <div class="article-summary-box-inner">
                                        <span>The generalization gap in reinforcement learning (RL) has been a significant
obstacle that prevents the RL agent from learning general skills and adapting
to varying environments. Increasing the generalization capacity of the RL
systems can significantly improve their performance on real-world working
environments. In this work, we propose a novel policy-aware adversarial data
augmentation method to augment the standard policy learning method with
automatically generated trajectory data. Different from the commonly used
observation transformation based data augmentations, our proposed method
adversarially generates new trajectory data based on the policy gradient
objective and aims to more effectively increase the RL agent&#x27;s generalization
ability with the policy-aware data augmentation. Moreover, we further deploy a
mixup step to integrate the original and generated data to enhance the
generalization capacity while mitigating the over-deviation of the adversarial
data. We conduct experiments on a number of RL tasks to investigate the
generalization performance of the proposed method by comparing it with the
standard baselines and the state-of-the-art mixreg approach. The results show
our method can generalize well with limited training diversity, and achieve the
state-of-the-art generalization test performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Against Membership Inference Attack: Pruning is All You Need. (arXiv:2008.13578v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yijue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenghong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zigeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shanglin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1">Jinbo Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajasekaran_S/0/1/0/all/0/1">Sanguthevar Rajasekaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.13578">
                                    <div class="article-summary-box-inner">
                                        <span>The large model size, high computational operations, and vulnerability
against membership inference attack (MIA) have impeded deep learning or deep
neural networks (DNNs) popularity, especially on mobile devices. To address the
challenge, we envision that the weight pruning technique will help DNNs against
MIA while reducing model storage and computational operation. In this work, we
propose a pruning algorithm, and we show that the proposed algorithm can find a
subnetwork that can prevent privacy leakage from MIA and achieves competitive
accuracy with the original DNNs. We also verify our theoretical insights with
experiments. Our experimental results illustrate that the attack accuracy using
model compression is up to 13.6% and 10% lower than that of the baseline and
Min-Max game, accordingly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Body Region Classification of MRI and CT examinations. (arXiv:2104.13826v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Raffy_P/0/1/0/all/0/1">Philippe Raffy</a>, <a href="http://arxiv.org/find/eess/1/au:+Pambrun_J/0/1/0/all/0/1">Jean-Fran&#xe7;ois Pambrun</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Ashish Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Dubois_D/0/1/0/all/0/1">David Dubois</a>, <a href="http://arxiv.org/find/eess/1/au:+Patti_J/0/1/0/all/0/1">Jay Waldron Patti</a>, <a href="http://arxiv.org/find/eess/1/au:+Cairns_R/0/1/0/all/0/1">Robyn Alexandra Cairns</a>, <a href="http://arxiv.org/find/eess/1/au:+Young_R/0/1/0/all/0/1">Ryan Young</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13826">
                                    <div class="article-summary-box-inner">
                                        <span>Standardized body region labelling of individual images provides data that
can improve human and computer use of medical images. A CNN-based classifier
was developed to identify body regions in CT and MRI. 17 CT (18 MRI) body
regions covering the entire human body were defined for the classification
task. Three retrospective databases were built for the AI model training,
validation, and testing, with a balanced distribution of studies per body
region. The test databases originated from a different healthcare network.
Accuracy, recall and precision of the classifier was evaluated for patient age,
patient gender, institution, scanner manufacturer, contrast, slice thickness,
MRI sequence, and CT kernel. The data included a retrospective cohort of 2,934
anonymized CT cases (training: 1,804 studies, validation: 602 studies, test:
528 studies) and 3,185 anonymized MRI cases (training: 1,911 studies,
validation: 636 studies, test: 638 studies). 27 institutions from primary care
hospitals, community hospitals and imaging centers contributed to the test
datasets. The data included cases of all genders in equal proportions and
subjects aged from a few months old to +90 years old. An image-level prediction
accuracy of 91.9% (90.2 - 92.1) for CT, and 94.2% (92.0 - 95.6) for MRI was
achieved. The classification results were robust across all body regions and
confounding factors. Due to limited data, performance results for subjects
under 10 years-old could not be reliably evaluated. We show that deep learning
models can classify CT and MRI images by body region including lower and upper
extremities with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Values Encoded in Machine Learning Research. (arXiv:2106.15590v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Birhane_A/0/1/0/all/0/1">Abeba Birhane</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalluri_P/0/1/0/all/0/1">Pratyusha Kalluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1">Dallas Card</a>, <a href="http://arxiv.org/find/cs/1/au:+Agnew_W/0/1/0/all/0/1">William Agnew</a>, <a href="http://arxiv.org/find/cs/1/au:+Dotan_R/0/1/0/all/0/1">Ravit Dotan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_M/0/1/0/all/0/1">Michelle Bao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15590">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) currently exerts an outsized influence on the world,
increasingly affecting communities and institutional practices. It is therefore
critical that we question vague conceptions of the field as value-neutral or
universally beneficial, and investigate what specific values the field is
advancing. In this paper, we present a rigorous examination of the values of
the field by quantitatively and qualitatively analyzing 100 highly cited ML
papers published at premier ML conferences, ICML and NeurIPS. We annotate key
features of papers which reveal their values: how they justify their choice of
project, which aspects they uplift, their consideration of potential negative
consequences, and their institutional affiliations and funding sources. We find
that societal needs are typically very loosely connected to the choice of
project, if mentioned at all, and that consideration of negative consequences
is extremely rare. We identify 67 values that are uplifted in machine learning
research, and, of these, we find that papers most frequently justify and assess
themselves based on performance, generalization, efficiency, researcher
understanding, novelty, and building on previous work. We present extensive
textual evidence and analysis of how these values are operationalized. Notably,
we find that each of these top values is currently being defined and applied
with assumptions and implications generally supporting the centralization of
power. Finally, we find increasingly close ties between these highly cited
papers and tech companies and elite universities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Evaluation of Deep Active Learning on Image Classification Tasks. (arXiv:2106.15324v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1">Durga Sivasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Dani_A/0/1/0/all/0/1">Apurva Dani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15324">
                                    <div class="article-summary-box-inner">
                                        <span>With the goal of making deep learning more label-efficient, a growing number
of papers have been studying active learning (AL) for deep models. However,
there are a number of issues in the prevalent experimental settings, mainly
stemming from a lack of unified implementation and benchmarking. Issues in the
current literature include sometimes contradictory observations on the
performance of different AL algorithms, unintended exclusion of important
generalization approaches such as data augmentation and SGD for optimization, a
lack of study of evaluation facets like the labeling efficiency of AL, and
little or no clarity on the scenarios in which AL outperforms random sampling
(RS). In this work, we present a unified re-implementation of state-of-the-art
AL algorithms in the context of image classification, and we carefully study
these issues as facets of effective evaluation. On the positive side, we show
that AL techniques are 2x to 4x more label-efficient compared to RS with the
use of data augmentation. Surprisingly, when data augmentation is included,
there is no longer a consistent gain in using BADGE, a state-of-the-art
approach, over simple uncertainty sampling. We then do a careful analysis of
how existing approaches perform with varying amounts of redundancy and number
of examples per class. Finally, we provide several insights for AL
practitioners to consider in future work, such as the effect of the AL batch
size, the effect of initialization, the importance of retraining a new model at
every round, and other insights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments. (arXiv:2104.14380v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_F/0/1/0/all/0/1">Fan Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1">Hamed Haddadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Katevas_K/0/1/0/all/0/1">Kleomenis Katevas</a>, <a href="http://arxiv.org/find/cs/1/au:+Marin_E/0/1/0/all/0/1">Eduard Marin</a>, <a href="http://arxiv.org/find/cs/1/au:+Perino_D/0/1/0/all/0/1">Diego Perino</a>, <a href="http://arxiv.org/find/cs/1/au:+Kourtellis_N/0/1/0/all/0/1">Nicolas Kourtellis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14380">
                                    <div class="article-summary-box-inner">
                                        <span>We propose and implement a Privacy-preserving Federated Learning ($PPFL$)
framework for mobile systems to limit privacy leakages in federated learning.
Leveraging the widespread presence of Trusted Execution Environments (TEEs) in
high-end and mobile devices, we utilize TEEs on clients for local training, and
on servers for secure aggregation, so that model/gradient updates are hidden
from adversaries. Challenged by the limited memory size of current TEEs, we
leverage greedy layer-wise training to train each model&#x27;s layer inside the
trusted area until its convergence. The performance evaluation of our
implementation shows that $PPFL$ can significantly improve privacy while
incurring small system overheads at the client-side. In particular, $PPFL$ can
successfully defend the trained model against data reconstruction, property
inference, and membership inference attacks. Furthermore, it can achieve
comparable model utility with fewer communication rounds (0.54$\times$) and a
similar amount of network traffic (1.002$\times$) compared to the standard
federated learning of a complete model. This is achieved while only introducing
up to ~15% CPU time, ~18% memory usage, and ~21% energy consumption overhead in
$PPFL$&#x27;s client-side.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expert Q-learning: Deep Q-learning With State Values From Expert Examples. (arXiv:2106.14642v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1">Li Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yazidi_A/0/1/0/all/0/1">Anis Yazidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1">Morten Goodwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelstad_P/0/1/0/all/0/1">Paal Engelstad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14642">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel algorithm named Expert Q-learning. Expert Q-learning was
inspired by Dueling Q-learning and aimed at incorporating the ideas from
semi-supervised learning into reinforcement learning through splitting Q-values
into state values and action advantages. Different from Generative Adversarial
Imitation Learning and Deep Q-Learning from Demonstrations, the offline expert
we have used only predicts the value of a state from {-1, 0, 1}, indicating
whether this is a bad, neutral or good state. An expert network was designed in
addition to the Q-network, which updates each time following the regular
offline minibatch update whenever the expert example buffer is not empty. The
Q-network plays the role of the advantage function only during the update. Our
algorithm also keeps asynchronous copies of the Q-network and expert network,
predicting the target values using the same manner as of Double Q-learning.

We compared on the game of Othello our algorithm with the state-of-the-art
Q-learning algorithm, which was a combination of Double Q-learning and Dueling
Q-learning. The results showed that Expert Q-learning was indeed useful and
more resistant to the overestimation bias of Q-learning. The baseline
Q-learning algorithm exhibited unstable and suboptimal behavior, especially
when playing against a stochastic player, whereas Expert Q-learning
demonstrated more robust performance with higher scores. Expert Q-learning
without using examples has also gained better results than the baseline
algorithm when trained and tested against a fixed player. On the other hand,
Expert Q-learning without examples cannot win against the baseline Q-learning
algorithm in direct game competitions despite the fact that it has also shown
the strength of reducing the overestimation bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Doing good by fighting fraud: Ethical anti-fraud systems for mobile payments. (arXiv:2106.14861v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Din_Z/0/1/0/all/0/1">Zainul Abi Din</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Venugopalan_H/0/1/0/all/0/1">Hari Venugopalan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Henry Lin</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Wushensky_A/0/1/0/all/0/1">Adam Wushensky</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Steven Liu</a> (2), <a href="http://arxiv.org/find/cs/1/au:+King_S/0/1/0/all/0/1">Samuel T. King</a> (1 and 2) ((1) University of California, Davis, (2) Bouncer Technologies)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14861">
                                    <div class="article-summary-box-inner">
                                        <span>App builders commonly use security challenges, a form of step-up
authentication, to add security to their apps. However, the ethical
implications of this type of architecture has not been studied previously. In
this paper, we present a large-scale measurement study of running an existing
anti-fraud security challenge, Boxer, in real apps running on mobile devices.
We find that although Boxer does work well overall, it is unable to scan
effectively on devices that run its machine learning models at less than one
frame per second (FPS), blocking users who use inexpensive devices. With the
insights from our study, we design Daredevil, anew anti-fraud system for
scanning payment cards that work swell across the broad range of performance
characteristics and hardware configurations found on modern mobile devices.
Daredevil reduces the number of devices that run at less than one FPS by an
order of magnitude compared to Boxer, providing a more equitable system for
fighting fraud. In total, we collect data from 5,085,444 real devices spread
across 496 real apps running production software and interacting with real
users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Decentralized Adaptive Momentum Method for Solving a Class of Min-Max Optimization Problems. (arXiv:2106.06075v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Barazandeh_B/0/1/0/all/0/1">Babak Barazandeh</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_T/0/1/0/all/0/1">Tianjian Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Michailidis_G/0/1/0/all/0/1">George Michailidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06075">
                                    <div class="article-summary-box-inner">
                                        <span>Min-max saddle point games have recently been intensely studied, due to their
wide range of applications, including training Generative Adversarial Networks
(GANs). However, most of the recent efforts for solving them are limited to
special regimes such as convex-concave games. Further, it is customarily
assumed that the underlying optimization problem is solved either by a single
machine or in the case of multiple machines connected in centralized fashion,
wherein each one communicates with a central node. The latter approach becomes
challenging, when the underlying communications network has low bandwidth. In
addition, privacy considerations may dictate that certain nodes can communicate
with a subset of other nodes. Hence, it is of interest to develop methods that
solve min-max games in a decentralized manner. To that end, we develop a
decentralized adaptive momentum (ADAM)-type algorithm for solving min-max
optimization problem under the condition that the objective function satisfies
a Minty Variational Inequality condition, which is a generalization to
convex-concave case. The proposed method overcomes shortcomings of recent
non-adaptive gradient-based decentralized algorithms for min-max optimization
problems that do not perform well in practice and require careful tuning. In
this paper, we obtain non-asymptotic rates of convergence of the proposed
algorithm (coined DADAM$^3$) for finding a (stochastic) first-order Nash
equilibrium point and subsequently evaluate its performance on training GANs.
The extensive empirical evaluation shows that DADAM$^3$ outperforms recently
developed methods, including decentralized optimistic stochastic gradient for
solving such min-max problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Guided Progressive GANs for Medical Image Translation. (arXiv:2106.15542v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_U/0/1/0/all/0/1">Uddeshya Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanbei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hepp_T/0/1/0/all/0/1">Tobias Hepp</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1">Sergios Gatidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15542">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-image translation plays a vital role in tackling various medical
imaging tasks such as attenuation correction, motion correction, undersampled
reconstruction, and denoising. Generative adversarial networks have been shown
to achieve the state-of-the-art in generating high fidelity images for these
tasks. However, the state-of-the-art GAN-based frameworks do not estimate the
uncertainty in the predictions made by the network that is essential for making
informed medical decisions and subsequent revision by medical experts and has
recently been shown to improve the performance and interpretability of the
model. In this work, we propose an uncertainty-guided progressive learning
scheme for image-to-image translation. By incorporating aleatoric uncertainty
as attention maps for GANs trained in a progressive manner, we generate images
of increasing fidelity progressively. We demonstrate the efficacy of our model
on three challenging medical image translation tasks, including PET to CT
translation, undersampled MRI reconstruction, and MRI motion artefact
correction. Our model generalizes well in three different tasks and improves
performance over state of the art under full-supervision and weak-supervision
with limited data. Code is released here:
https://github.com/ExplainableML/UncerGuidedI2I</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Attraction and Contrastive Repulsion for Representation Learning. (arXiv:2105.03746v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Huangjie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiangchao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1">Ivor Tsang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03746">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning (CL) is effective in learning data representations
without label supervision, where the encoder needs to contrast each positive
sample over multiple negative samples via a one-vs-many softmax cross-entropy
loss. However, conventional CL is sensitive to how many negative samples are
included and how they are selected. Proposed in this paper is a doubly CL
strategy that contrasts positive samples and negative ones within themselves
separately. We realize this strategy with contrastive attraction and
contrastive repulsion (CACR) makes the query not only exert a greater force to
attract more distant positive samples but also do so to repel closer negative
samples. Theoretical analysis reveals the connection between CACR and CL from
the perspectives of both positive attraction and negative repulsion and shows
the benefits in both efficiency and robustness brought by separately
contrasting within the sampled positive and negative pairs. Extensive
large-scale experiments on standard vision tasks show that CACR not only
consistently outperforms existing CL methods on benchmark datasets in
representation learning, but also provides interpretable contrastive weights,
demonstrating the efficacy of the proposed doubly contrastive strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolterraNet: A higher order convolutional network with group equivariance for homogeneous manifolds. (arXiv:2106.15301v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_M/0/1/0/all/0/1">Monami Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_R/0/1/0/all/0/1">Rudrasis Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouza_J/0/1/0/all/0/1">Jose Bouza</a>, <a href="http://arxiv.org/find/cs/1/au:+Vemuri_B/0/1/0/all/0/1">Baba C. Vemuri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15301">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks have been highly successful in image-based
learning tasks due to their translation equivariance property. Recent work has
generalized the traditional convolutional layer of a convolutional neural
network to non-Euclidean spaces and shown group equivariance of the generalized
convolution operation. In this paper, we present a novel higher order Volterra
convolutional neural network (VolterraNet) for data defined as samples of
functions on Riemannian homogeneous spaces. Analagous to the result for
traditional convolutions, we prove that the Volterra functional convolutions
are equivariant to the action of the isometry group admitted by the Riemannian
homogeneous spaces, and under some restrictions, any non-linear equivariant
function can be expressed as our homogeneous space Volterra convolution,
generalizing the non-linear shift equivariant characterization of Volterra
expansions in Euclidean space. We also prove that second order functional
convolution operations can be represented as cascaded convolutions which leads
to an efficient implementation. Beyond this, we also propose a dilated
VolterraNet model. These advances lead to large parameter reductions relative
to baseline non-Euclidean CNNs. To demonstrate the efficacy of the VolterraNet
performance, we present several real data experiments involving classification
tasks on spherical-MNIST, atomic energy, Shrec17 data sets, and group testing
on diffusion MRI data. Performance comparisons to the state-of-the-art are also
presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ambient Intelligence-Based Human Behavior Monitoring Framework for Ubiquitous Environments. (arXiv:2106.15609v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1">Nirmalya Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chia Y. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15609">
                                    <div class="article-summary-box-inner">
                                        <span>This framework for human behavior monitoring aims to take a holistic approach
to study, track, monitor, and analyze human behavior during activities of daily
living (ADLs). The framework consists of two novel functionalities. First, it
can perform the semantic analysis of user interactions on the diverse
contextual parameters during ADLs to identify a list of distinct behavioral
patterns associated with different complex activities. Second, it consists of
an intelligent decision-making algorithm that can analyze these behavioral
patterns and their relationships with the dynamic contextual and spatial
features of the environment to detect any anomalies in user behavior that could
constitute an emergency. These functionalities of this interdisciplinary
framework were developed by integrating the latest advancements and
technologies in human-computer interaction, machine learning, Internet of
Things, pattern recognition, and ubiquitous computing. The framework was
evaluated on a dataset of ADLs, and the performance accuracies of these two
functionalities were found to be 76.71% and 83.87%, respectively. The presented
and discussed results uphold the relevance and immense potential of this
framework to contribute towards improving the quality of life and assisted
living of the aging population in the future of Internet of Things (IoT)-based
ubiquitous living environments, e.g., smart homes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Representation Learning Perspective on the Importance of Train-Validation Splitting in Meta-Learning. (arXiv:2106.15615v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1">Nikunj Saunshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arushi Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15615">
                                    <div class="article-summary-box-inner">
                                        <span>An effective approach in meta-learning is to utilize multiple &quot;train tasks&quot;
to learn a good initialization for model parameters that can help solve unseen
&quot;test tasks&quot; with very few samples by fine-tuning from this initialization.
Although successful in practice, theoretical understanding of such methods is
limited. This work studies an important aspect of these methods: splitting the
data from each task into train (support) and validation (query) sets during
meta-training. Inspired by recent work (Raghu et al., 2020), we view such
meta-learning methods through the lens of representation learning and argue
that the train-validation split encourages the learned representation to be
low-rank without compromising on expressivity, as opposed to the non-splitting
variant that encourages high-rank representations. Since sample efficiency
benefits from low-rankness, the splitting strategy will require very few
samples to solve unseen test tasks. We present theoretical results that
formalize this idea for linear representation learning on a subspace
meta-learning instance, and experimentally verify this practical benefit of
splitting in simulations and on standard meta-learning benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ScanBank: A Benchmark Dataset for Figure Extraction from Scanned Electronic Theses and Dissertations. (arXiv:2106.15320v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kahu_S/0/1/0/all/0/1">Sampanna Yashwant Kahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingram_W/0/1/0/all/0/1">William A. Ingram</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1">Edward A. Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15320">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on electronic theses and dissertations (ETDs), aiming to improve
access and expand their utility, since more than 6 million are publicly
available, and they constitute an important corpus to aid research and
education across disciplines. The corpus is growing as new born-digital
documents are included, and since millions of older theses and dissertations
have been converted to digital form to be disseminated electronically in
institutional repositories. In ETDs, as with other scholarly works, figures and
tables can communicate a large amount of information in a concise way. Although
methods have been proposed for extracting figures and tables from born-digital
PDFs, they do not work well with scanned ETDs. Considering this problem, our
assessment of state-of-the-art figure extraction systems is that the reason
they do not function well on scanned PDFs is that they have only been trained
on born-digital documents. To address this limitation, we present ScanBank, a
new dataset containing 10 thousand scanned page images, manually labeled by
humans as to the presence of the 3.3 thousand figures or tables found therein.
We use this dataset to train a deep neural network model based on YOLOv5 to
accurately extract figures and tables from scanned ETDs. We pose and answer
important research questions aimed at finding better methods for figure
extraction from scanned documents. One of those concerns the value for
training, of data augmentation techniques applied to born-digital documents
which are used to train models better suited for figure extraction from scanned
documents. To the best of our knowledge, ScanBank is the first manually
annotated dataset for figure and table extraction for scanned ETDs. A
YOLOv5-based model, trained on ScanBank, outperforms existing comparable
open-source and freely available baseline methods by a considerable margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Soft Attention: Does it Actually Help to Learn Social Interactions in Pedestrian Trajectory Prediction?. (arXiv:2106.15321v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boucaud_L/0/1/0/all/0/1">Laurent Boucaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Aloise_D/0/1/0/all/0/1">Daniel Aloise</a>, <a href="http://arxiv.org/find/cs/1/au:+Saunier_N/0/1/0/all/0/1">Nicolas Saunier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15321">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of predicting the future path of a pedestrian using
its motion history and the motion history of the surrounding pedestrians,
called social information. Since the seminal paper on Social-LSTM,
deep-learning has become the main tool used to model the impact of social
interactions on a pedestrian&#x27;s motion. The demonstration that these models can
learn social interactions relies on an ablative study of these models. The
models are compared with and without their social interactions module on two
standard metrics, the Average Displacement Error and Final Displacement Error.
Yet, these complex models were recently outperformed by a simple
constant-velocity approach. This questions if they actually allow to model
social interactions as well as the validity of the proof. In this paper, we
focus on the deep-learning models with a soft-attention mechanism for social
interaction modeling and study whether they use social information at
prediction time. We conduct two experiments across four state-of-the-art
approaches on the ETH and UCY datasets, which were also used in previous work.
First, the models are trained by replacing the social information with random
noise and compared to model trained with actual social information. Second, we
use a gating mechanism along with a $L_0$ penalty, allowing models to shut down
their inner components. The models consistently learn to prune their
soft-attention mechanism. For both experiments, neither the course of the
convergence nor the prediction performance were altered. This demonstrates that
the soft-attention mechanism and therefore the social information are ignored
by the models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in Minimally Invasive Interventional Treatment. (arXiv:2106.15306v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruijters_D/0/1/0/all/0/1">Daniel Ruijters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15306">
                                    <div class="article-summary-box-inner">
                                        <span>Minimally invasive image guided treatment procedures often employ advanced
image processing algorithms. The recent developments of artificial intelligence
algorithms harbor potential to further enhance this domain. In this article we
explore several application areas within the minimally invasive treatment space
and discuss the deployment of artificial intelligence within these areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reliable and Fast Recurrent Neural Network Architecture Optimization. (arXiv:2106.15295v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Camero_A/0/1/0/all/0/1">Andr&#xe9;s Camero</a>, <a href="http://arxiv.org/find/cs/1/au:+Toutouh_J/0/1/0/all/0/1">Jamal Toutouh</a>, <a href="http://arxiv.org/find/cs/1/au:+Alba_E/0/1/0/all/0/1">Enrique Alba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15295">
                                    <div class="article-summary-box-inner">
                                        <span>This article introduces Random Error Sampling-based Neuroevolution (RESN), a
novel automatic method to optimize recurrent neural network architectures. RESN
combines an evolutionary algorithm with a training-free evaluation approach.
The results show that RESN achieves state-of-the-art error performance while
reducing by half the computational time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DCASE 2021 Task 3: Spectrotemporally-aligned Features for Polyphonic Sound Event Localization and Detection. (arXiv:2106.15190v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_T/0/1/0/all/0/1">Thi Ngoc Tho Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Watcharasupat_K/0/1/0/all/0/1">Karn Watcharasupat</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_N/0/1/0/all/0/1">Ngoc Khanh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jones_D/0/1/0/all/0/1">Douglas L. Jones</a>, <a href="http://arxiv.org/find/eess/1/au:+Gan_W/0/1/0/all/0/1">Woon Seng Gan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15190">
                                    <div class="article-summary-box-inner">
                                        <span>Sound event localization and detection consists of two subtasks which are
sound event detection and direction-of-arrival estimation. While sound event
detection mainly relies on time-frequency patterns to distinguish different
sound classes, direction-of-arrival estimation uses magnitude or phase
differences between microphones to estimate source directions. Therefore, it is
often difficult to jointly train these two subtasks simultaneously. We propose
a novel feature called spatial cue-augmented log-spectrogram (SALSA) with exact
time-frequency mapping between the signal power and the source
direction-of-arrival. The feature includes multichannel log-spectrograms
stacked along with the estimated direct-to-reverberant ratio and a normalized
version of the principal eigenvector of the spatial covariance matrix at each
time-frequency bin on the spectrograms. Experimental results on the DCASE 2021
dataset for sound event localization and detection with directional
interference showed that the deep learning-based models trained on this new
feature outperformed the DCASE challenge baseline by a large margin. We
combined several models with slightly different architectures that were trained
on the new feature to further improve the system performances for the DCASE
sound event localization and detection challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Sparse Coding Fast Approximation with Application to Seismic Reflectivity Estimation. (arXiv:2106.15296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereg_D/0/1/0/all/0/1">Deborah Pereg</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_I/0/1/0/all/0/1">Israel Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassiliou_A/0/1/0/all/0/1">Anthony A. Vassiliou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15296">
                                    <div class="article-summary-box-inner">
                                        <span>In sparse coding, we attempt to extract features of input vectors, assuming
that the data is inherently structured as a sparse superposition of basic
building blocks. Similarly, neural networks perform a given task by learning
features of the training data set. Recently both data-driven and model-driven
feature extracting methods have become extremely popular and have achieved
remarkable results. Nevertheless, practical implementations are often too slow
to be employed in real-life scenarios, especially for real-time applications.
We propose a speed-up upgraded version of the classic iterative thresholding
algorithm, that produces a good approximation of the convolutional sparse code
within 2-5 iterations. The speed advantage is gained mostly from the
observation that most solvers are slowed down by inefficient global
thresholding. The main idea is to normalize each data point by the local
receptive field energy, before applying a threshold. This way, the natural
inclination towards strong feature expressions is suppressed, so that one can
rely on a global threshold that can be easily approximated, or learned during
training. The proposed algorithm can be employed with a known predetermined
dictionary, or with a trained dictionary. The trained version is implemented as
a neural net designed as the unfolding of the proposed solver. The performance
of the proposed solution is demonstrated via the seismic inversion problem in
both synthetic and real data scenarios. We also provide theoretical guarantees
for a stable support recovery. Namely, we prove that under certain conditions
the true support is perfectly recovered within the first iteration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">US Fatal Police Shooting Analysis and Prediction. (arXiv:2106.15298v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Wang_Y/0/1/0/all/0/1">Yuan Wang</a>, <a href="http://arxiv.org/find/physics/1/au:+Fan_Y/0/1/0/all/0/1">Yangxin Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15298">
                                    <div class="article-summary-box-inner">
                                        <span>We believe that &quot;all men are created equal&quot;. With the rise of the police
shootings reported by media, more people in the U.S. think that police use
excessive force during law enforcement, especially to a specific group of
people. We want to apply multidimensional statistical analysis to reveal more
facts than the monotone mainstream media. Our paper has three parts. First, we
proposed a new method to quantify fatal police shooting news reporting
deviation of mainstream media, which includes CNN, FOX, ABC, and NBC. Second,
we analyzed the most comprehensive US fatal police shooting dataset from
Washington Post. We used FP-growth to reveal the frequent patterns and DBSCAN
clustering to find fatal shooting hotspots. We brought multi-attributes (social
economics, demographics, political tendency, education, gun ownership rate,
police training hours, etc.) to reveal connections under the iceberg. We found
that the police shooting rate of a state depends on many variables. The top
four most relevant attributes were state joined year, state land area, gun
ownership rate, and violent crime rate. Third, we proposed four regression
models to predict police shooting rates at the state level. The best model
Kstar could predict the fatal police shooting rate with about 88.53%
correlation coefficient. We also proposed classification models, including
Gradient Boosting Machine, Multi-class Classifier, Logistic Regression, and
Naive Bayes Classifier, to predict the race of fatal police shooting victims.
Our classification models show no significant evidence to conclude that racial
discrimination happened during fatal police shootings recorded by the WP
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection and Automated Labeling for Voter Registration File Changes. (arXiv:2106.15285v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Royston_S/0/1/0/all/0/1">Sam Royston</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenberg_B/0/1/0/all/0/1">Ben Greenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Tavasoli_O/0/1/0/all/0/1">Omeed Tavasoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotton_C/0/1/0/all/0/1">Courtenay Cotton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15285">
                                    <div class="article-summary-box-inner">
                                        <span>Voter eligibility in United States elections is determined by a patchwork of
state databases containing information about which citizens are eligible to
vote. Administrators at the state and local level are faced with the
exceedingly difficult task of ensuring that each of their jurisdictions is
properly managed, while also monitoring for improper modifications to the
database. Monitoring changes to Voter Registration Files (VRFs) is crucial,
given that a malicious actor wishing to disrupt the democratic process in the
US would be well-advised to manipulate the contents of these files in order to
achieve their goals. In 2020, we saw election officials perform admirably when
faced with administering one of the most contentious elections in US history,
but much work remains to secure and monitor the election systems Americans rely
on. Using data created by comparing snapshots taken of VRFs over time, we
present a set of methods that make use of machine learning to ease the burden
on analysts and administrators in protecting voter rolls. We first evaluate the
effectiveness of multiple unsupervised anomaly detection methods in detecting
VRF modifications by modeling anomalous changes as sparse additive noise. In
this setting we determine that statistical models comparing administrative
districts within a short time span and non-negative matrix factorization are
most effective for surfacing anomalous events for review. These methods were
deployed during 2019-2020 in our organization&#x27;s monitoring system and were used
in collaboration with the office of the Iowa Secretary of State. Additionally,
we propose a newly deployed model which uses historical and demographic
metadata to label the likely root cause of database modifications. We hope to
use this model to predict which modifications have known causes and therefore
better identify potentially anomalous modifications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Deep Neural Networks for Image Document Enhancement. (arXiv:2106.15286v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirsten_L/0/1/0/all/0/1">Lucas N. Kirsten</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccoli_R/0/1/0/all/0/1">Ricardo Piccoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribani_R/0/1/0/all/0/1">Ricardo Ribani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15286">
                                    <div class="article-summary-box-inner">
                                        <span>This work evaluates six state-of-the-art deep neural network (DNN)
architectures applied to the problem of enhancing camera-captured document
images. The results from each network were evaluated both qualitatively and
quantitatively using Image Quality Assessment (IQA) metrics, and also compared
with an existing approach based on traditional computer vision techniques. The
best performing architectures generally produced good enhancement compared to
the existing algorithm, showing that it is possible to use DNNs for document
image enhancement. Furthermore, the best performing architectures could work as
a baseline for future investigations on document enhancement using deep
learning techniques. The main contributions of this paper are: a baseline of
deep learning techniques that can be further improved to provide better
results, and a evaluation methodology using IQA metrics for quantitatively
comparing the produced images from the neural networks to a ground truth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Solar Potential of Rooftops using Image Segmentation and Structured Data. (arXiv:2106.15268v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soares_D/0/1/0/all/0/1">Daniel de Barros Soares</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Andrieux_F/0/1/0/all/0/1">Fran&#xe7;ois Andrieux</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Hell_B/0/1/0/all/0/1">Bastien Hell</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lenhardt_J/0/1/0/all/0/1">Julien Lenhardt</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Badosa_J/0/1/0/all/0/1">Jordi Badosa</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Gavoille_S/0/1/0/all/0/1">Sylvain Gavoille</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gaiffas_S/0/1/0/all/0/1">St&#xe9;phane Gaiffas</a> (1, 4 and 5), <a href="http://arxiv.org/find/cs/1/au:+Bacry_E/0/1/0/all/0/1">Emmanuel Bacry</a> (1 and 6), ((1) namR, Paris, France, (2) ENSTA Paris, France, (3) LMD, Ecole polytechnique, IP Paris, Palaiseau, France, (4) LPSM, Universit&#xe9; de Paris, France, (5) DMA, Ecole normale sup&#xe9;rieure, Paris, France, (6) CEREMADE, Universit&#xe9; Paris Dauphine, Paris, France)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15268">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating the amount of electricity that can be produced by rooftop
photovoltaic systems is a time-consuming process that requires on-site
measurements, a difficult task to achieve on a large scale. In this paper, we
present an approach to estimate the solar potential of rooftops based on their
location and architectural characteristics, as well as the amount of solar
radiation they receive annually. Our technique uses computer vision to achieve
semantic segmentation of roof sections and roof objects on the one hand, and a
machine learning model based on structured building features to predict roof
pitch on the other hand. We then compute the azimuth and maximum number of
solar panels that can be installed on a rooftop with geometric approaches.
Finally, we compute precise shading masks and combine them with solar
irradiation data that enables us to estimate the yearly solar potential of a
rooftop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open-Set Representation Learning through Combinatorial Embedding. (arXiv:2106.15278v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Geeho Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bohyung Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15278">
                                    <div class="article-summary-box-inner">
                                        <span>Visual recognition tasks are often limited to dealing with a small subset of
classes simply because the labels for the remaining classes are unavailable. We
are interested in identifying novel concepts in a dataset through
representation learning based on the examples in both labeled and unlabeled
classes, and extending the horizon of recognition to both known and novel
classes. To address this challenging task, we propose a combinatorial learning
approach, which naturally clusters the examples in unseen classes using the
compositional knowledge given by multiple supervised meta-classifiers on
heterogeneous label spaces. We also introduce a metric learning strategy to
estimate pairwise pseudo-labels for improving representations of unlabeled
examples, which preserves semantic relations across known and novel classes
effectively. The proposed algorithm discovers novel concepts via a joint
optimization of enhancing the discrimitiveness of unseen classes as well as
learning the representations of known classes generalizable to novel ones. Our
extensive experiments demonstrate remarkable performance gains by the proposed
approach in multiple image retrieval and novel class discovery benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating the Graph Gestalt: Kernel-Regularized Graph Representation Learning. (arXiv:2106.15239v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zahirnia_K/0/1/0/all/0/1">Kiarash Zahirnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakhuja_A/0/1/0/all/0/1">Ankita Sakhuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1">Oliver Schulte</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadaf_P/0/1/0/all/0/1">Parmis Nadaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15239">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work on graph generative models has made remarkable progress towards
generating increasingly realistic graphs, as measured by global graph features
such as degree distribution, density, and clustering coefficients. Deep
generative models have also made significant advances through better modelling
of the local correlations in the graph topology, which have been very useful
for predicting unobserved graph components, such as the existence of a link or
the class of a node, from nearby observed graph components. A complete
scientific understanding of graph data should address both global and local
structure. In this paper, we propose a joint model for both as complementary
objectives in a graph VAE framework. Global structure is captured by
incorporating graph kernels in a probabilistic model whose loss function is
closely related to the maximum mean discrepancy(MMD) between the global
structures of the reconstructed and the input graphs. The ELBO objective
derived from the model regularizes a standard local link reconstruction term
with an MMD term. Our experiments demonstrate a significant improvement in the
realism of the generated graph structures, typically by 1-2 orders of magnitude
of graph structure metrics, compared to leading graph VAEand GAN models. Local
link reconstruction improves as well in many cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Not Deceive Your Employer with a Virtual Background: A Video Conferencing Manipulation-Detection System. (arXiv:2106.15130v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1">Mauro Conti</a>, <a href="http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1">Simone Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1">Ehsan Nowroozi</a>, <a href="http://arxiv.org/find/cs/1/au:+Orazi_G/0/1/0/all/0/1">Gabriele Orazi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15130">
                                    <div class="article-summary-box-inner">
                                        <span>The last-generation video conferencing software allows users to utilize a
virtual background to conceal their personal environment due to privacy
concerns, especially in official meetings with other employers. On the other
hand, users maybe want to fool people in the meeting by considering the virtual
background to conceal where they are. In this case, developing tools to
understand the virtual background utilize for fooling people in meeting plays
an important role. Besides, such detectors must prove robust against different
kinds of attacks since a malicious user can fool the detector by applying a set
of adversarial editing steps on the video to conceal any revealing footprint.
In this paper, we study the feasibility of an efficient tool to detect whether
a videoconferencing user background is real. In particular, we provide the
first tool which computes pixel co-occurrences matrices and uses them to search
for inconsistencies among spectral and spatial bands. Our experiments confirm
that cross co-occurrences matrices improve the robustness of the detector
against different kinds of attacks. This work&#x27;s performance is especially
noteworthy with regard to color SPAM features. Moreover, the performance
especially is significant with regard to robustness versus post-processing,
like geometric transformations, filtering, contrast enhancement, and JPEG
compression with different quality factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modularity in Reinforcement Learning via Algorithmic Independence in Credit Assignment. (arXiv:2106.14993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Michael Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaushik_S/0/1/0/all/0/1">Sidhant Kaushik</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14993">
                                    <div class="article-summary-box-inner">
                                        <span>Many transfer problems require re-using previously optimal decisions for
solving new tasks, which suggests the need for learning algorithms that can
modify the mechanisms for choosing certain actions independently of those for
choosing others. However, there is currently no formalism nor theory for how to
achieve this kind of modular credit assignment. To answer this question, we
define modular credit assignment as a constraint on minimizing the algorithmic
mutual information among feedback signals for different decisions. We introduce
what we call the modularity criterion for testing whether a learning algorithm
satisfies this constraint by performing causal analysis on the algorithm
itself. We generalize the recently proposed societal decision-making framework
as a more granular formalism than the Markov decision process to prove that for
decision sequences that do not contain cycles, certain single-step temporal
difference action-value methods meet this criterion while all policy-gradient
methods do not. Empirical evidence suggests that such action-value methods are
more sample efficient than policy-gradient methods on transfer problems that
require only sparse changes to a sequence of previously optimal decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ElephantBook: A Semi-Automated Human-in-the-Loop System for Elephant Re-Identification. (arXiv:2106.15083v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulits_P/0/1/0/all/0/1">Peter Kulits</a>, <a href="http://arxiv.org/find/cs/1/au:+Wall_J/0/1/0/all/0/1">Jake Wall</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedetti_A/0/1/0/all/0/1">Anka Bedetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Henley_M/0/1/0/all/0/1">Michelle Henley</a>, <a href="http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1">Sara Beery</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15083">
                                    <div class="article-summary-box-inner">
                                        <span>African elephants are vital to their ecosystems, but their populations are
threatened by a rise in human-elephant conflict and poaching. Monitoring
population dynamics is essential in conservation efforts; however, tracking
elephants is a difficult task, usually relying on the invasive and sometimes
dangerous placement of GPS collars. Although there have been many recent
successes in the use of computer vision techniques for automated identification
of other species, identification of elephants is extremely difficult and
typically requires expertise as well as familiarity with elephants in the
population. We have built and deployed a web-based platform and database for
human-in-the-loop re-identification of elephants combining manual attribute
labeling and state-of-the-art computer vision algorithms, known as
ElephantBook. Our system is currently in use at the Mara Elephant Project,
helping monitor the protected and at-risk population of elephants in the
Greater Maasai Mara ecosystem. ElephantBook makes elephant re-identification
usable by non-experts and scalable for use by multiple conservation NGOs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Hypercomplex Embeddings for Link Prediction. (arXiv:2106.15230v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1">Caglar Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Moussallem_D/0/1/0/all/0/1">Diego Moussallem</a>, <a href="http://arxiv.org/find/cs/1/au:+Heindorf_S/0/1/0/all/0/1">Stefan Heindorf</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1">Axel-Cyrille Ngonga Ngomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15230">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge graph embedding research has mainly focused on the two smallest
normed division algebras, $\mathbb{R}$ and $\mathbb{C}$. Recent results suggest
that trilinear products of quaternion-valued embeddings can be a more effective
means to tackle link prediction. In addition, models based on convolutions on
real-valued embeddings often yield state-of-the-art results for link
prediction. In this paper, we investigate a composition of convolution
operations with hypercomplex multiplications. We propose the four approaches
QMult, OMult, ConvQ and ConvO to tackle the link prediction problem. QMult and
OMult can be considered as quaternion and octonion extensions of previous
state-of-the-art approaches, including DistMult and ComplEx. ConvQ and ConvO
build upon QMult and OMult by including convolution operations in a way
inspired by the residual learning framework. We evaluated our approaches on
seven link prediction datasets including WN18RR, FB15K-237 and YAGO3-10.
Experimental results suggest that the benefits of learning hypercomplex-valued
vector representations become more apparent as the size and complexity of the
knowledge graph grows. ConvO outperforms state-of-the-art approaches on
FB15K-237 in MRR, Hit@1 and Hit@3, while QMult, OMult, ConvQ and ConvO
outperform state-of-the-approaches on YAGO3-10 in all metrics. Results also
suggest that link prediction performances can be further improved via
prediction averaging. To foster reproducible research, we provide an
open-source implementation of approaches, including training and evaluation
scripts as well as pretrained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sample Selection for Robust Learning under Label Noise. (arXiv:2106.15292v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1">P.S. Sastry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15292">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have been shown to be susceptible to memorization
or overfitting in the presence of noisily labelled data. For the problem of
robust learning under such noisy data, several algorithms have been proposed. A
prominent class of algorithms rely on sample selection strategies, motivated by
curriculum learning. For example, many algorithms use the &#x60;small loss trick&#x27;
wherein a fraction of samples with loss values below a certain threshold are
selected for training. These algorithms are sensitive to such thresholds, and
it is difficult to fix or learn these thresholds. Often, these algorithms also
require information such as label noise rates which are typically unavailable
in practice. In this paper, we propose a data-dependent, adaptive sample
selection strategy that relies only on batch statistics of a given mini-batch
to provide robustness against label noise. The algorithm does not have any
additional hyperparameters for sample selection, does not need any information
on noise rates, and does not need access to separate data with clean labels. We
empirically demonstrate the effectiveness of our algorithm on benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Rates for Random Order Online Optimization. (arXiv:2106.15207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sherman_U/0/1/0/all/0/1">Uri Sherman</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15207">
                                    <div class="article-summary-box-inner">
                                        <span>We study online convex optimization in the random order model, recently
proposed by \citet{garber2020online}, where the loss functions may be chosen by
an adversary, but are then presented to the online algorithm in a uniformly
random order. Focusing on the scenario where the cumulative loss function is
(strongly) convex, yet individual loss functions are smooth but might be
non-convex, we give algorithms that achieve the optimal bounds and
significantly outperform the results of \citet{garber2020online}, completely
removing the dimension dependence and improving their scaling with respect to
the strong convexity parameter. Our analysis relies on novel connections
between algorithmic stability and generalization for sampling
without-replacement analogous to those studied in the with-replacement
i.i.d.~setting, as well as on a refined average stability analysis of
stochastic gradient descent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Majorization-Minimization for Nonnegative Matrix Factorization with the $\beta$-divergence. (arXiv:2106.15214v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marmin_A/0/1/0/all/0/1">Arthur Marmin</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulart_J/0/1/0/all/0/1">Jos&#xe9; Henrique de Morais Goulart</a>, <a href="http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1">C&#xe9;dric F&#xe9;votte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15214">
                                    <div class="article-summary-box-inner">
                                        <span>This article proposes new multiplicative updates for nonnegative matrix
factorization (NMF) with the $\beta$-divergence objective function. Our new
updates are derived from a joint majorization-minimization (MM) scheme, in
which an auxiliary function (a tight upper bound of the objective function) is
built for the two factors jointly and minimized at each iteration. This is in
contrast with the classic approach in which the factors are optimized
alternately and a MM scheme is applied to each factor individually. Like the
classic approach, our joint MM algorithm also results in multiplicative updates
that are simple to implement. They however yield a significant drop of
computation time (for equally good solutions), in particular for some
$\beta$-divergences of important applicative interest, such as the squared
Euclidean distance and the Kullback-Leibler or Itakura-Saito divergences. We
report experimental results using diverse datasets: face images, audio
spectrograms, hyperspectral data and song play counts. Depending on the value
of $\beta$ and on the dataset, our joint MM approach yields a CPU time
reduction of about $10\%$ to $78\%$ in comparison to the classic alternating
scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Static Models for Link Prediction in Temporal Knowledge Graphs. (arXiv:2106.15223v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radstok_W/0/1/0/all/0/1">Wessel Radstok</a>, <a href="http://arxiv.org/find/cs/1/au:+Chekol_M/0/1/0/all/0/1">Mel Chekol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15223">
                                    <div class="article-summary-box-inner">
                                        <span>The inclusion of temporal scopes of facts in knowledge graph embedding (KGE)
presents significant opportunities for improving the resulting embeddings, and
consequently for increased performance in downstream applications. Yet, little
research effort has focussed on this area and much of the carried out research
reports only marginally improved results compared to models trained without
temporal scopes (static models). Furthermore, rather than leveraging existing
work on static models, they introduce new models specific to temporal knowledge
graphs. We propose a novel perspective that takes advantage of the power of
existing static embedding models by focussing effort on manipulating the data
instead. Our method, SpliMe, draws inspiration from the field of signal
processing and early work in graph embedding. We show that SpliMe competes with
or outperforms the current state of the art in temporal KGE. Additionally, we
uncover issues with the procedure currently used to assess the performance of
static models on temporal graphs and introduce two ways to counteract them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Reach Real-Time AI on Consumer Devices? Solutions for Programmable and Custom Architectures. (arXiv:2106.15021v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1">Ioannis Panopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1">Ilias Leontiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1">Iakovos S. Venieris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15021">
                                    <div class="article-summary-box-inner">
                                        <span>The unprecedented performance of deep neural networks (DNNs) has led to large
strides in various Artificial Intelligence (AI) inference tasks, such as object
and speech recognition. Nevertheless, deploying such AI models across commodity
devices faces significant challenges: large computational cost, multiple
performance objectives, hardware heterogeneity and a common need for high
accuracy, together pose critical problems to the deployment of DNNs across the
various embedded and mobile devices in the wild. As such, we have yet to
witness the mainstream usage of state-of-the-art deep learning algorithms
across consumer devices. In this paper, we provide preliminary answers to this
potentially game-changing question by presenting an array of design techniques
for efficient AI systems. We start by examining the major roadblocks when
targeting both programmable processors and custom accelerators. Then, we
present diverse methods for achieving real-time performance following a
cross-stack approach. These span model-, system- and hardware-level techniques,
and their combination. Our findings provide illustrative examples of AI systems
that do not overburden mobile hardware, while also indicating how they can
improve inference accuracy. Moreover, we showcase how custom ASIC- and
FPGA-based accelerators can be an enabling factor for next-generation AI
applications, such as multi-DNN systems. Collectively, these results highlight
the critical need for further exploration as to how the various cross-stack
solutions can be best combined in order to bring the latest advances in deep
learning close to users, in a robust and efficient manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">INN: A Method Identifying Clean-annotated Samples via Consistency Effect in Deep Neural Networks. (arXiv:2106.15185v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yongchan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kunwoong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yongdai Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15185">
                                    <div class="article-summary-box-inner">
                                        <span>In many classification problems, collecting massive clean-annotated data is
not easy, and thus a lot of researches have been done to handle data with noisy
labels. Most recent state-of-art solutions for noisy label problems are built
on the small-loss strategy which exploits the memorization effect. While it is
a powerful tool, the memorization effect has several drawbacks. The
performances are sensitive to the choice of a training epoch required for
utilizing the memorization effect. In addition, when the labels are heavily
contaminated or imbalanced, the memorization effect may not occur in which case
the methods based on the small-loss strategy fail to identify clean labeled
data. We introduce a new method called INN(Integration with the Nearest
Neighborhoods) to refine clean labeled data from training data with noisy
labels. The proposed method is based on a new discovery that a prediction
pattern at neighbor regions of clean labeled data is consistently different
from that of noisy labeled data regardless of training epochs. The INN method
requires more computation but is much stable and powerful than the small-loss
strategy. By carrying out various experiments, we demonstrate that the INN
method resolves the shortcomings in the memorization effect successfully and
thus is helpful to construct more accurate deep prediction models with training
data with noisy labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Explanations for Arbitrary Regression Models. (arXiv:2106.15212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spooner_T/0/1/0/all/0/1">Thomas Spooner</a>, <a href="http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1">Danial Dervovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1">Jason Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Shepard_J/0/1/0/all/0/1">Jon Shepard</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1">Daniele Magazzeni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15212">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new method for counterfactual explanations (CFEs) based on
Bayesian optimisation that applies to both classification and regression
models. Our method is a globally convergent search algorithm with support for
arbitrary regression models and constraints like feature sparsity and
actionable recourse, and furthermore can answer multiple counterfactual
questions in parallel while learning from previous queries. We formulate CFE
search for regression models in a rigorous mathematical framework using
differentiable potentials, which resolves robustness issues in threshold-based
objectives. We prove that in this framework, (a) verifying the existence of
counterfactuals is NP-complete; and (b) that finding instances using such
potentials is CLS-complete. We describe a unified algorithm for CFEs using a
specialised acquisition function that composes both expected improvement and an
exponential-polynomial (EP) family with desirable properties. Our evaluation on
real-world benchmark domains demonstrate high sample-efficiency and precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Distributed Optimization With Randomly Corrupted Gradients. (arXiv:2106.14956v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Turan_B/0/1/0/all/0/1">Berkay Turan</a>, <a href="http://arxiv.org/find/math/1/au:+Uribe_C/0/1/0/all/0/1">Cesar A. Uribe</a>, <a href="http://arxiv.org/find/math/1/au:+Wai_H/0/1/0/all/0/1">Hoi-To Wai</a>, <a href="http://arxiv.org/find/math/1/au:+Alizadeh_M/0/1/0/all/0/1">Mahnoosh Alizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14956">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a first-order distributed optimization algorithm
that is provably robust to Byzantine failures-arbitrary and potentially
adversarial behavior, where all the participating agents are prone to failure.
We model each agent&#x27;s state over time as a two-state Markov chain that
indicates Byzantine or trustworthy behaviors at different time instants. We set
no restrictions on the maximum number of Byzantine agents at any given time. We
design our method based on three layers of defense: 1) Temporal gradient
averaging, 2) robust aggregation, and 3) gradient normalization. We study two
settings for stochastic optimization, namely Sample Average Approximation and
Stochastic Approximation, and prove that for strongly convex and smooth
non-convex cost functions, our algorithm achieves order-optimal statistical
error and convergence rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning for plant microRNA prediction: A systematic review. (arXiv:2106.15159v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Jayasundara_S/0/1/0/all/0/1">Shyaman Jayasundara</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lokuge_S/0/1/0/all/0/1">Sandali Lokuge</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ihalagedara_P/0/1/0/all/0/1">Puwasuru Ihalagedara</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Herath_D/0/1/0/all/0/1">Damayanthi Herath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15159">
                                    <div class="article-summary-box-inner">
                                        <span>MicroRNAs (miRNAs) are endogenous small non-coding RNAs that play an
important role in post-transcriptional gene regulation. However, the
experimental determination of miRNA sequence and structure is both expensive
and time-consuming. Therefore, computational and machine learning-based
approaches have been adopted to predict novel microRNAs. With the involvement
of data science and machine learning in biology, multiple research studies have
been conducted to find microRNAs with different computational methods and
different miRNA features. Multiple approaches are discussed in detail
considering the learning algorithm/s used, features considered, dataset/s used
and the criteria used in evaluations. This systematic review focuses on the
machine learning methods developed for miRNA identification in plants. This
will help researchers to gain a detailed idea about past studies and identify
novel paths that solve drawbacks occurred in past studies. Our findings
highlight the need for plant-specific computational methods for miRNA
identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding the Effectiveness of Attention Mechanism. (arXiv:2106.15067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15067">
                                    <div class="article-summary-box-inner">
                                        <span>Attention Mechanism is a widely used method for improving the performance of
convolutional neural networks (CNNs) on computer vision tasks. Despite its
pervasiveness, we have a poor understanding of what its effectiveness stems
from. It is popularly believed that its effectiveness stems from the visual
attention explanation, advocating focusing on the important part of input data
rather than ingesting the entire input. In this paper, we find that there is
only a weak consistency between the attention weights of features and their
importance. Instead, we verify the crucial role of feature map multiplication
in attention mechanism and uncover a fundamental impact of feature map
multiplication on the learned landscapes of CNNs: with the high order
non-linearity brought by the feature map multiplication, it played a
regularization role on CNNs, which made them learn smoother and more stable
landscapes near real samples compared to vanilla CNNs. This smoothness and
stability induce a more predictive and stable behavior in-between real samples,
and make CNNs generate better. Moreover, motivated by the proposed
effectiveness of feature map multiplication, we design feature map
multiplication network (FMMNet) by simply replacing the feature map addition in
ResNet with feature map multiplication. FMMNet outperforms ResNet on various
datasets, and this indicates that feature map multiplication plays a vital role
in improving the performance even without finely designed attention mechanism
in existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TUCaN: Progressively Teaching Colourisation to Capsules. (arXiv:2106.15176v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pucci_R/0/1/0/all/0/1">Rita Pucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinel_N/0/1/0/all/0/1">Niki Martinel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15176">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic image colourisation is the computer vision research path that
studies how to colourise greyscale images (for restoration). Deep learning
techniques improved image colourisation yielding astonishing results. These
differ by various factors, such as structural differences, input types, user
assistance, etc. Most of them, base the architectural structure on
convolutional layers with no emphasis on layers specialised in object features
extraction. We introduce a novel downsampling upsampling architecture named
TUCaN (Tiny UCapsNet) that exploits the collaboration of convolutional layers
and capsule layers to obtain a neat colourisation of entities present in every
single image. This is obtained by enforcing collaboration among such layers by
skip and residual connections. We pose the problem as a per pixel colour
classification task that identifies colours as a bin in a quantized space. To
train the network, in contrast with the standard end to end learning method, we
propose the progressive learning scheme to extract the context of objects by
only manipulating the learning process without changing the model. In this
scheme, the upsampling starts from the reconstruction of low resolution images
and progressively grows to high resolution images throughout the training
phase. Experimental results on three benchmark datasets show that our approach
with ImageNet10k dataset outperforms existing methods on standard quality
metrics and achieves state of the art performances on image colourisation. We
performed a user study to quantify the perceptual realism of the colourisation
results demonstrating: that progressive learning let the TUCaN achieve better
colours than the end to end scheme; and pointing out the limitations of the
existing evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-domain error minimization for unsupervised domain adaptation. (arXiv:2106.15057v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yuntao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_F/0/1/0/all/0/1">Fengli Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaowen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chongjun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15057">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation aims to transfer knowledge from a labeled
source domain to an unlabeled target domain. Previous methods focus on learning
domain-invariant features to decrease the discrepancy between the feature
distributions as well as minimizing the source error and have made remarkable
progress. However, a recently proposed theory reveals that such a strategy is
not sufficient for a successful domain adaptation. It shows that besides a
small source error, both the discrepancy between the feature distributions and
the discrepancy between the labeling functions should be small across domains.
The discrepancy between the labeling functions is essentially the cross-domain
errors which are ignored by existing methods. To overcome this issue, in this
paper, a novel method is proposed to integrate all the objectives into a
unified optimization framework. Moreover, the incorrect pseudo labels widely
used in previous methods can lead to error accumulation during learning. To
alleviate this problem, the pseudo labels are obtained by utilizing structural
information of the target domain besides source classifier and we propose a
curriculum learning based strategy to select the target samples with more
accurate pseudo-labels during training. Comprehensive experiments are
conducted, and the results validate that our approach outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FastPitchFormant: Source-filter based Decomposed Modeling for Speech Synthesis. (arXiv:2106.15123v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bak_T/0/1/0/all/0/1">Taejun Bak</a>, <a href="http://arxiv.org/find/eess/1/au:+Bae_J/0/1/0/all/0/1">Jae-Sung Bae</a>, <a href="http://arxiv.org/find/eess/1/au:+Bae_H/0/1/0/all/0/1">Hanbin Bae</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1">Young-Ik Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_H/0/1/0/all/0/1">Hoon-Young Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15123">
                                    <div class="article-summary-box-inner">
                                        <span>Methods for modeling and controlling prosody with acoustic features have been
proposed for neural text-to-speech (TTS) models. Prosodic speech can be
generated by conditioning acoustic features. However, synthesized speech with a
large pitch-shift scale suffers from audio quality degradation, and speaker
characteristics deformation. To address this problem, we propose a feed-forward
Transformer based TTS model that is designed based on the source-filter theory.
This model, called FastPitchFormant, has a unique structure that handles text
and acoustic features in parallel. With modeling each feature separately, the
tendency that the model learns the relationship between two features can be
mitigated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructing Forest Biomass Prediction Maps from Radar Backscatter by Sequential Regression with a Conditional Generative Adversarial Network. (arXiv:2106.15020v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bjork_S/0/1/0/all/0/1">Sara Bj&#xf6;rk</a>, <a href="http://arxiv.org/find/cs/1/au:+Anfinsen_S/0/1/0/all/0/1">Stian Normann Anfinsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Naesset_E/0/1/0/all/0/1">Erik N&#xe6;sset</a>, <a href="http://arxiv.org/find/cs/1/au:+Gobakken_T/0/1/0/all/0/1">Terje Gobakken</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahabu_E/0/1/0/all/0/1">Eliakimu Zahabu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15020">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies construction of above-ground biomass (AGB) prediction maps
from synthetic aperture radar (SAR) intensity images. The purpose is to improve
traditional regression models based on SAR intensity, trained with a limited
amount of AGB in situ measurements. Although it is costly to collect, data from
airborne laser scanning (ALS) sensors are highly correlated with AGB.
Therefore, we propose using AGB predictions based on ALS data as surrogate
response variables for SAR data in a sequential modelling fashion. This
increases the amount of training data dramatically. To model the regression
function between SAR intensity and ALS-predicted AGB we propose to utilise a
conditional generative adversarial network (cGAN), i.e. the Pix2Pix
convolutional neural network. This enables the recreation of existing ALS-based
AGB prediction maps. The generated synthesised ALS-based AGB predictions are
evaluated qualitatively and quantitatively against ALS-based AGB predictions
retrieved from a traditional non-sequential regression model trained in the
same area. Results show that the proposed architecture manages to capture
characteristics of the actual data. This suggests that the use of ALS-guided
generative models is a promising avenue for AGB prediction from SAR intensity.
Further research on this area has the potential of providing both large-scale
and low-cost predictions of AGB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Generalisable Deep Inertial Tracking via Geometry-Aware Learning. (arXiv:2106.15178v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alloulah_M/0/1/0/all/0/1">Mohammed Alloulah</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1">Maximilian Arnold</a>, <a href="http://arxiv.org/find/cs/1/au:+Isopoussu_A/0/1/0/all/0/1">Anton Isopoussu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15178">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous navigation in uninstrumented and unprepared environments is a
fundamental demand for next generation indoor and outdoor location-based
services. To bring about such ambition, a suite of collaborative sensing
modalities is required in order to sustain performance irrespective of
challenging dynamic conditions. Of the many modalities on offer, inertial
tracking plays a key role under momentary unfavourable operational conditions
owing to its independence of the surrounding environment. However, inertial
tracking has traditionally (i) suffered from excessive error growth and (ii)
required extensive and cumbersome tuning. Both of these issues have limited the
appeal and utility of inertial tracking. In this paper, we present DIT: a novel
Deep learning Inertial Tracking system that overcomes prior limitations;
namely, by (i) significantly reducing tracking drift and (ii) seamlessly
constructing robust and generalisable learned models. DIT describes two core
contributions: (i) DIT employs a robotic platform augmented with a mechanical
slider subsystem that automatically samples inertial signal variabilities
arising from different sensor mounting geometries. We use the platform to
curate in-house a 7.2 million sample dataset covering an aggregate distance of
21 kilometres split into 11 indexed sensor mounting geometries. (ii) DIT uses
deep learning, optimal transport, and domain adaptation (DA) to create a model
which is robust to variabilities in sensor mounting geometry. The overall
system synthesises high-performance and generalisable inertial navigation
models in an end-to-end, robotic-learning fashion. In our evaluation, DIT
outperforms an industrial-grade sensor fusion baseline by 10x (90th percentile)
and a state-of-the-art adversarial DA technique by &gt; 2.5x in performance (90th
percentile) and &gt;10x in training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Test-Time Adaptation to Distribution Shift by Confidence Maximization and Input Transformation. (arXiv:2106.14999v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mummadi_C/0/1/0/all/0/1">Chaithanya Kumar Mummadi</a>, <a href="http://arxiv.org/find/stat/1/au:+Hutmacher_R/0/1/0/all/0/1">Robin Hutmacher</a>, <a href="http://arxiv.org/find/stat/1/au:+Rambach_K/0/1/0/all/0/1">Kilian Rambach</a>, <a href="http://arxiv.org/find/stat/1/au:+Levinkov_E/0/1/0/all/0/1">Evgeny Levinkov</a>, <a href="http://arxiv.org/find/stat/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>, <a href="http://arxiv.org/find/stat/1/au:+Metzen_J/0/1/0/all/0/1">Jan Hendrik Metzen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14999">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks often exhibit poor performance on data that is unlikely
under the train-time data distribution, for instance data affected by
corruptions. Previous works demonstrate that test-time adaptation to data
shift, for instance using entropy minimization, effectively improves
performance on such shifted distributions. This paper focuses on the fully
test-time adaptation setting, where only unlabeled data from the target
distribution is required. This allows adapting arbitrary pretrained networks.
Specifically, we propose a novel loss that improves test-time adaptation by
addressing both premature convergence and instability of entropy minimization.
This is achieved by replacing the entropy by a non-saturating surrogate and
adding a diversity regularizer based on batch-wise entropy maximization that
prevents convergence to trivial collapsed solutions. Moreover, we propose to
prepend an input transformation module to the network that can partially undo
test-time distribution shifts. Surprisingly, this preprocessing can be learned
solely using the fully test-time adaptation loss in an end-to-end fashion
without any target domain labels or source domain data. We show that our
approach outperforms previous work in improving the robustness of publicly
available pretrained image classifiers to common corruptions on such
challenging benchmarks as ImageNet-C.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Achieving Statistical Optimality of Federated Learning: Beyond Stationary Points. (arXiv:2106.15216v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Su_L/0/1/0/all/0/1">Lili Su</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jiaming Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_P/0/1/0/all/0/1">Pengkun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15216">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) is a promising framework that has great potentials in
privacy preservation and in lowering the computation load at the cloud. FedAvg
and FedProx are two widely adopted algorithms. However, recent work raised
concerns on these two methods: (1) their fixed points do not correspond to the
stationary points of the original optimization problem, and (2) the common
model found might not generalize well locally.

In this paper, we alleviate these concerns. Towards this, we adopt the
statistical learning perspective yet allow the distributions to be
heterogeneous and the local data to be unbalanced. We show, in the general
kernel regression setting, that both FedAvg and FedProx converge to the
minimax-optimal error rates. Moreover, when the kernel function has a finite
rank, the convergence is exponentially fast. Our results further analytically
quantify the impact of the model heterogeneity and characterize the federation
gain - the reduction of the estimation error for a worker to join the federated
learning compared to the best local estimator. To the best of our knowledge, we
are the first to show the achievability of minimax error rates under FedAvg and
FedProx, and the first to characterize the gains in joining FL. Numerical
experiments further corroborate our theoretical findings on the statistical
optimality of FedAvg and FedProx and the federation gains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis. (arXiv:2106.15153v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1">Jinhyeok Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Bae_J/0/1/0/all/0/1">Jae-Sung Bae</a>, <a href="http://arxiv.org/find/eess/1/au:+Bak_T/0/1/0/all/0/1">Taejun Bak</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1">Youngik Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_H/0/1/0/all/0/1">Hoon-Young Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15153">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in neural multi-speaker text-to-speech (TTS) models have
enabled the generation of reasonably good speech quality with a single model
and made it possible to synthesize the speech of a speaker with limited
training data. Fine-tuning to the target speaker data with the multi-speaker
model can achieve better quality, however, there still exists a gap compared to
the real speech sample and the model depends on the speaker. In this work, we
propose GANSpeech, which is a high-fidelity multi-speaker TTS model that adopts
the adversarial training method to a non-autoregressive multi-speaker TTS
model. In addition, we propose simple but efficient automatic scaling methods
for feature matching loss used in adversarial training. In the subjective
listening tests, GANSpeech significantly outperformed the baseline
multi-speaker FastSpeech and FastSpeech2 models, and showed a better MOS score
than the speaker-specific fine-tuned FastSpeech2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent. (arXiv:2106.15023v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bryniarski_O/0/1/0/all/0/1">Oliver Bryniarski</a>, <a href="http://arxiv.org/find/cs/1/au:+Hingun_N/0/1/0/all/0/1">Nabeel Hingun</a>, <a href="http://arxiv.org/find/cs/1/au:+Pachuca_P/0/1/0/all/0/1">Pedro Pachuca</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_V/0/1/0/all/0/1">Vincent Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15023">
                                    <div class="article-summary-box-inner">
                                        <span>Evading adversarial example detection defenses requires finding adversarial
examples that must simultaneously (a) be misclassified by the model and (b) be
detected as non-adversarial. We find that existing attacks that attempt to
satisfy multiple simultaneous constraints often over-optimize against one
constraint at the cost of satisfying another. We introduce Orthogonal Projected
Gradient Descent, an improved attack technique to generate adversarial examples
that avoids this problem by orthogonalizing the gradients when running standard
gradient-based attacks. We use our technique to evade four state-of-the-art
detection defenses, reducing their accuracy to 0% while maintaining a 0%
detection rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Mobility Recognition for Intensive Care Unit Patients Using Accelerometers. (arXiv:2106.15017v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rex Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazio_S/0/1/0/all/0/1">Sarina A Fazio</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanle Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramli_A/0/1/0/all/0/1">Albara Ah Ramli</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_J/0/1/0/all/0/1">Jason Yeates Adams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15017">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of the Internet of Things(IoT) and Artificial
Intelligence(AI) technologies, human activity recognition has enabled various
applications, such as smart homes and assisted living. In this paper, we target
a new healthcare application of human activity recognition, early mobility
recognition for Intensive Care Unit(ICU) patients. Early mobility is essential
for ICU patients who suffer from long-time immobilization. Our system includes
accelerometer-based data collection from ICU patients and an AI model to
recognize patients&#x27; early mobility. To improve the model accuracy and
stability, we identify features that are insensitive to sensor orientations and
propose a segment voting process that leverages a majority voting strategy to
recognize each segment&#x27;s activity. Our results show that our system improves
model accuracy from 77.78\% to 81.86\% and reduces the model instability
(standard deviation) from 16.69\% to 6.92\%, compared to the same AI model
without our feature engineering and segment voting process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FallDeF5: A Fall Detection Framework Using 5G-based Deep Gated Recurrent Unit Networks. (arXiv:2106.15049v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Rakhami_M/0/1/0/all/0/1">Mabrook S. Al-Rakhami</a>, <a href="http://arxiv.org/find/cs/1/au:+Gumaei1_A/0/1/0/all/0/1">Abdu Gumaei1</a>, <a href="http://arxiv.org/find/cs/1/au:+Altaf_M/0/1/0/all/0/1">Meteb Altaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1">Mohammad Mehedi Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alkhamees_B/0/1/0/all/0/1">Bader Fahad Alkhamees</a>, <a href="http://arxiv.org/find/cs/1/au:+Muhammad_K/0/1/0/all/0/1">Khan Muhammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortino_G/0/1/0/all/0/1">Giancarlo Fortino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15049">
                                    <div class="article-summary-box-inner">
                                        <span>Fall prevalence is high among elderly people, which is challenging due to the
severe consequences of falling. This is why rapid assistance is a critical
task. Ambient assisted living (AAL) uses recent technologies such as 5G
networks and the internet of medical things (IoMT) to address this research
area. Edge computing can reduce the cost of cloud communication, including high
latency and bandwidth use, by moving conventional healthcare services and
applications closer to end-users. Artificial intelligence (AI) techniques such
as deep learning (DL) have been used recently for automatic fall detection, as
well as supporting healthcare services. However, DL requires a vast amount of
data and substantial processing power to improve its performance for the IoMT
linked to the traditional edge computing environment. This research proposes an
effective fall detection framework based on DL algorithms and mobile edge
computing (MEC) within 5G wireless networks, the aim being to empower
IoMT-based healthcare applications. We also propose the use of a deep gated
recurrent unit (DGRU) neural network to improve the accuracy of existing
DL-based fall detection methods. DGRU has the advantage of dealing with
time-series IoMT data, and it can reduce the number of parameters and avoid the
vanishing gradient problem. The experimental results on two public datasets
show that the DGRU model of the proposed framework achieves higher accuracy
rates compared to the current related works on the same datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Characterization of the Variation Spaces Corresponding to Shallow Neural Networks. (arXiv:2106.15002v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1">Jonathan W. Siegel</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jinchao Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15002">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the variation space corresponding to a dictionary of functions in
$L^2(\Omega)$ and present the basic theory of approximation in these spaces.
Specifically, we compare the definition based on integral representations with
the definition in terms of convex hulls. We show that in many cases, including
the dictionaries corresponding to shallow ReLU$^k$ networks and a dictionary of
decaying Fourier modes, that the two definitions coincide. We also give a
partial characterization of the variation space for shallow ReLU$^k$ networks
and show that the variation space with respect to the dictionary of decaying
Fourier modes corresponds to the Barron spectral space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Dynamic Spectrum Access. (arXiv:2106.14976v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Song_Y/0/1/0/all/0/1">Yifei Song</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_H/0/1/0/all/0/1">Hao-Hsuan Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_Z/0/1/0/all/0/1">Zhou Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Jere_S/0/1/0/all/0/1">Shashank Jere</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_L/0/1/0/all/0/1">Lingjia Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14976">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the growing volume of data traffic produced by the surge of Internet
of Things (IoT) devices, the demand for radio spectrum resources is approaching
their limitation defined by Federal Communications Commission (FCC). To this
end, Dynamic Spectrum Access (DSA) is considered as a promising technology to
handle this spectrum scarcity. However, standard DSA techniques often rely on
analytical modeling wireless networks, making its application intractable in
under-measured network environments. Therefore, utilizing neural networks to
approximate the network dynamics is an alternative approach. In this article,
we introduce a Federated Learning (FL) based framework for the task of DSA,
where FL is a distributive machine learning framework that can reserve the
privacy of network terminals under heterogeneous data distributions. We discuss
the opportunities, challenges, and opening problems of this framework. To
evaluate its feasibility, we implement a Multi-Agent Reinforcement Learning
(MARL)-based FL as a realization associated with its initial evaluation
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Training of Neural Lumigraph Representations using Meta Learning. (arXiv:2106.14942v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bergman_A/0/1/0/all/0/1">Alexander W. Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kellnhofer_P/0/1/0/all/0/1">Petr Kellnhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wetzstein_G/0/1/0/all/0/1">Gordon Wetzstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14942">
                                    <div class="article-summary-box-inner">
                                        <span>Novel view synthesis is a long-standing problem in machine learning and
computer vision. Significant progress has recently been made in developing
neural scene representations and rendering techniques that synthesize
photorealistic images from arbitrary views. These representations, however, are
extremely slow to train and often also slow to render. Inspired by neural
variants of image-based rendering, we develop a new neural rendering approach
with the goal of quickly learning a high-quality representation which can also
be rendered in real-time. Our approach, MetaNLR++, accomplishes this by using a
unique combination of a neural shape representation and 2D CNN-based image
feature extraction, aggregation, and re-projection. To push representation
convergence times down to minutes, we leverage meta learning to learn neural
shape and image feature priors which accelerate training. The optimized shape
and image features can then be extracted using traditional graphics techniques
and rendered in real time. We show that MetaNLR++ achieves similar or better
novel view synthesis results in a fraction of the time that competing methods
require.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction. (arXiv:2106.15013v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stoger_D/0/1/0/all/0/1">Dominik St&#xf6;ger</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1">Mahdi Soltanolkotabi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15013">
                                    <div class="article-summary-box-inner">
                                        <span>Recently there has been significant theoretical progress on understanding the
convergence and generalization of gradient-based methods on nonconvex losses
with overparameterized models. Nevertheless, many aspects of optimization and
generalization and in particular the critical role of small random
initialization are not fully understood. In this paper, we take a step towards
demystifying this role by proving that small random initialization followed by
a few iterations of gradient descent behaves akin to popular spectral methods.
We also show that this implicit spectral bias from small random initialization,
which is provably more prominent for overparameterized models, also puts the
gradient descent iterations on a particular trajectory towards solutions that
are not only globally optimal but also generalize well. Concretely, we focus on
the problem of reconstructing a low-rank matrix from a few measurements via a
natural nonconvex formulation. In this setting, we show that the trajectory of
the gradient descent iterations from small random initialization can be
approximately decomposed into three phases: (I) a spectral or alignment phase
where we show that that the iterates have an implicit spectral bias akin to
spectral initialization allowing us to show that at the end of this phase the
column space of the iterates and the underlying low-rank matrix are
sufficiently aligned, (II) a saddle avoidance/refinement phase where we show
that the trajectory of the gradient iterates moves away from certain degenerate
saddle points, and (III) a local refinement phase where we show that after
avoiding the saddles the iterates converge quickly to the underlying low-rank
matrix. Underlying our analysis are insights for the analysis of
overparameterized nonconvex optimization schemes that may have implications for
computational problems beyond low-rank reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Transferability of Adversarial Patches on Face Recognition with Generative Models. (arXiv:2106.15058v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zihao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chilin Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15058">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition is greatly improved by deep convolutional neural networks
(CNNs). Recently, these face recognition models have been used for identity
authentication in security sensitive applications. However, deep CNNs are
vulnerable to adversarial patches, which are physically realizable and
stealthy, raising new security concerns on the real-world applications of these
models. In this paper, we evaluate the robustness of face recognition models
using adversarial patches based on transferability, where the attacker has
limited accessibility to the target models. First, we extend the existing
transfer-based attack techniques to generate transferable adversarial patches.
However, we observe that the transferability is sensitive to initialization and
degrades when the perturbation magnitude is large, indicating the overfitting
to the substitute models. Second, we propose to regularize the adversarial
patches on the low dimensional data manifold. The manifold is represented by
generative models pre-trained on legitimate human face images. Using face-like
features as adversarial perturbations through optimization on the manifold, we
show that the gaps between the responses of substitute models and the target
models dramatically decrease, exhibiting a better transferability. Extensive
digital world experiments are conducted to demonstrate the superiority of the
proposed method in the black-box setting. We apply the proposed method in the
physical world as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attaining entropy production and dissipation maps from Brownian movies via neural networks. (arXiv:2106.15108v1 [cond-mat.stat-mech])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Bae_Y/0/1/0/all/0/1">Youngkyoung Bae</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kim_D/0/1/0/all/0/1">Dong-Kyum Kim</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Jeong_H/0/1/0/all/0/1">Hawoong Jeong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15108">
                                    <div class="article-summary-box-inner">
                                        <span>Quantifying entropy production (EP) is essential to understand stochastic
systems at mesoscopic scales, such as living organisms or biological
assemblies. However, without tracking the relevant variables, it is challenging
to figure out where and to what extent EP occurs from recorded time-series
image data from experiments. Here, applying a convolutional neural network
(CNN), a powerful tool for image processing, we develop an estimation method
for EP through an unsupervised learning algorithm that calculates only from
movies. Together with an attention map of the CNN&#x27;s last layer, our method can
not only quantify stochastic EP but also produce the spatiotemporal pattern of
the EP (dissipation map). We show that our method accurately measures the EP
and creates a dissipation map in two nonequilibrium systems, the bead-spring
model and a network of elastic filaments. We further confirm high performance
even with noisy, low spatial resolution data, and partially observed
situations. Our method will provide a practical way to obtain dissipation maps
and ultimately contribute to uncovering the nonequilibrium nature of complex
systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Estimation and Coverage Control with Heterogeneous Sensing Information. (arXiv:2106.14984v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McDonald_A/0/1/0/all/0/1">Andrew McDonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lai Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1">Vaibhav Srivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14984">
                                    <div class="article-summary-box-inner">
                                        <span>Heterogeneous multi-robot sensing systems are able to characterize physical
processes more comprehensively than homogeneous systems. Access to multiple
modalities of sensory data allow such systems to fuse information between
complementary sources and learn richer representations of a phenomenon of
interest. Often, these data are correlated but vary in fidelity, i.e., accuracy
(bias) and precision (noise). Low-fidelity data may be more plentiful, while
high-fidelity data may be more trustworthy. In this paper, we address the
problem of multi-robot online estimation and coverage control by combining low-
and high-fidelity data to learn and cover a sensory function of interest. We
propose two algorithms for this task of heterogeneous learning and coverage --
namely Stochastic Sequencing of Multi-fidelity Learning and Coverage (SMLC) and
Deterministic Sequencing of Multi-fidelity Learning and Coverage (DMLC) -- and
prove that they converge asymptotically. In addition, we demonstrate the
empirical efficacy of SMLC and DMLC through numerical simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On component interactions in two-stage recommender systems. (arXiv:2106.14979v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hron_J/0/1/0/all/0/1">Jiri Hron</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauth_K/0/1/0/all/0/1">Karl Krauth</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1">Niki Kilbertus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14979">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to their scalability, two-stage recommenders are used by many of
today&#x27;s largest online platforms, including YouTube, LinkedIn, and Pinterest.
These systems produce recommendations in two steps: (i) multiple nominators --
tuned for low prediction latency -- preselect a small subset of candidates from
the whole item pool; (ii)~a slower but more accurate ranker further narrows
down the nominated items, and serves to the user. Despite their popularity, the
literature on two-stage recommenders is relatively scarce, and the algorithms
are often treated as the sum of their parts. Such treatment presupposes that
the two-stage performance is explained by the behavior of individual components
if they were deployed independently. This is not the case: using synthetic and
real-world data, we demonstrate that interactions between the ranker and the
nominators substantially affect the overall performance. Motivated by these
findings, we derive a generalization lower bound which shows that careful
choice of each nominator&#x27;s training set is sometimes the only difference
between a poor and an optimal two-stage recommender. Since searching for a good
choice manually is difficult, we learn one instead. In particular, using a
Mixture-of-Experts approach, we train the nominators (experts) to specialize on
different subsets of the item pool. This significantly improves performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sharp Lower Bounds on the Approximation Rate of Shallow Neural Networks. (arXiv:2106.14997v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1">Jonathan W. Siegel</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1">Jinchao Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14997">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the approximation rates of shallow neural networks with respect
to the variation norm. Upper bounds on these rates have been established for
sigmoidal and ReLU activation functions, but it has remained an important open
problem whether these rates are sharp. In this article, we provide a solution
to this problem by proving sharp lower bounds on the approximation rates for
shallow neural networks, which are obtained by lower bounding the $L^2$-metric
entropy of the convex hull of the neural network basis functions. In addition,
our methods also give sharp lower bounds on the Kolmogorov $n$-widths of this
convex hull, which show that the variation spaces corresponding to shallow
neural networks cannot be efficiently approximated by linear methods. These
lower bounds apply to both sigmoidal activation functions with bounded
variation and to activation functions which are a power of the ReLU. Our
results also quantify how much stronger the Barron spectral norm is than the
variation norm and, combined with previous results, give the asymptotics of the
$L^\infty$-metric entropy up to logarithmic factors in the case of the ReLU
activation function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">As easy as APC: Leveraging self-supervised learning in the context of time series classification with varying levels of sparsity and severe class imbalance. (arXiv:2106.15577v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wever_F/0/1/0/all/0/1">Fiorella Wever</a>, <a href="http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1">T. Anderson Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_V/0/1/0/all/0/1">Victor Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Symul_L/0/1/0/all/0/1">Laura Symul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15577">
                                    <div class="article-summary-box-inner">
                                        <span>High levels of sparsity and strong class imbalance are ubiquitous challenges
that are often presented simultaneously in real-world time series data. While
most methods tackle each problem separately, our proposed approach handles both
in conjunction, while imposing fewer assumptions on the data. In this work, we
propose leveraging a self-supervised learning method, specifically
Autoregressive Predictive Coding (APC), to learn relevant hidden
representations of time series data in the context of both missing data and
class imbalance. We apply APC using either a GRU or GRU-D encoder on two
real-world datasets, and show that applying one-step-ahead prediction with APC
improves the classification results in all settings. In fact, by applying GRU-D
- APC, we achieve state-of-the-art AUPRC results on the Physionet benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Similarity Embedding Networks for Robust Human Activity Recognition. (arXiv:2106.15283v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_C/0/1/0/all/0/1">Carrie Lu Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Di Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xiao Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Lei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jian Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianming Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15283">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models for human activity recognition (HAR) based on sensor
data have been heavily studied recently. However, the generalization ability of
deep models on complex real-world HAR data is limited by the availability of
high-quality labeled activity data, which are hard to obtain. In this paper, we
design a similarity embedding neural network that maps input sensor signals
onto real vectors through carefully designed convolutional and LSTM layers. The
embedding network is trained with a pairwise similarity loss, encouraging the
clustering of samples from the same class in the embedded real space, and can
be effectively trained on a small dataset and even on a noisy dataset with
mislabeled samples. Based on the learned embeddings, we further propose both
nonparametric and parametric approaches for activity recognition. Extensive
evaluation based on two public datasets has shown that the proposed similarity
embedding network significantly outperforms state-of-the-art deep models on HAR
classification tasks, is robust to mislabeled samples in the training set, and
can also be used to effectively denoise a noisy dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LB-CNN: An Open Source Framework for Fast Training of Light Binary Convolutional Neural Networks using Chainer and Cupy. (arXiv:2106.15350v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dogaru_R/0/1/0/all/0/1">Radu Dogaru</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogaru_I/0/1/0/all/0/1">Ioana Dogaru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15350">
                                    <div class="article-summary-box-inner">
                                        <span>Light binary convolutional neural networks (LB-CNN) are particularly useful
when implemented in low-energy computing platforms as required in many
industrial applications. Herein, a framework for optimizing compact LB-CNN is
introduced and its effectiveness is evaluated. The framework is freely
available and may run on free-access cloud platforms, thus requiring no major
investments. The optimized model is saved in the standardized .h5 format and
can be used as input to specialized tools for further deployment into specific
technologies, thus enabling the rapid development of various intelligent image
sensors. The main ingredient in accelerating the optimization of our model,
particularly the selection of binary convolution kernels, is the Chainer/Cupy
machine learning library offering significant speed-ups for training the output
layer as an extreme-learning machine. Additional training of the output layer
using Keras/Tensorflow is included, as it allows an increase in accuracy.
Results for widely used datasets including MNIST, GTSRB, ORL, VGG show very
good compromise between accuracy and complexity. Particularly, for face
recognition problems a carefully optimized LB-CNN model provides up to 100%
accuracies. Such TinyML solutions are well suited for industrial applications
requiring image recognition with low energy consumption.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomous Driving Implementation in an Experimental Environment. (arXiv:2106.15274v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aliyev_N/0/1/0/all/0/1">Namig Aliyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezer_O/0/1/0/all/0/1">Oguzhan Sezer</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzel_M/0/1/0/all/0/1">Mehmet Turan Guzel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15274">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous systems require identifying the environment and it has a long way
to go before putting it safely into practice. In autonomous driving systems,
the detection of obstacles and traffic lights are of importance as well as lane
tracking. In this study, an autonomous driving system is developed and tested
in the experimental environment designed for this purpose. In this system, a
model vehicle having a camera is used to trace the lanes and avoid obstacles to
experimentally study autonomous driving behavior. Convolutional Neural Network
models were trained for Lane tracking. For the vehicle to avoid obstacles,
corner detection, optical flow, focus of expansion, time to collision, balance
calculation, and decision mechanism were created, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepGD: A Deep Learning Framework for Graph Drawing Using GNN. (arXiv:2106.15347v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_K/0/1/0/all/0/1">Kevin Yen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yifan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15347">
                                    <div class="article-summary-box-inner">
                                        <span>In the past decades, many graph drawing techniques have been proposed for
generating aesthetically pleasing graph layouts. However, it remains a
challenging task since different layout methods tend to highlight different
characteristics of the graphs. Recently, studies on deep learning based graph
drawing algorithm have emerged but they are often not generalizable to
arbitrary graphs without re-training. In this paper, we propose a Convolutional
Graph Neural Network based deep learning framework, DeepGD, which can draw
arbitrary graphs once trained. It attempts to generate layouts by compromising
among multiple pre-specified aesthetics considering a good graph layout usually
complies with multiple aesthetics simultaneously. In order to balance the
trade-off, we propose two adaptive training strategies which adjust the weight
factor of each aesthetic dynamically during training. The quantitative and
qualitative assessment of DeepGD demonstrates that it is capable of drawing
arbitrary graphs effectively, while being flexible at accommodating different
aesthetic criteria.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Diffusion Models for High Fidelity Image Generation. (arXiv:2106.15282v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15282">
                                    <div class="article-summary-box-inner">
                                        <span>We show that cascaded diffusion models are capable of generating high
fidelity images on the class-conditional ImageNet generation challenge, without
any assistance from auxiliary image classifiers to boost sample quality. A
cascaded diffusion model comprises a pipeline of multiple diffusion models that
generate images of increasing resolution, beginning with a standard diffusion
model at the lowest resolution, followed by one or more super-resolution
diffusion models that successively upsample the image and add higher resolution
details. We find that the sample quality of a cascading pipeline relies
crucially on conditioning augmentation, our proposed method of data
augmentation of the lower resolution conditioning inputs to the
super-resolution models. Our experiments show that conditioning augmentation
prevents compounding error during sampling in a cascaded model, helping us to
train cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at
128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-board Volcanic Eruption Detection through CNNs and Satellite Multispectral Imagery. (arXiv:2106.15281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosso_M/0/1/0/all/0/1">Maria Pia Del Rosso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiller_D/0/1/0/all/0/1">Dario Spiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_P/0/1/0/all/0/1">Pierre Philippe Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15281">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the growth of Machine Learning algorithms in a variety of
different applications has raised numerous studies on the applicability of
these algorithms in real scenarios. Among all, one of the hardest scenarios,
due to its physical requirements, is the aerospace one. In this context, the
authors of this work aim to propose a first prototype and a study of
feasibility for an AI model to be &#x27;loaded&#x27; on board. As a case study, the
authors decided to investigate the detection of volcanic eruptions as a method
to swiftly produce alerts. Two Convolutional Neural Networks have been proposed
and created, also showing how to correctly implement them on real hardware and
how the complexity of a CNN can be adapted to fit computational requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Depth from Semantic Segmentation using Game Engine Dataset. (arXiv:2106.15257v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kashi_M/0/1/0/all/0/1">Mohammad Amin Kashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15257">
                                    <div class="article-summary-box-inner">
                                        <span>Depth perception is fundamental for robots to understand the surrounding
environment. As the view of cognitive neuroscience, visual depth perception
methods are divided into three categories, namely binocular, active, and
pictorial. The first two categories have been studied for decades in detail.
However, research for the exploration of the third category is still in its
infancy and has got momentum by the advent of deep learning methods in recent
years. In cognitive neuroscience, it is known that pictorial depth perception
mechanisms are dependent on the perception of seen objects. Inspired by this
fact, in this thesis, we investigated the relation of perception of objects and
depth estimation convolutional neural networks. For this purpose, we developed
new network structures based on a simple depth estimation network that only
used a single image at its input. Our proposed structures use both an image and
a semantic label of the image as their input. We used semantic labels as the
output of object perception. The obtained results of performance comparison
between the developed network and original network showed that our novel
structures can improve the performance of depth estimation by 52\% of relative
error of distance in the examined cases. Most of the experimental studies were
carried out on synthetic datasets that were generated by game engines to
isolate the performance comparison from the effect of inaccurate depth and
semantic labels of non-synthetic datasets. It is shown that particular
synthetic datasets may be used for training of depth networks in cases that an
appropriate dataset is not available. Furthermore, we showed that in these
cases, usage of semantic labels improves the robustness of the network against
domain shift from synthetic training data to non-synthetic test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuViS: Online MU-MIMO Grouping for Multi-User Applications Over Commodity WiFi. (arXiv:2106.15262v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1">Hannaneh Barahouei Pasandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_T/0/1/0/all/0/1">Tamer Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirpour_H/0/1/0/all/0/1">Hadi Amirpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15262">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last decade, the bandwidth expansion and MU-MIMO spectral efficiency
have promised to increase data throughput by allowing concurrent communication
between one Access Point and multiple users. However, we are still a long way
from enjoying such MU-MIMO MAC protocol improvements for bandwidth hungry
applications such as video streaming in practical WiFi network settings due to
heterogeneous channel conditions and devices, unreliable transmissions, and
lack of useful feedback exchange among the lower and upper layers&#x27;
requirements. This paper introduces MuViS, a novel dual-phase optimization
framework that proposes a Quality of Experience (QoE) aware MU-MIMO
optimization for multi-user video streaming over IEEE 802.11ac. MuViS first
employs reinforcement learning to optimize the MU-MIMO user group and mode
selection for users based on their PHY/MAC layer characteristics. The video
bitrate is then optimized based on the user&#x27;s mode (Multi-User (MU) or
Single-User (SU)). We present our design and its evaluation on smartphones and
laptops using 802.11ac WiFi. Our experimental results in various indoor
environments and configurations show a scalable framework that can support a
large number of users with streaming at high video rates and satisfying QoE
requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption. (arXiv:2106.15147v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Heinrich Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1">Yi Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1">Donald Metzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15147">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised contrastive representation learning has proved incredibly
successful in the vision and natural language domains, enabling
state-of-the-art performance with orders of magnitude less labeled data.
However, such methods are domain-specific and little has been done to leverage
this technique on real-world tabular datasets. We propose SCARF, a simple,
widely-applicable technique for contrastive learning, where views are formed by
corrupting a random subset of features. When applied to pre-train deep neural
networks on the 69 real-world, tabular classification datasets from the
OpenML-CC18 benchmark, SCARF not only improves classification accuracy in the
fully-supervised setting but does so also in the presence of label noise and in
the semi-supervised setting where only a fraction of the available training
data is labeled. We show that SCARF complements existing strategies and
outperforms alternatives like autoencoders. We conduct comprehensive ablations,
detailing the importance of a range of factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certifiable Machine Unlearning for Linear Models. (arXiv:2106.15093v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahadevan_A/0/1/0/all/0/1">Ananth Mahadevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1">Michael Mathioudakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15093">
                                    <div class="article-summary-box-inner">
                                        <span>Machine unlearning is the task of updating machine learning (ML) models after
a subset of the training data they were trained on is deleted. Methods for the
task are desired to combine effectiveness and efficiency, i.e., they should
effectively &quot;unlearn&quot; deleted data, but in a way that does not require
excessive computation effort (e.g., a full retraining) for a small amount of
deletions. Such a combination is typically achieved by tolerating some amount
of approximation in the unlearning. In addition, laws and regulations in the
spirit of &quot;the right to be forgotten&quot; have given rise to requirements for
certifiability, i.e., the ability to demonstrate that the deleted data has
indeed been unlearned by the ML model.

In this paper, we present an experimental study of the three state-of-the-art
approximate unlearning methods for linear models and demonstrate the trade-offs
between efficiency, effectiveness and certifiability offered by each method. In
implementing the study, we extend some of the existing works and describe a
common ML pipeline to compare and evaluate the unlearning methods on six
real-world datasets and a variety of settings. We provide insights into the
effect of the quantity and distribution of the deleted data on ML models and
the performance of each unlearning method in different settings. We also
propose a practical online strategy to determine when the accumulated error
from approximate unlearning is large enough to warrant a full retrain of the ML
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Robustness of Streaming Algorithms through Importance Sampling. (arXiv:2106.14952v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassidim_A/0/1/0/all/0/1">Avinatan Hassidim</a>, <a href="http://arxiv.org/find/cs/1/au:+Matias_Y/0/1/0/all/0/1">Yossi Matias</a>, <a href="http://arxiv.org/find/cs/1/au:+Schain_M/0/1/0/all/0/1">Mariano Schain</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14952">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce adversarially robust streaming algorithms for
central machine learning and algorithmic tasks, such as regression and
clustering, as well as their more general counterparts, subspace embedding,
low-rank approximation, and coreset construction. For regression and other
numerical linear algebra related tasks, we consider the row arrival streaming
model. Our results are based on a simple, but powerful, observation that many
importance sampling-based algorithms give rise to adversarial robustness which
is in contrast to sketching based algorithms, which are very prevalent in the
streaming literature but suffer from adversarial attacks. In addition, we show
that the well-known merge and reduce paradigm in streaming is adversarially
robust. Since the merge and reduce paradigm allows coreset constructions in the
streaming setting, we thus obtain robust algorithms for $k$-means, $k$-median,
$k$-center, Bregman clustering, projective clustering, principal component
analysis (PCA) and non-negative matrix factorization. To the best of our
knowledge, these are the first adversarially robust results for these problems
yet require no new algorithmic implementations. Finally, we empirically confirm
the robustness of our algorithms on various adversarial attacks and demonstrate
that by contrast, some common existing algorithms are not robust.

(Abstract shortened to meet arXiv limits)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphPiece: Efficiently Generating High-Quality Molecular Graph with Substructures. (arXiv:2106.15098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xiangzhe Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhixing Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15098">
                                    <div class="article-summary-box-inner">
                                        <span>Molecular graph generation is a fundamental but challenging task in various
applications such as drug discovery and material science, which requires
generating valid molecules with desired properties. Auto-regressive models,
which usually construct graphs following sequential actions of adding nodes and
edges at the atom-level, have made rapid progress in recent years. However,
these atom-level models ignore high-frequency subgraphs that not only capture
the regularities of atomic combination in molecules but also are often related
to desired chemical properties. In this paper, we propose a method to
automatically discover such common substructures, which we call {\em graph
pieces}, from given molecular graphs. Based on graph pieces, we leverage a
variational autoencoder to generate molecules in two phases: piece-level graph
generation followed by bond completion. Experiments show that our graph piece
variational autoencoder achieves better performance over state-of-the-art
baselines on property optimization and constrained property optimization tasks
with higher computational efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving-Graph Gaussian Processes. (arXiv:2106.15127v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blanco_Mulero_D/0/1/0/all/0/1">David Blanco-Mulero</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1">Markus Heinonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1">Ville Kyrki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15127">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Gaussian Processes (GGPs) provide a data-efficient solution on graph
structured domains. Existing approaches have focused on static structures,
whereas many real graph data represent a dynamic structure, limiting the
applications of GGPs. To overcome this we propose evolving-Graph Gaussian
Processes (e-GGPs). The proposed method is capable of learning the transition
function of graph vertices over time with a neighbourhood kernel to model the
connectivity and interaction changes between vertices. We assess the
performance of our method on time-series regression problems where graphs
evolve over time. We demonstrate the benefits of e-GGPs over static graph
Gaussian Process approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation for deep learning based accelerated MRI reconstruction with limited data. (arXiv:2106.14947v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fabian_Z/0/1/0/all/0/1">Zalan Fabian</a>, <a href="http://arxiv.org/find/eess/1/au:+Heckel_R/0/1/0/all/0/1">Reinhard Heckel</a>, <a href="http://arxiv.org/find/eess/1/au:+Soltanolkotabi_M/0/1/0/all/0/1">Mahdi Soltanolkotabi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14947">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have emerged as very successful tools for image
restoration and reconstruction tasks. These networks are often trained
end-to-end to directly reconstruct an image from a noisy or corrupted
measurement of that image. To achieve state-of-the-art performance, training on
large and diverse sets of images is considered critical. However, it is often
difficult and/or expensive to collect large amounts of training images.
Inspired by the success of Data Augmentation (DA) for classification problems,
in this paper, we propose a pipeline for data augmentation for accelerated MRI
reconstruction and study its effectiveness at reducing the required training
data in a variety of settings. Our DA pipeline, MRAugment, is specifically
designed to utilize the invariances present in medical imaging measurements as
naive DA strategies that neglect the physics of the problem fail. Through
extensive studies on multiple datasets we demonstrate that in the low-data
regime DA prevents overfitting and can match or even surpass the state of the
art while using significantly fewer training data, whereas in the high-data
regime it has diminishing returns. Furthermore, our findings show that DA can
improve the robustness of the model against various shifts in the test
distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularized OFU: an Efficient UCB Estimator forNon-linear Contextual Bandit. (arXiv:2106.15128v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yichi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shihong Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huishuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15128">
                                    <div class="article-summary-box-inner">
                                        <span>Balancing exploration and exploitation (EE) is a fundamental problem in
contex-tual bandit. One powerful principle for EE trade-off isOptimism in Face
of Uncer-tainty(OFU), in which the agent takes the action according to an upper
confidencebound (UCB) of reward. OFU has achieved (near-)optimal regret bound
for lin-ear/kernel contextual bandits. However, it is in general unknown how to
deriveefficient and effective EE trade-off methods for non-linearcomplex tasks,
suchas contextual bandit with deep neural network as the reward function. In
thispaper, we propose a novel OFU algorithm namedregularized OFU(ROFU). InROFU,
we measure the uncertainty of the reward by a differentiable function
andcompute the upper confidence bound by solving a regularized optimization
prob-lem. We prove that, for multi-armed bandit, kernel contextual bandit and
neuraltangent kernel bandit, ROFU achieves (near-)optimal regret bounds with
certainuncertainty measure, which theoretically justifies its effectiveness on
EE trade-off.Importantly, ROFU admits a very efficient implementation with
gradient-basedoptimizer, which easily extends to general deep neural network
models beyondneural tangent kernel, in sharp contrast with previous OFU
methods. The em-pirical evaluation demonstrates that ROFU works extremelywell
for contextualbandits under various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-learning for Matrix Factorization without Shared Rows or Columns. (arXiv:2106.15133v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15133">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method that meta-learns a knowledge on matrix factorization from
various matrices, and uses the knowledge for factorizing unseen matrices. The
proposed method uses a neural network that takes a matrix as input, and
generates prior distributions of factorized matrices of the given matrix. The
neural network is meta-learned such that the expected imputation error is
minimized when the factorized matrices are adapted to each matrix by a maximum
a posteriori (MAP) estimation. We use a gradient descent method for the MAP
estimation, which enables us to backpropagate the expected imputation error
through the gradient descent steps for updating neural network parameters since
each gradient descent step is written in a closed form and is differentiable.
The proposed method can meta-learn from matrices even when their rows and
columns are not shared, and their sizes are different from each other. In our
experiments with three user-item rating datasets, we demonstrate that our
proposed method can impute the missing values from a limited number of
observations in unseen matrices after being trained with different matrices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Multiple Annotators by Incorporating Instance Features. (arXiv:2106.15146v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hailong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhijun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1">Renshuai Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yufei Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15146">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from multiple annotators aims to induce a high-quality classifier
from training instances, where each of them is associated with a set of
possibly noisy labels provided by multiple annotators under the influence of
their varying abilities and own biases. In modeling the probability transition
process from latent true labels to observed labels, most existing methods adopt
class-level confusion matrices of annotators that observed labels do not depend
on the instance features, just determined by the true labels. It may limit the
performance that the classifier can achieve. In this work, we propose the noise
transition matrix, which incorporates the influence of instance features on
annotators&#x27; performance based on confusion matrices. Furthermore, we propose a
simple yet effective learning framework, which consists of a classifier module
and a noise transition matrix module in a unified neural network architecture.
Experimental results demonstrate the superiority of our method in comparison
with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Waveform Learning Through Joint Optimization of Pulse and Constellation Shaping. (arXiv:2106.15158v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1">Fay&#xe7;al Ait Aoudia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1">Jakob Hoydis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15158">
                                    <div class="article-summary-box-inner">
                                        <span>As communication systems are foreseen to enable new services such as joint
communication and sensing and utilize parts of the sub-THz spectrum, the design
of novel waveforms that can support these emerging applications becomes
increasingly challenging. We present in this work an end-to-end learning
approach to design waveforms through joint learning of pulse shaping and
constellation geometry, together with a neural network (NN)-based receiver.
Optimization is performed to maximize an achievable information rate, while
satisfying constraints on out-of-band emission and power envelope. Our results
show that the proposed approach enables up to orders of magnitude smaller
adjacent channel leakage ratios (ACLRs) with peak-to-average power ratios
(PAPRs) competitive with traditional filters, without significant loss of
information rate on an additive white Gaussian noise (AWGN) channel, and no
additional complexity at the transmitter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature selection for intrusion detection systems. (arXiv:2106.14941v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamalov_F/0/1/0/all/0/1">Firuz Kamalov</a>, <a href="http://arxiv.org/find/cs/1/au:+Moussa_S/0/1/0/all/0/1">Sherif Moussa</a>, <a href="http://arxiv.org/find/cs/1/au:+Zgheib_R/0/1/0/all/0/1">Rita Zgheib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mashaal_O/0/1/0/all/0/1">Omar Mashaal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14941">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we analyze existing feature selection methods to identify the
key elements of network traffic data that allow intrusion detection. In
addition, we propose a new feature selection method that addresses the
challenge of considering continuous input features and discrete target values.
We show that the proposed method performs well against the benchmark selection
methods. We use our findings to develop a highly effective machine
learning-based detection systems that achieves 99.9% accuracy in distinguishing
between DDoS and benign signals. We believe that our results can be useful to
experts who are interested in designing and building automated intrusion
detection systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syntactically Guided Generative Embeddings for Zero-Shot Skeleton Action Recognition. (arXiv:2101.11530v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Pranay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1">Divyanshu Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11530">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce SynSE, a novel syntactically guided generative approach for
Zero-Shot Learning (ZSL). Our end-to-end approach learns progressively refined
generative embedding spaces constrained within and across the involved
modalities (visual, language). The inter-modal constraints are defined between
action sequence embedding and embeddings of Parts of Speech (PoS) tagged words
in the corresponding action description. We deploy SynSE for the task of
skeleton-based action sequence recognition. Our design choices enable SynSE to
generalize compositionally, i.e., recognize sequences whose action descriptions
contain words not encountered during training. We also extend our approach to
the more challenging Generalized Zero-Shot Learning (GZSL) problem via a
confidence-based gating mechanism. We are the first to present zero-shot
skeleton action recognition results on the large-scale NTU-60 and NTU-120
skeleton action datasets with multiple splits. Our results demonstrate SynSE&#x27;s
state of the art performance in both ZSL and GZSL settings compared to strong
baselines on the NTU-60 and NTU-120 datasets. The code and pretrained models
are available at https://github.com/skelemoa/synse-zsl</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepFaceLab: Integrated, flexible and extensible face-swapping framework. (arXiv:2005.05535v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perov_I/0/1/0/all/0/1">Ivan Perov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1">Daiheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chervoniy_N/0/1/0/all/0/1">Nikolay Chervoniy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kunlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Marangonda_S/0/1/0/all/0/1">Sugasa Marangonda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ume_C/0/1/0/all/0/1">Chris Um&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Dpfks_M/0/1/0/all/0/1">Mr. Dpfks</a>, <a href="http://arxiv.org/find/cs/1/au:+Facenheim_C/0/1/0/all/0/1">Carl Shift Facenheim</a>, <a href="http://arxiv.org/find/cs/1/au:+RP_L/0/1/0/all/0/1">Luis RP</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jian Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Pingyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfake defense not only requires the research of detection but also
requires the efforts of generation methods. However, current deepfake methods
suffer the effects of obscure workflow and poor performance. To solve this
problem, we present DeepFaceLab, the current dominant deepfake framework for
face-swapping. It provides the necessary tools as well as an easy-to-use way to
conduct high-quality face-swapping. It also offers a flexible and loose
coupling structure for people who need to strengthen their pipeline with other
features without writing complicated boilerplate code. We detail the principles
that drive the implementation of DeepFaceLab and introduce its pipeline,
through which every aspect of the pipeline can be modified painlessly by users
to achieve their customization purpose. It is noteworthy that DeepFaceLab could
achieve cinema-quality results with high fidelity. We demonstrate the advantage
of our system by comparing our approach with other face-swapping methods.For
more information, please visit:https://github.com/iperov/DeepFaceLab/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuViS: Online MU-MIMO Grouping for Multi-User Applications Over Commodity WiFi. (arXiv:2106.15262v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1">Hannaneh Barahouei Pasandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_T/0/1/0/all/0/1">Tamer Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirpour_H/0/1/0/all/0/1">Hadi Amirpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15262">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last decade, the bandwidth expansion and MU-MIMO spectral efficiency
have promised to increase data throughput by allowing concurrent communication
between one Access Point and multiple users. However, we are still a long way
from enjoying such MU-MIMO MAC protocol improvements for bandwidth hungry
applications such as video streaming in practical WiFi network settings due to
heterogeneous channel conditions and devices, unreliable transmissions, and
lack of useful feedback exchange among the lower and upper layers&#x27;
requirements. This paper introduces MuViS, a novel dual-phase optimization
framework that proposes a Quality of Experience (QoE) aware MU-MIMO
optimization for multi-user video streaming over IEEE 802.11ac. MuViS first
employs reinforcement learning to optimize the MU-MIMO user group and mode
selection for users based on their PHY/MAC layer characteristics. The video
bitrate is then optimized based on the user&#x27;s mode (Multi-User (MU) or
Single-User (SU)). We present our design and its evaluation on smartphones and
laptops using 802.11ac WiFi. Our experimental results in various indoor
environments and configurations show a scalable framework that can support a
large number of users with streaming at high video rates and satisfying QoE
requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Not Deceive Your Employer with a Virtual Background: A Video Conferencing Manipulation-Detection System. (arXiv:2106.15130v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1">Mauro Conti</a>, <a href="http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1">Simone Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1">Ehsan Nowroozi</a>, <a href="http://arxiv.org/find/cs/1/au:+Orazi_G/0/1/0/all/0/1">Gabriele Orazi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15130">
                                    <div class="article-summary-box-inner">
                                        <span>The last-generation video conferencing software allows users to utilize a
virtual background to conceal their personal environment due to privacy
concerns, especially in official meetings with other employers. On the other
hand, users maybe want to fool people in the meeting by considering the virtual
background to conceal where they are. In this case, developing tools to
understand the virtual background utilize for fooling people in meeting plays
an important role. Besides, such detectors must prove robust against different
kinds of attacks since a malicious user can fool the detector by applying a set
of adversarial editing steps on the video to conceal any revealing footprint.
In this paper, we study the feasibility of an efficient tool to detect whether
a videoconferencing user background is real. In particular, we provide the
first tool which computes pixel co-occurrences matrices and uses them to search
for inconsistencies among spectral and spatial bands. Our experiments confirm
that cross co-occurrences matrices improve the robustness of the detector
against different kinds of attacks. This work&#x27;s performance is especially
noteworthy with regard to color SPAM features. Moreover, the performance
especially is significant with regard to robustness versus post-processing,
like geometric transformations, filtering, contrast enhancement, and JPEG
compression with different quality factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-07-06T00:44:38.137Z">2021-07-06T00:44:38.137Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>