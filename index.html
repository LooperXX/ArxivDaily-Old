 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-16">2021-08-16</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diachronic Analysis of German Parliamentary Proceedings: Ideological Shifts through the Lens of Political Biases. (arXiv:2108.06295v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walter_T/0/1/0/all/0/1">Tobias Walter</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirschner_C/0/1/0/all/0/1">Celina Kirschner</a>, <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponzetto_S/0/1/0/all/0/1">Simone Paolo Ponzetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06295">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze bias in historical corpora as encoded in diachronic distributional
semantic models by focusing on two specific forms of bias, namely a political
(i.e., anti-communism) and racist (i.e., antisemitism) one. For this, we use a
new corpus of German parliamentary proceedings, DeuPARL, spanning the period
1867--2020. We complement this analysis of historical biases in diachronic word
embeddings with a novel measure of bias on the basis of term co-occurrences and
graph-based label propagation. The results of our bias measurements align with
commonly perceived historical trends of antisemitic and anti-communist biases
in German politics in different time periods, thus indicating the viability of
analyzing historical bias trends using semantic spaces induced from historical
corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simplifying Paragraph-level Question Generation via Transformer Language Models. (arXiv:2005.01107v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lopez_L/0/1/0/all/0/1">Luis Enrico Lopez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_D/0/1/0/all/0/1">Diane Kathryn Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1">Jan Christian Blaise Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Charibeth Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01107">
                                    <div class="article-summary-box-inner">
                                        <span>Question generation (QG) is a natural language generation task where a model
is trained to ask questions corresponding to some input text. Most recent
approaches frame QG as a sequence-to-sequence problem and rely on additional
features and mechanisms to increase performance; however, these often increase
model complexity, and can rely on auxiliary data unavailable in practical use.
A single Transformer-based unidirectional language model leveraging transfer
learning can be used to produce high quality questions while disposing of
additional task-specific complexity. Our QG model, finetuned from GPT-2 Small,
outperforms several paragraph-level QG baselines on the SQuAD dataset by 0.95
METEOR points. Human evaluators rated questions as easy to answer, relevant to
their context paragraph, and corresponding well to natural human speech. Also
introduced is a new set of baseline scores on the RACE dataset, which has not
previously been used for QG tasks. Further experimentation with varying model
capacities and datasets with non-identification type questions is recommended
in order to further verify the robustness of pretrained Transformer-based LMs
as question generators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Relationships Between Scientific Documents. (arXiv:2002.00317v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Kelvin Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1">Rik Koncel-Kedziorski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cachola_I/0/1/0/all/0/1">Isabel Cachola</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00317">
                                    <div class="article-summary-box-inner">
                                        <span>We address the task of explaining relationships between two scientific
documents using natural language text. This task requires modeling the complex
content of long technical documents, deducing a relationship between these
documents, and expressing the details of that relationship in text. In addition
to the theoretical interest of this task, successful solutions can help improve
researcher efficiency in search and review. In this paper we establish a
dataset of 622K examples from 154K documents. We pretrain a large language
model to serve as the foundation for autoregressive approaches to the task. We
explore the impact of taking different views on the two documents, including
the use of dense representations extracted with scientific IE systems. We
provide extensive automatic and human evaluations which show the promise of
such models, but make clear challenges for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning. (arXiv:2108.06332v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yanan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhilin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06332">
                                    <div class="article-summary-box-inner">
                                        <span>Most previous methods for text data augmentation are limited to simple tasks
and weak baselines. We explore data augmentation on hard tasks (i.e., few-shot
natural language understanding) and strong baselines (i.e., pretrained models
with over one billion parameters). Under this setting, we reproduced a large
number of previous augmentation methods and found that these methods bring
marginal gains at best and sometimes degrade the performance much. To address
this challenge, we propose a novel data augmentation method FlipDA that jointly
uses a generative model and a classifier to generate label-flipped data.
Central to the idea of FlipDA is the discovery that generating label-flipped
data is more crucial to the performance than generating label-preserved data.
Experiments show that FlipDA achieves a good tradeoff between effectiveness and
robustness---it substantially improves many tasks while not negatively
affecting the others.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spanish Language Models. (arXiv:2107.07253v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_Fandino_A/0/1/0/all/0/1">Asier Guti&#xe9;rrez-Fandi&#xf1;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Armengol_Estape_J/0/1/0/all/0/1">Jordi Armengol-Estap&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pamies_M/0/1/0/all/0/1">Marc P&#xe0;mies</a>, <a href="http://arxiv.org/find/cs/1/au:+Llop_Palao_J/0/1/0/all/0/1">Joan Llop-Palao</a>, <a href="http://arxiv.org/find/cs/1/au:+Silveira_Ocampo_J/0/1/0/all/0/1">Joaqu&#xed;n Silveira-Ocampo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carrino_C/0/1/0/all/0/1">Casimiro Pio Carrino</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Agirre_A/0/1/0/all/0/1">Aitor Gonzalez-Agirre</a>, <a href="http://arxiv.org/find/cs/1/au:+Armentano_Oller_C/0/1/0/all/0/1">Carme Armentano-Oller</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Penagos_C/0/1/0/all/0/1">Carlos Rodriguez-Penagos</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_M/0/1/0/all/0/1">Marta Villegas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07253">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the Spanish RoBERTa-base and RoBERTa-large models, as
well as the corresponding performance evaluations. Both models were pre-trained
using the largest Spanish corpus known to date, with a total of 570GB of clean
and deduplicated text processed for this work, compiled from the web crawlings
performed by the National Library of Spain from 2009 to 2019. We extended the
current evaluation datasets with an extractive Question Answering dataset and
our models outperform the existing Spanish models across tasks and settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models. (arXiv:2106.00245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00245">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from large-scale pre-training, we have witnessed significant
performance boost on the popular Visual Question Answering (VQA) task. Despite
rapid progress, it remains unclear whether these state-of-the-art (SOTA) models
are robust when encountering examples in the wild. To study this, we introduce
Adversarial VQA, a new large-scale VQA benchmark, collected iteratively via an
adversarial human-and-model-in-the-loop procedure. Through this new benchmark,
we discover several interesting findings. (i) Surprisingly, we find that during
dataset collection, non-expert annotators can easily attack SOTA VQA models
successfully. (ii) Both large-scale pre-trained models and adversarial training
methods achieve far worse performance on the new benchmark than over standard
VQA v2 dataset, revealing the fragility of these models while demonstrating the
effectiveness of our adversarial dataset. (iii) When used for data
augmentation, our dataset can effectively boost model performance on other
robust VQA benchmarks. We hope our Adversarial VQA dataset can shed new light
on robustness study in the community and serve as a valuable benchmark for
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting News Article Structure for Automatic Corpus Generation of Entailment Datasets. (arXiv:2010.11574v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1">Jan Christian Blaise Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Resabal_J/0/1/0/all/0/1">Jose Kristian Resabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">James Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1">Dan John Velasco</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Charibeth Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11574">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language Inference (NLI) benchmark datasets
for low-resource languages using published news articles. Through this, we
create and release NewsPH-NLI, the first sentence entailment benchmark dataset
in the low-resource Filipino language. Second, we produce new pretrained
transformers based on the ELECTRA technique to further alleviate the resource
scarcity in Filipino, benchmarking them on our dataset against other
commonly-used transfer learning techniques. Lastly, we perform analyses on
transfer learning techniques to shed light on their true performance when
operating in low-data domains through the use of degradation tests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Smart Chatbot Prototype for Patient Monitoring. (arXiv:2103.06816v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_H/0/1/0/all/0/1">Hannah Lei</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Weiqi Lu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ji_A/0/1/0/all/0/1">Alan Ji</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Bertram_E/0/1/0/all/0/1">Emmett Bertram</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Paul Gao</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoqian Jiang</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Barman_A/0/1/0/all/0/1">Arko Barman</a> (1) ((1) Rice University, Houston, United States, (2) The University of Texas Health Science Center at Houston, United States)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06816">
                                    <div class="article-summary-box-inner">
                                        <span>Many COVID-19 patients developed prolonged symptoms after the infection,
including fatigue, delirium, and headache. The long-term health impact of these
conditions is still not clear. It is necessary to develop a way to follow up
with these patients for monitoring their health status to support timely
intervention and treatment. In the lack of sufficient human resources to follow
up with patients, we propose a novel smart chatbot solution backed with machine
learning to collect information (i.e., generating digital diary) in a
personalized manner. In this article, we describe the design framework and
components of our prototype.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset for Answering Time-Sensitive Questions. (arXiv:2108.06314v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06314">
                                    <div class="article-summary-box-inner">
                                        <span>Time is an important dimension in our physical world. Lots of facts can
evolve with respect to time. For example, the U.S. President might change every
four years. Therefore, it is important to consider the time dimension and
empower the existing QA models to reason over time. However, the existing QA
datasets contain rather few time-sensitive questions, hence not suitable for
diagnosing or benchmarking the model&#x27;s temporal reasoning capability. In order
to promote research in this direction, we propose to construct a time-sensitive
QA dataset. The dataset is constructed by 1) mining time-evolving facts from
WikiData and align them to their corresponding Wikipedia page, 2) employing
crowd workers to verify and calibrate these noisy facts, 3) generating
question-answer pairs based on the annotated time-sensitive facts. Our dataset
poses two novel challenges: 1) the model needs to understand both explicit and
implicit mention of time information in the long document, 2) the model needs
to perform temporal reasoning like comparison, addition, subtraction. We
evaluate different SoTA long-document QA systems like BigBird and FiD on our
dataset. The best-performing model FiD can only achieve 46\% accuracy, still
far behind the human performance of 87\%. We demonstrate that these models are
still lacking the ability to perform robust temporal understanding and
reasoning. Therefore, we believe that our dataset could serve as a benchmark to
empower future studies in temporal reasoning. The dataset and code are released
in~\url{https://github.com/wenhuchen/Time-Sensitive-QA}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MeetSum: Transforming Meeting Transcript Summarization using Transformers!. (arXiv:2108.06310v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadri_N/0/1/0/all/0/1">Nima Sadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bihan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06310">
                                    <div class="article-summary-box-inner">
                                        <span>Creating abstractive summaries from meeting transcripts has proven to be
challenging due to the limited amount of labeled data available for training
neural network models. Moreover, Transformer-based architectures have proven to
beat state-of-the-art models in summarizing news data. In this paper, we
utilize a Transformer-based Pointer Generator Network to generate abstract
summaries for meeting transcripts. This model uses 2 LSTMs as an encoder and a
decoder, a Pointer network which copies words from the inputted text, and a
Generator network to produce out-of-vocabulary words (hence making the summary
abstractive). Moreover, a coverage mechanism is used to avoid repetition of
words in the generated summary. First, we show that training the model on a
news summary dataset and using zero-shot learning to test it on the meeting
dataset proves to produce better results than training it on the AMI meeting
dataset. Second, we show that training this model first on out-of-domain data,
such as the CNN-Dailymail dataset, followed by a fine-tuning stage on the AMI
meeting dataset is able to improve the performance of the model significantly.
We test our model on a testing set from the AMI dataset and report the ROUGE-2
score of the generated summary to compare with previous literature. We also
report the Factual score of our summaries since it is a better benchmark for
abstractive summaries since the ROUGE-2 score is limited to measuring
word-overlaps. We show that our improved model is able to improve on previous
models by at least 5 ROUGE-2 scores, which is a substantial improvement. Also,
a qualitative analysis of the summaries generated by our model shows that these
summaries and human-readable and indeed capture most of the important
information from the transcripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Structured Dynamic Sparse Pre-Training of BERT. (arXiv:2108.06277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06277">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying algorithms for computational efficient unsupervised training of
large language models is an important and active area of research. In this
work, we develop and study a straightforward, dynamic always-sparse
pre-training approach for BERT language modeling task, which leverages periodic
compression steps based on magnitude pruning followed by random parameter
re-allocation. This approach enables us to achieve Pareto improvements in terms
of the number of floating-point operations (FLOPs) over statically sparse and
dense models across a broad spectrum of network sizes. Furthermore, we
demonstrate that training remains FLOP-efficient when using coarse-grained
block sparsity, making it particularly promising for efficient execution on
modern hardware accelerators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAIR: Framework for mining relationships between research articles, strategies, and regulations in the field of explainable artificial intelligence. (arXiv:2108.06216v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1">Stanis&#x142;aw Gizinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzba_M/0/1/0/all/0/1">Micha&#x142; Kuzba</a>, <a href="http://arxiv.org/find/cs/1/au:+Pielinski_B/0/1/0/all/0/1">Bartosz Pielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sienkiewicz_J/0/1/0/all/0/1">Julian Sienkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Laniewski_S/0/1/0/all/0/1">Stanis&#x142;aw &#x141;aniewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1">Przemys&#x142;aw Biecek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06216">
                                    <div class="article-summary-box-inner">
                                        <span>The growing number of AI applications, also for high-stake decisions,
increases the interest in Explainable and Interpretable Machine Learning
(XI-ML). This trend can be seen both in the increasing number of regulations
and strategies for developing trustworthy AI and the growing number of
scientific papers dedicated to this topic. To ensure the sustainable
development of AI, it is essential to understand the dynamics of the impact of
regulation on research papers as well as the impact of scientific discourse on
AI-related policies. This paper introduces a novel framework for joint analysis
of AI-related policy documents and eXplainable Artificial Intelligence (XAI)
research papers. The collected documents are enriched with metadata and
interconnections, using various NLP methods combined with a methodology
inspired by Institutional Grammar. Based on the information extracted from
collected documents, we showcase a series of analyses that help understand
interactions, similarities, and differences between documents at different
stages of institutionalization. To the best of our knowledge, this is the first
work to use automatic language analysis tools to understand the dynamics
between XI-ML methods and regulations. We believe that such a system
contributes to better cooperation between XAI researchers and AI policymakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1">Greyson Gerhard-Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1">Raviteja Anantha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1">Srinivas Chappidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1">Bj&#xf6;rn Hoffmeister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06329">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work building open-domain chatbots has demonstrated that increasing
model size improves performance. On the other hand, latency and connectivity
considerations dictate the move of digital assistants on the device. Giving a
digital assistant like Siri, Alexa, or Google Assistant the ability to discuss
just about anything leads to the need for reducing the chatbot model size such
that it fits on the user&#x27;s device. We demonstrate that low parameter models can
simultaneously retain their general knowledge conversational abilities while
improving in a specific domain. Additionally, we propose a generic framework
that accounts for variety in question types, tracks reference throughout
multi-turn conversations, and removes inconsistent and potentially toxic
responses. Our framework seamlessly transitions between chatting and performing
transactional tasks, which will ultimately make interactions with digital
assistants more human-like. We evaluate our framework on 1 internal and 4
public benchmark datasets using both automatic (Perplexity) and human (SSA -
Sensibleness and Specificity Average) evaluation metrics and establish
comparable performance while reducing model parameters by 90%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Single and Multiple Representations in Dense Passage Retrieval. (arXiv:2108.06279v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06279">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextualised language models has brought gains in search
effectiveness, not just when applied for re-ranking the output of classical
weighting models such as BM25, but also when used directly for passage indexing
and retrieval, a technique which is called dense retrieval. In the existing
literature in neural ranking, two dense retrieval families have become
apparent: single representation, where entire passages are represented by a
single embedding (usually BERT&#x27;s [CLS] token, as exemplified by the recent ANCE
approach), or multiple representations, where each token in a passage is
represented by its own embedding (as exemplified by the recent ColBERT
approach). These two families have not been directly compared. However, because
of the likely importance of dense retrieval moving forward, a clear
understanding of their advantages and disadvantages is paramount. To this end,
this paper contributes a direct study on their comparative effectiveness,
noting situations where each method under/over performs w.r.t. each other, and
w.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than
ColBERT in terms of response time and memory usage, multiple representations
are statistically more effective than the single representations for MAP and
MRR@10. We also show that multiple representations obtain better improvements
than single representations for queries that are the hardest for BM25, as well
as for definitional queries, and those with complex information needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aspect Sentiment Triplet Extraction Using Reinforcement Learning. (arXiv:2108.06107v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Samson Yu Bai Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_T/0/1/0/all/0/1">Tapas Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06107">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting triplets
of aspect terms, their associated sentiments, and the opinion terms that
provide evidence for the expressed sentiments. Previous approaches to ASTE
usually simultaneously extract all three components or first identify the
aspect and opinion terms, then pair them up to predict their sentiment
polarities. In this work, we present a novel paradigm, ASTE-RL, by regarding
the aspect and opinion terms as arguments of the expressed sentiment in a
hierarchical reinforcement learning (RL) framework. We first focus on
sentiments expressed in a sentence, then identify the target aspect and opinion
terms for that sentiment. This takes into account the mutual interactions among
the triplet&#x27;s components while improving exploration and sample efficiency.
Furthermore, this hierarchical RLsetup enables us to deal with multiple and
overlapping triplets. In our experiments, we evaluate our model on existing
datasets from laptop and restaurant domains and show that it achieves
state-of-the-art performance. The implementation of this work is publicly
available at https://github.com/declare-lab/ASTE-RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Answer Similarity for Evaluating Question Answering Models. (arXiv:2108.06130v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutsch_J/0/1/0/all/0/1">Julian Gutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietsch_M/0/1/0/all/0/1">Malte Pietsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06130">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of question answering models compares ground-truth annotations
with model predictions. However, as of today, this comparison is mostly
lexical-based and therefore misses out on answers that have no lexical overlap
but are still semantically similar, thus treating correct answers as false.
This underestimation of the true performance of models hinders user acceptance
in applications and complicates a fair comparison of different models.
Therefore, there is a need for an evaluation metric that is based on semantics
instead of pure string similarity. In this short paper, we present SAS, a
cross-encoder-based metric for the estimation of semantic answer similarity,
and compare it to seven existing metrics. To this end, we create an English and
a German three-way annotated evaluation dataset containing pairs of answers
along with human judgment of their semantic similarity, which we release along
with an implementation of the SAS metric and the experiments. We find that
semantic similarity metrics based on recent transformer models correlate much
better with human judgment than traditional lexical similarity metrics on our
two newly created datasets and one dataset from related work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Ruiyang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1">Shangwen Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Yingqi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">QiaoQiao She</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, dense passage retrieval has become a mainstream approach to finding
relevant information in various natural language processing tasks. A number of
studies have been devoted to improving the widely adopted dual-encoder
architecture. However, most of the previous studies only consider query-centric
similarity relation when learning the dual-encoder retriever. In order to
capture more comprehensive similarity relations, we propose a novel approach
that leverages both query-centric and PAssage-centric sImilarity Relations
(called PAIR) for dense passage retrieval. To implement our approach, we make
three major technical contributions by introducing formal formulations of the
two kinds of similarity relations, generating high-quality pseudo labeled data
via knowledge distillation, and designing an effective two-stage training
procedure that incorporates passage-centric similarity relation constraint.
Extensive experiments show that our approach significantly outperforms previous
state-of-the-art models on both MSMARCO and Natural Questions datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Graph Reasoning with Relational Directed Graph. (arXiv:2108.06040v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06040">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning on the knowledge graph (KG) aims to infer new facts from existing
ones. Methods based on the relational path in the literature have shown strong,
interpretable, and inductive reasoning ability. However, the paths are
naturally limited in capturing complex topology in KG. In this paper, we
introduce a novel relational structure, i.e., relational directed graph
(r-digraph), which is composed of overlapped relational paths, to capture the
KG&#x27;s structural information. Since the digraph exhibits more complex structure
than paths, constructing and learning on the r-digraph are challenging. Here,
we propose a variant of graph neural network, i.e., RED-GNN, to address the
above challenges by learning the RElational Digraph with a variant of GNN.
Specifically, RED-GNN recursively encodes multiple r-digraphs with shared edges
and selects the strongly correlated edges through query-dependent attention
weights. We demonstrate the significant gains on reasoning both KG with unseen
entities and incompletion KG benchmarks by the r-digraph, the efficiency of
RED-GNN, and the interpretable dependencies learned on the r-digraph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TPRM: A Topic-based Personalized Ranking Model for Web Search. (arXiv:2108.06014v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06014">
                                    <div class="article-summary-box-inner">
                                        <span>Ranking models have achieved promising results, but it remains challenging to
design personalized ranking systems to leverage user profiles and semantic
representations between queries and documents. In this paper, we propose a
topic-based personalized ranking model (TPRM) that integrates user topical
profile with pretrained contextualized term representations to tailor the
general document ranking list. Experiments on the real-world dataset
demonstrate that TPRM outperforms state-of-the-art ad-hoc ranking models and
personalized ranking models significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of the HASOC track at FIRE 2020: Hate Speech and Offensive Content Identification in Indo-European Languages. (arXiv:2108.05927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mandla_T/0/1/0/all/0/1">Thomas Mandla</a>, <a href="http://arxiv.org/find/cs/1/au:+Modha_S/0/1/0/all/0/1">Sandip Modha</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1">Amit Kumar Jaiswal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nandini_D/0/1/0/all/0/1">Durgesh Nandini</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Daksh Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_P/0/1/0/all/0/1">Prasenjit Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_J/0/1/0/all/0/1">Johannes Sch&#xe4;fer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05927">
                                    <div class="article-summary-box-inner">
                                        <span>With the growth of social media, the spread of hate speech is also increasing
rapidly. Social media are widely used in many countries. Also Hate Speech is
spreading in these countries. This brings a need for multilingual Hate Speech
detection algorithms. Much research in this area is dedicated to English at the
moment. The HASOC track intends to provide a platform to develop and optimize
Hate Speech detection algorithms for Hindi, German and English. The dataset is
collected from a Twitter archive and pre-classified by a machine learning
system. HASOC has two sub-task for all three languages: task A is a binary
classification problem (Hate and Not Offensive) while task B is a fine-grained
classification problem for three classes (HATE) Hate speech, OFFENSIVE and
PROFANITY. Overall, 252 runs were submitted by 40 teams. The performance of the
best classification algorithms for task A are F1 measures of 0.51, 0.53 and
0.52 for English, Hindi, and German, respectively. For task B, the best
classification algorithms achieved F1 measures of 0.26, 0.33 and 0.29 for
English, Hindi, and German, respectively. This article presents the tasks and
the data development as well as the results. The best performing algorithms
were mainly variants of the transformer architecture BERT. However, also other
systems were applied with good success</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GQE-PRF: Generative Query Expansion with Pseudo-Relevance Feedback. (arXiv:2108.06010v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Meizhen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06010">
                                    <div class="article-summary-box-inner">
                                        <span>Query expansion with pseudo-relevance feedback (PRF) is a powerful approach
to enhance the effectiveness in information retrieval. Recently, with the rapid
advance of deep learning techniques, neural text generation has achieved
promising success in many natural language tasks. To leverage the strength of
text generation for information retrieval, in this article, we propose a novel
approach which effectively integrates text generation models into PRF-based
query expansion. In particular, our approach generates augmented query terms
via neural text generation models conditioned on both the initial query and
pseudo-relevance feedback. Moreover, in order to train the generative model, we
adopt the conditional generative adversarial nets (CGANs) and propose the
PRF-CGAN method in which both the generator and the discriminator are
conditioned on the pseudo-relevance feedback. We evaluate the performance of
our approach on information retrieval tasks using two benchmark datasets. The
experimental results show that our approach achieves comparable performance or
outperforms traditional query expansion methods on both the retrieval and
reranking tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate. (arXiv:2108.05921v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Rose Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertram Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1">Paul R&#xf6;ttger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05921">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting online hate is a complex task, and low-performing detection models
have harmful consequences when used for sensitive applications such as content
moderation. Emoji-based hate is a key emerging challenge for online hate
detection. We present HatemojiCheck, a test suite of 3,930 short-form
statements that allows us to evaluate how detection models perform on hateful
language expressed with emoji. Using the test suite, we expose weaknesses in
existing hate detection models. To address these weaknesses, we create the
HatemojiTrain dataset using an innovative human-and-model-in-the-loop approach.
Models trained on these 5,912 adversarial examples perform substantially better
at detecting emoji-based hate, while retaining strong performance on text-only
hate. Both HatemojiCheck and HatemojiTrain are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Lifespan Face Synthesis. (arXiv:2108.02874v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Sen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wentong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Michael Ying Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02874">
                                    <div class="article-summary-box-inner">
                                        <span>A lifespan face synthesis (LFS) model aims to generate a set of
photo-realistic face images of a person&#x27;s whole life, given only one snapshot
as reference. The generated face image given a target age code is expected to
be age-sensitive reflected by bio-plausible transformations of shape and
texture, while being identity preserving. This is extremely challenging because
the shape and texture characteristics of a face undergo separate and highly
nonlinear transformations w.r.t. age. Most recent LFS models are based on
generative adversarial networks (GANs) whereby age code conditional
transformations are applied to a latent face representation. They benefit
greatly from the recent advancements of GANs. However, without explicitly
disentangling their latent representations into the texture, shape and identity
factors, they are fundamentally limited in modeling the nonlinear age-related
transformation on texture and shape whilst preserving identity. In this work, a
novel LFS model is proposed to disentangle the key face characteristics
including shape, texture and identity so that the unique shape and texture age
transformations can be modeled effectively. This is achieved by extracting
shape, texture and identity features separately from an encoder. Critically,
two transformation modules, one conditional convolution based and the other
channel attention based, are designed for modeling the nonlinear shape and
texture feature transformations respectively. This is to accommodate their
rather distinct aging processes and ensure that our synthesized images are both
age-sensitive and identity preserving. Extensive experiments show that our LFS
model is clearly superior to the state-of-the-art alternatives. Codes and demo
are available on our project website:
\url{https://senhe.github.io/projects/iccv_2021_lifespan_face}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unifying Nonlocal Blocks for Neural Networks. (arXiv:2108.02451v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yanye Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02451">
                                    <div class="article-summary-box-inner">
                                        <span>The nonlocal-based blocks are designed for capturing long-range
spatial-temporal dependencies in computer vision tasks. Although having shown
excellent performance, they still lack the mechanism to encode the rich,
structured information among elements in an image or video. In this paper, to
theoretically analyze the property of these nonlocal-based blocks, we provide a
new perspective to interpret them, where we view them as a set of graph filters
generated on a fully-connected graph. Specifically, when choosing the Chebyshev
graph filter, a unified formulation can be derived for explaining and analyzing
the existing nonlocal-based blocks (e.g., nonlocal block, nonlocal stage,
double attention block). Furthermore, by concerning the property of spectral,
we propose an efficient and robust spectral nonlocal block, which can be more
robust and flexible to catch long-range dependencies when inserted into deep
neural networks than the existing nonlocal blocks. Experimental results
demonstrate the clear-cut improvements and practical applicabilities of our
method on image classification, action recognition, semantic segmentation, and
person re-identification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPACE: A Simulator for Physical Interactions and Causal Learning in 3D Environments. (arXiv:2108.06180v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jiafei Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Samson Yu Bai Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheston Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06180">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep learning, computer vision, and embodied AI have
given rise to synthetic causal reasoning video datasets. These datasets
facilitate the development of AI algorithms that can reason about physical
interactions between objects. However, datasets thus far have primarily focused
on elementary physical events such as rolling or falling. There is currently a
scarcity of datasets that focus on the physical interactions that humans
perform daily with objects in the real world. To address this scarcity, we
introduce SPACE: A Simulator for Physical Interactions and Causal Learning in
3D Environments. The SPACE simulator allows us to generate the SPACE dataset, a
synthetic video dataset in a 3D environment, to systematically evaluate
physics-based models on a range of physical causal reasoning tasks. Inspired by
daily object interactions, the SPACE dataset comprises videos depicting three
types of physical events: containment, stability and contact. These events make
up the vast majority of the basic physical interactions between objects. We
then further evaluate it with a state-of-the-art physics-based deep model and
show that the SPACE dataset improves the learning of intuitive physics with an
approach inspired by curriculum learning. Repository:
https://github.com/jiafei1224/SPACE</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness testing of AI systems: A case study for traffic sign recognition. (arXiv:2108.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berghoff_C/0/1/0/all/0/1">Christian Berghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielik_P/0/1/0/all/0/1">Pavol Bielik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neu_M/0/1/0/all/0/1">Matthias Neu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsankov_P/0/1/0/all/0/1">Petar Tsankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Twickel_A/0/1/0/all/0/1">Arndt von Twickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06159">
                                    <div class="article-summary-box-inner">
                                        <span>In the last years, AI systems, in particular neural networks, have seen a
tremendous increase in performance, and they are now used in a broad range of
applications. Unlike classical symbolic AI systems, neural networks are trained
using large data sets and their inner structure containing possibly billions of
parameters does not lend itself to human interpretation. As a consequence, it
is so far not feasible to provide broad guarantees for the correct behaviour of
neural networks during operation if they process input data that significantly
differ from those seen during training. However, many applications of AI
systems are security- or safety-critical, and hence require obtaining
statements on the robustness of the systems when facing unexpected events,
whether they occur naturally or are induced by an attacker in a targeted way.
As a step towards developing robust AI systems for such applications, this
paper presents how the robustness of AI systems can be practically examined and
which methods and metrics can be used to do so. The robustness testing
methodology is described and analysed for the example use case of traffic sign
recognition in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TokenPose: Learning Keypoint Tokens for Human Pose Estimation. (arXiv:2104.03516v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shoukui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wankou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03516">
                                    <div class="article-summary-box-inner">
                                        <span>Human pose estimation deeply relies on visual clues and anatomical
constraints between parts to locate keypoints. Most existing CNN-based methods
do well in visual representation, however, lacking in the ability to explicitly
learn the constraint relationships between keypoints. In this paper, we propose
a novel approach based on Token representation for human Pose
estimation~(TokenPose). In detail, each keypoint is explicitly embedded as a
token to simultaneously learn constraint relationships and appearance cues from
images. Extensive experiments show that the small and large TokenPose models
are on par with state-of-the-art CNN-based counterparts while being more
lightweight. Specifically, our TokenPose-S and TokenPose-L achieve $72.5$ AP
and $75.8$ AP on COCO validation dataset respectively, with significant
reduction in parameters ($\downarrow80.6\%$; $\downarrow$ $56.8\%$) and GFLOPs
($\downarrow$ $75.3\%$; $\downarrow$ $24.7\%$). Code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Interpretable Classification and Weakly-Supervised Segmentation of Histology Images via Max-Min Uncertainty. (arXiv:2011.07221v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belharbi_S/0/1/0/all/0/1">Soufiane Belharbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rony_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Rony</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+McCaffrey_L/0/1/0/all/0/1">Luke McCaffrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07221">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised learning (WSL) has recently triggered substantial interest
as it mitigates the lack of pixel-wise annotations.

Given global image labels, WSL methods yield pixel-level predictions
(segmentations), which enable to interpret class predictions. Despite their
recent success, mostly with natural images, such methods can face important
challenges when the foreground and background regions have similar visual cues,
yielding high false-positive rates in segmentations, as is the case in
challenging histology images. WSL training is commonly driven by standard
classification losses, which implicitly maximize model confidence, and locate
the discriminative regions linked to classification decisions. Therefore, they
lack mechanisms for modeling explicitly non-discriminative regions and reducing
false-positive rates. We propose novel regularization terms, which enable the
model to seek both non-discriminative and discriminative regions, while
discouraging unbalanced segmentations. We introduce high uncertainty as a
criterion to localize non-discriminative regions that do not affect classifier
decision, and describe it with original Kullback-Leibler (KL) divergence losses
evaluating the deviation of posterior predictions from the uniform
distribution. Our KL terms encourage high uncertainty of the model when the
latter inputs the latent non-discriminative regions. Our loss integrates: (i) a
cross-entropy seeking a foreground, where model confidence about class
prediction is high; (ii) a KL regularizer seeking a background, where model
uncertainty is high; and (iii) log-barrier terms discouraging unbalanced
segmentations. Comprehensive experiments and ablation studies over the public
GlaS colon cancer data and a Camelyon16 patch-based benchmark for breast cancer
show substantial improvements over state-of-the-art WSL methods, and confirm
the effect of our new regularizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VTGAN: Semi-supervised Retinal Image Synthesis and Disease Prediction using Vision Transformers. (arXiv:2104.06757v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamran_S/0/1/0/all/0/1">Sharif Amit Kamran</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_K/0/1/0/all/0/1">Khondker Fariha Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Tavakkoli_A/0/1/0/all/0/1">Alireza Tavakkoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerbrod_S/0/1/0/all/0/1">Stewart Lee Zuckerbrod</a>, <a href="http://arxiv.org/find/eess/1/au:+Baker_S/0/1/0/all/0/1">Salah A. Baker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06757">
                                    <div class="article-summary-box-inner">
                                        <span>In Fluorescein Angiography (FA), an exogenous dye is injected in the
bloodstream to image the vascular structure of the retina. The injected dye can
cause adverse reactions such as nausea, vomiting, anaphylactic shock, and even
death. In contrast, color fundus imaging is a non-invasive technique used for
photographing the retina but does not have sufficient fidelity for capturing
its vascular structure. The only non-invasive method for capturing retinal
vasculature is optical coherence tomography-angiography (OCTA). However, OCTA
equipment is quite expensive, and stable imaging is limited to small areas on
the retina. In this paper, we propose a novel conditional generative
adversarial network (GAN) capable of simultaneously synthesizing FA images from
fundus photographs while predicting retinal degeneration. The proposed system
has the benefit of addressing the problem of imaging retinal vasculature in a
non-invasive manner as well as predicting the existence of retinal
abnormalities. We use a semi-supervised approach to train our GAN using
multiple weighted losses on different modalities of data. Our experiments
validate that the proposed architecture exceeds recent state-of-the-art
generative networks for fundus-to-angiography synthesis. Moreover, our vision
transformer-based discriminators generalize quite well on out-of-distribution
data sets for retinal disease prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Path Learning for Domain Adaptation of Semantic Segmentation. (arXiv:2108.06337v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yiting Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_F/0/1/0/all/0/1">Fang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenqiang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06337">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation for semantic segmentation enables to alleviate the need for
large-scale pixel-wise annotations. Recently, self-supervised learning (SSL)
with a combination of image-to-image translation shows great effectiveness in
adaptive segmentation. The most common practice is to perform SSL along with
image translation to well align a single domain (the source or target).
However, in this single-domain paradigm, unavoidable visual inconsistency
raised by image translation may affect subsequent learning. In this paper,
based on the observation that domain adaptation frameworks performed in the
source and target domain are almost complementary in terms of image translation
and SSL, we propose a novel dual path learning (DPL) framework to alleviate
visual inconsistency. Concretely, DPL contains two complementary and
interactive single-domain adaptation pipelines aligned in source and target
domain respectively. The inference of DPL is extremely simple, only one
segmentation model in the target domain is employed. Novel technologies such as
dual path image translation and dual path adaptive segmentation are proposed to
make two paths promote each other in an interactive manner. Experiments on
GTA5$\rightarrow$Cityscapes and SYNTHIA$\rightarrow$Cityscapes scenarios
demonstrate the superiority of our DPL model over the state-of-the-art methods.
The code and models are available at: \url{https://github.com/royee182/DPL}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech. (arXiv:2106.14736v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonell_P/0/1/0/all/0/1">Patrik Jonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14736">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework for gesture generation, aiming to allow
data-driven approaches to produce more semantically rich gestures. Our approach
first predicts whether to gesture, followed by a prediction of the gesture
properties. Those properties are then used as conditioning for a modern
probabilistic gesture-generation model capable of high-quality output. This
empowers the approach to generate gestures that are both diverse and
representational. Follow-ups and more information can be found on the project
page: https://svito-zar.github.io/speech2properties2gestures/ .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models. (arXiv:2106.00245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00245">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from large-scale pre-training, we have witnessed significant
performance boost on the popular Visual Question Answering (VQA) task. Despite
rapid progress, it remains unclear whether these state-of-the-art (SOTA) models
are robust when encountering examples in the wild. To study this, we introduce
Adversarial VQA, a new large-scale VQA benchmark, collected iteratively via an
adversarial human-and-model-in-the-loop procedure. Through this new benchmark,
we discover several interesting findings. (i) Surprisingly, we find that during
dataset collection, non-expert annotators can easily attack SOTA VQA models
successfully. (ii) Both large-scale pre-trained models and adversarial training
methods achieve far worse performance on the new benchmark than over standard
VQA v2 dataset, revealing the fragility of these models while demonstrating the
effectiveness of our adversarial dataset. (iii) When used for data
augmentation, our dataset can effectively boost model performance on other
robust VQA benchmarks. We hope our Adversarial VQA dataset can shed new light
on robustness study in the community and serve as a valuable benchmark for
future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuLF: Efficient Novel View Synthesis with Neural 4D Light Field. (arXiv:2105.07112v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Celong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Junsong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07112">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an efficient and robust deep learning solution for
novel view synthesis of complex scenes. In our approach, a 3D scene is
represented as a light field, i.e., a set of rays, each of which has a
corresponding color when reaching the image plane. For efficient novel view
rendering, we adopt a 4D parameterization of the light field, where each ray is
characterized by a 4D parameter. We then formulate the light field as a 4D
function that maps 4D coordinates to corresponding color values. We train a
deep fully connected network to optimize this implicit function and memorize
the 3D scene. Then, the scene-specific model is used to synthesize novel views.
Different from previous light field approaches which require dense view
sampling to reliably render novel views, our method can render novel views by
sampling rays and querying the color for each ray from the network directly,
thus enabling high-quality light field rendering with a sparser set of training
images. Our method achieves state-of-the-art novel view synthesis results while
maintaining an interactive frame rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild. (arXiv:2107.03465v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antoniadis_P/0/1/0/all/0/1">Panagiotis Antoniadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pikoulis_I/0/1/0/all/0/1">Ioannis Pikoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Filntisis_P/0/1/0/all/0/1">Panagiotis P. Filntisis</a>, <a href="http://arxiv.org/find/cs/1/au:+Maragos_P/0/1/0/all/0/1">Petros Maragos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03465">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we tackle the task of video-based audio-visual emotion
recognition, within the premises of the 2nd Workshop and Competition on
Affective Behavior Analysis in-the-wild (ABAW2). Poor illumination conditions,
head/body orientation and low image resolution constitute factors that can
potentially hinder performance in case of methodologies that solely rely on the
extraction and analysis of facial features. In order to alleviate this problem,
we leverage both bodily and contextual features, as part of a broader emotion
recognition framework. We choose to use a standard CNN-RNN cascade as the
backbone of our proposed model for sequence-to-sequence (seq2seq) learning.
Apart from learning through the RGB input modality, we construct an aural
stream which operates on sequences of extracted mel-spectrograms. Our extensive
experiments on the challenging and newly assembled Aff-Wild2 dataset verify the
validity of our intuitive multi-stream and multi-modal approach towards emotion
recognition in-the-wild. Emphasis is being laid on the the beneficial influence
of the human body and scene context, as aspects of the emotion recognition
process that have been left relatively unexplored up to this point. All the
code was implemented using PyTorch and is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FCOS3D: Fully Convolutional One-Stage Monocular 3D Object Detection. (arXiv:2104.10956v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinge Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10956">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular 3D object detection is an important task for autonomous driving
considering its advantage of low cost. It is much more challenging than
conventional 2D cases due to its inherent ill-posed property, which is mainly
reflected in the lack of depth information. Recent progress on 2D detection
offers opportunities to better solving this problem. However, it is non-trivial
to make a general adapted 2D detector work in this 3D task. In this paper, we
study this problem with a practice built on a fully convolutional single-stage
detector and propose a general framework FCOS3D. Specifically, we first
transform the commonly defined 7-DoF 3D targets to the image domain and
decouple them as 2D and 3D attributes. Then the objects are distributed to
different feature levels with consideration of their 2D scales and assigned
only according to the projected 3D-center for the training procedure.
Furthermore, the center-ness is redefined with a 2D Gaussian distribution based
on the 3D-center to fit the 3D target formulation. All of these make this
framework simple yet effective, getting rid of any 2D detection or 2D-3D
correspondence priors. Our solution achieves 1st place out of all the
vision-only methods in the nuScenes 3D detection challenge of NeurIPS 2020.
Code and models are released at https://github.com/open-mmlab/mmdetection3d.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectroscopic Approach to Correction and Visualisation of Bright-Field Light Transmission Microscopy Biological Data. (arXiv:1903.06519v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Platonova_G/0/1/0/all/0/1">Ganna Platonova</a>, <a href="http://arxiv.org/find/eess/1/au:+Stys_D/0/1/0/all/0/1">Dalibor Stys</a>, <a href="http://arxiv.org/find/eess/1/au:+Soucek_P/0/1/0/all/0/1">Pavel Soucek</a>, <a href="http://arxiv.org/find/eess/1/au:+Lonhus_K/0/1/0/all/0/1">Kirill Lonhus</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenta_J/0/1/0/all/0/1">Jan Valenta</a>, <a href="http://arxiv.org/find/eess/1/au:+Rychtarikova_R/0/1/0/all/0/1">Renata Rychtarikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.06519">
                                    <div class="article-summary-box-inner">
                                        <span>The most realistic information about the transparent sample such as a live
cell can be obtained only using bright-field light microscopy. At
high-intensity pulsing LED illumination, we captured a primary
12-bit-per-channel (bpc) response from an observed sample using a bright-field
microscope equipped with a high-resolution (4872x3248) image sensor. In order
to suppress data distortions originating from the light interactions with
elements in the optical path, poor sensor reproduction (geometrical defects of
the camera sensor and some peculiarities of sensor sensitivity), we propose a
spectroscopic approach for the correction of this uncompressed 12-bpc data by
simultaneous calibration of all parts of the experimental arrangement.
Moreover, the final intensities of the corrected images are proportional to the
photon fluxes detected by a camera sensor. It can be visualized in 8-bpc
intensity depth after the Least Information Loss compression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D point cloud segmentation using GIS. (arXiv:2108.06306v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao-Jung Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Krylov_V/0/1/0/all/0/1">Vladimir Krylov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahyot_R/0/1/0/all/0/1">Rozenn Dahyot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06306">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we propose an approach to perform semantic segmentation of 3D
point cloud data by importing the geographic information from a 2D GIS layer
(OpenStreetMap). The proposed automatic procedure identifies meaningful units
such as buildings and adjusts their locations to achieve best fit between the
GIS polygonal perimeters and the point cloud. Our processing pipeline is
presented and illustrated by segmenting point cloud data of Trinity College
Dublin (Ireland) campus constructed from optical imagery collected by a drone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEEA-Net: An Early Exit Evolutionary Neural Architecture Search. (arXiv:2108.06156v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Termritthikun_C/0/1/0/all/0/1">Chakkrit Termritthikun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamtsho_Y/0/1/0/all/0/1">Yeshi Jamtsho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ieamsaard_J/0/1/0/all/0/1">Jirarat Ieamsaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Muneesawang_P/0/1/0/all/0/1">Paisarn Muneesawang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Ivan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06156">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this research were to search for Convolutional Neural Network
(CNN) architectures, suitable for an on-device processor with limited computing
resources, performing at substantially lower Network Architecture Search (NAS)
costs. A new algorithm entitled an Early Exit Population Initialisation (EE-PI)
for Evolutionary Algorithm (EA) was developed to achieve both goals. The EE-PI
reduces the total number of parameters in the search process by filtering the
models with fewer parameters than the maximum threshold. It will look for a new
model to replace those models with parameters more than the threshold. Thereby,
reducing the number of parameters, memory usage for model storage and
processing time while maintaining the same performance or accuracy. The search
time was reduced to 0.52 GPU day. This is a huge and significant achievement
compared to the NAS of 4 GPU days achieved using NSGA-Net, 3,150 GPU days by
the AmoebaNet model, and the 2,000 GPU days by the NASNet model. As well, Early
Exit Evolutionary Algorithm networks (EEEA-Nets) yield network architectures
with minimal error and computational cost suitable for a given dataset as a
class of network algorithms. Using EEEA-Net on CIFAR-10, CIFAR-100, and
ImageNet datasets, our experiments showed that EEEA-Net achieved the lowest
error rate among state-of-the-art NAS models, with 2.46% for CIFAR-10, 15.02%
for CIFAR-100, and 23.8% for ImageNet dataset. Further, we implemented this
image recognition architecture for other tasks, such as object detection,
semantic segmentation, and keypoint detection tasks, and, in our experiments,
EEEA-Net-C2 outperformed MobileNet-V3 on all of these various tasks. (The
algorithm code is available at https://github.com/chakkritte/EEEA-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets, often with better accuracy and fewer
parameters. Our model eliminates the requirement for class token and positional
embeddings through a novel sequence pooling strategy and the use of
convolution/s. It is flexible in terms of model size, and can have as little as
0.28M parameters while achieving good results. Our model can reach 98.00%
accuracy when training from scratch on CIFAR-10, which is a significant
improvement over previous Transformer based models. It also outperforms many
modern CNN based approaches, such as ResNet, and even some recent NAS-based
approaches, such as Proxyless-NAS. Our simple and compact design democratizes
transformers by making them accessible to those with limited computing
resources and/or dealing with small datasets. Our method also works on larger
datasets, such as ImageNet (82.71% accuracy with 29% parameters of ViT), and
NLP tasks as well. Our code and pre-trained models are publicly available at
https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior Analysis. (arXiv:2107.04225v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shisen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jin Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_K/0/1/0/all/0/1">Kenji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04225">
                                    <div class="article-summary-box-inner">
                                        <span>Affective Behavior Analysis is an important part in human-computer
interaction. Existing multi-task affective behavior recognition methods suffer
from the problem of incomplete labeled datasets. To tackle this problem, this
paper presents a semi-supervised model with a mean teacher framework to
leverage additional unlabeled data. To be specific, a multi-task model is
proposed to learn three different kinds of facial affective representations
simultaneously. After that, the proposed model is assigned to be student and
teacher networks. When training with unlabeled data, the teacher network is
employed to predict pseudo labels for student network training, which allows it
to learn from unlabeled data. Experimental results showed that our proposed
method achieved much better performance than baseline model and ranked 4th in
both competition track 1 and track 2, and 6th in track 3, which verifies that
the proposed network can effectively learn from incomplete datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Zero-Shot Learning for Semantic Segmentation of 3D Point Cloud. (arXiv:2108.06230v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Michele_B/0/1/0/all/0/1">Bj&#xf6;rn Michele</a>, <a href="http://arxiv.org/find/cs/1/au:+Boulch_A/0/1/0/all/0/1">Alexandre Boulch</a>, <a href="http://arxiv.org/find/cs/1/au:+Puy_G/0/1/0/all/0/1">Gilles Puy</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlet_R/0/1/0/all/0/1">Renaud Marlet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06230">
                                    <div class="article-summary-box-inner">
                                        <span>While there has been a number of studies on Zero-Shot Learning (ZSL) for 2D
images, its application to 3D data is still recent and scarce, with just a few
methods limited to classification. We present the first generative approach for
both ZSL and Generalized ZSL (GZSL) on 3D data, that can handle both
classification and, for the first time, semantic segmentation. We show that it
reaches or outperforms the state of the art on ModelNet40 classification for
both inductive ZSL and inductive GZSL. For semantic segmentation, we created
three benchmarks for evaluating this new ZSL task, using S3DIS, ScanNet and
SemanticKITTI. Our experiments show that our method outperforms strong
baselines, which we additionally propose for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LSG-CPD: Coherent Point Drift with Local Surface Geometry for Point Cloud Registration. (arXiv:2103.15039v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weixiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongtao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chirikjian_G/0/1/0/all/0/1">Gregory Chirikjian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15039">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic point cloud registration methods are becoming more popular
because of their robustness. However, unlike point-to-plane variants of
iterative closest point (ICP) which incorporate local surface geometric
information such as surface normals, most probabilistic methods (e.g., coherent
point drift (CPD)) ignore such information and build Gaussian mixture models
(GMMs) with isotropic Gaussian covariances. This results in sphere-like GMM
components which only penalize the point-to-point distance between the two
point clouds. In this paper, we propose a novel method called CPD with Local
Surface Geometry (LSG-CPD) for rigid point cloud registration. Our method
adaptively adds different levels of point-to-plane penalization on top of the
point-to-point penalization based on the flatness of the local surface. This
results in GMM components with anisotropic covariances. We formulate point
cloud registration as a maximum likelihood estimation (MLE) problem and solve
it with the Expectation-Maximization (EM) algorithm. In the E step, we
demonstrate that the computation can be recast into simple matrix manipulations
and efficiently computed on a GPU. In the M step, we perform an unconstrained
optimization on a matrix Lie group to efficiently update the rigid
transformation of the registration. The proposed method outperforms
state-of-the-art algorithms in terms of accuracy and robustness on various
datasets captured with range scanners, RGBD cameras, and LiDARs. Also, it is
significantly faster than modern implementations of CPD. The source code is
available at https://github.com/ChirikjianLab/LSG-CPD.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Transferable Parameters for Unsupervised Domain Adaptation. (arXiv:2108.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhongyi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haoliang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) enables a learning machine to adapt from
a labeled source domain to an unlabeled domain under the distribution shift.
Thanks to the strong representation ability of deep neural networks, recent
remarkable achievements in UDA resort to learning domain-invariant features.
Intuitively, the hope is that a good feature representation, together with the
hypothesis learned from the source domain, can generalize well to the target
domain. However, the learning processes of domain-invariant features and source
hypothesis inevitably involve domain-specific information that would degrade
the generalizability of UDA models on the target domain. In this paper,
motivated by the lottery ticket hypothesis that only partial parameters are
essential for generalization, we find that only partial parameters are
essential for learning domain-invariant information and generalizing well in
UDA. Such parameters are termed transferable parameters. In contrast, the other
parameters tend to fit domain-specific details and often fail to generalize,
which we term as untransferable parameters. Driven by this insight, we propose
Transferable Parameter Learning (TransPar) to reduce the side effect brought by
domain-specific information in the learning process and thus enhance the
memorization of domain-invariant information. Specifically, according to the
distribution discrepancy degree, we divide all parameters into transferable and
untransferable ones in each training iteration. We then perform separate
updates rules for the two types of parameters. Extensive experiments on image
classification and regression tasks (keypoint detection) show that TransPar
outperforms prior arts by non-trivial margins. Moreover, experiments
demonstrate that TransPar can be integrated into the most popular deep UDA
networks and be easily extended to handle any data distribution shift
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Surface Function Networks for Clothed Human Bodies. (arXiv:2104.03978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burov_A/0/1/0/all/0/1">Andrei Burov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03978">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for temporal coherent reconstruction and tracking
of clothed humans. Given a monocular RGB-D sequence, we learn a person-specific
body model which is based on a dynamic surface function network. To this end,
we explicitly model the surface of the person using a multi-layer perceptron
(MLP) which is embedded into the canonical space of the SMPL body model. With
classical forward rendering, the represented surface can be rasterized using
the topology of a template mesh. For each surface point of the template mesh,
the MLP is evaluated to predict the actual surface location. To handle
pose-dependent deformations, the MLP is conditioned on the SMPL pose
parameters. We show that this surface representation as well as the pose
parameters can be learned in a self-supervised fashion using the principle of
analysis-by-synthesis and differentiable rasterization. As a result, we are
able to reconstruct a temporally coherent mesh sequence from the input data.
The underlying surface representation can be used to synthesize new animations
of the reconstructed person including pose-dependent deformations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards artificially intelligent recycling Improving image processing for waste classification. (arXiv:2108.06274v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youpeng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Grammenos_R/0/1/0/all/0/1">Ryan Grammenos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06274">
                                    <div class="article-summary-box-inner">
                                        <span>The ever-increasing amount of global refuse is overwhelming the waste and
recycling management industries. The need for smart systems for environmental
monitoring and the enhancement of recycling processes is thus greater than
ever. Amongst these efforts lies IBM&#x27;s Wastenet project which aims to improve
recycling by using artificial intelligence for waste classification. The work
reported in this paper builds on this project through the use of transfer
learning and data augmentation techniques to ameliorate classification
accuracy. Starting with a convolutional neural network (CNN), a systematic
approach is followed for selecting appropriate splitting ratios and for tuning
multiple training parameters including learning rate schedulers, layers
freezing, batch sizes and loss functions, in the context of the given scenario
which requires classification of waste into different recycling types. Results
are compared and contrasted using 10-fold cross validation and demonstrate that
the model developed achieves a 91.21% test accuracy. Subsequently, a range of
data augmentation techniques are then incorporated into this work including
flipping, rotation, shearing, zooming, and brightness control. Results show
that these augmentation techniques further improve the test accuracy of the
final model to 95.40%. Unlike other work reported in the field, this paper
provides full details regarding the training of the model. Furthermore, the
code for this work has been made open-source and we have demonstrated that the
model can perform successful real-time classification of recycling waste items
using a standard computer webcam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v10 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dai Quoc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer self-attention network has been extensively used in research
domains such as computer vision, image processing, and natural language
processing. The transformer, however, has not been actively used in graph
neural networks, where constructing an advanced aggregation function is
essential. To this end, we present an effective model, named UGformer, which --
by leveraging a transformer self-attention mechanism followed by a recurrent
transition -- induces an advanced aggregation function to learn graph
representations. Experimental results show that UGformer achieves
state-of-the-art accuracies on well-known benchmark datasets for graph
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Full-resolution quality assessment for pansharpening. (arXiv:2108.06144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scarpa_G/0/1/0/all/0/1">Giuseppe Scarpa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciotola_M/0/1/0/all/0/1">Matteo Ciotola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06144">
                                    <div class="article-summary-box-inner">
                                        <span>A reliable quality assessment procedure for pansharpening methods is of
critical importance for the development of the related solutions.
Unfortunately, the lack of ground-truths to be used as guidance for an
objective evaluation has pushed the community to resort to either
reference-based reduced-resolution indexes or to no-reference subjective
quality indexes that can be applied on full-resolution datasets. In particular,
the reference-based approach leverages on Wald&#x27;s protocol, a resolution
degradation process that allows one to synthesize data with related ground
truth. Both solutions, however, present critical shortcomings that we aim to
mitigate in this work by means of an alternative no-reference full-resolution
framework. On one side we introduce a protocol, namely the reprojection
protocol, which allows to handle the spectral fidelity problem. On the other
side, a new index of the spatial consistency between the pansharpened image and
the panchromatic band at full resolution is proposed. The experimental results
show the effectiveness of the proposed approach which is confirmed also by
visual inspection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry Uncertainty Projection Network for Monocular 3D Object Detection. (arXiv:2107.13774v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xinzhu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianzhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yating Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1">Qi Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13774">
                                    <div class="article-summary-box-inner">
                                        <span>Geometry Projection is a powerful depth estimation method in monocular 3D
object detection. It estimates depth dependent on heights, which introduces
mathematical priors into the deep model. But projection process also introduces
the error amplification problem, in which the error of the estimated height
will be amplified and reflected greatly at the output depth. This property
leads to uncontrollable depth inferences and also damages the training
efficiency. In this paper, we propose a Geometry Uncertainty Projection Network
(GUP Net) to tackle the error amplification problem at both inference and
training stages. Specifically, a GUP module is proposed to obtains the
geometry-guided uncertainty of the inferred depth, which not only provides high
reliable confidence for each depth but also benefits depth learning.
Furthermore, at the training stage, we propose a Hierarchical Task Learning
strategy to reduce the instability caused by error amplification. This learning
algorithm monitors the learning situation of each task by a proposed indicator
and adaptively assigns the proper loss weights for different tasks according to
their pre-tasks situation. Based on that, each task starts learning only when
its pre-tasks are learned well, which can significantly improve the stability
and efficiency of the training process. Extensive experiments demonstrate the
effectiveness of the proposed method. The overall model can infer more reliable
object depth than existing methods and outperforms the state-of-the-art
image-based monocular 3D detectors by 3.74% and 4.7% AP40 of the car and
pedestrian categories on the KITTI benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Inversion: A Survey. (arXiv:2101.05278v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Weihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yulun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yujiu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jing-Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05278">
                                    <div class="article-summary-box-inner">
                                        <span>GAN inversion aims to invert a given image back into the latent space of a
pretrained GAN model, for the image to be faithfully reconstructed from the
inverted code by the generator. As an emerging technique to bridge the real and
fake image domains, GAN inversion plays an essential role in enabling the
pretrained GAN models such as StyleGAN and BigGAN to be used for real image
editing applications. Meanwhile, GAN inversion also provides insights on the
interpretation of GAN&#x27;s latent space and how the realistic images can be
generated. In this paper, we provide an overview of GAN inversion with a focus
on its recent algorithms and applications. We cover important techniques of GAN
inversion and their applications to image restoration and image manipulation.
We further elaborate on some trends and challenges for future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IFR: Iterative Fusion Based Recognizer For Low Quality Scene Text Recognition. (arXiv:2108.06166v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shugong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_S/0/1/0/all/0/1">Shiyi Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yue Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06166">
                                    <div class="article-summary-box-inner">
                                        <span>Although recent works based on deep learning have made progress in improving
recognition accuracy on scene text recognition, how to handle low-quality text
images in end-to-end deep networks remains a research challenge. In this paper,
we propose an Iterative Fusion based Recognizer (IFR) for low quality scene
text recognition, taking advantage of refined text images input and robust
feature representation. IFR contains two branches which focus on scene text
recognition and low quality scene text image recovery respectively. We utilize
an iterative collaboration between two branches, which can effectively
alleviate the impact of low quality input. A feature fusion module is proposed
to strengthen the feature representation of the two branches, where the
features from the Recognizer are Fused with image Restoration branch, referred
to as RRF. Without changing the recognition network structure, extensive
quantitative and qualitative experimental results show that the proposed method
significantly outperforms the baseline methods in boosting the recognition
accuracy of benchmark datasets and low resolution images in TextZoom dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Interpretable Algorithm for Uveal Melanoma Subtyping from Whole Slide Cytology Images. (arXiv:2108.06246v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haomin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">T.Y. Alvin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_C/0/1/0/all/0/1">Catalina Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Correa_Z/0/1/0/all/0/1">Zelia Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06246">
                                    <div class="article-summary-box-inner">
                                        <span>Algorithmic decision support is rapidly becoming a staple of personalized
medicine, especially for high-stakes recommendations in which access to certain
information can drastically alter the course of treatment, and thus, patient
outcome; a prominent example is radiomics for cancer subtyping. Because in
these scenarios the stakes are high, it is desirable for decision systems to
not only provide recommendations but supply transparent reasoning in support
thereof. For learning-based systems, this can be achieved through an
interpretable design of the inference pipeline. Herein we describe an automated
yet interpretable system for uveal melanoma subtyping with digital cytology
images from fine needle aspiration biopsies. Our method embeds every
automatically segmented cell of a candidate cytology image as a point in a 2D
manifold defined by many representative slides, which enables reasoning about
the cell-level composition of the tissue sample, paving the way for
interpretable subtyping of the biopsy. Finally, a rule-based slide-level
classification algorithm is trained on the partitions of the circularly
distorted 2D manifold. This process results in a simple rule set that is
evaluated automatically but highly transparent for human verification. On our
in house cytology dataset of 88 uveal melanoma patients, the proposed method
achieves an accuracy of 87.5% that compares favorably to all competing
approaches, including deep &quot;black box&quot; models. The method comes with a user
interface to facilitate interaction with cell-level content, which may offer
additional insights for pathological assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional DETR for Fast Training Convergence. (arXiv:2108.06152v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Depu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaokang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zejia Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1">Gang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuhui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06152">
                                    <div class="article-summary-box-inner">
                                        <span>The recently-developed DETR approach applies the transformer encoder and
decoder architecture to object detection and achieves promising performance. In
this paper, we handle the critical issue, slow training convergence, and
present a conditional cross-attention mechanism for fast DETR training. Our
approach is motivated by that the cross-attention in DETR relies highly on the
content embeddings for localizing the four extremities and predicting the box,
which increases the need for high-quality content embeddings and thus the
training difficulty. Our approach, named conditional DETR, learns a conditional
spatial query from the decoder embedding for decoder multi-head
cross-attention. The benefit is that through the conditional spatial query,
each cross-attention head is able to attend to a band containing a distinct
region, e.g., one object extremity or a region inside the object box. This
narrows down the spatial range for localizing the distinct regions for object
classification and box regression, thus relaxing the dependence on the content
embeddings and easing the training. Empirical results show that conditional
DETR converges 6.7x faster for the backbones R50 and R101 and 10x faster for
stronger backbones DC5-R50 and DC5-R101. Code is available at
https://git.io/ConditionalDETR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimCVD: Simple Contrastive Voxel-Wise Representation Distillation for Semi-Supervised Medical Image Segmentation. (arXiv:2108.06227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruihan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1">Lawrence Staib</a>, <a href="http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1">James S. Duncan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06227">
                                    <div class="article-summary-box-inner">
                                        <span>Automated segmentation in medical image analysis is a challenging task that
requires a large amount of manually labeled data. However, most existing
learning-based approaches usually suffer from limited manually annotated
medical data, which poses a major practical problem for accurate and robust
medical image segmentation. In addition, most existing semi-supervised
approaches are usually not robust compared with the supervised counterparts,
and also lack explicit modeling of geometric structure and semantic
information, both of which limit the segmentation accuracy. In this work, we
present SimCVD, a simple contrastive distillation framework that significantly
advances state-of-the-art voxel-wise representation learning. We first describe
an unsupervised training strategy, which takes two views of an input volume and
predicts their signed distance maps of object boundaries in a contrastive
objective, with only two independent dropout as mask. This simple approach
works surprisingly well, performing on the same level as previous fully
supervised methods with much less labeled data. We hypothesize that dropout can
be viewed as a minimal form of data augmentation and makes the network robust
to representation collapse. Then, we propose to perform structural distillation
by distilling pair-wise similarities. We evaluate SimCVD on two popular
datasets: the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT
dataset. The results on the LA dataset demonstrate that, in two types of
labeled ratios (i.e., 20% and 10%), SimCVD achieves an average Dice score of
90.85% and 89.03% respectively, a 0.91% and 2.22% improvement compared to
previous best results. Our method can be trained in an end-to-end fashion,
showing the promise of utilizing SimCVD as a general framework for downstream
tasks, such as medical image synthesis and registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient Point Cloud Graph Neural Networks Through Architectural Simplification. (arXiv:2108.06317v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1">Shyam A. Tailor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_R/0/1/0/all/0/1">Ren&#xe9; de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Azevedo_T/0/1/0/all/0/1">Tiago Azevedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1">Matthew Mattina</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1">Partha Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06317">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years graph neural network (GNN)-based approaches have become a
popular strategy for processing point cloud data, regularly achieving
state-of-the-art performance on a variety of tasks. To date, the research
community has primarily focused on improving model expressiveness, with
secondary thought given to how to design models that can run efficiently on
resource constrained mobile devices including smartphones or mixed reality
headsets. In this work we make a step towards improving the efficiency of these
models by making the observation that these GNN models are heavily limited by
the representational power of their first, feature extracting, layer. We find
that it is possible to radically simplify these models so long as the feature
extraction layer is retained with minimal degradation to model performance;
further, we discover that it is possible to improve performance overall on
ModelNet40 and S3DIS by improving the design of the feature extractor. Our
approach reduces memory consumption by 20$\times$ and latency by up to
9.9$\times$ for graph layers in models such as DGCNN; overall, we achieve
speed-ups of up to 4.5$\times$ and peak memory reductions of 72.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based transformation of the H&amp;E stain into special stains. (arXiv:2008.08871v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Haan_K/0/1/0/all/0/1">Kevin de Haan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yijie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerman_J/0/1/0/all/0/1">Jonathan E. Zuckerman</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tairan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sisk_A/0/1/0/all/0/1">Anthony E. Sisk</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_M/0/1/0/all/0/1">Miguel F. P. Diaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Jen_K/0/1/0/all/0/1">Kuang-Yu Jen</a>, <a href="http://arxiv.org/find/eess/1/au:+Nobori_A/0/1/0/all/0/1">Alexander Nobori</a>, <a href="http://arxiv.org/find/eess/1/au:+Liou_S/0/1/0/all/0/1">Sofia Liou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Sarah Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Riahi_R/0/1/0/all/0/1">Rana Riahi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rivenson_Y/0/1/0/all/0/1">Yair Rivenson</a>, <a href="http://arxiv.org/find/eess/1/au:+Wallace_W/0/1/0/all/0/1">W. Dean Wallace</a>, <a href="http://arxiv.org/find/eess/1/au:+Ozcan_A/0/1/0/all/0/1">Aydogan Ozcan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08871">
                                    <div class="article-summary-box-inner">
                                        <span>Pathology is practiced by visual inspection of histochemically stained
slides. Most commonly, the hematoxylin and eosin (H&amp;E) stain is used in the
diagnostic workflow and it is the gold standard for cancer diagnosis. However,
in many cases, especially for non-neoplastic diseases, additional &quot;special
stains&quot; are used to provide different levels of contrast and color to tissue
components and allow pathologists to get a clearer diagnostic picture. In this
study, we demonstrate the utility of supervised learning-based computational
stain transformation from H&amp;E to different special stains (Masson&#x27;s Trichrome,
periodic acid-Schiff and Jones silver stain) using tissue sections from kidney
needle core biopsies. Based on evaluation by three renal pathologists, followed
by adjudication by a fourth renal pathologist, we show that the generation of
virtual special stains from existing H&amp;E images improves the diagnosis in
several non-neoplastic kidney diseases sampled from 58 unique subjects. A
second study performed by three pathologists found that the quality of the
special stains generated by the stain transformation network was statistically
equivalent to those generated through standard histochemical staining. As the
transformation of H&amp;E images into special stains can be achieved within 1 min
or less per patient core specimen slide, this stain-to-stain transformation
framework can improve the quality of the preliminary diagnosis when additional
special stains are needed, along with significant savings in time and cost,
reducing the burden on healthcare system and patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Robustness of Semantic Segmentation for Autonomous Driving against Real-World Adversarial Patch Attacks. (arXiv:2108.06179v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nesti_F/0/1/0/all/0/1">Federico Nesti</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossolini_G/0/1/0/all/0/1">Giulio Rossolini</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Saasha Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Biondi_A/0/1/0/all/0/1">Alessandro Biondi</a>, <a href="http://arxiv.org/find/cs/1/au:+Buttazzo_G/0/1/0/all/0/1">Giorgio Buttazzo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06179">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning and convolutional neural networks allow achieving impressive
performance in computer vision tasks, such as object detection and semantic
segmentation (SS). However, recent studies have shown evident weaknesses of
such models against adversarial perturbations. In a real-world scenario
instead, like autonomous driving, more attention should be devoted to
real-world adversarial examples (RWAEs), which are physical objects (e.g.,
billboards and printable patches) optimized to be adversarial to the entire
perception pipeline. This paper presents an in-depth evaluation of the
robustness of popular SS models by testing the effects of both digital and
real-world adversarial patches. These patches are crafted with powerful attacks
enriched with a novel loss function. Firstly, an investigation on the
Cityscapes dataset is conducted by extending the Expectation Over
Transformation (EOT) paradigm to cope with SS. Then, a novel attack
optimization, called scene-specific attack, is proposed. Such an attack
leverages the CARLA driving simulator to improve the transferability of the
proposed EOT-based attack to a real 3D environment. Finally, a printed physical
billboard containing an adversarial patch was tested in an outdoor driving
scenario to assess the feasibility of the studied attacks in the real world.
Exhaustive experiments revealed that the proposed attack formulations
outperform previous work to craft both digital and real-world adversarial
patches for SS. At the same time, the experimental results showed how these
attacks are notably less effective in the real world, hence questioning the
practical relevance of adversarial attacks to SS models for autonomous/assisted
driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DDNet: Dual-path Decoder Network for Occlusion Relationship Reasoning. (arXiv:1911.11582v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1">Lizhu Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11582">
                                    <div class="article-summary-box-inner">
                                        <span>Occlusion relationship reasoning based on convolution neural networks
consists of two subtasks: occlusion boundary extraction and occlusion
orientation inference. Due to the essential differences between the two
subtasks in the feature expression at the higher and lower stages, it is
challenging to carry on them simultaneously in one network. To address this
issue, we propose a novel Dual-path Decoder Network, which uniformly extracts
occlusion information at higher stages and separates into two paths to recover
boundary and occlusion orientation respectively in lower stages. Besides,
considering the restriction of occlusion orientation presentation to occlusion
orientation learning, we design a new orthogonal representation for occlusion
orientation and proposed the Orthogonal Orientation Regression loss which can
get rid of the unfitness between occlusion representation and learning and
further prompt the occlusion orientation learning. Finally, we apply a
multi-scale loss together with our proposed orientation regression loss to
guide the boundary and orientation path learning respectively. Experiments
demonstrate that our proposed method achieves state-of-the-art results on PIOD
and BSDS ownership datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Language Navigation with Random Environmental Mixup. (arXiv:2106.07876v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fengda Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiaojun Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yi-Dong Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07876">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-language Navigation (VLN) tasks require an agent to navigate
step-by-step while perceiving the visual observations and comprehending a
natural language instruction. Large data bias, which is caused by the disparity
ratio between the small data scale and large navigation space, makes the VLN
task challenging. Previous works have proposed various data augmentation
methods to reduce data bias. However, these works do not explicitly reduce the
data bias across different house scenes. Therefore, the agent would overfit to
the seen scenes and achieve poor navigation performance in the unseen scenes.
To tackle this problem, we propose the Random Environmental Mixup (REM) method,
which generates cross-connected house scenes as augmented data via mixuping
environment. Specifically, we first select key viewpoints according to the room
connection graph for each scene. Then, we cross-connect the key views of
different scenes to construct augmented scenes. Finally, we generate augmented
instruction-path pairs in the cross-connected scenes. The experimental results
on benchmark datasets demonstrate that our augmentation data via REM help the
agent reduce its performance gap between the seen and unseen environment and
improve the overall performance, making our model the best existing approach on
the standard VLN benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FIERY: Future Instance Prediction in Bird&#x27;s-Eye View from Surround Monocular Cameras. (arXiv:2104.10490v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1">Anthony Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Murez_Z/0/1/0/all/0/1">Zak Murez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_N/0/1/0/all/0/1">Nikhil Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudas_S/0/1/0/all/0/1">Sof&#xed;a Dudas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawke_J/0/1/0/all/0/1">Jeffrey Hawke</a>, <a href="http://arxiv.org/find/cs/1/au:+Badrinarayanan_V/0/1/0/all/0/1">Vijay Badrinarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cipolla_R/0/1/0/all/0/1">Roberto Cipolla</a>, <a href="http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1">Alex Kendall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10490">
                                    <div class="article-summary-box-inner">
                                        <span>Driving requires interacting with road agents and predicting their future
behaviour in order to navigate safely. We present FIERY: a probabilistic future
prediction model in bird&#x27;s-eye view from monocular cameras. Our model predicts
future instance segmentation and motion of dynamic agents that can be
transformed into non-parametric future trajectories. Our approach combines the
perception, sensor fusion and prediction components of a traditional autonomous
driving stack by estimating bird&#x27;s-eye-view prediction directly from surround
RGB monocular camera inputs. FIERY learns to model the inherent stochastic
nature of the future solely from camera driving data in an end-to-end manner,
without relying on HD maps, and predicts multimodal future trajectories. We
show that our model outperforms previous prediction baselines on the NuScenes
and Lyft datasets. The code and trained models are available at
https://github.com/wayveai/fiery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Random Walker Segmentation for Large Volumetric Biomedical Images. (arXiv:2103.09564v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drees_D/0/1/0/all/0/1">Dominik Drees</a>, <a href="http://arxiv.org/find/cs/1/au:+Eilers_F/0/1/0/all/0/1">Florian Eilers</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoyi Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09564">
                                    <div class="article-summary-box-inner">
                                        <span>The random walker method for image segmentation is a popular tool for
semi-automatic image segmentation, especially in the biomedical field. However,
its linear asymptotic run time and memory requirements make application to 3D
datasets of increasing sizes impractical. We propose a hierarchical framework
that, to the best of our knowledge, is the first attempt to overcome these
restrictions for the random walker algorithm and achieves sublinear run time
and constant memory complexity. The goal of this framework is -- rather than
improving the segmentation quality compared to the baseline method -- to make
interactive segmentation on out-of-core datasets possible. The method is
evaluated quantitavely on synthetic data and the CT-ORG dataset where the
expected improvements in algorithm run time while maintaining high segmentation
quality are confirmed. The incremental (i.e., interaction update) run time is
demonstrated to be in seconds on a standard PC even for volumes of hundreds of
Gigabytes in size. In a small case study the applicability to large real world
from current biomedical research is demonstrated. An implementation of the
presented method is publicly available in version 5.2 of the widely used volume
rendering and processing software Voreen (https://www.uni-muenster.de/Voreen/).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Continuity to Editability: Inverting GANs with Consecutive Images. (arXiv:2107.13812v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yangyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenpeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuemiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shengfeng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13812">
                                    <div class="article-summary-box-inner">
                                        <span>Existing GAN inversion methods are stuck in a paradox that the inverted codes
can either achieve high-fidelity reconstruction, or retain the editing
capability. Having only one of them clearly cannot realize real image editing.
In this paper, we resolve this paradox by introducing consecutive images (\eg,
video frames or the same person with different poses) into the inversion
process. The rationale behind our solution is that the continuity of
consecutive images leads to inherent editable directions. This inborn property
is used for two unique purposes: 1) regularizing the joint inversion process,
such that each of the inverted code is semantically accessible from one of the
other and fastened in a editable domain; 2) enforcing inter-image coherence,
such that the fidelity of each inverted code can be maximized with the
complement of other images. Extensive experiments demonstrate that our
alternative significantly outperforms state-of-the-art methods in terms of
reconstruction fidelity and editability on both the real image dataset and
synthesis dataset. Furthermore, our method provides the first support of
video-based GAN inversion, and an interesting application of unsupervised
semantic transfer from consecutive images. Source code can be found at:
\url{https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CNN-based Two-Stage Parking Slot Detection Using Region-Specific Multi-Scale Feature Extraction. (arXiv:2108.06185v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bui_Q/0/1/0/all/0/1">Quang Huy Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhr_J/0/1/0/all/0/1">Jae Kyu Suhr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06185">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous parking systems start with the detection of available parking
slots. Parking slot detection performance has been dramatically improved by
deep learning techniques. Deep learning-based object detection methods can be
categorized into one-stage and two-stage approaches. Although it is well-known
that the two-stage approach outperforms the one-stage approach in general
object detection, they have performed similarly in parking slot detection so
far. We consider this is because the two-stage approach has not yet been
adequately specialized for parking slot detection. Thus, this paper proposes a
highly specialized two-stage parking slot detector that uses region-specific
multi-scale feature extraction. In the first stage, the proposed method finds
the entrance of the parking slot as a region proposal by estimating its center,
length, and orientation. The second stage of this method designates specific
regions that most contain the desired information and extracts features from
them. That is, features for the location and orientation are separately
extracted from only the specific regions that most contain the locational and
orientational information. In addition, multi-resolution feature maps are
utilized to increase both positioning and classification accuracies. A
high-resolution feature map is used to extract detailed information (location
and orientation), while another low-resolution feature map is used to extract
semantic information (type and occupancy). In experiments, the proposed method
was quantitatively evaluated with two large-scale public parking slot detection
datasets and outperformed previous methods, including both one-stage and
two-stage approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MUSIQ: Multi-scale Image Quality Transformer. (arXiv:2108.05997v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1">Junjie Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Feng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05997">
                                    <div class="article-summary-box-inner">
                                        <span>Image quality assessment (IQA) is an important research topic for
understanding and improving visual experience. The current state-of-the-art IQA
methods are based on convolutional neural networks (CNNs). The performance of
CNN-based models is often compromised by the fixed shape constraint in batch
training. To accommodate this, the input images are usually resized and cropped
to a fixed shape, causing image quality degradation. To address this, we design
a multi-scale image quality Transformer (MUSIQ) to process native resolution
images with varying sizes and aspect ratios. With a multi-scale image
representation, our proposed method can capture image quality at different
granularities. Furthermore, a novel hash-based 2D spatial embedding and a scale
embedding is proposed to support the positional embedding in the multi-scale
representation. Experimental results verify that our method can achieve
state-of-the-art performance on multiple large scale IQA datasets such as
PaQ-2-PiQ, SPAQ and KonIQ-10k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANav: Group-wise Attention Network for Classifying Navigable Regions in Unstructured Outdoor Environments. (arXiv:2103.04233v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_T/0/1/0/all/0/1">Tianrui Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothandaraman_D/0/1/0/all/0/1">Divya Kothandaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Rohan Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sathyamoorthy_A/0/1/0/all/0/1">Adarsh Jagan Sathyamoorthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1">Dinesh Manocha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04233">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new learning-based method for identifying safe and navigable
regions in off-road terrains and unstructured environments from RGB images. Our
approach consists of classifying groups of terrains based on their navigability
levels using coarse-grained semantic segmentation. We propose a bottleneck
transformer-based deep neural network architecture that uses a novel group-wise
attention mechanism to distinguish between navigability levels of different
terrains. Our group-wise attention heads enable the network to explicitly focus
on the different groups and improve the accuracy. We show through extensive
evaluations on the RUGD and RELLIS-3D datasets that our learning algorithm
improves visual perception accuracy in off-road terrains for navigation. We
compare our approach with prior work on these datasets and achieve an
improvement over the state-of-the-art mIoU by 6.74-39.1% on RUGD and
3.82-10.64% on RELLIS-3D. In addition, we deploy our method on a Clearpath
Jackal robot. Our approach improves the performance of the navigation algorithm
in terms of average progress towards the goal by 54.73% and the false positives
in terms of forbidden region by 29.96%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting socially interacting groups using f-formation: A survey of taxonomy, methods, datasets, applications, challenges, and future research directions. (arXiv:2108.06181v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1">Hrishav Bakul Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Mg_T/0/1/0/all/0/1">Theint Haythi Mg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pramanick_P/0/1/0/all/0/1">Pradip Pramanick</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_C/0/1/0/all/0/1">Chayan Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06181">
                                    <div class="article-summary-box-inner">
                                        <span>Robots in our daily surroundings are increasing day by day. Their usability
and acceptability largely depend on their explicit and implicit interaction
capability with fellow human beings. As a result, social behavior is one of the
most sought-after qualities that a robot can possess. However, there is no
specific aspect and/or feature that defines socially acceptable behavior and it
largely depends on the situation, application, and society. In this article, we
investigate one such social behavior for collocated robots. Imagine a group of
people is interacting with each other and we want to join the group. We as
human beings do it in a socially acceptable manner, i.e., within the group, we
do position ourselves in such a way that we can participate in the group
activity without disturbing/obstructing anybody. To possess such a quality,
first, a robot needs to determine the formation of the group and then determine
a position for itself, which we humans do implicitly. The theory of f-formation
can be utilized for this purpose. As the types of formations can be very
diverse, detecting the social groups is not a trivial task. In this article, we
provide a comprehensive survey of the existing work on social interaction and
group detection using f-formation for robotics and other applications. We also
put forward a novel holistic survey framework combining all the possible
concerns and modules relevant to this problem. We define taxonomies based on
methods, camera views, datasets, detection capabilities and scale, evaluation
approaches, and application areas. We discuss certain open challenges and
limitations in current literature along with possible future research
directions based on this framework. In particular, we discuss the existing
methods/techniques and their relative merits and demerits, applications, and
provide a set of unsolved but relevant problems in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning vs XNOR-Net: A Comprehensive Study on Deep Learning for Audio Classification in Microcontrollers. (arXiv:2108.06128v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohaimenuzzaman_M/0/1/0/all/0/1">Md Mohaimenuzzaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_B/0/1/0/all/0/1">Bernd Meyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06128">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning has celebrated resounding successes in many application areas
of relevance to the Internet-of-Things, for example, computer vision and
machine listening. To fully harness the power of deep leaning for the IoT,
these technologies must ultimately be brought directly to the edge. The obvious
challenge is that deep learning techniques can only be implemented on strictly
resource-constrained edge devices if the models are radically downsized. This
task relies on different model compression techniques, such as network pruning,
quantization and the recent advancement of XNOR-Net. This paper examines the
suitability of these techniques for audio classification in microcontrollers.
We present an XNOR-Net for end-to-end raw audio classification and a
comprehensive empirical study comparing this approach with
pruning-and-quantization methods. We show that raw audio classification with
XNOR yields comparable performance to regular full precision networks for small
numbers of classes while reducing memory requirements 32-fold and computation
requirements 58-fold. However, as the number of classes increases
significantly, performance degrades and pruning-and-quantization based
compression techniques take over as the preferred technique being able to
satisfy the same space constraints but requiring about 8x more computation. We
show that these insights are consistent between raw audio classification and
image classification using standard benchmark sets.To the best of our
knowledge, this is the first study applying XNOR to end-to-end audio
classification and evaluating it in the context of alternative techniques. All
code is publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Benchmarking Analysis of Transfer Learning for Medical Image Analysis. (arXiv:2108.05930v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taher_M/0/1/0/all/0/1">Mohammad Reza Hosseinzadeh Taher</a>, <a href="http://arxiv.org/find/cs/1/au:+Haghighi_F/0/1/0/all/0/1">Fatemeh Haghighi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ruibin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gotway_M/0/1/0/all/0/1">Michael B. Gotway</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jianming Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05930">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning from supervised ImageNet models has been frequently used in
medical image analysis. Yet, no large-scale evaluation has been conducted to
benchmark the efficacy of newly-developed pre-training techniques for medical
image analysis, leaving several important questions unanswered. As the first
step in this direction, we conduct a systematic study on the transferability of
models pre-trained on iNat2021, the most recent large-scale fine-grained
dataset, and 14 top self-supervised ImageNet models on 7 diverse medical tasks
in comparison with the supervised ImageNet model. Furthermore, we present a
practical approach to bridge the domain gap between natural and medical images
by continually (pre-)training supervised ImageNet models on medical images. Our
comprehensive evaluation yields new insights: (1) pre-trained models on
fine-grained data yield distinctive local representations that are more
suitable for medical segmentation tasks, (2) self-supervised ImageNet models
learn holistic features more effectively than supervised ImageNet models, and
(3) continual pre-training can bridge the domain gap between natural and
medical images. We hope that this large-scale open evaluation of transfer
learning can direct the future research of deep learning for medical imaging.
As open science, all codes and pre-trained models are available on our GitHub
page https://github.com/JLiangLab/BenchmarkTransferLearning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coupling Model-Driven and Data-Driven Methods for Remote Sensing Image Restoration and Fusion. (arXiv:2108.06073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huanfeng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Menghui Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chenxia Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1">Qiangqiang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangpei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06073">
                                    <div class="article-summary-box-inner">
                                        <span>In the fields of image restoration and image fusion, model-driven methods and
data-driven methods are the two representative frameworks. However, both
approaches have their respective advantages and disadvantages. The model-driven
methods consider the imaging mechanism, which is deterministic and
theoretically reasonable; however, they cannot easily model complicated
nonlinear problems. The data-driven methods have a stronger prior knowledge
learning capability for huge data, especially for nonlinear statistical
features; however, the interpretability of the networks is poor, and they are
over-dependent on training data. In this paper, we systematically investigate
the coupling of model-driven and data-driven methods, which has rarely been
considered in the remote sensing image restoration and fusion communities. We
are the first to summarize the coupling approaches into the following three
categories: 1) data-driven and model-driven cascading methods; 2) variational
models with embedded learning; and 3) model-constrained network learning
methods. The typical existing and potential coupling methods for remote sensing
image restoration and fusion are introduced with application examples. This
paper also gives some new insights into the potential future directions, in
terms of both methods and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedPara: Low-rank Hadamard Product Parameterization for Efficient Federated Learning. (arXiv:2108.06098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hyeon_Woo_N/0/1/0/all/0/1">Nam Hyeon-Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Bin_M/0/1/0/all/0/1">Moon Ye-Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1">Tae-Hyun Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06098">
                                    <div class="article-summary-box-inner">
                                        <span>To overcome the burdens on frequent model uploads and downloads during
federated learning (FL), we propose a communication-efficient
re-parameterization, FedPara. Our method re-parameterizes the model&#x27;s layers
using low-rank matrices or tensors followed by the Hadamard product. Different
from the conventional low-rank parameterization, our method is not limited to
low-rank constraints. Thereby, our FedPara has a larger capacity than the
low-rank one, even with the same number of parameters. It can achieve
comparable performance to the original models while requiring 2.8 to 10.1 times
lower communication costs than the original models, which is not achievable by
the traditional low-rank parameterization. Moreover, the efficiency can be
further improved by combining our method and other efficient FL techniques
because our method is compatible with others. We also extend our method to a
personalized FL application, pFedPara, which separates parameters into global
and local ones. We show that pFedPara outperforms competing personalized FL
methods with more than three times fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-imaging real-time detection and tracking of fast-moving objects. (arXiv:2108.06009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Fengming Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xuelei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tianhang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yiguang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06009">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time detection and tracking of fast-moving objects have achieved great
success in various fields. However, many existing methods, especially low-cost
ones, are difficult to achieve real-time and long-term object detection and
tracking. Here, a non-imaging strategy is proposed, including two stages, to
realize fast-moving object detection and tracking in real-time and for the long
term: 1) a contour-moments-based method is proposed to optimize the Hadamard
pattern sequence. And then reconstructing projection curves of the object based
on single-pixel imaging technology. The projection curve, which including the
object location information, is reconstructed directly with the measurements
collected by a single-pixel detector; 2) The fastest changing position in the
projection curve can be obtained by solving first-order gradients. A gradient
differential is used in two first-order gradients to calculate a differential
curve with the sudden change positions. Finally, we can obtain the boundary
information of the fast-moving object. We experimentally demonstrate that our
approach can achieve a temporal resolution of 105 frames per second at a 1.28%
sampling rate by using a 22,000 Hz digital micro-mirror device. The detection
and tracking algorithm of the proposed strategy is computationally efficient.
Compared with the state-of-the-art methods, our approach can make the sampling
rate lower. Additionally, the strategy acquires not more than 1MB of data for
each frame, which is capable of fast-moving object real-time and long-term
detection and tracking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point-Voxel Transformer: An Efficient Approach To 3D Deep Learning. (arXiv:2108.06076v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Cheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1">Haocheng Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xinyi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zizhao Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06076">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the sparsity and irregularity of the 3D data, approaches that directly
process points have become popular. Among all point-based models,
Transformer-based models have achieved state-of-the-art performance by fully
preserving point interrelation. However, most of them spend high percentage of
total time on sparse data accessing (e.g., Farthest Point Sampling (FPS) and
neighbor points query), which becomes the computation burden. Therefore, we
present a novel 3D Transformer, called Point-Voxel Transformer (PVT) that
leverages self-attention computation in points to gather global context
features, while performing multi-head self-attention (MSA) computation in
voxels to capture local information and reduce the irregular data access.
Additionally, to further reduce the cost of MSA computation, we design a cyclic
shifted boxing scheme which brings greater efficiency by limiting the MSA
computation to non-overlapping local boxes while also preserving cross-box
connection. Our method fully exploits the potentials of Transformer
architecture, paving the road to efficient and accurate recognition results.
Evaluated on classification and segmentation benchmarks, our PVT not only
achieves strong accuracy but outperforms previous state-of-the-art
Transformer-based models with 9x measured speedup on average. For 3D object
detection task, we replace the primitives in Frustrum PointNet with PVT layer
and achieve the improvement of 8.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Representative Labeling for Deep Semi-Supervised Learning. (arXiv:2108.06070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiaopeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Riquan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Litong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Huabin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wayne Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06070">
                                    <div class="article-summary-box-inner">
                                        <span>Deep semi-supervised learning (SSL) has experienced significant attention in
recent years, to leverage a huge amount of unlabeled data to improve the
performance of deep learning with limited labeled data. Pseudo-labeling is a
popular approach to expand the labeled dataset. However, whether there is a
more effective way of labeling remains an open problem. In this paper, we
propose to label only the most representative samples to expand the labeled
set. Representative samples, selected by indegree of corresponding nodes on a
directed k-nearest neighbor (kNN) graph, lie in the k-nearest neighborhood of
many other samples. We design a graph neural network (GNN) labeler to label
them in a progressive learning manner. Aided by the progressive GNN labeler,
our deep SSL approach outperforms state-of-the-art methods on several popular
SSL benchmarks including CIFAR-10, SVHN, and ILSVRC-2012. Notably, we achieve
72.1% top-1 accuracy, surpassing the previous best result by 3.3%, on the
challenging ImageNet benchmark with only $10\%$ labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning. (arXiv:2108.06017v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuefan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Shinjae Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibin Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yuewei Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06017">
                                    <div class="article-summary-box-inner">
                                        <span>While deep neural networks have shown impressive performance in many tasks,
they are fragile to carefully designed adversarial attacks. We propose a novel
adversarial training-based model by Attention Guided Knowledge Distillation and
Bi-directional Metric Learning (AGKD-BML). The attention knowledge is obtained
from a weight-fixed model trained on a clean dataset, referred to as a teacher
model, and transferred to a model that is under training on adversarial
examples (AEs), referred to as a student model. In this way, the student model
is able to focus on the correct region, as well as correcting the intermediate
features corrupted by AEs to eventually improve the model accuracy. Moreover,
to efficiently regularize the representation in feature space, we propose a
bidirectional metric learning. Specifically, given a clean image, it is first
attacked to its most confusing class to get the forward AE. A clean image in
the most confusing class is then randomly picked and attacked back to the
original class to get the backward AE. A triplet loss is then used to shorten
the representation distance between original image and its AE, while enlarge
that between the forward and backward AEs. We conduct extensive adversarial
robustness experiments on two widely used datasets with different attacks. Our
proposed AGKD-BML model consistently outperforms the state-of-the-art
approaches. The code of AGKD-BML will be available at:
https://github.com/hongw579/AGKD-BML.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-Temporal Semantic Reasoning for the Semantic Change Detection of HR Remote Sensing Images. (arXiv:2108.06103v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Lei Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Haitao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sicong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1">Lichao Mou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruzzone_L/0/1/0/all/0/1">Lorenzo Bruzzone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06103">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic change detection (SCD) extends the change detection (CD) task to
provide not only the change locations but also the detailed semantic categories
(before and after the observation intervals). This fine-grained change
information is more useful in land-cover/land-use (LC/LU) applications. Recent
studies indicate that the SCD can be modeled through a triple-branch
Convolutional Neural Network (CNN), which contains two temporal branches and a
change branch. However, in this architecture, the connections between the
temporal branches and the change branch are weak. To overcome these
limitations, we propose a novel CNN architecture for the SCD, where the
temporal features are re-used and are deeply merged in the temporal branch.
Furthermore, we elaborate on this architecture to model the bi-temporal
semantic correlations. The resulting Bi-temporal Semantic Reasoning Network
(Bi-SRNet) contains two types of semantic reasoning blocks to reason both
single-temporal and cross-temporal semantic correlations, as well as a novel
loss function to improve the semantic consistency of change detection results.
Experimental results on a benchmark dataset show that the proposed architecture
obtains significant accuracy improvements over the existing approaches, while
the added designs in the Bi-SRNet further improves the segmentation of both
semantic categories and the changed areas. The codes in this paper are
accessible at: https://github.com/ggsDing/Bi-SRNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted Physical-World Attention Attack on Deep Learning Models in Road Sign Recognition. (arXiv:2010.04331v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weifeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04331">
                                    <div class="article-summary-box-inner">
                                        <span>Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modal-Adaptive Gated Recoding Network for RGB-D Salient Object Detection. (arXiv:2108.06281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_F/0/1/0/all/0/1">Feng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jinchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xian Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qiu Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06281">
                                    <div class="article-summary-box-inner">
                                        <span>The multi-modal salient object detection model based on RGB-D information has
better robustness in the real world. However, it remains nontrivial to better
adaptively balance effective multi-modal information in the feature fusion
phase. In this letter, we propose a novel gated recoding network (GRNet) to
evaluate the information validity of the two modes, and balance their
influence. Our framework is divided into three phases: perception phase,
recoding mixing phase and feature integration phase. First, A perception
encoder is adopted to extract multi-level single-modal features, which lays the
foundation for multi-modal semantic comparative analysis. Then, a
modal-adaptive gate unit (MGU) is proposed to suppress the invalid information
and transfer the effective modal features to the recoding mixer and the hybrid
branch decoder. The recoding mixer is responsible for recoding and mixing the
balanced multi-modal information. Finally, the hybrid branch decoder completes
the multi-level feature integration under the guidance of an optional edge
guidance stream (OEGS). Experiments and analysis on eight popular benchmarks
verify that our framework performs favorably against 9 state-of-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective semantic segmentation in Cataract Surgery: What matters most?. (arXiv:2108.06119v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pissas_T/0/1/0/all/0/1">Theodoros Pissas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravasio_C/0/1/0/all/0/1">Claudio Ravasio</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1">Lyndon Da Cruz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergeles_C/0/1/0/all/0/1">Christos Bergeles</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06119">
                                    <div class="article-summary-box-inner">
                                        <span>Our work proposes neural network design choices that set the state-of-the-art
on a challenging public benchmark on cataract surgery, CaDIS. Our methodology
achieves strong performance across three semantic segmentation tasks with
increasingly granular surgical tool class sets by effectively handling class
imbalance, an inherent challenge in any surgical video. We consider and
evaluate two conceptually simple data oversampling methods as well as different
loss functions. We show significant performance gains across network
architectures and tasks especially on the rarest tool classes, thereby
presenting an approach for achieving high performance when imbalanced granular
datasets are considered. Our code and trained models are available at
https://github.com/RViMLab/MICCAI2021_Cataract_semantic_segmentation and
qualitative results on unseen surgical video can be found at
https://youtu.be/twVIPUj1WZM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Captioning with Unseen Object Classes. (arXiv:2108.06165v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1">Berkan Demirel</a>, <a href="http://arxiv.org/find/cs/1/au:+Cinbis_R/0/1/0/all/0/1">Ramazan Gokberk Cinbis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06165">
                                    <div class="article-summary-box-inner">
                                        <span>Image caption generation is one of the most challenging problems at the
intersection of visual recognition and natural language modeling domains. In
this work, we propose and study a practically important variant of this problem
where test images may contain visual objects with no corresponding visual or
textual training examples. For this problem, we propose a detection-driven
approach based on a generalized zero-shot detection model and a template-based
sentence generation model. In order to improve the detection component, we
jointly define a class-to-class similarity based class representation and a
practical score calibration mechanism. We also propose a novel evaluation
metric that provides complimentary insights to the captioning outputs, by
separately handling the visual and non-visual components of the captions. Our
experiments show that the proposed zero-shot detection model obtains
state-of-the-art performance on the MS-COCO dataset and the zero-shot
captioning approach yields promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Track without Appearance: Learn Box and Tracklet Embedding with Local and Global Motion Patterns for Vehicle Tracking. (arXiv:2108.06029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gaoang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1">Renshu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zuozhu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06029">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicle tracking is an essential task in the multi-object tracking (MOT)
field. A distinct characteristic in vehicle tracking is that the trajectories
of vehicles are fairly smooth in both the world coordinate and the image
coordinate. Hence, models that capture motion consistencies are of high
necessity. However, tracking with the standalone motion-based trackers is quite
challenging because targets could get lost easily due to limited information,
detection error and occlusion. Leveraging appearance information to assist
object re-identification could resolve this challenge to some extent. However,
doing so requires extra computation while appearance information is sensitive
to occlusion as well. In this paper, we try to explore the significance of
motion patterns for vehicle tracking without appearance information. We propose
a novel approach that tackles the association issue for long-term tracking with
the exclusive fully-exploited motion information. We address the tracklet
embedding issue with the proposed reconstruct-to-embed strategy based on deep
graph convolutional neural networks (GCN). Comprehensive experiments on the
KITTI-car tracking dataset and UA-Detrac dataset show that the proposed method,
though without appearance information, could achieve competitive performance
with the state-of-the-art (SOTA) trackers. The source code will be available at
https://github.com/GaoangW/LGMTracker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue. (arXiv:2108.06024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Keke Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_D/0/1/0/all/0/1">Dingruibo Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Weilong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianpeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yawen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1">Zhaoquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhihong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06024">
                                    <div class="article-summary-box-inner">
                                        <span>Overconfident predictions on out-of-distribution (OOD) samples is a thorny
issue for deep neural networks. The key to resolve the OOD overconfidence issue
inherently is to build a subset of OOD samples and then suppress predictions on
them. This paper proposes the Chamfer OOD examples (CODEs), whose distribution
is close to that of in-distribution samples, and thus could be utilized to
alleviate the OOD overconfidence issue effectively by suppressing predictions
on them. To obtain CODEs, we first generate seed OOD examples via
slicing&amp;splicing operations on in-distribution samples from different
categories, and then feed them to the Chamfer generative adversarial network
for distribution transformation, without accessing to any extra data. Training
with suppressing predictions on CODEs is validated to alleviate the OOD
overconfidence issue largely without hurting classification accuracy, and
outperform the state-of-the-art methods. Besides, we demonstrate CODEs are
useful for improving OOD detection and classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation. (arXiv:2108.05988v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1">Ning Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05988">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to transfer the knowledge learnt
from a labeled source domain to an unlabeled target domain. Previous work is
mainly built upon convolutional neural networks (CNNs) to learn
domain-invariant representations. With the recent exponential increase in
applying Vision Transformer (ViT) to vision tasks, the capability of ViT in
adapting cross-domain knowledge, however, remains unexplored in the literature.
To fill this gap, this paper first comprehensively investigates the
transferability of ViT on a variety of domain adaptation tasks. Surprisingly,
ViT demonstrates superior transferability over its CNNs-based counterparts with
a large margin, while the performance can be further improved by incorporating
adversarial adaptation. Notwithstanding, directly using CNNs-based adaptation
strategies fails to take the advantage of ViT&#x27;s intrinsic merits (e.g.,
attention mechanism and sequential image representation) which play an
important role in knowledge transfer. To remedy this, we propose an unified
framework, namely Transferable Vision Transformer (TVT), to fully exploit the
transferability of ViT for domain adaptation. Specifically, we delicately
devise a novel and effective unit, which we term Transferability Adaption
Module (TAM). By injecting learned transferabilities into attention blocks, TAM
compels ViT focus on both transferable and discriminative features. Besides, we
leverage discriminative clustering to enhance feature diversity and separation
which are undermined during adversarial domain alignment. To verify its
versatility, we perform extensive studies of TVT on four benchmarks and the
experimental results demonstrate that TVT attains significant improvements
compared to existing state-of-the-art UDA methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Adversarial Framework for Optimizing Image Matting and Harmonization Simultaneously. (arXiv:2108.06087v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuqian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chunlei Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06087">
                                    <div class="article-summary-box-inner">
                                        <span>Image matting and image harmonization are two important tasks in image
composition. Image matting, aiming to achieve foreground boundary details, and
image harmonization, aiming to make the background compatible with the
foreground, are both promising yet challenging tasks. Previous works consider
optimizing these two tasks separately, which may lead to a sub-optimal
solution. We propose to optimize matting and harmonization simultaneously to
get better performance on both the two tasks and achieve more natural results.
We propose a new Generative Adversarial (GAN) framework which optimizing the
matting network and the harmonization network based on a self-attention
discriminator. The discriminator is required to distinguish the natural images
from different types of fake synthesis images. Extensive experiments on our
constructed dataset demonstrate the effectiveness of our proposed method. Our
dataset and dataset generating pipeline can be found in
\url{https://git.io/HaMaGAN}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SVC-onGoing: Signature Verification Competition. (arXiv:2108.06090v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1">Ruben Tolosana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1">Ruben Vera-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Garcia_C/0/1/0/all/0/1">Carlos Gonzalez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_Garcia_J/0/1/0/all/0/1">Javier Ortega-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_J/0/1/0/all/0/1">Juan Carlos Ruiz-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_Tapiador_S/0/1/0/all/0/1">Sergio Romero-Tapiador</a>, <a href="http://arxiv.org/find/cs/1/au:+Rengifo_S/0/1/0/all/0/1">Santiago Rengifo</a>, <a href="http://arxiv.org/find/cs/1/au:+Caruana_M/0/1/0/all/0/1">Miguel Caruana</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiajia Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1">Songxuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yecheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Galbally_J/0/1/0/all/0/1">Javier Galbally</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1">Moises Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_M/0/1/0/all/0/1">Miguel Angel Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Barrero_M/0/1/0/all/0/1">Marta Gomez-Barrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodashinsky_I/0/1/0/all/0/1">Ilya Hodashinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarin_K/0/1/0/all/0/1">Konstantin Sarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Slezkin_A/0/1/0/all/0/1">Artem Slezkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bardamova_M/0/1/0/all/0/1">Marina Bardamova</a>, <a href="http://arxiv.org/find/cs/1/au:+Svetlakov_M/0/1/0/all/0/1">Mikhail Svetlakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleem_M/0/1/0/all/0/1">Mohammad Saleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Szucs_C/0/1/0/all/0/1">Cintia Lia Szucs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovari_B/0/1/0/all/0/1">Bence Kovari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulsmeyer_F/0/1/0/all/0/1">Falk Pulsmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehbi_M/0/1/0/all/0/1">Mohamad Wehbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1">Dario Zanca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1">Sumaiya Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Sarthak Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jabin_S/0/1/0/all/0/1">Suraiya Jabin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06090">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents SVC-onGoing, an on-going competition for on-line
signature verification where researchers can easily benchmark their systems
against the state of the art in an open common platform using large-scale
public databases, such as DeepSignDB and SVC2021_EvalDB, and standard
experimental protocols. SVC-onGoing is based on the ICDAR 2021 Competition on
On-Line Signature Verification (SVC 2021), which has been extended to allow
participants anytime. The goal of SVC-onGoing is to evaluate the limits of
on-line signature verification systems on popular scenarios (office/mobile) and
writing inputs (stylus/finger) through large-scale public databases. Three
different tasks are considered in the competition, simulating realistic
scenarios as both random and skilled forgeries are simultaneously considered on
each task. The results obtained in SVC-onGoing prove the high potential of deep
learning methods in comparison with traditional methods. In particular, the
best signature verification system has obtained Equal Error Rate (EER) values
of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3). Future studies in the
field should be oriented to improve the performance of signature verification
systems on the challenging mobile scenarios of SVC-onGoing in which several
mobile devices and the finger are used during the signature acquisition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Disease Diagnosis via Deep Factorization Machine Models. (arXiv:2108.05916v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ronge_R/0/1/0/all/0/1">Raphael Ronge</a>, <a href="http://arxiv.org/find/cs/1/au:+Nho_K/0/1/0/all/0/1">Kwangsik Nho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Polsterl_S/0/1/0/all/0/1">Sebastian P&#xf6;lsterl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05916">
                                    <div class="article-summary-box-inner">
                                        <span>The current state-of-the-art deep neural networks (DNNs) for Alzheimer&#x27;s
Disease diagnosis use different biomarker combinations to classify patients,
but do not allow extracting knowledge about the interactions of biomarkers.
However, to improve our understanding of the disease, it is paramount to
extract such knowledge from the learned model. In this paper, we propose a Deep
Factorization Machine model that combines the ability of DNNs to learn complex
relationships and the ease of interpretability of a linear model. The proposed
model has three parts: (i) an embedding layer to deal with sparse categorical
data, (ii) a Factorization Machine to efficiently learn pairwise interactions,
and (iii) a DNN to implicitly model higher order interactions. In our
experiments on data from the Alzheimer&#x27;s Disease Neuroimaging Initiative, we
demonstrate that our proposed model classifies cognitive normal, mild cognitive
impaired, and demented patients more accurately than competing models. In
addition, we show that valuable knowledge about the interactions among
biomarkers can be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UMFA: A photorealistic style transfer method based on U-Net and multi-layer feature aggregation. (arXiv:2108.06113v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_D/0/1/0/all/0/1">D.Y. Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">X.J. Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">H. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kittler_J/0/1/0/all/0/1">J. Kittler</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">T.Y. Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06113">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a photorealistic style transfer network to
emphasize the natural effect of photorealistic image stylization. In general,
distortion of the image content and lacking of details are two typical issues
in the style transfer field. To this end, we design a novel framework employing
the U-Net structure to maintain the rich spatial clues, with a multi-layer
feature aggregation (MFA) method to simultaneously provide the details obtained
by the shallow layers in the stylization processing. In particular, an encoder
based on the dense block and a decoder form a symmetrical structure of U-Net
are jointly staked to realize an effective feature extraction and image
reconstruction. Besides, a transfer module based on MFA and &quot;adaptive instance
normalization&quot; (AdaIN) is inserted in the skip connection positions to achieve
the stylization. Accordingly, the stylized image possesses the texture of a
real photo and preserves rich content details without introducing any mask or
post-processing steps. The experimental results on public datasets demonstrate
that our method achieves a more faithful structural similarity with a lower
style loss, reflecting the effectiveness and merit of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Recommendation-cum-Reminder System. (arXiv:2108.06206v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Rohan Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_M/0/1/0/all/0/1">Maheep Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurya_C/0/1/0/all/0/1">Chandresh Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1">Shitala Prasad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06206">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent recommendation and reminder systems are the need of the
fast-pacing life. Current intelligent systems such as Siri, Google Assistant,
Microsoft Cortona, etc., have limited capability. For example, if you want to
wake up at 6 am because you have an upcoming trip, you have to set the alarm
manually. Besides, these systems do not recommend or remind what else to carry,
such as carrying an umbrella during a likely rain. The present work proposes a
system that takes an email as input and returns a recommendation-cumreminder
list. As a first step, we parse the emails, recognize the entities using named
entity recognition (NER). In the second step, information retrieval over the
web is done to identify nearby places, climatic conditions, etc. Imperative
sentences from the reviews of all places are extracted and passed to the object
extraction module. The main challenge lies in extracting the objects (items) of
interest from the review. To solve it, a modified Machine Reading
Comprehension-NER (MRC-NER) model is trained to tag objects of interest by
formulating annotation rules as a query. The objects so found are recommended
to the user one day in advance. The final reminder list of objects is pruned by
our proposed model for tracking objects kept during the &quot;packing activity.&quot;
Eventually, when the user leaves for the event/trip, an alert is sent
containing the reminding list items. Our approach achieves superior performance
compared to several baselines by as much as 30% on recall and 10% on precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1">Ruiyang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1">Shangwen Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Yingqi Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">QiaoQiao She</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, dense passage retrieval has become a mainstream approach to finding
relevant information in various natural language processing tasks. A number of
studies have been devoted to improving the widely adopted dual-encoder
architecture. However, most of the previous studies only consider query-centric
similarity relation when learning the dual-encoder retriever. In order to
capture more comprehensive similarity relations, we propose a novel approach
that leverages both query-centric and PAssage-centric sImilarity Relations
(called PAIR) for dense passage retrieval. To implement our approach, we make
three major technical contributions by introducing formal formulations of the
two kinds of similarity relations, generating high-quality pseudo labeled data
via knowledge distillation, and designing an effective two-stage training
procedure that incorporates passage-centric similarity relation constraint.
Extensive experiments show that our approach significantly outperforms previous
state-of-the-art models on both MSMARCO and Natural Questions datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Music Performance Assessment with Contrastive Learning. (arXiv:2108.01711v1 [cs.SD] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1">Pavan Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerch_A/0/1/0/all/0/1">Alexander Lerch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Several automatic approaches for objective music performance assessment (MPA)
have been proposed in the past, however, existing systems are not yet capable
of reliably predicting ratings with the same accuracy as professional judges.
This study investigates contrastive learning as a potential method to improve
existing MPA systems. Contrastive learning is a widely used technique in
representation learning to learn a structured latent space capable of
separately clustering multiple classes. It has been shown to produce state of
the art results for image-based classification problems. We introduce a
weighted contrastive loss suitable for regression tasks applied to a
convolutional neural network and show that contrastive loss results in
performance gains in regression tasks for MPA. Our results show that
contrastive-based methods are able to match and exceed SoTA performance for MPA
regression tasks by creating better class clusters within the latent space of
the neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LT-OCF: Learnable-Time ODE-based Collaborative Filtering. (arXiv:2108.06208v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jeongwhan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06208">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is a long-standing problem of recommender
systems. Many novel methods have been proposed, ranging from classical matrix
factorization to recent graph convolutional network-based approaches. After
recent fierce debates, researchers started to focus on linear graph
convolutional networks (GCNs) with a layer combination, which show
state-of-the-art accuracy in many datasets. In this work, we extend them based
on neural ordinary differential equations (NODEs), because the linear GCN
concept can be interpreted as a differential equation, and present the method
of Learnable-Time ODE-based Collaborative Filtering (LT-OCF). The main novelty
in our method is that after redesigning linear GCNs on top of the NODE regime,
i) we learn the optimal architecture rather than relying on manually designed
ones, ii) we learn smooth ODE solutions that are considered suitable for CF,
and iii) we test with various ODE solvers that internally build a diverse set
of neural network connections. We also present a novel training method
specialized to our method. In our experiments with three benchmark datasets,
Gowalla, Yelp2018, and Amazon-Book, our method consistently shows better
accuracy than existing methods, e.g., a recall of 0.0411 by LightGCN vs. 0.0442
by LT-OCF and an NDCG of 0.0315 by LightGCN vs. 0.0341 by LT-OCF in
Amazon-Book. One more important discovery in our experiments that is worth
mentioning is that our best accuracy was achieved by dense connections rather
than linear connections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Single and Multiple Representations in Dense Passage Retrieval. (arXiv:2108.06279v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06279">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextualised language models has brought gains in search
effectiveness, not just when applied for re-ranking the output of classical
weighting models such as BM25, but also when used directly for passage indexing
and retrieval, a technique which is called dense retrieval. In the existing
literature in neural ranking, two dense retrieval families have become
apparent: single representation, where entire passages are represented by a
single embedding (usually BERT&#x27;s [CLS] token, as exemplified by the recent ANCE
approach), or multiple representations, where each token in a passage is
represented by its own embedding (as exemplified by the recent ColBERT
approach). These two families have not been directly compared. However, because
of the likely importance of dense retrieval moving forward, a clear
understanding of their advantages and disadvantages is paramount. To this end,
this paper contributes a direct study on their comparative effectiveness,
noting situations where each method under/over performs w.r.t. each other, and
w.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than
ColBERT in terms of response time and memory usage, multiple representations
are statistically more effective than the single representations for MAP and
MRR@10. We also show that multiple representations obtain better improvements
than single representations for queries that are the hardest for BM25, as well
as for definitional queries, and those with complex information needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Effectiveness of Reviews in E-commerce Top-N Recommendation. (arXiv:2106.09665v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhichao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1">Hansi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09665">
                                    <div class="article-summary-box-inner">
                                        <span>Modern E-commerce websites contain heterogeneous sources of information, such
as numerical ratings, textual reviews and images. These information can be
utilized to assist recommendation. Through textual reviews, a user explicitly
express her affinity towards the item. Previous researchers found that by using
the information extracted from these reviews, we can better profile the users&#x27;
explicit preferences as well as the item features, leading to the improvement
of recommendation performance. However, most of the previous algorithms were
only utilizing the review information for explicit-feedback problem i.e. rating
prediction, and when it comes to implicit-feedback ranking problem such as
top-N recommendation, the usage of review information has not been fully
explored. Seeing this gap, in this work, we investigate the effectiveness of
textual review information for top-N recommendation under E-commerce settings.
We adapt several SOTA review-based rating prediction models for top-N
recommendation tasks and compare them to existing top-N recommendation models
from both performance and efficiency. We find that models utilizing only review
information can not achieve better performances than vanilla implicit-feedback
matrix factorization method. When utilizing review information as a regularizer
or auxiliary information, the performance of implicit-feedback matrix
factorization method can be further improved. However, the optimal model
structure to utilize textual reviews for E-commerce top-N recommendation is yet
to be determined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recommending Insurance products by using Users&#x27; Sentiments. (arXiv:2108.06210v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parasrampuria_R/0/1/0/all/0/1">Rohan Parasrampuria</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Ayan Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Suchandra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dhrubasish Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06210">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s tech-savvy world every industry is trying to formulate methods for
recommending products by combining several techniques and algorithms to form a
pool that would bring forward the most enhanced models for making the
predictions. Building on these lines is our paper focused on the application of
sentiment analysis for recommendation in the insurance domain. We tried
building the following Machine Learning models namely, Logistic Regression,
Multinomial Naive Bayes, and the mighty Random Forest for analyzing the
polarity of a given feedback line given by a customer. Then we used this
polarity along with other attributes like Age, Gender, Locality, Income, and
the list of other products already purchased by our existing customers as input
for our recommendation model. Then we matched the polarity score along with the
user&#x27;s profiles and generated the list of insurance products to be recommended
in descending order. Despite our model&#x27;s simplicity and the lack of the key
data sets, the results seemed very logical and realistic. So, by developing the
model with more enhanced methods and with access to better and true data
gathered from an insurance industry may be the sector could be very well
benefitted from the amalgamation of sentiment analysis with a recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAIR: Framework for mining relationships between research articles, strategies, and regulations in the field of explainable artificial intelligence. (arXiv:2108.06216v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1">Stanis&#x142;aw Gizinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuzba_M/0/1/0/all/0/1">Micha&#x142; Kuzba</a>, <a href="http://arxiv.org/find/cs/1/au:+Pielinski_B/0/1/0/all/0/1">Bartosz Pielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sienkiewicz_J/0/1/0/all/0/1">Julian Sienkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Laniewski_S/0/1/0/all/0/1">Stanis&#x142;aw &#x141;aniewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1">Przemys&#x142;aw Biecek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06216">
                                    <div class="article-summary-box-inner">
                                        <span>The growing number of AI applications, also for high-stake decisions,
increases the interest in Explainable and Interpretable Machine Learning
(XI-ML). This trend can be seen both in the increasing number of regulations
and strategies for developing trustworthy AI and the growing number of
scientific papers dedicated to this topic. To ensure the sustainable
development of AI, it is essential to understand the dynamics of the impact of
regulation on research papers as well as the impact of scientific discourse on
AI-related policies. This paper introduces a novel framework for joint analysis
of AI-related policy documents and eXplainable Artificial Intelligence (XAI)
research papers. The collected documents are enriched with metadata and
interconnections, using various NLP methods combined with a methodology
inspired by Institutional Grammar. Based on the information extracted from
collected documents, we showcase a series of analyses that help understand
interactions, similarities, and differences between documents at different
stages of institutionalization. To the best of our knowledge, this is the first
work to use automatic language analysis tools to understand the dynamics
between XI-ML methods and regulations. We believe that such a system
contributes to better cooperation between XAI researchers and AI policymakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMET: Convolutional Dimension Interaction for Collaborative Filtering. (arXiv:2007.14129v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xingzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee Keong Kwoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14129">
                                    <div class="article-summary-box-inner">
                                        <span>Latent factor models play a dominant role among recommendation techniques.
However, most of the existing latent factor models assume both historical
interactions and embedding dimensions are independent of each other, and thus
regrettably ignore the high-order interaction information among historical
interactions and embedding dimensions. In this paper, we propose a novel latent
factor model called COMET (COnvolutional diMEnsion inTeraction), which
simultaneously model the high-order interaction patterns among historical
interactions and embedding dimensions. To be specific, COMET stacks the
embeddings of historical interactions horizontally at first, which results in
two &quot;embedding maps&quot;. In this way, internal interactions and dimensional
interactions can be exploited by convolutional neural networks with kernels of
different sizes simultaneously. A fully-connected multi-layer perceptron is
then applied to obtain two interaction vectors. Lastly, the representations of
users and items are enriched by the learnt interaction vectors, which can
further be used to produce the final prediction. Extensive experiments and
ablation studies on various public implicit feedback datasets clearly
demonstrate the effectiveness and the rationality of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TPRM: A Topic-based Personalized Ranking Model for Web Search. (arXiv:2108.06014v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06014">
                                    <div class="article-summary-box-inner">
                                        <span>Ranking models have achieved promising results, but it remains challenging to
design personalized ranking systems to leverage user profiles and semantic
representations between queries and documents. In this paper, we propose a
topic-based personalized ranking model (TPRM) that integrates user topical
profile with pretrained contextualized term representations to tailor the
general document ranking list. Experiments on the real-world dataset
demonstrate that TPRM outperforms state-of-the-art ad-hoc ranking models and
personalized ranking models significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Answer Similarity for Evaluating Question Answering Models. (arXiv:2108.06130v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutsch_J/0/1/0/all/0/1">Julian Gutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietsch_M/0/1/0/all/0/1">Malte Pietsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06130">
                                    <div class="article-summary-box-inner">
                                        <span>The evaluation of question answering models compares ground-truth annotations
with model predictions. However, as of today, this comparison is mostly
lexical-based and therefore misses out on answers that have no lexical overlap
but are still semantically similar, thus treating correct answers as false.
This underestimation of the true performance of models hinders user acceptance
in applications and complicates a fair comparison of different models.
Therefore, there is a need for an evaluation metric that is based on semantics
instead of pure string similarity. In this short paper, we present SAS, a
cross-encoder-based metric for the estimation of semantic answer similarity,
and compare it to seven existing metrics. To this end, we create an English and
a German three-way annotated evaluation dataset containing pairs of answers
along with human judgment of their semantic similarity, which we release along
with an implementation of the SAS metric and the experiments. We find that
semantic similarity metrics based on recent transformer models correlate much
better with human judgment than traditional lexical similarity metrics on our
two newly created datasets and one dataset from related work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GQE-PRF: Generative Query Expansion with Pseudo-Relevance Feedback. (arXiv:2108.06010v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minghui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1">Meizhen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06010">
                                    <div class="article-summary-box-inner">
                                        <span>Query expansion with pseudo-relevance feedback (PRF) is a powerful approach
to enhance the effectiveness in information retrieval. Recently, with the rapid
advance of deep learning techniques, neural text generation has achieved
promising success in many natural language tasks. To leverage the strength of
text generation for information retrieval, in this article, we propose a novel
approach which effectively integrates text generation models into PRF-based
query expansion. In particular, our approach generates augmented query terms
via neural text generation models conditioned on both the initial query and
pseudo-relevance feedback. Moreover, in order to train the generative model, we
adopt the conditional generative adversarial nets (CGANs) and propose the
PRF-CGAN method in which both the generator and the discriminator are
conditioned on the pseudo-relevance feedback. We evaluate the performance of
our approach on information retrieval tasks using two benchmark datasets. The
experimental results show that our approach achieves comparable performance or
outperforms traditional query expansion methods on both the retrieval and
reranking tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shift-invariant waveform learning on epileptic ECoG. (arXiv:2108.03177v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mendoza_Cardenas_C/0/1/0/all/0/1">Carlos H. Mendoza-Cardenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockmeier_A/0/1/0/all/0/1">Austin J. Brockmeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03177">
                                    <div class="article-summary-box-inner">
                                        <span>Seizure detection algorithms must discriminate abnormal neuronal activity
associated with a seizure from normal neural activity in a variety of
conditions. Our approach is to seek spatiotemporal waveforms with distinct
morphology in electrocorticographic (ECoG) recordings of epileptic patients
that are indicative of a subsequent seizure (preictal) versus non-seizure
segments (interictal). To find these waveforms we apply a shift-invariant
k-means algorithm to segments of spatially filtered signals to learn codebooks
of prototypical waveforms. The frequency of the cluster labels from the
codebooks is then used to train a binary classifier that predicts the class
(preictal or interictal) of a test ECoG segment. We use the Matthews
correlation coefficient to evaluate the performance of the classifier and the
quality of the codebooks. We found that our method finds recurrent
non-sinusoidal waveforms that could be used to build interpretable features for
seizure prediction and that are also physiologically meaningful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient Point Cloud Graph Neural Networks Through Architectural Simplification. (arXiv:2108.06317v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1">Shyam A. Tailor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_R/0/1/0/all/0/1">Ren&#xe9; de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Azevedo_T/0/1/0/all/0/1">Tiago Azevedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1">Matthew Mattina</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1">Partha Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06317">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years graph neural network (GNN)-based approaches have become a
popular strategy for processing point cloud data, regularly achieving
state-of-the-art performance on a variety of tasks. To date, the research
community has primarily focused on improving model expressiveness, with
secondary thought given to how to design models that can run efficiently on
resource constrained mobile devices including smartphones or mixed reality
headsets. In this work we make a step towards improving the efficiency of these
models by making the observation that these GNN models are heavily limited by
the representational power of their first, feature extracting, layer. We find
that it is possible to radically simplify these models so long as the feature
extraction layer is retained with minimal degradation to model performance;
further, we discover that it is possible to improve performance overall on
ModelNet40 and S3DIS by improving the design of the feature extractor. Our
approach reduces memory consumption by 20$\times$ and latency by up to
9.9$\times$ for graph layers in models such as DGCNN; overall, we achieve
speed-ups of up to 4.5$\times$ and peak memory reductions of 72.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness testing of AI systems: A case study for traffic sign recognition. (arXiv:2108.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berghoff_C/0/1/0/all/0/1">Christian Berghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielik_P/0/1/0/all/0/1">Pavol Bielik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neu_M/0/1/0/all/0/1">Matthias Neu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsankov_P/0/1/0/all/0/1">Petar Tsankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Twickel_A/0/1/0/all/0/1">Arndt von Twickel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06159">
                                    <div class="article-summary-box-inner">
                                        <span>In the last years, AI systems, in particular neural networks, have seen a
tremendous increase in performance, and they are now used in a broad range of
applications. Unlike classical symbolic AI systems, neural networks are trained
using large data sets and their inner structure containing possibly billions of
parameters does not lend itself to human interpretation. As a consequence, it
is so far not feasible to provide broad guarantees for the correct behaviour of
neural networks during operation if they process input data that significantly
differ from those seen during training. However, many applications of AI
systems are security- or safety-critical, and hence require obtaining
statements on the robustness of the systems when facing unexpected events,
whether they occur naturally or are induced by an attacker in a targeted way.
As a step towards developing robust AI systems for such applications, this
paper presents how the robustness of AI systems can be practically examined and
which methods and metrics can be used to do so. The robustness testing
methodology is described and analysed for the example use case of traffic sign
recognition in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Learning to Predict Engineering Technology Students&#x27; Success with Computer Aided Design. (arXiv:2108.05955v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1">Jasmine Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Perera_V/0/1/0/all/0/1">Viranga Perera</a>, <a href="http://arxiv.org/find/cs/1/au:+Magana_A/0/1/0/all/0/1">Alejandra J. Magana</a>, <a href="http://arxiv.org/find/cs/1/au:+Newell_B/0/1/0/all/0/1">Brittany Newell</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Kocsis_J/0/1/0/all/0/1">Jin Wei-Kocsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Seah_Y/0/1/0/all/0/1">Ying Ying Seah</a>, <a href="http://arxiv.org/find/cs/1/au:+Strimel_G/0/1/0/all/0/1">Greg J. Strimel</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Charles Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05955">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided design (CAD) programs are essential to engineering as they
allow for better designs through low-cost iterations. While CAD programs are
typically taught to undergraduate students as a job skill, such software can
also help students learn engineering concepts. A current limitation of CAD
programs (even those that are specifically designed for educational purposes)
is that they are not capable of providing automated real-time help to students.
To encourage CAD programs to build in assistance to students, we used data
generated from students using a free, open source CAD software called Aladdin
to demonstrate how student data combined with machine learning techniques can
predict how well a particular student will perform in a design task. We
challenged students to design a house that consumed zero net energy as part of
an introductory engineering technology undergraduate course. Using data from
128 students, along with the scikit-learn Python machine learning library, we
tested our models using both total counts of design actions and sequences of
design actions as inputs. We found that our models using early design sequence
actions are particularly valuable for prediction. Our logistic regression model
achieved a &gt;60% chance of predicting if a student would succeed in designing a
zero net energy house. Our results suggest that it would be feasible for
Aladdin to provide useful feedback to students when they are approximately
halfway through their design. Further improvements to these models could lead
to earlier predictions and thus provide students feedback sooner to enhance
their learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph2MDA: a multi-modal variational graph embedding model for predicting microbe-drug associations. (arXiv:2108.06338v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Deng_L/0/1/0/all/0/1">Lei Deng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_Y/0/1/0/all/0/1">Yibiao Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_X/0/1/0/all/0/1">Xuejun Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06338">
                                    <div class="article-summary-box-inner">
                                        <span>Accumulated clinical studies show that microbes living in humans interact
closely with human hosts, and get involved in modulating drug efficacy and drug
toxicity. Microbes have become novel targets for the development of
antibacterial agents. Therefore, screening of microbe-drug associations can
benefit greatly drug research and development. With the increase of microbial
genomic and pharmacological datasets, we are greatly motivated to develop an
effective computational method to identify new microbe-drug associations. In
this paper, we proposed a novel method, Graph2MDA, to predict microbe-drug
associations by using variational graph autoencoder (VGAE). We constructed
multi-modal attributed graphs based on multiple features of microbes and drugs,
such as molecular structures, microbe genetic sequences, and function
annotations. Taking as input the multi-modal attribute graphs, VGAE was trained
to learn the informative and interpretable latent representations of each node
and the whole graph, and then a deep neural network classifier was used to
predict microbe-drug associations. The hyperparameter analysis and model
ablation studies showed the sensitivity and robustness of our model. We
evaluated our method on three independent datasets and the experimental results
showed that our proposed method outperformed six existing state-of-the-art
methods. We also explored the meaningness of the learned latent representations
of drugs and found that the drugs show obvious clustering patterns that are
significantly consistent with drug ATC classification. Moreover, we conducted
case studies on two microbes and two drugs and found 75\%-95\% predicted
associations have been reported in PubMed literature. Our extensive performance
evaluations validated the effectiveness of our proposed method.\</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIND - Mainstream and Independent News Documents Corpus. (arXiv:2108.06249v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caled_D/0/1/0/all/0/1">Danielle Caled</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_P/0/1/0/all/0/1">Paula Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1">M&#xe1;rio J. Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06249">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents and characterizes MIND, a new Portuguese corpus comprised
of different types of articles collected from online mainstream and alternative
media sources, over a 10-month period. The articles in the corpus are organized
into five collections: facts, opinions, entertainment, satires, and conspiracy
theories. Throughout this paper, we explain how the data collection process was
conducted, and present a set of linguistic metrics that allow us to perform a
preliminary characterization of the texts included in the corpus. Also, we
deliver an analysis of the most frequent topics in the corpus, and discuss the
main differences and similarities among the collections considered. Finally, we
enumerate some tasks and applications that could benefit from this corpus, in
particular the ones (in)directly related to misinformation detection. Overall,
our contribution of a corpus and initial analysis are designed to support
future exploratory news studies, and provide a better insight into
misinformation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressive Sensing and Neural Networks from a Statistical Learning Perspective. (arXiv:2010.15658v4 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Behboodi_A/0/1/0/all/0/1">Arash Behboodi</a>, <a href="http://arxiv.org/find/math/1/au:+Rauhut_H/0/1/0/all/0/1">Holger Rauhut</a>, <a href="http://arxiv.org/find/math/1/au:+Schnoor_E/0/1/0/all/0/1">Ekkehard Schnoor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15658">
                                    <div class="article-summary-box-inner">
                                        <span>Various iterative reconstruction algorithms for inverse problems can be
unfolded as neural networks. Empirically, this approach has often led to
improved results, but theoretical guarantees are still scarce. While some
progress on generalization properties of neural networks have been made, great
challenges remain. In this chapter, we discuss and combine these topics to
present a generalization error analysis for a class of neural networks suitable
for sparse reconstruction from few linear measurements. The hypothesis class
considered is inspired by the classical iterative soft-thresholding algorithm
(ISTA). The neural networks in this class are obtained by unfolding iterations
of ISTA and learning some of the weights. Based on training samples, we aim at
learning the optimal network parameters via empirical risk minimization and
thereby the optimal network that reconstructs signals from their compressive
linear measurements. In particular, we may learn a sparsity basis that is
shared by all of the iterations/layers and thereby obtain a new approach for
dictionary learning. For this class of networks, we present a generalization
bound, which is based on bounding the Rademacher complexity of hypothesis
classes consisting of such deep networks via Dudley&#x27;s integral. Remarkably,
under realistic conditions, the generalization error scales only
logarithmically in the number of layers, and at most linear in number of
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Scalable Verification of Deep Reinforcement Learning. (arXiv:2105.11931v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1">Guy Amir</a>, <a href="http://arxiv.org/find/cs/1/au:+Schapira_M/0/1/0/all/0/1">Michael Schapira</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11931">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have gained significant popularity in recent
years, becoming the state of the art in a variety of domains. In particular,
deep reinforcement learning (DRL) has recently been employed to train DNNs that
realize control policies for various types of real-world systems. In this work,
we present the whiRL 2.0 tool, which implements a new approach for verifying
complex properties of interest for DRL systems. To demonstrate the benefits of
whiRL 2.0, we apply it to case studies from the communication networks domain
that have recently been used to motivate formal verification of DRL systems,
and which exhibit characteristics that are conducive for scalable verification.
We propose techniques for performing k-induction and semi-automated invariant
inference on such systems, and leverage these techniques for proving safety and
liveness properties that were previously impossible to verify due to the
scalability barriers of prior approaches. Furthermore, we show how our proposed
techniques provide insights into the inner workings and the generalizability of
DRL systems. whiRL 2.0 is publicly available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Models Improve Radiomics Reproducibility in Low Dose CTs: A Simulation Study. (arXiv:2104.15050v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chen_J/0/1/0/all/0/1">Junhua Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_C/0/1/0/all/0/1">Chong Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Traverso_A/0/1/0/all/0/1">Alberto Traverso</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhovannik_I/0/1/0/all/0/1">Ivan Zhovannik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dekker_A/0/1/0/all/0/1">Andre Dekker</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wee_L/0/1/0/all/0/1">Leonard Wee</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bermejo_I/0/1/0/all/0/1">Inigo Bermejo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15050">
                                    <div class="article-summary-box-inner">
                                        <span>Radiomics is an active area of research in medical image analysis, the low
reproducibility of radiomics has limited its applicability to clinical
practice. This issue is especially prominent when radiomic features are
calculated from noisy images, such as low dose computed tomography (CT) scans.
In this article, we investigate the possibility of improving the
reproducibility of radiomic features calculated on noisy CTs by using
generative models for denoising.One traditional denoising method - non-local
means - and two generative models - encoder-decoder networks (EDN) and
conditional generative adversarial networks (CGANs) - were selected as the test
models. We added noise to the sinograms of full dose CTs to mimic low dose CTs
with two different levels of noise: low-noise CT and high-noise CT. Models were
trained on high-noise CTs and used to denoise low-noise CTs without
re-training. We also test the performance of our model in real data, using
dataset of same-day repeat low dose CTs to assess the reproducibility of
radiomic features in denoised images. The EDN and the CGAN improved the
concordance correlation coefficients (CCC) of radiomic features for low-noise
images from 0.87 to 0.92 and for high-noise images from 0.68 to 0.92
respectively. Moreover, the EDN and the CGAN improved the test-retest
reliability of radiomic features (mean CCC increased from 0.89 to 0.94) based
on real low dose CTs. The results show that denoising using EDN and CGANs can
improve the reproducibility of radiomic features calculated on noisy CTs.
Moreover, images with different noise levels can be denoised to improve the
reproducibility using these models without re-training, as long as the noise
intensity is equal or lower than that in high-noise CTs. To the authors&#x27;
knowledge, this is the first effort to improve the reproducibility of radiomic
features calculated on low dose CT scans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedPara: Low-rank Hadamard Product Parameterization for Efficient Federated Learning. (arXiv:2108.06098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hyeon_Woo_N/0/1/0/all/0/1">Nam Hyeon-Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Bin_M/0/1/0/all/0/1">Moon Ye-Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1">Tae-Hyun Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06098">
                                    <div class="article-summary-box-inner">
                                        <span>To overcome the burdens on frequent model uploads and downloads during
federated learning (FL), we propose a communication-efficient
re-parameterization, FedPara. Our method re-parameterizes the model&#x27;s layers
using low-rank matrices or tensors followed by the Hadamard product. Different
from the conventional low-rank parameterization, our method is not limited to
low-rank constraints. Thereby, our FedPara has a larger capacity than the
low-rank one, even with the same number of parameters. It can achieve
comparable performance to the original models while requiring 2.8 to 10.1 times
lower communication costs than the original models, which is not achievable by
the traditional low-rank parameterization. Moreover, the efficiency can be
further improved by combining our method and other efficient FL techniques
because our method is compatible with others. We also extend our method to a
personalized FL application, pFedPara, which separates parameters into global
and local ones. We show that pFedPara outperforms competing personalized FL
methods with more than three times fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Split Learning. (arXiv:2108.06309v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Joongheon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghoon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Soyi Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Seehwan Yoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06309">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel split learning framework with multiple
end-systems in order to realize privacypreserving deep neural network
computation. In conventional split learning frameworks, deep neural network
computation is separated into multiple computing systems for hiding entire
network architectures. In our proposed framework, multiple computing
end-systems are sharing one centralized server in split learning computation,
where the multiple end-systems are with input and first hidden layers and the
centralized server is with the other hidden layers and output layer. This
framework, which is called as spatio-temporal split learning, is spatially
separated for gathering data from multiple end-systems and also temporally
separated due to the nature of split learning. Our performance evaluation
verifies that our proposed framework shows nearoptimal accuracy while
preserving data privacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted VAE: Variational and Targeted Learning for Causal Inference. (arXiv:2009.13472v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1">Matthew James Vowels</a>, <a href="http://arxiv.org/find/stat/1/au:+Camgoz_N/0/1/0/all/0/1">Necati Cihan Camgoz</a>, <a href="http://arxiv.org/find/stat/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13472">
                                    <div class="article-summary-box-inner">
                                        <span>Undertaking causal inference with observational data is incredibly useful
across a wide range of tasks including the development of medical treatments,
advertisements and marketing, and policy making. There are two significant
challenges associated with undertaking causal inference using observational
data: treatment assignment heterogeneity (i.e., differences between the treated
and untreated groups), and an absence of counterfactual data (i.e., not knowing
what would have happened if an individual who did get treatment, were instead
to have not been treated). We address these two challenges by combining
structured inference and targeted learning. In terms of structure, we factorize
the joint distribution into risk, confounding, instrumental, and miscellaneous
factors, and in terms of targeted learning, we apply a regularizer derived from
the influence curve in order to reduce residual bias. An ablation study is
undertaken, and an evaluation on benchmark datasets demonstrates that TVAE has
competitive and state of the art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEEA-Net: An Early Exit Evolutionary Neural Architecture Search. (arXiv:2108.06156v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Termritthikun_C/0/1/0/all/0/1">Chakkrit Termritthikun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamtsho_Y/0/1/0/all/0/1">Yeshi Jamtsho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ieamsaard_J/0/1/0/all/0/1">Jirarat Ieamsaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Muneesawang_P/0/1/0/all/0/1">Paisarn Muneesawang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Ivan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06156">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this research were to search for Convolutional Neural Network
(CNN) architectures, suitable for an on-device processor with limited computing
resources, performing at substantially lower Network Architecture Search (NAS)
costs. A new algorithm entitled an Early Exit Population Initialisation (EE-PI)
for Evolutionary Algorithm (EA) was developed to achieve both goals. The EE-PI
reduces the total number of parameters in the search process by filtering the
models with fewer parameters than the maximum threshold. It will look for a new
model to replace those models with parameters more than the threshold. Thereby,
reducing the number of parameters, memory usage for model storage and
processing time while maintaining the same performance or accuracy. The search
time was reduced to 0.52 GPU day. This is a huge and significant achievement
compared to the NAS of 4 GPU days achieved using NSGA-Net, 3,150 GPU days by
the AmoebaNet model, and the 2,000 GPU days by the NASNet model. As well, Early
Exit Evolutionary Algorithm networks (EEEA-Nets) yield network architectures
with minimal error and computational cost suitable for a given dataset as a
class of network algorithms. Using EEEA-Net on CIFAR-10, CIFAR-100, and
ImageNet datasets, our experiments showed that EEEA-Net achieved the lowest
error rate among state-of-the-art NAS models, with 2.46% for CIFAR-10, 15.02%
for CIFAR-100, and 23.8% for ImageNet dataset. Further, we implemented this
image recognition architecture for other tasks, such as object detection,
semantic segmentation, and keypoint detection tasks, and, in our experiments,
EEEA-Net-C2 outperformed MobileNet-V3 on all of these various tasks. (The
algorithm code is available at https://github.com/chakkritte/EEEA-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentiment Analysis of the COVID-related r/Depression Posts. (arXiv:2108.06215v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1">Marina Sokolova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06215">
                                    <div class="article-summary-box-inner">
                                        <span>Reddit.com is a popular social media platform among young people. Reddit
users share their stories to seek support from other users, especially during
the Covid-19 pandemic. Messages posted on Reddit and their content have
provided researchers with opportunity to analyze public concerns. In this
study, we analyzed sentiments of COVID-related messages posted on r/Depression.
Our study poses the following questions: a) What are the common topics that the
Reddit users discuss? b) Can we use these topics to classify sentiments of the
posts? c) What matters concern people more during the pandemic?

Key Words: Sentiment Classification, Depression, COVID-19, Reddit, LDA, BERT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information-theoretic Perspective of Hierarchical Clustering. (arXiv:2108.06036v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yicheng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_B/0/1/0/all/0/1">Bingchen Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06036">
                                    <div class="article-summary-box-inner">
                                        <span>A combinatorial cost function for hierarchical clustering was introduced by
Dasgupta \cite{dasgupta2016cost}. It has been generalized by Cohen-Addad et al.
\cite{cohen2019hierarchical} to a general form named admissible function. In
this paper, we investigate hierarchical clustering from the
\emph{information-theoretic} perspective and formulate a new objective
function. We also establish the relationship between these two perspectives. In
algorithmic aspect, we get rid of the traditional top-down and bottom-up
frameworks, and propose a new one to stratify the \emph{sparsest} level of a
cluster tree recursively in guide with our objective function. For practical
use, our resulting cluster tree is not binary. Our algorithm called HCSE
outputs a $k$-level cluster tree by a novel and interpretable mechanism to
choose $k$ automatically without any hyper-parameter. Our experimental results
on synthetic datasets show that HCSE has a great advantage in finding the
intrinsic number of hierarchies, and the results on real datasets show that
HCSE also achieves competitive costs over the popular algorithms LOUVAIN and
HLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Overview of Machine Learning-aided Optical Performance Monitoring Techniques. (arXiv:2107.07338v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tizikara_D/0/1/0/all/0/1">Dativa K. Tizikara</a>, <a href="http://arxiv.org/find/cs/1/au:+Serugunda_J/0/1/0/all/0/1">Jonathan Serugunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Katumba_A/0/1/0/all/0/1">Andrew Katumba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07338">
                                    <div class="article-summary-box-inner">
                                        <span>Future communication systems are faced with increased demand for high
capacity, dynamic bandwidth, reliability and heterogeneous traffic. To meet
these requirements, networks have become more complex and thus require new
design methods and monitoring techniques, as they evolve towards becoming
autonomous. Machine learning has come to the forefront in recent years as a
promising technology to aid in this evolution. Optical fiber communications can
already provide the high capacity required for most applications, however,
there is a need for increased scalability and adaptability to changing user
demands and link conditions. Accurate performance monitoring is an integral
part of this transformation. In this paper we review optical performance
monitoring techniques where machine learning algorithms have been applied.
Moreover, since alot of OPM depends on knowledge of the signal type, we also
review work for modulation format recognition and bitrate identification. We
additionally briefly introduce a neuromorphic approach to OPM as an emerging
technique that has only recently been applied to this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Iterative Graph Self-Distillation. (arXiv:2010.12609v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuai Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1">Eric P. Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12609">
                                    <div class="article-summary-box-inner">
                                        <span>How to discriminatively vectorize graphs is a fundamental challenge that
attracts increasing attentions in recent years. Inspired by the recent success
of unsupervised contrastive learning, we aim to learn graph-level
representation in an unsupervised manner. Specifically, we propose a novel
unsupervised graph learning paradigm called Iterative Graph Self-Distillation
(IGSD) which iteratively performs the teacher-student distillation with graph
augmentations. Different from conventional knowledge distillation, IGSD
constructs the teacher with an exponential moving average of the student model
and distills the knowledge of itself. The intuition behind IGSD is to predict
the teacher network representation of the graph pairs under different augmented
views. As a natural extension, we also apply IGSD to semi-supervised scenarios
by jointly regularizing the network with both supervised and unsupervised
contrastive loss. Finally, we show that finetuning the IGSD-trained models with
self-training can further improve the graph representation power. Empirically,
we achieve significant and consistent performance gain on various graph
datasets in both unsupervised and semi-supervised settings, which well
validates the superiority of IGSD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast model-based clustering of partial records. (arXiv:2103.16336v5 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Goren_E/0/1/0/all/0/1">Emily M. Goren</a>, <a href="http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1">Ranjan Maitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16336">
                                    <div class="article-summary-box-inner">
                                        <span>Partially recorded data are frequently encountered in many applications and
usually clustered by first removing incomplete cases or features with missing
values, or by imputing missing values, followed by application of a clustering
algorithm to the resulting altered dataset. Here, we develop clustering
methodology through a model-based approach using the marginal density for the
observed values, assuming a finite mixture model of multivariate $t$
distributions. We compare our approximate algorithm to the corresponding full
expectation-maximization (EM) approach that considers the missing values in the
incomplete data set and makes a missing at random (MAR) assumption, as well as
case deletion and imputation methods. Since only the observed values are
utilized, our approach is computationally more efficient than imputation or
full EM. Simulation studies demonstrate that our approach has favorable
recovery of the true cluster partition compared to case deletion and imputation
under various missingness mechanisms, and is at least competitive with the full
EM approach, even when MAR assumptions are violated. Our methodology is
demonstrated on a problem of clustering gamma-ray bursts and is implemented at
https://github.com/emilygoren/MixtClust.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training. (arXiv:2108.06209v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yu-An Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Chung-Cheng Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">James Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Ruoming Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06209">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the success of masked language modeling~(MLM) in pre-training
natural language processing models, we propose w2v-BERT that explores MLM for
self-supervised speech representation learning. w2v-BERT is a framework that
combines contrastive learning and MLM, where the former trains the model to
discretize input continuous speech signals into a finite set of discriminative
speech tokens, and the latter trains the model to learn contextualized speech
representations via solving a masked prediction task consuming the discretized
tokens. In contrast to existing MLM-based speech pre-training frameworks such
as HuBERT, which relies on an iterative re-clustering and re-training process,
or vq-wav2vec, which concatenates two separately trained modules, w2v-BERT can
be optimized in an end-to-end fashion by solving the two self-supervised
tasks~(the contrastive task and MLM) simultaneously. Our experiments show that
w2v-BERT achieves competitive results compared to current state-of-the-art
pre-trained models on the LibriSpeech benchmarks when using the Libri-Light~60k
corpus as the unsupervised data. In particular, when compared to published
models such as conformer-based wav2vec~2.0 and HuBERT, our model shows~5\%
to~10\% relative WER reduction on the test-clean and test-other subsets. When
applied to the Google&#x27;s Voice Search traffic dataset, w2v-BERT outperforms our
internal conformer-based wav2vec~2.0 by more than~30\% relatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Structured Dynamic Sparse Pre-Training of BERT. (arXiv:2108.06277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06277">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying algorithms for computational efficient unsupervised training of
large language models is an important and active area of research. In this
work, we develop and study a straightforward, dynamic always-sparse
pre-training approach for BERT language modeling task, which leverages periodic
compression steps based on magnitude pruning followed by random parameter
re-allocation. This approach enables us to achieve Pareto improvements in terms
of the number of floating-point operations (FLOPs) over statically sparse and
dense models across a broad spectrum of network sizes. Furthermore, we
demonstrate that training remains FLOP-efficient when using coarse-grained
block sparsity, making it particularly promising for efficient execution on
modern hardware accelerators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Transfer for Invoice Extraction via Class-aware QA Ensemble. (arXiv:2108.06069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damodaran_P/0/1/0/all/0/1">Prithiviraj Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhkaran Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Achankuju_J/0/1/0/all/0/1">Josemon Achankuju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06069">
                                    <div class="article-summary-box-inner">
                                        <span>We present VESPA, an intentionally simple yet novel zero-shot system for
layout, locale, and domain agnostic document extraction. In spite of the
availability of large corpora of documents, the lack of labeled and validated
datasets makes it a challenge to discriminatively train document extraction
models for enterprises. We show that this problem can be addressed by simply
transferring the information extraction (IE) task to a natural language
Question-Answering (QA) task without engineering task-specific architectures.
We demonstrate the effectiveness of our system by evaluating on a closed corpus
of real-world retail and tax invoices with multiple complex layouts, domains,
and geographies. The empirical evaluation shows that our system outperforms 4
prominent commercial invoice solutions that use discriminatively trained models
with architectures specifically crafted for invoice extraction. We extracted 6
fields with zero upfront human annotation or training with an Avg. F1 of 87.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principal Component Analysis Applied to Gradient Fields in Band Gap Optimization Problems for Metamaterials. (arXiv:2104.02588v6 [cs.CE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gnecco_G/0/1/0/all/0/1">Giorgio Gnecco</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacigalupo_A/0/1/0/all/0/1">Andrea Bacigalupo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fantoni_F/0/1/0/all/0/1">Francesca Fantoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Selvi_D/0/1/0/all/0/1">Daniela Selvi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02588">
                                    <div class="article-summary-box-inner">
                                        <span>A promising technique for the spectral design of acoustic metamaterials is
based on the formulation of suitable constrained nonlinear optimization
problems. Unfortunately, the straightforward application of classical
gradient-based iterative optimization algorithms to the numerical solution of
such problems is typically highly demanding, due to the complexity of the
underlying physical models. Nevertheless, supervised machine learning
techniques can reduce such a computational effort, e.g., by replacing the
original objective functions of such optimization problems with more-easily
computable approximations. In this framework, the present article describes the
application of a related unsupervised machine learning technique, namely,
principal component analysis, to approximate the gradient of the objective
function of a band gap optimization problem for an acoustic metamaterial, with
the aim of making the successive application of a gradient-based iterative
optimization algorithm faster. Numerical results show the effectiveness of the
proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the Big Data Paradigm with Compact Transformers. (arXiv:2104.05704v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1">Ali Hassani</a>, <a href="http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1">Steven Walton</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Nikhil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05704">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of Transformers as the standard for language processing, and
their advancements in computer vision, along with their unprecedented size and
amounts of training data, many have come to believe that they are not suitable
for small sets of data. This trend leads to great concerns, including but not
limited to: limited availability of data in certain scientific domains and the
exclusion of those with limited resource from research in the field. In this
paper, we dispel the myth that transformers are &quot;data hungry&quot; and therefore can
only be applied to large sets of data. We show for the first time that with the
right size and tokenization, transformers can perform head-to-head with
state-of-the-art CNNs on small datasets, often with better accuracy and fewer
parameters. Our model eliminates the requirement for class token and positional
embeddings through a novel sequence pooling strategy and the use of
convolution/s. It is flexible in terms of model size, and can have as little as
0.28M parameters while achieving good results. Our model can reach 98.00%
accuracy when training from scratch on CIFAR-10, which is a significant
improvement over previous Transformer based models. It also outperforms many
modern CNN based approaches, such as ResNet, and even some recent NAS-based
approaches, such as Proxyless-NAS. Our simple and compact design democratizes
transformers by making them accessible to those with limited computing
resources and/or dealing with small datasets. Our method also works on larger
datasets, such as ImageNet (82.71% accuracy with 29% parameters of ViT), and
NLP tasks as well. Our code and pre-trained models are publicly available at
https://github.com/SHI-Labs/Compact-Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-Based Value Functions. (arXiv:2006.09226v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faccio_F/0/1/0/all/0/1">Francesco Faccio</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirsch_L/0/1/0/all/0/1">Louis Kirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09226">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional off-policy actor-critic Reinforcement Learning (RL) algorithms
learn value functions of a single target policy. However, when value functions
are updated to track the learned policy, they forget potentially useful
information about old policies. We introduce a class of value functions called
Parameter-Based Value Functions (PBVFs) whose inputs include the policy
parameters. They can generalize across different policies. PBVFs can evaluate
the performance of any policy given a state, a state-action pair, or a
distribution over the RL agent&#x27;s initial states. First we show how PBVFs yield
novel off-policy policy gradient theorems. Then we derive off-policy
actor-critic algorithms based on PBVFs trained by Monte Carlo or Temporal
Difference methods. We show how learned PBVFs can zero-shot learn new policies
that outperform any policy seen during training. Finally our algorithms are
evaluated on a selection of discrete and continuous control tasks using shallow
policies and deep neural networks. Their performance is comparable to
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMDNet: Learning a Probabilistic Relaxation of Discrete Variables for Soft Detection with Low Complexity. (arXiv:2102.12756v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Beck_E/0/1/0/all/0/1">Edgar Beck</a>, <a href="http://arxiv.org/find/eess/1/au:+Bockelmann_C/0/1/0/all/0/1">Carsten Bockelmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Dekorsy_A/0/1/0/all/0/1">Armin Dekorsy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12756">
                                    <div class="article-summary-box-inner">
                                        <span>Following the great success of Machine Learning (ML), especially Deep Neural
Networks (DNNs), in many research domains in 2010s, several ML-based approaches
were proposed for detection in large inverse linear problems, e.g., massive
MIMO systems. The main motivation behind is that the complexity of Maximum
A-Posteriori (MAP) detection grows exponentially with system dimensions.
Instead of using DNNs, essentially being a black-box, we take a slightly
different approach and introduce a probabilistic Continuous relaxation of
disCrete variables to MAP detection. Enabling close approximation and
continuous optimization, we derive an iterative detection algorithm: Concrete
MAP Detection (CMD). Furthermore, extending CMD by the idea of deep unfolding
into CMDNet, we allow for (online) optimization of a small number of parameters
to different working points while limiting complexity. In contrast to recent
DNN-based approaches, we select the optimization criterion and output of CMDNet
based on information theory and are thus able to learn approximate
probabilities of the individual optimal detector. This is crucial for soft
decoding in today&#x27;s communication systems. Numerical simulation results in MIMO
systems reveal CMDNet to feature a promising accuracy complexity trade-off
compared to State of the Art. Notably, we demonstrate CMDNet&#x27;s soft outputs to
be reliable for decoders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Learning in Robotics: From Learning-Based Control to Safe Reinforcement Learning. (arXiv:2108.06266v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brunke_L/0/1/0/all/0/1">Lukas Brunke</a>, <a href="http://arxiv.org/find/cs/1/au:+Greeff_M/0/1/0/all/0/1">Melissa Greeff</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_A/0/1/0/all/0/1">Adam W. Hall</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhaocong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Siqi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Panerati_J/0/1/0/all/0/1">Jacopo Panerati</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoellig_A/0/1/0/all/0/1">Angela P. Schoellig</a> (University of Toronto Institute for Aerospace Studies, University of Toronto Robotics Institute, Vector Institute for Artificial Intelligence)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06266">
                                    <div class="article-summary-box-inner">
                                        <span>The last half-decade has seen a steep rise in the number of contributions on
safe learning methods for real-world robotic deployments from both the control
and reinforcement learning communities. This article provides a concise but
holistic review of the recent advances made in using machine learning to
achieve safe decision making under uncertainties, with a focus on unifying the
language and frameworks used in control theory and reinforcement learning
research. Our review includes: learning-based control approaches that safely
improve performance by learning the uncertain dynamics, reinforcement learning
approaches that encourage safety or robustness, and methods that can formally
certify the safety of a learned control policy. As data- and learning-based
robot control methods continue to gain traction, researchers must understand
when and how to best leverage them in real-world scenarios where safety is
imperative, such as when operating in close proximity to humans. We highlight
some of the open challenges that will drive the field of robot learning in the
coming years, and emphasize the need for realistic physics-based benchmarks to
facilitate fair comparisons between control and reinforcement learning
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Subspace Mixture Models for Interpretable Anomaly Detection. (arXiv:2108.06283v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Savkli_C/0/1/0/all/0/1">Cetin Savkli</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_C/0/1/0/all/0/1">Catherine Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06283">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new subspace-based method to construct probabilistic models for
high-dimensional data and highlight its use in anomaly detection. The approach
is based on a statistical estimation of probability density using densities of
random subspaces combined with geometric averaging. In selecting random
subspaces, equal representation of each attribute is used to ensure correct
statistical limits. Gaussian mixture models (GMMs) are used to create the
probability densities for each subspace with techniques included to mitigate
singularities allowing for the ability to handle both numerical and categorial
attributes. The number of components for each GMM is determined automatically
through Bayesian information criterion to prevent overfitting. The proposed
algorithm attains competitive AUC scores compared with prominent algorithms
against benchmark anomaly detection datasets with the added benefits of being
simple, scalable, and interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-shot Transfer Learning for Population Mapping. (arXiv:2108.06228v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_E/0/1/0/all/0/1">Erzhuo Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06228">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained population distribution data is of great importance for many
applications, e.g., urban planning, traffic scheduling, epidemic modeling, and
risk control. However, due to the limitations of data collection, including
infrastructure density, user privacy, and business security, such fine-grained
data is hard to collect and usually, only coarse-grained data is available.
Thus, obtaining fine-grained population distribution from coarse-grained
distribution becomes an important problem. To complete this task, existing
methods mainly rely on sufficient fine-grained ground truth for training, which
is not often available. This limits the applications of these methods and
brings the necessity to transfer knowledge from data-sufficient cities to
data-scarce cities.

In knowledge transfer scenario, we employ single reference fine-grained
ground truth in the target city as the ground truth to inform the large-scale
urban structure and support the knowledge transfer in the target city. By this
approach, we transform the fine-grained population mapping problem into a
one-shot transfer learning problem for population mapping task.

In this paper, we propose a one-shot transfer learning framework, PSRNet, to
transfer spatial-temporal knowledge across cities in fine-grained population
mapping task from the view of network structure, data, and optimization.
Experiments on real-life datasets of 4 cities demonstrate that PSRNet has
significant advantages over 8 baselines by reducing RMSE and MAE for more than
25%. Our code and datasets are released in Github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Operator Splitting View of Federated Learning. (arXiv:2108.05974v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malekmohammadi_S/0/1/0/all/0/1">Saber Malekmohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaloudegi_K/0/1/0/all/0/1">Kiarash Shaloudegi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zeou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaoliang Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05974">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past few years, the federated learning ($\texttt{FL}$) community has
witnessed a proliferation of new $\texttt{FL}$ algorithms. However, our
understating of the theory of $\texttt{FL}$ is still fragmented, and a
thorough, formal comparison of these algorithms remains elusive. Motivated by
this gap, we show that many of the existing $\texttt{FL}$ algorithms can be
understood from an operator splitting point of view. This unification allows us
to compare different algorithms with ease, to refine previous convergence
results and to uncover new algorithmic variants. In particular, our analysis
reveals the vital role played by the step size in $\texttt{FL}$ algorithms. The
unification also leads to a streamlined and economic way to accelerate
$\texttt{FL}$ algorithms, without incurring any communication overhead. We
perform numerical experiments on both convex and nonconvex models to validate
our findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarially Robust Low Dimensional Representations. (arXiv:1911.13268v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1">Pranjal Awasthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatziafratis_V/0/1/0/all/0/1">Vaggos Chatziafratis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xue Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijayaraghavan_A/0/1/0/all/0/1">Aravindan Vijayaraghavan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.13268">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning systems are vulnerable to small perturbations made to
inputs either at test time or at training time. This has received much recent
interest on the empirical front due to applications where reliability and
security are critical. However, theoretical understanding of algorithms that
are robust to adversarial perturbations is limited.

In this work we focus on Principal Component Analysis (PCA), a ubiquitous
algorithmic primitive in machine learning. We formulate a natural robust
variant of PCA where the goal is to find a low dimensional subspace to
represent the given data with minimum projection error, that is in addition
robust to small perturbations measured in $\ell_q$ norm (say $q&#x3D;\infty$).
Unlike PCA which is solvable in polynomial time, our formulation is
computationally intractable to optimize as it captures a variant of the
well-studied sparse PCA objective as a special case. We show the following
results:

-Polynomial time algorithm that is constant factor competitive in the
worst-case with respect to the best subspace, in terms of the projection error
and the robustness criterion.

-We show that our algorithmic techniques can also be made robust to
adversarial training-time perturbations, in addition to yielding
representations that are robust to adversarial perturbations at test time.
Specifically, we design algorithms for a strong notion of training-time
perturbations, where every point is adversarially perturbed up to a specified
amount.

-We illustrate the broad applicability of our algorithmic techniques in
addressing robustness to adversarial perturbations, both at training time and
test time. In particular, our adversarially robust PCA primitive leads to
computationally efficient and robust algorithms for both unsupervised and
supervised learning problems such as clustering and learning adversarially
robust classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Fairness-Aware Learning with Imbalanced Data Streams. (arXiv:2108.06231v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_V/0/1/0/all/0/1">Vasileios Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06231">
                                    <div class="article-summary-box-inner">
                                        <span>Data-driven learning algorithms are employed in many online applications, in
which data become available over time, like network monitoring, stock price
prediction, job applications, etc. The underlying data distribution might
evolve over time calling for model adaptation as new instances arrive and old
instances become obsolete. In such dynamic environments, the so-called data
streams, fairness-aware learning cannot be considered as a one-off requirement,
but rather it should comprise a continual requirement over the stream. Recent
fairness-aware stream classifiers ignore the problem of class imbalance, which
manifests in many real-life applications, and mitigate discrimination mainly
because they &quot;reject&quot; minority instances at large due to their inability to
effectively learn all classes.

In this work, we propose \ours, an online fairness-aware approach that
maintains a valid and fair classifier over the stream. \ours~is an online
boosting approach that changes the training distribution in an online fashion
by monitoring stream&#x27;s class imbalance and tweaks its decision boundary to
mitigate discriminatory outcomes over the stream. Experiments on 8 real-world
and 1 synthetic datasets from different domains with varying class imbalance
demonstrate the superiority of our method over state-of-the-art fairness-aware
stream approaches with a range (relative) increase [11.2\%-14.2\%] in balanced
accuracy, [22.6\%-31.8\%] in gmean, [42.5\%-49.6\%] in recall, [14.3\%-25.7\%]
in kappa and [89.4\%-96.6\%] in statistical parity (fairness).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recommending Insurance products by using Users&#x27; Sentiments. (arXiv:2108.06210v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parasrampuria_R/0/1/0/all/0/1">Rohan Parasrampuria</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Ayan Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Suchandra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1">Dhrubasish Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06210">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s tech-savvy world every industry is trying to formulate methods for
recommending products by combining several techniques and algorithms to form a
pool that would bring forward the most enhanced models for making the
predictions. Building on these lines is our paper focused on the application of
sentiment analysis for recommendation in the insurance domain. We tried
building the following Machine Learning models namely, Logistic Regression,
Multinomial Naive Bayes, and the mighty Random Forest for analyzing the
polarity of a given feedback line given by a customer. Then we used this
polarity along with other attributes like Age, Gender, Locality, Income, and
the list of other products already purchased by our existing customers as input
for our recommendation model. Then we matched the polarity score along with the
user&#x27;s profiles and generated the list of insurance products to be recommended
in descending order. Despite our model&#x27;s simplicity and the lack of the key
data sets, the results seemed very logical and realistic. So, by developing the
model with more enhanced methods and with access to better and true data
gathered from an insurance industry may be the sector could be very well
benefitted from the amalgamation of sentiment analysis with a recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDE constraints on smooth hierarchical functions computed by neural networks. (arXiv:2005.08859v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Filom_K/0/1/0/all/0/1">Khashayar Filom</a>, <a href="http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1">Konrad Paul Kording</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhoodi_R/0/1/0/all/0/1">Roozbeh Farhoodi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08859">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are versatile tools for computation, having the ability to
approximate a broad range of functions. An important problem in the theory of
deep neural networks is expressivity; that is, we want to understand the
functions that are computable by a given network. We study real infinitely
differentiable (smooth) hierarchical functions implemented by feedforward
neural networks via composing simpler functions in two cases:

1) each constituent function of the composition has fewer inputs than the
resulting function;

2) constituent functions are in the more specific yet prevalent form of a
non-linear univariate function (e.g. tanh) applied to a linear multivariate
function.

We establish that in each of these regimes there exist non-trivial algebraic
partial differential equations (PDEs), which are satisfied by the computed
functions. These PDEs are purely in terms of the partial derivatives and are
dependent only on the topology of the network. For compositions of polynomial
functions, the algebraic PDEs yield non-trivial equations (of degrees dependent
only on the architecture) in the ambient polynomial space that are satisfied on
the associated functional varieties. Conversely, we conjecture that such PDE
constraints, once accompanied by appropriate non-singularity conditions and
perhaps certain inequalities involving partial derivatives, guarantee that the
smooth function under consideration can be represented by the network. The
conjecture is verified in numerous examples including the case of tree
architectures which are of neuroscientific interest. Our approach is a step
toward formulating an algebraic description of functional spaces associated
with specific neural networks, and may provide new, useful tools for
constructing neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural ODE to model and prognose thermoacoustic instability. (arXiv:2106.12758v2 [physics.flu-dyn] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Dhadphale_J/0/1/0/all/0/1">Jayesh Dhadphale</a>, <a href="http://arxiv.org/find/physics/1/au:+Unni_V/0/1/0/all/0/1">Vishnu R. Unni</a>, <a href="http://arxiv.org/find/physics/1/au:+Saha_A/0/1/0/all/0/1">Abhishek Saha</a>, <a href="http://arxiv.org/find/physics/1/au:+Sujith_R/0/1/0/all/0/1">R. I. Sujith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12758">
                                    <div class="article-summary-box-inner">
                                        <span>In reacting flow systems, thermoacoustic instability characterized by high
amplitude pressure fluctuations, is driven by a positive coupling between the
unsteady heat release rate and the acoustic field of the combustor. When the
underlying flow is turbulent, as a control parameter of the system is varied
and the system approach thermoacoustic instability, the acoustic pressure
oscillations synchronize with heat release rate oscillations. Consequently,
during the onset of thermoacoustic instability in turbulent combustors, the
system dynamics transition from chaotic oscillations to periodic oscillations
via a state of intermittency. Thermoacoustic systems are traditionally modeled
by coupling the model for the unsteady heat source and the acoustic subsystem,
each estimated independently. The response of the unsteady heat source, the
flame, to acoustic fluctuations are characterized by introducing external
unsteady forcing. This necessitates a powerful excitation module to obtain the
nonlinear response of the flame to acoustic perturbations. Instead of
characterizing individual subsystems, we introduce a neural ordinary
differential equation (neural ODE) framework to model the thermoacoustic system
as a whole. The neural ODE model for the thermoacoustic system uses time series
of the heat release rate and the pressure fluctuations, measured simultaneously
without introducing any external perturbations, to model their coupled
interaction. Further, we use the parameters of neural ODE to define an anomaly
measure that represents the proximity of system dynamics to limit cycle
oscillations and thus provide an early warning signal for the onset of
thermoacoustic instability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preparation of Many-body Ground States by Time Evolution with Variational Microscopic Magnetic Fields and Incomplete Interactions. (arXiv:2106.01779v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Lu_Y/0/1/0/all/0/1">Ying Lu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_Y/0/1/0/all/0/1">Yue-Min Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1">Peng-Fei Zhou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01779">
                                    <div class="article-summary-box-inner">
                                        <span>State preparation is of fundamental importance in quantum physics, which can
be realized by constructing the quantum circuit as a unitary that transforms
the initial state to the target, or implementing a quantum control protocol to
evolve to the target state with a designed Hamiltonian. In this work, we study
the latter on quantum many-body systems by the time evolution with fixed
couplings and variational magnetic fields. In specific, we consider to prepare
the ground states of the Hamiltonians containing certain interactions that are
missing in the Hamiltonians for the time evolution. An optimization method is
proposed to optimize the magnetic fields by &quot;fine-graining&quot; the discretization
of time, in order to gain high precision and stability. The back propagation
technique is utilized to obtain the gradients of the fields against the
logarithmic fidelity. Our method is tested on preparing the ground state of
Heisenberg chain with the time evolution by the XY and Ising interactions, and
its performance surpasses two baseline methods that use local and global
optimization strategies, respectively. Our work can be applied and generalized
to other quantum models such as those defined on higher dimensional lattices.
It enlightens to reduce the complexity of the required interactions for
implementing quantum control or other tasks in quantum information and
computation by means of optimizing the magnetic fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient active learning of sparse halfspaces with arbitrary bounded noise. (arXiv:2002.04840v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jie Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1">Pranjal Awasthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04840">
                                    <div class="article-summary-box-inner">
                                        <span>We study active learning of homogeneous $s$-sparse halfspaces in
$\mathbb{R}^d$ under the setting where the unlabeled data distribution is
isotropic log-concave and each label is flipped with probability at most $\eta$
for a parameter $\eta \in \big[0, \frac12\big)$, known as the bounded noise.
Even in the presence of mild label noise, i.e. $\eta$ is a small constant, this
is a challenging problem and only recently have label complexity bounds of the
form $\tilde{O}\big(s \cdot \mathrm{polylog}(d, \frac{1}{\epsilon})\big)$ been
established in [Zhang, 2018] for computationally efficient algorithms. In
contrast, under high levels of label noise, the label complexity bounds
achieved by computationally efficient algorithms are much worse: the best known
result of [Awasthi et al., 2016] provides a computationally efficient algorithm
with label complexity $\tilde{O}\big((\frac{s \ln
d}{\epsilon})^{2^{\mathrm{poly}(1/(1-2\eta))}} \big)$, which is label-efficient
only when the noise rate $\eta$ is a fixed constant. In this work, we
substantially improve on it by designing a polynomial time algorithm for active
learning of $s$-sparse halfspaces, with a label complexity of
$\tilde{O}\big(\frac{s}{(1-2\eta)^4} \mathrm{polylog} (d, \frac 1 \epsilon)
\big)$. This is the first efficient algorithm with label complexity polynomial
in $\frac{1}{1-2\eta}$ in this setting, which is label-efficient even for
$\eta$ arbitrarily close to $\frac12$. Our active learning algorithm and its
theoretical guarantees also immediately translate to new state-of-the-art label
and sample complexity results for full-dimensional active and passive halfspace
learning under arbitrary bounded noise. The key insight of our algorithm and
analysis is a new interpretation of online learning regret inequalities, which
may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech. (arXiv:2106.14736v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonell_P/0/1/0/all/0/1">Patrik Jonell</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14736">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework for gesture generation, aiming to allow
data-driven approaches to produce more semantically rich gestures. Our approach
first predicts whether to gesture, followed by a prediction of the gesture
properties. Those properties are then used as conditioning for a modern
probabilistic gesture-generation model capable of high-quality output. This
empowers the approach to generate gestures that are both diverse and
representational. Follow-ups and more information can be found on the project
page: https://svito-zar.github.io/speech2properties2gestures/ .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Music Performance Assessment with Contrastive Learning. (arXiv:2108.01711v1 [cs.SD] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1">Pavan Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerch_A/0/1/0/all/0/1">Alexander Lerch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Several automatic approaches for objective music performance assessment (MPA)
have been proposed in the past, however, existing systems are not yet capable
of reliably predicting ratings with the same accuracy as professional judges.
This study investigates contrastive learning as a potential method to improve
existing MPA systems. Contrastive learning is a widely used technique in
representation learning to learn a structured latent space capable of
separately clustering multiple classes. It has been shown to produce state of
the art results for image-based classification problems. We introduce a
weighted contrastive loss suitable for regression tasks applied to a
convolutional neural network and show that contrastive loss results in
performance gains in regression tasks for MPA. Our results show that
contrastive-based methods are able to match and exceed SoTA performance for MPA
regression tasks by creating better class clusters within the latent space of
the neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Jasmine: A New Active Learning Approach to Combat Cybercrime. (arXiv:2108.06238v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klein_J/0/1/0/all/0/1">Jan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhulai_S/0/1/0/all/0/1">Sandjai Bhulai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1">Mark Hoogendoorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_R/0/1/0/all/0/1">Rob van der Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06238">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past decade, the advent of cybercrime has accelarated the research
on cybersecurity. However, the deployment of intrusion detection methods falls
short. One of the reasons for this is the lack of realistic evaluation
datasets, which makes it a challenge to develop techniques and compare them.
This is caused by the large amounts of effort it takes for a cyber analyst to
classify network connections. This has raised the need for methods (i) that can
learn from small sets of labeled data, (ii) that can make predictions on large
sets of unlabeled data, and (iii) that request the label of only specially
selected unlabeled data instances. Hence, Active Learning (AL) methods are of
interest. These approaches choose speci?fic unlabeled instances by a query
function that are expected to improve overall classi?cation performance. The
resulting query observations are labeled by a human expert and added to the
labeled set.

In this paper, we propose a new hybrid AL method called Jasmine. Firstly, it
determines how suitable each observation is for querying, i.e., how likely it
is to enhance classi?cation. These properties are the uncertainty score and
anomaly score. Secondly, Jasmine introduces dynamic updating. This allows the
model to adjust the balance between querying uncertain, anomalous and randomly
selected observations. To this end, Jasmine is able to learn the best query
strategy during the labeling process. This is in contrast to the other AL
methods in cybersecurity that all have static, predetermined query functions.
We show that dynamic updating, and therefore Jasmine, is able to consistently
obtain good and more robust results than querying only uncertainties, only
anomalies or a ?fixed combination of the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven advice for interpreting local and global model predictions in bioinformatics problems. (arXiv:2108.06201v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Loecher_M/0/1/0/all/0/1">Markus Loecher</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06201">
                                    <div class="article-summary-box-inner">
                                        <span>Tree-based algorithms such as random forests and gradient boosted trees
continue to be among the most popular and powerful machine learning models used
across multiple disciplines. The conventional wisdom of estimating the impact
of a feature in tree based models is to measure the \textit{node-wise reduction
of a loss function}, which (i) yields only global importance measures and (ii)
is known to suffer from severe biases. Conditional feature contributions (CFCs)
provide \textit{local}, case-by-case explanations of a prediction by following
the decision path and attributing changes in the expected output of the model
to each feature along the path. However, Lundberg et al. pointed out a
potential bias of CFCs which depends on the distance from the root of a tree.
The by now immensely popular alternative, SHapley Additive exPlanation (SHAP)
values appear to mitigate this bias but are computationally much more
expensive. Here we contribute a thorough comparison of the explanations
computed by both methods on a set of 164 publicly available classification
problems in order to provide data-driven algorithm recommendations to current
researchers. For random forests, we find extremely high similarities and
correlations of both local and global SHAP values and CFC scores, leading to
very similar rankings and interpretations. Analogous conclusions hold for the
fidelity of using global feature importance scores as a proxy for the
predictive power associated with each feature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Recommendation-cum-Reminder System. (arXiv:2108.06206v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxena_R/0/1/0/all/0/1">Rohan Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_M/0/1/0/all/0/1">Maheep Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurya_C/0/1/0/all/0/1">Chandresh Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1">Shitala Prasad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06206">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent recommendation and reminder systems are the need of the
fast-pacing life. Current intelligent systems such as Siri, Google Assistant,
Microsoft Cortona, etc., have limited capability. For example, if you want to
wake up at 6 am because you have an upcoming trip, you have to set the alarm
manually. Besides, these systems do not recommend or remind what else to carry,
such as carrying an umbrella during a likely rain. The present work proposes a
system that takes an email as input and returns a recommendation-cumreminder
list. As a first step, we parse the emails, recognize the entities using named
entity recognition (NER). In the second step, information retrieval over the
web is done to identify nearby places, climatic conditions, etc. Imperative
sentences from the reviews of all places are extracted and passed to the object
extraction module. The main challenge lies in extracting the objects (items) of
interest from the review. To solve it, a modified Machine Reading
Comprehension-NER (MRC-NER) model is trained to tag objects of interest by
formulating annotation rules as a query. The objects so found are recommended
to the user one day in advance. The final reminder list of objects is pruned by
our proposed model for tracking objects kept during the &quot;packing activity.&quot;
Eventually, when the user leaves for the event/trip, an alert is sent
containing the reminding list items. Our approach achieves superior performance
compared to several baselines by as much as 30% on recall and 10% on precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sherman_U/0/1/0/all/0/1">Uri Sherman</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03803">
                                    <div class="article-summary-box-inner">
                                        <span>We study a variant of online convex optimization where the player is
permitted to switch decisions at most $S$ times in expectation throughout $T$
rounds. Similar problems have been addressed in prior work for the discrete
decision set setting, and more recently in the continuous setting but only with
an adaptive adversary. In this work, we aim to fill the gap and present
computationally efficient algorithms in the more prevalent oblivious setting,
establishing a regret bound of $O(T/S)$ for general convex losses and
$\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic
i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches
with only a multiplicative $\log T$ factor overhead in its regret in both the
general and strongly convex settings. Finally, we complement our algorithms
with lower bounds that match our upper bounds in some of the cases we consider.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1">Greyson Gerhard-Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1">Raviteja Anantha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1">Srinivas Chappidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1">Bj&#xf6;rn Hoffmeister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06329">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work building open-domain chatbots has demonstrated that increasing
model size improves performance. On the other hand, latency and connectivity
considerations dictate the move of digital assistants on the device. Giving a
digital assistant like Siri, Alexa, or Google Assistant the ability to discuss
just about anything leads to the need for reducing the chatbot model size such
that it fits on the user&#x27;s device. We demonstrate that low parameter models can
simultaneously retain their general knowledge conversational abilities while
improving in a specific domain. Additionally, we propose a generic framework
that accounts for variety in question types, tracks reference throughout
multi-turn conversations, and removes inconsistent and potentially toxic
responses. Our framework seamlessly transitions between chatting and performing
transactional tasks, which will ultimately make interactions with digital
assistants more human-like. We evaluate our framework on 1 internal and 4
public benchmark datasets using both automatic (Perplexity) and human (SSA -
Sensibleness and Specificity Average) evaluation metrics and establish
comparable performance while reducing model parameters by 90%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted Physical-World Attention Attack on Deep Learning Models in Road Sign Recognition. (arXiv:2010.04331v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xinghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weifeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04331">
                                    <div class="article-summary-box-inner">
                                        <span>Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders. (arXiv:2107.12698v2 [gr-qc] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/gr-qc/1/au:+Moreno_E/0/1/0/all/0/1">Eric A. Moreno</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Vlimant_J/0/1/0/all/0/1">Jean-Roch Vlimant</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Spiropulu_M/0/1/0/all/0/1">Maria Spiropulu</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Borzyszkowski_B/0/1/0/all/0/1">Bartlomiej Borzyszkowski</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12698">
                                    <div class="article-summary-box-inner">
                                        <span>We present an application of anomaly detection techniques based on deep
recurrent autoencoders to the problem of detecting gravitational wave signals
in laser interferometers. Trained on noise data, this class of algorithms could
detect signals using an unsupervised strategy, i.e., without targeting a
specific kind of source. We develop a custom architecture to analyze the data
from two interferometers. We compare the obtained performance to that obtained
with other autoencoder architectures and with a convolutional classifier. The
unsupervised nature of the proposed strategy comes with a cost in terms of
accuracy, when compared to more traditional supervised techniques. On the other
hand, there is a qualitative gain in generalizing the experimental sensitivity
beyond the ensemble of pre-computed signal templates. The recurrent autoencoder
outperforms other autoencoders based on different architectures. The class of
recurrent autoencoders presented in this paper could complement the search
strategy employed for gravitational wave detection and extend the reach of the
ongoing detection campaigns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting socially interacting groups using f-formation: A survey of taxonomy, methods, datasets, applications, challenges, and future research directions. (arXiv:2108.06181v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1">Hrishav Bakul Barua</a>, <a href="http://arxiv.org/find/cs/1/au:+Mg_T/0/1/0/all/0/1">Theint Haythi Mg</a>, <a href="http://arxiv.org/find/cs/1/au:+Pramanick_P/0/1/0/all/0/1">Pradip Pramanick</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_C/0/1/0/all/0/1">Chayan Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06181">
                                    <div class="article-summary-box-inner">
                                        <span>Robots in our daily surroundings are increasing day by day. Their usability
and acceptability largely depend on their explicit and implicit interaction
capability with fellow human beings. As a result, social behavior is one of the
most sought-after qualities that a robot can possess. However, there is no
specific aspect and/or feature that defines socially acceptable behavior and it
largely depends on the situation, application, and society. In this article, we
investigate one such social behavior for collocated robots. Imagine a group of
people is interacting with each other and we want to join the group. We as
human beings do it in a socially acceptable manner, i.e., within the group, we
do position ourselves in such a way that we can participate in the group
activity without disturbing/obstructing anybody. To possess such a quality,
first, a robot needs to determine the formation of the group and then determine
a position for itself, which we humans do implicitly. The theory of f-formation
can be utilized for this purpose. As the types of formations can be very
diverse, detecting the social groups is not a trivial task. In this article, we
provide a comprehensive survey of the existing work on social interaction and
group detection using f-formation for robotics and other applications. We also
put forward a novel holistic survey framework combining all the possible
concerns and modules relevant to this problem. We define taxonomies based on
methods, camera views, datasets, detection capabilities and scale, evaluation
approaches, and application areas. We discuss certain open challenges and
limitations in current literature along with possible future research
directions based on this framework. In particular, we discuss the existing
methods/techniques and their relative merits and demerits, applications, and
provide a set of unsolved but relevant problems in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based transformation of the H&amp;E stain into special stains. (arXiv:2008.08871v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Haan_K/0/1/0/all/0/1">Kevin de Haan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yijie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerman_J/0/1/0/all/0/1">Jonathan E. Zuckerman</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tairan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sisk_A/0/1/0/all/0/1">Anthony E. Sisk</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_M/0/1/0/all/0/1">Miguel F. P. Diaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Jen_K/0/1/0/all/0/1">Kuang-Yu Jen</a>, <a href="http://arxiv.org/find/eess/1/au:+Nobori_A/0/1/0/all/0/1">Alexander Nobori</a>, <a href="http://arxiv.org/find/eess/1/au:+Liou_S/0/1/0/all/0/1">Sofia Liou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Sarah Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Riahi_R/0/1/0/all/0/1">Rana Riahi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rivenson_Y/0/1/0/all/0/1">Yair Rivenson</a>, <a href="http://arxiv.org/find/eess/1/au:+Wallace_W/0/1/0/all/0/1">W. Dean Wallace</a>, <a href="http://arxiv.org/find/eess/1/au:+Ozcan_A/0/1/0/all/0/1">Aydogan Ozcan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08871">
                                    <div class="article-summary-box-inner">
                                        <span>Pathology is practiced by visual inspection of histochemically stained
slides. Most commonly, the hematoxylin and eosin (H&amp;E) stain is used in the
diagnostic workflow and it is the gold standard for cancer diagnosis. However,
in many cases, especially for non-neoplastic diseases, additional &quot;special
stains&quot; are used to provide different levels of contrast and color to tissue
components and allow pathologists to get a clearer diagnostic picture. In this
study, we demonstrate the utility of supervised learning-based computational
stain transformation from H&amp;E to different special stains (Masson&#x27;s Trichrome,
periodic acid-Schiff and Jones silver stain) using tissue sections from kidney
needle core biopsies. Based on evaluation by three renal pathologists, followed
by adjudication by a fourth renal pathologist, we show that the generation of
virtual special stains from existing H&amp;E images improves the diagnosis in
several non-neoplastic kidney diseases sampled from 58 unique subjects. A
second study performed by three pathologists found that the quality of the
special stains generated by the stain transformation network was statistically
equivalent to those generated through standard histochemical staining. As the
transformation of H&amp;E images into special stains can be achieved within 1 min
or less per patient core specimen slide, this stain-to-stain transformation
framework can improve the quality of the preliminary diagnosis when additional
special stains are needed, along with significant savings in time and cost,
reducing the burden on healthcare system and patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Ordinary Differential Equation Control of Dynamics on Graphs. (arXiv:2006.09773v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asikis_T/0/1/0/all/0/1">Thomas Asikis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bottcher_L/0/1/0/all/0/1">Lucas B&#xf6;ttcher</a>, <a href="http://arxiv.org/find/cs/1/au:+Antulov_Fantulin_N/0/1/0/all/0/1">Nino Antulov-Fantulin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09773">
                                    <div class="article-summary-box-inner">
                                        <span>We study the ability of neural networks to steer or control trajectories of
continuous time non-linear dynamical systems on graphs, which we represent with
neural ordinary differential equations (neural ODEs). To do so, we introduce a
neural-ODE control (NODEC) framework and find that it can learn control signals
that drive graph dynamical systems into desired target states. While we use
loss functions that do not constrain the control energy, our results show that
NODEC produces low energy control signals. Finally, we showcase the performance
and versatility of NODEC by using it to control a system of more than one
thousand coupled, non-linear ODEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context Aware Object Geotagging. (arXiv:2108.06302v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chao-Jung Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulicny_M/0/1/0/all/0/1">Matej Ulicny</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzke_M/0/1/0/all/0/1">Michael Manzke</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahyot_R/0/1/0/all/0/1">Rozenn Dahyot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06302">
                                    <div class="article-summary-box-inner">
                                        <span>Localization of street objects from images has gained a lot of attention in
recent years. We propose an approach to improve asset geolocation from street
view imagery by enhancing the quality of the metadata associated with the
images using Structure from Motion. The predicted object geolocation is further
refined by imposing contextual geographic information extracted from
OpenStreetMap. Our pipeline is validated experimentally against the state of
the art approaches for geotagging traffic lights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Transferable Parameters for Unsupervised Domain Adaptation. (arXiv:2108.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhongyi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haoliang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) enables a learning machine to adapt from
a labeled source domain to an unlabeled domain under the distribution shift.
Thanks to the strong representation ability of deep neural networks, recent
remarkable achievements in UDA resort to learning domain-invariant features.
Intuitively, the hope is that a good feature representation, together with the
hypothesis learned from the source domain, can generalize well to the target
domain. However, the learning processes of domain-invariant features and source
hypothesis inevitably involve domain-specific information that would degrade
the generalizability of UDA models on the target domain. In this paper,
motivated by the lottery ticket hypothesis that only partial parameters are
essential for generalization, we find that only partial parameters are
essential for learning domain-invariant information and generalizing well in
UDA. Such parameters are termed transferable parameters. In contrast, the other
parameters tend to fit domain-specific details and often fail to generalize,
which we term as untransferable parameters. Driven by this insight, we propose
Transferable Parameter Learning (TransPar) to reduce the side effect brought by
domain-specific information in the learning process and thus enhance the
memorization of domain-invariant information. Specifically, according to the
distribution discrepancy degree, we divide all parameters into transferable and
untransferable ones in each training iteration. We then perform separate
updates rules for the two types of parameters. Extensive experiments on image
classification and regression tasks (keypoint detection) show that TransPar
outperforms prior arts by non-trivial margins. Moreover, experiments
demonstrate that TransPar can be integrated into the most popular deep UDA
networks and be easily extended to handle any data distribution shift
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alzheimer&#x27;s Disease Diagnosis via Deep Factorization Machine Models. (arXiv:2108.05916v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ronge_R/0/1/0/all/0/1">Raphael Ronge</a>, <a href="http://arxiv.org/find/cs/1/au:+Nho_K/0/1/0/all/0/1">Kwangsik Nho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Polsterl_S/0/1/0/all/0/1">Sebastian P&#xf6;lsterl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05916">
                                    <div class="article-summary-box-inner">
                                        <span>The current state-of-the-art deep neural networks (DNNs) for Alzheimer&#x27;s
Disease diagnosis use different biomarker combinations to classify patients,
but do not allow extracting knowledge about the interactions of biomarkers.
However, to improve our understanding of the disease, it is paramount to
extract such knowledge from the learned model. In this paper, we propose a Deep
Factorization Machine model that combines the ability of DNNs to learn complex
relationships and the ease of interpretability of a linear model. The proposed
model has three parts: (i) an embedding layer to deal with sparse categorical
data, (ii) a Factorization Machine to efficiently learn pairwise interactions,
and (iii) a DNN to implicitly model higher order interactions. In our
experiments on data from the Alzheimer&#x27;s Disease Neuroimaging Initiative, we
demonstrate that our proposed model classifies cognitive normal, mild cognitive
impaired, and demented patients more accurately than competing models. In
addition, we show that valuable knowledge about the interactions among
biomarkers can be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the gap between emotion and joint action. (arXiv:2108.06264v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bienkiewicz_M/0/1/0/all/0/1">M. M. N. Bie&#x144;kiewicz</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Smykovskyi_A/0/1/0/all/0/1">A. Smykovskyi</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Olugbade_T/0/1/0/all/0/1">T. Olugbade</a> (2), <a href="http://arxiv.org/find/q-bio/1/au:+Janaqi_S/0/1/0/all/0/1">S. Janaqi</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Camurri_A/0/1/0/all/0/1">A. Camurri</a> (3), <a href="http://arxiv.org/find/q-bio/1/au:+Bianchi_Berthouze_N/0/1/0/all/0/1">N. Bianchi-Berthouze</a> (2), <a href="http://arxiv.org/find/q-bio/1/au:+Bjorkman_M/0/1/0/all/0/1">M. Bj&#xf6;rkman</a> (4), <a href="http://arxiv.org/find/q-bio/1/au:+Bardy_B/0/1/0/all/0/1">B. G. Bardy</a> (1) ((1) EuroMov Digital Health in Motion Univ. Montpellier IMT Mines Ales France, (2) UCL, University College of London UK, (3) UNIGE InfoMus Casa Paganini Italy, (4) KTH Royal Institute of Technology Sweden)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06264">
                                    <div class="article-summary-box-inner">
                                        <span>Our daily human life is filled with a myriad of joint action moments, be it
children playing, adults working together (i.e., team sports), or strangers
navigating through a crowd. Joint action brings individuals (and embodiment of
their emotions) together, in space and in time. Yet little is known about how
individual emotions propagate through embodied presence in a group, and how
joint action changes individual emotion. In fact, the multi-agent component is
largely missing from neuroscience-based approaches to emotion, and reversely
joint action research has not found a way yet to include emotion as one of the
key parameters to model socio-motor interaction. In this review, we first
identify the gap and then stockpile evidence showing strong entanglement
between emotion and acting together from various branches of sciences. We
propose an integrative approach to bridge the gap, highlight five research
avenues to do so in behavioral neuroscience and digital sciences, and address
some of the key challenges in the area faced by modern societies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Room Classification on Floor Plan Graphs using Graph Neural Networks. (arXiv:2108.05947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paudel_A/0/1/0/all/0/1">Abhishek Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhakal_R/0/1/0/all/0/1">Roshan Dhakal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattarai_S/0/1/0/all/0/1">Sakshat Bhattarai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05947">
                                    <div class="article-summary-box-inner">
                                        <span>We present our approach to improve room classification task on floor plan
maps of buildings by representing floor plans as undirected graphs and
leveraging graph neural networks to predict the room categories. Rooms in the
floor plans are represented as nodes in the graph with edges representing their
adjacency in the map. We experiment with House-GAN dataset that consists of
floor plan maps in vector format and train multilayer perceptron and graph
neural networks. Our results show that graph neural networks, specifically
GraphSAGE and Topology Adaptive GCN were able to achieve accuracy of 80% and
81% respectively outperforming baseline multilayer perceptron by more than 15%
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CNN depth analysis with different channel inputs for Acoustic Scene Classification. (arXiv:1906.04591v4 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_Castanos_S/0/1/0/all/0/1">Sergi Perez-Castanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Naranjo_Alcazar_J/0/1/0/all/0/1">Javier Naranjo-Alcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuccarello_P/0/1/0/all/0/1">Pedro Zuccarello</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobos_M/0/1/0/all/0/1">Maximo Cobos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferri_F/0/1/0/all/0/1">Frances J. Ferri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.04591">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic scene classification (ASC) has been approached in the last years
using deep learning techniques such as convolutional neural networks or
recurrent neural networks. Many state-of-the-art solutions are based on image
classification frameworks and, as such, a 2D representation of the audio signal
is considered for training these networks. Finding the most suitable audio
representation is still a research area of interest. In this paper, different
log-Mel representations and combinations are analyzed. Experiments show that
the best results are obtained using the harmonic and percussive components plus
the difference between left and right stereo channels, (L-R). On the other
hand, it is a common strategy to ensemble different models in order to increase
the final accuracy. Even though averaging different model predictions is a
common choice, an exhaustive analysis of different ensemble techniques has not
been presented in ASC problems. In this paper, geometric and arithmetic mean
plus the Ordered Weighted Averaging (OWA) operator are studied as aggregation
operators for the output of the different models of the ensemble. Finally, the
work carried out in this paper is highly oriented towards real-time
implementations. In this context, as the number of applications for audio
classification on edge devices is increasing exponentially, we also analyze
different network depths and efficient solutions for aggregating ensemble
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimCVD: Simple Contrastive Voxel-Wise Representation Distillation for Semi-Supervised Medical Image Segmentation. (arXiv:2108.06227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Ruihan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1">Lawrence Staib</a>, <a href="http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1">James S. Duncan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06227">
                                    <div class="article-summary-box-inner">
                                        <span>Automated segmentation in medical image analysis is a challenging task that
requires a large amount of manually labeled data. However, most existing
learning-based approaches usually suffer from limited manually annotated
medical data, which poses a major practical problem for accurate and robust
medical image segmentation. In addition, most existing semi-supervised
approaches are usually not robust compared with the supervised counterparts,
and also lack explicit modeling of geometric structure and semantic
information, both of which limit the segmentation accuracy. In this work, we
present SimCVD, a simple contrastive distillation framework that significantly
advances state-of-the-art voxel-wise representation learning. We first describe
an unsupervised training strategy, which takes two views of an input volume and
predicts their signed distance maps of object boundaries in a contrastive
objective, with only two independent dropout as mask. This simple approach
works surprisingly well, performing on the same level as previous fully
supervised methods with much less labeled data. We hypothesize that dropout can
be viewed as a minimal form of data augmentation and makes the network robust
to representation collapse. Then, we propose to perform structural distillation
by distilling pair-wise similarities. We evaluate SimCVD on two popular
datasets: the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT
dataset. The results on the LA dataset demonstrate that, in two types of
labeled ratios (i.e., 20% and 10%), SimCVD achieves an average Dice score of
90.85% and 89.03% respectively, a 0.91% and 2.22% improvement compared to
previous best results. Our method can be trained in an end-to-end fashion,
showing the promise of utilizing SimCVD as a general framework for downstream
tasks, such as medical image synthesis and registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDM: Trustworthy Decision-Making via Interpretability Enhancement. (arXiv:2108.06080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1">Daoming Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fangkai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1">Hugh Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Wen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_L/0/1/0/all/0/1">Levent Yilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06080">
                                    <div class="article-summary-box-inner">
                                        <span>Human-robot interactive decision-making is increasingly becoming ubiquitous,
and trust is an influential factor in determining the reliance on autonomy.
However, it is not reasonable to trust systems that are beyond our
comprehension, and typical machine learning and data-driven decision-making are
black-box paradigms that impede interpretability. Therefore, it is critical to
establish computational trustworthy decision-making mechanisms enhanced by
interpretability-aware strategies. To this end, we propose a Trustworthy
Decision-Making (TDM) framework, which integrates symbolic planning into
sequential decision-making. The framework learns interpretable subtasks that
result in a complex, higher-level composite task that can be formally evaluated
using the proposed trust metric. TDM enables the subtask-level interpretability
by design and converges to an optimal symbolic plan from the learned subtasks.
Moreover, a TDM-based algorithm is introduced to demonstrate the unification of
symbolic planning with other sequential-decision making algorithms, reaping the
benefits of both. Experimental results validate the effectiveness of
trust-score-based planning while improving the interpretability of subtasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v10 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dai Quoc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11855">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer self-attention network has been extensively used in research
domains such as computer vision, image processing, and natural language
processing. The transformer, however, has not been actively used in graph
neural networks, where constructing an advanced aggregation function is
essential. To this end, we present an effective model, named UGformer, which --
by leveraging a transformer self-attention mechanism followed by a recurrent
transition -- induces an advanced aggregation function to learn graph
representations. Experimental results show that UGformer achieves
state-of-the-art accuracies on well-known benchmark datasets for graph
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster Kernel Interpolation for Gaussian Processes. (arXiv:2101.11751v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_M/0/1/0/all/0/1">Mohit Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheldon_D/0/1/0/all/0/1">Daniel Sheldon</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11751">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge in scaling Gaussian Process (GP) regression to massive
datasets is that exact inference requires computation with a dense n x n kernel
matrix, where n is the number of data points. Significant work focuses on
approximating the kernel matrix via interpolation using a smaller set of m
inducing points. Structured kernel interpolation (SKI) is among the most
scalable methods: by placing inducing points on a dense grid and using
structured matrix algebra, SKI achieves per-iteration time of O(n + m log m)
for approximate inference. This linear scaling in n enables inference for very
large data sets; however the cost is per-iteration, which remains a limitation
for extremely large n. We show that the SKI per-iteration time can be reduced
to O(m log m) after a single O(n) time precomputation step by reframing SKI as
solving a natural Bayesian linear regression problem with a fixed set of m
compact basis functions. With per-iteration complexity independent of the
dataset size n for a fixed grid, our method scales to truly massive data sets.
We demonstrate speedups in practice for a wide range of m and n and apply the
method to GP inference on a three-dimensional weather radar dataset with over
100 million points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Next Waves in Veridical Network Embedding. (arXiv:2007.05385v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ward_O/0/1/0/all/0/1">Owen G. Ward</a>, <a href="http://arxiv.org/find/stat/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Davison_A/0/1/0/all/0/1">Andrew Davison</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_T/0/1/0/all/0/1">Tian Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05385">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding nodes of a large network into a metric (e.g., Euclidean) space has
become an area of active research in statistical machine learning, which has
found applications in natural and social sciences. Generally, a representation
of a network object is learned in a Euclidean geometry and is then used for
subsequent tasks regarding the nodes and/or edges of the network, such as
community detection, node classification and link prediction. Network embedding
algorithms have been proposed in multiple disciplines, often with
domain-specific notations and details. In addition, different measures and
tools have been adopted to evaluate and compare the methods proposed under
different settings, often dependent of the downstream tasks. As a result, it is
challenging to study these algorithms in the literature systematically.
Motivated by the recently proposed Veridical Data Science (VDS) framework, we
propose a framework for network embedding algorithms and discuss how the
principles of predictability, computability and stability apply in this
context. The utilization of this framework in network embedding holds the
potential to motivate and point to new directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Structural Vulnerability in Graph Convolutional Networks. (arXiv:2108.06280v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jintang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qibiao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zibin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06280">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that Graph Convolutional Networks (GCNs) are
vulnerable to adversarial attacks on the graph structure. Although multiple
works have been proposed to improve their robustness against such structural
adversarial attacks, the reasons for the success of the attacks remain unclear.
In this work, we theoretically and empirically demonstrate that structural
adversarial examples can be attributed to the non-robust aggregation scheme
(i.e., the weighted mean) of GCNs. Specifically, our analysis takes advantage
of the breakdown point which can quantitatively measure the robustness of
aggregation schemes. The key insight is that weighted mean, as the basic design
of GCNs, has a low breakdown point and its output can be dramatically changed
by injecting a single edge. We show that adopting the aggregation scheme with a
high breakdown point (e.g., median or trimmed mean) could significantly enhance
the robustness of GCNs against structural attacks. Extensive experiments on
four real-world datasets demonstrate that such a simple but effective method
achieves the best robustness performance compared to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Interpretable Classification and Weakly-Supervised Segmentation of Histology Images via Max-Min Uncertainty. (arXiv:2011.07221v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belharbi_S/0/1/0/all/0/1">Soufiane Belharbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rony_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Rony</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolz_J/0/1/0/all/0/1">Jose Dolz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ismail Ben Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+McCaffrey_L/0/1/0/all/0/1">Luke McCaffrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1">Eric Granger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07221">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised learning (WSL) has recently triggered substantial interest
as it mitigates the lack of pixel-wise annotations.

Given global image labels, WSL methods yield pixel-level predictions
(segmentations), which enable to interpret class predictions. Despite their
recent success, mostly with natural images, such methods can face important
challenges when the foreground and background regions have similar visual cues,
yielding high false-positive rates in segmentations, as is the case in
challenging histology images. WSL training is commonly driven by standard
classification losses, which implicitly maximize model confidence, and locate
the discriminative regions linked to classification decisions. Therefore, they
lack mechanisms for modeling explicitly non-discriminative regions and reducing
false-positive rates. We propose novel regularization terms, which enable the
model to seek both non-discriminative and discriminative regions, while
discouraging unbalanced segmentations. We introduce high uncertainty as a
criterion to localize non-discriminative regions that do not affect classifier
decision, and describe it with original Kullback-Leibler (KL) divergence losses
evaluating the deviation of posterior predictions from the uniform
distribution. Our KL terms encourage high uncertainty of the model when the
latter inputs the latent non-discriminative regions. Our loss integrates: (i) a
cross-entropy seeking a foreground, where model confidence about class
prediction is high; (ii) a KL regularizer seeking a background, where model
uncertainty is high; and (iii) log-barrier terms discouraging unbalanced
segmentations. Comprehensive experiments and ablation studies over the public
GlaS colon cancer data and a Camelyon16 patch-based benchmark for breast cancer
show substantial improvements over state-of-the-art WSL methods, and confirm
the effect of our new regularizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Ridge Solution for the Incremental Broad Learning System on Added Nodes by Inverse Cholesky Factorization of a Partitioned Matrix. (arXiv:1911.04872v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hufei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chenghao Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04872">
                                    <div class="article-summary-box-inner">
                                        <span>To accelerate the existing Broad Learning System (BLS) for new added nodes in
[7], we extend the inverse Cholesky factorization in [10] to deduce an
efficient inverse Cholesky factorization for a Hermitian matrix partitioned
into 2 * 2 blocks, which is utilized to develop the proposed BLS algorithm 1.
The proposed BLS algorithm 1 compute the ridge solution (i.e, the output
weights) from the inverse Cholesky factor of the Hermitian matrix in the ridge
inverse, and update the inverse Cholesky factor efficiently. From the proposed
BLS algorithm 1, we deduce the proposed ridge inverse, which can be obtained
from the generalized inverse in [7] by just change one matrix in the equation
to compute the newly added sub-matrix. We also modify the proposed algorithm 1
into the proposed algorithm 2, which is equivalent to the existing BLS
algorithm [7] in terms of numerical computations. The proposed algorithms 1 and
2 can reduce the computational complexity, since usually the Hermitian matrix
in the ridge inverse is smaller than the ridge inverse. With respect to the
existing BLS algorithm, the proposed algorithms 1 and 2 usually require about
13 and 2 3 of complexities, respectively, while in numerical experiments they
achieve the speedups (in each additional training time) of 2.40 - 2.91 and 1.36
- 1.60, respectively. Numerical experiments also show that the proposed
algorithm 1 and the standard ridge solution always bear the same testing
accuracy, and usually so do the proposed algorithm 2 and the existing BLS
algorithm. The existing BLS assumes the ridge parameter lamda-&gt;0, since it is
based on the generalized inverse with the ridge regression approximation. When
the assumption of lamda-&gt; 0 is not satisfied, the standard ridge solution
obviously achieves a better testing accuracy than the existing BLS algorithm in
numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMET: Convolutional Dimension Interaction for Collaborative Filtering. (arXiv:2007.14129v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xingzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee Keong Kwoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14129">
                                    <div class="article-summary-box-inner">
                                        <span>Latent factor models play a dominant role among recommendation techniques.
However, most of the existing latent factor models assume both historical
interactions and embedding dimensions are independent of each other, and thus
regrettably ignore the high-order interaction information among historical
interactions and embedding dimensions. In this paper, we propose a novel latent
factor model called COMET (COnvolutional diMEnsion inTeraction), which
simultaneously model the high-order interaction patterns among historical
interactions and embedding dimensions. To be specific, COMET stacks the
embeddings of historical interactions horizontally at first, which results in
two &quot;embedding maps&quot;. In this way, internal interactions and dimensional
interactions can be exploited by convolutional neural networks with kernels of
different sizes simultaneously. A fully-connected multi-layer perceptron is
then applied to obtain two interaction vectors. Lastly, the representations of
users and items are enriched by the learnt interaction vectors, which can
further be used to produce the final prediction. Extensive experiments and
ablation studies on various public implicit feedback datasets clearly
demonstrate the effectiveness and the rationality of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Backprop: Stochastic Gradient Descent with Persistent Randomness. (arXiv:2108.06325v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dohare_S/0/1/0/all/0/1">Shibhansh Dohare</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">A. Rupam Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1">Richard S. Sutton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06325">
                                    <div class="article-summary-box-inner">
                                        <span>The Backprop algorithm for learning in neural networks utilizes two
mechanisms: first, stochastic gradient descent and second, initialization with
small random weights, where the latter is essential to the effectiveness of the
former. We show that in continual learning setups, Backprop performs well
initially, but over time its performance degrades. Stochastic gradient descent
alone is insufficient to learn continually; the initial randomness enables only
initial learning but not continual learning. To the best of our knowledge, ours
is the first result showing this degradation in Backprop&#x27;s ability to learn. To
address this issue, we propose an algorithm that continually injects random
features alongside gradient descent using a new generate-and-test process. We
call this the Continual Backprop algorithm. We show that, unlike Backprop,
Continual Backprop is able to continually adapt in both supervised and
reinforcement learning problems. We expect that as continual learning becomes
more common in future applications, a method like Continual Backprop will be
essential where the advantages of random initialization are present throughout
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Datasets for Studying Generalization from Easy to Hard Examples. (arXiv:2108.06011v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgnia_E/0/1/0/all/0/1">Eitan Borgnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Arpit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Emam_Z/0/1/0/all/0/1">Zeyad Emam</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06011">
                                    <div class="article-summary-box-inner">
                                        <span>We describe new datasets for studying generalization from easy to hard
examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Stage Graph Peeling Algorithm for Probabilistic Core Decomposition. (arXiv:2108.06094v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1">Xuekui Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Esfahani_F/0/1/0/all/0/1">Fatemeh Esfahani</a>, <a href="http://arxiv.org/find/stat/1/au:+Srinivasan_V/0/1/0/all/0/1">Venkatesh Srinivasan</a>, <a href="http://arxiv.org/find/stat/1/au:+Thomo_A/0/1/0/all/0/1">Alex Thomo</a>, <a href="http://arxiv.org/find/stat/1/au:+Xing_L/0/1/0/all/0/1">Li Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06094">
                                    <div class="article-summary-box-inner">
                                        <span>Mining dense subgraphs where vertices connect closely with each other is a
common task when analyzing graphs. A very popular notion in subgraph analysis
is core decomposition. Recently, Esfahani et al. presented a probabilistic core
decomposition algorithm based on graph peeling and Central Limit Theorem (CLT)
that is capable of handling very large graphs. Their proposed peeling algorithm
(PA) starts from the lowest degree vertices and recursively deletes these
vertices, assigning core numbers, and updating the degree of neighbour vertices
until it reached the maximum core. However, in many applications, particularly
in biology, more valuable information can be obtained from dense
sub-communities and we are not interested in small cores where vertices do not
interact much with others. To make the previous PA focus more on dense
subgraphs, we propose a multi-stage graph peeling algorithm (M-PA) that has a
two-stage data screening procedure added before the previous PA. After removing
vertices from the graph based on the user-defined thresholds, we can reduce the
graph complexity largely and without affecting the vertices in subgraphs that
we are interested in. We show that M-PA is more efficient than the previous PA
and with the properly set filtering threshold, can produce very similar if not
identical dense subgraphs to the previous PA (in terms of graph density and
clustering coefficient).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bayesian Approach to In-Game Win Probability in Soccer. (arXiv:1906.05029v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robberechts_P/0/1/0/all/0/1">Pieter Robberechts</a>, <a href="http://arxiv.org/find/cs/1/au:+Haaren_J/0/1/0/all/0/1">Jan Van Haaren</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jesse Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.05029">
                                    <div class="article-summary-box-inner">
                                        <span>In-game win probability models, which provide a sports team&#x27;s likelihood of
winning at each point in a game based on historical observations, are becoming
increasingly popular. In baseball, basketball and American football, they have
become important tools to enhance fan experience, to evaluate in-game
decision-making, and to inform coaching decisions. While equally relevant in
soccer, the adoption of these models is held back by technical challenges
arising from the low-scoring nature of the sport.

In this paper, we introduce an in-game win probability model for soccer that
addresses the shortcomings of existing models. First, we demonstrate that
in-game win probability models for other sports struggle to provide accurate
estimates for soccer, especially towards the end of a game. Second, we
introduce a novel Bayesian statistical framework that estimates running win,
tie and loss probabilities by leveraging a set of contextual game state
features. An empirical evaluation on eight seasons of data for the top-five
soccer leagues demonstrates that our framework provides well-calibrated
probabilities. Furthermore, two use cases show its ability to enhance fan
experience and to evaluate performance in crucial game situations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Positive-Unlabelled Learning via Markov Diffusion. (arXiv:2108.06158v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stolfi_P/0/1/0/all/0/1">Paola Stolfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mastropietro_A/0/1/0/all/0/1">Andrea Mastropietro</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasculli_G/0/1/0/all/0/1">Giuseppe Pasculli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tieri_P/0/1/0/all/0/1">Paolo Tieri</a>, <a href="http://arxiv.org/find/cs/1/au:+Vergni_D/0/1/0/all/0/1">Davide Vergni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06158">
                                    <div class="article-summary-box-inner">
                                        <span>Positive-Unlabelled (PU) learning is the machine learning setting in which
only a set of positive instances are labelled, while the rest of the data set
is unlabelled. The unlabelled instances may be either unspecified positive
samples or true negative samples. Over the years, many solutions have been
proposed to deal with PU learning. Some techniques consider the unlabelled
samples as negative ones, reducing the problem to a binary classification with
a noisy negative set, while others aim to detect sets of possible negative
examples to later apply a supervised machine learning strategy (two-step
techniques). The approach proposed in this work falls in the latter category
and works in a semi-supervised fashion: motivated and inspired by previous
works, a Markov diffusion process with restart is used to assign pseudo-labels
to unlabelled instances. Afterward, a machine learning model, exploiting the
newly assigned classes, is trained. The principal aim of the algorithm is to
identify a set of instances which are likely to contain positive instances that
were originally unlabelled.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charts and atlases for nonlinear data-driven models of dynamics on manifolds. (arXiv:2108.05928v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Floryan_D/0/1/0/all/0/1">Daniel Floryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_M/0/1/0/all/0/1">Michael D. Graham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05928">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method for learning minimal-dimensional dynamical models from
high-dimensional time series data that lie on a low-dimensional manifold, as
arises for many processes. For an arbitrary manifold, there is no smooth global
coordinate representation, so following the formalism of differential topology
we represent the manifold as an atlas of charts. We first partition the data
into overlapping regions. Then undercomplete autoencoders are used to find
low-dimensional coordinate representations for each region. We then use the
data to learn dynamical models in each region, which together yield a global
low-dimensional dynamical model. We apply this method to examples ranging from
simple periodic dynamics to complex, nominally high-dimensional non-periodic
bursting dynamics of the Kuramoto-Sivashinsky equation. We demonstrate that it:
(1) can yield dynamical models of the lowest possible dimension, where previous
methods generally cannot; (2) exhibits computational benefits including
scalability, parallelizability, and adaptivity; and (3) separates state space
into regions of distinct behaviours.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MeetSum: Transforming Meeting Transcript Summarization using Transformers!. (arXiv:2108.06310v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadri_N/0/1/0/all/0/1">Nima Sadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bihan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06310">
                                    <div class="article-summary-box-inner">
                                        <span>Creating abstractive summaries from meeting transcripts has proven to be
challenging due to the limited amount of labeled data available for training
neural network models. Moreover, Transformer-based architectures have proven to
beat state-of-the-art models in summarizing news data. In this paper, we
utilize a Transformer-based Pointer Generator Network to generate abstract
summaries for meeting transcripts. This model uses 2 LSTMs as an encoder and a
decoder, a Pointer network which copies words from the inputted text, and a
Generator network to produce out-of-vocabulary words (hence making the summary
abstractive). Moreover, a coverage mechanism is used to avoid repetition of
words in the generated summary. First, we show that training the model on a
news summary dataset and using zero-shot learning to test it on the meeting
dataset proves to produce better results than training it on the AMI meeting
dataset. Second, we show that training this model first on out-of-domain data,
such as the CNN-Dailymail dataset, followed by a fine-tuning stage on the AMI
meeting dataset is able to improve the performance of the model significantly.
We test our model on a testing set from the AMI dataset and report the ROUGE-2
score of the generated summary to compare with previous literature. We also
report the Factual score of our summaries since it is a better benchmark for
abstractive summaries since the ROUGE-2 score is limited to measuring
word-overlaps. We show that our improved model is able to improve on previous
models by at least 5 ROUGE-2 scores, which is a substantial improvement. Also,
a qualitative analysis of the summaries generated by our model shows that these
summaries and human-readable and indeed capture most of the important
information from the transcripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Follow the Prophet: Accurate Online Conversion Rate Prediction in the Face of Delayed Feedback. (arXiv:2108.06167v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Feiyang Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1">Xiang Ao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Min Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Junwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dapeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1">Qing He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06167">
                                    <div class="article-summary-box-inner">
                                        <span>The delayed feedback problem is one of the imperative challenges in online
advertising, which is caused by the highly diversified feedback delay of a
conversion varying from a few minutes to several days. It is hard to design an
appropriate online learning system under these non-identical delay for
different types of ads and users. In this paper, we propose to tackle the
delayed feedback problem in online advertising by &quot;Following the Prophet&quot; (FTP
for short). The key insight is that, if the feedback came instantly for all the
logged samples, we could get a model without delayed feedback, namely the
&quot;prophet&quot;. Although the prophet cannot be obtained during online learning, we
show that we could predict the prophet&#x27;s predictions by an aggregation policy
on top of a set of multi-task predictions, where each task captures the
feedback patterns of different periods. We propose the objective and
optimization approach for the policy, and use the logged data to imitate the
prophet. Extensive experiments on three real-world advertising datasets show
that our method outperforms the previous state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ST-PCNN: Spatio-Temporal Physics-Coupled Neural Networks for Dynamics Forecasting. (arXiv:2108.05940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">James Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Min Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Hanqi Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingquan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherubin_L/0/1/0/all/0/1">Laurent Ch&#xe9;rubin</a>, <a href="http://arxiv.org/find/cs/1/au:+VanZwieten_J/0/1/0/all/0/1">James VanZwieten</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yufei Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05940">
                                    <div class="article-summary-box-inner">
                                        <span>Ocean current, fluid mechanics, and many other spatio-temporal physical
dynamical systems are essential components of the universe. One key
characteristic of such systems is that certain physics laws -- represented as
ordinary/partial differential equations (ODEs/PDEs) -- largely dominate the
whole process, irrespective of time or location. Physics-informed learning has
recently emerged to learn physics for accurate prediction, but they often lack
a mechanism to leverage localized spatial and temporal correlation or rely on
hard-coded physics parameters. In this paper, we advocate a physics-coupled
neural network model to learn parameters governing the physics of the system,
and further couple the learned physics to assist the learning of recurring
dynamics. A spatio-temporal physics-coupled neural network (ST-PCNN) model is
proposed to achieve three goals: (1) learning the underlying physics
parameters, (2) transition of local information between spatio-temporal
regions, and (3) forecasting future values for the dynamical system. The
physics-coupled learning ensures that the proposed model can be tremendously
improved by using learned physics parameters, and can achieve good long-range
forecasting (e.g., more than 30-steps). Experiments, using simulated and
field-collected ocean current data, validate that ST-PCNN outperforms existing
physics-informed models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Q-Mixing Network for Multi-Agent Pathfinding in Partially Observable Grid Environments. (arXiv:2108.06148v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davydov_V/0/1/0/all/0/1">Vasilii Davydov</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrynnik_A/0/1/0/all/0/1">Alexey Skrynnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1">Konstantin Yakovlev</a>, <a href="http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1">Aleksandr I. Panov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06148">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider the problem of multi-agent navigation in partially
observable grid environments. This problem is challenging for centralized
planning approaches as they, typically, rely on the full knowledge of the
environment. We suggest utilizing the reinforcement learning approach when the
agents, first, learn the policies that map observations to actions and then
follow these policies to reach their goals. To tackle the challenge associated
with learning cooperative behavior, i.e. in many cases agents need to yield to
each other to accomplish a mission, we use a mixing Q-network that complements
learning individual policies. In the experimental evaluation, we show that such
approach leads to plausible results and scales well to large number of agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ergonomically Intelligent Physical Human-Robot Interaction: Postural Estimation, Assessment, and Optimization. (arXiv:2108.05971v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yazdani_A/0/1/0/all/0/1">Amir Yazdani</a>, <a href="http://arxiv.org/find/cs/1/au:+Novin_R/0/1/0/all/0/1">Roya Sabbagh Novin</a>, <a href="http://arxiv.org/find/cs/1/au:+Merryweather_A/0/1/0/all/0/1">Andrew Merryweather</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermans_T/0/1/0/all/0/1">Tucker Hermans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05971">
                                    <div class="article-summary-box-inner">
                                        <span>Ergonomics and human comfort are essential concerns in physical human-robot
interaction applications, and common practical methods either fail in
estimating the correct posture due to occlusion or suffer from less accurate
ergonomics models in their postural optimization methods. Instead, we propose a
novel framework for posture estimation, assessment, and optimization for
ergonomically intelligent physical human-robot interaction. We show that we can
estimate human posture solely from the trajectory of the interacting robot. We
propose DULA, a differentiable ergonomics model, and use it in gradient-free
postural optimization for physical human-robot interaction tasks such as
co-manipulation and teleoperation. We evaluate our framework through human and
simulation experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable3-BO: Big Data meets HPC - A scalable asynchronous parallel high-dimensional Bayesian optimization framework on supercomputers. (arXiv:2108.05969v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05969">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is a flexible and powerful framework that is
suitable for computationally expensive simulation-based applications and
guarantees statistical convergence to the global optimum. While remaining as
one of the most popular optimization methods, its capability is hindered by the
size of data, the dimensionality of the considered problem, and the nature of
sequential optimization. These scalability issues are intertwined with each
other and must be tackled simultaneously. In this work, we propose the
Scalable$^3$-BO framework, which employs sparse GP as the underlying surrogate
model to scope with Big Data and is equipped with a random embedding to
efficiently optimize high-dimensional problems with low effective
dimensionality. The Scalable$^3$-BO framework is further leveraged with
asynchronous parallelization feature, which fully exploits the computational
resource on HPC within a computational budget. As a result, the proposed
Scalable$^3$-BO framework is scalable in three independent perspectives: with
respect to data size, dimensionality, and computational resource on HPC. The
goal of this work is to push the frontiers of BO beyond its well-known
scalability issues and minimize the wall-clock waiting time for optimizing
high-dimensional computationally expensive applications. We demonstrate the
capability of Scalable$^3$-BO with 1 million data points, 10,000-dimensional
problems, with 20 concurrent workers in an HPC environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Network Approximation for Smooth Functions. (arXiv:2001.03040v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03040">
                                    <div class="article-summary-box-inner">
                                        <span>This paper establishes the optimal approximation error characterization of
deep rectified linear unit (ReLU) networks for smooth functions in terms of
both width and depth simultaneously. To that end, we first prove that
multivariate polynomials can be approximated by deep ReLU networks of width
$\mathcal{O}(N)$ and depth $\mathcal{O}(L)$ with an approximation error
$\mathcal{O}(N^{-L})$. Through local Taylor expansions and their deep ReLU
network approximations, we show that deep ReLU networks of width
$\mathcal{O}(N\ln N)$ and depth $\mathcal{O}(L\ln L)$ can approximate $f\in
C^s([0,1]^d)$ with a nearly optimal approximation error
$\mathcal{O}(\|f\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our estimate is
non-asymptotic in the sense that it is valid for arbitrary width and depth
specified by $N\in\mathbb{N}^+$ and $L\in\mathbb{N}^+$, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling extra-deep electromagnetic logs using a deep neural network. (arXiv:2005.08919v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Alyaev_S/0/1/0/all/0/1">Sergey Alyaev</a>, <a href="http://arxiv.org/find/eess/1/au:+Shahriari_M/0/1/0/all/0/1">Mostafa Shahriari</a>, <a href="http://arxiv.org/find/eess/1/au:+Pardo_D/0/1/0/all/0/1">David Pardo</a>, <a href="http://arxiv.org/find/eess/1/au:+Omella_A/0/1/0/all/0/1">Angel Javier Omella</a>, <a href="http://arxiv.org/find/eess/1/au:+Larsen_D/0/1/0/all/0/1">David Larsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jahani_N/0/1/0/all/0/1">Nazanin Jahani</a>, <a href="http://arxiv.org/find/eess/1/au:+Suter_E/0/1/0/all/0/1">Erich Suter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08919">
                                    <div class="article-summary-box-inner">
                                        <span>Modern geosteering is heavily dependent on real-time interpretation of deep
electromagnetic (EM) measurements. We present a methodology to construct a deep
neural network (DNN) model trained to reproduce a full set of extra-deep EM
logs consisting of 22 measurements per logging position. The model is trained
in a 1D layered environment consisting of up to seven layers with different
resistivity values. A commercial simulator provided by a tool vendor is used to
generate a training dataset. The dataset size is limited because the simulator
provided by the vendor is optimized for sequential execution. Therefore, we
design a training dataset that embraces the geological rules and geosteering
specifics supported by the forward model. We use this dataset to produce an EM
simulator based on a DNN without access to the proprietary information about
the EM tool configuration or the original simulator source code. Despite
employing a relatively small training set size, the resulting DNN forward model
is quite accurate for the considered examples: a multi-layer synthetic case and
a section of a published historical operation from the Goliat Field. The
observed average evaluation time of 0.15 ms per logging position makes it also
suitable for future use as part of evaluation-hungry statistical and/or
Monte-Carlo inversion algorithms within geosteering workflows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A reduced-order modeling framework for simulating signatures of faults in a bladed disk. (arXiv:2108.06265v1 [cs.CE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1">Divya Shyam Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Atul Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahapatra_D/0/1/0/all/0/1">D. Roy Mahapatra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06265">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reports a reduced-order modeling framework of bladed disks on a
rotating shaft to simulate the vibration signature of faults like cracks in
different components aiming towards simulated data-driven machine learning. We
have employed lumped and one-dimensional analytical models of the subcomponents
for better insight into the complex dynamic response. The framework seeks to
address some of the challenges encountered in analyzing and optimizing fault
detection and identification schemes for health monitoring of rotating
turbomachinery, including aero-engines. We model the bladed disks and shafts by
combining lumped elements and one-dimensional finite elements, leading to a
coupled system. The simulation results are in good agreement with previously
published data. We model the cracks in a blade analytically with their
effective reduced stiffness approximation. Multiple types of faults are
modeled, including cracks in the blades of single and two-stage bladed disks,
Fan Blade Off (FBO), and Foreign Object Damage (FOD). We have applied
aero-engine operational loading conditions to simulate realistic scenarios of
online health monitoring. The proposed reduced-order simulation framework will
have applications in probabilistic signal modeling, machine learning toward
fault signature identification, and parameter estimation with measured
vibration signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training. (arXiv:2108.06084v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Conglong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minjia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuxiong He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06084">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have demonstrated great success in training high-capacity
autoregressive language models (GPT, GPT-2, GPT-3) on a huge amount of
unlabeled text corpus for text generation. Despite showing great results, this
generates two training efficiency challenges. First, training large corpora can
be extremely timing consuming, and how to present training samples to the model
to improve the token-wise convergence speed remains a challenging and open
question. Second, many of these large models have to be trained with hundreds
or even thousands of processors using data-parallelism with a very large batch
size. Despite of its better compute efficiency, it has been observed that
large-batch training often runs into training instability issue or converges to
solutions with bad generalization performance. To overcome these two
challenges, we present a study of a curriculum learning based approach, which
helps improves the pre-training convergence speed of autoregressive models.
More importantly, we find that curriculum learning, as a regularization method,
exerts a gradient variance reduction effect and enables to train autoregressive
models with much larger batch sizes and learning rates without training
instability, further improving the training speed. Our evaluations demonstrate
that curriculum learning enables training GPT-2 models (with up to 1.5B
parameters) with 8x larger batch size and 4x larger learning rate, whereas the
baseline approach struggles with training divergence. To achieve the same
validation perplexity targets during pre-training, curriculum learning reduces
the required number of tokens and wall clock time by up to 59% and 54%,
respectively. To achieve the same or better zero-shot WikiText-103/LAMBADA
evaluation results at the end of pre-training, curriculum learning reduces the
required number of tokens and wall clock time by up to 13% and 61%,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining. (arXiv:2108.06197v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qianqian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessen_D/0/1/0/all/0/1">David J. Hessen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heijden_P/0/1/0/all/0/1">Peter G. M. van der Heijden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Both latent semantic analysis (LSA) and correspondence analysis (CA) use a
singular value decomposition (SVD) for dimensionality reduction. In this
article, LSA and CA are compared from a theoretical point of view and applied
in both a toy example and an authorship attribution example. In text mining
interest goes out to the relationships among documents and terms: for example,
what terms are more often used in what documents. However, the LSA solution
displays a mix of marginal effects and these relationships. It appears that CA
has more attractive properties than LSA. One such property is that, in CA, the
effect of the margins is effectively eliminated, so that the CA solution is
optimally suited to focus on the relationships among documents and terms. Three
mechanisms are distinguished to weight documents and terms, and a unifying
framework is proposed that includes these three mechanisms and includes both CA
and LSA as special cases. In the authorship attribution example, the national
anthem of the Netherlands, the application of the discussed methods is
illustrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LT-OCF: Learnable-Time ODE-based Collaborative Filtering. (arXiv:2108.06208v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jeongwhan Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06208">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is a long-standing problem of recommender
systems. Many novel methods have been proposed, ranging from classical matrix
factorization to recent graph convolutional network-based approaches. After
recent fierce debates, researchers started to focus on linear graph
convolutional networks (GCNs) with a layer combination, which show
state-of-the-art accuracy in many datasets. In this work, we extend them based
on neural ordinary differential equations (NODEs), because the linear GCN
concept can be interpreted as a differential equation, and present the method
of Learnable-Time ODE-based Collaborative Filtering (LT-OCF). The main novelty
in our method is that after redesigning linear GCNs on top of the NODE regime,
i) we learn the optimal architecture rather than relying on manually designed
ones, ii) we learn smooth ODE solutions that are considered suitable for CF,
and iii) we test with various ODE solvers that internally build a diverse set
of neural network connections. We also present a novel training method
specialized to our method. In our experiments with three benchmark datasets,
Gowalla, Yelp2018, and Amazon-Book, our method consistently shows better
accuracy than existing methods, e.g., a recall of 0.0411 by LightGCN vs. 0.0442
by LT-OCF and an NDCG of 0.0315 by LightGCN vs. 0.0341 by LT-OCF in
Amazon-Book. One more important discovery in our experiments that is worth
mentioning is that our best accuracy was achieved by dense connections rather
than linear connections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Fairness Metrics: Roadblocks and Challenges for Ethical AI in Practice. (arXiv:2108.06217v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Storchan_V/0/1/0/all/0/1">Victor Storchan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurshan_E/0/1/0/all/0/1">Eren Kurshan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06217">
                                    <div class="article-summary-box-inner">
                                        <span>We review practical challenges in building and deploying ethical AI at the
scale of contemporary industrial and societal uses. Apart from the purely
technical concerns that are the usual focus of academic research, the
operational challenges of inconsistent regulatory pressures, conflicting
business goals, data quality issues, development processes, systems integration
practices, and the scale of deployment all conspire to create new ethical
risks. Such ethical concerns arising from these practical considerations are
not adequately addressed by existing research results. We argue that a holistic
consideration of ethics in the development and deployment of AI systems is
necessary for building ethical AI in practice, and exhort researchers to
consider the full operational contexts of AI systems when assessing ethical
risks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Quality Toolkit: Automatic assessment of data quality and remediation for machine learning datasets. (arXiv:2108.05935v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nitin Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_H/0/1/0/all/0/1">Hima Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Afzal_S/0/1/0/all/0/1">Shazia Afzal</a>, <a href="http://arxiv.org/find/cs/1/au:+Panwar_N/0/1/0/all/0/1">Naveen Panwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1">Ruhi Sharma Mittal</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttula_S/0/1/0/all/0/1">Shanmukha Guttula</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Abhinav Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagalapatti_L/0/1/0/all/0/1">Lokesh Nagalapatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1">Sameep Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Hans_S/0/1/0/all/0/1">Sandeep Hans</a>, <a href="http://arxiv.org/find/cs/1/au:+Lohia_P/0/1/0/all/0/1">Pranay Lohia</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1">Aniya Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1">Diptikalyan Saha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05935">
                                    <div class="article-summary-box-inner">
                                        <span>The quality of training data has a huge impact on the efficiency, accuracy
and complexity of machine learning tasks. Various tools and techniques are
available that assess data quality with respect to general cleaning and
profiling checks. However these techniques are not applicable to detect data
issues in the context of machine learning tasks, like noisy labels, existence
of overlapping classes etc. We attempt to re-look at the data quality issues in
the context of building a machine learning pipeline and build a tool that can
detect, explain and remediate issues in the data, and systematically and
automatically capture all the changes applied to the data. We introduce the
Data Quality Toolkit for machine learning as a library of some key quality
metrics and relevant remediation techniques to analyze and enhance the
readiness of structured training datasets for machine learning projects. The
toolkit can reduce the turn-around times of data preparation pipelines and
streamline the data quality assessment process. Our toolkit is publicly
available via IBM API Hub [1] platform, any developer can assess the data
quality using the IBM&#x27;s Data Quality for AI apis [2]. Detailed tutorials are
also available on IBM Learning Path [3].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text. (arXiv:2104.11178v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1">Hassan Akbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liangzhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_R/0/1/0/all/0/1">Rui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1">Wei-Hong Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yin Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11178">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for learning multimodal representations from unlabeled
data using convolution-free Transformer architectures. Specifically, our
Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts
multimodal representations that are rich enough to benefit a variety of
downstream tasks. We train VATT end-to-end from scratch using multimodal
contrastive losses and evaluate its performance by the downstream tasks of
video action recognition, audio event classification, image classification, and
text-to-video retrieval. Furthermore, we study a modality-agnostic
single-backbone Transformer by sharing weights among the three modalities. We
show that the convolution-free VATT outperforms state-of-the-art ConvNet-based
architectures in the downstream tasks. Especially, VATT&#x27;s vision Transformer
achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,and
41.1% on Moments in Time, new records while avoiding supervised pre-training.
Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet
compared to 64.7% by training the same Transformer from scratch, showing the
generalizability of our model despite the domain gap between videos and images.
VATT&#x27;s audio Transformer also sets a new record on waveform-based audio event
recognition by achieving the mAP of 39.4% on AudioSet without any supervised
pre-training. VATT&#x27;s source code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Hate in Online Memes. (arXiv:2108.06207v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Rui Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1">Wen-Haw Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06207">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful and offensive content detection has been extensively explored in a
single modality such as text. However, such toxic information could also be
communicated via multimodal content such as online memes. Therefore, detecting
multimodal hateful content has recently garnered much attention in academic and
industry research communities. This paper aims to contribute to this emerging
research topic by proposing DisMultiHate, which is a novel framework that
performed the classification of multimodal hateful content. Specifically,
DisMultiHate is designed to disentangle target entities in multimodal memes to
improve hateful content classification and explainability. We conduct extensive
experiments on two publicly available hateful and offensive memes datasets. Our
experiment results show that DisMultiHate is able to outperform
state-of-the-art unimodal and multimodal baselines in the hateful meme
classification task. Empirical case studies were also conducted to demonstrate
DisMultiHate&#x27;s ability to disentangle target entities in memes and ultimately
showcase DisMultiHate&#x27;s explainability of the multimodal hateful content
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaze-Contingent Retinal Speckle Suppression for Perceptually-Matched Foveated Holographic Displays. (arXiv:2108.06192v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakravarthula_P/0/1/0/all/0/1">Praneeth Chakravarthula</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Okan Tursun</a>, <a href="http://arxiv.org/find/cs/1/au:+Didyk_P/0/1/0/all/0/1">Piotr Didyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuchs_H/0/1/0/all/0/1">Henry Fuchs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06192">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-generated holographic (CGH) displays show great potential and are
emerging as the next-generation displays for augmented and virtual reality, and
automotive heads-up displays. One of the critical problems harming the wide
adoption of such displays is the presence of speckle noise inherent to
holography, that compromises its quality by introducing perceptible artifacts.
Although speckle noise suppression has been an active research area, the
previous works have not considered the perceptual characteristics of the Human
Visual System (HVS), which receives the final displayed imagery. However, it is
well studied that the sensitivity of the HVS is not uniform across the visual
field, which has led to gaze-contingent rendering schemes for maximizing the
perceptual quality in various computer-generated imagery. Inspired by this, we
present the first method that reduces the &quot;perceived speckle noise&quot; by
integrating foveal and peripheral vision characteristics of the HVS, along with
the retinal point spread function, into the phase hologram computation.
Specifically, we introduce the anatomical and statistical retinal receptor
distribution into our computational hologram optimization, which places a
higher priority on reducing the perceived foveal speckle noise while being
adaptable to any individual&#x27;s optical aberration on the retina. Our method
demonstrates superior perceptual quality on our emulated holographic display.
Our evaluations with objective measurements and subjective studies demonstrate
a significant reduction of the human perceived noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-13">2021-08-13</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dissecting User-Perceived Latency of On-Device E2E Speech Recognition. (arXiv:2104.02207v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1">Yuan Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1">Rohit Prabhavalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1">Jay Mahadeokar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yangyang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiatong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chunyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1">Duc Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1">Ozlem Kalinli</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1">Christian Fuegen</a>, <a href="http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1">Michael L. Seltzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02207">
                                    <div class="article-summary-box-inner">
                                        <span>As speech-enabled devices such as smartphones and smart speakers become
increasingly ubiquitous, there is growing interest in building automatic speech
recognition (ASR) systems that can run directly on-device; end-to-end (E2E)
speech recognition models such as recurrent neural network transducers and
their variants have recently emerged as prime candidates for this task. Apart
from being accurate and compact, such systems need to decode speech with low
user-perceived latency (UPL), producing words as soon as they are spoken. This
work examines the impact of various techniques - model architectures, training
criteria, decoding hyperparameters, and endpointer parameters - on UPL. Our
analyses suggest that measures of model size (parameters, input chunk sizes),
or measures of computation (e.g., FLOPS, RTF) that reflect the model&#x27;s ability
to process input frames are not always strongly correlated with observed UPL.
Thus, conventional algorithmic latency measurements might be inadequate in
accurately capturing latency observed when models are deployed on embedded
devices. Instead, we find that factors affecting token emission latency, and
endpointing behavior have a larger impact on UPL. We achieve the best trade-off
between latency and word error rate when performing ASR jointly with
endpointing, while utilizing the recently proposed alignment regularization
mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word Alignment by Fine-tuning Embeddings on Parallel Corpora. (arXiv:2101.08231v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08231">
                                    <div class="article-summary-box-inner">
                                        <span>Word alignment over parallel corpora has a wide variety of applications,
including learning translation lexicons, cross-lingual transfer of language
processing tools, and automatic evaluation or analysis of translation outputs.
The great majority of past work on word alignment has worked by performing
unsupervised learning on parallel texts. Recently, however, other work has
demonstrated that pre-trained contextualized word embeddings derived from
multilingually trained language models (LMs) prove an attractive alternative,
achieving competitive results on the word alignment task even in the absence of
explicit training on parallel data. In this paper, we examine methods to marry
the two approaches: leveraging pre-trained LMs but fine-tuning them on parallel
text with objectives designed to improve alignment quality, and proposing
methods to effectively extract alignments from these fine-tuned models. We
perform experiments on five language pairs and demonstrate that our model can
consistently outperform previous state-of-the-art models of all varieties. In
addition, we demonstrate that we are able to train multilingual word aligners
that can obtain robust performance on different language pairs. Our aligner,
AWESOME (Aligning Word Embedding Spaces of Multilingual Encoders), with
pre-trained models is available at https://github.com/neulab/awesome-align</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Lexically Constrained Neural Machine Translation with Source-Conditioned Masked Span Prediction. (arXiv:2105.05498v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gyubok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seongjun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05498">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate terminology translation is crucial for ensuring the practicality and
reliability of neural machine translation (NMT) systems. To address this,
lexically constrained NMT explores various methods to ensure pre-specified
words and phrases appear in the translation output. However, in many cases,
those methods are studied on general domain corpora, where the terms are mostly
uni- and bi-grams (&gt;98%). In this paper, we instead tackle a more challenging
setup consisting of domain-specific corpora with much longer n-gram and highly
specialized terms. Inspired by the recent success of masked span prediction
models, we propose a simple and effective training strategy that achieves
consistent improvements on both terminology and sentence-level translation for
three domain-specific corpora in two language pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ambiguity Hierarchy of Regular Infinite Tree Languages. (arXiv:2009.02985v3 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rabinovich_A/0/1/0/all/0/1">Alexander Rabinovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiferet_D/0/1/0/all/0/1">Doron Tiferet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02985">
                                    <div class="article-summary-box-inner">
                                        <span>An automaton is unambiguous if for every input it has at most one accepting
computation. An automaton is k-ambiguous (for k &gt; 0) if for every input it has
at most k accepting computations. An automaton is boundedly ambiguous if it is
k-ambiguous for some $k \in \mathbb{N}$. An automaton is finitely
(respectively, countably) ambiguous if for every input it has at most finitely
(respectively, countably) many accepting computations.

The degree of ambiguity of a regular language is defined in a natural way. A
language is k-ambiguous (respectively, boundedly, finitely, countably
ambiguous) if it is accepted by a k-ambiguous (respectively, boundedly,
finitely, countably ambiguous) automaton. Over finite words every regular
language is accepted by a deterministic automaton. Over finite trees every
regular language is accepted by an unambiguous automaton. Over $\omega$-words
every regular language is accepted by an unambiguous B\&quot;uchi automaton and by a
deterministic parity automaton. Over infinite trees Carayol et al. showed that
there are ambiguous languages.

We show that over infinite trees there is a hierarchy of degrees of
ambiguity: For every k &gt; 1 there are k-ambiguous languages that are not k - 1
ambiguous; and there are finitely (respectively countably, uncountably)
ambiguous languages that are not boundedly (respectively finitely, countably)
ambiguous.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syntax Matters! Syntax-Controlled in Text Style Transfer. (arXiv:2108.05869v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiqiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1">Roy Ka-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu C. Aggarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05869">
                                    <div class="article-summary-box-inner">
                                        <span>Existing text style transfer (TST) methods rely on style classifiers to
disentangle the text&#x27;s content and style attributes for text style transfer.
While the style classifier plays a critical role in existing TST methods, there
is no known investigation on its effect on the TST methods. In this paper, we
conduct an empirical study on the limitations of the style classifiers used in
existing TST methods. We demonstrate that the existing style classifiers cannot
learn sentence syntax effectively and ultimately worsen existing TST models&#x27;
performance. To address this issue, we propose a novel Syntax-Aware
Controllable Generation (SACG) model, which includes a syntax-aware style
classifier that ensures learned style latent representations effectively
capture the syntax information for TST. Through extensive experiments on two
popular TST tasks, we show that our proposed method significantly outperforms
the state-of-the-art methods. Our case studies have also demonstrated SACG&#x27;s
ability to generate fluent target-style sentences that preserved the original
content.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cyclic Proof System for HFLN. (arXiv:2010.14891v3 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kori_M/0/1/0/all/0/1">Mayuko Kori</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsukada_T/0/1/0/all/0/1">Takeshi Tsukada</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_N/0/1/0/all/0/1">Naoki Kobayashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14891">
                                    <div class="article-summary-box-inner">
                                        <span>A cyclic proof system allows us to perform inductive reasoning without
explicit inductions. We propose a cyclic proof system for HFLN, which is a
higher-order predicate logic with natural numbers and alternating fixed-points.
Ours is the first cyclic proof system for a higher-order logic, to our
knowledge. Due to the presence of higher-order predicates and alternating
fixed-points, our cyclic proof system requires a more delicate global condition
on cyclic proofs than the original system of Brotherston and Simpson. We prove
the decidability of checking the global condition and soundness of this system,
and also prove a restricted form of standard completeness for an infinitary
variant of our cyclic proof system. A potential application of our cyclic proof
system is semi-automated verification of higher-order programs, based on
Kobayashi et al.&#x27;s recent work on reductions from program verification to HFLN
validity checking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Neural Information Fusion Architecture for Textual Network Embeddings. (arXiv:1908.11057v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qinliang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weijia Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.11057">
                                    <div class="article-summary-box-inner">
                                        <span>Textual network embeddings aim to learn a low-dimensional representation for
every node in the network so that both the structural and textual information
from the networks can be well preserved in the representations. Traditionally,
the structural and textual embeddings were learned by models that rarely take
the mutual influences between them into account. In this paper, a deep neural
architecture is proposed to effectively fuse the two kinds of informations into
one representation. The novelties of the proposed architecture are manifested
in the aspects of a newly defined objective function, the complementary
information fusion method for structural and textual features, and the mutual
gate mechanism for textual feature extraction. Experimental results show that
the proposed model outperforms the comparing methods on all three datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistent Dialogue Generation with Self-supervised Feature Learning. (arXiv:1903.05759v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1">Chris Brockett</a>, <a href="http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1">Michel Galley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1">Bill Dolan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.05759">
                                    <div class="article-summary-box-inner">
                                        <span>Generating responses that are consistent with the dialogue context is one of
the central challenges in building engaging conversational agents. We
demonstrate that neural conversation models can be geared towards generating
consistent responses by maintaining certain features related to topics and
personas throughout the conversation. Past work has required external
supervision that exploits features such as user identities that are often
unavailable. In our approach, topic and persona feature extractors are trained
using a contrastive training scheme that utilizes the natural structure of
dialogue data. We further adopt a feature disentangling loss which, paired with
controllable response generation techniques, allows us to promote or demote
certain learned topics and persona features. Evaluation results demonstrate the
model&#x27;s ability to capture meaningful topics and persona features. The
incorporation of the learned features brings significant improvement in terms
of the quality of generated responses on two dialogue datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining (second-order) graph-based and headed span-based projective dependency parsing. (arXiv:2108.05838v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Songlin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05838">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based methods are popular in dependency parsing for decades. Recently,
\citet{yang2021headed} propose a headed span-based method. Both of them score
all possible trees and globally find the highest-scoring tree. In this paper,
we combine these two kinds of methods, designing several dynamic programming
algorithms for joint inference. Experiments show the effectiveness of our
proposed methods\footnote{Our code is publicly available at
\url{https://github.com/sustcsonglin/span-based-dependency-parsing}.}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable pragmatic communication via self-supervision. (arXiv:2108.05799v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jennifer Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1">Roger Levy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaslavsky_N/0/1/0/all/0/1">Noga Zaslavsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05799">
                                    <div class="article-summary-box-inner">
                                        <span>Models of context-sensitive communication often use the Rational Speech Act
framework (RSA; Frank &amp; Goodman, 2012), which formulates listeners and speakers
in a cooperative reasoning process. However, the standard RSA formulation can
only be applied to small domains, and large-scale applications have relied on
imitating human behavior. Here, we propose a new approach to scalable
pragmatics, building upon recent theoretical results (Zaslavsky et al., 2020)
that characterize pragmatic reasoning in terms of general information-theoretic
principles. Specifically, we propose an architecture and learning process in
which agents acquire pragmatic policies via self-supervision instead of
imitating human data. This work suggests a new principled approach for
equipping artificial agents with pragmatic skills via self-supervision, which
is grounded both in pragmatic theory and in information theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting Semantics from Maintenance Records. (arXiv:2108.05454v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dixit_S/0/1/0/all/0/1">Sharad Dixit</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulwad_V/0/1/0/all/0/1">Varish Mulwad</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1">Abhinav Saxena</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05454">
                                    <div class="article-summary-box-inner">
                                        <span>Rapid progress in natural language processing has led to its utilization in a
variety of industrial and enterprise settings, including in its use for
information extraction, specifically named entity recognition and relation
extraction, from documents such as engineering manuals and field maintenance
reports. While named entity recognition is a well-studied problem, existing
state-of-the-art approaches require large labelled datasets which are hard to
acquire for sensitive data such as maintenance records. Further, industrial
domain experts tend to distrust results from black box machine learning models,
especially when the extracted information is used in downstream predictive
maintenance analytics. We overcome these challenges by developing three
approaches built on the foundation of domain expert knowledge captured in
dictionaries and ontologies. We develop a syntactic and semantic rules-based
approach and an approach leveraging a pre-trained language model, fine-tuned
for a question-answering task on top of our base dictionary lookup to extract
entities of interest from maintenance records. We also develop a preliminary
ontology to represent and capture the semantics of maintenance records. Our
evaluations on a real-world aviation maintenance records dataset show promising
results and help identify challenges specific to named entity recognition in
the context of noisy industrial data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1">Verna Dankers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1">Elia Bruni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1">Dieuwke Hupkes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05885">
                                    <div class="article-summary-box-inner">
                                        <span>Moving towards human-like linguistic performance is often argued to require
compositional generalisation. Whether neural networks exhibit this ability is
typically studied using artificial languages, for which the compositionality of
input fragments can be guaranteed and their meanings algebraically composed.
However, compositionality in natural language is vastly more complex than this
rigid, arithmetics-like version of compositionality, and as such artificial
compositionality tests do not allow us to draw conclusions about how neural
models deal with compositionality in more realistic scenarios. In this work, we
re-instantiate three compositionality tests from the literature and reformulate
them for neural machine translation (NMT). The results highlight two main
issues: the inconsistent behaviour of NMT models and their inability to
(correctly) modulate between local and global processing. Aside from an
empirical study, our work is a call to action: we should rethink the evaluation
of compositionality in neural networks of natural language, where composing
meaning is not as straightforward as doing the math.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">(Un)solving Morphological Inflection: Lemma Overlap Artificially Inflates Models&#x27; Performance. (arXiv:2108.05682v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goldman_O/0/1/0/all/0/1">Omer Goldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Guriel_D/0/1/0/all/0/1">David Guriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1">Reut Tsarfaty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05682">
                                    <div class="article-summary-box-inner">
                                        <span>In the domain of Morphology, Inflection is a fundamental and important task
that gained a lot of traction in recent years, mostly via SIGMORPHON&#x27;s
shared-tasks. With average accuracy above 0.9 over the scores of all languages,
the task is considered mostly solved using relatively generic neural
sequence-to-sequence models, even with little data provided. In this work, we
propose to re-evaluate morphological inflection models by employing harder
train-test splits that will challenge the generalization capacity of the
models. In particular, as opposed to the na\&quot;ive split-by-form, we propose a
split-by-lemma method to challenge the performance on existing benchmarks. Our
experiments with the three top-ranked systems on the SIGMORPHON&#x27;s 2020
shared-task show that the lemma-split presents an average drop of 30 percentage
points in macro-average for the 90 languages included. The effect is most
significant for low-resourced languages with a drop as high as 95 points, but
even high-resourced languages lose about 10 points on average. Our results
clearly show that generalizing inflection to unseen lemmas is far from being
solved, presenting a simple yet effective means to promote more sophisticated
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NoFake at CheckThat! 2021: Fake News Detection Using BERT. (arXiv:2108.05419v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sushma Kumari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05419">
                                    <div class="article-summary-box-inner">
                                        <span>Much research has been done for debunking and analysing fake news. Many
researchers study fake news detection in the last year, but many are limited to
social media data. Currently, multiples fact-checkers are publishing their
results in various formats. Also, multiple fact-checkers use different labels
for the fake news, making it difficult to make a generalisable classifier. With
the merge classes, the performance of the machine model can be enhanced. This
domain categorisation will help group the article, which will help save the
manual effort in assigning the claim verification. In this paper, we have
presented BERT based classification model to predict the domain and
classification. We have also used additional data from fact-checked articles.
We have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B
using the additional training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Optimal is Greedy Decoding for Extractive Question Answering?. (arXiv:2108.05857v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castel_O/0/1/0/all/0/1">Or Castel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1">Ori Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Efrat_A/0/1/0/all/0/1">Avia Efrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1">Omer Levy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05857">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-tuned language models use greedy decoding to answer reading
comprehension questions with relative success. However, this approach does not
ensure that the answer is a span in the given passage, nor does it guarantee
that it is the most probable one. Does greedy decoding actually perform worse
than an algorithm that does adhere to these properties? To study the
performance and optimality of greedy decoding, we present exact-extract, a
decoding algorithm that efficiently finds the most probable answer span in the
context. We compare the performance of T5 with both decoding algorithms on
zero-shot and few-shot extractive question answering. When no training examples
are available, exact-extract significantly outperforms greedy decoding.
However, greedy decoding quickly converges towards the performance of
exact-extract with the introduction of a few training examples, becoming more
extractive and increasingly likelier to generate the most probable span as the
training set grows. We also show that self-supervised training can bias the
model towards extractive behavior, increasing performance in the zero-shot
setting without resorting to annotated examples. Overall, our results suggest
that pretrained language models are so good at adapting to extractive question
answering, that it is often enough to fine-tune on a small training set for the
greedy algorithm to emulate the optimal decoding strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridger: Toward Bursting Scientific Filter Bubbles and Boosting Innovation via Novel Author Discovery. (arXiv:2108.05669v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portenoy_J/0/1/0/all/0/1">Jason Portenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radensky_M/0/1/0/all/0/1">Marissa Radensky</a>, <a href="http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1">Jevin West</a>, <a href="http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1">Eric Horvitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05669">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific silos can hinder innovation. These information &quot;filter bubbles&quot;
and the growing challenge of information overload limit awareness across the
literature, making it difficult to keep track of even narrow areas of interest,
let alone discover new ones. Algorithmic curation and recommendation, which
often prioritize relevance, can further reinforce these bubbles. In response,
we describe Bridger, a system for facilitating discovery of scholars and their
work, to explore design tradeoffs among relevant and novel recommendations. We
construct a faceted representation of authors using information extracted from
their papers and inferred personas. We explore approaches both for recommending
new content and for displaying it in a manner that helps researchers to
understand the work of authors who they are unfamiliar with. In studies with
computer science researchers, our approach substantially improves users&#x27;
abilities to do so. We develop an approach that locates commonalities and
contrasts between scientists---retrieving partially similar authors, rather
than aiming for strict similarity. We find this approach helps users discover
authors useful for generating novel research ideas of relevance to their work,
at a higher rate than a state-of-art neural model. Our analysis reveals that
Bridger connects authors who have different citation profiles, publish in
different venues, and are more distant in social co-authorship networks,
raising the prospect of bridging diverse communities and facilitating
discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Relevance Ranking under the Pre-training and Fine-tuning Paradigm. (arXiv:2108.05652v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Lin Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">XiuQiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05652">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pre-trained language models such as BERT have been applied to
document ranking for information retrieval, which first pre-train a general
language model on an unlabeled large corpus and then conduct ranking-specific
fine-tuning on expert-labeled relevance datasets. Ideally, an IR system would
model relevance from a user-system dualism: the user&#x27;s view and the system&#x27;s
view. User&#x27;s view judges the relevance based on the activities of &quot;real users&quot;
while the system&#x27;s view focuses on the relevance signals from the system side,
e.g., from the experts or algorithms, etc. Inspired by the user-system
relevance views and the success of pre-trained language models, in this paper
we propose a novel ranking framework called Pre-Rank that takes both user&#x27;s
view and system&#x27;s view into consideration, under the pre-training and
fine-tuning paradigm. Specifically, to model the user&#x27;s view of relevance,
Pre-Rank pre-trains the initial query-document representations based on
large-scale user activities data such as the click log. To model the system&#x27;s
view of relevance, Pre-Rank further fine-tunes the model on expert-labeled
relevance data. More importantly, the pre-trained representations, are
fine-tuned together with handcrafted learning-to-rank features under a wide and
deep network architecture. In this way, Pre-Rank can model the relevance by
incorporating the relevant knowledge and signals from both real search users
and the IR experts. To verify the effectiveness of Pre-Rank, we showed two
implementations by using BERT and SetRank as the underlying ranking model,
respectively. Experimental results base on three publicly available benchmarks
showed that in both of the implementations, Pre-Rank can respectively
outperform the underlying ranking models and achieved state-of-the-art
performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Diverse Descriptions from Semantic Graphs. (arXiv:2108.05659v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiuzhou Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_D/0/1/0/all/0/1">Daniel Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1">Trevor Cohn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05659">
                                    <div class="article-summary-box-inner">
                                        <span>Text generation from semantic graphs is traditionally performed with
deterministic methods, which generate a unique description given an input
graph. However, the generation problem admits a range of acceptable textual
outputs, exhibiting lexical, syntactic and semantic variation. To address this
disconnect, we present two main contributions. First, we propose a stochastic
graph-to-text model, incorporating a latent variable in an encoder-decoder
model, and its use in an ensemble. Second, to assess the diversity of the
generated sentences, we propose a new automatic evaluation metric which jointly
evaluates output diversity and quality in a multi-reference setting. We
evaluate the models on WebNLG datasets in English and Russian, and show an
ensemble of stochastic models produces diverse sets of generated sentences,
while retaining similar quality to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval. (arXiv:2108.05540v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Luyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1">Jamie Callan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05540">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research demonstrates the effectiveness of using fine-tuned language
models~(LM) for dense retrieval. However, dense retrievers are hard to train,
typically requiring heavily engineered fine-tuning pipelines to realize their
full potential. In this paper, we identify and address two underlying problems
of dense retrievers: i)~fragility to training data noise and ii)~requiring
large batches to robustly learn the embedding space. We use the recently
proposed Condenser pre-training architecture, which learns to condense
information into the dense vector through LM pre-training. On top of it, we
propose coCondenser, which adds an unsupervised corpus-level contrastive loss
to warm up the passage embedding space. Retrieval experiments on MS-MARCO,
Natural Question, and Trivia QA datasets show that coCondenser removes the need
for heavy data engineering such as augmentation, synthesis, or filtering, as
well as the need for large batch training. It shows comparable performance to
RocketQA, a state-of-the-art, heavily engineered system, using simple small
batch fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing. (arXiv:2108.05542v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalyan_K/0/1/0/all/0/1">Katikapalli Subramanyam Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajasekharan_A/0/1/0/all/0/1">Ajit Rajasekharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangeetha_S/0/1/0/all/0/1">Sivanesan Sangeetha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05542">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based pretrained language models (T-PTLMs) have achieved great
success in almost every NLP task. The evolution of these models started with
GPT and BERT. These models are built on the top of transformers,
self-supervised learning and transfer learning. Transformed-based PTLMs learn
universal language representations from large volumes of text data using
self-supervised learning and transfer this knowledge to downstream tasks. These
models provide good background knowledge to downstream tasks which avoids
training of downstream models from scratch. In this comprehensive survey paper,
we initially give a brief overview of self-supervised learning. Next, we
explain various core concepts like pretraining, pretraining methods,
pretraining tasks, embeddings and downstream adaptation methods. Next, we
present a new taxonomy of T-PTLMs and then give brief overview of various
benchmarks including both intrinsic and extrinsic. We present a summary of
various useful libraries to work with T-PTLMs. Finally, we highlight some of
the future research directions which will further improve these models. We
strongly believe that this comprehensive survey paper will serve as a good
reference to learn the core concepts as well as to stay updated with the recent
happenings in T-PTLMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kicktionary-LOME: A Domain-Specific Multilingual Frame Semantic Parsing Model for Football Language. (arXiv:2108.05575v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Minnema_G/0/1/0/all/0/1">Gosse Minnema</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05575">
                                    <div class="article-summary-box-inner">
                                        <span>This technical report introduces an adapted version of the LOME frame
semantic parsing model (Xia et al., EACL 2021) which is capable of
automatically annotating texts according to the &quot;Kicktionary&quot; domain-specific
framenet resource. Several methods for training a model even with limited
available training data are proposed. While there are some challenges for
evaluation related to the nature of the available annotations, preliminary
results are very promising, with the best model reaching F1-scores of 0.83
(frame prediction) and 0.81 (semantic role prediction).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generation Challenges: Results of the Accuracy Evaluation Shared Task. (arXiv:2108.05644v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomson_C/0/1/0/all/0/1">Craig Thomson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reiter_E/0/1/0/all/0/1">Ehud Reiter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05644">
                                    <div class="article-summary-box-inner">
                                        <span>The Shared Task on Evaluating Accuracy focused on techniques (both manual and
automatic) for evaluating the factual accuracy of texts produced by neural NLG
systems, in a sports-reporting domain. Four teams submitted evaluation
techniques for this task, using very different approaches and techniques. The
best-performing submissions did encouragingly well at this difficult task.
However, all automatic submissions struggled to detect factual errors which are
semantically or pragmatically complex (for example, based on incorrect
computation or inference).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethereum Data Structures. (arXiv:2108.05513v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jezek_K/0/1/0/all/0/1">Kamil Jezek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05513">
                                    <div class="article-summary-box-inner">
                                        <span>Ethereum platform operates with rich spectrum of data structures and hashing
and coding functions. The main source describing them is the Yellow paper,
complemented by a lot of informal blogs. These sources are somehow limited. In
particular, the Yellow paper does not ideally balance brevity and detail, in
some parts it is very detail, while too shallow elsewhere. The blogs on the
other hand are often too vague and in certain cases contain incorrect
information. As a solution, we provide this document, which summarises data
structures used in Ethereum. The goal is to provide sufficient detail while
keeping brevity. Sufficiently detailed formal view is enriched with examples to
extend on clarity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacks against Ranking Algorithms with Text Embeddings: a Case Study on Recruitment Algorithms. (arXiv:2108.05490v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samadi_A/0/1/0/all/0/1">Anahita Samadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1">Debapriya Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nilizadeh_S/0/1/0/all/0/1">Shirin Nilizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05490">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, some studies have shown that text classification tasks are
vulnerable to poisoning and evasion attacks. However, little work has
investigated attacks against decision making algorithms that use text
embeddings, and their output is a ranking. In this paper, we focus on ranking
algorithms for recruitment process, that employ text embeddings for ranking
applicants resumes when compared to a job description. We demonstrate both
white box and black box attacks that identify text items, that based on their
location in embedding space, have significant contribution in increasing the
similarity score between a resume and a job description. The adversary then
uses these text items to improve the ranking of their resume among others. We
tested recruitment algorithms that use the similarity scores obtained from
Universal Sentence Encoder (USE) and Term Frequency Inverse Document Frequency
(TF IDF) vectors. Our results show that in both adversarial settings, on
average the attacker is successful. We also found that attacks against TF IDF
is more successful compared to USE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes. (arXiv:2108.05615v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1">Dongki Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jaehoon Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yonghan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Deokhwa Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Changick Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1">Dinesh Manocha</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Donghwan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05615">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach for estimating depth from a monocular camera as
it moves through complex and crowded indoor environments, e.g., a department
store or a metro station. Our approach predicts absolute scale depth maps over
the entire scene consisting of a static background and multiple moving people,
by training on dynamic scenes. Since it is difficult to collect dense depth
maps from crowded indoor environments, we design our training framework without
requiring depths produced from depth sensing devices. Our network leverages RGB
images and sparse depth maps generated from traditional 3D reconstruction
methods to estimate dense depth maps. We use two constraints to handle depth
for non-rigidly moving people without tracking their motion explicitly. We
demonstrate that our approach offers consistent improvements over recent depth
estimation methods on the NAVERLABS dataset, which includes complex and crowded
scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep PET/CT fusion with Dempster-Shafer theory for lymphoma segmentation. (arXiv:2108.05422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Ling Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Denoeux_T/0/1/0/all/0/1">Thierry Denoeux</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonnelet_D/0/1/0/all/0/1">David Tonnelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Decazes_P/0/1/0/all/0/1">Pierre Decazes</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_S/0/1/0/all/0/1">Su Ruan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05422">
                                    <div class="article-summary-box-inner">
                                        <span>Lymphoma detection and segmentation from whole-body Positron Emission
Tomography/Computed Tomography (PET/CT) volumes are crucial for surgical
indication and radiotherapy. Designing automatic segmentation methods capable
of effectively exploiting the information from PET and CT as well as resolving
their uncertainty remain a challenge. In this paper, we propose an lymphoma
segmentation model using an UNet with an evidential PET/CT fusion layer.
Single-modality volumes are trained separately to get initial segmentation maps
and an evidential fusion layer is proposed to fuse the two pieces of evidence
using Dempster-Shafer theory (DST). Moreover, a multi-task loss function is
proposed: in addition to the use of the Dice loss for PET and CT segmentation,
a loss function based on the concordance between the two segmentation is added
to constrain the final segmentation. We evaluate our proposal on a database of
polycentric PET/CT volumes of patients treated for lymphoma, delineated by the
experts. Our method get accurate segmentation results with Dice score of 0.726,
without any user interaction. Quantitative results show that our method is
superior to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search From Task Similarity Measure. (arXiv:2103.00241v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1">Cat P. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltani_M/0/1/0/all/0/1">Mohammadreza Soltani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravier_R/0/1/0/all/0/1">Robert Ravier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00241">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a neural architecture search framework based on a
similarity measure between the baseline tasks and the incoming target task. We
first define the notion of task similarity based on the log-determinant of the
Fisher Information Matrices. Next, we compute the task similarity from each of
the baseline tasks to the incoming target task. By utilizing the relation
between a target and a set of learned baseline tasks, the search space of
architectures for the incoming target task can be significantly reduced, making
the discovery of the best candidates in the set of possible architectures
tractable and efficient, in terms of GPU days. This method eliminates the
requirement for training the networks from scratch for the incoming target task
as well as introducing the bias in the initialization of the search space from
the human domain. Experimental results with 8 classification tasks in MNIST and
CIFAR-10 datasets illustrate the efficacy of our proposed approach and its
competitiveness with other state-of-art methods in terms of the classification
performance, the number of parameters, and the search time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Image Semantic Segmentation. (arXiv:2107.13978v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chang-Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Peng-Tao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_F/0/1/0/all/0/1">Feng Mao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13978">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation models trained on public datasets have achieved great
success in recent years. However, these models didn&#x27;t consider the
personalization issue of segmentation though it is important in practice. In
this paper, we address the problem of personalized image segmentation. The
objective is to generate more accurate segmentation results on unlabeled
personalized images by investigating the data&#x27;s personalized traits. To open up
future research in this area, we collect a large dataset containing various
users&#x27; personalized images called PIS (Personalized Image Semantic
Segmentation). We also survey some recent researches related to this problem
and report their performance on our dataset. Furthermore, by observing the
correlation among a user&#x27;s personalized images, we propose a baseline method
that incorporates the inter-image context when segmenting certain images.
Extensive experiments show that our method outperforms the existing methods on
the proposed dataset. The code and the PIS dataset will be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations. (arXiv:2108.05851v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zike Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuxin Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xuesong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1">Ping Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongbin Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05851">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances have enabled a single neural network to serve as an implicit
scene representation, establishing the mapping function between spatial
coordinates and scene properties. In this paper, we make a further step towards
continual learning of the implicit scene representation directly from
sequential observations, namely Continual Neural Mapping. The proposed problem
setting bridges the gap between batch-trained implicit neural representations
and commonly used streaming data in robotics and vision communities. We
introduce an experience replay approach to tackle an exemplary task of
continual neural mapping: approximating a continuous signed distance function
(SDF) from sequential depth images as a scene geometry representation. We show
for the first time that a single network can represent scene geometry over time
continually without catastrophic forgetting, while achieving promising
trade-offs between accuracy and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Oriented R-CNN for Object Detection. (arXiv:2108.05699v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xingxing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Gong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiabao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xiwen Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junwei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05699">
                                    <div class="article-summary-box-inner">
                                        <span>Current state-of-the-art two-stage detectors generate oriented proposals
through time-consuming schemes. This diminishes the detectors&#x27; speed, thereby
becoming the computational bottleneck in advanced oriented object detection
systems. This work proposes an effective and simple oriented object detection
framework, termed Oriented R-CNN, which is a general two-stage oriented
detector with promising accuracy and efficiency. To be specific, in the first
stage, we propose an oriented Region Proposal Network (oriented RPN) that
directly generates high-quality oriented proposals in a nearly cost-free
manner. The second stage is oriented R-CNN head for refining oriented Regions
of Interest (oriented RoIs) and recognizing them. Without tricks, oriented
R-CNN with ResNet50 achieves state-of-the-art detection accuracy on two
commonly-used datasets for oriented object detection including DOTA (75.87%
mAP) and HRSC2016 (96.50% mAP), while having a speed of 15.1 FPS with the image
size of 1024$\times$1024 on a single RTX 2080Ti. We hope our work could inspire
rethinking the design of oriented detectors and serve as a baseline for
oriented object detection. Code is available at
https://github.com/jbwang1997/OBBDetection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing the State of the Art: A Critical Look at Visual Representation Evaluation. (arXiv:1912.00215v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1">Cinjon Resnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zeping Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00215">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised research improved greatly over the past half decade, with
much of the growth being driven by objectives that are hard to quantitatively
compare. These techniques include colorization, cyclical consistency, and
noise-contrastive estimation from image patches. Consequently, the field has
settled on a handful of measurements that depend on linear probes to adjudicate
which approaches are the best. Our first contribution is to show that this test
is insufficient and that models which perform poorly (strongly) on linear
classification can perform strongly (weakly) on more involved tasks like
temporal activity localization. Our second contribution is to analyze the
capabilities of five different representations. And our third contribution is a
much needed new dataset for temporal activity localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiview Detection with Shadow Transformer (and View-Coherent Data Augmentation). (arXiv:2108.05888v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yunzhong Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05888">
                                    <div class="article-summary-box-inner">
                                        <span>Multiview detection incorporates multiple camera views to deal with
occlusions, and its central problem is multiview aggregation. Given feature map
projections from multiple views onto a common ground plane, the
state-of-the-art method addresses this problem via convolution, which applies
the same calculation regardless of object locations. However, such
translation-invariant behaviors might not be the best choice, as object
features undergo various projection distortions according to their positions
and cameras. In this paper, we propose a novel multiview detector, MVDeTr, that
adopts a newly introduced shadow transformer to aggregate multiview
information. Unlike convolutions, shadow transformer attends differently at
different positions and cameras to deal with various shadow-like distortions.
We propose an effective training scheme that includes a new view-coherent data
augmentation method, which applies random augmentations while maintaining
multiview consistency. On two multiview detection benchmarks, we report new
state-of-the-art accuracy with the proposed system. Code is available at
https://github.com/hou-yz/MVDeTr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascade Bagging for Accuracy Prediction with Few Training Samples. (arXiv:2108.05613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xubo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheyang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05613">
                                    <div class="article-summary-box-inner">
                                        <span>Accuracy predictor is trained to predict the validation accuracy of an
network from its architecture encoding. It can effectively assist in designing
networks and improving Neural Architecture Search(NAS) efficiency. However, a
high-performance predictor depends on adequate trainning samples, which
requires unaffordable computation overhead. To alleviate this problem, we
propose a novel framework to train an accuracy predictor under few training
samples. The framework consists ofdata augmentation methods and an ensemble
learning algorithm. The data augmentation methods calibrate weak labels and
inject noise to feature space. The ensemble learning algorithm, termed cascade
bagging, trains two-level models by sampling data and features. In the end, the
advantages of above methods are proved in the Performance Prediciton Track of
CVPR2021 1st Lightweight NAS Challenge. Our code is made public at:
https://github.com/dlongry/Solutionto-CVPR2021-NAS-Track2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TF-Blender: Temporal Feature Blender for Video Object Detection. (arXiv:2108.05821v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yiming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1">Liqi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zhiwen Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dongfang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05821">
                                    <div class="article-summary-box-inner">
                                        <span>Video objection detection is a challenging task because isolated video frames
may encounter appearance deterioration, which introduces great confusion for
detection. One of the popular solutions is to exploit the temporal information
and enhance per-frame representation through aggregating features from
neighboring frames. Despite achieving improvements in detection, existing
methods focus on the selection of higher-level video frames for aggregation
rather than modeling lower-level temporal relations to increase the feature
representation. To address this limitation, we propose a novel solution named
TF-Blender,which includes three modules: 1) Temporal relation mod-els the
relations between the current frame and its neighboring frames to preserve
spatial information. 2). Feature adjustment enriches the representation of
every neigh-boring feature map; 3) Feature blender combines outputs from the
first two modules and produces stronger features for the later detection tasks.
For its simplicity, TF-Blender can be effortlessly plugged into any detection
network to improve detection behavior. Extensive evaluations on ImageNet VID
and YouTube-VIS benchmarks indicate the performance guarantees of using
TF-Blender on recent state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resetting the baseline: CT-based COVID-19 diagnosis with Deep Transfer Learning is not as accurate as widely thought. (arXiv:2108.05649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altaf_F/0/1/0/all/0/1">Fouzia Altaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Syed M.S. Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is gaining instant popularity in computer aided diagnosis of
COVID-19. Due to the high sensitivity of Computed Tomography (CT) to this
disease, CT-based COVID-19 detection with visual models is currently at the
forefront of medical imaging research. Outcomes published in this direction are
frequently claiming highly accurate detection under deep transfer learning.
This is leading medical technologists to believe that deep transfer learning is
the mainstream solution for the problem. However, our critical analysis of the
literature reveals an alarming performance disparity between different
published results. Hence, we conduct a systematic thorough investigation to
analyze the effectiveness of deep transfer learning for COVID-19 detection with
CT images. Exploring 14 state-of-the-art visual models with over 200 model
training sessions, we conclusively establish that the published literature is
frequently overestimating transfer learning performance for the problem, even
in the prestigious scientific sources. The roots of overestimation trace back
to inappropriate data curation. We also provide case studies that consider more
realistic scenarios, and establish transparent baselines for the problem. We
hope that our reproducible investigation will help in curbing hype-driven
claims for the critical problem of COVID-19 diagnosis, and pave the way for a
more transparent performance evaluation of techniques for CT-based COVID-19
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D-SiamRPN: An End-to-End Learning Method for Real-Time 3D Single Object Tracking Using Raw Point Cloud. (arXiv:2108.05630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sifan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yubo Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05630">
                                    <div class="article-summary-box-inner">
                                        <span>3D single object tracking is a key issue for autonomous following robot,
where the robot should robustly track and accurately localize the target for
efficient following. In this paper, we propose a 3D tracking method called
3D-SiamRPN Network to track a single target object by using raw 3D point cloud
data. The proposed network consists of two subnetworks. The first subnetwork is
feature embedding subnetwork which is used for point cloud feature extraction
and fusion. In this subnetwork, we first use PointNet++ to extract features of
point cloud from template and search branches. Then, to fuse the information of
features in the two branches and obtain their similarity, we propose two cross
correlation modules, named Pointcloud-wise and Point-wise respectively. The
second subnetwork is region proposal network(RPN), which is used to get the
final 3D bounding box of the target object based on the fusion feature from
cross correlation modules. In this subnetwork, we utilize the regression and
classification branches of a region proposal subnetwork to obtain proposals and
scores, thus get the final 3D bounding box of the target object. Experimental
results on KITTI dataset show that our method has a competitive performance in
both Success and Precision compared to the state-of-the-art methods, and could
run in real-time at 20.8 FPS. Additionally, experimental results on H3D dataset
demonstrate that our method also has good generalization ability and could
achieve good tracking performance in a new scene without re-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-aware Synthesis of High-resolution Diffusion from Structural Imaging. (arXiv:2108.04135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anctil_Robitaille_B/0/1/0/all/0/1">Benoit Anctil-Robitaille</a>, <a href="http://arxiv.org/find/cs/1/au:+Theberge_A/0/1/0/all/0/1">Antoine Th&#xe9;berge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1">Maxime Descoteaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Christian Desrosiers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombaert_H/0/1/0/all/0/1">Herv&#xe9; Lombaert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04135">
                                    <div class="article-summary-box-inner">
                                        <span>The physical and clinical constraints surrounding diffusion-weighted imaging
(DWI) often limit the spatial resolution of the produced images to voxels up to
8 times larger than those of T1w images. Thus, the detailed information
contained in T1w imagescould help in the synthesis of diffusion images in
higher resolution. However, the non-Euclidean nature of diffusion imaging
hinders current deep generative models from synthesizing physically plausible
images. In this work, we propose the first Riemannian network architecture for
the direct generation of diffusion tensors (DT) and diffusion orientation
distribution functions (dODFs) from high-resolution T1w images. Our integration
of the Log-Euclidean Metric into a learning objective guarantees, unlike
standard Euclidean networks, the mathematically-valid synthesis of diffusion.
Furthermore, our approach improves the fractional anisotropy mean squared error
(FA MSE) between the synthesized diffusion and the ground-truth by more than
23% and the cosine similarity between principal directions by almost 5% when
compared to our baselines. We validate our generated diffusion by comparing the
resulting tractograms to our expected real data. We observe similar fiber
bundles with streamlines having less than 3% difference in length, less than 1%
difference in volume, and a visually close shape. While our method is able to
generate high-resolution diffusion images from structural inputs in less than
15 seconds, we acknowledge and discuss the limits of diffusion inference solely
relying on T1w images. Our results nonetheless suggest a relationship between
the high-level geometry of the brain and the overall white matter architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Vision Transformer. (arXiv:2012.12556v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">An Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaohui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiman Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12556">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer, first applied to the field of natural language processing, is a
type of deep neural network mainly based on the self-attention mechanism.
Thanks to its strong representation capabilities, researchers are looking at
ways to apply transformer to computer vision tasks. In a variety of visual
benchmarks, transformer-based models perform similar to or better than other
types of networks such as convolutional and recurrent networks. Given its high
performance and less need for vision-specific inductive bias, transformer is
receiving more and more attention from the computer vision community. In this
paper, we review these vision transformer models by categorizing them in
different tasks and analyzing their advantages and disadvantages. The main
categories we explore include the backbone network, high/mid-level vision,
low-level vision, and video processing. We also include efficient transformer
methods for pushing transformer into real device-based applications.
Furthermore, we also take a brief look at the self-attention mechanism in
computer vision, as it is the base component in transformer. Toward the end of
this paper, we discuss the challenges and provide several further research
directions for vision transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction. (arXiv:2108.02110v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhao_M/0/1/0/all/0/1">Minyi Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1">Shuigeng Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02110">
                                    <div class="article-summary-box-inner">
                                        <span>A number of deep learning based algorithms have been proposed to recover
high-quality videos from low-quality compressed ones. Among them, some restore
the missing details of each frame via exploring the spatiotemporal information
of neighboring frames. However, these methods usually suffer from a narrow
temporal scope, thus may miss some useful details from some frames outside the
neighboring ones. In this paper, to boost artifact removal, on the one hand, we
propose a Recursive Fusion (RF) module to model the temporal dependency within
a long temporal range. Specifically, RF utilizes both the current reference
frames and the preceding hidden state to conduct better spatiotemporal
compensation. On the other hand, we design an efficient and effective
Deformable Spatiotemporal Attention (DSTA) module such that the model can pay
more effort on restoring the artifact-rich areas like the boundary area of a
moving object. Extensive experiments show that our method outperforms the
existing ones on the MFQE 2.0 dataset in terms of both fidelity and perceptual
effect. Code is available at https://github.com/zhaominyiz/RFDA-PyTorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification. (arXiv:2101.08467v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chaoyou Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yibo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Hailin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ran He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08467">
                                    <div class="article-summary-box-inner">
                                        <span>Visible-Infrared person re-identification (VI-ReID) aims to match
cross-modality pedestrian images, breaking through the limitation of
single-modality person ReID in dark environment. In order to mitigate the
impact of large modality discrepancy, existing works manually design various
two-stream architectures to separately learn modality-specific and
modality-sharable representations. Such a manual design routine, however,
highly depends on massive experiments and empirical practice, which is time
consuming and labor intensive. In this paper, we systematically study the
manually designed architectures, and identify that appropriately separating
Batch Normalization (BN) layers is the key to bring a great boost towards
cross-modality matching. Based on this observation, the essential objective is
to find the optimal separation scheme for each BN layer. To this end, we
propose a novel method, named Cross-Modality Neural Architecture Search
(CM-NAS). It consists of a BN-oriented search space in which the standard
optimization can be fulfilled subject to the cross-modality task. Equipped with
the searched architecture, our method outperforms state-of-the-art counterparts
in both two benchmarks, improving the Rank-1/mAP by 6.70%/6.13% on SYSU-MM01
and by 12.17%/11.23% on RegDB. Code is released at
https://github.com/JDAI-CV/CM-NAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Roll-off Points Variations: Exploring Useful Information in Feature Maps by Its Variations. (arXiv:2102.00369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yunkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yuyang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guozheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peiyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_W/0/1/0/all/0/1">Wenjing Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00369">
                                    <div class="article-summary-box-inner">
                                        <span>Useful information (UI) is an elusive concept in neural networks. A
quantitative measurement of UI is absent, despite the variations of UI can be
recognized by prior knowledge. The communication bandwidth of feature maps
decreases after downscaling operations, but UI flows smoothly after training
due to lower Nyquist frequency. Inspired by the low-Nyqusit-frequency nature of
UI, we propose the use of spectral roll-off points (SROPs) to estimate UI on
variations. The computation of an SROP is extended from a 1-D signal to a 2-D
image by the required rotation invariance in image classification tasks. SROP
statistics across feature maps are implemented as layer-wise useful information
estimates. We design sanity checks to explore SROP variations when UI
variations are produced by variations in model input, model architecture and
training stages. The variations of SROP is synchronizes with UI variations in
various randomized and sufficiently trained model structures. Therefore, SROP
variations is an accurate and convenient sign of UI variations, which promotes
the explainability of data representations with respect to frequency-domain
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Mitigation of Face Recognition Models Through Calibration. (arXiv:2106.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salvador_T/0/1/0/all/0/1">Tiago Salvador</a>, <a href="http://arxiv.org/find/cs/1/au:+Cairns_S/0/1/0/all/0/1">Stephanie Cairns</a>, <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marshall_N/0/1/0/all/0/1">Noah Marshall</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition models suffer from bias: for example, the probability of a
false positive (incorrect face match) strongly depends on sensitive attributes
like ethnicity. As a result, these models may disproportionately and negatively
impact minority groups when used in law enforcement. In this work, we introduce
the Bias Mitigation Calibration (BMC) method, which (i) increases model
accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated
probabilities, (iii) significantly reduces the gap in the false positive rates,
and (iv) does not require knowledge of the sensitive attribute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v11 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10762">
                                    <div class="article-summary-box-inner">
                                        <span>Random field and random cluster theory are used to describe certain
mathematical results concerning the probability distribution of image pixel
intensities characterized as generic $2D$ integer arrays. The size of the
smallest bounded region within an image is estimated for segmenting an image,
from which, the equilibrium distribution of intensities can be recovered. From
the estimated bounded regions, properties of the sub-optimal and equilibrium
distributions of intensities are derived, which leads to an image compression
methodology whereby only slightly more than half of all pixels are required for
a worst-case reconstruction of the original image. A custom deep belief network
and heuristic allows for the unsupervised segmentation, detection and
localization of objects in an image. An example illustrates the mathematical
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EV-VGCNN: A Voxel Graph CNN for Event-based Object Classification. (arXiv:2106.00216v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yongjian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huiying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Youfu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00216">
                                    <div class="article-summary-box-inner">
                                        <span>Event cameras report sparse intensity changes and hold noticeable advantages
of low power consumption, high dynamic range, and high response speed for
visual perception and understanding on portable devices. Event-based learning
methods have recently achieved massive success on object recognition by
integrating events into dense frame-based representations to apply traditional
2D learning algorithms. However, these approaches introduce much redundant
information during the sparse-to-dense conversion and necessitate models with
heavy-weight and large capacities, limiting the potential of event cameras on
real-life applications. To address the core problem of balancing accuracy and
model complexity for event-based classification models, we (1) construct graph
representations for event data to utilize their sparsity nature better and
design a lightweight end-to-end graph neural network (EV-VGCNN) for
classification; (2) use voxel-wise vertices rather than traditional point-wise
methods to incorporate the information from more points; (3) introduce a
multi-scale feature relational layer (MFRL) to extract semantic and motion cues
from each vertex adaptively concerning its distances to neighbors.
Comprehensive experiments show that our approach advances state-of-the-art
classification accuracy while achieving nearly 20 times parameter reduction
(merely 0.84M parameters).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation. (arXiv:2107.11264v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Sanghun Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungsoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gwak_D/0/1/0/all/0/1">Daehoon Gwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Sungha Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11264">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying unexpected objects on roads in semantic segmentation (e.g.,
identifying dogs on roads) is crucial in safety-critical applications. Existing
approaches use images of unexpected objects from external datasets or require
additional training (e.g., retraining segmentation networks or training an
extra network), which necessitate a non-trivial amount of labor intensity or
lengthy inference time. One possible alternative is to use prediction scores of
a pre-trained network such as the max logits (i.e., maximum values among
classes before the final softmax layer) for detecting such objects. However,
the distribution of max logits of each predicted class is significantly
different from each other, which degrades the performance of identifying
unexpected objects in urban-scene segmentation. To address this issue, we
propose a simple yet effective approach that standardizes the max logits in
order to align the different distributions and reflect the relative meanings of
max logits within each predicted class. Moreover, we consider the local regions
from two different perspectives based on the intuition that neighboring pixels
share similar semantic information. In contrast to previous approaches, our
method does not utilize any external datasets or require additional training,
which makes our method widely applicable to existing pre-trained segmentation
models. Such a straightforward approach achieves a new state-of-the-art
performance on the publicly available Fishyscapes Lost &amp; Found leaderboard with
a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransVG: End-to-End Visual Grounding with Transformers. (arXiv:2104.08541v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiajun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhengyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08541">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a neat yet effective transformer-based framework
for visual grounding, namely TransVG, to address the task of grounding a
language query to the corresponding region onto an image. The state-of-the-art
methods, including two-stage or one-stage ones, rely on a complex module with
manually-designed mechanisms to perform the query reasoning and multi-modal
fusion. However, the involvement of certain mechanisms in fusion module design,
such as query decomposition and image scene graph, makes the models easily
overfit to datasets with specific scenarios, and limits the plenitudinous
interaction between the visual-linguistic context. To avoid this caveat, we
propose to establish the multi-modal correspondence by leveraging transformers,
and empirically show that the complex fusion modules (\eg, modular attention
network, dynamic graph, and multi-modal tree) can be replaced by a simple stack
of transformer encoder layers with higher performance. Moreover, we
re-formulate the visual grounding as a direct coordinates regression problem
and avoid making predictions out of a set of candidates (\emph{i.e.}, region
proposals or anchor boxes). Extensive experiments are conducted on five widely
used datasets, and a series of state-of-the-art records are set by our TransVG.
We build the benchmark of transformer-based visual grounding framework and make
the code available at \url{https://github.com/djiajunustc/TransVG}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivAug: Plug-in Automated Data Augmentation with Explicit Diversity Maximization. (arXiv:2103.14545v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zirui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Haifeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Ting-Hsiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaixiong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14545">
                                    <div class="article-summary-box-inner">
                                        <span>Human-designed data augmentation strategies have been replaced by
automatically learned augmentation policy in the past two years. Specifically,
recent work has empirically shown that the superior performance of the
automated data augmentation methods stems from increasing the diversity of
augmented data \cite{autoaug, randaug}. However, two factors regarding the
diversity of augmented data are still missing: 1) the explicit definition (and
thus measurement) of diversity and 2) the quantifiable relationship between
diversity and its regularization effects. To bridge this gap, we propose a
diversity measure called Variance Diversity and theoretically show that the
regularization effect of data augmentation is promised by Variance Diversity.
We validate in experiments that the relative gain from automated data
augmentation in test accuracy is highly correlated to Variance Diversity. An
unsupervised sampling-based framework, \textbf{DivAug}, is designed to directly
maximize Variance Diversity and hence strengthen the regularization effect.
Without requiring a separate search process, the performance gain from DivAug
is comparable with the state-of-the-art method with better efficiency.
Moreover, under the semi-supervised setting, our framework can further improve
the performance of semi-supervised learning algorithms compared to RandAugment,
making it highly applicable to real-world problems, where labeled data is
scarce. The code is available at
\texttt{\url{https://github.com/warai-0toko/DivAug}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamical Pose Estimation. (arXiv:2103.06182v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Heng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Doran_C/0/1/0/all/0/1">Chris Doran</a>, <a href="http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1">Jean-Jacques Slotine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06182">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of aligning two sets of 3D geometric primitives given
known correspondences. Our first contribution is to show that this primitive
alignment framework unifies five perception problems including point cloud
registration, primitive (mesh) registration, category-level 3D registration,
absolution pose estimation (APE), and category-level APE. Our second
contribution is to propose DynAMical Pose estimation (DAMP), the first general
and practical algorithm to solve primitive alignment problem by simulating
rigid body dynamics arising from virtual springs and damping, where the springs
span the shortest distances between corresponding primitives. We evaluate DAMP
in simulated and real datasets across all five problems, and demonstrate (i)
DAMP always converges to the globally optimal solution in the first three
problems with 3D-3D correspondences; (ii) although DAMP sometimes converges to
suboptimal solutions in the last two problems with 2D-3D correspondences, using
a scheme for escaping local minima, DAMP always succeeds. Our third
contribution is to demystify the surprising empirical performance of DAMP and
formally prove a global convergence result in the case of point cloud
registration by charactering local stability of the equilibrium points of the
underlying dynamical system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MicroNet: Improving Image Recognition with Extremely Low FLOPs. (arXiv:2108.05894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1">Nuno Vasconcelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05894">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims at addressing the problem of substantial performance
degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet
classification). We found that two factors, sparse connectivity and dynamic
activation function, are effective to improve the accuracy. The former avoids
the significant reduction of network width, while the latter mitigates the
detriment of reduction in network depth. Technically, we propose
micro-factorized convolution, which factorizes a convolution matrix into low
rank matrices, to integrate sparse connectivity into convolution. We also
present a new dynamic activation function, named Dynamic Shift Max, to improve
the non-linearity via maxing out multiple dynamic fusions between an input
feature map and its circular channel shift. Building upon these two new
operators, we arrive at a family of networks, named MicroNet, that achieves
significant performance gains over the state of the art in the low FLOP regime.
For instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\% top-1
accuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\%. Source
code is at
\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Concentration for Domain Adaptation. (arXiv:2108.05720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Mixue Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1">Fangrui Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chi Harold Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05720">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation (DA) paves the way for label annotation and dataset bias
issues by the knowledge transfer from a label-rich source domain to a related
but unlabeled target domain. A mainstream of DA methods is to align the feature
distributions of the two domains. However, the majority of them focus on the
entire image features where irrelevant semantic information, e.g., the messy
background, is inevitably embedded. Enforcing feature alignments in such case
will negatively influence the correct matching of objects and consequently lead
to the semantically negative transfer due to the confusion of irrelevant
semantics. To tackle this issue, we propose Semantic Concentration for Domain
Adaptation (SCDA), which encourages the model to concentrate on the most
principal features via the pair-wise adversarial alignment of prediction
distributions. Specifically, we train the classifier to class-wisely maximize
the prediction distribution divergence of each sample pair, which enables the
model to find the region with large differences among the same class of
samples. Meanwhile, the feature extractor attempts to minimize that
discrepancy, which suppresses the features of dissimilar regions among the same
class of samples and accentuates the features of principal parts. As a general
method, SCDA can be easily integrated into various DA methods as a regularizer
to further boost their performance. Extensive experiments on the cross-domain
benchmarks show the efficacy of SCDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">m-RevNet: Deep Reversible Neural Networks with Momentum. (arXiv:2108.05862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shang-Hua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05862">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the connections between deep residual networks and
first-order Ordinary Differential Equations (ODEs) have been disclosed. In this
work, we further bridge the deep neural architecture design with the
second-order ODEs and propose a novel reversible neural network, termed as
m-RevNet, that is characterized by inserting momentum update to residual
blocks. The reversible property allows us to perform backward pass without
access to activation values of the forward pass, greatly relieving the storage
burden during training. Furthermore, the theoretical foundation based on
second-order ODEs grants m-RevNet with stronger representational power than
vanilla residual networks, which potentially explains its performance gains.
For certain learning scenarios, we analytically and empirically reveal that our
m-RevNet succeeds while standard ResNet fails. Comprehensive experiments on
various image classification and semantic segmentation benchmarks demonstrate
the superiority of our m-RevNet over ResNet, concerning both memory efficiency
and recognition performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Test-time Augmentation for Content-based Image Retrieval. (arXiv:2002.01642v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Osman Tursun</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.01642">
                                    <div class="article-summary-box-inner">
                                        <span>Off-the-shelf convolutional neural network features achieve outstanding
results in many image retrieval tasks. However, their invariance to target data
is pre-defined by the network architecture and training data. Existing image
retrieval approaches require fine-tuning or modification of pre-trained
networks to adapt to variations unique to the target data. In contrast, our
method enhances the invariance of off-the-shelf features by aggregating
features extracted from images augmented at test-time, with augmentations
guided by a policy learned through reinforcement learning. The learned policy
assigns different magnitudes and weights to the selected transformations, which
are selected from a list of image transformations. Policies are evaluated using
a metric learning protocol to learn the optimal policy. The model converges
quickly and the cost of each policy iteration is minimal as we propose an
off-line caching technique to greatly reduce the computational cost of
extracting features from augmented images. Experimental results on large
trademark retrieval (METU trademark dataset) and landmark retrieval (ROxford5k
and RParis6k scene datasets) tasks show that the learned ensemble of
transformations is highly effective for improving performance, and is
practical, and transferable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Deep Metric Learning with Structural Matching. (arXiv:2108.05889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05889">
                                    <div class="article-summary-box-inner">
                                        <span>How do the neural networks distinguish two images? It is of critical
importance to understand the matching mechanism of deep models for developing
reliable intelligent systems for many risky visual applications such as
surveillance and access control. However, most existing deep metric learning
methods match the images by comparing feature vectors, which ignores the
spatial structure of images and thus lacks interpretability. In this paper, we
present a deep interpretable metric learning (DIML) method for more transparent
embedding learning. Unlike conventional metric learning methods based on
feature vector comparison, we propose a structural matching strategy that
explicitly aligns the spatial embeddings by computing an optimal matching flow
between feature maps of the two images. Our method enables deep models to learn
metrics in a more human-friendly way, where the similarity of two images can be
decomposed to several part-wise similarities and their contributions to the
overall similarity. Our method is model-agnostic, which can be applied to
off-the-shelf backbone networks and metric learning methods. We evaluate our
method on three major benchmarks of deep metric learning including CUB200-2011,
Cars196, and Stanford Online Products, and achieve substantial improvements
over popular metric learning methods with better interpretability. Code is
available at https://github.com/wl-zhao/DIML</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Visual Attribute Learning for Fashion Compatibility. (arXiv:2008.00348v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_K/0/1/0/all/0/1">Kuniaki Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Samarth Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1">Stan Sclaroff</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1">Bryan A Plummer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00348">
                                    <div class="article-summary-box-inner">
                                        <span>Many self-supervised learning (SSL) methods have been successful in learning
semantically meaningful visual representations by solving pretext tasks.
However, prior work in SSL focuses on tasks like object recognition or
detection, which aim to learn object shapes and assume that the features should
be invariant to concepts like colors and textures. Thus, these SSL methods
perform poorly on downstream tasks where these concepts provide critical
information. In this paper, we present an SSL framework that enables us to
learn color and texture-aware features without requiring any labels during
training. Our approach consists of three self-supervised tasks designed to
capture different concepts that are neglected in prior work that we can select
from depending on the needs of our downstream tasks. Our tasks include learning
to predict color histograms and discriminate shapeless local patches and
textures from each instance. We evaluate our approach on fashion compatibility
using Polyvore Outfits and In-Shop Clothing Retrieval using Deepfashion,
improving upon prior SSL methods by 9.5-16%, and even outperforming some
supervised approaches on Polyvore Outfits despite using no labels. We also show
that our approach can be used for transfer learning, demonstrating that we can
train on one dataset while achieving high performance on a different dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation. (arXiv:2010.05903v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_L/0/1/0/all/0/1">Liron Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection methods require high-quality features. In recent years, the
anomaly detection community has attempted to obtain better features using
advances in deep self-supervised feature learning. Surprisingly, a very
promising direction, using pretrained deep features, has been mostly
overlooked. In this paper, we first empirically establish the perhaps expected,
but unreported result, that combining pretrained features with simple anomaly
detection and segmentation methods convincingly outperforms, much more complex,
state-of-the-art methods.

In order to obtain further performance gains in anomaly detection, we adapt
pretrained features to the target distribution. Although transfer learning
methods are well established in multi-class classification problems, the
one-class classification (OCC) setting is not as well explored. It turns out
that naive adaptation methods, which typically work well in supervised
learning, often result in catastrophic collapse (feature deterioration) and
reduce performance in OCC settings. A popular OCC method, DeepSVDD, advocates
using specialized architectures, but this limits the adaptation performance
gain. We propose two methods for combating collapse: i) a variant of early
stopping that dynamically learns the stopping iteration ii) elastic
regularization inspired by continual learning. Our method, PANDA, outperforms
the state-of-the-art in the OCC, outlier exposure and anomaly segmentation
settings by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MT-ORL: Multi-Task Occlusion Relationship Learning. (arXiv:2108.05722v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+ZHANG_L/0/1/0/all/0/1">Lin ZHANG</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zijian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05722">
                                    <div class="article-summary-box-inner">
                                        <span>Retrieving occlusion relation among objects in a single image is challenging
due to sparsity of boundaries in image. We observe two key issues in existing
works: firstly, lack of an architecture which can exploit the limited amount of
coupling in the decoder stage between the two subtasks, namely occlusion
boundary extraction and occlusion orientation prediction, and secondly,
improper representation of occlusion orientation. In this paper, we propose a
novel architecture called Occlusion-shared and Path-separated Network (OPNet),
which solves the first issue by exploiting rich occlusion cues in shared
high-level features and structured spatial information in task-specific
low-level features. We then design a simple but effective orthogonal occlusion
representation (OOR) to tackle the second issue. Our method surpasses the
state-of-the-art methods by 6.1%/8.3% Boundary-AP and 6.5%/10% Orientation-AP
on standard PIOD/BSDS ownership datasets. Code is available at
https://github.com/fengpanhe/MT-ORL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Descent Algorithm for Nonsmooth Nonconvex Image Reconstruction. (arXiv:2007.11245v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunmei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongcheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaojing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingchao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11245">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a general learning based framework for solving nonsmooth and
nonconvex image reconstruction problems. We model the regularization function
as the composition of the $l_{2,1}$ norm and a smooth but nonconvex feature
mapping parametrized as a deep convolutional neural network. We develop a
provably convergent descent-type algorithm to solve the nonsmooth nonconvex
minimization problem by leveraging the Nesterov&#x27;s smoothing technique and the
idea of residual learning, and learn the network parameters such that the
outputs of the algorithm match the references in training data. Our method is
versatile as one can employ various modern network structures into the
regularization, and the resulting network inherits the guaranteed convergence
of the algorithm. We also show that the proposed network is parameter-efficient
and its performance compares favorably to the state-of-the-art methods in a
variety of image reconstruction problems in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Approach to Partial Observability in Games: Learning to Both Act and Observe. (arXiv:2108.05701v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gilmour_E/0/1/0/all/0/1">Elizabeth Gilmour</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotkin_N/0/1/0/all/0/1">Noah Plotkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Leslie Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05701">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is successful at learning to play games where the
entire environment is visible. However, RL approaches are challenged in complex
games like Starcraft II and in real-world environments where the entire
environment is not visible. In these more complex games with more limited
visual information, agents must choose where to look and how to optimally use
their limited visual information in order to succeed at the game. We verify
that with a relatively simple model the agent can learn where to look in
scenarios with a limited visual bandwidth. We develop a method for masking part
of the environment in Atari games to force the RL agent to learn both where to
look and how to play the game in order to study where the RL agent learns to
look. In addition, we develop a neural network architecture and method for
allowing the agent to choose where to look and what action to take in the Pong
game. Further, we analyze the strategies the agent learns to better understand
how the RL agent learns to play the game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Billion-Scale Pretraining with Vision Transformers for Multi-Task Visual Representations. (arXiv:2108.05887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beal_J/0/1/0/all/0/1">Josh Beal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao-Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dong Huk Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_A/0/1/0/all/0/1">Andrew Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kislyuk_D/0/1/0/all/0/1">Dmitry Kislyuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05887">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretraining of visual representations has led to state-of-the-art
performance on a range of benchmark computer vision tasks, yet the benefits of
these techniques at extreme scale in complex production systems has been
relatively unexplored. We consider the case of a popular visual discovery
product, where these representations are trained with multi-task learning, from
use-case specific visual understanding (e.g. skin tone classification) to
general representation learning for all visual content (e.g. embeddings for
retrieval). In this work, we describe how we (1) generate a dataset with over a
billion images via large weakly-supervised pretraining to improve the
performance of these visual representations, and (2) leverage Transformers to
replace the traditional convolutional backbone, with insights into both system
and performance improvements, especially at 1B+ image scale. To support this
backbone model, we detail a systematic approach to deriving weakly-supervised
image annotations from heterogenous text signals, demonstrating the benefits of
clustering techniques to handle the long-tail distribution of image labels.
Through a comprehensive study of offline and online evaluation, we show that
large-scale Transformer-based pretraining provides significant benefits to
industry computer vision applications. The model is deployed in a production
visual shopping system, with 36% improvement in top-1 relevance and 23%
improvement in click-through volume. We conduct extensive experiments to better
understand the empirical relationships between Transformer-based architectures,
dataset scale, and the performance of production vision systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-driven Graph Clustering Network. (arXiv:2108.05499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhihao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuheng Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05499">
                                    <div class="article-summary-box-inner">
                                        <span>The combination of the traditional convolutional network (i.e., an
auto-encoder) and the graph convolutional network has attracted much attention
in clustering, in which the auto-encoder extracts the node attribute feature
and the graph convolutional network captures the topological graph feature.
However, the existing works (i) lack a flexible combination mechanism to
adaptively fuse those two kinds of features for learning the discriminative
representation and (ii) overlook the multi-scale information embedded at
different layers for subsequent cluster assignment, leading to inferior
clustering results. To this end, we propose a novel deep clustering method
named Attention-driven Graph Clustering Network (AGCN). Specifically, AGCN
exploits a heterogeneity-wise fusion module to dynamically fuse the node
attribute feature and the topological graph feature. Moreover, AGCN develops a
scale-wise fusion module to adaptively aggregate the multi-scale features
embedded at different layers. Based on a unified optimization framework, AGCN
can jointly perform feature learning and cluster assignment in an unsupervised
fashion. Compared with the existing deep clustering methods, our method is more
flexible and effective since it comprehensively considers the numerous and
discriminative information embedded in the network and directly produces the
clustering results. Extensive quantitative and qualitative results on commonly
used benchmark datasets validate that our AGCN consistently outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Holistic Knowledge with Graph Neural Networks. (arXiv:2108.05507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yucheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Defang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Can Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1">Jiajun Bu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05507">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) aims at transferring knowledge from a larger
well-optimized teacher network to a smaller learnable student network.Existing
KD methods have mainly considered two types of knowledge, namely the individual
knowledge and the relational knowledge. However, these two types of knowledge
are usually modeled independently while the inherent correlations between them
are largely ignored. It is critical for sufficient student network learning to
integrate both individual knowledge and relational knowledge while reserving
their inherent correlation. In this paper, we propose to distill the novel
holistic knowledge based on an attributed graph constructed among instances.
The holistic knowledge is represented as a unified graph-based embedding by
aggregating individual knowledge from relational neighborhood samples with
graph neural networks, the student network is learned by distilling the
holistic knowledge in a contrastive manner. Extensive experiments and ablation
studies are conducted on benchmark datasets, the results demonstrate the
effectiveness of the proposed method. The code has been published in
https://github.com/wyc-ruiker/HKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yuzhe Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yueh-Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hanwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05877">
                                    <div class="article-summary-box-inner">
                                        <span>While we have made significant progress on understanding hand-object
interactions in computer vision, it is still very challenging for robots to
perform complex dexterous manipulation. In this paper, we propose a new
platform and pipeline, DexMV (Dex Manipulation from Videos), for imitation
learning to bridge the gap between computer vision and robot learning. We
design a platform with: (i) a simulation system for complex dexterous
manipulation tasks with a multi-finger robot hand and (ii) a computer vision
system to record large-scale demonstrations of a human hand conducting the same
tasks. In our new pipeline, we extract 3D hand and object poses from the
videos, and convert them to robot demonstrations via motion retargeting. We
then apply and compare multiple imitation learning algorithms with the
demonstrations. We show that the demonstrations can indeed improve robot
learning by a large margin and solve the complex tasks which reinforcement
learning alone cannot solve. Project page with video:
https://yzqin.github.io/dexmv/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">perf4sight: A toolflow to model CNN training performance on Edge GPUs. (arXiv:2108.05580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_A/0/1/0/all/0/1">Aditya Rajagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1">Christos-Savvas Bouganis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05580">
                                    <div class="article-summary-box-inner">
                                        <span>The increased memory and processing capabilities of today&#x27;s edge devices
create opportunities for greater edge intelligence. In the domain of vision,
the ability to adapt a Convolutional Neural Network&#x27;s (CNN) structure and
parameters to the input data distribution leads to systems with lower memory
footprint, latency and power consumption. However, due to the limited compute
resources and memory budget on edge devices, it is necessary for the system to
be able to predict the latency and memory footprint of the training process in
order to identify favourable training configurations of the network topology
and device combination for efficient network adaptation. This work proposes
perf4sight, an automated methodology for developing accurate models that
predict CNN training memory footprint and latency given a target device and
network. This enables rapid identification of network topologies that can be
retrained on the edge device with low resource consumption. With PyTorch as the
framework and NVIDIA Jetson TX2 as the target device, the developed models
predict training memory footprint and latency with 95% and 91% accuracy
respectively for a wide range of networks, opening the path towards efficient
network adaptation on edge GPUs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation. (arXiv:2108.05570v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shin_I/0/1/0/all/0/1">Inkyu Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sanghyun Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kwanyong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05570">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) for semantic segmentation has been
actively studied to mitigate the domain gap between label-rich source data and
unlabeled target data. Despite these efforts, UDA still has a long way to go to
reach the fully supervised performance. To this end, we propose a Labeling Only
if Required strategy, LabOR, where we introduce a human-in-the-loop approach to
adaptively give scarce labels to points that a UDA model is uncertain about. In
order to find the uncertain points, we generate an inconsistency mask using the
proposed adaptive pixel selector and we label these segment-based regions to
achieve near supervised performance with only a small fraction (about 2.2%)
ground truth points, which we call &quot;Segment based Pixel-Labeling (SPL)&quot;. To
further reduce the efforts of the human annotator, we also propose &quot;Point-based
Pixel-Labeling (PPL)&quot;, which finds the most representative points for labeling
within the generated inconsistency mask. This reduces efforts from 2.2% segment
label to 40 points label while minimizing performance degradation. Through
extensive experimentation, we show the advantages of this new framework for
domain adaptive semantic segmentation while minimizing human labor costs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision. (arXiv:2108.05863v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaoshi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1">Hadar Averbuch-Elor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1">Noah Snavely</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05863">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance and richness of Internet photos of landmarks and cities has led
to significant progress in 3D vision over the past two decades, including
automated 3D reconstructions of the world&#x27;s landmarks from tourist photos.
However, a major source of information available for these 3D-augmented
collections---namely language, e.g., from image captions---has been virtually
untapped. In this work, we present WikiScenes, a new, large-scale dataset of
landmark photo collections that contains descriptive text in the form of
captions and hierarchical category names. WikiScenes forms a new testbed for
multimodal reasoning involving images, text, and 3D geometry. We demonstrate
the utility of WikiScenes for learning semantic concepts over images and 3D
models. Our weakly-supervised framework connects images, 3D structure, and
semantics---utilizing the strong constraints provided by 3D geometry---to
associate semantic concepts to image pixels and 3D points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation. (arXiv:2011.06294v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhewei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1">Wen Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuchang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06294">
                                    <div class="article-summary-box-inner">
                                        <span>We propose RIFE, a Real-time Intermediate Flow Estimation algorithm for Video
Frame Interpolation (VFI). Many recent flow-based VFI methods first estimate
the bi-directional optical flows, then scale and reverse them to approximate
intermediate flows, leading to artifacts on motion boundaries. RIFE uses a
neural network named IFNet that can directly estimate the intermediate flows
from coarse-to-fine with much better speed. We design a privileged distillation
scheme for training intermediate flow model, which leads to a large performance
improvement. Experiments demonstrate that RIFE is flexible and can achieve
state-of-the-art performance on several public benchmarks. The code is
available at \url{https://github.com/hzwer/arXiv2020-RIFE}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Gaze Analysis: A Survey of DeepLearning based Approaches. (arXiv:2108.05479v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Shreya Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhall_A/0/1/0/all/0/1">Abhinav Dhall</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Knibbe_J/0/1/0/all/0/1">Jarrod Knibbe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1">Qiang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05479">
                                    <div class="article-summary-box-inner">
                                        <span>Eye gaze analysis is an important research problem in the field of computer
vision and Human-Computer Interaction (HCI). Even with significant progress in
the last few years, automatic gaze analysis still remains challenging due to
the individuality of eyes, eye-head interplay, occlusion, image quality, and
illumination conditions. There are several open questions including what are
the important cues to interpret gaze direction in an unconstrained environment
without prior knowledge and how to encode them in real-time. We review the
progress across a range of gaze analysis tasks and applications to shed light
on these fundamental questions; identify effective methods in gaze analysis and
provide possible future directions. We analyze recent gaze estimation and
segmentation methods, especially in the unsupervised and weakly supervised
domain, based on their advantages and reported evaluation metrics. Our analysis
shows that the development of a robust and generic gaze analysis method still
needs to address real-world challenges such as unconstrained setup and learning
with less supervision. We conclude by discussing future research directions for
designing a real-world gaze analysis system that can propagate to other domains
including computer vision, AR (Augmented Reality), VR (Virtual Reality), and
HCI (Human Computer Interaction).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Silhouette based View embeddings for Gait Recognition under Multiple Views. (arXiv:2108.05524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1">Tianrui Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_X/0/1/0/all/0/1">Xinyu Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Annan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05524">
                                    <div class="article-summary-box-inner">
                                        <span>Gait recognition under multiple views is an important computer vision and
pattern recognition task. In the emerging convolutional neural network based
approaches, the information of view angle is ignored to some extent. Instead of
direct view estimation and training view-specific recognition models, we
propose a compatible framework that can embed view information into existing
architectures of gait recognition. The embedding is simply achieved by a
selective projection layer. Experimental results on two large public datasets
show that the proposed framework is very effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Temporal Variational AutoEncoder for Action Video Prediction. (arXiv:2108.05658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaogang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05658">
                                    <div class="article-summary-box-inner">
                                        <span>To synthesize a realistic action sequence based on a single human image, it
is crucial to model both motion patterns and diversity in the action video.
This paper proposes an Action Conditional Temporal Variational AutoEncoder
(ACT-VAE) to improve motion prediction accuracy and capture movement diversity.
ACT-VAE predicts pose sequences for an action clips from a single input image.
It is implemented as a deep generative model that maintains temporal coherence
according to the action category with a novel temporal modeling on latent
space. Further, ACT-VAE is a general action sequence prediction framework. When
connected with a plug-and-play Pose-to-Image (P2I) network, ACT-VAE can
synthesize image sequences. Extensive experiments bear out our approach can
predict accurate pose and synthesize realistic image sequences, surpassing
state-of-the-art approaches. Compared to existing methods, ACT-VAE improves
model accuracy and preserves diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile-Former: Bridging MobileNet and Transformer. (arXiv:2108.05895v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05895">
                                    <div class="article-summary-box-inner">
                                        <span>We present Mobile-Former, a parallel design of MobileNet and Transformer with
a two-way bridge in between. This structure leverages the advantage of
MobileNet at local processing and transformer at global interaction. And the
bridge enables bidirectional fusion of local and global features. Different
with recent works on vision transformer, the transformer in Mobile-Former
contains very few tokens (e.g. less than 6 tokens) that are randomly
initialized, resulting in low computational cost. Combining with the proposed
light-weight cross attention to model the bridge, Mobile-Former is not only
computationally efficient, but also has more representation power,
outperforming MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet
classification. For instance, it achieves 77.9\% top-1 accuracy at 294M FLOPs,
gaining 1.3\% over MobileNetV3 but saving 17\% of computations. When
transferring to object detection, Mobile-Former outperforms MobileNetV3 by 8.6
AP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Camera Obscura: An Image Restoration Pipeline for Lensless Pinhole Photography. (arXiv:2108.05563v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rego_J/0/1/0/all/0/1">Joshua D. Rego</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huaijin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinwei Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasuriya_S/0/1/0/all/0/1">Suren Jayasuriya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05563">
                                    <div class="article-summary-box-inner">
                                        <span>The lensless pinhole camera is perhaps the earliest and simplest form of an
imaging system using only a pinhole-sized aperture in place of a lens. They can
capture an infinite depth-of-field and offer greater freedom from optical
distortion over their lens-based counterparts. However, the inherent
limitations of a pinhole system result in lower sharpness from blur caused by
optical diffraction and higher noise levels due to low light throughput of the
small aperture, requiring very long exposure times to capture well-exposed
images. In this paper, we explore an image restoration pipeline using deep
learning and domain-knowledge of the pinhole system to enhance the pinhole
image quality through a joint denoise and deblur approach. Our approach allows
for more practical exposure times for hand-held photography and provides higher
image quality, making it more suitable for daily photography compared to other
lensless cameras while keeping size and cost low. This opens up the potential
of pinhole cameras to be used in smaller devices, such as smartphones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preventing Catastrophic Forgetting and Distribution Mismatch in Knowledge Distillation via Synthetic Data. (arXiv:2108.05698v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Binici_K/0/1/0/all/0/1">Kuluhan Binici</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1">Nam Trung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1">Tulika Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Leman_K/0/1/0/all/0/1">Karianto Leman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05698">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing popularity of deep learning on edge devices, compressing
large neural networks to meet the hardware requirements of resource-constrained
devices became a significant research direction. Numerous compression
methodologies are currently being used to reduce the memory sizes and energy
consumption of neural networks. Knowledge distillation (KD) is among such
methodologies and it functions by using data samples to transfer the knowledge
captured by a large model (teacher) to a smaller one(student). However, due to
various reasons, the original training data might not be accessible at the
compression stage. Therefore, data-free model compression is an ongoing
research problem that has been addressed by various works. In this paper, we
point out that catastrophic forgetting is a problem that can potentially be
observed in existing data-free distillation methods. Moreover, the sample
generation strategies in some of these methods could result in a mismatch
between the synthetic and real data distributions. To prevent such problems, we
propose a data-free KD framework that maintains a dynamic collection of
generated samples over time. Additionally, we add the constraint of matching
the real data distribution in sample generation strategies that target maximum
information gain. Our experiments demonstrate that we can improve the accuracy
of the student models obtained via KD when compared with state-of-the-art
approaches on the SVHN, Fashion MNIST and CIFAR100 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Presenting an extensive lab- and field-image dataset of crops and weeds for computer vision tasks in agriculture. (arXiv:2108.05789v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_M/0/1/0/all/0/1">Michael A. Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen-Yi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidinosti_C/0/1/0/all/0/1">Christopher P. Bidinosti</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_C/0/1/0/all/0/1">Christopher J. Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Godee_C/0/1/0/all/0/1">Cara M. Godee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ajmani_M/0/1/0/all/0/1">Manisha Ajmani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05789">
                                    <div class="article-summary-box-inner">
                                        <span>We present two large datasets of labelled plant-images that are suited
towards the training of machine learning and computer vision models. The first
dataset encompasses as the day of writing over 1.2 million images of
indoor-grown crops and weeds common to the Canadian Prairies and many US
states. The second dataset consists of over 540,000 images of plants imaged in
farmland. All indoor plant images are labelled by species and we provide rich
etadata on the level of individual images. This comprehensive database allows
to filter the datasets under user-defined specifications such as for example
the crop-type or the age of the plant. Furthermore, the indoor dataset contains
images of plants taken from a wide variety of angles, including profile shots,
top-down shots, and angled perspectives. The images taken from plants in fields
are all from a top-down perspective and contain usually multiple plants per
image. For these images metadata is also available. In this paper we describe
both datasets&#x27; characteristics with respect to plant variety, plant age, and
number of images. We further introduce an open-access sample of the
indoor-dataset that contains 1,000 images of each species covered in our
dataset. These, in total 14,000 images, had been selected, such that they form
a representative sample with respect to plant age and ndividual plants per
species. This sample serves as a quick entry point for new users to the
dataset, allowing them to explore the data on a small scale and find the
parameters of data most useful for their application without having to deal
with hundreds of thousands of individual images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unconditional Scene Graph Generation. (arXiv:2108.05884v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sarthak Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhamo_H/0/1/0/all/0/1">Helisa Dhamo</a>, <a href="http://arxiv.org/find/cs/1/au:+Farshad_A/0/1/0/all/0/1">Azade Farshad</a>, <a href="http://arxiv.org/find/cs/1/au:+Musatian_S/0/1/0/all/0/1">Sabrina Musatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05884">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent advancements in single-domain or single-object image
generation, it is still challenging to generate complex scenes containing
diverse, multiple objects and their interactions. Scene graphs, composed of
nodes as objects and directed-edges as relationships among objects, offer an
alternative representation of a scene that is more semantically grounded than
images. We hypothesize that a generative model for scene graphs might be able
to learn the underlying semantic structure of real-world scenes more
effectively than images, and hence, generate realistic novel scenes in the form
of scene graphs. In this work, we explore a new task for the unconditional
generation of semantic scene graphs. We develop a deep auto-regressive model
called SceneGraphGen which can directly learn the probability distribution over
labelled and directed graphs using a hierarchical recurrent architecture. The
model takes a seed object as input and generates a scene graph in a sequence of
steps, each step generating an object node, followed by a sequence of
relationship edges connecting to the previous nodes. We show that the scene
graphs generated by SceneGraphGen are diverse and follow the semantic patterns
of real-world scenes. Additionally, we demonstrate the application of the
generated graphs in image synthesis, anomaly detection and scene graph
completion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PixelSynth: Generating a 3D-Consistent Experience from a Single Image. (arXiv:2108.05892v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rockwell_C/0/1/0/all/0/1">Chris Rockwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Fouhey_D/0/1/0/all/0/1">David F. Fouhey</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_J/0/1/0/all/0/1">Justin Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05892">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in differentiable rendering and 3D reasoning have driven
exciting results in novel view synthesis from a single image. Despite realistic
results, methods are limited to relatively small view change. In order to
synthesize immersive scenes, models must also be able to extrapolate. We
present an approach that fuses 3D reasoning with autoregressive modeling to
outpaint large view changes in a 3D-consistent manner, enabling scene
synthesis. We demonstrate considerable improvement in single image large-angle
view synthesis results compared to a variety of methods and possible variants
across simulated and real datasets. In addition, we show increased 3D
consistency compared to alternative accumulation methods. Project website:
https://crockwell.github.io/pixelsynth/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniFaceGAN: A Unified Framework for Temporally Consistent Facial Video Editing. (arXiv:2108.05650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haozhi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1">Linchao Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05650">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has witnessed advances in facial image editing tasks
including face swapping and face reenactment. However, these methods are
confined to dealing with one specific task at a time. In addition, for video
facial editing, previous methods either simply apply transformations frame by
frame or utilize multiple frames in a concatenated or iterative fashion, which
leads to noticeable visual flickers. In this paper, we propose a unified
temporally consistent facial video editing framework termed UniFaceGAN. Based
on a 3D reconstruction model and a simple yet efficient dynamic training sample
selection mechanism, our framework is designed to handle face swapping and face
reenactment simultaneously. To enforce the temporal consistency, a novel 3D
temporal loss constraint is introduced based on the barycentric coordinate
interpolation. Besides, we propose a region-aware conditional normalization
layer to replace the traditional AdaIN or SPADE to synthesize more
context-harmonious results. Compared with the state-of-the-art facial image
editing methods, our framework generates video portraits that are more
photo-realistic and temporally smooth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards real-world navigation with deep differentiable planners. (arXiv:2108.05713v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishida_S/0/1/0/all/0/1">Shu Ishida</a>, <a href="http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1">Jo&#xe3;o F. Henriques</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05713">
                                    <div class="article-summary-box-inner">
                                        <span>We train embodied neural networks to plan and navigate unseen complex 3D
environments, emphasising real-world deployment. Rather than requiring prior
knowledge of the agent or environment, the planner learns to model the state
transitions and rewards. To avoid the potentially hazardous trial-and-error of
reinforcement learning, we focus on differentiable planners such as Value
Iteration Networks (VIN), which are trained offline from safe expert
demonstrations. Although they work well in small simulations, we address two
major limitations that hinder their deployment. First, we observed that current
differentiable planners struggle to plan long-term in environments with a high
branching complexity. While they should ideally learn to assign low rewards to
obstacles to avoid collisions, we posit that the constraints imposed on the
network are not strong enough to guarantee the network to learn sufficiently
large penalties for every possible collision. We thus impose a structural
constraint on the value iteration, which explicitly learns to model any
impossible actions. Secondly, we extend the model to work with a limited
perspective camera under translation and rotation, which is crucial for real
robot deployment. Many VIN-like planners assume a 360 degrees or overhead view
without rotation. In contrast, our method uses a memory-efficient lattice map
to aggregate CNN embeddings of partial observations, and models the rotational
dynamics explicitly using a 3D state-space grid (translation and rotation). Our
proposals significantly improve semantic navigation and exploration on several
2D and 3D environments, succeeding in settings that are otherwise challenging
for this class of methods. As far as we know, we are the first to successfully
perform differentiable planning on the difficult Active Vision Dataset,
consisting of real images captured from a robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds. (arXiv:2108.05836v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Runsong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zhen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tengping Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bisheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05836">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a neural network for robust normal estimation on point
clouds, named AdaFit, that can deal with point clouds with noise and density
variations. Existing works use a network to learn point-wise weights for
weighted least squares surface fitting to estimate the normals, which has
difficulty in finding accurate normals in complex regions or containing noisy
points. By analyzing the step of weighted least squares surface fitting, we
find that it is hard to determine the polynomial order of the fitting surface
and the fitting surface is sensitive to outliers. To address these problems, we
propose a simple yet effective solution that adds an additional offset
prediction to improve the quality of normal estimation. Furthermore, in order
to take advantage of points from different neighborhood sizes, a novel Cascaded
Scale Aggregation layer is proposed to help the network predict more accurate
point-wise offsets and weights. Extensive experiments demonstrate that AdaFit
achieves state-of-the-art performance on both the synthetic PCPNet dataset and
the real-word SceneNN dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVINS: Visual-Inertial SLAM for Centralized Collaboration. (arXiv:2108.05756v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmuck_P/0/1/0/all/0/1">Patrik Schmuck</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziegler_T/0/1/0/all/0/1">Thomas Ziegler</a>, <a href="http://arxiv.org/find/cs/1/au:+Karrer_M/0/1/0/all/0/1">Marco Karrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Perraudin_J/0/1/0/all/0/1">Jonathan Perraudin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chli_M/0/1/0/all/0/1">Margarita Chli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05756">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative SLAM enables a group of agents to simultaneously co-localize
and jointly map an environment, thus paving the way to wide-ranging
applications of multi-robot perception and multi-user AR experiences by
eliminating the need for external infrastructure or pre-built maps. This
article presents COVINS, a novel collaborative SLAM system, that enables
multi-agent, scalable SLAM in large environments and for large teams of more
than 10 agents. The paradigm here is that each agent runs visual-inertial
odomety independently onboard in order to ensure its autonomy, while sharing
map information with the COVINS server back-end running on a powerful local PC
or a remote cloud server. The server back-end establishes an accurate
collaborative global estimate from the contributed data, refining the joint
estimate by means of place recognition, global optimization and removal of
redundant data, in order to ensure an accurate, but also efficient SLAM
process. A thorough evaluation of COVINS reveals increased accuracy of the
collaborative SLAM estimates, as well as efficiency in both removing redundant
information and reducing the coordination overhead, and demonstrates successful
operation in a large-scale mission with 12 agents jointly performing SLAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Ranking Correlation of Supernet with Candidates Enhancement and Progressive Training. (arXiv:2108.05866v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xubo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheyang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05866">
                                    <div class="article-summary-box-inner">
                                        <span>One-shot neural architecture search (NAS) applies weight-sharing supernet to
reduce the unaffordable computation overhead of automated architecture
designing. However, the weight-sharing technique worsens the ranking
consistency of performance due to the interferences between different candidate
networks. To address this issue, we propose a candidates enhancement method and
progressive training pipeline to improve the ranking correlation of supernet.
Specifically, we carefully redesign the sub-networks in the supernet and map
the original supernet to a new one of high capacity. In addition, we gradually
add narrow branches of supernet to reduce the degree of weight sharing which
effectively alleviates the mutual interference between sub-networks. Finally,
our method ranks the 1st place in the Supernet Track of CVPR2021 1st
Lightweight NAS Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIDER: Single-Image Neural Optimization for Facial Geometric Detail Recovery. (arXiv:2108.05465v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatziagapi_A/0/1/0/all/0/1">Aggelina Chatziagapi</a>, <a href="http://arxiv.org/find/cs/1/au:+Athar_S/0/1/0/all/0/1">ShahRukh Athar</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1">Francesc Moreno-Noguer</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1">Dimitris Samaras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05465">
                                    <div class="article-summary-box-inner">
                                        <span>We present SIDER(Single-Image neural optimization for facial geometric DEtail
Recovery), a novel photometric optimization method that recovers detailed
facial geometry from a single image in an unsupervised manner. Inspired by
classical techniques of coarse-to-fine optimization and recent advances in
implicit neural representations of 3D shape, SIDER combines a geometry prior
based on statistical models and Signed Distance Functions (SDFs) to recover
facial details from single images. First, it estimates a coarse geometry using
a morphable model represented as an SDF. Next, it reconstructs facial geometry
details by optimizing a photometric loss with respect to the ground truth
image. In contrast to prior work, SIDER does not rely on any dataset priors and
does not require additional supervision from multiple views, lighting changes
or ground truth 3D shape. Extensive qualitative and quantitative evaluation
demonstrates that our method achieves state-of-the-art on facial geometric
detail recovery, using only a single in-the-wild image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DARTS for Inverse Problems: a Study on Hyperparameter Sensitivity. (arXiv:2108.05647v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1">Jovita Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05647">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) is a widely researched tool for
neural architecture search, due to its promising results for image
classification. The main benefit of DARTS is the effectiveness achieved through
the weight-sharing one-shot paradigm, which allows efficient architecture
search. In this work, we investigate DARTS in a systematic case study of
inverse problems, which allows us to analyze these potential benefits in a
controlled manner. Although we demonstrate that the success of DARTS can be
extended from image classification to reconstruction, our experiments yield
three fundamental difficulties in the evaluation of DARTS-based methods: First,
the results show a large variance in all test cases. Second, the final
performance is highly dependent on the hyperparameters of the optimizer. And
third, the performance of the weight-sharing architecture used during training
does not reflect the final performance of the found architecture well. Thus, we
conclude the necessity to 1) report the results of any DARTS-based methods from
several runs along with its underlying performance statistics, 2) show the
correlation of the training and final architecture performance, and 3)
carefully consider if the computational efficiency of DARTS outweighs the costs
of hyperparameter optimization and multiple runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation. (arXiv:2108.05773v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bangunharcana_A/0/1/0/all/0/1">Antyanta Bangunharcana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seokju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyung-Soo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohyun Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05773">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric deep learning approach towards stereo matching aggregates a cost
volume computed from input left and right images using 3D convolutions. Recent
works showed that utilization of extracted image features and a spatially
varying cost volume aggregation complements 3D convolutions. However, existing
methods with spatially varying operations are complex, cost considerable
computation time, and cause memory consumption to increase. In this work, we
construct Guided Cost volume Excitation (GCE) and show that simple channel
excitation of cost volume guided by image can improve performance considerably.
Moreover, we propose a novel method of using top-k selection prior to
soft-argmin disparity regression for computing the final disparity estimate.
Combining our novel contributions, we present an end-to-end network that we
call Correlate-and-Excite (CoEx). Extensive experiments of our model on the
SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate the effectiveness
and efficiency of our model and show that our model outperforms other
speed-based algorithms while also being competitive to other state-of-the-art
algorithms. Codes will be made available at https://github.com/antabangun/coex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Amended Gradient Descent for Efficient Spectral Reconstruction from Single RGB Images. (arXiv:2108.05547v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhiyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1">Sen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05547">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the problem of recovering hyperspectral (HS) images
from single RGB images. To tackle such a severely ill-posed problem, we propose
a physically-interpretable, compact, efficient, and end-to-end learning-based
framework, namely AGD-Net. Precisely, by taking advantage of the imaging
process, we first formulate the problem explicitly based on the classic
gradient descent algorithm. Then, we design a lightweight neural network with a
multi-stage architecture to mimic the formed amended gradient descent process,
in which efficient convolution and novel spectral zero-mean normalization are
proposed to effectively extract spatial-spectral features for regressing an
initialization, a basic gradient, and an incremental gradient. Besides, based
on the approximate low-rank property of HS images, we propose a novel rank loss
to promote the similarity between the global structures of reconstructed and
ground-truth HS images, which is optimized with our singular value weighting
strategy during training. Moreover, AGD-Net, a single network after one-time
training, is flexible to handle the reconstruction with various spectral
response functions. Extensive experiments over three commonly-used benchmark
datasets demonstrate that AGD-Net can improve the reconstruction quality by
more than 1.0 dB on average while saving 67$\times$ parameters and 32$\times$
FLOPs, compared with state-of-the-art methods. The code will be publicly
available at https://github.com/zbzhzhy/GD-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MISS GAN: A Multi-IlluStrator Style Generative Adversarial Network for image to illustration translation. (arXiv:2108.05693v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barzilay_N/0/1/0/all/0/1">Noa Barzilay</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalev_T/0/1/0/all/0/1">Tal Berkovitz Shalev</a>, <a href="http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05693">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised style transfer that supports diverse input styles using only one
trained generator is a challenging and interesting task in computer vision.
This paper proposes a Multi-IlluStrator Style Generative Adversarial Network
(MISS GAN) that is a multi-style framework for unsupervised
image-to-illustration translation, which can generate styled yet content
preserving images. The illustrations dataset is a challenging one since it is
comprised of illustrations of seven different illustrators, hence contains
diverse styles. Existing methods require to train several generators (as the
number of illustrators) to handle the different illustrators&#x27; styles, which
limits their practical usage, or require to train an image specific network,
which ignores the style information provided in other images of the
illustrator. MISS GAN is both input image specific and uses the information of
other images using only one trained model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Depth-Based Estimation of Object Articulation Models. (arXiv:2108.05875v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ajinkya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Giguere_S/0/1/0/all/0/1">Stephen Giguere</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1">Rudolf Lioutikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05875">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method that efficiently learns distributions over articulation
model parameters directly from depth images without the need to know
articulation model categories a priori. By contrast, existing methods that
learn articulation models from raw observations typically only predict point
estimates of the model parameters, which are insufficient to guarantee the safe
manipulation of articulated objects. Our core contributions include a novel
representation for distributions over rigid body transformations and
articulation model parameters based on screw theory, von Mises-Fisher
distributions, and Stiefel manifolds. Combining these concepts allows for an
efficient, mathematically sound representation that implicitly satisfies the
constraints that rigid body transformations and articulations must adhere to.
Leveraging this representation, we introduce a novel deep learning based
approach, DUST-net, that performs category-independent articulation model
estimation while also providing model uncertainties. We evaluate our approach
on several benchmarking datasets and real-world objects and compare its
performance with two current state-of-the-art methods. Our results demonstrate
that DUST-net can successfully learn distributions over articulation models for
novel objects across articulation model categories, which generate point
estimates with better accuracy than state-of-the-art methods and effectively
capture the uncertainty over predicted model parameters due to noisy inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Microlocal Reconstruction for Limited-Angle Tomography. (arXiv:2108.05732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andrade_Loarca_H/0/1/0/all/0/1">H&#xe9;ctor Andrade-Loarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1">Gitta Kutyniok</a>, <a href="http://arxiv.org/find/cs/1/au:+Oktem_O/0/1/0/all/0/1">Ozan &#xd6;ktem</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Philipp Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning-based algorithm to jointly solve a reconstruction
problem and a wavefront set extraction problem in tomographic imaging. The
algorithm is based on a recently developed digital wavefront set extractor as
well as the well-known microlocal canonical relation for the Radon transform.
We use the wavefront set information about x-ray data to improve the
reconstruction by requiring that the underlying neural networks simultaneously
extract the correct ground truth wavefront set and ground truth image. As a
necessary theoretical step, we identify the digital microlocal canonical
relations for deep convolutional residual neural networks. We find strong
numerical evidence for the effectiveness of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit Attenuating Weight Normalization. (arXiv:2108.05839v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aman Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanath_R/0/1/0/all/0/1">Rohan Ramanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1">Anika Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sirou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingzhou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Keerthi_S/0/1/0/all/0/1">S. Sathiya Keerthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05839">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized deep networks trained using gradient-based optimizers are
a popular choice for solving classification and ranking problems. Without
appropriately tuned $\ell_2$ regularization or weight decay, such networks have
the tendency to make output scores (logits) and network weights large, causing
training loss to become too small and the network to lose its adaptivity
(ability to move around) in the parameter space. Although regularization is
typically understood from an overfitting perspective, we highlight its role in
making the network more adaptive and enabling it to escape more easily from
weights that generalize poorly. To provide such a capability, we propose a
method called Logit Attenuating Weight Normalization (LAWN), that can be
stacked onto any gradient-based optimizer. LAWN controls the logits by
constraining the weight norms of layers in the final homogeneous sub-network.
Empirically, we show that the resulting LAWN variant of the optimizer makes a
deep network more adaptive to finding minimas with superior generalization
performance on large-scale image classification and recommender systems. While
LAWN is particularly impressive in improving Adam, it greatly improves all
optimizers when used with large batch sizes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Motion Prior for Weakly-Supervised Temporal Action Localization. (arXiv:2108.05607v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Can Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shou_M/0/1/0/all/0/1">Mike Zheng Shou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05607">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-Supervised Temporal Action Localization (WSTAL) aims to localize
actions in untrimmed videos with only video-level labels. Currently, most
state-of-the-art WSTAL methods follow a Multi-Instance Learning (MIL) pipeline:
producing snippet-level predictions first and then aggregating to the
video-level prediction. However, we argue that existing methods have overlooked
two important drawbacks: 1) inadequate use of motion information and 2) the
incompatibility of prevailing cross-entropy training loss. In this paper, we
analyze that the motion cues behind the optical flow features are complementary
informative. Inspired by this, we propose to build a context-dependent motion
prior, termed as motionness. Specifically, a motion graph is introduced to
model motionness based on the local motion carrier (e.g., optical flow). In
addition, to highlight more informative video snippets, a motion-guided loss is
proposed to modulate the network training conditioned on motionness scores.
Extensive ablation studies confirm that motionness efficaciously models
action-of-interest, and the motion-guided loss leads to more accurate results.
Besides, our motion-guided loss is a plug-and-play loss function and is
applicable with existing WSTAL methods. Without loss of generality, based on
the standard MIL pipeline, our method achieves new state-of-the-art performance
on three challenging benchmarks, including THUMOS&#x27;14, ActivityNet v1.2 and
v1.3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Visual Affordance Grounding from Demonstration Videos. (arXiv:2108.05675v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hongchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1">Wei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05675">
                                    <div class="article-summary-box-inner">
                                        <span>Visual affordance grounding aims to segment all possible interaction regions
between people and objects from an image/video, which is beneficial for many
applications, such as robot grasping and action recognition. However, existing
methods mainly rely on the appearance feature of the objects to segment each
region of the image, which face the following two problems: (i) there are
multiple possible regions in an object that people interact with; and (ii)
there are multiple possible human interactions in the same object region. To
address these problems, we propose a Hand-aided Affordance Grounding Network
(HAGNet) that leverages the aided clues provided by the position and action of
the hand in demonstration videos to eliminate the multiple possibilities and
better locate the interaction regions in the object. Specifically, HAG-Net has
a dual-branch structure to process the demonstration video and object image.
For the video branch, we introduce hand-aided attention to enhance the region
around the hand in each video frame and then use the LSTM network to aggregate
the action features. For the object branch, we introduce a semantic enhancement
module (SEM) to make the network focus on different parts of the object
according to the action classes and utilize a distillation loss to align the
output features of the object branch with that of the video branch and transfer
the knowledge in the video branch to the object branch. Quantitative and
qualitative evaluations on two challenging datasets show that our method has
achieved stateof-the-art results for affordance grounding. The source code will
be made available to the public.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Coordinate Transforms for Monocular 3D Object Detection. (arXiv:2108.05793v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Li Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">Xiangyang Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05793">
                                    <div class="article-summary-box-inner">
                                        <span>Recognizing and localizing objects in the 3D space is a crucial ability for
an AI agent to perceive its surrounding environment. While significant progress
has been achieved with expensive LiDAR point clouds, it poses a great challenge
for 3D object detection given only a monocular image. While there exist
different alternatives for tackling this problem, it is found that they are
either equipped with heavy networks to fuse RGB and depth information or
empirically ineffective to process millions of pseudo-LiDAR points. With
in-depth examination, we realize that these limitations are rooted in
inaccurate object localization. In this paper, we propose a novel and
lightweight approach, dubbed Progressive Coordinate Transforms (PCT) to
facilitate learning coordinate representations. Specifically, a localization
boosting mechanism with confidence-aware loss is introduced to progressively
refine the localization prediction. In addition, semantic image repre-
sentation is also exploited to compensate for the usage of patch proposals.
Despite being lightweight and simple, our strategy leads to superior
improvements on the KITTI and Waymo Open Dataset monocular 3D detection
benchmarks. At the same time, our proposed PCT shows great generalization to
most coordinate- based 3D detection frameworks. The code is available at:
https://github.com/ amazon-research/progressive-coordinate-transforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robotic Testbed for Rendezvous and Optical Navigation: Multi-Source Calibration and Machine Learning Use Cases. (arXiv:2108.05529v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1">Tae Ha Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosse_J/0/1/0/all/0/1">Juergen Bosse</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmico_S/0/1/0/all/0/1">Simone D&#x27;Amico</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05529">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents the most recent advances of the Robotic Testbed for
Rendezvous and Optical Navigation (TRON) at Stanford University - the first
robotic testbed capable of validating machine learning algorithms for
spaceborne optical navigation. The TRON facility consists of two 6
degrees-of-freedom KUKA robot arms and a set of Vicon motion track cameras to
reconfigure an arbitrary relative pose between a camera and a target mockup
model. The facility includes multiple Earth albedo light boxes and a sun lamp
to recreate the high-fidelity spaceborne illumination conditions. After the
overview of the facility, this work details the multi-source calibration
procedure which enables the estimation of the relative pose between the object
and the camera with millimeter-level position and millidegree-level orientation
accuracies. Finally, a comparative analysis of the synthetic and TRON simulated
imageries is performed using a Convolutional Neural Network (CNN) pre-trained
on the synthetic images. The result shows a considerable gap in the CNN&#x27;s
performance, suggesting the TRON simulated images can be used to validate the
robustness of any machine learning algorithms trained on more easily accessible
synthetic imagery from computer graphics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities. (arXiv:2108.05779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eulig_E/0/1/0/all/0/1">Elias Eulig</a>, <a href="http://arxiv.org/find/cs/1/au:+Saranrittichai_P/0/1/0/all/0/1">Piyapat Saranrittichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1">Chaithanya Kumar Mummadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambach_K/0/1/0/all/0/1">Kilian Rambach</a>, <a href="http://arxiv.org/find/cs/1/au:+Beluch_W/0/1/0/all/0/1">William Beluch</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiahan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_V/0/1/0/all/0/1">Volker Fischer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05779">
                                    <div class="article-summary-box-inner">
                                        <span>Common deep neural networks (DNNs) for image classification have been shown
to rely on shortcut opportunities (SO) in the form of predictive and
easy-to-represent visual factors. This is known as shortcut learning and leads
to impaired generalization. In this work, we show that common DNNs also suffer
from shortcut learning when predicting only basic visual object factors of
variation (FoV) such as shape, color, or texture. We argue that besides
shortcut opportunities, generalization opportunities (GO) are also an inherent
part of real-world vision data and arise from partial independence between
predicted classes and FoVs. We also argue that it is necessary for DNNs to
exploit GO to overcome shortcut learning. Our core contribution is to introduce
the Diagnostic Vision Benchmark suite DiagViB-6, which includes datasets and
metrics to study a network&#x27;s shortcut vulnerability and generalization
capability for six independent FoV. In particular, DiagViB-6 allows controlling
the type and degree of SO and GO in a dataset. We benchmark a wide range of
popular vision architectures and show that they can exploit GO only to a
limited extent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIODE: Dilatable Incremental Object Detection. (arXiv:2108.05627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Can Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Maksoud_S/0/1/0/all/0/1">Sam Maksoud</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovell_B/0/1/0/all/0/1">Brian C. Lovell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05627">
                                    <div class="article-summary-box-inner">
                                        <span>To accommodate rapid changes in the real world, the cognition system of
humans is capable of continually learning concepts. On the contrary,
conventional deep learning models lack this capability of preserving previously
learned knowledge. When a neural network is fine-tuned to learn new tasks, its
performance on previously trained tasks will significantly deteriorate. Many
recent works on incremental object detection tackle this problem by introducing
advanced regularization. Although these methods have shown promising results,
the benefits are often short-lived after the first incremental step. Under
multi-step incremental learning, the trade-off between old knowledge preserving
and new task learning becomes progressively more severe. Thus, the performance
of regularization-based incremental object detectors gradually decays for
subsequent learning steps. In this paper, we aim to alleviate this performance
decay on multi-step incremental detection tasks by proposing a dilatable
incremental object detector (DIODE). For the task-shared parameters, our method
adaptively penalizes the changes of important weights for previous tasks. At
the same time, the structure of the model is dilated or expanded by a limited
number of task-specific parameters to promote new task learning. Extensive
experiments on PASCAL VOC and COCO datasets demonstrate substantial
improvements over the state-of-the-art methods. Notably, compared with the
state-of-the-art methods, our method achieves up to 6.0% performance
improvement by increasing the number of parameters by just 1.2% for each newly
learned task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization. (arXiv:2108.05449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1">Haofu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05449">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms mine knowledge from the training data and thus would
likely inherit the dataset&#x27;s bias information. As a result, the obtained model
would generalize poorly and even mislead the decision process in real-life
applications. We propose to remove the bias information misused by the target
task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly
extracts target and bias features disentangled from the latent representation
generated by a feature extractor and then learns to discover and remove the
correlation between the target and bias features. The correlation measurement
plays a critical role in adversarial debiasing and is conducted by a
cross-sample neural mutual information estimator. Moreover, we propose joint
content and local structural representation learning to boost mutual
information estimation for better performance. We conduct thorough experiments
on publicly available datasets to validate the advantages of the proposed
method over state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Human Action Recognition Modelwith Flexible-interval Sampling and Normalization. (arXiv:2108.05633v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuke/0/1/0/all/0/1">Yuke</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang/0/1/0/all/0/1">Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05633">
                                    <div class="article-summary-box-inner">
                                        <span>Human action recognition is a well-known computer vision and pattern
recognition task of identifying which action a man is actually doing.
Extracting the keypoint information of a single human with both spatial and
temporal features of action sequences plays an essential role to accomplish the
task.In this paper, we propose a human action system for Red-Green-Blue(RGB)
input video with our own designed module. Based on the efficient Gated
Recurrent Unit(GRU) for spatio-temporal feature extraction, we add another
sampling module and normalization module to improve the performance of the
model in order to recognize the human actions. Furthermore, we build a novel
dataset with a similar background and discriminative actions for both human
keypoint prediction and behavior recognition. To get a better result, we
retrain the pose model with our new dataset to get better performance.
Experimental results demonstrate the effectiveness of the proposed model on our
own human behavior recognition dataset and some public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Medical Image Segmentation. (arXiv:2108.05476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_P/0/1/0/all/0/1">Pedro H. T. Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05476">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach for few-shot semantic segmentation
with sparse labeled images. We investigate the effectiveness of our method,
which is based on the Model-Agnostic Meta-Learning (MAML) algorithm, in the
medical scenario, where the use of sparse labeling and few-shot can alleviate
the cost of producing new annotated datasets. Our method uses sparse labels in
the meta-training and dense labels in the meta-test, thus making the model
learn to predict dense labels from sparse ones. We conducted experiments with
four Chest X-Ray datasets to evaluate two types of annotations (grid and
points). The results show that our method is the most suitable when the target
domain highly differs from source domains, achieving Jaccard scores comparable
to dense labels, using less than 2% of the pixels of an image with labels in
few-shot scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Semantic Segmentation for Off-road Unstructured Natural Environments. (arXiv:2108.05635v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Youngsaeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">David K. Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1">Hanseok Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05635">
                                    <div class="article-summary-box-inner">
                                        <span>With the availability of many datasets tailored for autonomous driving in
real-world urban scenes, semantic segmentation for urban driving scenes
achieves significant progress. However, semantic segmentation for off-road,
unstructured environments is not widely studied. Directly applying existing
segmentation networks often results in performance degradation as they cannot
overcome intrinsic problems in such environments, such as illumination changes.
In this paper, a built-in memory module for semantic segmentation is proposed
to overcome these problems. The memory module stores significant
representations of training images as memory items. In addition to the encoder
embedding like items together, the proposed memory module is specifically
designed to cluster together instances of the same class even when there are
significant variances in embedded features. Therefore, it makes segmentation
networks better deal with unexpected illumination changes. A triplet loss is
used in training to minimize redundancy in storing discriminative
representations of the memory module. The proposed memory module is general so
that it can be adopted in a variety of networks. We conduct experiments on the
Robot Unstructured Ground Driving (RUGD) dataset and RELLIS dataset, which are
collected from off-road, unstructured natural environments. Experimental
results show that the proposed memory module improves the performance of
existing segmentation networks and contributes to capturing unclear objects
over various off-road, unstructured natural scenes with equivalent
computational cost and network parameters. As the proposed method can be
integrated into compact networks, it presents a viable approach for
resource-limited small autonomous platforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iButter: Neural Interactive Bullet Time Generator for Human Free-viewpoint Rendering. (arXiv:2108.05577v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1">Pei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suo_X/0/1/0/all/0/1">Xin Suo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Minye Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jingyi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05577">
                                    <div class="article-summary-box-inner">
                                        <span>Generating &#x60;&#x60;bullet-time&#x27;&#x27; effects of human free-viewpoint videos is critical
for immersive visual effects and VR/AR experience. Recent neural advances still
lack the controllable and interactive bullet-time design ability for human
free-viewpoint rendering, especially under the real-time, dynamic and general
setting for our trajectory-aware task. To fill this gap, in this paper we
propose a neural interactive bullet-time generator (iButter) for
photo-realistic human free-viewpoint rendering from dense RGB streams, which
enables flexible and interactive design for human bullet-time visual effects.
Our iButter approach consists of a real-time preview and design stage as well
as a trajectory-aware refinement stage. During preview, we propose an
interactive bullet-time design approach by extending the NeRF rendering to a
real-time and dynamic setting and getting rid of the tedious per-scene
training. To this end, our bullet-time design stage utilizes a hybrid training
set, light-weight network design and an efficient silhouette-based sampling
strategy. During refinement, we introduce an efficient trajectory-aware scheme
within 20 minutes, which jointly encodes the spatial, temporal consistency and
semantic cues along the designed trajectory, achieving photo-realistic
bullet-time viewing experience of human activities. Extensive experiments
demonstrate the effectiveness of our approach for convenient interactive
bullet-time design and photo-realistic human free-viewpoint video generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal MRI Reconstruction with Spatial Alignment Network. (arXiv:2108.05603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xuan_K/0/1/0/all/0/1">Kai Xuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1">Lei Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaoqian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1">Dinggang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05603">
                                    <div class="article-summary-box-inner">
                                        <span>In clinical practice, magnetic resonance imaging (MRI) with multiple
contrasts is usually acquired in a single study to assess different properties
of the same region of interest in human body. The whole acquisition process can
be accelerated by having one or more modalities under-sampled in the k-space.
Recent researches demonstrate that, considering the redundancy between
different contrasts or modalities, a target MRI modality under-sampled in the
k-space can be better reconstructed with the helps from a fully-sampled
sequence (i.e., the reference modality). It implies that, in the same study of
the same subject, multiple sequences can be utilized together toward the
purpose of highly efficient multi-modal reconstruction. However, we find that
multi-modal reconstruction can be negatively affected by subtle spatial
misalignment between different sequences, which is actually common in clinical
practice. In this paper, we integrate the spatial alignment network with
reconstruction, to improve the quality of the reconstructed target modality.
Specifically, the spatial alignment network estimates the spatial misalignment
between the fully-sampled reference and the under-sampled target images, and
warps the reference image accordingly. Then, the aligned fully-sampled
reference image joins the under-sampled target image in the reconstruction
network, to produce the high-quality target image. Considering the contrast
difference between the target and the reference, we particularly design the
cross-modality-synthesis-based registration loss, in combination with the
reconstruction loss, to jointly train the spatial alignment network and the
reconstruction network. Our experiments on both clinical MRI and multi-coil
k-space raw data demonstrate the superiority and robustness of our spatial
alignment network. Code is publicly available at
https://github.com/woxuankai/SpatialAlignmentNetwork.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning for Irrigation Detection in Satellite Imagery. (arXiv:2108.05484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agastya_C/0/1/0/all/0/1">Chitra Agastya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghebremusse_S/0/1/0/all/0/1">Sirak Ghebremusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_I/0/1/0/all/0/1">Ian Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahabi_H/0/1/0/all/0/1">Hossein Vahabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Todeschini_A/0/1/0/all/0/1">Alberto Todeschini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05484">
                                    <div class="article-summary-box-inner">
                                        <span>Climate change has caused reductions in river runoffs and aquifer recharge
resulting in an increasingly unsustainable crop water demand from reduced
freshwater availability. Achieving food security while deploying water in a
sustainable manner will continue to be a major challenge necessitating careful
monitoring and tracking of agricultural water usage. Historically, monitoring
water usage has been a slow and expensive manual process with many
imperfections and abuses. Ma-chine learning and remote sensing developments
have increased the ability to automatically monitor irrigation patterns, but
existing techniques often require curated and labelled irrigation data, which
are expensive and time consuming to obtain and may not exist for impactful
areas such as developing countries. In this paper, we explore an end-to-end
real world application of irrigation detection with uncurated and unlabeled
satellite imagery. We apply state-of-the-art self-supervised deep learning
techniques to optical remote sensing data, and find that we are able to detect
irrigation with up to nine times better precision, 90% better recall and 40%
more generalization ability than the traditional supervised learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Voxel-level Importance Maps for Interpretable Brain Age Estimation. (arXiv:2108.05388v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bintsi_K/0/1/0/all/0/1">Kyriaki-Margarita Bintsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Baltatzis_V/0/1/0/all/0/1">Vasileios Baltatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammers_A/0/1/0/all/0/1">Alexander Hammers</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05388">
                                    <div class="article-summary-box-inner">
                                        <span>Brain aging, and more specifically the difference between the chronological
and the biological age of a person, may be a promising biomarker for
identifying neurodegenerative diseases. For this purpose accurate prediction is
important but the localisation of the areas that play a significant role in the
prediction is also crucial, in order to gain clinicians&#x27; trust and reassurance
about the performance of a prediction model. Most interpretability methods are
focused on classification tasks and cannot be directly transferred to
regression tasks. In this study, we focus on the task of brain age regression
from 3D brain Magnetic Resonance (MR) images using a Convolutional Neural
Network, termed prediction model. We interpret its predictions by extracting
importance maps, which discover the parts of the brain that are the most
important for brain age. In order to do so, we assume that voxels that are not
useful for the regression are resilient to noise addition. We implement a noise
model which aims to add as much noise as possible to the input without harming
the performance of the prediction model. We average the importance maps of the
subjects and end up with a population-based importance map, which displays the
regions of the brain that are influential for the task. We test our method on
13,750 3D brain MR images from the UK Biobank, and our findings are consistent
with the existing neuropathology literature, highlighting that the hippocampus
and the ventricles are the most relevant regions for brain aging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton. (arXiv:2108.05545v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wencan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Hyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jong Hwan Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05545">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing applications of 3D hand pose estimation in various
human-computer interaction applications, convolution neural networks (CNNs)
based estimation models have been actively explored. However, the existing
models require complex architectures or redundant computational resources to
trade with the acceptable accuracy. To tackle this limitation, this paper
proposes HandFoldingNet, an accurate and efficient hand pose estimator that
regresses the hand joint locations from the normalized 3D hand point cloud
input. The proposed model utilizes a folding-based decoder that folds a given
2D hand skeleton into the corresponding joint coordinates. For higher
estimation accuracy, folding is guided by multi-scale features, which include
both global and joint-wise local features. Experimental results show that the
proposed model outperforms the existing methods on three hand pose benchmark
datasets with the lowest model parameter requirement. Code is available at
https://github.com/cwc1260/HandFold.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Language Transformer and Query Generation for Referring Segmentation. (arXiv:2108.05565v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Henghui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suchen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xudong Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05565">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the challenging task of referring segmentation. The
query expression in referring segmentation typically indicates the target
object by describing its relationship with others. Therefore, to find the
target one among all instances in the image, the model must have a holistic
understanding of the whole image. To achieve this, we reformulate referring
segmentation as a direct attention problem: finding the region in the image
where the query language expression is most attended to. We introduce
transformer and multi-head attention to build a network with an encoder-decoder
attention mechanism architecture that &quot;queries&quot; the given image with the
language expression. Furthermore, we propose a Query Generation Module, which
produces multiple sets of queries with different attention weights that
represent the diversified comprehensions of the language expression from
different aspects. At the same time, to find the best way from these
diversified comprehensions based on visual clues, we further propose a Query
Balance Module to adaptively select the output features of these queries for a
better mask generation. Without bells and whistles, our approach is
light-weight and achieves new state-of-the-art performance consistently on
three referring segmentation datasets, RefCOCO, RefCOCO+, and G-Ref. Our code
is available at https://github.com/henghuiding/Vision-Language-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Pitfalls of Sample Selection: A Case Study on Lung Nodule Classification. (arXiv:2108.05386v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baltatzis_V/0/1/0/all/0/1">Vasileios Baltatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bintsi_K/0/1/0/all/0/1">Kyriaki-Margarita Bintsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Folgoc_L/0/1/0/all/0/1">Loic Le Folgoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzanera_O/0/1/0/all/0/1">Octavio E. Martinez Manzanera</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_S/0/1/0/all/0/1">Sam Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1">Arjun Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1">Sujal Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05386">
                                    <div class="article-summary-box-inner">
                                        <span>Using publicly available data to determine the performance of methodological
contributions is important as it facilitates reproducibility and allows
scrutiny of the published results. In lung nodule classification, for example,
many works report results on the publicly available LIDC dataset. In theory,
this should allow a direct comparison of the performance of proposed methods
and assess the impact of individual contributions. When analyzing seven recent
works, however, we find that each employs a different data selection process,
leading to largely varying total number of samples and ratios between benign
and malignant cases. As each subset will have different characteristics with
varying difficulty for classification, a direct comparison between the proposed
methods is thus not always possible, nor fair. We study the particular effect
of truthing when aggregating labels from multiple experts. We show that
specific choices can have severe impact on the data distribution where it may
be possible to achieve superior performance on one sample distribution but not
on another. While we show that we can further improve on the state-of-the-art
on one sample selection, we also find that on a more challenging sample
selection, on the same database, the more advanced models underperform with
respect to very simple baseline methods, highlighting that the selected data
distribution may play an even more important role than the model architecture.
This raises concerns about the validity of claimed methodological
contributions. We believe the community should be aware of these pitfalls and
make recommendations on how these can be avoided in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning. (arXiv:2108.05617v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junkai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1">Chaowei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weikai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1">Zhenhua Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaolin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1">Pengxu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05617">
                                    <div class="article-summary-box-inner">
                                        <span>Open-set semi-supervised learning (open-set SSL) investigates a challenging
but practical scenario where out-of-distribution (OOD) samples are contained in
the unlabeled data. While the mainstream technique seeks to completely filter
out the OOD samples for semi-supervised learning (SSL), we propose a novel
training mechanism that could effectively exploit the presence of OOD data for
enhanced feature learning while avoiding its adverse impact on the SSL. We
achieve this goal by first introducing a warm-up training that leverages all
the unlabeled data, including both the in-distribution (ID) and OOD samples.
Specifically, we perform a pretext task that enforces our feature extractor to
obtain a high-level semantic understanding of the training images, leading to
more discriminative features that can benefit the downstream tasks. Since the
OOD samples are inevitably detrimental to SSL, we propose a novel cross-modal
matching strategy to detect OOD samples. Instead of directly applying binary
classification, we train the network to predict whether the data sample is
matched to an assigned one-hot class label. The appeal of the proposed
cross-modal matching over binary classification is the ability to generate a
compatible feature space that aligns with the core classification task.
Extensive experiments show that our approach substantially lifts the
performance on open-set SSL and outperforms the state-of-the-art by a large
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patchwork: Concentric Zone-based Region-wise Ground Segmentation with Ground Likelihood Estimation Using a 3D LiDAR Sensor. (arXiv:2108.05560v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1">Hyungtae Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_M/0/1/0/all/0/1">Minho Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Myung_H/0/1/0/all/0/1">Hyun Myung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05560">
                                    <div class="article-summary-box-inner">
                                        <span>Ground segmentation is crucial for terrestrial mobile platforms to perform
navigation or neighboring object recognition. Unfortunately, the ground is not
flat, as it features steep slopes; bumpy roads; or objects, such as curbs,
flower beds, and so forth. To tackle the problem, this paper presents a novel
ground segmentation method called \textit{Patchwork}, which is robust for
addressing the under-segmentation problem and operates at more than 40 Hz. In
this paper, a point cloud is encoded into a Concentric Zone Model-based
representation to assign an appropriate density of cloud points among bins in a
way that is not computationally complex. This is followed by Region-wise Ground
Plane Fitting, which is performed to estimate the partial ground for each bin.
Finally, Ground Likelihood Estimation is introduced to dramatically reduce
false positives. As experimentally verified on SemanticKITTI and rough terrain
datasets, our proposed method yields promising performance compared with the
state-of-the-art methods, showing faster speed compared with existing plane
fitting--based methods. Code is available:
https://github.com/LimHyungTae/patchwork</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Trend Networks for Recommendations. (arXiv:2108.05552v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05552">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems aim to provide personalized services to users and are
playing an increasingly important role in our daily lives. The key of
recommender systems is to predict how likely users will interact with items
based on their historical online behaviors, e.g., clicks, add-to-cart,
purchases, etc. To exploit these user-item interactions, there are increasing
efforts on considering the user-item interactions as a user-item bipartite
graph and then performing information propagation in the graph via Graph Neural
Networks (GNNs). Given the power of GNNs in graph representation learning,
these GNN-based recommendation methods have remarkably boosted the
recommendation performance. Despite their success, most existing GNN-based
recommender systems overlook the existence of interactions caused by unreliable
behaviors (e.g., random/bait clicks) and uniformly treat all the interactions,
which can lead to sub-optimal and unstable performance. In this paper, we
investigate the drawbacks (e.g., non-adaptive propagation and non-robustness)
of existing GNN-based recommendation methods. To address these drawbacks, we
propose the Graph Trend Networks for recommendations (GTN) with principled
designs that can capture the adaptive reliability of the interactions.
Comprehensive experiments and ablation studies are presented to verify and
understand the effectiveness of the proposed framework. Our implementation and
datasets can be released after publication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Page-level Optimization of e-Commerce Item Recommendations. (arXiv:2108.05891v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1">Chieh Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1">Krutika Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changchen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kathy Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Platz_J/0/1/0/all/0/1">Justin Platz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilardi_A/0/1/0/all/0/1">Adam Ilardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhvanath_S/0/1/0/all/0/1">Sriganesh Madhvanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05891">
                                    <div class="article-summary-box-inner">
                                        <span>The item details page (IDP) is a web page on an e-commerce website that
provides information on a specific product or item listing. Just below the
details of the item on this page, the buyer can usually find recommendations
for other relevant items. These are typically in the form of a series of
modules or carousels, with each module containing a set of recommended items.
The selection and ordering of these item recommendation modules are intended to
increase discover-ability of relevant items and encourage greater user
engagement, while simultaneously showcasing diversity of inventory and
satisfying other business objectives. Item recommendation modules on the IDP
are often curated and statically configured for all customers, ignoring
opportunities for personalization. In this paper, we present a scalable
end-to-end production system to optimize the personalized selection and
ordering of item recommendation modules on the IDP in real-time by utilizing
deep neural networks. Through extensive offline experimentation and online A/B
testing, we show that our proposed system achieves significantly higher
click-through and conversion rates compared to other existing methods. In our
online A/B test, our framework improved click-through rate by 2.48% and
purchase-through rate by 7.34% over a static configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval. (arXiv:2108.05540v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Luyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1">Jamie Callan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05540">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research demonstrates the effectiveness of using fine-tuned language
models~(LM) for dense retrieval. However, dense retrievers are hard to train,
typically requiring heavily engineered fine-tuning pipelines to realize their
full potential. In this paper, we identify and address two underlying problems
of dense retrievers: i)~fragility to training data noise and ii)~requiring
large batches to robustly learn the embedding space. We use the recently
proposed Condenser pre-training architecture, which learns to condense
information into the dense vector through LM pre-training. On top of it, we
propose coCondenser, which adds an unsupervised corpus-level contrastive loss
to warm up the passage embedding space. Retrieval experiments on MS-MARCO,
Natural Question, and Trivia QA datasets show that coCondenser removes the need
for heavy data engineering such as augmentation, synthesis, or filtering, as
well as the need for large batch training. It shows comparable performance to
RocketQA, a state-of-the-art, heavily engineered system, using simple small
batch fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Sequential Slate Optimization. (arXiv:2108.05618v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Mingjian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Indrakanti_S/0/1/0/all/0/1">Saratchandra Indrakanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kannadasan_M/0/1/0/all/0/1">Manojkumar Rangasamy Kannadasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagherjeiran_A/0/1/0/all/0/1">Abraham Bagherjeiran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05618">
                                    <div class="article-summary-box-inner">
                                        <span>The top search results matching a user query that are displayed on the first
page are critical to the effectiveness and perception of a search system. A
search ranking system typically orders the results by independent
query-document scores to produce a slate of search results. However, such
unilateral scoring methods may fail to capture inter-document dependencies that
users are sensitive to, thus producing a sub-optimal slate. Further, in
practice, many real-world applications such as e-commerce search require
enforcing certain distributional criteria at the slate-level, due to business
objectives or long term user retention goals. Unilateral scoring of results
does not explicitly support optimizing for such objectives with respect to a
slate. Hence, solutions to the slate optimization problem must consider the
optimal selection and order of the documents, along with adherence to
slate-level distributional criteria. To that end, we propose a hybrid framework
extended from traditional slate optimization to solve the conditional slate
optimization problem. We introduce conditional sequential slate optimization
(CSSO), which jointly learns to optimize for traditional ranking metrics as
well as prescribed distribution criteria of documents within the slate. The
proposed method can be applied to practical real world problems such as
enforcing diversity in e-commerce search results, mitigating bias in top
results and personalization of results. Experiments on public datasets and
real-world data from e-commerce datasets show that CSSO outperforms popular
comparable ranking methods in terms of adherence to distributional criteria
while producing comparable or better relevance metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridger: Toward Bursting Scientific Filter Bubbles and Boosting Innovation via Novel Author Discovery. (arXiv:2108.05669v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portenoy_J/0/1/0/all/0/1">Jason Portenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radensky_M/0/1/0/all/0/1">Marissa Radensky</a>, <a href="http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1">Jevin West</a>, <a href="http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1">Eric Horvitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1">Daniel Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05669">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific silos can hinder innovation. These information &quot;filter bubbles&quot;
and the growing challenge of information overload limit awareness across the
literature, making it difficult to keep track of even narrow areas of interest,
let alone discover new ones. Algorithmic curation and recommendation, which
often prioritize relevance, can further reinforce these bubbles. In response,
we describe Bridger, a system for facilitating discovery of scholars and their
work, to explore design tradeoffs among relevant and novel recommendations. We
construct a faceted representation of authors using information extracted from
their papers and inferred personas. We explore approaches both for recommending
new content and for displaying it in a manner that helps researchers to
understand the work of authors who they are unfamiliar with. In studies with
computer science researchers, our approach substantially improves users&#x27;
abilities to do so. We develop an approach that locates commonalities and
contrasts between scientists---retrieving partially similar authors, rather
than aiming for strict similarity. We find this approach helps users discover
authors useful for generating novel research ideas of relevance to their work,
at a higher rate than a state-of-art neural model. Our analysis reveals that
Bridger connects authors who have different citation profiles, publish in
different venues, and are more distant in social co-authorship networks,
raising the prospect of bridging diverse communities and facilitating
discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locality Sensitive Hashing with Extended Differential Privacy. (arXiv:2010.09393v5 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_N/0/1/0/all/0/1">Natasha Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawamoto_Y/0/1/0/all/0/1">Yusuke Kawamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1">Takao Murakami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09393">
                                    <div class="article-summary-box-inner">
                                        <span>Extended differential privacy, a generalization of standard differential
privacy (DP) using a general metric, has been widely studied to provide
rigorous privacy guarantees while keeping high utility. However, existing works
on extended DP are limited to few metrics, such as the Euclidean metric.
Consequently, they have only a small number of applications, such as
location-based services and document processing. In this paper, we propose a
couple of mechanisms providing extended DP with a different metric: angular
distance (or cosine distance). Our mechanisms are based on locality sensitive
hashing (LSH), which can be applied to the angular distance and work well for
personal data in a high-dimensional space. We theoretically analyze the privacy
properties of our mechanisms, and prove extended DP for input data by taking
into account that LSH preserves the original metric only approximately. We
apply our mechanisms to friend matching based on high-dimensional personal data
with angular distance in the local model, and evaluate our mechanisms using two
real datasets. We show that LDP requires a very large privacy budget and that
RAPPOR does not work in this application. Then we show that our mechanisms
enable friend matching with high utility and rigorous privacy guarantees based
on extended DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Session-based Recommendation with Heterogeneous Graph Neural Network. (arXiv:2108.05641v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haiyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Senzhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1">Kaimin Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05641">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of the Session-Based Recommendation System is to predict the
user&#x27;s next click according to the previous session sequence. The current
studies generally learn user preferences according to the transitions of items
in the user&#x27;s session sequence. However, other effective information in the
session sequence, such as user profiles, are largely ignored which may lead to
the model unable to learn the user&#x27;s specific preferences. In this paper, we
propose a heterogeneous graph neural network-based session recommendation
method, named SR-HetGNN, which can learn session embeddings by heterogeneous
graph neural network (HetGNN), and capture the specific preferences of
anonymous users. Specifically, SR-HetGNN first constructs heterogeneous graphs
containing various types of nodes according to the session sequence, which can
capture the dependencies among items, users, and sessions. Second, HetGNN
captures the complex transitions between items and learns the item embeddings
containing user information. Finally, to consider the influence of users&#x27; long
and short-term preferences, local and global session embeddings are combined
with the attentional network to obtain the final session embedding. SR-HetGNN
is shown to be superior to the existing state-of-the-art session-based
recommendation methods through extensive experiments over two real large
datasets Diginetica and Tmall.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Analysis on Transparent Algorithmic Exploration in Recommender Systems. (arXiv:2108.00151v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kihwan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00151">
                                    <div class="article-summary-box-inner">
                                        <span>All learning algorithms for recommendations face inevitable and critical
trade-off between exploiting partial knowledge of a user&#x27;s preferences for
short-term satisfaction and exploring additional user preferences for long-term
coverage. Although exploration is indispensable for long success of a
recommender system, the exploration has been considered as the risk to decrease
user satisfaction. The reason for the risk is that items chosen for exploration
frequently mismatch with the user&#x27;s interests. To mitigate this risk,
recommender systems have mixed items chosen for exploration into a
recommendation list, disguising the items as recommendations to elicit feedback
on the items to discover the user&#x27;s additional tastes. This mix-in approach has
been widely used in many recommenders, but there is rare research, evaluating
the effectiveness of the mix-in approach or proposing a new approach for
eliciting user feedback without deceiving users. In this work, we aim to
propose a new approach for feedback elicitation without any deception and
compare our approach to the conventional mix-in approach for evaluation. To
this end, we designed a recommender interface that reveals which items are for
exploration and conducted a within-subject study with 94 MTurk workers. Our
results indicated that users left significantly more feedback on items chosen
for exploration with our interface. Besides, users evaluated that our new
interface is better than the conventional mix-in interface in terms of novelty,
diversity, transparency, trust, and satisfaction. Finally, path analysis show
that, in only our new interface, exploration caused to increase user-centric
evaluation metrics. Our work paves the way for how to design an interface,
which utilizes learning algorithm based on users&#x27; feedback signals, giving
better user experience and gathering more feedback data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Relevance Ranking under the Pre-training and Fine-tuning Paradigm. (arXiv:2108.05652v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Lin Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1">Liang Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">XiuQiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05652">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pre-trained language models such as BERT have been applied to
document ranking for information retrieval, which first pre-train a general
language model on an unlabeled large corpus and then conduct ranking-specific
fine-tuning on expert-labeled relevance datasets. Ideally, an IR system would
model relevance from a user-system dualism: the user&#x27;s view and the system&#x27;s
view. User&#x27;s view judges the relevance based on the activities of &quot;real users&quot;
while the system&#x27;s view focuses on the relevance signals from the system side,
e.g., from the experts or algorithms, etc. Inspired by the user-system
relevance views and the success of pre-trained language models, in this paper
we propose a novel ranking framework called Pre-Rank that takes both user&#x27;s
view and system&#x27;s view into consideration, under the pre-training and
fine-tuning paradigm. Specifically, to model the user&#x27;s view of relevance,
Pre-Rank pre-trains the initial query-document representations based on
large-scale user activities data such as the click log. To model the system&#x27;s
view of relevance, Pre-Rank further fine-tunes the model on expert-labeled
relevance data. More importantly, the pre-trained representations, are
fine-tuned together with handcrafted learning-to-rank features under a wide and
deep network architecture. In this way, Pre-Rank can model the relevance by
incorporating the relevant knowledge and signals from both real search users
and the IR experts. To verify the effectiveness of Pre-Rank, we showed two
implementations by using BERT and SetRank as the underlying ranking model,
respectively. Experimental results base on three publicly available benchmarks
showed that in both of the implementations, Pre-Rank can respectively
outperform the underlying ranking models and achieved state-of-the-art
performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ontology drift is a challenge for explainable data governance. (arXiv:2108.05401v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05401">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the needs for explainable AI that arise from Standard No. 239
from the Basel Committee on Banking Standards (BCBS 239), which outlines 11
principles for effective risk data aggregation and risk reporting for financial
institutions. Of these, explainableAI is necessary for compliance in two key
aspects: data quality, and appropriate reporting for multiple stakeholders. We
describe the implementation challenges for one specific regulatory
requirement:that of having a complete data taxonomy that is appropriate for
firmwide use. The constantly evolving nature of financial ontologies
necessitate a continuous updating process to ensure ongoing compliance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Microlocal Reconstruction for Limited-Angle Tomography. (arXiv:2108.05732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andrade_Loarca_H/0/1/0/all/0/1">H&#xe9;ctor Andrade-Loarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1">Gitta Kutyniok</a>, <a href="http://arxiv.org/find/cs/1/au:+Oktem_O/0/1/0/all/0/1">Ozan &#xd6;ktem</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Philipp Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning-based algorithm to jointly solve a reconstruction
problem and a wavefront set extraction problem in tomographic imaging. The
algorithm is based on a recently developed digital wavefront set extractor as
well as the well-known microlocal canonical relation for the Radon transform.
We use the wavefront set information about x-ray data to improve the
reconstruction by requiring that the underlying neural networks simultaneously
extract the correct ground truth wavefront set and ground truth image. As a
necessary theoretical step, we identify the digital microlocal canonical
relations for deep convolutional residual neural networks. We find strong
numerical evidence for the effectiveness of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MicroNet: Improving Image Recognition with Extremely Low FLOPs. (arXiv:2108.05894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1">Nuno Vasconcelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05894">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims at addressing the problem of substantial performance
degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet
classification). We found that two factors, sparse connectivity and dynamic
activation function, are effective to improve the accuracy. The former avoids
the significant reduction of network width, while the latter mitigates the
detriment of reduction in network depth. Technically, we propose
micro-factorized convolution, which factorizes a convolution matrix into low
rank matrices, to integrate sparse connectivity into convolution. We also
present a new dynamic activation function, named Dynamic Shift Max, to improve
the non-linearity via maxing out multiple dynamic fusions between an input
feature map and its circular channel shift. Building upon these two new
operators, we arrive at a family of networks, named MicroNet, that achieves
significant performance gains over the state of the art in the low FLOP regime.
For instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\% top-1
accuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\%. Source
code is at
\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Lexically Constrained Neural Machine Translation with Source-Conditioned Masked Span Prediction. (arXiv:2105.05498v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gyubok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seongjun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05498">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate terminology translation is crucial for ensuring the practicality and
reliability of neural machine translation (NMT) systems. To address this,
lexically constrained NMT explores various methods to ensure pre-specified
words and phrases appear in the translation output. However, in many cases,
those methods are studied on general domain corpora, where the terms are mostly
uni- and bi-grams (&gt;98%). In this paper, we instead tackle a more challenging
setup consisting of domain-specific corpora with much longer n-gram and highly
specialized terms. Inspired by the recent success of masked span prediction
models, we propose a simple and effective training strategy that achieves
consistent improvements on both terminology and sentence-level translation for
three domain-specific corpora in two language pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Neural Information Fusion Architecture for Textual Network Embeddings. (arXiv:1908.11057v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qinliang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weijia Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.11057">
                                    <div class="article-summary-box-inner">
                                        <span>Textual network embeddings aim to learn a low-dimensional representation for
every node in the network so that both the structural and textual information
from the networks can be well preserved in the representations. Traditionally,
the structural and textual embeddings were learned by models that rarely take
the mutual influences between them into account. In this paper, a deep neural
architecture is proposed to effectively fuse the two kinds of informations into
one representation. The novelties of the proposed architecture are manifested
in the aspects of a newly defined objective function, the complementary
information fusion method for structural and textual features, and the mutual
gate mechanism for textual feature extraction. Experimental results show that
the proposed model outperforms the comparing methods on all three datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing the State of the Art: A Critical Look at Visual Representation Evaluation. (arXiv:1912.00215v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1">Cinjon Resnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1">Zeping Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00215">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised research improved greatly over the past half decade, with
much of the growth being driven by objectives that are hard to quantitatively
compare. These techniques include colorization, cyclical consistency, and
noise-contrastive estimation from image patches. Consequently, the field has
settled on a handful of measurements that depend on linear probes to adjudicate
which approaches are the best. Our first contribution is to show that this test
is insufficient and that models which perform poorly (strongly) on linear
classification can perform strongly (weakly) on more involved tasks like
temporal activity localization. Our second contribution is to analyze the
capabilities of five different representations. And our third contribution is a
much needed new dataset for temporal activity localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeanML: A Design Pattern To Slash Avoidable Wastes in Machine Learning Projects. (arXiv:2107.08066v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samo_Y/0/1/0/all/0/1">Yves-Laurent Kom Samo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08066">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first application of the lean methodology to machine
learning projects. Similar to lean startups and lean manufacturing, we argue
that lean machine learning (LeanML) can drastically slash avoidable wastes in
commercial machine learning projects, reduce the business risk in investing in
machine learning capabilities and, in so doing, further democratize access to
machine learning. The lean design pattern we propose in this paper is based on
two realizations. First, it is possible to estimate the best performance one
may achieve when predicting an outcome $y \in \mathcal{Y}$ using a given set of
explanatory variables $x \in \mathcal{X}$, for a wide range of performance
metrics, and without training any predictive model. Second, doing so is
considerably easier, faster, and cheaper than learning the best predictive
model. We derive formulae expressing the best $R^2$, MSE, classification
accuracy, and log-likelihood per observation achievable when using $x$ to
predict $y$ as a function of the mutual information $I\left(y; x\right)$, and
possibly a measure of the variability of $y$ (e.g. its Shannon entropy in the
case of classification accuracy, and its variance in the case regression MSE).
We illustrate the efficacy of the LeanML design pattern on a wide range of
regression and classification problems, synthetic and real-life.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping the &quot;Impossibility of Fairness&quot;: From Formal to Substantive Algorithmic Fairness. (arXiv:2107.04642v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Green_B/0/1/0/all/0/1">Ben Green</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04642">
                                    <div class="article-summary-box-inner">
                                        <span>In the face of compounding crises of social and economic inequality, many
have turned to algorithmic decision-making to achieve greater fairness in
society. As these efforts intensify, reasoning within the burgeoning field of
&quot;algorithmic fairness&quot; increasingly shapes how fairness manifests in practice.
This paper interrogates whether algorithmic fairness provides the appropriate
conceptual and practical tools for enhancing social equality. I argue that the
dominant, &quot;formal&quot; approach to algorithmic fairness is ill-equipped as a
framework for pursuing equality, as its narrow frame of analysis generates
restrictive approaches to reform. In light of these shortcomings, I propose an
alternative: a &quot;substantive&quot; approach to algorithmic fairness that centers
opposition to social hierarchies and provides a more expansive analysis of how
to address inequality. This substantive approach enables more fruitful
theorizing about the role of algorithms in combatting oppression. The
distinction between formal and substantive algorithmic fairness is exemplified
by each approach&#x27;s responses to the &quot;impossibility of fairness&quot; (an
incompatibility between mathematical definitions of algorithmic fairness).
While the formal approach requires us to accept the &quot;impossibility of fairness&quot;
as a harsh limit on efforts to enhance equality, the substantive approach
allows us to escape the &quot;impossibility of fairness&quot; by suggesting reforms that
are not subject to this false dilemma and that are better equipped to
ameliorate conditions of social oppression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Stochastic Block Model for Community Detection in Multiplex Networks. (arXiv:1904.05330v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Arash A. Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Paez_M/0/1/0/all/0/1">Marina S. Paez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lizhen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.05330">
                                    <div class="article-summary-box-inner">
                                        <span>Multiplex networks have become increasingly more prevalent in many fields,
and have emerged as a powerful tool for modeling the complexity of real
networks. There is a critical need for developing inference models for
multiplex networks that can take into account potential dependencies across
different layers, particularly when the aim is community detection. We add to a
limited literature by proposing a novel and efficient Bayesian model for
community detection in multiplex networks. A key feature of our approach is the
ability to model varying communities at different network layers. In contrast,
many existing models assume the same communities for all layers. Moreover, our
model automatically picks up the necessary number of communities at each layer
(as validated by real data examples). This is appealing, since deciding the
number of communities is a challenging aspect of community detection, and
especially so in the multiplex setting, if one allows the communities to change
across layers. Borrowing ideas from hierarchical Bayesian modeling, we use a
hierarchical Dirichlet prior to model community labels across layers, allowing
dependency in their structure. Given the community labels, a stochastic block
model (SBM) is assumed for each layer. We develop an efficient slice sampler
for sampling the posterior distribution of the community labels as well as the
link probabilities between communities. In doing so, we address some unique
challenges posed by coupling the complex likelihood of SBM with the
hierarchical nature of the prior on the labels. An extensive empirical
validation is performed on simulated and real data, demonstrating the superior
performance of the model over single-layer alternatives, as well as the ability
to uncover interesting structures in real networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation. (arXiv:2010.05903v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Niv Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_L/0/1/0/all/0/1">Liron Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection methods require high-quality features. In recent years, the
anomaly detection community has attempted to obtain better features using
advances in deep self-supervised feature learning. Surprisingly, a very
promising direction, using pretrained deep features, has been mostly
overlooked. In this paper, we first empirically establish the perhaps expected,
but unreported result, that combining pretrained features with simple anomaly
detection and segmentation methods convincingly outperforms, much more complex,
state-of-the-art methods.

In order to obtain further performance gains in anomaly detection, we adapt
pretrained features to the target distribution. Although transfer learning
methods are well established in multi-class classification problems, the
one-class classification (OCC) setting is not as well explored. It turns out
that naive adaptation methods, which typically work well in supervised
learning, often result in catastrophic collapse (feature deterioration) and
reduce performance in OCC settings. A popular OCC method, DeepSVDD, advocates
using specialized architectures, but this limits the adaptation performance
gain. We propose two methods for combating collapse: i) a variant of early
stopping that dynamically learns the stopping iteration ii) elastic
regularization inspired by continual learning. Our method, PANDA, outperforms
the state-of-the-art in the OCC, outlier exposure and anomaly segmentation
settings by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Depth-Based Estimation of Object Articulation Models. (arXiv:2108.05875v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ajinkya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Giguere_S/0/1/0/all/0/1">Stephen Giguere</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1">Rudolf Lioutikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05875">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method that efficiently learns distributions over articulation
model parameters directly from depth images without the need to know
articulation model categories a priori. By contrast, existing methods that
learn articulation models from raw observations typically only predict point
estimates of the model parameters, which are insufficient to guarantee the safe
manipulation of articulated objects. Our core contributions include a novel
representation for distributions over rigid body transformations and
articulation model parameters based on screw theory, von Mises-Fisher
distributions, and Stiefel manifolds. Combining these concepts allows for an
efficient, mathematically sound representation that implicitly satisfies the
constraints that rigid body transformations and articulations must adhere to.
Leveraging this representation, we introduce a novel deep learning based
approach, DUST-net, that performs category-independent articulation model
estimation while also providing model uncertainties. We evaluate our approach
on several benchmarking datasets and real-world objects and compare its
performance with two current state-of-the-art methods. Our results demonstrate
that DUST-net can successfully learn distributions over articulation models for
novel objects across articulation model categories, which generate point
estimates with better accuracy than state-of-the-art methods and effectively
capture the uncertainty over predicted model parameters due to noisy inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation. (arXiv:2106.04096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04096">
                                    <div class="article-summary-box-inner">
                                        <span>Natural policy gradient (NPG) methods with function approximation achieve
impressive empirical success in reinforcement learning problems with large
state-action spaces. However, theoretical understanding of their convergence
behaviors remains limited in the function approximation setting. In this paper,
we perform a finite-time analysis of NPG with linear function approximation and
softmax parameterization, and prove for the first time that widely used entropy
regularization method, which encourages exploration, leads to linear
convergence rate. Under considerably weaker regularity conditions, we prove
that entropy-regularized Q-NPG variant with linear function approximation
achieves $\tilde{O}(1/T)$ convergence rate. We adopt a Lyapunov drift analysis
to prove the convergence results and explain the effectiveness of entropy
regularization in improving the convergence rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication Optimization in Large Scale Federated Learning using Autoencoder Compressed Weight Updates. (arXiv:2108.05670v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Srikanth Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandran_P/0/1/0/all/0/1">Pravin Chandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1">Raghavendra Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_A/0/1/0/all/0/1">Avinash Chakravarthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05670">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) solves many of this decade&#x27;s concerns regarding data
privacy and computation challenges. FL ensures no data leaves its source as the
model is trained at where the data resides. However, FL comes with its own set
of challenges. The communication of model weight updates in this distributed
environment comes with significant network bandwidth costs. In this context, we
propose a mechanism of compressing the weight updates using Autoencoders (AE),
which learn the data features of the weight updates and subsequently perform
compression. The encoder is set up on each of the nodes where the training is
performed while the decoder is set up on the node where the weights are
aggregated. This setup achieves compression through the encoder and recreates
the weights at the end of every communication round using the decoder. This
paper shows that the dynamic and orthogonal AE based weight compression
technique could serve as an advantageous alternative (or an add-on) in a large
scale FL, as it not only achieves compression ratios ranging from 500x to 1720x
and beyond, but can also be modified based on the accuracy requirements,
computational capacity, and other requirements of the given FL setup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation. (arXiv:2011.06294v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhewei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1">Wen Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuchang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06294">
                                    <div class="article-summary-box-inner">
                                        <span>We propose RIFE, a Real-time Intermediate Flow Estimation algorithm for Video
Frame Interpolation (VFI). Many recent flow-based VFI methods first estimate
the bi-directional optical flows, then scale and reverse them to approximate
intermediate flows, leading to artifacts on motion boundaries. RIFE uses a
neural network named IFNet that can directly estimate the intermediate flows
from coarse-to-fine with much better speed. We design a privileged distillation
scheme for training intermediate flow model, which leads to a large performance
improvement. Experiments demonstrate that RIFE is flexible and can achieve
state-of-the-art performance on several public benchmarks. The code is
available at \url{https://github.com/hzwer/arXiv2020-RIFE}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Analysis on Transparent Algorithmic Exploration in Recommender Systems. (arXiv:2108.00151v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kihwan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00151">
                                    <div class="article-summary-box-inner">
                                        <span>All learning algorithms for recommendations face inevitable and critical
trade-off between exploiting partial knowledge of a user&#x27;s preferences for
short-term satisfaction and exploring additional user preferences for long-term
coverage. Although exploration is indispensable for long success of a
recommender system, the exploration has been considered as the risk to decrease
user satisfaction. The reason for the risk is that items chosen for exploration
frequently mismatch with the user&#x27;s interests. To mitigate this risk,
recommender systems have mixed items chosen for exploration into a
recommendation list, disguising the items as recommendations to elicit feedback
on the items to discover the user&#x27;s additional tastes. This mix-in approach has
been widely used in many recommenders, but there is rare research, evaluating
the effectiveness of the mix-in approach or proposing a new approach for
eliciting user feedback without deceiving users. In this work, we aim to
propose a new approach for feedback elicitation without any deception and
compare our approach to the conventional mix-in approach for evaluation. To
this end, we designed a recommender interface that reveals which items are for
exploration and conducted a within-subject study with 94 MTurk workers. Our
results indicated that users left significantly more feedback on items chosen
for exploration with our interface. Besides, users evaluated that our new
interface is better than the conventional mix-in interface in terms of novelty,
diversity, transparency, trust, and satisfaction. Finally, path analysis show
that, in only our new interface, exploration caused to increase user-centric
evaluation metrics. Our work paves the way for how to design an interface,
which utilizes learning algorithm based on users&#x27; feedback signals, giving
better user experience and gathering more feedback data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Testing Autonomous Systems with Believed Equivalence Refinement. (arXiv:2103.04578v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Chih-Hong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rongjie Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04578">
                                    <div class="article-summary-box-inner">
                                        <span>Continuous engineering of autonomous driving functions commonly requires
deploying vehicles in road testing to obtain inputs that cause problematic
decisions. Although the discovery leads to producing an improved system, it
also challenges the foundation of testing using equivalence classes and the
associated relative test coverage criterion. In this paper, we propose believed
equivalence, where the establishment of an equivalence class is initially based
on expert belief and is subject to a set of available test cases having a
consistent valuation. Upon a newly encountered test case that breaks the
consistency, one may need to refine the established categorization in order to
split the originally believed equivalence into two. Finally, we focus on
modules implemented using deep neural networks where every category partitions
an input over the real domain. We present both analytical and lazy methods to
suggest the refinement. The concept is demonstrated in analyzing multiple
autonomous driving modules, indicating the potential of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal analysis of the predictability of hand-gesture properties. (arXiv:2108.05762v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05762">
                                    <div class="article-summary-box-inner">
                                        <span>Embodied conversational agents benefit from being able to accompany their
speech with gestures. Although many data-driven approaches to gesture
generation have been proposed in recent years, it is still unclear whether such
systems can consistently generate gestures that convey meaning. We investigate
which gesture properties (phase, category, and semantics) can be predicted from
speech text and/or audio using contemporary deep learning. In extensive
experiments, we show that gesture properties related to gesture meaning
(semantics and category) are predictable from text features (time-aligned BERT
embeddings) alone, but not from prosodic audio features, while rhythm-related
gesture properties (phase) on the other hand can be predicted from either
audio, text (with word-level timing information), or both. These results are
encouraging as they indicate that it is possible to equip an embodied agent
with content-wise meaningful co-speech gestures using a machine-learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning-Based Control via Bootstrapped Multiplicative Noise. (arXiv:2002.10069v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gravell_B/0/1/0/all/0/1">Benjamin Gravell</a>, <a href="http://arxiv.org/find/cs/1/au:+Summers_T/0/1/0/all/0/1">Tyler Summers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.10069">
                                    <div class="article-summary-box-inner">
                                        <span>Despite decades of research and recent progress in adaptive control and
reinforcement learning, there remains a fundamental lack of understanding in
designing controllers that provide robustness to inherent non-asymptotic
uncertainties arising from models estimated with finite, noisy data. We propose
a robust adaptive control algorithm that explicitly incorporates such
non-asymptotic uncertainties into the control design. The algorithm has three
components: (1) a least-squares nominal model estimator; (2) a bootstrap
resampling method that quantifies non-asymptotic variance of the nominal model
estimate; and (3) a non-conventional robust control design method using an
optimal linear quadratic regulator (LQR) with multiplicative noise. A key
advantage of the proposed approach is that the system identification and robust
control design procedures both use stochastic uncertainty representations, so
that the actual inherent statistical estimation uncertainty directly aligns
with the uncertainty the robust controller is being designed against. We show
through numerical experiments that the proposed robust adaptive controller can
significantly outperform the certainty equivalent controller on both expected
regret and measures of regret risk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Discretization for Adversarial Lipschitz Bandits. (arXiv:2006.12367v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1">Chara Podimata</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12367">
                                    <div class="article-summary-box-inner">
                                        <span>Lipschitz bandits is a prominent version of multi-armed bandits that studies
large, structured action spaces such as the [0,1] interval, where similar
actions are guaranteed to have similar rewards. A central theme here is the
adaptive discretization of the action space, which gradually &#x60;&#x60;zooms in&#x27;&#x27; on
the more promising regions thereof. The goal is to take advantage of &#x60;&#x60;nicer&#x27;&#x27;
problem instances, while retaining near-optimal worst-case performance. While
the stochastic version of the problem is well-understood, the general version
with adversarial rewards is not. We provide the first algorithm for adaptive
discretization in the adversarial version, and derive instance-dependent regret
bounds. In particular, we recover the worst-case optimal regret bound for the
adversarial version, and the instance-dependent regret bound for the stochastic
version. Further, an application of our algorithm to dynamic pricing (where a
seller repeatedly adjusts prices for a product) enjoys these regret bounds
without any smoothness assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reimagining an autonomous vehicle. (arXiv:2108.05805v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hawke_J/0/1/0/all/0/1">Jeffrey Hawke</a>, <a href="http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1">Haibo E</a>, <a href="http://arxiv.org/find/cs/1/au:+Badrinarayanan_V/0/1/0/all/0/1">Vijay Badrinarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1">Alex Kendall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05805">
                                    <div class="article-summary-box-inner">
                                        <span>The self driving challenge in 2021 is this century&#x27;s technological equivalent
of the space race, and is now entering the second major decade of development.
Solving the technology will create social change which parallels the invention
of the automobile itself. Today&#x27;s autonomous driving technology is laudable,
though rooted in decisions made a decade ago. We argue that a rethink is
required, reconsidering the autonomous vehicle (AV) problem in the light of the
body of knowledge that has been gained since the DARPA challenges which seeded
the industry. What does AV2.0 look like? We present an alternative vision: a
recipe for driving with machine learning, and grand challenges for research in
driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. (arXiv:2102.06387v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1">Peter Kairouz</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06387">
                                    <div class="article-summary-box-inner">
                                        <span>We consider training models on private data that are distributed across user
devices. To ensure privacy, we add on-device noise and use secure aggregation
so that only the noisy sum is revealed to the server. We present a
comprehensive end-to-end system, which appropriately discretizes the data and
adds discrete Gaussian noise before performing secure aggregation. We provide a
novel privacy analysis for sums of discrete Gaussians and carefully analyze the
effects of data quantization and modular summation arithmetic. Our theoretical
guarantees highlight the complex tension between communication, privacy, and
accuracy. Our extensive experimental results demonstrate that our solution is
essentially able to match the accuracy to central differential privacy with
less than 16 bits of precision per value.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning: A Field Experiment. (arXiv:1912.02572v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaxi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yidong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuming Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xingyu Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02572">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present an end-to-end framework for addressing the problem
of dynamic pricing (DP) on E-commerce platform using methods based on deep
reinforcement learning (DRL). By using four groups of different business data
to represent the states of each time period, we model the dynamic pricing
problem as a Markov Decision Process (MDP). Compared with the state-of-the-art
DRL-based dynamic pricing algorithms, our approaches make the following three
contributions. First, we extend the discrete set problem to the continuous
price set. Second, instead of using revenue as the reward function directly, we
define a new function named difference of revenue conversion rates (DRCR).
Third, the cold-start problem of MDP is tackled by pre-training and evaluation
using some carefully chosen historical sales data. Our approaches are evaluated
by both offline evaluation method using real dataset of Alibaba Inc., and
online field experiments starting from July 2018 with thousands of items,
lasting for months on Tmall.com. To our knowledge, there is no other DP field
experiment using DRL before. Field experiment results suggest that DRCR is a
more appropriate reward function than revenue, which is widely used by current
literature. Also, continuous price sets have better performance than discrete
sets and our approaches significantly outperformed the manual pricing by
operation experts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructing Multiclass Classifiers using Binary Classifiers Under Log-Loss. (arXiv:2102.08184v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Yishai_A/0/1/0/all/0/1">Assaf Ben-Yishai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordentlich_O/0/1/0/all/0/1">Or Ordentlich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08184">
                                    <div class="article-summary-box-inner">
                                        <span>The construction of multiclass classifiers from binary elements is studied in
this paper, and performance is quantified by the regret, defined with respect
to the Bayes optimal log-loss. We discuss two known methods. The first is one
vs. all (OVA), for which we prove that the multiclass regret is upper bounded
by the sum of binary regrets of the constituent classifiers. The second is
hierarchical classification, based on a binary tree. For this method we prove
that the multiclass regret is exactly a weighted sum of constituent binary
regrets where the weighing is determined by the tree structure.

We also introduce a leverage-hierarchical classification method, which
potentially yields smaller log-loss and regret. The advantages of these
classification methods are demonstrated by simulation on both synthetic and
real-life datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning and Slicing Neural Networks using Formal Verification. (arXiv:2105.13649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lahav_O/0/1/0/all/0/1">Ori Lahav</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1">Guy Katz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) play an increasingly important role in various
computer systems. In order to create these networks, engineers typically
specify a desired topology, and then use an automated training algorithm to
select the network&#x27;s weights. While training algorithms have been studied
extensively and are well understood, the selection of topology remains a form
of art, and can often result in networks that are unnecessarily large - and
consequently are incompatible with end devices that have limited memory,
battery or computational power. Here, we propose to address this challenge by
harnessing recent advances in DNN verification. We present a framework and a
methodology for discovering redundancies in DNNs - i.e., for finding neurons
that are not needed, and can be removed in order to reduce the size of the DNN.
By using sound verification techniques, we can formally guarantee that our
simplified network is equivalent to the original, either completely, or up to a
prescribed tolerance. Further, we show how to combine our technique with
slicing, which results in a family of very small DNNs, which are together
equivalent to the original. Our approach can produce DNNs that are
significantly smaller than the original, rendering them suitable for deployment
on additional kinds of systems, and even more amenable to subsequent formal
verification. We provide a proof-of-concept implementation of our approach, and
use it to evaluate our techniques on several real-world DNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DANA: Dimension-Adaptive Neural Architecture for Multivariate Sensor Data. (arXiv:2008.02397v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1">Mohammad Malekzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Clegg_R/0/1/0/all/0/1">Richard G. Clegg</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1">Hamed Haddadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02397">
                                    <div class="article-summary-box-inner">
                                        <span>Motion sensors embedded in wearable and mobile devices allow for dynamic
selection of sensor streams and sampling rates, enabling several applications,
such as power management and data-sharing control. While deep neural networks
(DNNs) achieve competitive accuracy in sensor data classification, DNNs
generally process incoming data from a fixed set of sensors with a fixed
sampling rate, and changes in the dimensions of their inputs cause considerable
accuracy loss, unnecessary computations, or failure in operation. We introduce
a dimension-adaptive pooling (DAP) layer that makes DNNs flexible and more
robust to changes in sensor availability and in sampling rate. DAP operates on
convolutional filter maps of variable dimensions and produces an input of fixed
dimensions suitable for feedforward and recurrent layers. We also propose a
dimension-adaptive training (DAT) procedure for enabling DNNs that use DAP to
better generalize over the set of feasible data dimensions at inference time.
DAT comprises the random selection of dimensions during the forward passes and
optimization with accumulated gradients of several backward passes. Combining
DAP and DAT, we show how to transform non-adaptive DNNs into a
Dimension-Adaptive Neural Architecture (DANA), while keeping the same number of
parameters. Compared to existing approaches, our solution provides better
classification accuracy over the range of possible data dimensions at inference
time and does not require up-sampling or imputation, thus reducing unnecessary
computations. Experiments on seven datasets (four benchmark real-world datasets
for human activity recognition and three synthetic datasets) show that DANA
prevents significant losses in classification accuracy of the state-of-the-art
DNNs and, compared to baselines, it better captures correlated patterns in
sensor data under dynamic sensor availability and varying sampling rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ubiquitous Acoustic Sensing on Commodity IoT Devices: A Survey. (arXiv:1901.03450v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Rong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.03450">
                                    <div class="article-summary-box-inner">
                                        <span>With the proliferation of Internet-of-Things devices, acoustic sensing
attracts much attention in recent years. It exploits acoustic transceivers such
as microphones and speakers beyond their primary functions, namely recording
and playing, to enable novel applications and new user experiences. In this
paper, we present the first systematic survey of recent advances in active
acoustic sensing using commodity hardware with a frequency range below
24~\!kHz. We propose a general framework that categorizes main building blocks
of acoustic sensing systems. This framework encompasses three layers, i.e.,
physical layer, core technique layer, and application layer. The physical layer
includes basic hardware components, acoustic platforms as well as the air-borne
and structure-borne channel characteristics. The core technique layer
encompasses key mechanisms to generate acoustic signals (waveforms) and to
extract useful temporal, spatial and spectral information from received
signals. The application layer builds upon the functions offered by the core
techniques to realize different acoustic sensing applications. We highlight
unique challenges due to the limitations of physical devices and acoustic
channels and how they are mitigated or overcame by core processing techniques
and application-specific solutions. Finally, research opportunities and future
directions are discussed to spawn further in-depth investigation on acoustic
sensing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DDGC: Generative Deep Dexterous Grasping in Clutter. (arXiv:2103.04783v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lundell_J/0/1/0/all/0/1">Jens Lundell</a>, <a href="http://arxiv.org/find/cs/1/au:+Verdoja_F/0/1/0/all/0/1">Francesco Verdoja</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1">Ville Kyrki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04783">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in multi-fingered robotic grasping have enabled fast
6-Degrees-Of-Freedom (DOF) single object grasping. Multi-finger grasping in
cluttered scenes, on the other hand, remains mostly unexplored due to the added
difficulty of reasoning over obstacles which greatly increases the
computational time to generate high-quality collision-free grasps. In this work
we address such limitations by introducing DDGC, a fast generative multi-finger
grasp sampling method that can generate high quality grasps in cluttered scenes
from a single RGB-D image. DDGC is built as a network that encodes scene
information to produce coarse-to-fine collision-free grasp poses and
configurations. We experimentally benchmark DDGC against the
simulated-annealing planner in GraspIt! on 1200 simulated cluttered scenes and
7 real world scenes. The results show that DDGC outperforms the baseline on
synthesizing high-quality grasps and removing clutter while being 5 times
faster. This, in turn, opens up the door for using multi-finger grasps in
practical applications which has so far been limited due to the excessive
computation time needed by other methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Attention-based Communication-Efficient Federated Learning. (arXiv:2108.05765v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chong_K/0/1/0/all/0/1">Kai Fong Ernest Chong</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q. S. Quek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05765">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) offers a solution to train a global machine learning
model while still maintaining data privacy, without needing access to data
stored locally at the clients. However, FL suffers performance degradation when
client data distribution is non-IID, and a longer training duration to combat
this degradation may not necessarily be feasible due to communication
limitations. To address this challenge, we propose a new adaptive training
algorithm $\texttt{AdaFL}$, which comprises two components: (i) an
attention-based client selection mechanism for a fairer training scheme among
the clients; and (ii) a dynamic fraction method to balance the trade-off
between performance stability and communication efficiency. Experimental
results show that our $\texttt{AdaFL}$ algorithm outperforms the usual
$\texttt{FedAvg}$ algorithm, and can be incorporated to further improve various
state-of-the-art FL algorithms, with respect to three aspects: model accuracy,
performance stability, and communication efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mean-Field Controls with Q-learning for Cooperative MARL: Convergence and Complexity Analysis. (arXiv:2002.04131v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Haotian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaoli Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Renyuan Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04131">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent reinforcement learning (MARL), despite its popularity and
empirical success, suffers from the curse of dimensionality. This paper builds
the mathematical framework to approximate cooperative MARL by a mean-field
control (MFC) approach, and shows that the approximation error is of
$\mathcal{O}(\frac{1}{\sqrt{N}})$. By establishing an appropriate form of the
dynamic programming principle for both the value function and the Q function,
it proposes a model-free kernel-based Q-learning algorithm (MFC-K-Q), which is
shown to have a linear convergence rate for the MFC problem, the first of its
kind in the MARL literature. It further establishes that the convergence rate
and the sample complexity of MFC-K-Q are independent of the number of agents
$N$, which provides an $\mathcal{O}(\frac{1}{\sqrt{N}})$ approximation to the
MARL problem with $N$ agents in the learning environment. Empirical studies for
the network traffic congestion problem demonstrate that MFC-K-Q outperforms
existing MARL algorithms when $N$ is large, for instance when $N&gt;50$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-aware Synthesis of High-resolution Diffusion from Structural Imaging. (arXiv:2108.04135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anctil_Robitaille_B/0/1/0/all/0/1">Benoit Anctil-Robitaille</a>, <a href="http://arxiv.org/find/cs/1/au:+Theberge_A/0/1/0/all/0/1">Antoine Th&#xe9;berge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1">Maxime Descoteaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Christian Desrosiers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombaert_H/0/1/0/all/0/1">Herv&#xe9; Lombaert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04135">
                                    <div class="article-summary-box-inner">
                                        <span>The physical and clinical constraints surrounding diffusion-weighted imaging
(DWI) often limit the spatial resolution of the produced images to voxels up to
8 times larger than those of T1w images. Thus, the detailed information
contained in T1w imagescould help in the synthesis of diffusion images in
higher resolution. However, the non-Euclidean nature of diffusion imaging
hinders current deep generative models from synthesizing physically plausible
images. In this work, we propose the first Riemannian network architecture for
the direct generation of diffusion tensors (DT) and diffusion orientation
distribution functions (dODFs) from high-resolution T1w images. Our integration
of the Log-Euclidean Metric into a learning objective guarantees, unlike
standard Euclidean networks, the mathematically-valid synthesis of diffusion.
Furthermore, our approach improves the fractional anisotropy mean squared error
(FA MSE) between the synthesized diffusion and the ground-truth by more than
23% and the cosine similarity between principal directions by almost 5% when
compared to our baselines. We validate our generated diffusion by comparing the
resulting tractograms to our expected real data. We observe similar fiber
bundles with streamlines having less than 3% difference in length, less than 1%
difference in volume, and a visually close shape. While our method is able to
generate high-resolution diffusion images from structural inputs in less than
15 seconds, we acknowledge and discuss the limits of diffusion inference solely
relying on T1w images. Our results nonetheless suggest a relationship between
the high-level geometry of the brain and the overall white matter architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal-difference learning with nonlinear function approximation: lazy training and mean field regimes. (arXiv:1905.10917v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agazzi_A/0/1/0/all/0/1">Andrea Agazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10917">
                                    <div class="article-summary-box-inner">
                                        <span>We discuss the approximation of the value function for infinite-horizon
discounted Markov Reward Processes (MRP) with nonlinear functions trained with
the Temporal-Difference (TD) learning algorithm. We first consider this problem
under a certain scaling of the approximating function, leading to a regime
called lazy training. In this regime, the parameters of the model vary only
slightly during the learning process, a feature that has recently been observed
in the training of neural networks, where the scaling we study arises
naturally, implicit in the initialization of their parameters. Both in the
under- and over-parametrized frameworks, we prove exponential convergence to
local, respectively global minimizers of the above algorithm in the lazy
training regime. We then compare this scaling of the parameters to the
mean-field regime, where the approximately linear behavior of the model is
lost. Under this alternative scaling we prove that all fixed points of the
dynamics in parameter space are global minimizers. We finally give examples of
our convergence results in the case of models that diverge if trained with
non-lazy TD learning, and in the case of neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speaker-invariant Affective Representation Learning via Adversarial Training. (arXiv:1911.01533v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Haoqi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Tu_M/0/1/0/all/0/1">Ming Tu</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Narayanan_S/0/1/0/all/0/1">Shrikanth Narayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Georgiou_P/0/1/0/all/0/1">Panayiotis Georgiou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01533">
                                    <div class="article-summary-box-inner">
                                        <span>Representation learning for speech emotion recognition is challenging due to
labeled data sparsity issue and lack of gold standard references. In addition,
there is much variability from input speech signals, human subjective
perception of the signals and emotion label ambiguity. In this paper, we
propose a machine learning framework to obtain speech emotion representations
by limiting the effect of speaker variability in the speech signals.
Specifically, we propose to disentangle the speaker characteristics from
emotion through an adversarial training network in order to better represent
emotion. Our method combines the gradient reversal technique with an entropy
loss function to remove such speaker information. Our approach is evaluated on
both IEMOCAP and CMU-MOSEI datasets. We show that our method improves speech
emotion classification and increases generalization to unseen speakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Compressed Records: Taking a Byte out of Deep Learning Data. (arXiv:1911.00472v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuchnik_M/0/1/0/all/0/1">Michael Kuchnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Amvrosiadis_G/0/1/0/all/0/1">George Amvrosiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1">Virginia Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.00472">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning accelerators efficiently train over vast and growing amounts of
data, placing a newfound burden on commodity networks and storage devices. A
common approach to conserve bandwidth involves resizing or compressing data
prior to training. We introduce Progressive Compressed Records (PCRs), a data
format that uses compression to reduce the overhead of fetching and
transporting data, effectively reducing the training time required to achieve a
target accuracy. PCRs deviate from previous storage formats by combining
progressive compression with an efficient storage layout to view a single
dataset at multiple fidelities---all without adding to the total dataset size.
We implement PCRs and evaluate them on a range of datasets, training tasks, and
hardware architectures. Our work shows that: (i) the amount of compression a
dataset can tolerate exceeds 50% of the original encoding for many DL training
tasks; (ii) it is possible to automatically and efficiently select appropriate
compression levels for a given task; and (iii) PCRs enable tasks to readily
access compressed data at runtime---utilizing as little as half the training
bandwidth and thus potentially doubling training speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing hierarchical multi-view MRI data with StaPLR: An application to Alzheimer&#x27;s disease classification. (arXiv:2108.05761v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Loon_W/0/1/0/all/0/1">Wouter van Loon</a>, <a href="http://arxiv.org/find/stat/1/au:+Vos_F/0/1/0/all/0/1">Frank de Vos</a>, <a href="http://arxiv.org/find/stat/1/au:+Fokkema_M/0/1/0/all/0/1">Marjolein Fokkema</a>, <a href="http://arxiv.org/find/stat/1/au:+Szabo_B/0/1/0/all/0/1">Botond Szabo</a>, <a href="http://arxiv.org/find/stat/1/au:+Koini_M/0/1/0/all/0/1">Marisa Koini</a>, <a href="http://arxiv.org/find/stat/1/au:+Schmidt_R/0/1/0/all/0/1">Reinhold Schmidt</a>, <a href="http://arxiv.org/find/stat/1/au:+Rooij_M/0/1/0/all/0/1">Mark de Rooij</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05761">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view data refers to a setting where features are divided into feature
sets, for example because they correspond to different sources. Stacked
penalized logistic regression (StaPLR) is a recently introduced method that can
be used for classification and automatically selecting the views that are most
important for prediction. We show how this method can easily be extended to a
setting where the data has a hierarchical multi-view structure. We apply StaPLR
to Alzheimer&#x27;s disease classification where different MRI measures have been
calculated from three scan types: structural MRI, diffusion-weighted MRI, and
resting-state fMRI. StaPLR can identify which scan types and which MRI measures
are most important for classification, and it outperforms elastic net
regression in classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Gradients Incorporating the Future. (arXiv:2108.02096v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venuto_D/0/1/0/all/0/1">David Venuto</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_E/0/1/0/all/0/1">Elaine Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1">Ofir Nachum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02096">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning about the future -- understanding how decisions in the present time
affect outcomes in the future -- is one of the central challenges for
reinforcement learning (RL), especially in highly-stochastic or partially
observable environments. While predicting the future directly is hard, in this
work we introduce a method that allows an agent to &quot;look into the future&quot;
without explicitly predicting it. Namely, we propose to allow an agent, during
its training on past experience, to observe what \emph{actually} happened in
the future at that time, while enforcing an information bottleneck to avoid the
agent overly relying on this privileged information. This gives our agent the
opportunity to utilize rich and useful information about the future trajectory
dynamics in addition to the present. Our method, Policy Gradients Incorporating
the Future (PGIF), is easy to implement and versatile, being applicable to
virtually any policy gradient algorithm. We apply our proposed method to a
number of off-the-shelf RL algorithms and show that PGIF is able to achieve
higher reward faster in a variety of online and offline RL domains, as well as
sparse-reward and partially observable environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locality Sensitive Hashing with Extended Differential Privacy. (arXiv:2010.09393v5 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_N/0/1/0/all/0/1">Natasha Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawamoto_Y/0/1/0/all/0/1">Yusuke Kawamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1">Takao Murakami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09393">
                                    <div class="article-summary-box-inner">
                                        <span>Extended differential privacy, a generalization of standard differential
privacy (DP) using a general metric, has been widely studied to provide
rigorous privacy guarantees while keeping high utility. However, existing works
on extended DP are limited to few metrics, such as the Euclidean metric.
Consequently, they have only a small number of applications, such as
location-based services and document processing. In this paper, we propose a
couple of mechanisms providing extended DP with a different metric: angular
distance (or cosine distance). Our mechanisms are based on locality sensitive
hashing (LSH), which can be applied to the angular distance and work well for
personal data in a high-dimensional space. We theoretically analyze the privacy
properties of our mechanisms, and prove extended DP for input data by taking
into account that LSH preserves the original metric only approximately. We
apply our mechanisms to friend matching based on high-dimensional personal data
with angular distance in the local model, and evaluate our mechanisms using two
real datasets. We show that LDP requires a very large privacy budget and that
RAPPOR does not work in this application. Then we show that our mechanisms
enable friend matching with high utility and rigorous privacy guarantees based
on extended DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation. (arXiv:2108.05773v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bangunharcana_A/0/1/0/all/0/1">Antyanta Bangunharcana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seokju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyung-Soo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soohyun Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05773">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric deep learning approach towards stereo matching aggregates a cost
volume computed from input left and right images using 3D convolutions. Recent
works showed that utilization of extracted image features and a spatially
varying cost volume aggregation complements 3D convolutions. However, existing
methods with spatially varying operations are complex, cost considerable
computation time, and cause memory consumption to increase. In this work, we
construct Guided Cost volume Excitation (GCE) and show that simple channel
excitation of cost volume guided by image can improve performance considerably.
Moreover, we propose a novel method of using top-k selection prior to
soft-argmin disparity regression for computing the final disparity estimate.
Combining our novel contributions, we present an end-to-end network that we
call Correlate-and-Excite (CoEx). Extensive experiments of our model on the
SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate the effectiveness
and efficiency of our model and show that our model outperforms other
speed-based algorithms while also being competitive to other state-of-the-art
algorithms. Codes will be made available at https://github.com/antabangun/coex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards real-world navigation with deep differentiable planners. (arXiv:2108.05713v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishida_S/0/1/0/all/0/1">Shu Ishida</a>, <a href="http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1">Jo&#xe3;o F. Henriques</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05713">
                                    <div class="article-summary-box-inner">
                                        <span>We train embodied neural networks to plan and navigate unseen complex 3D
environments, emphasising real-world deployment. Rather than requiring prior
knowledge of the agent or environment, the planner learns to model the state
transitions and rewards. To avoid the potentially hazardous trial-and-error of
reinforcement learning, we focus on differentiable planners such as Value
Iteration Networks (VIN), which are trained offline from safe expert
demonstrations. Although they work well in small simulations, we address two
major limitations that hinder their deployment. First, we observed that current
differentiable planners struggle to plan long-term in environments with a high
branching complexity. While they should ideally learn to assign low rewards to
obstacles to avoid collisions, we posit that the constraints imposed on the
network are not strong enough to guarantee the network to learn sufficiently
large penalties for every possible collision. We thus impose a structural
constraint on the value iteration, which explicitly learns to model any
impossible actions. Secondly, we extend the model to work with a limited
perspective camera under translation and rotation, which is crucial for real
robot deployment. Many VIN-like planners assume a 360 degrees or overhead view
without rotation. In contrast, our method uses a memory-efficient lattice map
to aggregate CNN embeddings of partial observations, and models the rotational
dynamics explicitly using a 3D state-space grid (translation and rotation). Our
proposals significantly improve semantic navigation and exploration on several
2D and 3D environments, succeeding in settings that are otherwise challenging
for this class of methods. As far as we know, we are the first to successfully
perform differentiable planning on the difficult Active Vision Dataset,
consisting of real images captured from a robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection using principles of human perception. (arXiv:2103.12323v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nassir_M/0/1/0/all/0/1">Mohammad Nassir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12323">
                                    <div class="article-summary-box-inner">
                                        <span>In the fields of statistics and unsupervised machine learning a fundamental
and well-studied problem is anomaly detection. Although anomalies are difficult
to define, many algorithms have been proposed. Underlying the approaches is the
nebulous understanding that anomalies are rare, unusual or inconsistent with
the majority of data. The present work gives a philosophical approach to
clearly define anomalies and to develop an algorithm for their efficient
detection with minimal user intervention. Inspired by the Gestalt School of
Psychology and the Helmholtz principle of human perception, the idea is to
assume anomalies are observations that are unexpected to occur with respect to
certain groupings made by the majority of the data. Thus, under appropriate
random variable modelling anomalies are directly found in a set of data under a
uniform and independent random assumption of the distribution of constituent
elements of the observations; anomalies correspond to those observations where
the expectation of occurrence of the elements in a given view is $&lt;1$. Starting
from fundamental principles of human perception an unsupervised anomaly
detection algorithm is developed that is simple, real-time and parameter-free.
Experiments suggest it as the prime choice for univariate data and it shows
promising performance on the detection of global anomalies in multivariate
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Mitigation of Face Recognition Models Through Calibration. (arXiv:2106.03761v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salvador_T/0/1/0/all/0/1">Tiago Salvador</a>, <a href="http://arxiv.org/find/cs/1/au:+Cairns_S/0/1/0/all/0/1">Stephanie Cairns</a>, <a href="http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1">Vikram Voleti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marshall_N/0/1/0/all/0/1">Noah Marshall</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1">Adam Oberman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03761">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition models suffer from bias: for example, the probability of a
false positive (incorrect face match) strongly depends on sensitive attributes
like ethnicity. As a result, these models may disproportionately and negatively
impact minority groups when used in law enforcement. In this work, we introduce
the Bias Mitigation Calibration (BMC) method, which (i) increases model
accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated
probabilities, (iii) significantly reduces the gap in the false positive rates,
and (iv) does not require knowledge of the sensitive attribute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Roll-off Points Variations: Exploring Useful Information in Feature Maps by Its Variations. (arXiv:2102.00369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yunkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yuyang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhihong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guozheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peiyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhicheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_W/0/1/0/all/0/1">Wenjing Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00369">
                                    <div class="article-summary-box-inner">
                                        <span>Useful information (UI) is an elusive concept in neural networks. A
quantitative measurement of UI is absent, despite the variations of UI can be
recognized by prior knowledge. The communication bandwidth of feature maps
decreases after downscaling operations, but UI flows smoothly after training
due to lower Nyquist frequency. Inspired by the low-Nyqusit-frequency nature of
UI, we propose the use of spectral roll-off points (SROPs) to estimate UI on
variations. The computation of an SROP is extended from a 1-D signal to a 2-D
image by the required rotation invariance in image classification tasks. SROP
statistics across feature maps are implemented as layer-wise useful information
estimates. We design sanity checks to explore SROP variations when UI
variations are produced by variations in model input, model architecture and
training stages. The variations of SROP is synchronizes with UI variations in
various randomized and sufficiently trained model structures. Therefore, SROP
variations is an accurate and convenient sign of UI variations, which promotes
the explainability of data representations with respect to frequency-domain
knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is the brain macroscopically linear? A system identification of resting state dynamics. (arXiv:2012.12351v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Nozari_E/0/1/0/all/0/1">Erfan Nozari</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bertolero_M/0/1/0/all/0/1">Maxwell A. Bertolero</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Stiso_J/0/1/0/all/0/1">Jennifer Stiso</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Caciagli_L/0/1/0/all/0/1">Lorenzo Caciagli</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cornblath_E/0/1/0/all/0/1">Eli J. Cornblath</a>, <a href="http://arxiv.org/find/q-bio/1/au:+He_X/0/1/0/all/0/1">Xiaosong He</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mahadevan_A/0/1/0/all/0/1">Arun S. Mahadevan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pappas_G/0/1/0/all/0/1">George J. Pappas</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bassett_D/0/1/0/all/0/1">Dani Smith Bassett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12351">
                                    <div class="article-summary-box-inner">
                                        <span>A central challenge in the computational modeling of neural dynamics is the
trade-off between accuracy and simplicity. At the level of individual neurons,
nonlinear dynamics are both experimentally established and essential for
neuronal functioning. An implicit assumption has thus formed that an accurate
computational model of whole-brain dynamics must also be highly nonlinear,
whereas linear models may provide a first-order approximation. Here, we provide
a rigorous and data-driven investigation of this hypothesis at the level of
whole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential
dynamics by leveraging the theory of system identification. Using functional
MRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of
700 subjects in the Human Connectome Project (HCP) and 122 subjects from the
Restoring Active Memory (RAM) project using state-of-the-art linear and
nonlinear model families. We assess relative model fit using predictive power,
computational complexity, and the extent of residual dynamics unexplained by
the model. Contrary to our expectations, linear auto-regressive models achieve
the best measures across all three metrics, eliminating the trade-off between
accuracy and simplicity. To understand and explain this linearity, we highlight
four properties of macroscopic neurodynamics which can counteract or mask
microscopic nonlinear dynamics: averaging over space, averaging over time,
observation noise, and limited data samples. Whereas the latter two are
technological limitations and can improve in the future, the former two are
inherent to aggregated macroscopic brain activity. Our results, together with
the unparalleled interpretability of linear models, can greatly facilitate our
understanding of macroscopic neural dynamics and the principled design of
model-based interventions for the treatment of neuropsychiatric disorders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Ask: Learning to Answer Questions from Millions of Narrated Videos. (arXiv:2012.00451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">Antoine Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miech_A/0/1/0/all/0/1">Antoine Miech</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivic_J/0/1/0/all/0/1">Josef Sivic</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and show excellent
results, in particular for rare answers. Furthermore, we demonstrate our method
to significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,
ActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce
iVQA, a new VideoQA dataset with reduced language biases and high-quality
redundant manual annotations. Our code, datasets and trained models are
available at https://antoyang.github.io/just-ask.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedXGBoost: Privacy-Preserving XGBoost for Federated Learning. (arXiv:2106.10662v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Nhan Khanh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quang Minh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fangzhou Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Quanwei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirche_S/0/1/0/all/0/1">Sandra Hirche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10662">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is the distributed machine learning framework that enables
collaborative training across multiple parties while ensuring data privacy.
Practical adaptation of XGBoost, the state-of-the-art tree boosting framework,
to federated learning remains limited due to high cost incurred by conventional
privacy-preserving methods. To address the problem, we propose two variants of
federated XGBoost with privacy guarantee: FedXGBoost-SMM and FedXGBoost-LDP.
Our first protocol FedXGBoost-SMM deploys enhanced secure matrix multiplication
method to preserve privacy with lossless accuracy and lower overhead than
encryption-based techniques. Developed independently, the second protocol
FedXGBoost-LDP is heuristically designed with noise perturbation for local
differential privacy, and empirically evaluated on real-world and synthetic
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1">Verna Dankers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1">Elia Bruni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1">Dieuwke Hupkes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05885">
                                    <div class="article-summary-box-inner">
                                        <span>Moving towards human-like linguistic performance is often argued to require
compositional generalisation. Whether neural networks exhibit this ability is
typically studied using artificial languages, for which the compositionality of
input fragments can be guaranteed and their meanings algebraically composed.
However, compositionality in natural language is vastly more complex than this
rigid, arithmetics-like version of compositionality, and as such artificial
compositionality tests do not allow us to draw conclusions about how neural
models deal with compositionality in more realistic scenarios. In this work, we
re-instantiate three compositionality tests from the literature and reformulate
them for neural machine translation (NMT). The results highlight two main
issues: the inconsistent behaviour of NMT models and their inability to
(correctly) modulate between local and global processing. Aside from an
empirical study, our work is a call to action: we should rethink the evaluation
of compositionality in neural networks of natural language, where composing
meaning is not as straightforward as doing the math.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantics-Native Communication with Contextual Reasoning. (arXiv:2108.05681v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_H/0/1/0/all/0/1">Hyowoon Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jihong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1">M&#xe9;rouane Debbah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05681">
                                    <div class="article-summary-box-inner">
                                        <span>Spurred by a huge interest in the post-Shannon communication, it has recently
been shown that leveraging semantics can significantly improve the
communication effectiveness across many tasks. In this article, inspired by
human communication, we propose a novel stochastic model of System 1
semantics-native communication (SNC) for generic tasks, where a speaker has an
intention of referring to an entity, extracts the semantics, and communicates
its symbolic representation to a target listener. To further reach its full
potential, we additionally infuse contextual reasoning into SNC such that the
speaker locally and iteratively self-communicates with a virtual agent built on
the physical listener&#x27;s unique way of coding its semantics, i.e., communication
context. The resultant System 2 SNC allows the speaker to extract the most
effective semantics for its listener. Leveraging the proposed stochastic model,
we show that the reliability of System 2 SNC increases with the number of
meaningful concepts, and derive the expected semantic representation (SR) bit
length which quantifies the extracted effective semantics. It is also shown
that System 2 SNC significantly reduces the SR length without compromising
communication reliability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mobile-Former: Bridging MobileNet and Transformer. (arXiv:2108.05895v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengchen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05895">
                                    <div class="article-summary-box-inner">
                                        <span>We present Mobile-Former, a parallel design of MobileNet and Transformer with
a two-way bridge in between. This structure leverages the advantage of
MobileNet at local processing and transformer at global interaction. And the
bridge enables bidirectional fusion of local and global features. Different
with recent works on vision transformer, the transformer in Mobile-Former
contains very few tokens (e.g. less than 6 tokens) that are randomly
initialized, resulting in low computational cost. Combining with the proposed
light-weight cross attention to model the bridge, Mobile-Former is not only
computationally efficient, but also has more representation power,
outperforming MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet
classification. For instance, it achieves 77.9\% top-1 accuracy at 294M FLOPs,
gaining 1.3\% over MobileNetV3 but saving 17\% of computations. When
transferring to object detection, Mobile-Former outperforms MobileNetV3 by 8.6
AP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Approach to Partial Observability in Games: Learning to Both Act and Observe. (arXiv:2108.05701v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gilmour_E/0/1/0/all/0/1">Elizabeth Gilmour</a>, <a href="http://arxiv.org/find/cs/1/au:+Plotkin_N/0/1/0/all/0/1">Noah Plotkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Leslie Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05701">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is successful at learning to play games where the
entire environment is visible. However, RL approaches are challenged in complex
games like Starcraft II and in real-world environments where the entire
environment is not visible. In these more complex games with more limited
visual information, agents must choose where to look and how to optimally use
their limited visual information in order to succeed at the game. We verify
that with a relatively simple model the agent can learn where to look in
scenarios with a limited visual bandwidth. We develop a method for masking part
of the environment in Atari games to force the RL agent to learn both where to
look and how to play the game in order to study where the RL agent learns to
look. In addition, we develop a neural network architecture and method for
allowing the agent to choose where to look and what action to take in the Pong
game. Further, we analyze the strategies the agent learns to better understand
how the RL agent learns to play the game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Correlation Clustering with Asymmetric Classification Errors. (arXiv:2108.05697v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarov_J/0/1/0/all/0/1">Jafar Jafarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalhan_S/0/1/0/all/0/1">Sanchit Kalhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05697">
                                    <div class="article-summary-box-inner">
                                        <span>In the Correlation Clustering problem, we are given a complete weighted graph
$G$ with its edges labeled as &quot;similar&quot; and &quot;dissimilar&quot; by a noisy binary
classifier. For a clustering $\mathcal{C}$ of graph $G$, a similar edge is in
disagreement with $\mathcal{C}$, if its endpoints belong to distinct clusters;
and a dissimilar edge is in disagreement with $\mathcal{C}$ if its endpoints
belong to the same cluster. The disagreements vector, $\text{dis}$, is a vector
indexed by the vertices of $G$ such that the $v$-th coordinate $\text{dis}_v$
equals the weight of all disagreeing edges incident on $v$. The goal is to
produce a clustering that minimizes the $\ell_p$ norm of the disagreements
vector for $p\geq 1$. We study the $\ell_p$ objective in Correlation Clustering
under the following assumption: Every similar edge has weight in the range of
$[\alpha\mathbf{w},\mathbf{w}]$ and every dissimilar edge has weight at least
$\alpha\mathbf{w}$ (where $\alpha \leq 1$ and $\mathbf{w}&gt;0$ is a scaling
parameter). We give an
$O\left((\frac{1}{\alpha})^{\frac{1}{2}-\frac{1}{2p}}\cdot
\log\frac{1}{\alpha}\right)$ approximation algorithm for this problem.
Furthermore, we show an almost matching convex programming integrality gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Matured Dumb Teacher for Fine Generalization. (arXiv:2108.05776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1">HeeSeung Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kangil Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoyong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jong-Hun Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05776">
                                    <div class="article-summary-box-inner">
                                        <span>The flexibility of decision boundaries in neural networks that are unguided
by training data is a well-known problem typically resolved with generalization
methods. A surprising result from recent knowledge distillation (KD) literature
is that random, untrained, and equally structured teacher networks can also
vastly improve generalization performance. It raises the possibility of
existence of undiscovered assumptions useful for generalization on an uncertain
region. In this paper, we shed light on the assumptions by analyzing decision
boundaries and confidence distributions of both simple and KD-based
generalization methods. Assuming that a decision boundary exists to represent
the most general tendency of distinction on an input sample space (i.e., the
simplest hypothesis), we show the various limitations of methods when using the
hypothesis. To resolve these limitations, we propose matured dumb teacher based
KD, conservatively transferring the hypothesis for generalization of the
student without massive destruction of trained information. In practical
experiments on feed-forward and convolution neural networks for image
classification tasks on MNIST, CIFAR-10, and CIFAR-100 datasets, the proposed
method shows stable improvement to the best test performance in the grid search
of hyperparameters. The analysis and results imply that the proposed method can
provide finer generalization than existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Page-level Optimization of e-Commerce Item Recommendations. (arXiv:2108.05891v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1">Chieh Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1">Krutika Shetty</a>, <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Changchen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Kathy Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Platz_J/0/1/0/all/0/1">Justin Platz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilardi_A/0/1/0/all/0/1">Adam Ilardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhvanath_S/0/1/0/all/0/1">Sriganesh Madhvanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05891">
                                    <div class="article-summary-box-inner">
                                        <span>The item details page (IDP) is a web page on an e-commerce website that
provides information on a specific product or item listing. Just below the
details of the item on this page, the buyer can usually find recommendations
for other relevant items. These are typically in the form of a series of
modules or carousels, with each module containing a set of recommended items.
The selection and ordering of these item recommendation modules are intended to
increase discover-ability of relevant items and encourage greater user
engagement, while simultaneously showcasing diversity of inventory and
satisfying other business objectives. Item recommendation modules on the IDP
are often curated and statically configured for all customers, ignoring
opportunities for personalization. In this paper, we present a scalable
end-to-end production system to optimize the personalized selection and
ordering of item recommendation modules on the IDP in real-time by utilizing
deep neural networks. Through extensive offline experimentation and online A/B
testing, we show that our proposed system achieves significantly higher
click-through and conversion rates compared to other existing methods. In our
online A/B test, our framework improved click-through rate by 2.48% and
purchase-through rate by 7.34% over a static configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FreaAI: Automated extraction of data slices to test machine learning models. (arXiv:2108.05620v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ackerman_S/0/1/0/all/0/1">Samuel Ackerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_O/0/1/0/all/0/1">Orna Raz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmanovici_M/0/1/0/all/0/1">Marcel Zalmanovici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05620">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) solutions are prevalent. However, many challenges exist
in making these solutions business-grade. One major challenge is to ensure that
the ML solution provides its expected business value. In order to do that, one
has to bridge the gap between the way ML model performance is measured and the
solution requirements. In previous work (Barash et al, &quot;Bridging the gap...&quot;)
we demonstrated the effectiveness of utilizing feature models in bridging this
gap. Whereas ML performance metrics, such as the accuracy or F1-score of a
classifier, typically measure the average ML performance, feature models shed
light on explainable data slices that are too far from that average, and
therefore might indicate unsatisfied requirements. For example, the overall
accuracy of a bank text terms classifier may be very high, say $98\% \pm 2\%$,
yet it might perform poorly for terms that include short descriptions and
originate from commercial accounts. A business requirement, which may be
implicit in the training data, may be to perform well regardless of the type of
account and length of the description. Therefore, the under-performing data
slice that includes short descriptions and commercial accounts suggests
poorly-met requirements. In this paper we show the feasibility of automatically
extracting feature models that result in explainable data slices over which the
ML solution under-performs. Our novel technique, IBM FreaAI aka FreaAI,
extracts such slices from structured ML test data or any other labeled data. We
demonstrate that FreaAI can automatically produce explainable and
statistically-significant data slices over seven open datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real Negatives Matter: Continuous Training with Real Negatives for Delayed Feedback Modeling. (arXiv:2104.14121v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Siyu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1">Xiang-Rong Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Ying Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guorui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14121">
                                    <div class="article-summary-box-inner">
                                        <span>One of the difficulties of conversion rate (CVR) prediction is that the
conversions can delay and take place long after the clicks. The delayed
feedback poses a challenge: fresh data are beneficial to continuous training
but may not have complete label information at the time they are ingested into
the training pipeline. To balance model freshness and label certainty, previous
methods set a short waiting window or even do not wait for the conversion
signal. If conversion happens outside the waiting window, this sample will be
duplicated and ingested into the training pipeline with a positive label.
However, these methods have some issues. First, they assume the observed
feature distribution remains the same as the actual distribution. But this
assumption does not hold due to the ingestion of duplicated samples. Second,
the certainty of the conversion action only comes from the positives. But the
positives are scarce as conversions are sparse in commercial systems. These
issues induce bias during the modeling of delayed feedback. In this paper, we
propose DElayed FEedback modeling with Real negatives (DEFER) method to address
these issues. The proposed method ingests real negative samples into the
training pipeline. The ingestion of real negatives ensures the observed feature
distribution is equivalent to the actual distribution, thus reducing the bias.
The ingestion of real negatives also brings more certainty information of the
conversion. To correct the distribution shift, DEFER employs importance
sampling to weigh the loss function. Experimental results on industrial
datasets validate the superiority of DEFER. DEFER have been deployed in the
display advertising system of Alibaba, obtaining over 6.0% improvement on CVR
in several scenarios. The code and data in this paper are now open-sourced
{https://github.com/gusuperstar/defer.git}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Engineering with Regularity Structures. (arXiv:2108.05879v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chevyrev_I/0/1/0/all/0/1">Ilya Chevyrev</a>, <a href="http://arxiv.org/find/stat/1/au:+Gerasimovics_A/0/1/0/all/0/1">Andris Gerasimovics</a>, <a href="http://arxiv.org/find/stat/1/au:+Weber_H/0/1/0/all/0/1">Hendrik Weber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05879">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the use of models from the theory of regularity structure as
features in machine learning tasks. A model is a multi-linear function of a
space-time signal designed to well-approximate solutions to partial
differential equations (PDEs), even in low regularity regimes. Models can be
seen as natural multi-dimensional generalisations of signatures of paths; our
work therefore aims to extend the recent use of signatures in data science
beyond the context of time-ordered data. We provide a flexible definition of a
model feature vector associated to a space-time signal, along with two
algorithms which illustrate ways in which these features can be combined with
linear regression. We apply these algorithms in several numerical experiments
designed to learn solutions to PDEs with a given forcing and boundary data. Our
experiments include semi-linear parabolic and wave equations with forcing, and
Burgers&#x27; equation with no forcing. We find an advantage in favour of our
algorithms when compared to several alternative methods. Additionally, in the
experiment with Burgers&#x27; equation, we noticed stability in the prediction power
when noise is added to the observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Development of Risk-Free COVID-19 Screening Algorithm from Routine Blood Test using Ensemble Machine Learning. (arXiv:2108.05660v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raihan_M/0/1/0/all/0/1">Md. Mohsin Sarker Raihan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Md. Mohi Uddin Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Akter_L/0/1/0/all/0/1">Laboni Akter</a>, <a href="http://arxiv.org/find/cs/1/au:+Shams_A/0/1/0/all/0/1">Abdullah Bin Shams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05660">
                                    <div class="article-summary-box-inner">
                                        <span>The Reverse Transcription Polymerase Chain Reaction (RTPCR) test is the
silver bullet diagnostic test to discern COVID infection. Rapid antigen
detection is a screening test to identify COVID positive patients in little as
15 minutes, but has a lower sensitivity than the PCR tests. Besides having
multiple standardized test kits, many people are getting infected &amp; either
recovering or dying even before the test due to the shortage and cost of kits,
lack of indispensable specialists and labs, time-consuming result compared to
bulk population especially in developing and underdeveloped countries.
Intrigued by the parametric deviations in immunological &amp; hematological profile
of a COVID patient, this research work leveraged the concept of COVID-19
detection by proposing a risk-free and highly accurate Stacked Ensemble Machine
Learning model to identify a COVID patient from communally
available-widespread-cheap routine blood tests which gives a promising
accuracy, precision, recall &amp; F1-score of 100%. Analysis from R-curve also
shows the preciseness of the risk-free model to be implemented. The proposed
method has the potential for large scale ubiquitous low-cost screening
application. This can add an extra layer of protection in keeping the number of
infected cases to a minimum and control the pandemic by identifying
asymptomatic or pre-symptomatic people early.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PatrickStar: Parallel Training of Pre-trained Models via a Chunk-based Memory Management. (arXiv:2108.05818v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiarui Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shenggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05818">
                                    <div class="article-summary-box-inner">
                                        <span>The pre-trained model (PTM) is revolutionizing Artificial intelligence (AI)
technology. It learns a model with general language features on the vast text
and then fine-tunes the model using a task-specific dataset. Unfortunately, PTM
training requires prohibitively expensive computing devices, especially
fine-tuning, which is still a game for a small proportion of people in the AI
community. Enabling PTMs training on low-quality devices, PatrickStar now makes
PTM accessible to everyone.

PatrickStar reduces memory requirements of computing platforms by using the
CPU-GPU heterogeneous memory space to store model data, consisting of
parameters, gradients, and optimizer states. We observe that the GPU memory
available for model data changes regularly, in a tide-like pattern, decreasing
and increasing iteratively. However, the existing heterogeneous training works
do not take advantage of this pattern. Instead, they statically partition the
model data among CPU and GPU, leading to both memory waste and memory abuse. In
contrast, PatrickStar manages model data in chunks, which are dynamically
distributed in heterogeneous memory spaces. Chunks consist of stateful tensors
which run as finite state machines during training. Guided by the runtime
memory statistics collected in a warm-up iteration, chunks are orchestrated
efficiently in heterogeneous memory and generate lower CPU-GPU data
transmission volume. Symbiosis with the Zero Redundancy Optimizer, PatrickStar
scales to multiple GPUs using data parallelism, with the lowest communication
bandwidth requirements and more efficient bandwidth utilization. Experimental
results show PatrickStar trains a 12 billion parameters GPT model, 2x larger
than the STOA work, on an 8-V100 and 240GB CPU memory node, and is also more
efficient on the same model size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preventing Catastrophic Forgetting and Distribution Mismatch in Knowledge Distillation via Synthetic Data. (arXiv:2108.05698v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Binici_K/0/1/0/all/0/1">Kuluhan Binici</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1">Nam Trung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1">Tulika Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Leman_K/0/1/0/all/0/1">Karianto Leman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05698">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing popularity of deep learning on edge devices, compressing
large neural networks to meet the hardware requirements of resource-constrained
devices became a significant research direction. Numerous compression
methodologies are currently being used to reduce the memory sizes and energy
consumption of neural networks. Knowledge distillation (KD) is among such
methodologies and it functions by using data samples to transfer the knowledge
captured by a large model (teacher) to a smaller one(student). However, due to
various reasons, the original training data might not be accessible at the
compression stage. Therefore, data-free model compression is an ongoing
research problem that has been addressed by various works. In this paper, we
point out that catastrophic forgetting is a problem that can potentially be
observed in existing data-free distillation methods. Moreover, the sample
generation strategies in some of these methods could result in a mismatch
between the synthetic and real data distributions. To prevent such problems, we
propose a data-free KD framework that maintains a dynamic collection of
generated samples over time. Additionally, we add the constraint of matching
the real data distribution in sample generation strategies that target maximum
information gain. Our experiments demonstrate that we can improve the accuracy
of the student models obtained via KD when compared with state-of-the-art
approaches on the SVHN, Fashion MNIST and CIFAR100 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HopfE: Knowledge Graph Representation Learning using Inverse Hopf Fibrations. (arXiv:2108.05774v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several Knowledge Graph Embedding (KGE) approaches have been
devised to represent entities and relations in dense vector space and employed
in downstream tasks such as link prediction. A few KGE techniques address
interpretability, i.e., mapping the connectivity patterns of the relations
(i.e., symmetric/asymmetric, inverse, and composition) to a geometric
interpretation such as rotations. Other approaches model the representations in
higher dimensional space such as four-dimensional space (4D) to enhance the
ability to infer the connectivity patterns (i.e., expressiveness). However,
modeling relation and entity in a 4D space often comes at the cost of
interpretability. This paper proposes HopfE, a novel KGE approach aiming to
achieve the interpretability of inferred relations in the four-dimensional
space. We first model the structural embeddings in 3D Euclidean space and view
the relation operator as an SO(3) rotation. Next, we map the entity embedding
vector from a 3D space to a 4D hypersphere using the inverse Hopf Fibration, in
which we embed the semantic information from the KG ontology. Thus, HopfE
considers the structural and semantic properties of the entities without losing
expressivity and interpretability. Our empirical results on four well-known
benchmarks achieve state-of-the-art performance for the KG completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal scoring in Premier League with Poisson regression. (arXiv:2108.05796v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pham_C/0/1/0/all/0/1">Cuong Pham</a>, <a href="http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1">Tung Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05796">
                                    <div class="article-summary-box-inner">
                                        <span>Premier League is known as one of the most competitive football league in the
world, hence there are many goals are scored here every match. Which are the
factors that affect to the number of goal scored in each match? We use Poisson
regression to find out the relation between many factors as shots on target,
corners, red cards, to the goals home team can score in their match.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform. (arXiv:2108.05684v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Youxuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zongze Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shugong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05684">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, synthetic speech generated by advanced text-to-speech (TTS)
and voice conversion (VC) systems has caused great harms to automatic speaker
verification (ASV) systems, urging us to design a synthetic speech detection
system to protect ASV systems. In this paper, we propose a new speech
anti-spoofing model named ResWavegram-Resnet (RW-Resnet). The model contains
two parts, Conv1D Resblocks and backbone Resnet34. The Conv1D Resblock is based
on the Conv1D block with a residual connection. For the first part, we use the
raw waveform as input and feed it to the stacked Conv1D Resblocks to get the
ResWavegram. Compared with traditional methods, ResWavegram keeps all the
information from the audio signal and has a stronger ability in extracting
features. For the second part, the extracted features are fed to the backbone
Resnet34 for the spoofed or bonafide decision. The ASVspoof2019 logical access
(LA) corpus is used to evaluate our proposed RW-Resnet. Experimental results
show that the RW-Resnet achieves better performance than other state-of-the-art
anti-spoofing models, which illustrates its effectiveness in detecting
synthetic speech attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Deep Metric Learning with Structural Matching. (arXiv:2108.05889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05889">
                                    <div class="article-summary-box-inner">
                                        <span>How do the neural networks distinguish two images? It is of critical
importance to understand the matching mechanism of deep models for developing
reliable intelligent systems for many risky visual applications such as
surveillance and access control. However, most existing deep metric learning
methods match the images by comparing feature vectors, which ignores the
spatial structure of images and thus lacks interpretability. In this paper, we
present a deep interpretable metric learning (DIML) method for more transparent
embedding learning. Unlike conventional metric learning methods based on
feature vector comparison, we propose a structural matching strategy that
explicitly aligns the spatial embeddings by computing an optimal matching flow
between feature maps of the two images. Our method enables deep models to learn
metrics in a more human-friendly way, where the similarity of two images can be
decomposed to several part-wise similarities and their contributions to the
overall similarity. Our method is model-agnostic, which can be applied to
off-the-shelf backbone networks and metric learning methods. We evaluate our
method on three major benchmarks of deep metric learning including CUB200-2011,
Cars196, and Stanford Online Products, and achieve substantial improvements
over popular metric learning methods with better interpretability. Code is
available at https://github.com/wl-zhao/DIML</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Billion-Scale Pretraining with Vision Transformers for Multi-Task Visual Representations. (arXiv:2108.05887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beal_J/0/1/0/all/0/1">Josh Beal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao-Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dong Huk Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_A/0/1/0/all/0/1">Andrew Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kislyuk_D/0/1/0/all/0/1">Dmitry Kislyuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05887">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretraining of visual representations has led to state-of-the-art
performance on a range of benchmark computer vision tasks, yet the benefits of
these techniques at extreme scale in complex production systems has been
relatively unexplored. We consider the case of a popular visual discovery
product, where these representations are trained with multi-task learning, from
use-case specific visual understanding (e.g. skin tone classification) to
general representation learning for all visual content (e.g. embeddings for
retrieval). In this work, we describe how we (1) generate a dataset with over a
billion images via large weakly-supervised pretraining to improve the
performance of these visual representations, and (2) leverage Transformers to
replace the traditional convolutional backbone, with insights into both system
and performance improvements, especially at 1B+ image scale. To support this
backbone model, we detail a systematic approach to deriving weakly-supervised
image annotations from heterogenous text signals, demonstrating the benefits of
clustering techniques to handle the long-tail distribution of image labels.
Through a comprehensive study of offline and online evaluation, we show that
large-scale Transformer-based pretraining provides significant benefits to
industry computer vision applications. The model is deployed in a production
visual shopping system, with 36% improvement in top-1 relevance and 23%
improvement in click-through volume. We conduct extensive experiments to better
understand the empirical relationships between Transformer-based architectures,
dataset scale, and the performance of production vision systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate spectral clustering using both reference vectors and topology of the network generated by growing neural gas. (arXiv:2009.07101v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1">Kazuhisa Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07101">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral clustering (SC) is one of the most popular clustering methods and
often outperforms traditional clustering methods. SC uses the eigenvectors of a
Laplacian matrix calculated from a similarity matrix of a dataset. SC has
serious drawbacks: the significant increases in the time complexity derived
from the computation of eigenvectors and the memory space complexity to store
the similarity matrix. To address the issues, I develop a new approximate
spectral clustering using the network generated by growing neural gas (GNG),
called ASC with GNG in this study. ASC with GNG uses not only reference vectors
for vector quantization but also the topology of the network for extraction of
the topological relationship between data points in a dataset. ASC with GNG
calculates the similarity matrix from both the reference vectors and the
topology of the network generated by GNG. Using the network generated from a
dataset by GNG, ASC with GNG achieves to reduce the computational and space
complexities and improve clustering quality. In this study, I demonstrate that
ASC with GNG effectively reduces the computational time. Moreover, this study
shows that ASC with GNG provides equal to or better clustering performance than
SC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yuzhe Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yueh-Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hanwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05877">
                                    <div class="article-summary-box-inner">
                                        <span>While we have made significant progress on understanding hand-object
interactions in computer vision, it is still very challenging for robots to
perform complex dexterous manipulation. In this paper, we propose a new
platform and pipeline, DexMV (Dex Manipulation from Videos), for imitation
learning to bridge the gap between computer vision and robot learning. We
design a platform with: (i) a simulation system for complex dexterous
manipulation tasks with a multi-finger robot hand and (ii) a computer vision
system to record large-scale demonstrations of a human hand conducting the same
tasks. In our new pipeline, we extract 3D hand and object poses from the
videos, and convert them to robot demonstrations via motion retargeting. We
then apply and compare multiple imitation learning algorithms with the
demonstrations. We show that the demonstrations can indeed improve robot
learning by a large margin and solve the complex tasks which reinforcement
learning alone cannot solve. Project page with video:
https://yzqin.github.io/dexmv/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Nonconformity Functions and Difficulty of Datasets Impact the Efficiency of Conformal Classifiers. (arXiv:2108.05677v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aleksandrova_M/0/1/0/all/0/1">Marharyta Aleksandrova</a>, <a href="http://arxiv.org/find/cs/1/au:+Chertov_O/0/1/0/all/0/1">Oleg Chertov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05677">
                                    <div class="article-summary-box-inner">
                                        <span>The property of conformal predictors to guarantee the required accuracy rate
makes this framework attractive in various practical applications. However,
this property is achieved at a price of reduction in precision. In the case of
conformal classification, the systems can output multiple class labels instead
of one. It is also known from the literature, that the choice of nonconformity
function has a major impact on the efficiency of conformal classifiers.
Recently, it was shown that different model-agnostic nonconformity functions
result in conformal classifiers with different characteristics. For a Neural
Network-based conformal classifier, the inverse probability (or hinge loss)
allows minimizing the average number of predicted labels, and margin results in
a larger fraction of singleton predictions. In this work, we aim to further
extend this study. We perform an experimental evaluation using 8 different
classification algorithms and discuss when the previously observed relationship
holds or not. Additionally, we propose a successful method to combine the
properties of these two nonconformity functions. The experimental evaluation is
done using 11 real and 5 synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems. (arXiv:2108.05385v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yufei Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xingquan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Min Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ali Muhamed Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1">Hanqi Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherubin_L/0/1/0/all/0/1">Laurent Cherubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05385">
                                    <div class="article-summary-box-inner">
                                        <span>Spatio-temporal forecasting is of great importance in a wide range of
dynamical systems applications from atmospheric science, to recent COVID-19
spread modeling. These applications rely on accurate predictions of
spatio-temporal structured data reflecting real-world phenomena. A stunning
characteristic is that the dynamical system is not only driven by some physics
laws but also impacted by the localized factor in spatial and temporal regions.
One of the major challenges is to infer the underlying causes, which generate
the perceived data stream and propagate the involved causal dynamics through
the distributed observing units. Another challenge is that the success of
machine learning based predictive models requires massive annotated data for
model training. However, the acquisition of high-quality annotated data is
objectively manual and tedious as it needs a considerable amount of human
intervention, making it infeasible in fields that require high levels of
expertise. To tackle these challenges, we advocate a spatio-temporal
physics-coupled neural networks (ST-PCNN) model to learn the underlying physics
of the dynamical system and further couple the learned physics to assist the
learning of the recurring dynamics. To deal with data-acquisition constraints,
an active learning mechanism with Kriging for actively acquiring the most
informative data is proposed for ST-PCNN training in a partially observable
environment. Our experiments on both synthetic and real-world datasets exhibit
that the proposed ST-PCNN with active learning converges to near optimal
accuracy with substantially fewer instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python. (arXiv:1909.02688v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1">Thomas L. Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tingshan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedigo_B/0/1/0/all/0/1">Benjamin D. Pedigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.02688">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Gaussian mixture modeling is a fundamental tool in clustering, as
well as discriminant analysis and semiparametric density estimation. However,
estimating the optimal model for any given number of components is an NP-hard
problem, and estimating the number of components is in some respects an even
harder problem. Findings: In R, a popular package called mclust addresses both
of these problems. However, Python has lacked such a package. We therefore
introduce AutoGMM, a Python algorithm for automatic Gaussian mixture modeling,
and its hierarchical version, HGMM. AutoGMM builds upon scikit-learn&#x27;s
AgglomerativeClustering and GaussianMixture classes, with certain modifications
to make the results more stable. Empirically, on several different
applications, AutoGMM performs approximately as well as mclust, and sometimes
better. Conclusions: AutoMM, a freely available Python package, enables
efficient Gaussian mixture modeling by automatically selecting the
initialization, number of clusters and covariance constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit Attenuating Weight Normalization. (arXiv:2108.05839v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aman Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanath_R/0/1/0/all/0/1">Rohan Ramanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1">Anika Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sirou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingzhou Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Keerthi_S/0/1/0/all/0/1">S. Sathiya Keerthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05839">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized deep networks trained using gradient-based optimizers are
a popular choice for solving classification and ranking problems. Without
appropriately tuned $\ell_2$ regularization or weight decay, such networks have
the tendency to make output scores (logits) and network weights large, causing
training loss to become too small and the network to lose its adaptivity
(ability to move around) in the parameter space. Although regularization is
typically understood from an overfitting perspective, we highlight its role in
making the network more adaptive and enabling it to escape more easily from
weights that generalize poorly. To provide such a capability, we propose a
method called Logit Attenuating Weight Normalization (LAWN), that can be
stacked onto any gradient-based optimizer. LAWN controls the logits by
constraining the weight norms of layers in the final homogeneous sub-network.
Empirically, we show that the resulting LAWN variant of the optimizer makes a
deep network more adaptive to finding minimas with superior generalization
performance on large-scale image classification and recommender systems. While
LAWN is particularly impressive in improving Adam, it greatly improves all
optimizers when used with large batch sizes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A functional mirror ascent view of policy gradient methods with function approximation. (arXiv:2108.05828v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1">Sharan Vaswani</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1">Olivier Bachem</a>, <a href="http://arxiv.org/find/cs/1/au:+Totaro_S/0/1/0/all/0/1">Simone Totaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_R/0/1/0/all/0/1">Robert Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>, <a href="http://arxiv.org/find/cs/1/au:+Machado_M/0/1/0/all/0/1">Marlos C. Machado</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05828">
                                    <div class="article-summary-box-inner">
                                        <span>We use functional mirror ascent to propose a general framework (referred to
as FMA-PG) for designing policy gradient methods. The functional perspective
distinguishes between a policy&#x27;s functional representation (what are its
sufficient statistics) and its parameterization (how are these statistics
represented) and naturally results in computationally efficient off-policy
updates. For simple policy parameterizations, the FMA-PG framework ensures that
the optimal policy is a fixed point of the updates. It also allows us to handle
complex policy parameterizations (e.g., neural networks) while guaranteeing
policy improvement. Our framework unifies several PG methods and opens the way
for designing sample-efficient variants of existing methods. Moreover, it
recovers important implementation heuristics (e.g., using forward vs reverse KL
divergence) in a principled way. With a softmax functional representation,
FMA-PG results in a variant of TRPO with additional desirable properties. It
also suggests an improved variant of PPO, whose robustness and efficiency we
empirically demonstrate on MuJoCo. Via experiments on simple reinforcement
learning problems, we evaluate algorithms instantiated by FMA-PG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlation Clustering with Asymmetric Classification Errors. (arXiv:2108.05696v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarov_J/0/1/0/all/0/1">Jafar Jafarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalhan_S/0/1/0/all/0/1">Sanchit Kalhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Makarychev_Y/0/1/0/all/0/1">Yury Makarychev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05696">
                                    <div class="article-summary-box-inner">
                                        <span>In the Correlation Clustering problem, we are given a weighted graph $G$ with
its edges labeled as &quot;similar&quot; or &quot;dissimilar&quot; by a binary classifier. The goal
is to produce a clustering that minimizes the weight of &quot;disagreements&quot;: the
sum of the weights of &quot;similar&quot; edges across clusters and &quot;dissimilar&quot; edges
within clusters. We study the correlation clustering problem under the
following assumption: Every &quot;similar&quot; edge $e$ has weight
$\mathbf{w}_e\in[\alpha \mathbf{w}, \mathbf{w}]$ and every &quot;dissimilar&quot; edge
$e$ has weight $\mathbf{w}_e\geq \alpha \mathbf{w}$ (where $\alpha\leq 1$ and
$\mathbf{w}&gt;0$ is a scaling parameter). We give a $(3 + 2 \log_e (1/\alpha))$
approximation algorithm for this problem. This assumption captures well the
scenario when classification errors are asymmetric. Additionally, we show an
asymptotically matching Linear Programming integrality gap of $\Omega(\log
1/\alpha)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Feedback. (arXiv:2108.05382v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaofei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1">Kourosh Hakhamaneshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1">Michael Laskin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05382">
                                    <div class="article-summary-box-inner">
                                        <span>A promising approach to solving challenging long-horizon tasks has been to
extract behavior priors (skills) by fitting generative models to large offline
datasets of demonstrations. However, such generative models inherit the biases
of the underlying data and result in poor and unusable skills when trained on
imperfect demonstration data. To better align skill extraction with human
intent we present Skill Preferences (SkiP), an algorithm that learns a model
over human preferences and uses it to extract human-aligned skills from offline
data. After extracting human-preferred skills, SkiP also utilizes human
feedback to solve down-stream tasks with RL. We show that SkiP enables a
simulated kitchen robot to solve complex multi-step manipulation tasks and
substantially outperforms prior leading RL algorithms with human preferences as
well as leading skill extraction algorithms without human preferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hybrid Learning Approach to Detecting Regime Switches in Financial Markets. (arXiv:2108.05801v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Akioyamen_P/0/1/0/all/0/1">Peter Akioyamen</a> (1), <a href="http://arxiv.org/find/q-fin/1/au:+Tang_Y/0/1/0/all/0/1">Yi Zhou Tang</a> (1), <a href="http://arxiv.org/find/q-fin/1/au:+Hussien_H/0/1/0/all/0/1">Hussien Hussien</a> (1) ((1) Western University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05801">
                                    <div class="article-summary-box-inner">
                                        <span>Financial markets are of much interest to researchers due to their dynamic
and stochastic nature. With their relations to world populations, global
economies and asset valuations, understanding, identifying and forecasting
trends and regimes are highly important. Attempts have been made to forecast
market trends by employing machine learning methodologies, while statistical
techniques have been the primary methods used in developing market regime
switching models used for trading and hedging. In this paper we present a novel
framework for the detection of regime switches within the US financial markets.
Principal component analysis is applied for dimensionality reduction and the
k-means algorithm is used as a clustering technique. Using a combination of
cluster analysis and classification, we identify regimes in financial markets
based on publicly available economic data. We display the efficacy of the
framework by constructing and assessing the performance of two trading
strategies based on detected regimes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">perf4sight: A toolflow to model CNN training performance on Edge GPUs. (arXiv:2108.05580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_A/0/1/0/all/0/1">Aditya Rajagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1">Christos-Savvas Bouganis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05580">
                                    <div class="article-summary-box-inner">
                                        <span>The increased memory and processing capabilities of today&#x27;s edge devices
create opportunities for greater edge intelligence. In the domain of vision,
the ability to adapt a Convolutional Neural Network&#x27;s (CNN) structure and
parameters to the input data distribution leads to systems with lower memory
footprint, latency and power consumption. However, due to the limited compute
resources and memory budget on edge devices, it is necessary for the system to
be able to predict the latency and memory footprint of the training process in
order to identify favourable training configurations of the network topology
and device combination for efficient network adaptation. This work proposes
perf4sight, an automated methodology for developing accurate models that
predict CNN training memory footprint and latency given a target device and
network. This enables rapid identification of network topologies that can be
retrained on the edge device with low resource consumption. With PyTorch as the
framework and NVIDIA Jetson TX2 as the target device, the developed models
predict training memory footprint and latency with 95% and 91% accuracy
respectively for a wide range of networks, opening the path towards efficient
network adaptation on edge GPUs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Medical Image Segmentation. (arXiv:2108.05476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_P/0/1/0/all/0/1">Pedro H. T. Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1">Hugo Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1">Jefersson A. dos Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05476">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach for few-shot semantic segmentation
with sparse labeled images. We investigate the effectiveness of our method,
which is based on the Model-Agnostic Meta-Learning (MAML) algorithm, in the
medical scenario, where the use of sparse labeling and few-shot can alleviate
the cost of producing new annotated datasets. Our method uses sparse labels in
the meta-training and dense labels in the meta-test, thus making the model
learn to predict dense labels from sparse ones. We conducted experiments with
four Chest X-Ray datasets to evaluate two types of annotations (grid and
points). The results show that our method is the most suitable when the target
domain highly differs from source domains, achieving Jaccard scores comparable
to dense labels, using less than 2% of the pixels of an image with labels in
few-shot scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Critical Connectivity Radius for Randomly-Generated, High Dimensional Data Points. (arXiv:1602.03822v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1602.03822">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by a $2$-dimensional (unsupervised) image segmentation task whereby
local regions of pixels are clustered via edge detection methods, a more
general probabilistic mathematical framework is devised. Critical thresholds
are calculated that indicate strong correlation between randomly-generated,
high dimensional data points that have been projected into structures in a
partition of a bounded, $2$-dimensional area, of which, an image is a special
case. A neighbor concept for structures in the partition is defined and a
critical radius is uncovered. Measured from a central structure in localized
regions of the partition, the radius indicates strong, long and short range
correlation in the count of occupied structures. The size of a short interval
of radii is estimated upon which the transition from short-to-long range
correlation is virtually assured, which defines a demarcation of when an image
ceases to be &quot;interesting&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search From Task Similarity Measure. (arXiv:2103.00241v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1">Cat P. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Soltani_M/0/1/0/all/0/1">Mohammadreza Soltani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravier_R/0/1/0/all/0/1">Robert Ravier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00241">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a neural architecture search framework based on a
similarity measure between the baseline tasks and the incoming target task. We
first define the notion of task similarity based on the log-determinant of the
Fisher Information Matrices. Next, we compute the task similarity from each of
the baseline tasks to the incoming target task. By utilizing the relation
between a target and a set of learned baseline tasks, the search space of
architectures for the incoming target task can be significantly reduced, making
the discovery of the best candidates in the set of possible architectures
tractable and efficient, in terms of GPU days. This method eliminates the
requirement for training the networks from scratch for the incoming target task
as well as introducing the bias in the initialization of the search space from
the human domain. Experimental results with 8 classification tasks in MNIST and
CIFAR-10 datasets illustrate the efficacy of our proposed approach and its
competitiveness with other state-of-art methods in terms of the classification
performance, the number of parameters, and the search time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoder Fusion RNN: Context and Interaction Aware Decoders for Trajectory Prediction. (arXiv:2108.05814v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rella_E/0/1/0/all/0/1">Edoardo Mello Rella</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zaech_J/0/1/0/all/0/1">Jan-Nico Zaech</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Liniger_A/0/1/0/all/0/1">Alexander Liniger</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a> (1 and 2) ((1) Computer Vision Lab, ETH Z&#xfc;urich (2) PSI, KU Leuven)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05814">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the future behavior of all traffic agents in the vicinity is a
key task to achieve safe and reliable autonomous driving systems. It is a
challenging problem as agents adjust their behavior depending on their
intentions, the others&#x27; actions, and the road layout. In this paper, we propose
Decoder Fusion RNN (DF-RNN), a recurrent, attention-based approach for motion
forecasting. Our network is composed of a recurrent behavior encoder, an
inter-agent multi-headed attention module, and a context-aware decoder. We
design a map encoder that embeds polyline segments, combines them to create a
graph structure, and merges their relevant parts with the agents&#x27; embeddings.
We fuse the encoded map information with further inter-agent interactions only
inside the decoder and propose to use explicit training as a method to
effectively utilize the information available. We demonstrate the efficacy of
our method by testing it on the Argoverse motion forecasting dataset and show
its state-of-the-art performance on the public benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">m-RevNet: Deep Reversible Neural Networks with Momentum. (arXiv:2108.05862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Duo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Shang-Hua Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05862">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the connections between deep residual networks and
first-order Ordinary Differential Equations (ODEs) have been disclosed. In this
work, we further bridge the deep neural architecture design with the
second-order ODEs and propose a novel reversible neural network, termed as
m-RevNet, that is characterized by inserting momentum update to residual
blocks. The reversible property allows us to perform backward pass without
access to activation values of the forward pass, greatly relieving the storage
burden during training. Furthermore, the theoretical foundation based on
second-order ODEs grants m-RevNet with stronger representational power than
vanilla residual networks, which potentially explains its performance gains.
For certain learning scenarios, we analytically and empirically reveal that our
m-RevNet succeeds while standard ResNet fails. Comprehensive experiments on
various image classification and semantic segmentation benchmarks demonstrate
the superiority of our m-RevNet over ResNet, concerning both memory efficiency
and recognition performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MT-ORL: Multi-Task Occlusion Relationship Learning. (arXiv:2108.05722v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_P/0/1/0/all/0/1">Panhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+ZHANG_L/0/1/0/all/0/1">Lin ZHANG</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zijian Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunpeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xuejing Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1">Anlong Ming</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05722">
                                    <div class="article-summary-box-inner">
                                        <span>Retrieving occlusion relation among objects in a single image is challenging
due to sparsity of boundaries in image. We observe two key issues in existing
works: firstly, lack of an architecture which can exploit the limited amount of
coupling in the decoder stage between the two subtasks, namely occlusion
boundary extraction and occlusion orientation prediction, and secondly,
improper representation of occlusion orientation. In this paper, we propose a
novel architecture called Occlusion-shared and Path-separated Network (OPNet),
which solves the first issue by exploiting rich occlusion cues in shared
high-level features and structured spatial information in task-specific
low-level features. We then design a simple but effective orthogonal occlusion
representation (OOR) to tackle the second issue. Our method surpasses the
state-of-the-art methods by 6.1%/8.3% Boundary-AP and 6.5%/10% Orientation-AP
on standard PIOD/BSDS ownership datasets. Code is available at
https://github.com/fengpanhe/MT-ORL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Engineering an Efficient Boolean Functional Synthesis Engine. (arXiv:2108.05717v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golia_P/0/1/0/all/0/1">Priyanka Golia</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivovsky_F/0/1/0/all/0/1">Friedrich Slivovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Subhajit Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Meel_K/0/1/0/all/0/1">Kuldeep S. Meel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05717">
                                    <div class="article-summary-box-inner">
                                        <span>Given a Boolean specification between a set of inputs and outputs, the
problem of Boolean functional synthesis is to synthesise each output as a
function of inputs such that the specification is met. Although the past few
years have witnessed intense algorithmic development, accomplishing scalability
remains the holy grail. The state-of-the-art approach combines machine learning
and automated reasoning to efficiently synthesise Boolean functions. In this
paper, we propose four algorithmic improvements for a data-driven framework for
functional synthesis: using a dependency-driven multi-classifier to learn
candidate function, extracting uniquely defined functions by interpolation,
variables retention, and using lexicographic MaxSAT to repair candidates. We
implement these improvements in the state-of-the-art framework, called Manthan.
The proposed framework is called Manthan2. Manthan2 shows significantly
improved runtime performance compared to Manthan. In an extensive experimental
evaluation on 609 benchmarks, Manthan2 is able to synthesise a Boolean function
vector for 509 instances compared to 356 instances solved by Manthan--- an
increment of 153 instances over the state-of-the-art. To put this into
perspective, Manthan improved on the prior state-of-the-art by only 76
instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AffRankNet+: Ranking Affect Using Privileged Information. (arXiv:2108.05598v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makantasis_K/0/1/0/all/0/1">Konstantinos Makantasis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05598">
                                    <div class="article-summary-box-inner">
                                        <span>Many of the affect modelling tasks present an asymmetric distribution of
information between training and test time; additional information is given
about the training data, which is not available at test time. Learning under
this setting is called Learning Under Privileged Information (LUPI). At the
same time, due to the ordinal nature of affect annotations, formulating affect
modelling tasks as supervised learning ranking problems is gaining ground
within the Affective Computing research community. Motivated by the two facts
above, in this study, we introduce a ranking model that treats additional
information about the training data as privileged information to accurately
rank affect states. Our ranking model extends the well-known RankNet model to
the LUPI paradigm, hence its name AffRankNet+. To the best of our knowledge, it
is the first time that a ranking model based on neural networks exploits
privileged information. We evaluate the performance of the proposed model on
the public available Afew-VA dataset and compare it against the RankNet model,
which does not use privileged information. Experimental evaluation indicates
that the AffRankNet+ model can yield significantly better performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Sparse Regularization: The Impact of Depth and Early Stopping. (arXiv:2108.05574v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1">Jiangyuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1">Thanh V. Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Hegde_C/0/1/0/all/0/1">Chinmay Hegde</a>, <a href="http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1">Raymond K. W. Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05574">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the implicit bias of gradient descent for sparse
regression. We extend results on regression with quadratic parametrization,
which amounts to depth-2 diagonal linear networks, to more general depth-N
networks, under more realistic settings of noise and correlated designs. We
show that early stopping is crucial for gradient descent to converge to a
sparse model, a phenomenon that we call implicit sparse regularization. This
result is in sharp contrast to known results for noiseless and
uncorrelated-design cases. We characterize the impact of depth and early
stopping and show that for a general depth parameter N, gradient descent with
early stopping achieves minimax optimal sparse recovery with sufficiently small
initialization and step size. In particular, we show that increasing depth
enlarges the scale of working initialization and the early-stopping window,
which leads to more stable gradient paths for sparse recovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning Approach to Active Learning for Image Classification. (arXiv:2108.05595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Werner_T/0/1/0/all/0/1">Thorben Werner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05595">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning requires large amounts of labeled data to fit a model. Many
datasets are already publicly available, nevertheless forcing application
possibilities of machine learning to the domains of those public datasets. The
ever-growing penetration of machine learning algorithms in new application
areas requires solutions for the need for data in those new domains. This
thesis works on active learning as one possible solution to reduce the amount
of data that needs to be processed by hand, by processing only those datapoints
that specifically benefit the training of a strong model for the task. A newly
proposed framework for framing the active learning workflow as a reinforcement
learning problem is adapted for image classification and a series of three
experiments is conducted. Each experiment is evaluated and potential issues
with the approach are outlined. Each following experiment then proposes
improvements to the framework and evaluates their impact. After the last
experiment, a final conclusion is drawn, unfortunately rejecting this work&#x27;s
hypothesis and outlining that the proposed framework at the moment is not
capable of improving active learning for image classification with a trained
reinforcement learning agent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Hash Robustly, with Guarantees. (arXiv:2108.05433v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andoni_A/0/1/0/all/0/1">Alexandr Andoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Beaglehole_D/0/1/0/all/0/1">Daniel Beaglehole</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05433">
                                    <div class="article-summary-box-inner">
                                        <span>The indexing algorithms for the high-dimensional nearest neighbor search
(NNS) with the best worst-case guarantees are based on the randomized Locality
Sensitive Hashing (LSH), and its derivatives. In practice, many heuristic
approaches exist to &quot;learn&quot; the best indexing method in order to speed-up NNS,
crucially adapting to the structure of the given dataset.

Oftentimes, these heuristics outperform the LSH-based algorithms on real
datasets, but, almost always, come at the cost of losing the guarantees of
either correctness or robust performance on adversarial queries, or apply to
datasets with an assumed extra structure/model. In this paper, we design an NNS
algorithm for the Hamming space that has worst-case guarantees essentially
matching that of theoretical algorithms, while optimizing the hashing to the
structure of the dataset (think instance-optimal algorithms) for performance on
the minimum-performing query. We evaluate the algorithm&#x27;s ability to optimize
for a given dataset both theoretically and practically. On the theoretical
side, we exhibit a natural setting (dataset model) where our algorithm is much
better than the standard theoretical one. On the practical side, we run
experiments that show that our algorithm has a 1.8x and 2.1x better recall on
the worst-performing queries to the MNIST and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Sequential Slate Optimization. (arXiv:2108.05618v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Mingjian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Indrakanti_S/0/1/0/all/0/1">Saratchandra Indrakanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kannadasan_M/0/1/0/all/0/1">Manojkumar Rangasamy Kannadasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagherjeiran_A/0/1/0/all/0/1">Abraham Bagherjeiran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05618">
                                    <div class="article-summary-box-inner">
                                        <span>The top search results matching a user query that are displayed on the first
page are critical to the effectiveness and perception of a search system. A
search ranking system typically orders the results by independent
query-document scores to produce a slate of search results. However, such
unilateral scoring methods may fail to capture inter-document dependencies that
users are sensitive to, thus producing a sub-optimal slate. Further, in
practice, many real-world applications such as e-commerce search require
enforcing certain distributional criteria at the slate-level, due to business
objectives or long term user retention goals. Unilateral scoring of results
does not explicitly support optimizing for such objectives with respect to a
slate. Hence, solutions to the slate optimization problem must consider the
optimal selection and order of the documents, along with adherence to
slate-level distributional criteria. To that end, we propose a hybrid framework
extended from traditional slate optimization to solve the conditional slate
optimization problem. We introduce conditional sequential slate optimization
(CSSO), which jointly learns to optimize for traditional ranking metrics as
well as prescribed distribution criteria of documents within the slate. The
proposed method can be applied to practical real world problems such as
enforcing diversity in e-commerce search results, mitigating bias in top
results and personalization of results. Experiments on public datasets and
real-world data from e-commerce datasets show that CSSO outperforms popular
comparable ranking methods in terms of adherence to distributional criteria
while producing comparable or better relevance metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resetting the baseline: CT-based COVID-19 diagnosis with Deep Transfer Learning is not as accurate as widely thought. (arXiv:2108.05649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altaf_F/0/1/0/all/0/1">Fouzia Altaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Syed M.S. Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05649">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is gaining instant popularity in computer aided diagnosis of
COVID-19. Due to the high sensitivity of Computed Tomography (CT) to this
disease, CT-based COVID-19 detection with visual models is currently at the
forefront of medical imaging research. Outcomes published in this direction are
frequently claiming highly accurate detection under deep transfer learning.
This is leading medical technologists to believe that deep transfer learning is
the mainstream solution for the problem. However, our critical analysis of the
literature reveals an alarming performance disparity between different
published results. Hence, we conduct a systematic thorough investigation to
analyze the effectiveness of deep transfer learning for COVID-19 detection with
CT images. Exploring 14 state-of-the-art visual models with over 200 model
training sessions, we conclusively establish that the published literature is
frequently overestimating transfer learning performance for the problem, even
in the prestigious scientific sources. The roots of overestimation trace back
to inappropriate data curation. We also provide case studies that consider more
realistic scenarios, and establish transparent baselines for the problem. We
hope that our reproducible investigation will help in curbing hype-driven
claims for the critical problem of COVID-19 diagnosis, and pave the way for a
more transparent performance evaluation of techniques for CT-based COVID-19
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacks against Ranking Algorithms with Text Embeddings: a Case Study on Recruitment Algorithms. (arXiv:2108.05490v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samadi_A/0/1/0/all/0/1">Anahita Samadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1">Debapriya Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Nilizadeh_S/0/1/0/all/0/1">Shirin Nilizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05490">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, some studies have shown that text classification tasks are
vulnerable to poisoning and evasion attacks. However, little work has
investigated attacks against decision making algorithms that use text
embeddings, and their output is a ranking. In this paper, we focus on ranking
algorithms for recruitment process, that employ text embeddings for ranking
applicants resumes when compared to a job description. We demonstrate both
white box and black box attacks that identify text items, that based on their
location in embedding space, have significant contribution in increasing the
similarity score between a resume and a job description. The adversary then
uses these text items to improve the ranking of their resume among others. We
tested recruitment algorithms that use the similarity scores obtained from
Universal Sentence Encoder (USE) and Term Frequency Inverse Document Frequency
(TF IDF) vectors. Our results show that in both adversarial settings, on
average the attacker is successful. We also found that attacks against TF IDF
is more successful compared to USE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DOI: Divergence-based Out-of-Distribution Indicators via Deep Generative Models. (arXiv:2108.05509v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_X/0/1/0/all/0/1">Xiaohui Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mingliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_D/0/1/0/all/0/1">Dan Pei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05509">
                                    <div class="article-summary-box-inner">
                                        <span>To ensure robust and reliable classification results, OoD
(out-of-distribution) indicators based on deep generative models are proposed
recently and are shown to work well on small datasets. In this paper, we
conduct the first large collection of benchmarks (containing 92 dataset pairs,
which is 1 order of magnitude larger than previous ones) for existing OoD
indicators and observe that none perform well. We thus advocate that a large
collection of benchmarks is mandatory for evaluating OoD indicators. We propose
a novel theoretical framework, DOI, for divergence-based Out-of-Distribution
indicators (instead of traditional likelihood-based) in deep generative models.
Following this framework, we further propose a simple and effective OoD
detection algorithm: Single-shot Fine-tune. It significantly outperforms past
works by 5~8 in AUROC, and its performance is close to optimal. In recent, the
likelihood criterion is shown to be ineffective in detecting OoD. Single-shot
Fine-tune proposes a novel fine-tune criterion to detect OoD, by whether the
likelihood of the testing sample is improved after fine-tuning a well-trained
model on it. Fine-tune criterion is a clear and easy-following criterion, which
will lead the OoD domain into a new stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DARTS for Inverse Problems: a Study on Hyperparameter Sensitivity. (arXiv:2108.05647v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1">Jonas Geiping</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1">Jovita Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05647">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search (DARTS) is a widely researched tool for
neural architecture search, due to its promising results for image
classification. The main benefit of DARTS is the effectiveness achieved through
the weight-sharing one-shot paradigm, which allows efficient architecture
search. In this work, we investigate DARTS in a systematic case study of
inverse problems, which allows us to analyze these potential benefits in a
controlled manner. Although we demonstrate that the success of DARTS can be
extended from image classification to reconstruction, our experiments yield
three fundamental difficulties in the evaluation of DARTS-based methods: First,
the results show a large variance in all test cases. Second, the final
performance is highly dependent on the hyperparameters of the optimizer. And
third, the performance of the weight-sharing architecture used during training
does not reflect the final performance of the found architecture well. Thus, we
conclude the necessity to 1) report the results of any DARTS-based methods from
several runs along with its underlying performance statistics, 2) show the
correlation of the training and final architecture performance, and 3)
carefully consider if the computational efficiency of DARTS outweighs the costs
of hyperparameter optimization and multiple runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On minimal representations of shallow ReLU networks. (arXiv:2108.05643v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dereich_S/0/1/0/all/0/1">S. Dereich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kassing_S/0/1/0/all/0/1">S. Kassing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05643">
                                    <div class="article-summary-box-inner">
                                        <span>The realization function of a shallow ReLU network is a continuous and
piecewise affine function $f:\mathbb R^d\to \mathbb R$, where the domain
$\mathbb R^{d}$ is partitioned by a set of $n$ hyperplanes into cells on which
$f$ is affine. We show that the minimal representation for $f$ uses either $n$,
$n+1$ or $n+2$ neurons and we characterize each of the three cases. In the
particular case, where the input layer is one-dimensional, minimal
representations always use at most $n+1$ neurons but in all higher dimensional
settings there are functions for which $n+2$ neurons are needed. Then we show
that the set of minimal networks representing $f$ forms a
$C^\infty$-submanifold $M$ and we derive the dimension and the number of
connected components of $M$. Additionally, we give a criterion for the
hyperplanes that guarantees that all continuous, piecewise affine functions are
realization functions of appropriate ReLU networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Local Planning with Linear Function Approximation. (arXiv:2108.05533v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1">Botao Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1">Yasin Abbasi-Yadkori</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazi%7Bc%7D_N/0/1/0/all/0/1">Nevena Lazi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesv%7Ba%7Dri_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05533">
                                    <div class="article-summary-box-inner">
                                        <span>We study query and computationally efficient planning algorithms with linear
function approximation and a simulator. We assume that the agent only has local
access to the simulator, meaning that the agent can only query the simulator at
states that have been visited before. This setting is more practical than many
prior works on reinforcement learning with a generative model. We propose an
algorithm named confident Monte Carlo least square policy iteration (Confident
MC-LSPI) for this setting. Under the assumption that the Q-functions of all
deterministic policies are linear in known features of the state-action pairs,
we show that our algorithm has polynomial query and computational complexities
in the dimension of the features, the effective planning horizon and the
targeted sub-optimality, while these complexities are independent of the size
of the state space. One technical contribution of our work is the introduction
of a novel proof technique that makes use of a virtual policy iteration
algorithm. We use this method to leverage existing results on
$\ell_\infty$-bounded approximate policy iteration to show that our algorithm
can learn the optimal policy for the given initial state even only with local
access to the simulator. We believe that this technique can be extended to
broader settings beyond this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ontology drift is a challenge for explainable data governance. (arXiv:2108.05401v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05401">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the needs for explainable AI that arise from Standard No. 239
from the Basel Committee on Banking Standards (BCBS 239), which outlines 11
principles for effective risk data aggregation and risk reporting for financial
institutions. Of these, explainableAI is necessary for compliance in two key
aspects: data quality, and appropriate reporting for multiple stakeholders. We
describe the implementation challenges for one specific regulatory
requirement:that of having a complete data taxonomy that is appropriate for
firmwide use. The constantly evolving nature of financial ontologies
necessitate a continuous updating process to ensure ongoing compliance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robotic Testbed for Rendezvous and Optical Navigation: Multi-Source Calibration and Machine Learning Use Cases. (arXiv:2108.05529v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1">Tae Ha Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosse_J/0/1/0/all/0/1">Juergen Bosse</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmico_S/0/1/0/all/0/1">Simone D&#x27;Amico</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05529">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents the most recent advances of the Robotic Testbed for
Rendezvous and Optical Navigation (TRON) at Stanford University - the first
robotic testbed capable of validating machine learning algorithms for
spaceborne optical navigation. The TRON facility consists of two 6
degrees-of-freedom KUKA robot arms and a set of Vicon motion track cameras to
reconfigure an arbitrary relative pose between a camera and a target mockup
model. The facility includes multiple Earth albedo light boxes and a sun lamp
to recreate the high-fidelity spaceborne illumination conditions. After the
overview of the facility, this work details the multi-source calibration
procedure which enables the estimation of the relative pose between the object
and the camera with millimeter-level position and millidegree-level orientation
accuracies. Finally, a comparative analysis of the synthetic and TRON simulated
imageries is performed using a Convolutional Neural Network (CNN) pre-trained
on the synthetic images. The result shows a considerable gap in the CNN&#x27;s
performance, suggesting the TRON simulated images can be used to validate the
robustness of any machine learning algorithms trained on more easily accessible
synthetic imagery from computer graphics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Contextual Appointment Scheduling Problem. (arXiv:2108.05531v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sadghiani_N/0/1/0/all/0/1">Nima Salehi Sadghiani</a>, <a href="http://arxiv.org/find/math/1/au:+Motiian_S/0/1/0/all/0/1">Saeid Motiian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05531">
                                    <div class="article-summary-box-inner">
                                        <span>This study is concerned with the determination of optimal appointment times
for a sequence of jobs with uncertain duration. We investigate the data-driven
Appointment Scheduling Problem (ASP) when one has $n$ observations of $p$
features (covariates) related to the jobs as well as historical data. We
formulate ASP as an Integrated Estimation and Optimization problem using a
task-based loss function. We justify the use of contexts by showing that not
including the them yields to inconsistent decisions, which translates to
sub-optimal appointments. We validate our approach through two numerical
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Trend Networks for Recommendations. (arXiv:2108.05552v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05552">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems aim to provide personalized services to users and are
playing an increasingly important role in our daily lives. The key of
recommender systems is to predict how likely users will interact with items
based on their historical online behaviors, e.g., clicks, add-to-cart,
purchases, etc. To exploit these user-item interactions, there are increasing
efforts on considering the user-item interactions as a user-item bipartite
graph and then performing information propagation in the graph via Graph Neural
Networks (GNNs). Given the power of GNNs in graph representation learning,
these GNN-based recommendation methods have remarkably boosted the
recommendation performance. Despite their success, most existing GNN-based
recommender systems overlook the existence of interactions caused by unreliable
behaviors (e.g., random/bait clicks) and uniformly treat all the interactions,
which can lead to sub-optimal and unstable performance. In this paper, we
investigate the drawbacks (e.g., non-adaptive propagation and non-robustness)
of existing GNN-based recommendation methods. To address these drawbacks, we
propose the Graph Trend Networks for recommendations (GTN) with principled
designs that can capture the adaptive reliability of the interactions.
Comprehensive experiments and ablation studies are presented to verify and
understand the effectiveness of the proposed framework. Our implementation and
datasets can be released after publication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization. (arXiv:2108.05449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Haitian Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1">Haofu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weijian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05449">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms mine knowledge from the training data and thus would
likely inherit the dataset&#x27;s bias information. As a result, the obtained model
would generalize poorly and even mislead the decision process in real-life
applications. We propose to remove the bias information misused by the target
task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly
extracts target and bias features disentangled from the latent representation
generated by a feature extractor and then learns to discover and remove the
correlation between the target and bias features. The correlation measurement
plays a critical role in adversarial debiasing and is conducted by a
cross-sample neural mutual information estimator. Moreover, we propose joint
content and local structural representation learning to boost mutual
information estimation for better performance. We conduct thorough experiments
on publicly available datasets to validate the advantages of the proposed
method over state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seven challenges for harmonizing explainability requirements. (arXiv:2108.05390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiahao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Storchan_V/0/1/0/all/0/1">Victor Storchan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05390">
                                    <div class="article-summary-box-inner">
                                        <span>Regulators have signalled an interest in adopting explainable AI(XAI)
techniques to handle the diverse needs for model governance, operational
servicing, and compliance in the financial services industry. In this short
overview, we review the recent technical literature in XAI and argue that based
on our current understanding of the field, the use of XAI techniques in
practice necessitate a highly contextualized approach considering the specific
needs of stakeholders for particular business applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Contract Theory based Incentive Mechanism for Federated Learning. (arXiv:2108.05568v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_M/0/1/0/all/0/1">Mengmeng Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zehui Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_C/0/1/0/all/0/1">Cyril Leung</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05568">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) serves as a data privacy-preserved machine learning
paradigm, and realizes the collaborative model trained by distributed clients.
To accomplish an FL task, the task publisher needs to pay financial incentives
to the FL server and FL server offloads the task to the contributing FL
clients. It is challenging to design proper incentives for the FL clients due
to the fact that the task is privately trained by the clients. This paper aims
to propose a contract theory based FL task training model towards minimizing
incentive budget subject to clients being individually rational (IR) and
incentive compatible (IC) in each FL training round. We design a
two-dimensional contract model by formally defining two private types of
clients, namely data quality and computation effort. To effectively aggregate
the trained models, a contract-based aggregator is proposed. We analyze the
feasible and optimal contract solutions to the proposed contract model.
%Experimental results demonstrate that the proposed framework and contract
model can effective improve the generation accuracy of FL tasks. Experimental
results show that the generalization accuracy of the FL tasks can be improved
by the proposed incentive mechanism where contract-based aggregation is
applied.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seismic wave propagation and inversion with Neural Operators. (arXiv:2108.05421v1 [physics.geo-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Yang_Y/0/1/0/all/0/1">Yan Yang</a>, <a href="http://arxiv.org/find/physics/1/au:+Gao_A/0/1/0/all/0/1">Angela F. Gao</a>, <a href="http://arxiv.org/find/physics/1/au:+Castellanos_J/0/1/0/all/0/1">Jorge C. Castellanos</a>, <a href="http://arxiv.org/find/physics/1/au:+Ross_Z/0/1/0/all/0/1">Zachary E. Ross</a>, <a href="http://arxiv.org/find/physics/1/au:+Azizzadenesheli_K/0/1/0/all/0/1">Kamyar Azizzadenesheli</a>, <a href="http://arxiv.org/find/physics/1/au:+Clayton_R/0/1/0/all/0/1">Robert W. Clayton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05421">
                                    <div class="article-summary-box-inner">
                                        <span>Seismic wave propagation forms the basis for most aspects of seismological
research, yet solving the wave equation is a major computational burden that
inhibits the progress of research. This is exaspirated by the fact that new
simulations must be performed when the velocity structure or source location is
perturbed. Here, we explore a prototype framework for learning general
solutions using a recently developed machine learning paradigm called Neural
Operator. A trained Neural Operator can compute a solution in negligible time
for any velocity structure or source location. We develop a scheme to train
Neural Operators on an ensemble of simulations performed with random velocity
models and source locations. As Neural Operators are grid-free, it is possible
to evaluate solutions on higher resolution velocity models than trained on,
providing additional computational efficiency. We illustrate the method with
the 2D acoustic wave equation and demonstrate the method&#x27;s applicability to
seismic tomography, using reverse mode automatic differentiation to compute
gradients of the wavefield with respect to the velocity structure. The
developed procedure is nearly an order of magnitude faster than using
conventional numerical methods for full waveform inversion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gap-Dependent Unsupervised Exploration for Reinforcement Learning. (arXiv:2108.05439v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05439">
                                    <div class="article-summary-box-inner">
                                        <span>For the problem of task-agnostic reinforcement learning (RL), an agent first
collects samples from an unknown environment without the supervision of reward
signals, then is revealed with a reward and is asked to compute a corresponding
near-optimal policy. Existing approaches mainly concern the worst-case
scenarios, in which no structural information of the reward/transition-dynamics
is utilized. Therefore the best sample upper bound is
$\propto\widetilde{\mathcal{O}}(1/\epsilon^2)$, where $\epsilon&gt;0$ is the
target accuracy of the obtained policy, and can be overly pessimistic. To
tackle this issue, we provide an efficient algorithm that utilizes a gap
parameter, $\rho&gt;0$, to reduce the amount of exploration. In particular, for an
unknown finite-horizon Markov decision process, the algorithm takes only
$\widetilde{\mathcal{O}} (1/\epsilon \cdot (H^3SA / \rho + H^4 S^2 A) )$
episodes of exploration, and is able to obtain an $\epsilon$-optimal policy for
a post-revealed reward with sub-optimality gap at least $\rho$, where $S$ is
the number of states, $A$ is the number of actions, and $H$ is the length of
the horizon, obtaining a nearly \emph{quadratic saving} in terms of $\epsilon$.
We show that, information-theoretically, this bound is nearly tight for $\rho 1$. We further show that
$\propto\widetilde{\mathcal{O}}(1)$ sample bound is possible for $H&#x3D;1$ (i.e.,
multi-armed bandit) or with a sampling simulator, establishing a stark
separation between those settings and the RL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Contrastive Learning for Irrigation Detection in Satellite Imagery. (arXiv:2108.05484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agastya_C/0/1/0/all/0/1">Chitra Agastya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghebremusse_S/0/1/0/all/0/1">Sirak Ghebremusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_I/0/1/0/all/0/1">Ian Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahabi_H/0/1/0/all/0/1">Hossein Vahabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Todeschini_A/0/1/0/all/0/1">Alberto Todeschini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05484">
                                    <div class="article-summary-box-inner">
                                        <span>Climate change has caused reductions in river runoffs and aquifer recharge
resulting in an increasingly unsustainable crop water demand from reduced
freshwater availability. Achieving food security while deploying water in a
sustainable manner will continue to be a major challenge necessitating careful
monitoring and tracking of agricultural water usage. Historically, monitoring
water usage has been a slow and expensive manual process with many
imperfections and abuses. Ma-chine learning and remote sensing developments
have increased the ability to automatically monitor irrigation patterns, but
existing techniques often require curated and labelled irrigation data, which
are expensive and time consuming to obtain and may not exist for impactful
areas such as developing countries. In this paper, we explore an end-to-end
real world application of irrigation detection with uncurated and unlabeled
satellite imagery. We apply state-of-the-art self-supervised deep learning
techniques to optical remote sensing data, and find that we are able to detect
irrigation with up to nine times better precision, 90% better recall and 40%
more generalization ability than the traditional supervised learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Agnostic Online Learning and Excellent Sets. (arXiv:2108.05569v1 [cs.DM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malliaris_M/0/1/0/all/0/1">Maryanthe Malliaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1">Shay Moran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05569">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit a key idea from the interaction of model theory and combinatorics,
the existence of large &#x60;&#x60;indivisible&#x27;&#x27; sets, called &#x60;&#x60;$\epsilon$-excellent,&#x27;&#x27;
in $k$-edge stable graphs (equivalently, Littlestone classes). Translating to
the language of probability, we find a quite different existence proof for
$\epsilon$-excellent sets in Littlestone classes, using regret bounds in online
learning. This proof applies to any $\epsilon &lt; {1}/{2}$, compared to $&lt;
{1}/{2^{2^k}}$ or so in the original proof. We include a second proof using
closure properties and the VC theorem, with other advantages but weaker bounds.
As a simple corollary, the Littlestone dimension remains finite under some
natural modifications to the definition. A theme in these proofs is the
interaction of two abstract notions of majority, arising from measure, and from
rank or dimension; we prove that these densely often coincide and that this is
characteristic of Littlestone (stable) classes. The last section lists several
open problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Decision-Making for Food Inspections. (arXiv:2108.05523v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shubham Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_B/0/1/0/all/0/1">Bhuvni Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kash_I/0/1/0/all/0/1">Ian A. Kash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05523">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the application of predictive models by the Chicago Department of
Public Health to schedule restaurant inspections and prioritize the detection
of critical violations of the food code. Performing the first analysis from the
perspective of fairness to the population served by the restaurants, we find
that the model treats inspections unequally based on the sanitarian who
conducted the inspection and that in turn there are both geographic and
demographic disparities in the benefits of the model. We examine both
approaches to use the original model in a fairer way and ways to train the
model to achieve fairness and find more success with the former class of
approaches. The challenges from this application point to important directions
for future work around fairness with collective entities rather than
individuals, the use of critical violations as a proxy, and the disconnect
between fair classification and fairness in the dynamic scheduling system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal analysis of the predictability of hand-gesture properties. (arXiv:2108.05762v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1">Taras Kucherenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1">Rajmund Nagy</a>, <a href="http://arxiv.org/find/cs/1/au:+Neff_M/0/1/0/all/0/1">Michael Neff</a>, <a href="http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05762">
                                    <div class="article-summary-box-inner">
                                        <span>Embodied conversational agents benefit from being able to accompany their
speech with gestures. Although many data-driven approaches to gesture
generation have been proposed in recent years, it is still unclear whether such
systems can consistently generate gestures that convey meaning. We investigate
which gesture properties (phase, category, and semantics) can be predicted from
speech text and/or audio using contemporary deep learning. In extensive
experiments, we show that gesture properties related to gesture meaning
(semantics and category) are predictable from text features (time-aligned BERT
embeddings) alone, but not from prosodic audio features, while rhythm-related
gesture properties (phase) on the other hand can be predicted from either
audio, text (with word-level timing information), or both. These results are
encouraging as they indicate that it is possible to equip an embodied agent
with content-wise meaningful co-speech gestures using a machine-learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-driven Graph Clustering Network. (arXiv:2108.05499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhihao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuheng Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05499">
                                    <div class="article-summary-box-inner">
                                        <span>The combination of the traditional convolutional network (i.e., an
auto-encoder) and the graph convolutional network has attracted much attention
in clustering, in which the auto-encoder extracts the node attribute feature
and the graph convolutional network captures the topological graph feature.
However, the existing works (i) lack a flexible combination mechanism to
adaptively fuse those two kinds of features for learning the discriminative
representation and (ii) overlook the multi-scale information embedded at
different layers for subsequent cluster assignment, leading to inferior
clustering results. To this end, we propose a novel deep clustering method
named Attention-driven Graph Clustering Network (AGCN). Specifically, AGCN
exploits a heterogeneity-wise fusion module to dynamically fuse the node
attribute feature and the topological graph feature. Moreover, AGCN develops a
scale-wise fusion module to adaptively aggregate the multi-scale features
embedded at different layers. Based on a unified optimization framework, AGCN
can jointly perform feature learning and cluster assignment in an unsupervised
fashion. Compared with the existing deep clustering methods, our method is more
flexible and effective since it comprehensively considers the numerous and
discriminative information embedded in the network and directly produces the
clustering results. Extensive quantitative and qualitative results on commonly
used benchmark datasets validate that our AGCN consistently outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intelligent computational model for the classification of Covid-19 with chest radiography compared to other respiratory diseases. (arXiv:2108.05536v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santos_P/0/1/0/all/0/1">Paula Santos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05536">
                                    <div class="article-summary-box-inner">
                                        <span>Lung X-ray images, if processed using statistical and computational methods,
can distinguish pneumonia from COVID-19. The present work shows that it is
possible to extract lung X-ray characteristics to improve the methods of
examining and diagnosing patients with suspected COVID-19, distinguishing them
from malaria, dengue, H1N1, tuberculosis, and Streptococcus pneumonia. More
precisely, an intelligent computational model was developed to process lung
X-ray images and classify whether the image is of a patient with COVID-19. The
images were processed and extracted their characteristics. These
characteristics were the input data for an unsupervised statistical learning
method, PCA, and clustering, which identified specific attributes of X-ray
images with Covid-19. The introduction of statistical models allowed a fast
algorithm, which used the X-means clustering method associated with the
Bayesian Information Criterion (CIB). The developed algorithm efficiently
distinguished each pulmonary pathology from X-ray images. The method exhibited
excellent sensitivity. The average recognition accuracy of COVID-19 was 0.93
and 0.051.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-12">2021-08-12</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Oriented Script Construction. (arXiv:2107.13189v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1">Chris Callison-Burch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13189">
                                    <div class="article-summary-box-inner">
                                        <span>The knowledge of scripts, common chains of events in stereotypical scenarios,
is a valuable asset for task-oriented natural language understanding systems.
We propose the Goal-Oriented Script Construction task, where a model produces a
sequence of steps to accomplish a given goal. We pilot our task on the first
multilingual script learning dataset supporting 18 languages collected from
wikiHow, a website containing half a million how-to articles. For baselines, we
consider both a generation-based approach using a language model and a
retrieval-based approach by first retrieving the relevant steps from a large
candidate pool and then ordering them. We show that our task is practical,
feasible but challenging for state-of-the-art Transformer models, and that our
methods can be readily deployed for various other datasets and domains with
decent zero-shot performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeliData: A dataset for deliberation in multi-party problem solving. (arXiv:2108.05271v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karadzhov_G/0/1/0/all/0/1">Georgi Karadzhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Stafford_T/0/1/0/all/0/1">Tom Stafford</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05271">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue systems research is traditionally focused on dialogues between two
interlocutors, largely ignoring group conversations. Moreover, most previous
research is focused either on task-oriented dialogue (e.g.\ restaurant
bookings) or user engagement (chatbots), while research on systems for
collaborative dialogues is an under-explored area. To this end, we introduce
the first publicly available dataset containing collaborative conversations on
solving a cognitive task, consisting of 500 group dialogues and 14k utterances.
Furthermore, we propose a novel annotation schema that captures deliberation
cues and release 50 dialogues annotated with it. Finally, we demonstrate the
usefulness of the annotated data in training classifiers to predict the
constructiveness of a conversation. The data collection platform, dataset and
annotated corpus are publicly available at https://delibot.xyz</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Compression for Domain Adaptation through Causal Effect Estimation. (arXiv:2101.07086v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rotman_G/0/1/0/all/0/1">Guy Rotman</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07086">
                                    <div class="article-summary-box-inner">
                                        <span>Recent improvements in the predictive quality of natural language processing
systems are often dependent on a substantial increase in the number of model
parameters. This has led to various attempts of compressing such models, but
existing methods have not considered the differences in the predictive power of
various model components or in the generalizability of the compressed models.
To understand the connection between model compression and out-of-distribution
generalization, we define the task of compressing language representation
models such that they perform best in a domain adaptation setting. We choose to
address this problem from a causal perspective, attempting to estimate the
average treatment effect (ATE) of a model component, such as a single layer, on
the model&#x27;s predictions. Our proposed ATE-guided Model Compression scheme
(AMoC), generates many model candidates, differing by the model components that
were removed. Then, we select the best candidate through a stepwise regression
model that utilizes the ATE to predict the expected performance on the target
domain. AMoC outperforms strong baselines on dozens of domain pairs across
three text classification and sequence tagging tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-Trained Models: Past, Present and Future. (arXiv:2106.07139v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuxian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuqi Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jiezhong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Ao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wentao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhiwu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Ruihua Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jinhui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07139">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pre-trained models (PTMs) such as BERT and GPT have recently
achieved great success and become a milestone in the field of artificial
intelligence (AI). Owing to sophisticated pre-training objectives and huge
model parameters, large-scale PTMs can effectively capture knowledge from
massive labeled and unlabeled data. By storing knowledge into huge parameters
and fine-tuning on specific tasks, the rich knowledge implicitly encoded in
huge parameters can benefit a variety of downstream tasks, which has been
extensively demonstrated via experimental verification and empirical analysis.
It is now the consensus of the AI community to adopt PTMs as backbone for
downstream tasks rather than learning models from scratch. In this paper, we
take a deep look into the history of pre-training, especially its special
relation with transfer learning and self-supervised learning, to reveal the
crucial position of PTMs in the AI development spectrum. Further, we
comprehensively review the latest breakthroughs of PTMs. These breakthroughs
are driven by the surge of computational power and the increasing availability
of data, towards four important directions: designing effective architectures,
utilizing rich contexts, improving computational efficiency, and conducting
interpretation and theoretical analysis. Finally, we discuss a series of open
problems and research directions of PTMs, and hope our view can inspire and
advance the future study of PTMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning. (arXiv:2108.05067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yinghong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fuyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaolin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuixing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05067">
                                    <div class="article-summary-box-inner">
                                        <span>Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Icelandic Parallel Abstracts Corpus. (arXiv:2108.05289v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simonarson_H/0/1/0/all/0/1">Haukur Barri S&#xed;monarson</a>, <a href="http://arxiv.org/find/cs/1/au:+Snaebjarnarson_V/0/1/0/all/0/1">V&#xe9;steinn Sn&#xe6;bjarnarson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05289">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new Icelandic-English parallel corpus, the Icelandic Parallel
Abstracts Corpus (IPAC), composed of abstracts from student theses and
dissertations. The texts were collected from the Skemman repository which keeps
records of all theses, dissertations and final projects from students at
Icelandic universities. The corpus was aligned based on sentence-level BLEU
scores, in both translation directions, from NMT models using Bleualign. The
result is a corpus of 64k sentence pairs from over 6 thousand parallel
abstracts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models. (arXiv:2108.04949v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zehao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_C/0/1/0/all/0/1">Chong Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Songzi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Adekkanattu_P/0/1/0/all/0/1">Prakash Adekkanattu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_J/0/1/0/all/0/1">Jyotishman Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1">Thomas J. George</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_W/0/1/0/all/0/1">William R. Hogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04949">
                                    <div class="article-summary-box-inner">
                                        <span>Social and behavioral determinants of health (SBDoH) have important roles in
shaping people&#x27;s health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients&#x27; SBDoH factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PGCD: a position-guied contributive distribution unit for aspect based sentiment analysis. (arXiv:2108.05098v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zijian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiangfeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05098">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect based sentiment analysis (ABSA), exploring sentim- ent polarity of
aspect-given sentence, has drawn widespread applications in social media and
public opinion. Previously researches typically derive aspect-independent
representation by sentence feature generation only depending on text data. In
this paper, we propose a Position-Guided Contributive Distribution (PGCD) unit.
It achieves a position-dependent contributive pattern and generates
aspect-related statement feature for ABSA task. Quoted from Shapley Value, PGCD
can gain position-guided contextual contribution and enhance the aspect-based
representation. Furthermore, the unit can be used for improving effects on
multimodal ABSA task, whose datasets restructured by ourselves. Extensive
experiments on both text and text-audio level using dataset (SemEval) show that
by applying the proposed unit, the mainstream models advance performance in
accuracy and F1 score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing. (arXiv:2108.04990v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1">Sanchit Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1">Arshdeep Sekhon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yangfeng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yanjun Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04990">
                                    <div class="article-summary-box-inner">
                                        <span>Interpretability methods like Integrated Gradient and LIME are popular
choices for explaining natural language model predictions with relative word
importance scores. These interpretations need to be robust for trustworthy NLP
applications in high-stake areas like medicine or finance. Our paper
demonstrates how interpretations can be manipulated by making simple word
perturbations on an input text. Via a small portion of word-level swaps, these
adversarial perturbations aim to make the resulting text semantically and
spatially similar to its seed input (therefore sharing similar
interpretations). Simultaneously, the generated examples achieve the same
prediction label as the seed yet are given a substantially different
explanation by the interpretation methods. Our experiments generate fragile
interpretations to attack two SOTA interpretation methods, across three popular
Transformer models and on two different NLP datasets. We observe that the rank
order correlation drops by over 20% when less than 10% of words are perturbed
on average. Further, rank-order correlation keeps decreasing as more words get
perturbed. Furthermore, we demonstrate that candidates generated from our
method have good quality metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Transformer-based Math Language Model for Handwritten Math Expression Recognition. (arXiv:2108.05002v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ung_H/0/1/0/all/0/1">Huy Quang Ung</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hung Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Nghia Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakagawa_M/0/1/0/all/0/1">Masaki Nakagawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05002">
                                    <div class="article-summary-box-inner">
                                        <span>Handwritten mathematical expressions (HMEs) contain ambiguities in their
interpretations, even for humans sometimes. Several math symbols are very
similar in the writing style, such as dot and comma or 0, O, and o, which is a
challenge for HME recognition systems to handle without using contextual
information. To address this problem, this paper presents a Transformer-based
Math Language Model (TMLM). Based on the self-attention mechanism, the
high-level representation of an input token in a sequence of tokens is computed
by how it is related to the previous tokens. Thus, TMLM can capture long
dependencies and correlations among symbols and relations in a mathematical
expression (ME). We trained the proposed language model using a corpus of
approximately 70,000 LaTeX sequences provided in CROHME 2016. TMLM achieved the
perplexity of 4.42, which outperformed the previous math language models, i.e.,
the N-gram and recurrent neural network-based language models. In addition, we
combine TMLM into a stochastic context-free grammar-based HME recognition
system using a weighting parameter to re-rank the top-10 best candidates. The
expression rates on the testing sets of CROHME 2016 and CROHME 2019 were
improved by 2.97 and 0.83 percentage points, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEMix Layers: Disentangling Domains for Modular Language Modeling. (arXiv:2108.05036v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1">Suchin Gururangan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Mike Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1">Ari Holtzman</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05036">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new domain expert mixture (DEMix) layer that enables
conditioning a language model (LM) on the domain of the input text. A DEMix
layer is a collection of expert feedforward networks, each specialized to a
domain, that makes the LM modular: experts can be mixed, added or removed after
initial training. Extensive experiments with autoregressive transformer LMs (up
to 1.3B parameters) show that DEMix layers reduce test-time perplexity,
increase training efficiency, and enable rapid adaptation with little overhead.
We show that mixing experts during inference, using a parameter-free weighted
ensemble, allows the model to better generalize to heterogeneous or unseen
domains. We also show that experts can be added to iteratively incorporate new
domains without forgetting older ones, and that experts can be removed to
restrict access to unwanted domains, without additional training. Overall,
these results demonstrate benefits of explicitly conditioning on textual
domains during language modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1">Andreas Madsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04840">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing (NLP) models have become increasingly more
complex and widespread. With recent developments in neural networks, a growing
concern is whether it is responsible to use these models. Concerns such as
safety and ethics can be partially addressed by providing explanations.
Furthermore, when models do fail, providing explanations is paramount for
accountability purposes. To this end, interpretability serves to provide these
explanations in terms that are understandable to humans. Central to what is
understandable is how explanations are communicated. Therefore, this survey
provides a categorization of how recent interpretability methods communicate
explanations and discusses the methods in depth. Furthermore, the survey
focuses on post-hoc methods, which provide explanations after a model is
learned and generally model-agnostic. A common concern for this class of
methods is whether they accurately reflect the model. Hence, how these post-hoc
methods are evaluated is discussed throughout the paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1">Alessandro Suglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qiaozi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Thattai_G/0/1/0/all/0/1">Govind Thattai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1">Gaurav Sukhatme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
                                    <div class="article-summary-box-inner">
                                        <span>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis. (arXiv:2108.04938v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Monajatipoor_M/0/1/0/all/0/1">Masoud Monajatipoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouhsedaghat_M/0/1/0/all/0/1">Mozhdeh Rouhsedaghat</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liunian Harold Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_A/0/1/0/all/0/1">Aichi Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Scalzo_F/0/1/0/all/0/1">Fabien Scalzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04938">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-and-language(V&amp;L) models take image and text as input and learn to
capture the associations between them. Prior studies show that pre-trained V&amp;L
models can significantly improve the model performance for downstream tasks
such as Visual Question Answering (VQA). However, V&amp;L models are less effective
when applied in the medical domain (e.g., on X-ray images and clinical notes)
due to the domain gap. In this paper, we investigate the challenges of applying
pre-trained V&amp;L models in medical applications. In particular, we identify that
the visual representation in general V&amp;L models is not suitable for processing
medical data. To overcome this limitation, we propose BERTHop, a
transformer-based model based on PixelHop++ and VisualBERT, for better
capturing the associations between the two modalities. Experiments on the OpenI
dataset, a commonly used thoracic disease diagnosis benchmark, show that
BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62%
higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining the Benefits of Two-stage and One-stage HOI Detection. (arXiv:2108.05077v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aixi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yue Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Miao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05077">
                                    <div class="article-summary-box-inner">
                                        <span>Two-stage methods have dominated Human-Object Interaction (HOI) detection for
several years. Recently, one-stage HOI detection methods have become popular.
In this paper, we aim to explore the essential pros and cons of two-stage and
one-stage methods. With this as the goal, we find that conventional two-stage
methods mainly suffer from positioning positive interactive human-object pairs,
while one-stage methods are challenging to make an appropriate trade-off on
multi-task learning, i.e., object detection, and interaction classification.
Therefore, a core problem is how to take the essence and discard the dregs from
the conventional two types of methods. To this end, we propose a novel
one-stage framework with disentangling human-object detection and interaction
classification in a cascade manner. In detail, we first design a human-object
pair generator based on a state-of-the-art one-stage HOI detector by removing
the interaction classification module or head and then design a relatively
isolated interaction classifier to classify each human-object pair. Two cascade
decoders in our proposed framework can focus on one specific task, detection or
interaction classification. In terms of the specific implementation, we adopt a
transformer-based HOI detector as our base model. The newly introduced
disentangling paradigm outperforms existing methods by a large margin, with a
significant relative mAP gain of 9.32% on HICO-Det.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation Learning for Remote Sensing: An Unsupervised Sensor Fusion Approach. (arXiv:2108.05094v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Swope_A/0/1/0/all/0/1">Aidan M. Swope</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudelis_X/0/1/0/all/0/1">Xander H. Rudelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Story_K/0/1/0/all/0/1">Kyle T. Story</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05094">
                                    <div class="article-summary-box-inner">
                                        <span>In the application of machine learning to remote sensing, labeled data is
often scarce or expensive, which impedes the training of powerful models like
deep convolutional neural networks. Although unlabeled data is abundant, recent
self-supervised learning approaches are ill-suited to the remote sensing
domain. In addition, most remote sensing applications currently use only a
small subset of the multi-sensor, multi-channel information available,
motivating the need for fused multi-sensor representations. We propose a new
self-supervised training objective, Contrastive Sensor Fusion, which exploits
coterminous data from multiple sources to learn useful representations of every
possible combination of those sources. This method uses information common
across multiple sensors and bands by training a single model to produce a
representation that remains similar when any subset of its input channels is
used. Using a dataset of 47 million unlabeled coterminous image triplets, we
train an encoder to produce semantically meaningful representations from any
possible combination of channels from the input sensors. These representations
outperform fully supervised ImageNet weights on a remote sensing classification
task and improve as more sensors are fused. Our code is available at
https://storage.cloud.google.com/public-published-datasets/csf_code.zip.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Video Object Segmentation by Motion Grouping. (arXiv:2104.07658v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Charig Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamdouar_H/0/1/0/all/0/1">Hala Lamdouar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_E/0/1/0/all/0/1">Erika Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weidi Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07658">
                                    <div class="article-summary-box-inner">
                                        <span>Animals have evolved highly functional visual systems to understand motion,
assisting perception even under complex environments. In this paper, we work
towards developing a computer vision system able to segment objects by
exploiting motion cues, i.e. motion segmentation. We make the following
contributions: First, we introduce a simple variant of the Transformer to
segment optical flow frames into primary objects and the background. Second, we
train the architecture in a self-supervised manner, i.e. without using any
manual annotations. Third, we analyze several critical components of our method
and conduct thorough ablation studies to validate their necessity. Fourth, we
evaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2,
and FBMS59). Despite using only optical flow as input, our approach achieves
superior or comparable results to previous state-of-the-art self-supervised
methods, while being an order of magnitude faster. We additionally evaluate on
a challenging camouflage dataset (MoCA), significantly outperforming the other
self-supervised approaches, and comparing favourably to the top supervised
approach, highlighting the importance of motion cues, and the potential bias
towards visual appearance in existing video segmentation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Classification of Lake Zooplankton. (arXiv:2108.05258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kyathanahally_S/0/1/0/all/0/1">S. P. Kyathanahally</a>, <a href="http://arxiv.org/find/cs/1/au:+Hardeman_T/0/1/0/all/0/1">T. Hardeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Merz_E/0/1/0/all/0/1">E. Merz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozakiewicz_T/0/1/0/all/0/1">T. Kozakiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Reyes_M/0/1/0/all/0/1">M. Reyes</a>, <a href="http://arxiv.org/find/cs/1/au:+Isles_P/0/1/0/all/0/1">P. Isles</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomati_F/0/1/0/all/0/1">F. Pomati</a>, <a href="http://arxiv.org/find/cs/1/au:+Baity_Jesi_M/0/1/0/all/0/1">M. Baity-Jesi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05258">
                                    <div class="article-summary-box-inner">
                                        <span>Plankton are effective indicators of environmental change and ecosystem
health in freshwater habitats, but collection of plankton data using manual
microscopic methods is extremely labor-intensive and expensive. Automated
plankton imaging offers a promising way forward to monitor plankton communities
with high frequency and accuracy in real-time. Yet, manual annotation of
millions of images proposes a serious challenge to taxonomists. Deep learning
classifiers have been successfully applied in various fields and provided
encouraging results when used to categorize marine plankton images. Here, we
present a set of deep learning models developed for the identification of lake
plankton, and study several strategies to obtain optimal performances,which
lead to operational prescriptions for users. To this aim, we annotated into 35
classes over 17900 images of zooplankton and large phytoplankton colonies,
detected in Lake Greifensee (Switzerland) with the Dual Scripps Plankton
Camera. Our best models were based on transfer learning and ensembling, which
classified plankton images with 98% accuracy and 93% F1 score. When tested on
freely available plankton datasets produced by other automated imaging tools
(ZooScan, FlowCytobot and ISIIS), our models performed better than previously
used models. Our annotated data, code and classification models are freely
available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D CNNs with Adaptive Temporal Feature Resolutions. (arXiv:2011.08652v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1">Mohsen Fayyaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahrami_E/0/1/0/all/0/1">Emad Bahrami</a>, <a href="http://arxiv.org/find/cs/1/au:+Diba_A/0/1/0/all/0/1">Ali Diba</a>, <a href="http://arxiv.org/find/cs/1/au:+Noroozi_M/0/1/0/all/0/1">Mehdi Noroozi</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08652">
                                    <div class="article-summary-box-inner">
                                        <span>While state-of-the-art 3D Convolutional Neural Networks (CNN) achieve very
good results on action recognition datasets, they are computationally very
expensive and require many GFLOPs. While the GFLOPs of a 3D CNN can be
decreased by reducing the temporal feature resolution within the network, there
is no setting that is optimal for all input clips. In this work, we therefore
introduce a differentiable Similarity Guided Sampling (SGS) module, which can
be plugged into any existing 3D CNN architecture. SGS empowers 3D CNNs by
learning the similarity of temporal features and grouping similar features
together. As a result, the temporal feature resolution is not anymore static
but it varies for each input video clip. By integrating SGS as an additional
layer within current 3D CNNs, we can convert them into much more efficient 3D
CNNs with adaptive temporal feature resolutions (ATFR). Our evaluations show
that the proposed module improves the state-of-the-art by reducing the
computational cost (GFLOPs) by half while preserving or even improving the
accuracy. We evaluate our module by adding it to multiple state-of-the-art 3D
CNNs on various datasets such as Kinetics-600, Kinetics-400, mini-Kinetics,
Something-Something V2, UCF101, and HMDB51.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AA3DNet: Attention Augmented Real Time 3D Object Detection. (arXiv:2107.12137v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12137">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
&gt; 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ask&amp;Confirm: Active Detail Enriching for Cross-Modal Retrieval with Partial Query. (arXiv:2103.01654v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_G/0/1/0/all/0/1">Guanyu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xinyang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yifei Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lianghua He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fufu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1">Pai Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaowei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xing Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01654">
                                    <div class="article-summary-box-inner">
                                        <span>Text-based image retrieval has seen considerable progress in recent years.
However, the performance of existing methods suffers in real life since the
user is likely to provide an incomplete description of an image, which often
leads to results filled with false positives that fit the incomplete
description. In this work, we introduce the partial-query problem and
extensively analyze its influence on text-based image retrieval. Previous
interactive methods tackle the problem by passively receiving users&#x27; feedback
to supplement the incomplete query iteratively, which is time-consuming and
requires heavy user effort. Instead, we propose a novel retrieval framework
that conducts the interactive process in an Ask-and-Confirm fashion, where AI
actively searches for discriminative details missing in the current query, and
users only need to confirm AI&#x27;s proposal. Specifically, we propose an
object-based interaction to make the interactive retrieval more user-friendly
and present a reinforcement-learning-based policy to search for discriminative
objects. Furthermore, since fully-supervised training is often infeasible due
to the difficulty of obtaining human-machine dialog data, we present a
weakly-supervised training strategy that needs no human-annotated dialogs other
than a text-image dataset. Experiments show that our framework significantly
improves the performance of text-based image retrieval. Code is avaiable at
https://github.com/CuthbertCai/Ask-Confirm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Distillation to Reduce Class Confusion in Continual Learning. (arXiv:2108.05187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1">Changhong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhiying Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruixuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wei-Shi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05187">
                                    <div class="article-summary-box-inner">
                                        <span>Successful continual learning of new knowledge would enable intelligent
systems to recognize more and more classes of objects. However, current
intelligent systems often fail to correctly recognize previously learned
classes of objects when updated to learn new classes. It is widely believed
that such downgraded performance is solely due to the catastrophic forgetting
of previously learned knowledge. In this study, we argue that the class
confusion phenomena may also play a role in downgrading the classification
performance during continual learning, i.e., the high similarity between new
classes and any previously learned classes would also cause the classifier to
make mistakes in recognizing these old classes, even if the knowledge of these
old classes is not forgotten. To alleviate the class confusion issue, we
propose a discriminative distillation strategy to help the classify well learn
the discriminative features between confusing classes during continual
learning. Experiments on multiple natural image classification tasks support
that the proposed distillation strategy, when combined with existing methods,
is effective in further improving continual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keep CALM and Improve Visual Feature Attribution. (arXiv:2106.07861v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jae Myung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1">Junsuk Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1">Zeynep Akata</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Seong Joon Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07861">
                                    <div class="article-summary-box-inner">
                                        <span>The class activation mapping, or CAM, has been the cornerstone of feature
attribution methods for multiple vision tasks. Its simplicity and effectiveness
have led to wide applications in the explanation of visual predictions and
weakly-supervised localization tasks. However, CAM has its own shortcomings.
The computation of attribution maps relies on ad-hoc calibration steps that are
not part of the training computational graph, making it difficult for us to
understand the real meaning of the attribution values. In this paper, we
improve CAM by explicitly incorporating a latent variable encoding the location
of the cue for recognition in the formulation, thereby subsuming the
attribution map into the training computational graph. The resulting model,
class activation latent mapping, or CALM, is trained with the
expectation-maximization algorithm. Our experiments show that CALM identifies
discriminative attributes for image classifiers more accurately than CAM and
other visual attribution baselines. CALM also shows performance improvements
over prior arts on the weakly-supervised object localization benchmarks. Our
code is available at
https://github.com/naver-ai/calm}{https://github.com/naver-ai/calm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions. (arXiv:2102.12122v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kaitao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12122">
                                    <div class="article-summary-box-inner">
                                        <span>Although using convolutional neural networks (CNNs) as backbones achieves
great successes in computer vision, this work investigates a simple backbone
network useful for many dense prediction tasks without convolutions. Unlike the
recently-proposed Transformer model (e.g., ViT) that is specially designed for
image classification, we propose Pyramid Vision Transformer~(PVT), which
overcomes the difficulties of porting Transformer to various dense prediction
tasks. PVT has several merits compared to prior arts. (1) Different from ViT
that typically has low-resolution outputs and high computational and memory
cost, PVT can be not only trained on dense partitions of the image to achieve
high output resolution, which is important for dense predictions but also using
a progressive shrinking pyramid to reduce computations of large feature maps.
(2) PVT inherits the advantages from both CNN and Transformer, making it a
unified backbone in various vision tasks without convolutions by simply
replacing CNN backbones. (3) We validate PVT by conducting extensive
experiments, showing that it boosts the performance of many downstream tasks,
e.g., object detection, semantic, and instance segmentation. For example, with
a comparable number of parameters, RetinaNet+PVT achieves 40.4 AP on the COCO
dataset, surpassing RetinNet+ResNet50 (36.3 AP) by 4.1 absolute AP. We hope PVT
could serve as an alternative and useful backbone for pixel-level predictions
and facilitate future researches. Code is available at
https://github.com/whai362/PVT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Amortized Training for Memory-efficient High Resolution 3D GAN. (arXiv:2008.01910v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_L/0/1/0/all/0/1">Li Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Junxiang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gong_M/0/1/0/all/0/1">Mingming Gong</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_K/0/1/0/all/0/1">Ke Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Batmanghelich_K/0/1/0/all/0/1">Kayhan Batmanghelich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01910">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GAN) have many potential medical imaging
applications, including data augmentation, domain adaptation, and model
explanation. Due to the limited memory of Graphical Processing Units (GPUs),
most current 3D GAN models are trained on low-resolution medical images, these
models either cannot scale to high-resolution or are prone to patchy artifacts.
In this work, we propose a novel end-to-end GAN architecture that can generate
high-resolution 3D images. We achieve this goal by separating training and
inference. During training, we adopt a hierarchical structure that
simultaneously generates a low-resolution version of the image and a randomly
selected sub-volume of the high-resolution image. The hierarchical design has
two advantages: First, the memory demand for training on high-resolution images
is amortized among subvolumes. Furthermore, anchoring the high-resolution
subvolumes to a single low-resolution image ensures anatomical consistency
between subvolumes. During inference, our model can directly generate full
high-resolution images. We also incorporate an encoder with a similar
hierarchical structure into the model to extract features from the images.
Experiments on 3D thorax CT and brain MRI demonstrate that our approach
outperforms state of the art in image generation. We also demonstrate clinical
applications of the proposed model in data augmentation, image super-resolution
and clinical-relevant feature extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset for Provident Vehicle Detection at Night. (arXiv:2105.13236v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saralajew_S/0/1/0/all/0/1">Sascha Saralajew</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohnemus_L/0/1/0/all/0/1">Lars Ohnemus</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewecker_L/0/1/0/all/0/1">Lukas Ewecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Asan_E/0/1/0/all/0/1">Ebubekir Asan</a>, <a href="http://arxiv.org/find/cs/1/au:+Isele_S/0/1/0/all/0/1">Simon Isele</a>, <a href="http://arxiv.org/find/cs/1/au:+Roos_S/0/1/0/all/0/1">Stefan Roos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13236">
                                    <div class="article-summary-box-inner">
                                        <span>In current object detection, algorithms require the object to be directly
visible in order to be detected. As humans, however, we intuitively use visual
cues caused by the respective object to already make assumptions about its
appearance. In the context of driving, such cues can be shadows during the day
and often light reflections at night. In this paper, we study the problem of
how to map this intuitive human behavior to computer vision algorithms to
detect oncoming vehicles at night just from the light reflections they cause by
their headlights. For that, we present an extensive open-source dataset
containing 59746 annotated grayscale images out of 346 different scenes in a
rural environment at night. In these images, all oncoming vehicles, their
corresponding light objects (e.g., headlamps), and their respective light
reflections (e.g., light reflections on guardrails) are labeled. In this
context, we discuss the characteristics of the dataset and the challenges in
objectively describing visual cues such as light reflections. We provide
different metrics for different ways to approach the task and report the
results we achieved using state-of-the-art and custom object detection models
as a first benchmark. With that, we want to bring attention to a new and so far
neglected field in computer vision research, encourage more researchers to
tackle the problem, and thereby further close the gap between human performance
and computer vision systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fighting deepfakes by detecting GAN DCT anomalies. (arXiv:2101.09781v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Giudice_O/0/1/0/all/0/1">Oliver Giudice</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Guarnera_L/0/1/0/all/0/1">Luca Guarnera</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Battiato_S/0/1/0/all/0/1">Sebastiano Battiato</a> (1 and 2) ((1) University of Catania, (2) iCTLab s.r.l. - Spin-off of University of Catania)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09781">
                                    <div class="article-summary-box-inner">
                                        <span>To properly contrast the Deepfake phenomenon the need to design new Deepfake
detection algorithms arises; the misuse of this formidable A.I. technology
brings serious consequences in the private life of every involved person.
State-of-the-art proliferates with solutions using deep neural networks to
detect a fake multimedia content but unfortunately these algorithms appear to
be neither generalizable nor explainable. However, traces left by Generative
Adversarial Network (GAN) engines during the creation of the Deepfakes can be
detected by analyzing ad-hoc frequencies. For this reason, in this paper we
propose a new pipeline able to detect the so-called GAN Specific Frequencies
(GSF) representing a unique fingerprint of the different generative
architectures. By employing Discrete Cosine Transform (DCT), anomalous
frequencies were detected. The \BETA statistics inferred by the AC coefficients
distribution have been the key to recognize GAN-engine generated data.
Robustness tests were also carried out in order to demonstrate the
effectiveness of the technique using different attacks on images such as JPEG
Compression, mirroring, rotation, scaling, addition of random sized rectangles.
Experiments demonstrated that the method is innovative, exceeds the state of
the art and also give many insights in terms of explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Person Re-identification via Attention Pyramid. (arXiv:2108.05340v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_T/0/1/0/all/0/1">Tianpei Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jin-An Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05340">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an attention pyramid method for person
re-identification. Unlike conventional attention-based methods which only learn
a global attention map, our attention pyramid exploits the attention regions in
a multi-scale manner because human attention varies with different scales. Our
attention pyramid imitates the process of human visual perception which tends
to notice the foreground person over the cluttered background, and further
focus on the specific color of the shirt with close observation. Specifically,
we describe our attention pyramid by a &quot;split-attend-merge-stack&quot; principle. We
first split the features into multiple local parts and learn the corresponding
attentions. Then, we merge local attentions and stack these merged attentions
with the residual connection as an attention pyramid. The proposed attention
pyramid is a lightweight plug-and-play module that can be applied to
off-the-shelf models. We implement our attention pyramid method in two
different attention mechanisms including channel-wise attention and spatial
attention. We evaluate our method on four largescale person re-identification
benchmarks including Market-1501, DukeMTMC, CUHK03, and MSMT17. Experimental
results demonstrate the superiority of our method, which outperforms the
state-of-the-art methods by a large margin with limited computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Where2Act: From Pixels to Actions for Articulated 3D Objects. (arXiv:2101.02692v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_K/0/1/0/all/0/1">Kaichun Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukadam_M/0/1/0/all/0/1">Mustafa Mukadam</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhinav Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulsiani_S/0/1/0/all/0/1">Shubham Tulsiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02692">
                                    <div class="article-summary-box-inner">
                                        <span>One of the fundamental goals of visual perception is to allow agents to
meaningfully interact with their environment. In this paper, we take a step
towards that long-term goal -- we extract highly localized actionable
information related to elementary actions such as pushing or pulling for
articulated objects with movable parts. For example, given a drawer, our
network predicts that applying a pulling force on the handle opens the drawer.
We propose, discuss, and evaluate novel network architectures that given image
and depth data, predict the set of actions possible at each pixel, and the
regions over articulated parts that are likely to move under the force. We
propose a learning-from-interaction framework with an online data sampling
strategy that allows us to train the network in simulation (SAPIEN) and
generalizes across categories. Check the website for code and data release:
https://cs.stanford.edu/~kaichun/where2act/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Interpretable Deep Networks for Monocular Depth Estimation. (arXiv:2108.05312v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1">Zunzhi You</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yi-Hsuan Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1">Wei-Chen Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05312">
                                    <div class="article-summary-box-inner">
                                        <span>Deep networks for Monocular Depth Estimation (MDE) have achieved promising
performance recently and it is of great importance to further understand the
interpretability of these networks. Existing methods attempt to provide posthoc
explanations by investigating visual cues, which may not explore the internal
representations learned by deep networks. In this paper, we find that some
hidden units of the network are selective to certain ranges of depth, and thus
such behavior can be served as a way to interpret the internal representations.
Based on our observations, we quantify the interpretability of a deep MDE
network by the depth selectivity of its hidden units. Moreover, we then propose
a method to train interpretable MDE deep networks without changing their
original architectures, by assigning a depth range for each unit to select.
Experimental results demonstrate that our method is able to enhance the
interpretability of deep MDE networks by largely improving the depth
selectivity of their units, while not harming or even improving the depth
estimation accuracy. We further provide a comprehensive analysis to show the
reliability of selective units, the applicability of our method on different
layers, models, and datasets, and a demonstration on analysis of model error.
Source code and models are available at
https://github.com/youzunzhi/InterpretableMDE .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two is a crowd: tracking relations in videos. (arXiv:2108.05331v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moskalev_A/0/1/0/all/0/1">Artem Moskalev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1">Ivan Sosnovik</a>, <a href="http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1">Arnold Smeulders</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05331">
                                    <div class="article-summary-box-inner">
                                        <span>Tracking multiple objects individually differs from tracking groups of
related objects. When an object is a part of the group, its trajectory depends
on the trajectories of the other group members. Most of the current
state-of-the-art trackers follow the approach of tracking each object
independently, with the mechanism to handle the overlapping trajectories where
necessary. Such an approach does not take inter-object relations into account,
which may cause unreliable tracking for the members of the groups, especially
in crowded scenarios, where individual cues become unreliable due to
occlusions. To overcome these limitations and to extend such trackers to
crowded scenes, we propose a plug-in Relation Encoding Module (REM). REM
encodes relations between tracked objects by running a message passing over a
corresponding spatio-temporal graph, computing relation embeddings for the
tracked objects. Our experiments on MOT17 and MOT20 demonstrate that the
baseline tracker improves its results after a simple extension with REM. The
proposed module allows for tracking severely or even fully occluded objects by
utilizing relational cues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Abstract Reasoning via Logic-guided Generation. (arXiv:2107.10493v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sihyun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1">Sangwoo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungsoo Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10493">
                                    <div class="article-summary-box-inner">
                                        <span>Abstract reasoning, i.e., inferring complicated patterns from given
observations, is a central building block of artificial general intelligence.
While humans find the answer by either eliminating wrong candidates or first
constructing the answer, prior deep neural network (DNN)-based methods focus on
the former discriminative approach. This paper aims to design a framework for
the latter approach and bridge the gap between artificial and human
intelligence. To this end, we propose logic-guided generation (LoGe), a novel
generative DNN framework that reduces abstract reasoning as an optimization
problem in propositional logic. LoGe is composed of three steps: extract
propositional variables from images, reason the answer variables with a logic
layer, and reconstruct the answer image from the variables. We demonstrate that
LoGe outperforms the black box DNN frameworks for generative abstract reasoning
under the RAVEN benchmark, i.e., reconstructing answers based on capturing
correct rules of various attributes from observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Level Fusion from Facial Attributes for Face Recognition. (arXiv:1909.13126v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1">Mohammad Rasool Izadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.13126">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a deep convolutional neural networks (CNN) architecture to
classify facial attributes and recognize face images simultaneously via a
shared learning paradigm to improve the accuracy for facial attribute
prediction and face recognition performance. In this method, we use facial
attributes as an auxiliary source of information to assist CNN features
extracted from the face images to improve the face recognition performance.
Specifically, we use a shared CNN architecture that jointly predicts facial
attributes and recognize face images simultaneously via a shared learning
parameters, and then we use facial attribute features an an auxiliary source of
information concatenated by face features to increase the discrimination of the
CNN for face recognition. This process assists the CNN classifier to better
recognize face images. The experimental results show that our model increases
both the face recognition and facial attribute prediction performance,
especially for the identity attributes such as gender and race. We evaluated
our method on several standard datasets labeled by identities and face
attributes and the results show that the proposed method outperforms
state-of-the-art face recognition models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Copy and Paste method based on Pose for Re-identification. (arXiv:2107.10479v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10479">
                                    <div class="article-summary-box-inner">
                                        <span>The aim of re-identification is to match objects in surveillance cameras with
different viewpoints. Although ReID is developing at a considerably rapid pace,
there is currently no processing method for the ReID task in multiple
scenarios. However, such processing method is required in real life scenarios,
such as those involving security. In the present study, a new ReID scenario was
explored, which differs in terms of perspective, background, and pose(walking
or cycling). Obviously, ordinary ReID processing methods cannot effectively
handle such a scenario, with the introduction of image datasets being the
optimal solution, in addition to being considerably expensive.

To solve the aforementioned problem, a simple and effective method to
generate images in several new scenarios was proposed, which is names the Copy
and Paste method based on Pose(CPP). The CPP method is based on key point
detection, using copy as paste, to composite a new semantic image dataset in
two different semantic image datasets. As an example, pedestrains and bicycles
can be used to generate several images that show the same person riding on
different bicycles. The CPP method is suitable for ReID tasks in new scenarios
and outperforms the traditional methods when applied to the original datasets
in original ReID tasks. To be specific, the CPP method can also perform better
in terms of generalization for third-party public dataset. The Code and
datasets composited by the CPP method will be available in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Transformer for Deepfake Detection with Incremental Learning. (arXiv:2108.05307v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Sohail A. Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hang Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05307">
                                    <div class="article-summary-box-inner">
                                        <span>Face forgery by deepfake is widely spread over the internet and this raises
severe societal concerns. In this paper, we propose a novel video transformer
with incremental learning for detecting deepfake videos. To better align the
input face images, we use a 3D face reconstruction method to generate UV
texture from a single input face image. The aligned face image can also provide
pose, eyes blink and mouth movement information that cannot be perceived in the
UV texture image, so we use both face images and their UV texture maps to
extract the image features. We present an incremental learning strategy to
fine-tune the proposed model on a smaller amount of data and achieve better
deepfake detection performance. The comprehensive experiments on various public
deepfake datasets demonstrate that the proposed video transformer model with
incremental learning achieves state-of-the-art performance in the deepfake
video detection task with enhanced feature learning from the sequenced data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08382">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism of late has been quite popular in the computer vision
community. A lot of work has been done to improve the performance of the
network, although almost always it results in increased computational
complexity. In this paper, we propose a new attention module that not only
achieves the best performance but also has lesser parameters compared to most
existing models. Our attention module can easily be integrated with other
convolutional neural networks because of its lightweight nature. The proposed
network named Dual Multi Scale Attention Network (DMSANet) is comprised of two
parts: the first part is used to extract features at various scales and
aggregate them, the second part uses spatial and channel attention modules in
parallel to adaptively integrate local features with their global dependencies.
We benchmark our network performance for Image Classification on ImageNet
dataset, Object Detection and Instance Segmentation both on MS COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Heuristic Sampling Necessary in Training Deep Object Detectors?. (arXiv:1909.04868v8 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Joya Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shiwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yifei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.04868">
                                    <div class="article-summary-box-inner">
                                        <span>To train accurate deep object detectors under the extreme
foreground-background imbalance, heuristic sampling methods are always
necessary, which either re-sample a subset of all training samples (hard
sampling methods, \eg biased sampling, OHEM), or use all training samples but
re-weight them discriminatively (soft sampling methods, \eg Focal Loss, GHM).
In this paper, we challenge the necessity of such hard/soft sampling methods
for training accurate deep object detectors. While previous studies have shown
that training detectors without heuristic sampling methods would significantly
degrade accuracy, we reveal that this degradation comes from an unreasonable
classification gradient magnitude caused by the imbalance, rather than a lack
of re-sampling/re-weighting. Motivated by our discovery, we propose a simple
yet effective \emph{Sampling-Free} mechanism to achieve a reasonable
classification gradient magnitude by initialization and loss scaling. Unlike
heuristic sampling methods with multiple hyperparameters, our Sampling-Free
mechanism is fully data diagnostic, without laborious hyperparameters
searching. We verify the effectiveness of our method in training anchor-based
and anchor-free object detectors, where our method always achieves higher
detection accuracy than heuristic sampling methods on COCO and PASCAL VOC
datasets. Our Sampling-Free mechanism provides a new perspective to address the
foreground-background imbalance. Our code is released at
\url{https://github.com/ChenJoya/sampling-free}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Pigs Fly: Contextual Reasoning in Synthetic and Natural Scenes. (arXiv:2104.02215v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bomatter_P/0/1/0/all/0/1">Philipp Bomatter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengmi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karev_D/0/1/0/all/0/1">Dimitar Karev</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_C/0/1/0/all/0/1">Claire Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreiman_G/0/1/0/all/0/1">Gabriel Kreiman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02215">
                                    <div class="article-summary-box-inner">
                                        <span>Context is of fundamental importance to both human and machine vision; e.g.,
an object in the air is more likely to be an airplane than a pig. The rich
notion of context incorporates several aspects including physics rules,
statistical co-occurrences, and relative object sizes, among others. While
previous work has focused on crowd-sourced out-of-context photographs from the
web to study scene context, controlling the nature and extent of contextual
violations has been a daunting task. Here we introduce a diverse, synthetic
Out-of-Context Dataset (OCD) with fine-grained control over scene context. By
leveraging a 3D simulation engine, we systematically control the gravity,
object co-occurrences and relative sizes across 36 object categories in a
virtual household environment. We conducted a series of experiments to gain
insights into the impact of contextual cues on both human and machine vision
using OCD. We conducted psychophysics experiments to establish a human
benchmark for out-of-context recognition, and then compared it with
state-of-the-art computer vision models to quantify the gap between the two. We
propose a context-aware recognition transformer model, fusing object and
contextual information via multi-head attention. Our model captures useful
information for contextual reasoning, enabling human-level performance and
better robustness in out-of-context conditions compared to baseline models
across OCD and other out-of-context datasets. All source code and data are
publicly available at https://github.com/kreimanlab/WhenPigsFlyContext</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GRF: Learning a General Radiance Field for 3D Representation and Rendering. (arXiv:2010.04595v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trevithick_A/0/1/0/all/0/1">Alex Trevithick</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04595">
                                    <div class="article-summary-box-inner">
                                        <span>We present a simple yet powerful neural network that implicitly represents
and renders 3D objects and scenes only from 2D observations. The network models
3D geometries as a general radiance field, which takes a set of 2D images with
camera poses and intrinsics as input, constructs an internal representation for
each point of the 3D space, and then renders the corresponding appearance and
geometry of that point viewed from an arbitrary position. The key to our
approach is to learn local features for each pixel in 2D images and to then
project these features to 3D points, thus yielding general and rich point
representations. We additionally integrate an attention mechanism to aggregate
pixel features from multiple 2D views, such that visual occlusions are
implicitly taken into account. Extensive experiments demonstrate that our
method can generate high-quality and realistic novel views for novel objects,
unseen categories and challenging real-world scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provident Vehicle Detection at Night for Advanced Driver Assistance Systems. (arXiv:2107.11302v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ewecker_L/0/1/0/all/0/1">Lukas Ewecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Asan_E/0/1/0/all/0/1">Ebubekir Asan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohnemus_L/0/1/0/all/0/1">Lars Ohnemus</a>, <a href="http://arxiv.org/find/cs/1/au:+Saralajew_S/0/1/0/all/0/1">Sascha Saralajew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11302">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, computer vision algorithms have become more and more
powerful, which enabled technologies such as autonomous driving to evolve with
rapid pace. However, current algorithms mainly share one limitation: They rely
on directly visible objects. This is a major drawback compared to human
behavior, where indirect visual cues caused by the actual object (e.g.,
shadows) are already used intuitively to retrieve information or anticipate
occurring objects. While driving at night, this performance deficit becomes
even more obvious: Humans already process the light artifacts caused by
oncoming vehicles to assume their future appearance, whereas current object
detection systems rely on the oncoming vehicle&#x27;s direct visibility. Based on
previous work in this subject, we present with this paper a complete system
capable of solving the task to providently detect oncoming vehicles at
nighttime based on their caused light artifacts. For that, we outline the full
algorithm architecture ranging from the detection of light artifacts in the
image space, localizing the objects in the three-dimensional space, and
verifying the objects over time. To demonstrate the applicability, we deploy
the system in a test vehicle and use the information of providently detected
vehicles to control the glare-free high beam system proactively. Using this
experimental setting, we quantify the time benefit that the provident vehicle
detection system provides compared to an in-production computer vision system.
Additionally, the glare-free high beam use case provides a real-time and
real-world visualization interface of the detection results. With this
contribution, we want to put awareness on the unconventional sensing task of
provident object detection and further close the performance gap between human
behavior and computer vision algorithms in order to bring autonomous and
automated driving a step forward.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Frequency Domain Constraint for Synthetic and Real X-ray Image Super Resolution. (arXiv:2105.06887v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_Q/0/1/0/all/0/1">Qing Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Koh_J/0/1/0/all/0/1">Jae Chul Koh</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_W/0/1/0/all/0/1">WonSook Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06887">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic X-ray images are simulated X-ray images projected from CT data.
High-quality synthetic X-ray images can facilitate various applications such as
surgical image guidance systems and VR training simulations. However, it is
difficult to produce high-quality arbitrary view synthetic X-ray images in
real-time due to different CT slice thickness, high computational cost, and the
complexity of algorithms. Our goal is to generate high-resolution synthetic
X-ray images in real-time by upsampling low-resolution images with deep
learning-based super-resolution methods. Reference-based Super Resolution
(RefSR) has been well studied in recent years and has shown higher performance
than traditional Single Image Super-Resolution (SISR). It can produce fine
details by utilizing the reference image but still inevitably generates some
artifacts and noise. In this paper, we introduce frequency domain loss as a
constraint to further improve the quality of the RefSR results with fine
details and without obvious artifacts. To the best of our knowledge, this is
the first paper utilizing the frequency domain for the loss functions in the
field of super-resolution. We achieved good results in evaluating our method on
both synthetic and real X-ray image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution. (arXiv:2108.05302v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jingyun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Guolei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05302">
                                    <div class="article-summary-box-inner">
                                        <span>Existing blind image super-resolution (SR) methods mostly assume blur kernels
are spatially invariant across the whole image. However, such an assumption is
rarely applicable for real images whose blur kernels are usually spatially
variant due to factors such as object motion and out-of-focus. Hence, existing
blind SR methods would inevitably give rise to poor performance in real
applications. To address this issue, this paper proposes a mutual affine
network (MANet) for spatially variant kernel estimation. Specifically, MANet
has two distinctive features. First, it has a moderate receptive field so as to
keep the locality of degradation. Second, it involves a new mutual affine
convolution (MAConv) layer that enhances feature expressiveness without
increasing receptive field, model size and computation burden. This is made
possible through exploiting channel interdependence, which applies each channel
split with an affine transformation module whose input are the rest channel
splits. Extensive experiments on synthetic and real images show that the
proposed MANet not only performs favorably for both spatially variant and
invariant kernel estimation, but also leads to state-of-the-art blind SR
performance when combined with non-blind SR methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConvNets vs. Transformers: Whose Visual Representations are More Transferable?. (arXiv:2108.05305v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong-Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chixiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sibei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yizhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05305">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers have attracted much attention from computer vision
researchers as they are not restricted to the spatial inductive bias of
ConvNets. However, although Transformer-based backbones have achieved much
progress on ImageNet classification, it is still unclear whether the learned
representations are as transferable as or even more transferable than ConvNets&#x27;
features. To address this point, we systematically investigate the transfer
learning ability of ConvNets and vision transformers in 15 single-task and
multi-task performance evaluations. Given the strong correlation between the
performance of pre-trained models and transfer learning, we include 2 residual
ConvNets (i.e., R-101x3 and R-152x4) and 3 Transformer-based visual backbones
(i.e., ViT-B, ViT-L and Swin-B), which have close error rates on ImageNet, that
indicate similar transfer learning performance on downstream datasets.

We observe consistent advantages of Transformer-based backbones on 13
downstream tasks (out of 15), including but not limited to fine-grained
classification, scene recognition (classification, segmentation and depth
estimation), open-domain classification, face recognition, etc. More
specifically, we find that two ViT models heavily rely on whole network
fine-tuning to achieve performance gains while Swin Transformer does not have
such a requirement. Moreover, vision transformers behave more robustly in
multi-task learning, i.e., bringing more improvements when managing mutually
beneficial tasks and reducing performance losses when tackling irrelevant
tasks. We hope our discoveries can facilitate the exploration and exploitation
of vision transformers in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Better Loss for Visual-Textual Grounding. (arXiv:2108.05308v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rigoni_D/0/1/0/all/0/1">Davide Rigoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Serafini_L/0/1/0/all/0/1">Luciano Serafini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1">Alessandro Sperduti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05308">
                                    <div class="article-summary-box-inner">
                                        <span>Given a textual phrase and an image, the visual grounding problem is defined
as the task of locating the content of the image referenced by the sentence. It
is a challenging task that has several real-world applications in
human-computer interaction, image-text reference resolution, and video-text
reference resolution. In the last years, several works have addressed this
problem with heavy and complex models that try to capture visual-textual
dependencies better than before. These models are typically constituted by two
main components that focus on how to learn useful multi-modal features for
grounding and how to improve the predicted bounding box of the visual mention,
respectively. Finding the right learning balance between these two sub-tasks is
not easy, and the current models are not necessarily optimal with respect to
this issue. In this work, we propose a model that, although using a simple
multi-modal feature fusion component, is able to achieve a higher accuracy than
state-of-the-art models thanks to the adoption of a more effective loss
function, based on the classes probabilities, that reach, in the considered
datasets, a better learning balance between the two sub-tasks mentioned above.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling. (arXiv:2108.05301v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jingyun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lugmayr_A/0/1/0/all/0/1">Andreas Lugmayr</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Danelljan_M/0/1/0/all/0/1">Martin Danelljan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05301">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows have recently demonstrated promising results for low-level
vision tasks. For image super-resolution (SR), it learns to predict diverse
photo-realistic high-resolution (HR) images from the low-resolution (LR) image
rather than learning a deterministic mapping. For image rescaling, it achieves
high accuracy by jointly modelling the downscaling and upscaling processes.
While existing approaches employ specialized techniques for these two tasks, we
set out to unify them in a single formulation. In this paper, we propose the
hierarchical conditional flow (HCFlow) as a unified framework for image SR and
image rescaling. More specifically, HCFlow learns a bijective mapping between
HR and LR image pairs by modelling the distribution of the LR image and the
rest high-frequency component simultaneously. In particular, the high-frequency
component is conditional on the LR image in a hierarchical manner. To further
enhance the performance, other losses such as perceptual loss and GAN loss are
combined with the commonly used negative log-likelihood loss in training.
Extensive experiments on general image SR, face image SR and image rescaling
have demonstrated that the proposed HCFlow achieves state-of-the-art
performance in terms of both quantitative metrics and visual quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Rearrange Voxels in Binary Segmentation Masks for Smooth Manifold Triangulation. (arXiv:2108.05269v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianning Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pepe_A/0/1/0/all/0/1">Antonio Pepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1">Christina Gsaxner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05269">
                                    <div class="article-summary-box-inner">
                                        <span>Medical images, especially volumetric images, are of high resolution and
often exceed the capacity of standard desktop GPUs. As a result, most deep
learning-based medical image analysis tasks require the input images to be
downsampled, often substantially, before these can be fed to a neural network.
However, downsampling can lead to a loss of image quality, which is undesirable
especially in reconstruction tasks, where the fine geometric details need to be
preserved. In this paper, we propose that high-resolution images can be
reconstructed in a coarse-to-fine fashion, where a deep learning algorithm is
only responsible for generating a coarse representation of the image, which
consumes moderate GPU memory. For producing the high-resolution outcome, we
propose two novel methods: learned voxel rearrangement of the coarse output and
hierarchical image synthesis. Compared to the coarse output, the
high-resolution counterpart allows for smooth surface triangulation, which can
be 3D-printed in the highest possible quality. Experiments of this paper are
carried out on the dataset of AutoImplant 2021
(https://autoimplant2021.grand-challenge.org/), a MICCAI challenge on cranial
implant design. The dataset contains high-resolution skulls that can be viewed
as 2D manifolds embedded in a 3D space. Codes associated with this study can be
accessed at https://github.com/Jianningli/voxel_rearrangement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in Adverse Weather. (arXiv:2108.05249v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hahner_M/0/1/0/all/0/1">Martin Hahner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakaridis_C/0/1/0/all/0/1">Christos Sakaridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Dengxin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05249">
                                    <div class="article-summary-box-inner">
                                        <span>This work addresses the challenging task of LiDAR-based 3D object detection
in foggy weather. Collecting and annotating data in such a scenario is very
time, labor and cost intensive. In this paper, we tackle this problem by
simulating physically accurate fog into clear-weather scenes, so that the
abundant existing real datasets captured in clear weather can be repurposed for
our task. Our contributions are twofold: 1) We develop a physically valid fog
simulation method that is applicable to any LiDAR dataset. This unleashes the
acquisition of large-scale foggy training data at no extra cost. These
partially synthetic data can be used to improve the robustness of several
perception methods, such as 3D object detection and tracking or simultaneous
localization and mapping, on real foggy data. 2) Through extensive experiments
with several state-of-the-art detection approaches, we show that our fog
simulation can be leveraged to significantly improve the performance for 3D
object detection in the presence of fog. Thus, we are the first to provide
strong 3D object detection baselines on the Seeing Through Fog dataset. Our
code is available at www.trace.ethz.ch/lidar_fog_simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Segmentation with Global and Local Contrastive Learning. (arXiv:2108.05293v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weide Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Henghui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fayao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jie Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05293">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the challenging task of few-shot segmentation.
Previous few-shot segmentation methods mainly employ the information of support
images as guidance for query image segmentation. Although some works propose to
build cross-reference between support and query images, their extraction of
query information still depends on the support images. We here propose to
extract the information from the query itself independently to benefit the
few-shot segmentation task. To this end, we first propose a prior extractor to
learn the query information from the unlabeled images with our proposed
global-local contrastive learning. Then, we extract a set of predetermined
priors via this prior extractor. With the obtained priors, we generate the
prior region maps for query images, which locate the objects, as guidance to
perform cross interaction with support features. In such a way, the extraction
of query information is detached from the support branch, overcoming the
limitation by support, and could obtain more informative query clues to achieve
better interaction. Without bells and whistles, the proposed approach achieves
new state-of-the-art performance for the few-shot segmentation task on
PASCAL-5$^{i}$ and COCO datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Real-Time Online Learning Framework for Joint 3D Reconstruction and Semantic Segmentation of Indoor Scenes. (arXiv:2108.05246v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Menini_D/0/1/0/all/0/1">Davide Menini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Suryansh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1">Martin R. Oswald</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandstrom_E/0/1/0/all/0/1">Erik Sandstrom</a>, <a href="http://arxiv.org/find/cs/1/au:+Sminchisescu_C/0/1/0/all/0/1">Cristian Sminchisescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05246">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a real-time online vision framework to jointly recover an
indoor scene&#x27;s 3D structure and semantic label. Given noisy depth maps, a
camera trajectory, and 2D semantic labels at train time, the proposed neural
network learns to fuse the depth over frames with suitable semantic labels in
the scene space. Our approach exploits the joint volumetric representation of
the depth and semantics in the scene feature space to solve this task. For a
compelling online fusion of the semantic labels and geometry in real-time, we
introduce an efficient vortex pooling block while dropping the routing network
in online depth fusion to preserve high-frequency surface details. We show that
the context information provided by the semantics of the scene helps the depth
fusion network learn noise-resistant features. Not only that, it helps overcome
the shortcomings of the current online depth fusion method in dealing with thin
object structures, thickening artifacts, and false surfaces. Experimental
evaluation on the Replica dataset shows that our approach can perform depth
fusion at 37, 10 frames per second with an average reconstruction F-score of
88%, and 91%, respectively, depending on the depth map resolution. Moreover,
our model shows an average IoU score of 0.515 on the ScanNet 3D semantic
benchmark leaderboard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProAI: An Efficient Embedded AI Hardware for Automotive Applications - a Benchmark Study. (arXiv:2108.05170v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mantowsky_S/0/1/0/all/0/1">Sven Mantowsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Heuer_F/0/1/0/all/0/1">Falk Heuer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukhari_S/0/1/0/all/0/1">Syed Saqib Bukhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Keckeisen_M/0/1/0/all/0/1">Michael Keckeisen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1">Georg Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05170">
                                    <div class="article-summary-box-inner">
                                        <span>Development in the field of Single Board Computers (SBC) have been increasing
for several years. They provide a good balance between computing performance
and power consumption which is usually required for mobile platforms, like
application in vehicles for Advanced Driver Assistance Systems (ADAS) and
Autonomous Driving (AD). However, there is an ever-increasing need of more
powerful and efficient SBCs which can run power intensive Deep Neural Networks
(DNNs) in real-time and can also satisfy necessary functional safety
requirements such as Automotive Safety Integrity Level (ASIL). ProAI is being
developed by ZF mainly to run powerful and efficient applications such as
multitask DNNs and on top of that it also has the required safety certification
for AD. In this work, we compare and discuss state of the art SBC on the basis
of power intensive multitask DNN architecture called Multitask-CenterNet with
respect to performance measures such as, FPS and power efficiency. As an
automotive supercomputer, ProAI delivers an excellent combination of
performance and efficiency, managing nearly twice the number of FPS per watt
than a modern workstation laptop and almost four times compared to the Jetson
Nano. Furthermore, it was also shown that there is still power in reserve for
further and more complex tasks on the ProAI, based on the CPU and GPU
utilization during the benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Surfel Fusion Using Normalised Information Distance. (arXiv:2108.05163v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gallagher_L/0/1/0/all/0/1">Louis Gallagher</a>, <a href="http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1">John B. McDonald</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05163">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new technique that achieves a significant reduction in the
quantity of measurements required for a fusion based dense 3D mapping system to
converge to an accurate, de-noised surface reconstruction. This is achieved
through the use of a Normalised Information Distance metric, that computes the
novelty of the information contained in each incoming frame with respect to the
reconstruction, and avoids fusing those frames that exceed a redundancy
threshold. This provides a principled approach for opitmising the trade-off
between surface reconstruction accuracy and the computational cost of
processing frames. The technique builds upon the ElasticFusion (EF) algorithm
where we report results of the technique&#x27;s scalability and the accuracy of the
resultant maps by applying it to both the ICL-NUIM and TUM RGB-D datasets.
These results demonstrate the capabilities of the approach in performing
accurate surface reconstructions whilst utilising a fraction of the frames when
compared to the original EF algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M3D-VTON: A Monocular-to-3D Virtual Try-On Network. (arXiv:2108.05126v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fuwei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhenyu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1">Michael Kampffmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Haoye Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Songfang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tianxiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05126">
                                    <div class="article-summary-box-inner">
                                        <span>Virtual 3D try-on can provide an intuitive and realistic view for online
shopping and has a huge potential commercial value. However, existing 3D
virtual try-on methods mainly rely on annotated 3D human shapes and garment
templates, which hinders their applications in practical scenarios. 2D virtual
try-on approaches provide a faster alternative to manipulate clothed humans,
but lack the rich and realistic 3D representation. In this paper, we propose a
novel Monocular-to-3D Virtual Try-On Network (M3D-VTON) that builds on the
merits of both 2D and 3D approaches. By integrating 2D information efficiently
and learning a mapping that lifts the 2D representation to 3D, we make the
first attempt to reconstruct a 3D try-on mesh only taking the target clothing
and a person image as inputs. The proposed M3D-VTON includes three modules: 1)
The Monocular Prediction Module (MPM) that estimates an initial full-body depth
map and accomplishes 2D clothes-person alignment through a novel two-stage
warping procedure; 2) The Depth Refinement Module (DRM) that refines the
initial body depth to produce more detailed pleat and face characteristics; 3)
The Texture Fusion Module (TFM) that fuses the warped clothing with the
non-target body part to refine the results. We also construct a high-quality
synthesized Monocular-to-3D virtual try-on dataset, in which each person image
is associated with a front and a back depth map. Extensive experiments
demonstrate that the proposed M3D-VTON can manipulate and reconstruct the 3D
human body wearing the given clothing with compelling details and is more
efficient than other 3D approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report Generation With Alternate Learning. (arXiv:2108.05067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yinghong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fuyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaolin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuixing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05067">
                                    <div class="article-summary-box-inner">
                                        <span>Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cervical Optical Coherence Tomography Image Classification Based on Contrastive Self-Supervised Texture Learning. (arXiv:2108.05081v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kaiyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingbin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yutao Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05081">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Cervical cancer seriously affects the health of the female
reproductive system. Optical coherence tomography (OCT) emerges as a
non-invasive, high-resolution imaging technology for cervical disease
detection. However, OCT image annotation is knowledge-intensive and
time-consuming, which impedes the training process of deep-learning-based
classification models. Objective: This study aims to develop a computer-aided
diagnosis (CADx) approach to classifying in-vivo cervical OCT images based on
self-supervised learning. Methods: Besides high-level semantic features
extracted by a convolutional neural network (CNN), the proposed CADx approach
leverages unlabeled cervical OCT images&#x27; texture features learned by
contrastive texture learning. We conducted ten-fold cross-validation on the OCT
image dataset from a multi-center clinical study on 733 patients from China.
Results: In a binary classification task for detecting high-risk diseases,
including high-grade squamous intraepithelial lesion (HSIL) and cervical
cancer, our method achieved an area-under-the-curve (AUC) value of 0.9798 Plus
or Minus 0.0157 with a sensitivity of 91.17 Plus or Minus 4.99% and a
specificity of 93.96 Plus or Minus 4.72% for OCT image patches; also, it
outperformed two out of four medical experts on the test set. Furthermore, our
method achieved a 91.53% sensitivity and 97.37% specificity on an external
validation dataset containing 287 3D OCT volumes from 118 Chinese patients in a
new hospital using a cross-shaped threshold voting strategy. Conclusion: The
proposed contrastive-learning-based CADx method outperformed the end-to-end CNN
models and provided better interpretability based on texture features, which
holds great potential to be used in the clinical protocol of &quot;see-and-treat.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Single-Image Defocus Deblurring: How Dual-Pixel Images Help Through Multi-Task Learning. (arXiv:2108.05251v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abuolaim_A/0/1/0/all/0/1">Abdullah Abuolaim</a>, <a href="http://arxiv.org/find/cs/1/au:+Afifi_M/0/1/0/all/0/1">Mahmoud Afifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_M/0/1/0/all/0/1">Michael S. Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05251">
                                    <div class="article-summary-box-inner">
                                        <span>Many camera sensors use a dual-pixel (DP) design that operates as a
rudimentary light field providing two sub-aperture views of a scene in a single
capture. The DP sensor was developed to improve how cameras perform autofocus.
Since the DP sensor&#x27;s introduction, researchers have found additional uses for
the DP data, such as depth estimation, reflection removal, and defocus
deblurring. We are interested in the latter task of defocus deblurring. In
particular, we propose a single-image deblurring network that incorporates the
two sub-aperture views into a multi-task framework. Specifically, we show that
jointly learning to predict the two DP views from a single blurry input image
improves the network&#x27;s ability to learn to deblur the image. Our experiments
show this multi-task strategy achieves +1dB PSNR improvement over
state-of-the-art defocus deblurring methods. In addition, our multi-task
framework allows accurate DP-view synthesis (e.g., ~ 39dB PSNR) from the single
input image. These high-quality DP views can be used for other DP-based
applications, such as reflection removal. As part of this effort, we have
captured a new dataset of 7,059 high-quality images to support our training for
the DP-view synthesis task. Our dataset, code, and trained models will be made
publicly available at
https://github.com/Abdullah-Abuolaim/multi-task-defocus-deblurring-dual-pixel-nimat</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-weighted Central Similarity for Multi-label Image Retrieval. (arXiv:2108.05274v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hanyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05274">
                                    <div class="article-summary-box-inner">
                                        <span>Deep hashing has been widely applied to large-scale image retrieval by
encoding high-dimensional data points into binary codes for efficient
retrieval. Compared with pairwise/triplet similarity based hash learning,
central similarity based hashing can more efficiently capture the global data
distribution. For multi-label image retrieval, however, previous methods only
use multiple hash centers with equal weights to generate one centroid as the
learning target, which ignores the relationship between the weights of hash
centers and the proportion of instance regions in the image. To address the
above issue, we propose a two-step alternative optimization approach,
Instance-weighted Central Similarity (ICS), to automatically learn the center
weight corresponding to a hash code. Firstly, we apply the maximum entropy
regularizer to prevent one hash center from dominating the loss function, and
compute the center weights via projection gradient descent. Secondly, we update
neural network parameters by standard back-propagation with fixed center
weights. More importantly, the learned center weights can well reflect the
proportion of foreground instances in the image. Our method achieves the
state-of-the-art performance on the image retrieval benchmarks, and especially
improves the mAP by 1.6%-6.4% on the MS COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mounting Video Metadata on Transformer-based Language Model for Open-ended Video Question Answering. (arXiv:2108.05158v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Donggeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Seongho Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_Y/0/1/0/all/0/1">Youwon Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Byoung-Tak Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05158">
                                    <div class="article-summary-box-inner">
                                        <span>Video question answering has recently received a lot of attention from
multimodal video researchers. Most video question answering datasets are
usually in the form of multiple-choice. But, the model for the multiple-choice
task does not infer the answer. Rather it compares the answer candidates for
picking the correct answer. Furthermore, it makes it difficult to extend to
other tasks. In this paper, we challenge the existing multiple-choice video
question answering by changing it to open-ended video question answering. To
tackle open-ended question answering, we use the pretrained GPT2 model. The
model is fine-tuned with video inputs and subtitles. An ablation study is
performed by changing the existing DramaQA dataset to an open-ended question
answering, and it shows that performance can be improved using video metadata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Polyp Segmentation via Multi-scale Subtraction Network. (arXiv:2108.05082v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiaoqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lihe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Huchuan Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05082">
                                    <div class="article-summary-box-inner">
                                        <span>More than 90\% of colorectal cancer is gradually transformed from colorectal
polyps. In clinical practice, precise polyp segmentation provides important
information in the early detection of colorectal cancer. Therefore, automatic
polyp segmentation techniques are of great importance for both patients and
doctors. Most existing methods are based on U-shape structure and use
element-wise addition or concatenation to fuse different level features
progressively in decoder. However, both the two operations easily generate
plenty of redundant information, which will weaken the complementarity between
different level features, resulting in inaccurate localization and blurred
edges of polyps. To address this challenge, we propose a multi-scale
subtraction network (MSNet) to segment polyp from colonoscopy image.
Specifically, we first design a subtraction unit (SU) to produce the difference
features between adjacent levels in encoder. Then, we pyramidally equip the SUs
at different levels with varying receptive fields, thereby obtaining rich
multi-scale difference information. In addition, we build a training-free
network &quot;LossNet&quot; to comprehensively supervise the polyp-aware features from
bottom layer to top layer, which drives the MSNet to capture the detailed and
structural cues simultaneously. Extensive experiments on five benchmark
datasets demonstrate that our MSNet performs favorably against most
state-of-the-art methods under different evaluation metrics. Furthermore, MSNet
runs at a real-time speed of $\sim$70fps when processing a $352 \times 352$
image. The source code will be publicly available at
\url{https://github.com/Xiaoqi-Zhao-DLUT/MSNet}. \keywords{Colorectal Cancer
\and Automatic Polyp Segmentation \and Subtraction \and LossNet.}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset. (arXiv:2108.05080v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khalid_H/0/1/0/all/0/1">Hasam Khalid</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05080">
                                    <div class="article-summary-box-inner">
                                        <span>With the significant advancements made in generation of forged video and
audio, commonly known as deepfakes, using deep learning technologies, the
problem of its misuse is a well-known issue now. Recently, a new problem of
generating cloned or synthesized human voice of a person is emerging. AI-based
deep learning models can synthesize any person&#x27;s voice requiring just a few
seconds of audio. With the emerging threat of impersonation attacks using
deepfake videos and audios, new deepfake detectors are need that focuses on
both, video and audio. Detecting deepfakes is a challenging task and
researchers have made numerous attempts and proposed several deepfake detection
methods. To develop a good deepfake detector, a handsome amount of good quality
dataset is needed that captures the real world scenarios. Many researchers have
contributed in this cause and provided several deepfake dataset, self generated
and in-the-wild. However, almost all of these datasets either contains deepfake
videos or audio. Moreover, the recent deepfake datasets proposed by researchers
have racial bias issues. Hence, there is a crucial need of a good deepfake
video and audio deepfake dataset. To fill this gap, we propose a novel
Audio-Video Deepfake dataset (FakeAVCeleb) that not only contains deepfake
videos but respective synthesized cloned audios as well. We generated our
dataset using recent most popular deepfake generation methods and the videos
and audios are perfectly lip-synced with each other. To generate a more
realistic dataset, we selected real YouTube videos of celebrities having four
racial backgrounds (Caucasian, Black, East Asian and South Asian) to counter
the racial bias issue. Lastly, we propose a novel multimodal detection method
that detects deepfake videos and audios based on our multimodal Audio-Video
deepfake dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-Shot Domain Adaptation with a Physics Prior. (arXiv:2108.05137v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lengyel_A/0/1/0/all/0/1">Attila Lengyel</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sourav Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Milford_M/0/1/0/all/0/1">Michael Milford</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05137">
                                    <div class="article-summary-box-inner">
                                        <span>We explore the zero-shot setting for day-night domain adaptation. The
traditional domain adaptation setting is to train on one domain and adapt to
the target domain by exploiting unlabeled data samples from the test set. As
gathering relevant test data is expensive and sometimes even impossible, we
remove any reliance on test data imagery and instead exploit a visual inductive
prior derived from physics-based reflection models for domain adaptation. We
cast a number of color invariant edge detectors as trainable layers in a
convolutional neural network and evaluate their robustness to illumination
changes. We show that the color invariant layer reduces the day-night
distribution shift in feature map activations throughout the network. We
demonstrate improved performance for zero-shot day to night domain adaptation
on both synthetic as well as natural datasets in various tasks, including
classification, segmentation and place recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach. (arXiv:2108.05060v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heuer_F/0/1/0/all/0/1">Falk Heuer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mantowsky_S/0/1/0/all/0/1">Sven Mantowsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukhari_S/0/1/0/all/0/1">Syed Saqib Bukhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1">Georg Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05060">
                                    <div class="article-summary-box-inner">
                                        <span>Multitask learning is a common approach in machine learning, which allows to
train multiple objectives with a shared architecture. It has been shown that by
training multiple tasks together inference time and compute resources can be
saved, while the objectives performance remains on a similar or even higher
level. However, in perception related multitask networks only closely related
tasks can be found, such as object detection, instance and semantic
segmentation or depth estimation. Multitask networks with diverse tasks and
their effects with respect to efficiency on one another are not well studied.
In this paper we augment the CenterNet anchor-free approach for training
multiple diverse perception related tasks together, including the task of
object detection and semantic segmentation as well as human pose estimation. We
refer to this DNN as Multitask-CenterNet (MCN). Additionally, we study
different MCN settings for efficiency. The MCN can perform several tasks at
once while maintaining, and in some cases even exceeding, the performance
values of its corresponding single task networks. More importantly, the MCN
architecture decreases inference time and reduces network size when compared to
a composition of single task networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Coarse-to-Fine Approach in Single Image Deblurring. (arXiv:2108.05054v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Sung-Jin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Seo-Won Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Jun-Pyo Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Seung-Won Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_S/0/1/0/all/0/1">Sung-Jea Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05054">
                                    <div class="article-summary-box-inner">
                                        <span>Coarse-to-fine strategies have been extensively used for the architecture
design of single image deblurring networks. Conventional methods typically
stack sub-networks with multi-scale input images and gradually improve
sharpness of images from the bottom sub-network to the top sub-network,
yielding inevitably high computational costs. Toward a fast and accurate
deblurring network design, we revisit the coarse-to-fine strategy and present a
multi-input multi-output U-net (MIMO-UNet). The MIMO-UNet has three distinct
features. First, the single encoder of the MIMO-UNet takes multi-scale input
images to ease the difficulty of training. Second, the single decoder of the
MIMO-UNet outputs multiple deblurred images with different scales to mimic
multi-cascaded U-nets using a single U-shaped network. Last, asymmetric feature
fusion is introduced to merge multi-scale features in an efficient manner.
Extensive experiments on the GoPro and RealBlur datasets demonstrate that the
proposed network outperforms the state-of-the-art methods in terms of both
accuracy and computational complexity. Source code is available for research
purposes at https://github.com/chosj95/MIMO-UNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Dependency Guided Contrastive Learning for Multiple Labeling in Prenatal Ultrasound. (arXiv:2108.05055v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shuangchi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zehui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shuang_X/0/1/0/all/0/1">Xue Shuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Ziwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiduo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1">Ruobing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_N/0/1/0/all/0/1">Nishant Ravikumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro Frangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuanji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1">Dong Ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05055">
                                    <div class="article-summary-box-inner">
                                        <span>Standard plane recognition plays an important role in prenatal ultrasound
(US) screening. Automatically recognizing the standard plane along with the
corresponding anatomical structures in US image can not only facilitate US
image interpretation but also improve diagnostic efficiency. In this study, we
build a novel multi-label learning (MLL) scheme to identify multiple standard
planes and corresponding anatomical structures of fetus simultaneously. Our
contribution is three-fold. First, we represent the class correlation by word
embeddings to capture the fine-grained semantic and latent statistical
concurrency. Second, we equip the MLL with a graph convolutional network to
explore the inner and outer relationship among categories. Third, we propose a
novel cluster relabel-based contrastive learning algorithm to encourage the
divergence among ambiguous classes. Extensive validation was performed on our
large in-house dataset. Our approach reports the highest accuracy as 90.25% for
standard planes labeling, 85.59% for planes and structures labeling and mAP as
94.63%. The proposed MLL scheme provides a novel perspective for standard plane
recognition and can be easily extended to other medical image classification
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source Fusion and Automatic Predictor Selection for Zero-Shot Video Object Segmentation. (arXiv:2108.05076v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiaoqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Youwei Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaxing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lihe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Huchuan Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05076">
                                    <div class="article-summary-box-inner">
                                        <span>Location and appearance are the key cues for video object segmentation. Many
sources such as RGB, depth, optical flow and static saliency can provide useful
information about the objects. However, existing approaches only utilize the
RGB or RGB and optical flow. In this paper, we propose a novel multi-source
fusion network for zero-shot video object segmentation. With the help of
interoceptive spatial attention module (ISAM), spatial importance of each
source is highlighted. Furthermore, we design a feature purification module
(FPM) to filter the inter-source incompatible features. By the ISAM and FPM,
the multi-source features are effectively fused. In addition, we put forward an
automatic predictor selection network (APS) to select the better prediction of
either the static saliency predictor or the moving object predictor in order to
prevent over-reliance on the failed results caused by low-quality optical flow
maps. Extensive experiments on three challenging public benchmarks (i.e.
DAVIS$_{16}$, Youtube-Objects and FBMS) show that the proposed model achieves
compelling performance against the state-of-the-arts. The source code will be
publicly available at
\textcolor{red}{\url{https://github.com/Xiaoqi-Zhao-DLUT/Multi-Source-APS-ZVOS}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Top-Down Just Noticeable Difference Estimation of Natural Images. (arXiv:2108.05058v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1">Qiuping Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_F/0/1/0/all/0/1">Feng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Weisi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05058">
                                    <div class="article-summary-box-inner">
                                        <span>Existing efforts on Just noticeable difference (JND) estimation mainly
dedicate to modeling the visibility masking effects of different factors in
spatial and frequency domains, and then fusing them into an overall JND
estimate. However, the overall visibility masking effect can be related with
more contributing factors beyond those have been considered in the literature
and it is also insufficiently accurate to formulate the masking effect even for
an individual factor. Moreover, the potential interactions among different
masking effects are also difficult to be characterized with a simple fusion
model. In this work, we turn to a dramatically different way to address these
problems with a top-down design philosophy. Instead of formulating and fusing
multiple masking effects in a bottom-up way, the proposed JND estimation model
directly generates a critical perceptual lossless (CPL) image from a top-down
perspective and calculates the difference map between the original image and
the CPL image as the final JND map. Given an input image, an adaptively
critical point (perceptual lossless threshold), defined as the minimum number
of spectral components in Karhunen-Lo\&#x27;{e}ve Transform (KLT) used for
perceptual lossless image reconstruction, is derived by exploiting the
convergence characteristics of KLT coefficient energy. Then, the CPL image can
be reconstructed via inverse KLT according to the derived critical point.
Finally, the difference map between the original image and the CPL image is
calculated as the JND map. The performance of the proposed JND model is
evaluated with two applications including JND-guided noise injection and
JND-guided image compression. Experimental results have demonstrated that our
proposed JND model can achieve better performance than several latest JND
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prototype Completion for Few-Shot Learning. (arXiv:2108.05010v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baoquan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xutao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yunming Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shanshan Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05010">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning aims to recognize novel classes with few examples.
Pre-training based methods effectively tackle the problem by pre-training a
feature extractor and then fine-tuning it through the nearest centroid based
meta-learning. However, results show that the fine-tuning step makes marginal
improvements. In this paper, 1) we figure out the reason, i.e., in the
pre-trained feature space, the base classes already form compact clusters while
novel classes spread as groups with large variances, which implies that
fine-tuning feature extractor is less meaningful; 2) instead of fine-tuning
feature extractor, we focus on estimating more representative prototypes.
Consequently, we propose a novel prototype completion based meta-learning
framework. This framework first introduces primitive knowledge (i.e.,
class-level part or attribute annotations) and extracts representative features
for seen attributes as priors. Second, a part/attribute transfer network is
designed to learn to infer the representative features for unseen attributes as
supplementary priors. Finally, a prototype completion network is devised to
learn to complete prototypes with these priors. Moreover, to avoid the
prototype completion error, we further develop a Gaussian based prototype
fusion strategy that fuses the mean-based and completed prototypes by
exploiting the unlabeled samples. Extensive experiments show that our method:
(i) obtains more accurate prototypes; (ii) achieves superior performance on
both inductive and transductive FSL settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Domain Generalizable Person Re-Identification. (arXiv:2108.05045v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lingxiao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kecheng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xingyu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Peng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05045">
                                    <div class="article-summary-box-inner">
                                        <span>Existing person re-identification (re-id) methods are stuck when deployed to
a new unseen scenario despite the success in cross-camera person matching.
Recent efforts have been substantially devoted to domain adaptive person re-id
where extensive unlabeled data in the new scenario are utilized in a
transductive learning manner. However, for each scenario, it is required to
first collect enough data and then train such a domain adaptive re-id model,
thus restricting their practical application. Instead, we aim to explore
multiple labeled datasets to learn generalized domain-invariant representations
for person re-id, which is expected universally effective for each new-coming
re-id scenario. To pursue practicability in real-world systems, we collect all
the person re-id datasets (20 datasets) in this field and select the three most
frequently used datasets (i.e., Market1501, DukeMTMC, and MSMT17) as unseen
target domains. In addition, we develop DataHunter that collects over 300K+
weak annotated images named YouTube-Human from YouTube street-view videos,
which joins 17 remaining full labeled datasets to form multiple source domains.
On such a large and challenging benchmark called FastHuman (~440K+ labeled
images), we further propose a simple yet effective Semi-Supervised Knowledge
Distillation (SSKD) framework. SSKD effectively exploits the weakly annotated
data by assigning soft pseudo labels to YouTube-Human to improve models&#x27;
generalization ability. Experiments on several protocols verify the
effectiveness of the proposed SSKD framework on domain generalizable person
re-id, which is even comparable to supervised learning on the target domains.
Lastly, but most importantly, we hope the proposed benchmark FastHuman could
bring the next development of domain generalizable person re-id algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NI-UDA: Graph Adversarial Domain Adaptation from Non-shared-and-Imbalanced Big Data to Small Imbalanced Applications. (arXiv:2108.05061v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1">Guangyi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1">Weiwei Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jingzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zhiguo Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05061">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new general Graph Adversarial Domain Adaptation (GADA) based on
semantic knowledge reasoning of class structure for solving the problem of
unsupervised domain adaptation (UDA) from the big data with non-shared and
imbalanced classes to specified small and imbalanced applications (NI-UDA),
where non-shared classes mean the label space out of the target domain. Our
goal is to leverage priori hierarchy knowledge to enhance domain adversarial
aligned feature representation with graph reasoning. In this paper, to address
two challenges in NI-UDA, we equip adversarial domain adaptation with Hierarchy
Graph Reasoning (HGR) layer and the Source Classifier Filter (SCF). For sparse
classes transfer challenge, our HGR layer can aggregate local feature to
hierarchy graph nodes by node prediction and enhance domain adversarial aligned
feature with hierarchy graph reasoning for sparse classes. Our HGR contributes
to learn direct semantic patterns for sparse classes by hierarchy attention in
self-attention, non-linear mapping and graph normalization. our SCF is proposed
for the challenge of knowledge sharing from non-shared data without negative
transfer effect by filtering low-confidence non-shared data in HGR layer.
Experiments on two benchmark datasets show our GADA methods consistently
improve the state-of-the-art adversarial UDA algorithms, e.g. GADA(HGR) can
greatly improve f1 of the MDD by \textbf{7.19\%} and GVB-GD by \textbf{7.89\%}
respectively on imbalanced source task in Meal300 dataset. The code is
available at https://gadatransfer.wixsite.com/gada.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder. (arXiv:2108.05028v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Hanwen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1">Peng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Juwei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05028">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art (SOTA) few-shot learning (FSL) methods suffer significant
performance drop in the presence of domain differences between source and
target datasets. The strong discrimination ability on the source dataset does
not necessarily translate to high classification accuracy on the target
dataset. In this work, we address this cross-domain few-shot learning (CDFSL)
problem by boosting the generalization capability of the model. Specifically,
we teach the model to capture broader variations of the feature distributions
with a novel noise-enhanced supervised autoencoder (NSAE). NSAE trains the
model by jointly reconstructing inputs and predicting the labels of inputs as
well as their reconstructed pairs. Theoretical analysis based on intra-class
correlation (ICC) shows that the feature embeddings learned from NSAE have
stronger discrimination and generalization abilities in the target domain. We
also take advantage of NSAE structure and propose a two-step fine-tuning
procedure that achieves better adaption and improves classification performance
in the target domain. Extensive experiments and ablation studies are conducted
to demonstrate the effectiveness of the proposed method. Experimental results
show that our proposed method consistently outperforms SOTA methods under
various conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Oculomotor Behaviors from Scanpath. (arXiv:2108.05025v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuechterlein_N/0/1/0/all/0/1">Nicholas Nuechterlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Barney_E/0/1/0/all/0/1">Erin Barney</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_C/0/1/0/all/0/1">Claire Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minah Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahony_M/0/1/0/all/0/1">Monique Mahony</a>, <a href="http://arxiv.org/find/cs/1/au:+Atyabi_A/0/1/0/all/0/1">Adham Atyabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Li Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventola_P/0/1/0/all/0/1">Pamela Ventola</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapiro_L/0/1/0/all/0/1">Linda Shapiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Shic_F/0/1/0/all/0/1">Frederick Shic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05025">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying oculomotor behaviors relevant for eye-tracking applications is a
critical but often challenging task. Aiming to automatically learn and extract
knowledge from existing eye-tracking data, we develop a novel method that
creates rich representations of oculomotor scanpaths to facilitate the learning
of downstream tasks. The proposed stimulus-agnostic Oculomotor Behavior
Framework (OBF) model learns human oculomotor behaviors from unsupervised and
semi-supervised tasks, including reconstruction, predictive coding, fixation
identification, and contrastive learning tasks. The resultant pre-trained OBF
model can be used in a variety of applications. Our pre-trained model
outperforms baseline approaches and traditional scanpath methods in autism
spectrum disorder and viewed-stimulus classification tasks. Ablation
experiments further show our proposed method could achieve even better results
with larger model sizes and more diverse eye-tracking training datasets,
supporting the model&#x27;s potential for future eye-tracking applications. Open
source code: this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Sided Box Filter for Edge Preserving Image Smoothing. (arXiv:2108.05021v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1">Yuanhao Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05021">
                                    <div class="article-summary-box-inner">
                                        <span>Image smoothing is a fundamental task in signal processing. For such task,
box filter is well-known. However, box filter can not keep some features of the
signal, such as edges, corners and the jump in the step function. In this
paper, we present a one-sided box filter that can smooth the signal but keep
the discontinuous features in the signal. More specifically, we perform box
filter on eight one-sided windows, leading to a one-sided box filter that can
preserve corners and edges. Our filter inherits the constant $O(1)$
computational complexity of the original box filter with respect to the window
size and also the linear $O(N)$ computational complexity with respect to the
total number of samples. We performance several experiments to show the
efficiency and effectiveness of this filter. We further compare our filter with
other the-state-of-the-art edge preserving methods. Our filter can be deployed
in a large range of applications where the classical box filter is adopted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows. (arXiv:2108.05015v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaowei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05015">
                                    <div class="article-summary-box-inner">
                                        <span>Different from visible cameras which record intensity images frame by frame,
the biologically inspired event camera produces a stream of asynchronous and
sparse events with much lower latency. In practice, the visible cameras can
better perceive texture details and slow motion, while event cameras can be
free from motion blurs and have a larger dynamic range which enables them to
work well under fast motion and low illumination. Therefore, the two sensors
can cooperate with each other to achieve more reliable object tracking. In this
work, we propose a large-scale Visible-Event benchmark (termed VisEvent) due to
the lack of a realistic and scaled dataset for this task. Our dataset consists
of 820 video pairs captured under low illumination, high speed, and background
clutter scenarios, and it is divided into a training and a testing subset, each
of which contains 500 and 320 videos, respectively. Based on VisEvent, we
transform the event flows into event images and construct more than 30 baseline
methods by extending current single-modality trackers into dual-modality
versions. More importantly, we further build a simple but effective tracking
algorithm by proposing a cross-modality transformer, to achieve more effective
feature fusion between visible and event data. Extensive experiments on the
proposed VisEvent dataset, and two simulated datasets (i.e., OTB-DVS and
VOT-DVS), validated the effectiveness of our model. The dataset and source code
will be available at our project page:
\url{https://sites.google.com/view/viseventtrack/}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple black-box universal adversarial attacks on medical image classification based on deep neural networks. (arXiv:2108.04979v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koga_K/0/1/0/all/0/1">Kazuki Koga</a>, <a href="http://arxiv.org/find/cs/1/au:+Takemoto_K/0/1/0/all/0/1">Kazuhiro Takemoto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04979">
                                    <div class="article-summary-box-inner">
                                        <span>Universal adversarial attacks, which hinder most deep neural network (DNN)
tasks using only a small single perturbation called a universal adversarial
perturbation (UAP), is a realistic security threat to the practical application
of a DNN. In particular, such attacks cause serious problems in medical
imaging. Given that computer-based systems are generally operated under a
black-box condition in which only queries on inputs are allowed and outputs are
accessible, the impact of UAPs seems to be limited because well-used algorithms
for generating UAPs are limited to a white-box condition in which adversaries
can access the model weights and loss gradients. Nevertheless, we demonstrate
that UAPs are easily generatable using a relatively small dataset under
black-box conditions. In particular, we propose a method for generating UAPs
using a simple hill-climbing search based only on DNN outputs and demonstrate
the validity of the proposed method using representative DNN-based medical
image classifications. Black-box UAPs can be used to conduct both non-targeted
and targeted attacks. Overall, the black-box UAPs showed high attack success
rates (40% to 90%), although some of them had relatively low success rates
because the method only utilizes limited information to generate UAPs. The
vulnerability of black-box UAPs was observed in several model architectures.
The results indicate that adversaries can also generate UAPs through a simple
procedure under the black-box condition to foil or control DNN-based medical
image diagnoses, and that UAPs are a more realistic security threat.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Action Completeness from Points for Weakly-supervised Temporal Action Localization. (arXiv:2108.05029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_P/0/1/0/all/0/1">Pilhyeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_H/0/1/0/all/0/1">Hyeran Byun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05029">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the problem of localizing temporal intervals of actions with only a
single frame label for each action instance for training. Owing to label
sparsity, existing work fails to learn action completeness, resulting in
fragmentary action predictions. In this paper, we propose a novel framework,
where dense pseudo-labels are generated to provide completeness guidance for
the model. Concretely, we first select pseudo background points to supplement
point-level action labels. Then, by taking the points as seeds, we search for
the optimal sequence that is likely to contain complete action instances while
agreeing with the seeds. To learn completeness from the obtained sequence, we
introduce two novel losses that contrast action instances with background ones
in terms of action score and feature similarity, respectively. Experimental
results demonstrate that our completeness guidance indeed helps the model to
locate complete action instances, leading to large performance gains especially
under high IoU thresholds. Moreover, we demonstrate the superiority of our
method over existing state-of-the-art methods on four benchmarks: THUMOS&#x27;14,
GTEA, BEOID, and ActivityNet. Notably, our method even performs comparably to
recent fully-supervised methods, at the 6 times cheaper annotation cost. Our
code is available at https://github.com/Pilhyeon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Deep Multimodal Feature Representation with Asymmetric Multi-layer Fusion. (arXiv:2108.05009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yikai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fuchun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Ming Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Anbang Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05009">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a compact and effective framework to fuse multimodal features at
multiple layers in a single network. The framework consists of two innovative
fusion schemes. Firstly, unlike existing multimodal methods that necessitate
individual encoders for different modalities, we verify that multimodal
features can be learnt within a shared single network by merely maintaining
modality-specific batch normalization layers in the encoder, which also enables
implicit fusion via joint feature representation learning. Secondly, we propose
a bidirectional multi-layer fusion scheme, where multimodal features can be
exploited progressively. To take advantage of such scheme, we introduce two
asymmetric fusion operations including channel shuffle and pixel shift, which
learn different fused features with respect to different fusion directions.
These two operations are parameter-free and strengthen the multimodal feature
interactions across channels as well as enhance the spatial feature
discrimination within channels. We conduct extensive experiments on semantic
segmentation and image translation tasks, based on three publicly available
datasets covering diverse modalities. Results indicate that our proposed
framework is general, compact and is superior to state-of-the-art fusion
frameworks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elastic Tactile Simulation Towards Tactile-Visual Perception. (arXiv:2108.05013v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yikai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenbing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_B/0/1/0/all/0/1">Bin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fuchun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05013">
                                    <div class="article-summary-box-inner">
                                        <span>Tactile sensing plays an important role in robotic perception and
manipulation tasks. To overcome the real-world limitations of data collection,
simulating tactile response in a virtual environment comes as a desirable
direction of robotic research. In this paper, we propose Elastic Interaction of
Particles (EIP) for tactile simulation. Most existing works model the tactile
sensor as a rigid multi-body, which is incapable of reflecting the elastic
property of the tactile sensor as well as characterizing the fine-grained
physical interaction between the two objects. By contrast, EIP models the
tactile sensor as a group of coordinated particles, and the elastic property is
applied to regulate the deformation of particles during contact. With the
tactile simulation by EIP, we further propose a tactile-visual perception
network that enables information fusion between tactile data and visual images.
The perception network is based on a global-to-local fusion mechanism where
multi-scale tactile features are aggregated to the corresponding local region
of the visual modality with the guidance of tactile positions and directions.
The fusion method exhibits superiority regarding the 3D geometric
reconstruction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image-based Generator Architecture for Synthetic Image Refinement. (arXiv:2108.04957v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasser_A/0/1/0/all/0/1">Alex Nasser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04957">
                                    <div class="article-summary-box-inner">
                                        <span>Proposed are alternative generator architectures for Boundary Equilibrium
Generative Adversarial Networks, motivated by Learning from Simulated and
Unsupervised Images through Adversarial Training. It disentangles the need for
a noise-based latent space. The generator will operate mainly as a refiner
network to gain a photo-realistic presentation of the given synthetic images.
It also attempts to resolve the latent space&#x27;s poorly understood properties by
eliminating the need for noise injection and replacing it with an image-based
concept. The new flexible and simple generator architecture will also give the
power to control the trade-off between restrictive refinement and
expressiveness ability. Contrary to other available methods, this architecture
will not require a paired or unpaired dataset of real and synthetic images for
the training phase. Only a relatively small set of real images would suffice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Transformer-based Math Language Model for Handwritten Math Expression Recognition. (arXiv:2108.05002v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ung_H/0/1/0/all/0/1">Huy Quang Ung</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Hung Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Nghia Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakagawa_M/0/1/0/all/0/1">Masaki Nakagawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05002">
                                    <div class="article-summary-box-inner">
                                        <span>Handwritten mathematical expressions (HMEs) contain ambiguities in their
interpretations, even for humans sometimes. Several math symbols are very
similar in the writing style, such as dot and comma or 0, O, and o, which is a
challenge for HME recognition systems to handle without using contextual
information. To address this problem, this paper presents a Transformer-based
Math Language Model (TMLM). Based on the self-attention mechanism, the
high-level representation of an input token in a sequence of tokens is computed
by how it is related to the previous tokens. Thus, TMLM can capture long
dependencies and correlations among symbols and relations in a mathematical
expression (ME). We trained the proposed language model using a corpus of
approximately 70,000 LaTeX sequences provided in CROHME 2016. TMLM achieved the
perplexity of 4.42, which outperformed the previous math language models, i.e.,
the N-gram and recurrent neural network-based language models. In addition, we
combine TMLM into a stochastic context-free grammar-based HME recognition
system using a weighting parameter to re-rank the top-10 best candidates. The
expression rates on the testing sets of CROHME 2016 and CROHME 2019 were
improved by 2.97 and 0.83 percentage points, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis. (arXiv:2108.04938v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Monajatipoor_M/0/1/0/all/0/1">Masoud Monajatipoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouhsedaghat_M/0/1/0/all/0/1">Mozhdeh Rouhsedaghat</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liunian Harold Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_A/0/1/0/all/0/1">Aichi Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Scalzo_F/0/1/0/all/0/1">Fabien Scalzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04938">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-and-language(V&amp;L) models take image and text as input and learn to
capture the associations between them. Prior studies show that pre-trained V&amp;L
models can significantly improve the model performance for downstream tasks
such as Visual Question Answering (VQA). However, V&amp;L models are less effective
when applied in the medical domain (e.g., on X-ray images and clinical notes)
due to the domain gap. In this paper, we investigate the challenges of applying
pre-trained V&amp;L models in medical applications. In particular, we identify that
the visual representation in general V&amp;L models is not suitable for processing
medical data. To overcome this limitation, we propose BERTHop, a
transformer-based model based on PixelHop++ and VisualBERT, for better
capturing the associations between the two modalities. Experiments on the OpenI
dataset, a commonly used thoracic disease diagnosis benchmark, show that
BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62%
higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Fair Face Representation With Progressive Cross Transformer. (arXiv:2108.04983v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yufei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04983">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition (FR) has made extraordinary progress owing to the
advancement of deep convolutional neural networks. However, demographic bias
among different racial cohorts still challenges the practical face recognition
system. The race factor has been proven to be a dilemma for fair FR (FFR) as
the subject-related specific attributes induce the classification bias whilst
carrying some useful cues for FR. To mitigate racial bias and meantime preserve
robust FR, we abstract face identity-related representation as a signal
denoising problem and propose a progressive cross transformer (PCT) method for
fair face recognition. Originating from the signal decomposition theory, we
attempt to decouple face representation into i) identity-related components and
ii) noisy/identity-unrelated components induced by race. As an extension of
signal subspace decomposition, we formulate face decoupling as a generalized
functional expression model to cross-predict face identity and race
information. The face expression model is further concretized by designing dual
cross-transformers to distill identity-related components and suppress racial
noises. In order to refine face representation, we take a progressive face
decoupling way to learn identity/race-specific transformations, so that
identity-unrelated components induced by race could be better disentangled. We
evaluate the proposed PCT on the public fair face recognition benchmarks (BFW,
RFW) and verify that PCT is capable of mitigating bias in face recognition
while achieving state-of-the-art FR performance. Besides, visualization results
also show that the attention maps in PCT can well reveal the
race-related/biased facial regions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?. (arXiv:2108.04893v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+pourmirzaei_M/0/1/0/all/0/1">Mahdi pourmirzaei</a>, <a href="http://arxiv.org/find/cs/1/au:+montazer_g/0/1/0/all/0/1">gholam ali montazer</a>, <a href="http://arxiv.org/find/cs/1/au:+esmaili_f/0/1/0/all/0/1">farzaneh esmaili</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04893">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress of Self-Supervised Learning (SSL) demonstrates the capability
of these methods in computer vision field. However, this progress could not
show any promises for fine-grained tasks such as Head Pose estimation. In this
article, we have tried to answer a question: How SSL can be used for Head Pose
estimation? In general, there are two main approaches to use SSL: 1. Using
pre-trained weights which can be done via weights pre-training on ImageNet or
via SSL tasks. 2. Leveraging SSL as an auxiliary co-training task besides of
Supervised Learning (SL) tasks at the same time. In this study, modified
versions of jigsaw puzzling and rotation as SSL pre-text tasks are used and the
best architecture for our proposed Hybrid Multi-Task Learning (HMTL) is found.
Finally, the HopeNet method as a baseline is selected and the impact of SSL
pre-training and ImageNet pre-training on both HMTL and SL are compared. The
error rate reduced by the HTML method up to 11% compare to the SL. Moreover,
HMTL method showed that it was good with all kinds of initial weights: random,
ImageNet and SSL pre-training weights. Also, it was observed, when puzzled
images are used for SL alone, the average error rate placed between SL and HMTL
which showed the importance of local spatial features compare to global spatial
features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">First Order Locally Orderless Registration. (arXiv:2108.04926v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Darkner_S/0/1/0/all/0/1">Sune Darkner</a>, <a href="http://arxiv.org/find/cs/1/au:+Tascon_J/0/1/0/all/0/1">Jose D Tascon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauze_F/0/1/0/all/0/1">Francois Lauze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04926">
                                    <div class="article-summary-box-inner">
                                        <span>First Order Locally Orderless Registration (FLOR) is a scale-space framework
for image density estimation used for defining image similarity, mainly for
Image Registration. The Locally Orderless Registration framework was designed
in principle to use zeroth-order information, providing image density estimates
over three scales: image scale, intensity scale, and integration scale. We
extend it to take first-order information into account and hint at higher-order
information. We show how standard similarity measures extend into the
framework. We study especially Sum of Squared Differences (SSD) and Normalized
Cross-Correlation (NCC) but present the theory of how Normalised Mutual
Information (NMI) can be included.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1">Alessandro Suglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qiaozi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Thattai_G/0/1/0/all/0/1">Govind Thattai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1">Gaurav Sukhatme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
                                    <div class="article-summary-box-inner">
                                        <span>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal MRI Undersampling Patterns for Ultimate Benefit of Medical Vision Tasks. (arXiv:2108.04914v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Razumov_A/0/1/0/all/0/1">Artem Razumov</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogov_O/0/1/0/all/0/1">Oleg Y. Rogov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dylov_D/0/1/0/all/0/1">Dmitry V. Dylov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04914">
                                    <div class="article-summary-box-inner">
                                        <span>To accelerate MRI, the field of compressed sensing is traditionally concerned
with optimizing the image quality after a partial undersampling of the
measurable $\textit{k}$-space. In our work, we propose to change the focus from
the quality of the reconstructed image to the quality of the downstream image
analysis outcome. Specifically, we propose to optimize the patterns according
to how well a sought-after pathology could be detected or localized in the
reconstructed images. We find the optimal undersampling patterns in
$\textit{k}$-space that maximize target value functions of interest in
commonplace medical vision problems (reconstruction, segmentation, and
classification) and propose a new iterative gradient sampling routine
universally suitable for these tasks. We validate the proposed MRI acceleration
paradigm on three classical medical datasets, demonstrating a noticeable
improvement of the target metrics at the high acceleration factors (for the
segmentation problem at $\times$16 acceleration, we report up to 12%
improvement in Dice score over the other undersampling patterns).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection. (arXiv:2108.04867v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiaoran Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1">Riley Simmons-Edler</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daewon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jackel_L/0/1/0/all/0/1">Larry Jackel</a>, <a href="http://arxiv.org/find/cs/1/au:+Howard_R/0/1/0/all/0/1">Richard Howard</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04867">
                                    <div class="article-summary-box-inner">
                                        <span>Perceiving obstacles and avoiding collisions is fundamental to the safe
operation of a robot system, particularly when the robot must operate in highly
dynamic human environments. Proximity detection using on-robot sensors can be
used to avoid or mitigate impending collisions. However, existing proximity
sensing methods are orientation and placement dependent, resulting in blind
spots even with large numbers of sensors. In this paper, we introduce the
phenomenon of the Leaky Surface Wave (LSW), a novel sensing modality, and
present AuraSense, a proximity detection system using the LSW. AuraSense is the
first system to realize no-dead-spot proximity sensing for robot arms. It
requires only a single pair of piezoelectric transducers, and can easily be
applied to off-the-shelf robots with minimal modifications. We further
introduce a set of signal processing techniques and a lightweight neural
network to address the unique challenges in using the LSW for proximity
sensing. Finally, we demonstrate a prototype system consisting of a single
piezoelectric element pair on a robot manipulator, which validates our design.
We conducted several micro benchmark experiments and performed more than 2000
on-robot proximity detection trials with various potential robot arm materials,
colliding objects, approach patterns, and robot movement patterns. AuraSense
achieves 100% and 95.3% true positive proximity detection rates when the arm
approaches static and mobile obstacles respectively, with a true negative rate
over 99%, showing the real-world viability of this system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth Infused Binaural Audio Generation using Hierarchical Cross-Modal Attention. (arXiv:2108.04906v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parida_K/0/1/0/all/0/1">Kranti Kumar Parida</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Siddharth Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Matiyali_N/0/1/0/all/0/1">Neeraj Matiyali</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_G/0/1/0/all/0/1">Gaurav Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04906">
                                    <div class="article-summary-box-inner">
                                        <span>Binaural audio gives the listener the feeling of being in the recording place
and enhances the immersive experience if coupled with AR/VR. But the problem
with binaural audio recording is that it requires a specialized setup which is
not possible to fabricate within handheld devices as compared to traditional
mono audio that can be recorded with a single microphone. In order to overcome
this drawback, prior works have tried to uplift the mono recorded audio to
binaural audio as a post processing step conditioning on the visual input. But
all the prior approaches missed other most important information required for
the task, i.e. distance of different sound producing objects from the recording
setup. In this work, we argue that the depth map of the scene can act as a
proxy for encoding distance information of objects in the scene and show that
adding depth features along with image features improves the performance both
qualitatively and quantitatively. We propose a novel encoder-decoder
architecture, where we use a hierarchical attention mechanism to encode the
image and depth feature extracted from individual transformer backbone, with
audio features at each layer of the decoder.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Generative Adversarial Networks for Interactive Image Generation. (arXiv:2108.04896v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04896">
                                    <div class="article-summary-box-inner">
                                        <span>Great progress has been made by the advances in Generative Adversarial
Networks (GANs) for image generation. However, there lacks enough understanding
on how a realistic image can be generated by the deep representations of GANs
from a random vector. This chapter will give a summary of recent works on
interpreting deep generative models. We will see how the human-understandable
concepts that emerge in the learned representation can be identified and used
for interactive image generation and editing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FLAME-in-NeRF : Neural control of Radiance Fields for Free View Face Animation. (arXiv:2108.04913v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Athar_S/0/1/0/all/0/1">ShahRukh Athar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_Z/0/1/0/all/0/1">Zhixin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1">Dimitris Samaras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04913">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a neural rendering method for controllable portrait video
synthesis. Recent advances in volumetric neural rendering, such as neural
radiance fields (NeRF), has enabled the photorealistic novel view synthesis of
static scenes with impressive results. However, modeling dynamic and
controllable objects as part of a scene with such scene representations is
still challenging. In this work, we design a system that enables both novel
view synthesis for portrait video, including the human subject and the scene
background, and explicit control of the facial expressions through a
low-dimensional expression representation. We leverage the expression space of
a 3D morphable face model (3DMM) to represent the distribution of human facial
expressions, and use it to condition the NeRF volumetric function. Furthermore,
we impose a spatial prior brought by 3DMM fitting to guide the network to learn
disentangled control for scene appearance and facial actions. We demonstrate
the effectiveness of our method on free view synthesis of portrait videos with
expression controls. To train a scene, our method only requires a short video
of a subject captured by a mobile device.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Surface Rendering via Non-Differentiable Sampling. (arXiv:2108.04886v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cole_F/0/1/0/all/0/1">Forrester Cole</a>, <a href="http://arxiv.org/find/cs/1/au:+Genova_K/0/1/0/all/0/1">Kyle Genova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sud_A/0/1/0/all/0/1">Avneesh Sud</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlasic_D/0/1/0/all/0/1">Daniel Vlasic</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhoutong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04886">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for differentiable rendering of 3D surfaces that supports
both explicit and implicit representations, provides derivatives at occlusion
boundaries, and is fast and simple to implement. The method first samples the
surface using non-differentiable rasterization, then applies differentiable,
depth-aware point splatting to produce the final image. Our approach requires
no differentiable meshing or rasterization steps, making it efficient for large
3D models and applicable to isosurfaces extracted from implicit surface
definitions. We demonstrate the effectiveness of our method for implicit-,
mesh-, and parametric-surface-based inverse rendering and neural-network
training applications. In particular, we show for the first time efficient,
differentiable rendering of an isosurface extracted from a neural radiance
field (NeRF), and demonstrate surface-based, rather than volume-based,
rendering of a NeRF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Effect of Pruning on Adversarial Robustness. (arXiv:2108.04890v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jordao_A/0/1/0/all/0/1">Artur Jordao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrini_H/0/1/0/all/0/1">Helio Pedrini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04890">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning is a well-known mechanism for reducing the computational cost of deep
convolutional networks. However, studies have shown the potential of pruning as
a form of regularization, which reduces overfitting and improves
generalization. We demonstrate that this family of strategies provides
additional benefits beyond computational performance and generalization. Our
analyses reveal that pruning structures (filters and/or layers) from
convolutional networks increase not only generalization but also robustness to
adversarial images (natural images with content modified). Such achievements
are possible since pruning reduces network capacity and provides
regularization, which have been proven effective tools against adversarial
images. In contrast to promising defense mechanisms that require training with
adversarial images and careful regularization, we show that pruning obtains
competitive results considering only natural images (e.g., the standard and
low-cost training). We confirm these findings on several adversarial attacks
and architectures; thus suggesting the potential of pruning as a novel defense
mechanism against adversarial images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision. (arXiv:2108.04869v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Usman_B/0/1/0/all/0/1">Ben Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_A/0/1/0/all/0/1">Andrea Tagliasacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sud_A/0/1/0/all/0/1">Avneesh Sud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04869">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, huge strides were made in monocular and multi-view pose estimation
with known camera parameters, whereas pose estimation from multiple cameras
with unknown positions and orientations received much less attention. In this
paper, we show how to train a neural model that can perform accurate 3D pose
and camera estimation, takes into account joint location uncertainty due
occlusion from multiple views, and requires only 2D keypoint data for training.
Our method outperforms both classical bundle adjustment and weakly-supervised
monocular 3D baselines on the well-established Human3.6M dataset, as well as
the more challenging in-the-wild Ski-Pose PTZ dataset with moving cameras. We
provide an extensive ablation study separating the error due to the camera
model, number of cameras, initialization, and image-space joint localization
from the additional error introduced by our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Consensus Representation Learning for Attributed Graph. (arXiv:2108.04822v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changshu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Liangjian Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guangchun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04822">
                                    <div class="article-summary-box-inner">
                                        <span>Attempting to fully exploit the rich information of topological structure and
node features for attributed graph, we introduce self-supervised learning
mechanism to graph representation learning and propose a novel Self-supervised
Consensus Representation Learning (SCRL) framework. In contrast to most
existing works that only explore one graph, our proposed SCRL method treats
graph from two perspectives: topology graph and feature graph. We argue that
their embeddings should share some common information, which could serve as a
supervisory signal. Specifically, we construct the feature graph of node
features via k-nearest neighbor algorithm. Then graph convolutional network
(GCN) encoders extract features from two graphs respectively. Self-supervised
loss is designed to maximize the agreement of the embeddings of the same node
in the topology graph and the feature graph. Extensive experiments on real
citation networks and social networks demonstrate the superiority of our
proposed SCRL over the state-of-the-art methods on semi-supervised node
classification task. Meanwhile, compared with its main competitors, SCRL is
rather efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-agnostic vs. Model-intrinsic Interpretability for Explainable Product Search. (arXiv:2108.05317v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramasamy_L/0/1/0/all/0/1">Lakshmi Narayanan Ramasamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05317">
                                    <div class="article-summary-box-inner">
                                        <span>Product retrieval systems have served as the main entry for customers to
discover and purchase products online. With increasing concerns on the
transparency and accountability of AI systems, studies on explainable
information retrieval has received more and more attention in the research
community. Interestingly, in the domain of e-commerce, despite the extensive
studies on explainable product recommendation, the studies of explainable
product search is still in an early stage. In this paper, we study how to
construct effective explainable product search by comparing model-agnostic
explanation paradigms with model-intrinsic paradigms and analyzing the
important factors that determine the performance of product search
explanations. We propose an explainable product search model with
model-intrinsic interpretability and conduct crowdsourcing to compare it with
the state-of-the-art explainable product search model with model-agnostic
interpretability. We observe that both paradigms have their own advantages and
the effectiveness of search explanations on different properties are affected
by different factors. For example, explanation fidelity is more important for
user&#x27;s overall satisfaction on the system while explanation novelty may be more
useful in attracting user purchases. These findings could have important
implications for the future studies and design of explainable product search
engines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Forgotten Role of Search Queries in IR-based Bug Localization: An Empirical Study. (arXiv:2108.05341v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mohammad Masudur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeasmin_S/0/1/0/all/0/1">Shamima Yeasmin</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_C/0/1/0/all/0/1">Chanchal K. Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05341">
                                    <div class="article-summary-box-inner">
                                        <span>Being light-weight and cost-effective, IR-based approaches for bug
localization have shown promise in finding software bugs. However, the accuracy
of these approaches heavily depends on their used bug reports. A significant
number of bug reports contain only plain natural language texts. According to
existing studies, IR-based approaches cannot perform well when they use these
bug reports as search queries. On the other hand, there is a piece of recent
evidence that suggests that even these natural language-only reports contain
enough good keywords that could help localize the bugs successfully. On one
hand, these findings suggest that natural language-only bug reports might be a
sufficient source for good query keywords. On the other hand, they cast serious
doubt on the query selection practices in the IR-based bug localization. In
this article, we attempted to clear the sky on this aspect by conducting an
in-depth empirical study that critically examines the state-of-the-art query
selection practices in IR-based bug localization. In particular, we use a
dataset of 2,320 bug reports, employ ten existing approaches from the
literature, exploit the Genetic Algorithm-based approach to construct optimal,
near-optimal search queries from these bug reports, and then answer three
research questions. We confirmed that the state-of-the-art query construction
approaches are indeed not sufficient for constructing appropriate queries (for
bug localization) from certain natural language-only bug reports although they
contain such queries. We also demonstrate that optimal queries and non-optimal
queries chosen from bug report texts are significantly different in terms of
several keyword characteristics, which has led us to actionable insights.
Furthermore, we demonstrate 27%--34% improvement in the performance of
non-optimal queries through the application of our actionable insights to them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness. (arXiv:2108.05278v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xin Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanbin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1">Man Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05278">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment (EA) aims to find the equivalent entities in different KGs,
which is a crucial step in integrating multiple KGs. However, most existing EA
methods have poor scalability and are unable to cope with large-scale datasets.
We summarize three issues leading to such high time-space complexity in
existing EA methods: (1) Inefficient graph encoders, (2) Dilemma of negative
sampling, and (3) &quot;Catastrophic forgetting&quot; in semi-supervised learning. To
address these challenges, we propose a novel EA method with three new
components to enable high Performance, high Scalability, and high Robustness
(PSR): (1) Simplified graph encoder with relational graph sampling, (2)
Symmetric negative-free alignment loss, and (3) Incremental semi-supervised
learning. Furthermore, we conduct detailed experiments on several public
datasets to examine the effectiveness and efficiency of our proposed method.
The experimental results show that PSR not only surpasses the previous SOTA in
performance but also has impressive scalability and robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIMG: Global and Local Item Graphs for Top-N Recommender Systems. (arXiv:2007.14018v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee-Keong Kwoh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14018">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based recommendation models work well for top-N recommender systems due
to their capability to capture the potential relationships between entities.
However, most of the existing methods only construct a single global item graph
shared by all the users and regrettably ignore the diverse tastes between
different user groups. Inspired by the success of local models for
recommendation, this paper provides the first attempt to investigate multiple
local item graphs along with a global item graph for graph-based recommendation
models. We argue that recommendation on global and local graphs outperforms
that on a single global graph or multiple local graphs. Specifically, we
propose a novel graph-based recommendation model named GLIMG (Global and Local
IteM Graphs), which simultaneously captures both the global and local user
tastes. By integrating the global and local graphs into an adapted
semi-supervised learning model, users&#x27; preferences on items are propagated
globally and locally. Extensive experimental results on real-world datasets
show that our proposed method consistently outperforms the state-of-the art
counterparts on the top-N recommendation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction. (arXiv:2101.11427v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1">Xiang-Rong Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liqin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guorui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xinyao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Binding Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1">Qiang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Siran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jingshan Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1">Hongbo Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11427">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional industrial recommenders are usually trained on a single business
domain and then serve for this domain. However, in large commercial platforms,
it is often the case that the recommenders need to make click-through rate
(CTR) predictions for multiple business domains. Different domains have
overlapping user groups and items. Thus, there exist commonalities. Since the
specific user groups have disparity and the user behaviors may change in
various business domains, there also have distinctions. The distinctions result
in domain-specific data distributions, making it hard for a single shared model
to work well on all domains. To learn an effective and efficient CTR model to
handle multiple domains simultaneously, we present Star Topology Adaptive
Recommender (STAR). Concretely, STAR has the star topology, which consists of
the shared centered parameters and domain-specific parameters. The shared
parameters are applied to learn commonalities of all domains, and the
domain-specific parameters capture domain distinction for more refined
prediction. Given requests from different business domains, STAR can adapt its
parameters conditioned on the domain characteristics. The experimental result
from production data validates the superiority of the proposed STAR model.
Since 2020, STAR has been deployed in the display advertising system of
Alibaba, obtaining averaging 8.0% improvement on CTR and 6.0% on RPM (Revenue
Per Mille).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimation of Fair Ranking Metrics with Incomplete Judgments. (arXiv:2108.05152v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirnap_O/0/1/0/all/0/1">&#xd6;mer K&#x131;rnap</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1">Fernando Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1">Asia Biega</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekstrand_M/0/1/0/all/0/1">Michael Ekstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Carterette_B/0/1/0/all/0/1">Ben Carterette</a>, <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1">Emine Y&#x131;lmaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05152">
                                    <div class="article-summary-box-inner">
                                        <span>There is increasing attention to evaluating the fairness of search system
ranking decisions. These metrics often consider the membership of items to
particular groups, often identified using protected attributes such as gender
or ethnicity. To date, these metrics typically assume the availability and
completeness of protected attribute labels of items. However, the protected
attributes of individuals are rarely present, limiting the application of fair
ranking metrics in large scale systems. In order to address this problem, we
propose a sampling strategy and estimation technique for four fair ranking
metrics. We formulate a robust and unbiased estimator which can operate even
with very limited number of labeled items. We evaluate our approach using both
simulated and real world data. Our experimental results demonstrate that our
method can estimate this family of fair ranking metrics and provides a robust,
reliable alternative to exhaustive or random data annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ULTRA: An Unbiased Learning To Rank Algorithm Toolbox. (arXiv:2108.05073v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05073">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to rank systems has become an important aspect of our daily life.
However, the implicit user feedback that is used to train many learning to rank
models is usually noisy and suffered from user bias (i.e., position bias).
Thus, obtaining an unbiased model using biased feedback has become an important
research field for IR. Existing studies on unbiased learning to rank (ULTR) can
be generalized into two families-algorithms that attain unbiasedness with
logged data, offline learning, and algorithms that achieve unbiasedness by
estimating unbiased parameters with real-time user interactions, namely online
learning. While there exist many algorithms from both families, there lacks a
unified way to compare and benchmark them. As a result, it can be challenging
for researchers to choose the right technique for their problems or for people
who are new to the field to learn and understand existing algorithms. To solve
this problem, we introduced ULTRA, which is a flexible, extensible, and easily
configure ULTR toolbox. Its key features include support for multiple ULTR
algorithms with configurable hyperparameters, a variety of built-in click
models that can be used separately to simulate clicks, different ranking model
architecture and evaluation metrics, and simple learning to rank pipeline
creation. In this paper, we discuss the general framework of ULTR, briefly
describe the algorithms in ULTRA, detailed the structure, and pipeline of the
toolbox. We experimented on all the algorithms supported by ultra and showed
that the toolbox performance is reasonable. Our toolbox is an important
resource for researchers to conduct experiments on ULTR algorithms with
different configurations as well as testing their own algorithms with the
supported features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retrieval &amp; Interaction Machine for Tabular Data Prediction. (arXiv:2108.05252v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jiarui Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1">Rong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhirong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Ruiming Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05252">
                                    <div class="article-summary-box-inner">
                                        <span>Prediction over tabular data is an essential task in many data science
applications such as recommender systems, online advertising, medical
treatment, etc. Tabular data is structured into rows and columns, with each row
as a data sample and each column as a feature attribute. Both the columns and
rows of the tabular data carry useful patterns that could improve the model
prediction performance. However, most existing models focus on the cross-column
patterns yet overlook the cross-row patterns as they deal with single samples
independently. In this work, we propose a general learning framework named
Retrieval &amp; Interaction Machine (RIM) that fully exploits both cross-row and
cross-column patterns among tabular data. Specifically, RIM first leverages
search engine techniques to efficiently retrieve useful rows of the table to
assist the label prediction of the target row, then uses feature interaction
networks to capture the cross-column patterns among the target row and the
retrieved rows so as to make the final label prediction. We conduct extensive
experiments on 11 datasets of three important tasks, i.e., CTR prediction
(classification), top-n recommendation (ranking) and rating prediction
(regression). Experimental results show that RIM achieves significant
improvements over the state-of-the-art and various baselines, demonstrating the
superiority and efficacy of RIM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of the TREC 2020 Fair Ranking Track. (arXiv:2108.05135v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1">Asia J. Biega</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1">Fernando Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekstrand_M/0/1/0/all/0/1">Michael D. Ekstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_S/0/1/0/all/0/1">Sergey Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohlmeier_S/0/1/0/all/0/1">Sebastian Kohlmeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05135">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides an overview of the NIST TREC 2020 Fair Ranking track. For
2020, we again adopted an academic search task, where we have a corpus of
academic article abstracts and queries submitted to a production academic
search engine. The central goal of the Fair Ranking track is to provide fair
exposure to different groups of authors (a group fairness framing). We
recognize that there may be multiple group definitions (e.g. based on
demographics, stature, topic) and hoped for the systems to be robust to these.
We expected participants to develop systems that optimize for fairness and
relevance for arbitrary group definitions, and did not reveal the exact group
definitions until after the evaluation runs were submitted.The track contains
two tasks,reranking and retrieval, with a shared evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are Neural Ranking Models Robust?. (arXiv:2108.05018v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yixing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05018">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, we have witnessed the bloom of neural ranking models in the
information retrieval (IR) field. So far, much effort has been devoted to
developing effective neural ranking models that can generalize well on new
data. There has been less attention paid to the robustness perspective. Unlike
the effectiveness which is about the average performance of a system under
normal purpose, robustness cares more about the system performance in the worst
case or under malicious operations instead. When a new technique enters into
the real-world application, it is critical to know not only how it works in
average, but also how would it behave in abnormal situations. So we raise the
question in this work: Are neural ranking models robust? To answer this
question, firstly, we need to clarify what we refer to when we talk about the
robustness of ranking models in IR. We show that robustness is actually a
multi-dimensional concept and there are three ways to define it in IR: 1) The
performance variance under the independent and identically distributed (I.I.D.)
setting; 2) The out-of-distribution (OOD) generalizability; and 3) The
defensive ability against adversarial operations. The latter two definitions
can be further specified into two different perspectives respectively, leading
to 5 robustness tasks in total. Based on this taxonomy, we build corresponding
benchmark datasets, design empirical experiments, and systematically analyze
the robustness of several representative neural ranking models against
traditional probabilistic ranking models and learning-to-rank (LTR) models. The
empirical results show that there is no simple answer to our question. While
neural ranking models are less robust against other IR models in most cases,
some of them can still win 1 out of 5 tasks. This is the first comprehensive
study on the robustness of neural ranking models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedMatch: Federated Learning Over Heterogeneous Question Answering Data. (arXiv:2108.05069v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiangui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yixing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05069">
                                    <div class="article-summary-box-inner">
                                        <span>Question Answering (QA), a popular and promising technique for intelligent
information access, faces a dilemma about data as most other AI techniques. On
one hand, modern QA methods rely on deep learning models which are typically
data-hungry. Therefore, it is expected to collect and fuse all the available QA
datasets together in a common site for developing a powerful QA model. On the
other hand, real-world QA datasets are typically distributed in the form of
isolated islands belonging to different parties. Due to the increasing
awareness of privacy security, it is almost impossible to integrate the data
scattered around, or the cost is prohibited. A possible solution to this
dilemma is a new approach known as federated learning, which is a
privacy-preserving machine learning technique over distributed datasets. In
this work, we propose to adopt federated learning for QA with the special
concern on the statistical heterogeneity of the QA data. Here the heterogeneity
refers to the fact that annotated QA data are typically with non-identical and
independent distribution (non-IID) and unbalanced sizes in practice.
Traditional federated learning methods may sacrifice the accuracy of individual
models under the heterogeneous situation. To tackle this problem, we propose a
novel Federated Matching framework for QA, named FedMatch, with a
backbone-patch architecture. The shared backbone is to distill the common
knowledge of all the participants while the private patch is a compact and
efficient module to retain the domain information for each participant. To
facilitate the evaluation, we build a benchmark collection based on several QA
datasets from different domains to simulate the heterogeneous situation in
practice. Empirical studies demonstrate that our model can achieve significant
improvements against the baselines over all the datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Pairwise Learning To Rank For Search Autocomplete. (arXiv:2108.04976v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1">Kai Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_D/0/1/0/all/0/1">Da Kuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04976">
                                    <div class="article-summary-box-inner">
                                        <span>Autocomplete (a.k.a &quot;Query Auto-Completion&quot;, &quot;AC&quot;) suggests full queries
based on a prefix typed by customer. Autocomplete has been a core feature of
commercial search engine. In this paper, we propose a novel context-aware
neural network based pairwise ranker (DeepPLTR) to improve AC ranking, DeepPLTR
leverages contextual and behavioral features to rank queries by minimizing a
pairwise loss, based on a fully-connected neural network structure. Compared to
LambdaMART ranker, DeepPLTR shows +3.90% MeanReciprocalRank (MRR) lift in
offline evaluation, and yielded +0.06% (p &lt; 0.1) Gross Merchandise Value (GMV)
lift in an Amazon&#x27;s online A/B experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple steps are all you need: Frank-Wolfe and generalized self-concordant functions. (arXiv:2105.13913v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Carderera_A/0/1/0/all/0/1">Alejandro Carderera</a>, <a href="http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1">Mathieu Besan&#xe7;on</a>, <a href="http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1">Sebastian Pokutta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13913">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized self-concordance is a key property present in the objective
function of many important learning problems. We establish the convergence rate
of a simple Frank-Wolfe variant that uses the open-loop step size strategy
$\gamma_t &#x3D; 2/(t+2)$, obtaining a $\mathcal{O}(1/t)$ convergence rate for this
class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the
iteration count. This avoids the use of second-order information or the need to
estimate local smoothness parameters of previous work. We also show improved
convergence rates for various common cases, e.g., when the feasible region
under consideration is uniformly convex or polyhedral.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Queueing-Theoretic Framework for Vehicle Dispatching in Dynamic Car-Hailing [technical report]. (arXiv:2107.08662v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Peng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiabao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuemin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Libin Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08662">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of smart mobile devices, the car-hailing platforms
(e.g., Uber or Lyft) have attracted much attention from both the academia and
the industry. In this paper, we consider an important dynamic car-hailing
problem, namely \textit{maximum revenue vehicle dispatching} (MRVD), in which
rider requests dynamically arrive and drivers need to serve as many riders as
possible such that the entire revenue of the platform is maximized. We prove
that the MRVD problem is NP-hard and intractable. In addition, the dynamic
car-hailing platforms have no information of the future riders, which makes the
problem even harder. To handle the MRVD problem, we propose a queueing-based
vehicle dispatching framework, which first uses existing machine learning
algorithms to predict the future vehicle demand of each region, then estimates
the idle time periods of drivers through a queueing model for each region. With
the information of the predicted vehicle demands and estimated idle time
periods of drivers, we propose two batch-based vehicle dispatching algorithms
to efficiently assign suitable drivers to riders such that the expected overall
revenue of the platform is maximized during each batch processing. Through
extensive experiments, we demonstrate the efficiency and effectiveness of our
proposed approaches over both real and synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AA3DNet: Attention Augmented Real Time 3D Object Detection. (arXiv:2107.12137v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12137">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
&gt; 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Frequency Domain Constraint for Synthetic and Real X-ray Image Super Resolution. (arXiv:2105.06887v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_Q/0/1/0/all/0/1">Qing Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Koh_J/0/1/0/all/0/1">Jae Chul Koh</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_W/0/1/0/all/0/1">WonSook Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06887">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic X-ray images are simulated X-ray images projected from CT data.
High-quality synthetic X-ray images can facilitate various applications such as
surgical image guidance systems and VR training simulations. However, it is
difficult to produce high-quality arbitrary view synthetic X-ray images in
real-time due to different CT slice thickness, high computational cost, and the
complexity of algorithms. Our goal is to generate high-resolution synthetic
X-ray images in real-time by upsampling low-resolution images with deep
learning-based super-resolution methods. Reference-based Super Resolution
(RefSR) has been well studied in recent years and has shown higher performance
than traditional Single Image Super-Resolution (SISR). It can produce fine
details by utilizing the reference image but still inevitably generates some
artifacts and noise. In this paper, we introduce frequency domain loss as a
constraint to further improve the quality of the RefSR results with fine
details and without obvious artifacts. To the best of our knowledge, this is
the first paper utilizing the frequency domain for the loss functions in the
field of super-resolution. We achieved good results in evaluating our method on
both synthetic and real X-ray image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Federated Learning with Clustering: Non-IID Heart Rate Variability Data Application. (arXiv:2108.01903v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1">Joo Hun Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1">Ha Min Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hyejun Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_E/0/1/0/all/0/1">Eun-Hye Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_A/0/1/0/all/0/1">Ah Young Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Han Young Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1">Hong Jin Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1">Tai-Myoung Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01903">
                                    <div class="article-summary-box-inner">
                                        <span>While machine learning techniques are being applied to various fields for
their exceptional ability to find complex relations in large datasets, the
strengthening of regulations on data ownership and privacy is causing
increasing difficulty in its application to medical data. In light of this,
Federated Learning has recently been proposed as a solution to train on private
data without breach of confidentiality. This conservation of privacy is
particularly appealing in the field of healthcare, where patient data is highly
confidential. However, many studies have shown that its assumption of
Independent and Identically Distributed data is unrealistic for medical data.
In this paper, we propose Personalized Federated Cluster Models, a hierarchical
clustering-based FL process, to predict Major Depressive Disorder severity from
Heart Rate Variability. By allowing clients to receive more personalized model,
we address problems caused by non-IID data, showing an accuracy increase in
severity prediction. This increase in performance may be sufficient to use
Personalized Federated Cluster Models in many existing Federated Learning
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedding Principle of Loss Landscape of Deep Neural Networks. (arXiv:2105.14573v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yaoyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhongwang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhi-Qin John Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14573">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the structure of loss landscape of deep neural networks
(DNNs)is obviously important. In this work, we prove an embedding principle
that the loss landscape of a DNN &quot;contains&quot; all the critical points of all the
narrower DNNs. More precisely, we propose a critical embedding such that any
critical point, e.g., local or global minima, of a narrower DNN can be embedded
to a critical point/hyperplane of the target DNN with higher degeneracy and
preserving the DNN output function. The embedding structure of critical points
is independent of loss function and training data, showing a stark difference
from other nonconvex problems such as protein-folding. Empirically, we find
that a wide DNN is often attracted by highly-degenerate critical points that
are embedded from narrow DNNs. The embedding principle provides an explanation
for the general easy optimization of wide DNNs and unravels a potential
implicit low-complexity regularization during the training. Overall, our work
provides a skeleton for the study of loss landscape of DNNs and its
implication, by which a more exact and comprehensive understanding can be
anticipated in the near</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Abstract Reasoning via Logic-guided Generation. (arXiv:2107.10493v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Sihyun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1">Sangwoo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungsoo Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10493">
                                    <div class="article-summary-box-inner">
                                        <span>Abstract reasoning, i.e., inferring complicated patterns from given
observations, is a central building block of artificial general intelligence.
While humans find the answer by either eliminating wrong candidates or first
constructing the answer, prior deep neural network (DNN)-based methods focus on
the former discriminative approach. This paper aims to design a framework for
the latter approach and bridge the gap between artificial and human
intelligence. To this end, we propose logic-guided generation (LoGe), a novel
generative DNN framework that reduces abstract reasoning as an optimization
problem in propositional logic. LoGe is composed of three steps: extract
propositional variables from images, reason the answer variables with a logic
layer, and reconstruct the answer image from the variables. We demonstrate that
LoGe outperforms the black box DNN frameworks for generative abstract reasoning
under the RAVEN benchmark, i.e., reconstructing answers based on capturing
correct rules of various attributes from observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector. (arXiv:2104.08044v7 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peilun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1">Fan Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hui Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08044">
                                    <div class="article-summary-box-inner">
                                        <span>Email threat is a serious issue for enterprise security, which consists of
various malicious scenarios, such as phishing, fraud, blackmail and
malvertisement. Traditional anti-spam gateway commonly requires to maintain a
greylist to filter out unexpected emails based on suspicious vocabularies
existed in the mail subject and content. However, the signature-based approach
cannot effectively discover novel and unknown suspicious emails that utilize
various hot topics at present, such as COVID-19 and US election. To address the
problem, in this paper, we present Holmes, an efficient and lightweight
semantic based engine for anomalous email detection. Holmes can convert each
event log of email to a sentence through word embedding then extract
interesting items among them by novelty detection. Based on our observations,
we claim that, in an enterprise environment, there is a stable relation between
senders and receivers, but suspicious emails are commonly from unusual sources,
which can be detected through the rareness selection. We evaluate the
performance of Holmes in a real-world enterprise environment, in which it sends
and receives around 5,000 emails each day. As a result, Holmes can achieve a
high detection rate (output around 200 suspicious emails per day) and maintain
a low false alarm rate for anomaly detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invariant Policy Learning: A Causal Perspective. (arXiv:2106.00808v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saengkyongam_S/0/1/0/all/0/1">Sorawit Saengkyongam</a>, <a href="http://arxiv.org/find/cs/1/au:+Thams_N/0/1/0/all/0/1">Nikolaj Thams</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jonas Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_N/0/1/0/all/0/1">Niklas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00808">
                                    <div class="article-summary-box-inner">
                                        <span>In the past decade, contextual bandit and reinforcement learning algorithms
have been successfully used in various interactive learning systems such as
online advertising, recommender systems, and dynamic pricing. However, they
have yet to be widely adopted in high-stakes application domains, such as
healthcare. One reason may be that existing approaches assume that the
underlying mechanisms are static in the sense that they do not change over
different environments. In many real world systems, however, the mechanisms are
subject to shifts across environments which may invalidate the static
environment assumption. In this paper, we tackle the problem of environmental
shifts under the framework of offline contextual bandits. We view the
environmental shift problem through the lens of causality and propose
multi-environment contextual bandits that allow for changes in the underlying
mechanisms. We adopt the concept of invariance from the causality literature
and introduce the notion of policy invariance. We argue that policy invariance
is only relevant if unobserved confounders are present and show that, in that
case, an optimal invariant policy is guaranteed to generalize across
environments under suitable assumptions. Our results may be a first step
towards solving the environmental shift problem. They also establish concrete
connections among causality, invariance and contextual bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Domain-Oblivious Approach for Learning Concise Representations of Filtered Topological Spaces for Clustering. (arXiv:2105.12208v2 [cs.CG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yu Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fasy_B/0/1/0/all/0/1">Brittany Terese Fasy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenk_C/0/1/0/all/0/1">Carola Wenk</a>, <a href="http://arxiv.org/find/cs/1/au:+Summa_B/0/1/0/all/0/1">Brian Summa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12208">
                                    <div class="article-summary-box-inner">
                                        <span>Persistence diagrams have been widely used to quantify the underlying
features of filtered topological spaces in data visualization. In many
applications, computing distances between diagrams is essential; however,
computing these distances has been challenging due to the computational cost.
In this paper, we propose a persistence diagram hashing framework that learns a
binary code representation of persistence diagrams, which allows for fast
computation of distances. This framework is built upon a generative adversarial
network (GAN) with a diagram distance loss function to steer the learning
process. Instead of using standard representations, we hash diagrams into
binary codes, which have natural advantages in large-scale tasks. The training
of this model is domain-oblivious in that it can be computed purely from
synthetic, randomly created diagrams. As a consequence, our proposed method is
directly applicable to various datasets without the need for retraining the
model. These binary codes, when compared using fast Hamming distance, better
maintain topological similarity properties between datasets than other
vectorized representations. To evaluate this method, we apply our framework to
the problem of diagram clustering and we compare the quality and performance of
our approach to the state-of-the-art. In addition, we show the scalability of
our approach on a dataset with 10k persistence diagrams, which is not possible
with current techniques. Moreover, our experimental results demonstrate that
our method is significantly faster with the potential of less memory usage,
while retaining comparable or better quality comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coordinate-wise Control Variates for Deep Policy Gradients. (arXiv:2107.04987v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yuanyi Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jian Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04987">
                                    <div class="article-summary-box-inner">
                                        <span>The control variates (CV) method is widely used in policy gradient estimation
to reduce the variance of the gradient estimators in practice. A control
variate is applied by subtracting a baseline function from the state-action
value estimates. Then the variance-reduced policy gradient presumably leads to
higher learning efficiency. Recent research on control variates with deep
neural net policies mainly focuses on scalar-valued baseline functions. The
effect of vector-valued baselines is under-explored. This paper investigates
variance reduction with coordinate-wise and layer-wise control variates
constructed from vector-valued baselines for neural net policies. We present
experimental evidence suggesting that lower variance can be obtained with such
baselines than with the conventional scalar-valued baseline. We demonstrate how
to equip the popular Proximal Policy Optimization (PPO) algorithm with these
new control variates. We show that the resulting algorithm with proper
regularization can achieve higher sample efficiency than scalar control
variates in continuous control benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Spectral Failure Mode for Graph Convolutional Networks. (arXiv:2010.13152v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1">Carey E. Priebe</a>, <a href="http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1">Cencheng Shen</a>, <a href="http://arxiv.org/find/stat/1/au:+Huang_N/0/1/0/all/0/1">Ningyuan Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1">Tianyi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13152">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved remarkable successes in machine learning tasks.
This has recently been extended to graph learning using neural networks.
However, there is limited theoretical work in understanding how and when they
perform well, especially relative to established statistical learning
techniques such as spectral embedding. In this short paper, we present a simple
generative model where unsupervised graph convolutional network fails, while
the adjacency spectral embedding succeeds. Specifically, unsupervised graph
convolutional network is unable to look beyond the first eigenvector in certain
approximately regular graphs, thus missing inference signals in non-leading
eigenvectors. The phenomenon is demonstrated by visual illustrations and
comprehensive simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid Exploration for Open-World Navigation with Latent Goal Models. (arXiv:2104.05859v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1">Dhruv Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1">Benjamin Eysenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhinehart_N/0/1/0/all/0/1">Nicholas Rhinehart</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05859">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a robotic learning system for autonomous exploration and
navigation in diverse, open-world environments. At the core of our method is a
learned latent variable model of distances and actions, along with a
non-parametric topological memory. We use an information bottleneck to
regularize the learned policy, giving us (i) a compact visual representation of
goals, (ii) improved generalization capabilities, and (iii) a mechanism for
sampling feasible goals for exploration. Trained on a large offline dataset of
prior experience, the model acquires a representation of visual goals that is
robust to task-irrelevant distractors. We demonstrate our method on a mobile
ground robot in open-world exploration scenarios. Given an image of a goal that
is up to 80 meters away, our method leverages its representation to explore and
discover the goal in under 20 minutes, even amidst previously-unseen obstacles
and weather conditions. We encourage the reader to visit the project website
for videos of our experiments and demonstrations
https://sites.google.com/view/recon-robot</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIMG: Global and Local Item Graphs for Top-N Recommender Systems. (arXiv:2007.14018v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhuoyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_R/0/1/0/all/0/1">Rui Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee-Keong Kwoh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14018">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based recommendation models work well for top-N recommender systems due
to their capability to capture the potential relationships between entities.
However, most of the existing methods only construct a single global item graph
shared by all the users and regrettably ignore the diverse tastes between
different user groups. Inspired by the success of local models for
recommendation, this paper provides the first attempt to investigate multiple
local item graphs along with a global item graph for graph-based recommendation
models. We argue that recommendation on global and local graphs outperforms
that on a single global graph or multiple local graphs. Specifically, we
propose a novel graph-based recommendation model named GLIMG (Global and Local
IteM Graphs), which simultaneously captures both the global and local user
tastes. By integrating the global and local graphs into an adapted
semi-supervised learning model, users&#x27; preferences on items are propagated
globally and locally. Extensive experimental results on real-world datasets
show that our proposed method consistently outperforms the state-of-the art
counterparts on the top-N recommendation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Rearrange Voxels in Binary Segmentation Masks for Smooth Manifold Triangulation. (arXiv:2108.05269v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianning Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pepe_A/0/1/0/all/0/1">Antonio Pepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1">Christina Gsaxner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1">Jan Egger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05269">
                                    <div class="article-summary-box-inner">
                                        <span>Medical images, especially volumetric images, are of high resolution and
often exceed the capacity of standard desktop GPUs. As a result, most deep
learning-based medical image analysis tasks require the input images to be
downsampled, often substantially, before these can be fed to a neural network.
However, downsampling can lead to a loss of image quality, which is undesirable
especially in reconstruction tasks, where the fine geometric details need to be
preserved. In this paper, we propose that high-resolution images can be
reconstructed in a coarse-to-fine fashion, where a deep learning algorithm is
only responsible for generating a coarse representation of the image, which
consumes moderate GPU memory. For producing the high-resolution outcome, we
propose two novel methods: learned voxel rearrangement of the coarse output and
hierarchical image synthesis. Compared to the coarse output, the
high-resolution counterpart allows for smooth surface triangulation, which can
be 3D-printed in the highest possible quality. Experiments of this paper are
carried out on the dataset of AutoImplant 2021
(https://autoimplant2021.grand-challenge.org/), a MICCAI challenge on cranial
implant design. The dataset contains high-resolution skulls that can be viewed
as 2D manifolds embedded in a 3D space. Codes associated with this study can be
accessed at https://github.com/Jianningli/voxel_rearrangement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Constraints Learning for Spiking Neurons. (arXiv:2103.12564v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huy Le Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_D/0/1/0/all/0/1">Dominique Chu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12564">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new supervised learning algorithm based to train spiking
neural networks for classification. The algorithm overcomes a limitation of
existing multi-spike learning methods: it solves the problem of interference
between interacting output spikes during a learning trial. This problem of
learning interference causes learning performance in existing approaches to
decrease as the number of output spikes increases, and represents an important
limitation in existing multi-spike learning approaches. We address learning
interference by introducing a novel mechanism to balance the magnitudes of
weight adjustments during learning, which in theory allows every spike to
simultaneously converge to their desired timings. Our results indicate that our
method achieves significantly higher memory capacity and faster convergence
compared to existing approaches for multi-spike classification. In the
ubiquitous Iris and MNIST datasets, our algorithm achieves competitive
predictive performance with state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dimension reduction in recurrent networks by canonicalization. (arXiv:2007.12141v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Grigoryeva_L/0/1/0/all/0/1">Lyudmila Grigoryeva</a>, <a href="http://arxiv.org/find/math/1/au:+Ortega_J/0/1/0/all/0/1">Juan-Pablo Ortega</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12141">
                                    <div class="article-summary-box-inner">
                                        <span>Many recurrent neural network machine learning paradigms can be formulated
using state-space representations. The classical notion of canonical
state-space realization is adapted in this paper to accommodate semi-infinite
inputs so that it can be used as a dimension reduction tool in the recurrent
networks setup. The so-called input forgetting property is identified as the
key hypothesis that guarantees the existence and uniqueness (up to system
isomorphisms) of canonical realizations for causal and time-invariant
input/output systems with semi-infinite inputs. Additionally, the notion of
optimal reduction coming from the theory of symmetric Hamiltonian systems is
implemented in our setup to construct canonical realizations out of input
forgetting but not necessarily canonical ones. These two procedures are studied
in detail in the framework of linear fading memory input/output systems.
Finally, the notion of implicit reduction using reproducing kernel Hilbert
spaces (RKHS) is introduced which allows, for systems with linear readouts, to
achieve dimension reduction without the need to actually compute the reduced
spaces introduced in the first part of the paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Natural Language-guided Programming. (arXiv:2108.05198v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heyman_G/0/1/0/all/0/1">Geert Heyman</a>, <a href="http://arxiv.org/find/cs/1/au:+Huysegems_R/0/1/0/all/0/1">Rafael Huysegems</a>, <a href="http://arxiv.org/find/cs/1/au:+Justen_P/0/1/0/all/0/1">Pascal Justen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cutsem_T/0/1/0/all/0/1">Tom Van Cutsem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05198">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s software world with its cornucopia of reusable software libraries,
when a programmer is faced with a programming task that they suspect can be
completed through the use of a library, they often look for code examples using
a search engine and then manually adapt found examples to their specific
context of use. We put forward a vision based on a new breed of developer tools
that have the potential to largely automate this process. The key idea is to
adapt code autocompletion tools such that they take into account not only the
developer&#x27;s already-written code but also the intent of the task the developer
is trying to achieve next, formulated in plain natural language. We call this
practice of enriching the code with natural language intent to facilitate its
completion natural language-guided programming.

To show that this idea is feasible we design, implement and benchmark a tool
that solves this problem in the context of a specific domain (data science) and
a specific programming language (Python). Central to the tool is the use of
language models trained on a large corpus of documented code. Our initial
experiments confirm the feasibility of the idea but also make it clear that we
have only scratched the surface of what may become possible in the future. We
end the paper with a comprehensive research agenda to stimulate additional
research in the budding area of natural language-guided programming.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Forgotten Role of Search Queries in IR-based Bug Localization: An Empirical Study. (arXiv:2108.05341v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mohammad Masudur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeasmin_S/0/1/0/all/0/1">Shamima Yeasmin</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_C/0/1/0/all/0/1">Chanchal K. Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05341">
                                    <div class="article-summary-box-inner">
                                        <span>Being light-weight and cost-effective, IR-based approaches for bug
localization have shown promise in finding software bugs. However, the accuracy
of these approaches heavily depends on their used bug reports. A significant
number of bug reports contain only plain natural language texts. According to
existing studies, IR-based approaches cannot perform well when they use these
bug reports as search queries. On the other hand, there is a piece of recent
evidence that suggests that even these natural language-only reports contain
enough good keywords that could help localize the bugs successfully. On one
hand, these findings suggest that natural language-only bug reports might be a
sufficient source for good query keywords. On the other hand, they cast serious
doubt on the query selection practices in the IR-based bug localization. In
this article, we attempted to clear the sky on this aspect by conducting an
in-depth empirical study that critically examines the state-of-the-art query
selection practices in IR-based bug localization. In particular, we use a
dataset of 2,320 bug reports, employ ten existing approaches from the
literature, exploit the Genetic Algorithm-based approach to construct optimal,
near-optimal search queries from these bug reports, and then answer three
research questions. We confirmed that the state-of-the-art query construction
approaches are indeed not sufficient for constructing appropriate queries (for
bug localization) from certain natural language-only bug reports although they
contain such queries. We also demonstrate that optimal queries and non-optimal
queries chosen from bug report texts are significantly different in terms of
several keyword characteristics, which has led us to actionable insights.
Furthermore, we demonstrate 27%--34% improvement in the performance of
non-optimal queries through the application of our actionable insights to them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Data Leakage in Machine-Learning Models with Fisher Information. (arXiv:2102.11673v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hannun_A/0/1/0/all/0/1">Awni Hannun</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Maaten_L/0/1/0/all/0/1">Laurens van der Maaten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11673">
                                    <div class="article-summary-box-inner">
                                        <span>Machine-learning models contain information about the data they were trained
on. This information leaks either through the model itself or through
predictions made by the model. Consequently, when the training data contains
sensitive attributes, assessing the amount of information leakage is paramount.
We propose a method to quantify this leakage using the Fisher information of
the model about the data. Unlike the worst-case a priori guarantees of
differential privacy, Fisher information loss measures leakage with respect to
specific examples, attributes, or sub-populations within the dataset. We
motivate Fisher information loss through the Cram\&#x27;{e}r-Rao bound and delineate
the implied threat model. We provide efficient methods to compute Fisher
information loss for output-perturbed generalized linear models. Finally, we
empirically validate Fisher information loss as a useful measure of information
leakage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-Scale Modeling of Mobile User Click Behaviors Using Deep Learning. (arXiv:2108.05342v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05342">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling tap or click sequences of users on a mobile device can improve our
understandings of interaction behavior and offers opportunities for UI
optimization by recommending next element the user might want to click on. We
analyzed a large-scale dataset of over 20 million clicks from more than 4,000
mobile users who opted in. We then designed a deep learning model that predicts
the next element that the user clicks given the user&#x27;s click history, the
structural information of the UI screen, and the current context such as the
time of the day. We thoroughly investigated the deep model by comparing it with
a set of baseline methods based on the dataset. The experiments show that our
model achieves 48% and 71% accuracy (top-1 and top-3) for predicting next
clicks based on a held-out dataset of test users, which significantly
outperformed all the baseline methods with a large margin. We discussed a few
scenarios for integrating the model in mobile interaction and how users can
potentially benefit from the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling the False Split Rate in Tree-Based Aggregation. (arXiv:2108.05350v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Shao_S/0/1/0/all/0/1">Simeng Shao</a>, <a href="http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1">Jacob Bien</a>, <a href="http://arxiv.org/find/stat/1/au:+Javanmard_A/0/1/0/all/0/1">Adel Javanmard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05350">
                                    <div class="article-summary-box-inner">
                                        <span>In many domains, data measurements can naturally be associated with the
leaves of a tree, expressing the relationships among these measurements. For
example, companies belong to industries, which in turn belong to ever coarser
divisions such as sectors; microbes are commonly arranged in a taxonomic
hierarchy from species to kingdoms; street blocks belong to neighborhoods,
which in turn belong to larger-scale regions. The problem of tree-based
aggregation that we consider in this paper asks which of these tree-defined
subgroups of leaves should really be treated as a single entity and which of
these entities should be distinguished from each other.

We introduce the &quot;false split rate&quot;, an error measure that describes the
degree to which subgroups have been split when they should not have been. We
then propose a multiple hypothesis testing algorithm for tree-based
aggregation, which we prove controls this error measure. We focus on two main
examples of tree-based aggregation, one which involves aggregating means and
the other which involves aggregating regression coefficients. We apply this
methodology to aggregate stocks based on their volatility and to aggregate
neighborhoods of New York City based on taxi fares.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence bounds for nonlinear least squares and applications to tensor recovery. (arXiv:2108.05237v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Trunschke_P/0/1/0/all/0/1">Philipp Trunschke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05237">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of approximating a function in general nonlinear
subsets of $L^2$ when only a weighted Monte Carlo estimate of the $L^2$-norm
can be computed. Of particular interest in this setting is the concept of
sample complexity, the number of samples that are necessary to recover the best
approximation. Bounds for this quantity have been derived in a previous work
and depend primarily on the model class and are not influenced positively by
the regularity of the sought function. This result however is only a worst-case
bound and is not able to explain the remarkable performance of iterative hard
thresholding algorithms that is observed in practice. We reexamine the results
of the previous paper and derive a new bound that is able to utilize the
regularity of the sought function. A critical analysis of our results allows us
to derive a sample efficient algorithm for the model set of low-rank tensors.
The viability of this algorithm is demonstrated by recovering quantities of
interest for a classical high-dimensional random partial differential equation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Classification of Lake Zooplankton. (arXiv:2108.05258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kyathanahally_S/0/1/0/all/0/1">S. P. Kyathanahally</a>, <a href="http://arxiv.org/find/cs/1/au:+Hardeman_T/0/1/0/all/0/1">T. Hardeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Merz_E/0/1/0/all/0/1">E. Merz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozakiewicz_T/0/1/0/all/0/1">T. Kozakiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Reyes_M/0/1/0/all/0/1">M. Reyes</a>, <a href="http://arxiv.org/find/cs/1/au:+Isles_P/0/1/0/all/0/1">P. Isles</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomati_F/0/1/0/all/0/1">F. Pomati</a>, <a href="http://arxiv.org/find/cs/1/au:+Baity_Jesi_M/0/1/0/all/0/1">M. Baity-Jesi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05258">
                                    <div class="article-summary-box-inner">
                                        <span>Plankton are effective indicators of environmental change and ecosystem
health in freshwater habitats, but collection of plankton data using manual
microscopic methods is extremely labor-intensive and expensive. Automated
plankton imaging offers a promising way forward to monitor plankton communities
with high frequency and accuracy in real-time. Yet, manual annotation of
millions of images proposes a serious challenge to taxonomists. Deep learning
classifiers have been successfully applied in various fields and provided
encouraging results when used to categorize marine plankton images. Here, we
present a set of deep learning models developed for the identification of lake
plankton, and study several strategies to obtain optimal performances,which
lead to operational prescriptions for users. To this aim, we annotated into 35
classes over 17900 images of zooplankton and large phytoplankton colonies,
detected in Lake Greifensee (Switzerland) with the Dual Scripps Plankton
Camera. Our best models were based on transfer learning and ensembling, which
classified plankton images with 98% accuracy and 93% F1 score. When tested on
freely available plankton datasets produced by other automated imaging tools
(ZooScan, FlowCytobot and ISIIS), our models performed better than previously
used models. Our annotated data, code and classification models are freely
available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GRF: Learning a General Radiance Field for 3D Representation and Rendering. (arXiv:2010.04595v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trevithick_A/0/1/0/all/0/1">Alex Trevithick</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04595">
                                    <div class="article-summary-box-inner">
                                        <span>We present a simple yet powerful neural network that implicitly represents
and renders 3D objects and scenes only from 2D observations. The network models
3D geometries as a general radiance field, which takes a set of 2D images with
camera poses and intrinsics as input, constructs an internal representation for
each point of the 3D space, and then renders the corresponding appearance and
geometry of that point viewed from an arbitrary position. The key to our
approach is to learn local features for each pixel in 2D images and to then
project these features to 3D points, thus yielding general and rich point
representations. We additionally integrate an attention mechanism to aggregate
pixel features from multiple 2D views, such that visual occlusions are
implicitly taken into account. Extensive experiments demonstrate that our
method can generate high-quality and realistic novel views for novel objects,
unseen categories and challenging real-world scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08382">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism of late has been quite popular in the computer vision
community. A lot of work has been done to improve the performance of the
network, although almost always it results in increased computational
complexity. In this paper, we propose a new attention module that not only
achieves the best performance but also has lesser parameters compared to most
existing models. Our attention module can easily be integrated with other
convolutional neural networks because of its lightweight nature. The proposed
network named Dual Multi Scale Attention Network (DMSANet) is comprised of two
parts: the first part is used to extract features at various scales and
aggregate them, the second part uses spatial and channel attention modules in
parallel to adaptively integrate local features with their global dependencies.
We benchmark our network performance for Image Classification on ImageNet
dataset, Object Detection and Instance Segmentation both on MS COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirical Risk Minimization for Time Series: Nonparametric Performance Bounds for Prediction. (arXiv:2108.05184v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Brownlees_C/0/1/0/all/0/1">Christian Brownlees</a>, <a href="http://arxiv.org/find/stat/1/au:+Llorens_Terrazas_J/0/1/0/all/0/1">Jordi Llorens-Terrazas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05184">
                                    <div class="article-summary-box-inner">
                                        <span>Empirical risk minimization is a standard principle for choosing algorithms
in learning theory. In this paper we study the properties of empirical risk
minimization for time series. The analysis is carried out in a general
framework that covers different types of forecasting applications encountered
in the literature. We are concerned with 1-step-ahead prediction of a
univariate time series generated by a parameter-driven process. A class of
recursive algorithms is available to forecast the time series. The algorithms
are recursive in the sense that the forecast produced in a given period is a
function of the lagged values of the forecast and of the time series. The
relationship between the generating mechanism of the time series and the class
of algorithms is unspecified. Our main result establishes that the algorithm
chosen by empirical risk minimization achieves asymptotically the optimal
predictive performance that is attainable within the class of algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks. (arXiv:2108.05233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yushun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ninghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalaian_B/0/1/0/all/0/1">Brian Jalaian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jundong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05233">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have recently demonstrated superior capability
of tackling graph analytical problems in various applications. Nevertheless,
with the wide-spreading practice of GNNs in high-stake decision-making
processes, there is an increasing societal concern that GNNs could make
discriminatory decisions that may be illegal towards certain demographic
groups. Although some explorations have been made towards developing fair GNNs,
existing approaches are tailored for a specific GNN model. However, in
practical scenarios, myriads of GNN variants have been proposed for different
tasks, and it is costly to train and fine-tune existing debiasing models for
different GNNs. Also, bias in a trained model could originate from training
data, while how to mitigate bias in the graph data is usually overlooked. In
this work, different from existing work, we first propose novel definitions and
metrics to measure the bias in an attributed network, which leads to the
optimization objective to mitigate bias. Based on the optimization objective,
we develop a framework named EDITS to mitigate the bias in attributed networks
while preserving useful information. EDITS works in a model-agnostic manner,
which means that it is independent of the specific GNNs applied for downstream
tasks. Extensive experiments on both synthetic and real-world datasets
demonstrate the validity of the proposed bias metrics and the superiority of
EDITS on both bias mitigation and utility maintenance. Open-source
implementation: https://github.com/yushundong/EDITS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are We Ready For Learned Cardinality Estimation?. (arXiv:2012.06743v4 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoying Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1">Changbo Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Weiyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qingqing Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06743">
                                    <div class="article-summary-box-inner">
                                        <span>Cardinality estimation is a fundamental but long unresolved problem in query
optimization. Recently, multiple papers from different research groups
consistently report that learned models have the potential to replace existing
cardinality estimators. In this paper, we ask a forward-thinking question: Are
we ready to deploy these learned cardinality models in production? Our study
consists of three main parts. Firstly, we focus on the static environment
(i.e., no data updates) and compare five new learned methods with eight
traditional methods on four real-world datasets under a unified workload
setting. The results show that learned models are indeed more accurate than
traditional methods, but they often suffer from high training and inference
costs. Secondly, we explore whether these learned models are ready for dynamic
environments (i.e., frequent data updates). We find that they cannot catch up
with fast data up-dates and return large errors for different reasons. For less
frequent updates, they can perform better but there is no clear winner among
themselves. Thirdly, we take a deeper look into learned models and explore when
they may go wrong. Our results show that the performance of learned methods can
be greatly affected by the changes in correlation, skewness, or domain size.
More importantly, their behaviors are much harder to interpret and often
unpredictable. Based on these findings, we identify two promising research
directions (control the cost of learned models and make learned models
trustworthy) and suggest a number of research opportunities. We hope that our
study can guide researchers and practitioners to work together to eventually
push learned cardinality estimators into real database systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch greedy maximization of non-submodular functions: Guarantees and applications to experimental design. (arXiv:2006.04554v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jagalur_Mohan_J/0/1/0/all/0/1">Jayanth Jagalur-Mohan</a>, <a href="http://arxiv.org/find/math/1/au:+Marzouk_Y/0/1/0/all/0/1">Youssef Marzouk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04554">
                                    <div class="article-summary-box-inner">
                                        <span>We propose and analyze batch greedy heuristics for cardinality constrained
maximization of non-submodular non-decreasing set functions. We consider the
standard greedy paradigm, along with its distributed greedy and stochastic
greedy variants. Our theoretical guarantees are characterized by the
combination of submodularity and supermodularity ratios. We argue how these
parameters define tight modular bounds based on incremental gains, and provide
a novel reinterpretation of the classical greedy algorithm using the
minorize-maximize (MM) principle. Based on that analogy, we propose a new class
of methods exploiting any plausible modular bound. In the context of optimal
experimental design for linear Bayesian inverse problems, we bound the
submodularity and supermodularity ratios when the underlying objective is based
on mutual information. We also develop novel modular bounds for the mutual
information in this setting, and describe certain connections to polyhedral
combinatorics. We discuss how algorithms using these modular bounds relate to
established statistical notions such as leverage scores and to more recent
efforts such as volume sampling. We demonstrate our theoretical findings on
synthetic problems and on a real-world climate monitoring example.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness Through Counterfactual Utilities. (arXiv:2108.05315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blandin_J/0/1/0/all/0/1">Jack Blandin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kash_I/0/1/0/all/0/1">Ian Kash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05315">
                                    <div class="article-summary-box-inner">
                                        <span>Group fairness definitions such as Demographic Parity and Equal Opportunity
make assumptions about the underlying decision-problem that restrict them to
classification problems. Prior work has translated these definitions to other
machine learning environments, such as unsupervised learning and reinforcement
learning, by implementing their closest mathematical equivalent. As a result,
there are numerous bespoke interpretations of these definitions. Instead, we
provide a generalized set of group fairness definitions that unambiguously
extend to all machine learning environments while still retaining their
original fairness notions. We derive two fairness principles that enable such a
generalized framework. First, our framework measures outcomes in terms of
utilities, rather than predictions, and does so for both the decision-algorithm
and the individual. Second, our framework considers counterfactual outcomes,
rather than just observed outcomes, thus preventing loopholes where fairness
criteria are satisfied through self-fulfilling prophecies. We provide concrete
examples of how our counterfactual utility fairness framework resolves known
fairness issues in classification, clustering, and reinforcement learning
problems. We also show that many of the bespoke interpretations of Demographic
Parity and Equal Opportunity fit nicely as special cases of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Learning of Non-Interacting Fermion Distributions. (arXiv:2102.10458v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Aaronson_S/0/1/0/all/0/1">Scott Aaronson</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Grewal_S/0/1/0/all/0/1">Sabee Grewal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10458">
                                    <div class="article-summary-box-inner">
                                        <span>We give an efficient classical algorithm that recovers the distribution of a
non-interacting fermion state over the computational basis. For a system of $n$
non-interacting fermions and $m$ modes, we show that $O(m^2 n^4 \log(m/\delta)/
\varepsilon^4)$ samples and $O(m^4 n^4 \log(m/\delta)/ \varepsilon^4)$ time are
sufficient to learn the original distribution to total variation distance
$\varepsilon$ with probability $1 - \delta$. Our algorithm empirically
estimates the one- and two-mode correlations and uses them to reconstruct a
succinct description of the entire distribution efficiently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Algorithms for Efficient Active Learning Halfspaces with Massart and Tsybakov noise. (arXiv:2102.05312v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yinan Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05312">
                                    <div class="article-summary-box-inner">
                                        <span>We give a computationally-efficient PAC active learning algorithm for
$d$-dimensional homogeneous halfspaces that can tolerate Massart noise (Massart
and N\&#x27;ed\&#x27;elec, 2006) and Tsybakov noise (Tsybakov, 2004). Specialized to the
$\eta$-Massart noise setting, our algorithm achieves an
information-theoretically near-optimal label complexity of $\tilde{O}\left(
\frac{d}{(1-2\eta)^2} \mathrm{polylog}(\frac1\epsilon) \right)$ under a wide
range of unlabeled data distributions (specifically, the family of &quot;structured
distributions&quot; defined in Diakonikolas et al. (2020)). Under the more
challenging Tsybakov noise condition, we identify two subfamilies of noise
conditions, under which our efficient algorithm provides label complexity
guarantees strictly lower than passive learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASMR: Learning Attribute-Based Person Search with Adaptive Semantic Margin Regularizer. (arXiv:2108.04533v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeong_B/0/1/0/all/0/1">Boseung Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jicheol Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1">Suha Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04533">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute-based person search is the task of finding person images that are
best matched with a set of text attributes given as query. The main challenge
of this task is the large modality gap between attributes and images. To reduce
the gap, we present a new loss for learning cross-modal embeddings in the
context of attribute-based person search. We regard a set of attributes as a
category of people sharing the same traits. In a joint embedding space of the
two modalities, our loss pulls images close to their person categories for
modality alignment. More importantly, it pushes apart a pair of person
categories by a margin determined adaptively by their semantic distance, where
the distance metric is learned end-to-end so that the loss considers importance
of each attribute when relating person categories. Our loss guided by the
adaptive semantic margin leads to more discriminative and semantically
well-arranged distributions of person images. As a consequence, it enables a
simple embedding model to achieve state-of-the-art records on public benchmarks
without bells and whistles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Model Drift Detection Via Weak Data Slices. (arXiv:2108.05319v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ackerman_S/0/1/0/all/0/1">Samuel Ackerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dube_P/0/1/0/all/0/1">Parijat Dube</a>, <a href="http://arxiv.org/find/cs/1/au:+Farchi_E/0/1/0/all/0/1">Eitan Farchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_O/0/1/0/all/0/1">Orna Raz</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmanovici_M/0/1/0/all/0/1">Marcel Zalmanovici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05319">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting drift in performance of Machine Learning (ML) models is an
acknowledged challenge. For ML models to become an integral part of business
applications it is essential to detect when an ML model drifts away from
acceptable operation. However, it is often the case that actual labels are
difficult and expensive to get, for example, because they require expert
judgment. Therefore, there is a need for methods that detect likely degradation
in ML operation without labels. We propose a method that utilizes feature space
rules, called data slices, for drift detection. We provide experimental
indications that our method is likely to identify that the ML model will likely
change in performance, based on changes in the underlying data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition. (arXiv:2108.05335v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Weishen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Sen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05335">
                                    <div class="article-summary-box-inner">
                                        <span>Algorithmic fairness has aroused considerable interests in data mining and
machine learning communities recently. So far the existing research has been
mostly focusing on the development of quantitative metrics to measure algorithm
disparities across different protected groups, and approaches for adjusting the
algorithm output to reduce such disparities. In this paper, we propose to study
the problem of identification of the source of model disparities. Unlike
existing interpretation methods which typically learn feature importance, we
consider the causal relationships among feature variables and propose a novel
framework to decompose the disparity into the sum of contributions from
fairness-aware causal paths, which are paths linking the sensitive attribute
and the final predictions, on the graph. We also consider the scenario when the
directions on certain edges within those paths cannot be determined. Our
framework is also model agnostic and applicable to a variety of quantitative
disparity measures. Empirical evaluations on both synthetic and real-world data
sets are provided to show that our method can provide precise and comprehensive
explanations to the model disparities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Better Loss for Visual-Textual Grounding. (arXiv:2108.05308v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rigoni_D/0/1/0/all/0/1">Davide Rigoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Serafini_L/0/1/0/all/0/1">Luciano Serafini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1">Alessandro Sperduti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05308">
                                    <div class="article-summary-box-inner">
                                        <span>Given a textual phrase and an image, the visual grounding problem is defined
as the task of locating the content of the image referenced by the sentence. It
is a challenging task that has several real-world applications in
human-computer interaction, image-text reference resolution, and video-text
reference resolution. In the last years, several works have addressed this
problem with heavy and complex models that try to capture visual-textual
dependencies better than before. These models are typically constituted by two
main components that focus on how to learn useful multi-modal features for
grounding and how to improve the predicted bounding box of the visual mention,
respectively. Finding the right learning balance between these two sub-tasks is
not easy, and the current models are not necessarily optimal with respect to
this issue. In this work, we propose a model that, although using a simple
multi-modal feature fusion component, is able to achieve a higher accuracy than
state-of-the-art models thanks to the adoption of a more effective loss
function, based on the classes probabilities, that reach, in the considered
datasets, a better learning balance between the two sub-tasks mentioned above.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Descending through a Crowded Valley - Benchmarking Deep Learning Optimizers. (arXiv:2007.01547v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmidt_R/0/1/0/all/0/1">Robin M. Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_F/0/1/0/all/0/1">Frank Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01547">
                                    <div class="article-summary-box-inner">
                                        <span>Choosing the optimizer is considered to be among the most crucial design
decisions in deep learning, and it is not an easy one. The growing literature
now lists hundreds of optimization methods. In the absence of clear theoretical
guidance and conclusive empirical evidence, the decision is often made based on
anecdotes. In this work, we aim to replace these anecdotes, if not with a
conclusive ranking, then at least with evidence-backed heuristics. To do so, we
perform an extensive, standardized benchmark of fifteen particularly popular
deep learning optimizers while giving a concise overview of the wide range of
possible choices. Analyzing more than $50,000$ individual runs, we contribute
the following three points: (i) Optimizer performance varies greatly across
tasks. (ii) We observe that evaluating multiple optimizers with default
parameters works approximately as well as tuning the hyperparameters of a
single, fixed optimizer. (iii) While we cannot discern an optimization method
clearly dominating across all tested tasks, we identify a significantly reduced
subset of specific optimizers and parameter choices that generally lead to
competitive results in our experiments: Adam remains a strong contender, with
newer methods failing to significantly and consistently outperform it. Our
open-sourced results are available as challenging and well-tuned baselines for
more meaningful evaluations of novel optimization methods without requiring any
further computational efforts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Putting RDF2vec in Order. (arXiv:2108.05280v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portisch_J/0/1/0/all/0/1">Jan Portisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05280">
                                    <div class="article-summary-box-inner">
                                        <span>The RDF2vec method for creating node embeddings on knowledge graphs is based
on word2vec, which, in turn, is agnostic towards the position of context words.
In this paper, we argue that this might be a shortcoming when training RDF2vec,
and show that using a word2vec variant which respects order yields considerable
performance gains especially on tasks where entities of different classes are
involved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards data-driven filters in Paraview. (arXiv:2108.05196v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Majarjan_D/0/1/0/all/0/1">Drishti Majarjan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaspel_P/0/1/0/all/0/1">Peter Zaspel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05196">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress in scientific visualization has expanded the scope of
visualization from being merely a way of presentation to an analysis and
discovery tool. A given visualization result is usually generated by applying a
series of transformations or filters to the underlying data. Nowadays, such
filters use deterministic algorithms to process the data. In this work, we aim
at extending this methodology towards data-driven filters, thus filters that
expose the abilities of pre-trained machine learning models to the
visualization system. The use of such data-driven filters is of particular
interest in fields like segmentation, classification, etc., where machine
learning models regularly outperform existing algorithmic approaches. To
showcase this idea, we couple Paraview, the well-known flow visualization tool,
with PyTorch, a deep learning framework. Paraview is extended by plugins that
allow users to load pre-trained models of their choice in the form of newly
developed filters. The filters transform the input data by feeding it into the
model and then provide the model&#x27;s output as input to the remaining
visualization pipeline. A series of simplistic use cases for segmentation and
classification on image and fluid data is presented to showcase the technical
applicability of such data-driven transformations in Paraview for future
complex analysis tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Truncated Emphatic Temporal Difference Methods for Prediction and Control. (arXiv:2108.05338v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shangtong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05338">
                                    <div class="article-summary-box-inner">
                                        <span>Emphatic Temporal Difference (TD) methods are a class of off-policy
Reinforcement Learning (RL) methods involving the use of followon traces.
Despite the theoretical success of emphatic TD methods in addressing the
notorious deadly triad (Sutton and Barto, 2018) of off-policy RL, there are
still three open problems. First, the motivation for emphatic TD methods
proposed by Sutton et al. (2016) does not align with the convergence analysis
of Yu (2015). Namely, a quantity used by Sutton et al. (2016) that is expected
to be essential for the convergence of emphatic TD methods is not used in the
actual convergence analysis of Yu (2015). Second, followon traces typically
suffer from large variance, making them hard to use in practice. Third, despite
the seminal work of Yu (2015) confirming the asymptotic convergence of some
emphatic TD methods for prediction problems, there is still no finite sample
analysis for any emphatic TD method for prediction, much less control. In this
paper, we address those three open problems simultaneously via using truncated
followon traces in emphatic TD methods. Unlike the original followon traces,
which depend on all previous history, truncated followon traces depend on only
finite history, reducing variance and enabling the finite sample analysis of
our proposed emphatic TD methods for both prediction and control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Arbitrage-Free Implied Volatility Surface Generation with Variational Autoencoders. (arXiv:2108.04941v1 [q-fin.MF])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Ning_B/0/1/0/all/0/1">Brian Ning</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Jaimungal_S/0/1/0/all/0/1">Sebastian Jaimungal</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhang_X/0/1/0/all/0/1">Xiaorong Zhang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Bergeron_M/0/1/0/all/0/1">Maxime Bergeron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04941">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a hybrid method for generating arbitrage-free implied volatility
(IV) surfaces consistent with historical data by combining model-free
Variational Autoencoders (VAEs) with continuous time stochastic differential
equation (SDE) driven models. We focus on two classes of SDE models: regime
switching models and L\&#x27;evy additive processes. By projecting historical
surfaces onto the space of SDE model parameters, we obtain a distribution on
the parameter subspace faithful to the data on which we then train a VAE.
Arbitrage-free IV surfaces are then generated by sampling from the posterior
distribution on the latent space, decoding to obtain SDE model parameters, and
finally mapping those parameters to IV surfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement learning of rare diffusive dynamics. (arXiv:2105.04321v2 [cond-mat.stat-mech] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Das_A/0/1/0/all/0/1">Avishek Das</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rose_D/0/1/0/all/0/1">Dominic C. Rose</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Garrahan_J/0/1/0/all/0/1">Juan P. Garrahan</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Limmer_D/0/1/0/all/0/1">David T. Limmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04321">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to probe rare molecular dynamics trajectories directly
using reinforcement learning. We consider trajectories that are conditioned to
transition between regions of configuration space in finite time, like those
relevant in the study of reactive events, as well as trajectories exhibiting
rare fluctuations of time-integrated quantities in the long time limit, like
those relevant in the calculation of large deviation functions. In both cases,
reinforcement learning techniques are used to optimize an added force that
minimizes the Kullback-Leibler divergence between the conditioned trajectory
ensemble and a driven one. Under the optimized added force, the system evolves
the rare fluctuation as a typical one, affording a variational estimate of its
likelihood in the original trajectory ensemble. Low variance gradients
employing value functions are proposed to increase the convergence of the
optimal force. The method we develop employing these gradients leads to
efficient and accurate estimates of both the optimal force and the likelihood
of the rare event for a variety of model systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction. (arXiv:2101.11427v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1">Xiang-Rong Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liqin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1">Guorui Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xinyao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Binding Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1">Qiang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Siran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jingshan Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1">Hongbo Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11427">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional industrial recommenders are usually trained on a single business
domain and then serve for this domain. However, in large commercial platforms,
it is often the case that the recommenders need to make click-through rate
(CTR) predictions for multiple business domains. Different domains have
overlapping user groups and items. Thus, there exist commonalities. Since the
specific user groups have disparity and the user behaviors may change in
various business domains, there also have distinctions. The distinctions result
in domain-specific data distributions, making it hard for a single shared model
to work well on all domains. To learn an effective and efficient CTR model to
handle multiple domains simultaneously, we present Star Topology Adaptive
Recommender (STAR). Concretely, STAR has the star topology, which consists of
the shared centered parameters and domain-specific parameters. The shared
parameters are applied to learn commonalities of all domains, and the
domain-specific parameters capture domain distinction for more refined
prediction. Given requests from different business domains, STAR can adapt its
parameters conditioned on the domain characteristics. The experimental result
from production data validates the superiority of the proposed STAR model.
Since 2020, STAR has been deployed in the display advertising system of
Alibaba, obtaining averaging 8.0% improvement on CTR and 6.0% on RPM (Revenue
Per Mille).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges in Markov chain Monte Carlo for Bayesian neural networks. (arXiv:1910.06539v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Papamarkou_T/0/1/0/all/0/1">Theodore Papamarkou</a>, <a href="http://arxiv.org/find/stat/1/au:+Hinkle_J/0/1/0/all/0/1">Jacob Hinkle</a>, <a href="http://arxiv.org/find/stat/1/au:+Young_M/0/1/0/all/0/1">M. Todd Young</a>, <a href="http://arxiv.org/find/stat/1/au:+Womble_D/0/1/0/all/0/1">David Womble</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.06539">
                                    <div class="article-summary-box-inner">
                                        <span>Markov chain Monte Carlo (MCMC) methods have not been broadly adopted in
Bayesian neural networks (BNNs). This paper initially reviews the main
challenges in sampling from the parameter posterior of a neural network via
MCMC. Such challenges culminate to lack of convergence to the parameter
posterior. Nevertheless, this paper shows that a non-converged Markov chain,
generated via MCMC sampling from the parameter space of a neural network, can
yield via Bayesian marginalization a valuable posterior predictive distribution
of the output of the neural network. Classification examples based on
multilayer perceptrons showcase highly accurate posterior predictive
distributions. The postulate of limited scope for MCMC developments in BNNs is
partially valid; an asymptotically exact parameter posterior seems less
plausible, yet an accurate posterior predictive distribution is a tenable
research avenue.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Video Object Segmentation by Motion Grouping. (arXiv:2104.07658v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Charig Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamdouar_H/0/1/0/all/0/1">Hala Lamdouar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_E/0/1/0/all/0/1">Erika Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weidi Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07658">
                                    <div class="article-summary-box-inner">
                                        <span>Animals have evolved highly functional visual systems to understand motion,
assisting perception even under complex environments. In this paper, we work
towards developing a computer vision system able to segment objects by
exploiting motion cues, i.e. motion segmentation. We make the following
contributions: First, we introduce a simple variant of the Transformer to
segment optical flow frames into primary objects and the background. Second, we
train the architecture in a self-supervised manner, i.e. without using any
manual annotations. Third, we analyze several critical components of our method
and conduct thorough ablation studies to validate their necessity. Fourth, we
evaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2,
and FBMS59). Despite using only optical flow as input, our approach achieves
superior or comparable results to previous state-of-the-art self-supervised
methods, while being an order of magnitude faster. We additionally evaluate on
a challenging camouflage dataset (MoCA), significantly outperforming the other
self-supervised approaches, and comparing favourably to the top supervised
approach, highlighting the importance of motion cues, and the potential bias
towards visual appearance in existing video segmentation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overview of the TREC 2020 Fair Ranking Track. (arXiv:2108.05135v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1">Asia J. Biega</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1">Fernando Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekstrand_M/0/1/0/all/0/1">Michael D. Ekstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_S/0/1/0/all/0/1">Sergey Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohlmeier_S/0/1/0/all/0/1">Sebastian Kohlmeier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05135">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides an overview of the NIST TREC 2020 Fair Ranking track. For
2020, we again adopted an academic search task, where we have a corpus of
academic article abstracts and queries submitted to a production academic
search engine. The central goal of the Fair Ranking track is to provide fair
exposure to different groups of authors (a group fairness framing). We
recognize that there may be multiple group definitions (e.g. based on
demographics, stature, topic) and hoped for the systems to be robust to these.
We expected participants to develop systems that optimize for fairness and
relevance for arbitrary group definitions, and did not reveal the exact group
definitions until after the evaluation runs were submitted.The track contains
two tasks,reranking and retrieval, with a shared evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Particle Variational Inference via Estimation of Functional Gradients. (arXiv:2103.01291v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ratzlaff_N/0/1/0/all/0/1">Neale Ratzlaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1">Qinxun Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuxin_L/0/1/0/all/0/1">Li Fuxin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01291">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, particle-based variational inference (ParVI) methods have gained
interest because they can avoid arbitrary parametric assumptions that are
common in variational inference. However, many ParVI approaches do not allow
arbitrary sampling from the posterior, and the few that do allow such sampling
suffer from suboptimality. This work proposes a new method for learning to
approximately sample from the posterior distribution. We construct a neural
sampler that is trained with the functional gradient of the KL-divergence
between the empirical sampling distribution and the target distribution,
assuming the gradient resides within a reproducing kernel Hilbert space. Our
generative ParVI (GPVI) approach maintains the asymptotic performance of ParVI
methods while offering the flexibility of a generative sampler. Through
carefully constructed experiments, we show that GPVI outperforms previous
generative ParVI methods such as amortized SVGD, and is competitive with ParVI
as well as gold-standard approaches like Hamiltonian Monte Carlo for fitting
both exactly known and intractable target distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PEng4NN: An Accurate Performance Estimation Engine for Efficient Automated Neural Network Architecture Search. (arXiv:2101.04185v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rorabaugh_A/0/1/0/all/0/1">Ariel Keller Rorabaugh</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Caino_Lores_S/0/1/0/all/0/1">Silvina Ca&#xed;no-Lores</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Wyatt_M/0/1/0/all/0/1">Michael R. Wyatt II</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Johnston_T/0/1/0/all/0/1">Travis Johnston</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Taufer_M/0/1/0/all/0/1">Michela Taufer</a> (1) ((1) University of Tennessee, Knoxville, USA, (2) Oak Ridge National Lab, Oak Ridge, USA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04185">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network (NN) models are increasingly used in scientific simulations,
AI, and other high performance computing (HPC) fields to extract knowledge from
datasets. Each dataset requires tailored NN model architecture, but designing
structures by hand is a time-consuming and error-prone process. Neural
architecture search (NAS) automates the design of NN architectures. NAS
attempts to find well-performing NN models for specialized datsets, where
performance is measured by key metrics that capture the NN capabilities (e.g.,
accuracy of classification of samples in a dataset). Existing NAS methods are
resource intensive, especially when searching for highly accurate models for
larger and larger datasets.

To address this problem, we propose a performance estimation strategy that
reduces the resources for training NNs and increases NAS throughput without
jeopardizing accuracy. We implement our strategy via an engine called PEng4NN
that plugs into existing NAS methods; in doing so, PEng4NN predicts the final
accuracy of NNs early in the training process, informs the NAS of NN
performance, and thus enables the NAS to terminate training NNs early. We
assess our engine on three diverse datasets (i.e., CIFAR-100, Fashion MNIST,
and SVHN). By reducing the training epochs needed, our engine achieves
substantial throughput gain; on average, our engine saves 61% to 82% of
training epochs, increasing throughput by a factor of 2.5 to 5 compared to a
state-of-the-art NAS method. We achieve this gain without compromising
accuracy, as we demonstrate with two key outcomes. First, across all our tests,
between 74% and 97% of the ground truth best models lie in our set of predicted
best models. Second, the accuracy distributions of the ground truth best models
and our predicted best models are comparable, with the mean accuracy values
differing by at most .7 percentage points across all tests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in Adverse Weather. (arXiv:2108.05249v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hahner_M/0/1/0/all/0/1">Martin Hahner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakaridis_C/0/1/0/all/0/1">Christos Sakaridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Dengxin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05249">
                                    <div class="article-summary-box-inner">
                                        <span>This work addresses the challenging task of LiDAR-based 3D object detection
in foggy weather. Collecting and annotating data in such a scenario is very
time, labor and cost intensive. In this paper, we tackle this problem by
simulating physically accurate fog into clear-weather scenes, so that the
abundant existing real datasets captured in clear weather can be repurposed for
our task. Our contributions are twofold: 1) We develop a physically valid fog
simulation method that is applicable to any LiDAR dataset. This unleashes the
acquisition of large-scale foggy training data at no extra cost. These
partially synthetic data can be used to improve the robustness of several
perception methods, such as 3D object detection and tracking or simultaneous
localization and mapping, on real foggy data. 2) Through extensive experiments
with several state-of-the-art detection approaches, we show that our fog
simulation can be leveraged to significantly improve the performance for 3D
object detection in the presence of fog. Thus, we are the first to provide
strong 3D object detection baselines on the Seeing Through Fog dataset. Our
code is available at www.trace.ethz.ch/lidar_fog_simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming the Weight Transport Problem via Spike-Timing-Dependent Weight Inference. (arXiv:2003.03988v4 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ahmad_N/0/1/0/all/0/1">Nasir Ahmad</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ambrogioni_L/0/1/0/all/0/1">Luca Ambrogioni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gerven_M/0/1/0/all/0/1">Marcel A. J. van Gerven</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03988">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a solution to the weight transport problem, which questions the
biological plausibility of the backpropagation algorithm. We derive our method
based upon a theoretical analysis of the (approximate) dynamics of leaky
integrate-and-fire neurons. We show that the use of spike timing alone
outcompetes existing biologically plausible methods for synaptic weight
inference in spiking neural network models. Furthermore, our proposed method is
more flexible, being applicable to any spiking neuron model, is conservative in
how many parameters are required for implementation and can be deployed in an
online-fashion with minimal computational overhead. These features, together
with its biological plausibility, make it an attractive mechanism underlying
weight inference at single synapses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Maximum Entropy for Supervised Classification. (arXiv:2007.05447v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mazuelas_S/0/1/0/all/0/1">Santiago Mazuelas</a>, <a href="http://arxiv.org/find/stat/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/stat/1/au:+Perez_A/0/1/0/all/0/1">Aritz P&#xe9;rez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05447">
                                    <div class="article-summary-box-inner">
                                        <span>The maximum entropy principle advocates to evaluate events&#x27; probabilities
using a distribution that maximizes entropy among those that satisfy certain
expectations&#x27; constraints. Such principle can be generalized for arbitrary
decision problems where it corresponds to minimax approaches. This paper
establishes a framework for supervised classification based on the generalized
maximum entropy principle that leads to minimax risk classifiers (MRCs). We
develop learning techniques that determine MRCs for general entropy functions
and provide performance guarantees by means of convex optimization. In
addition, we describe the relationship of the presented techniques with
existing classification methods, and quantify MRCs performance in comparison
with the proposed bounds and conventional methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PLEX: Towards Practical Learned Indexing. (arXiv:2108.05117v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stoian_M/0/1/0/all/0/1">Mihail Stoian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kipf_A/0/1/0/all/0/1">Andreas Kipf</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_R/0/1/0/all/0/1">Ryan Marcus</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1">Tim Kraska</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05117">
                                    <div class="article-summary-box-inner">
                                        <span>Latest research proposes to replace existing index structures with learned
models. However, current learned indexes tend to have many hyperparameters,
often do not provide any error guarantees, and are expensive to build. We
introduce Practical Learned Index (PLEX). PLEX only has a single hyperparameter
$\epsilon$ (maximum prediction error) and offers a better trade-off between
build and lookup time than state-of-the-art approaches. Similar to RadixSpline,
PLEX consists of a spline and a (multi-level) radix layer. It first builds a
spline satisfying the given $\epsilon$ and then performs an ad-hoc analysis of
the distribution of spline points to quickly tune the radix layer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Molecular Phenotypes with Single Cell RNA Sequencing Data: an Assessment of Unsupervised Machine Learning Models. (arXiv:2108.05039v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Dunca_A/0/1/0/all/0/1">Anastasia Dunca</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Adler_F/0/1/0/all/0/1">Frederick R. Adler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05039">
                                    <div class="article-summary-box-inner">
                                        <span>According to the National Cancer Institute, there were 9.5 million
cancer-related deaths in 2018. A challenge in improving treatment is resistance
in genetically unstable cells. The purpose of this study is to evaluate
unsupervised machine learning on classifying treatment-resistant phenotypes in
heterogeneous tumors through analysis of single cell RNA sequencing(scRNAseq)
data with a pipeline and evaluation metrics. scRNAseq quantifies mRNA in cells
and characterizes cell phenotypes. One scRNAseq dataset was analyzed
(tumor/non-tumor cells of different molecular subtypes and patient
identifications). The pipeline consisted of data filtering, dimensionality
reduction with Principal Component Analysis, projection with Uniform Manifold
Approximation and Projection, clustering with nine approaches (Ward, BIRCH,
Gaussian Mixture Model, DBSCAN, Spectral, Affinity Propagation, Agglomerative
Clustering, Mean Shift, and K-Means), and evaluation. Seven models divided
tumor versus non-tumor cells and molecular subtype while six models classified
different patient identification (13 of which were presented in the dataset);
K-Means, Ward, and BIRCH often ranked highest with ~80% accuracy on the tumor
versus non-tumor task and ~60% for molecular subtype and patient ID. An
optimized classification pipeline using K-Means, Ward, and BIRCH models was
evaluated to be most effective for further analysis. In clinical research where
there is currently no standard protocol for scRNAseq analysis, clusters
generated from this pipeline can be used to understand cancer cell behavior and
malignant growth, directly affecting the success of treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Explicit Prediction Matter in Energy Management Based on Deep Reinforcement Learning?. (arXiv:2108.05099v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Qin_Z/0/1/0/all/0/1">Zhaoming Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Huaying Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yuzhou Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xie_H/0/1/0/all/0/1">Hong Xie</a>, <a href="http://arxiv.org/find/eess/1/au:+Cao_J/0/1/0/all/0/1">Junwei Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05099">
                                    <div class="article-summary-box-inner">
                                        <span>As a model-free optimization and decision-making method, deep reinforcement
learning (DRL) has been widely applied to the filed of energy management in
energy Internet. While, some DRL-based energy management schemes also
incorporate the prediction module used by the traditional model-based methods,
which seems to be unnecessary and even adverse. In this work, we present the
standard DRL-based energy management scheme with and without prediction. Then,
these two schemes are compared in the unified energy management framework. The
simulation results demonstrate that the energy management scheme without
prediction is superior over the scheme with prediction. This work intends to
rectify the misuse of DRL methods in the field of energy management.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Oculomotor Behaviors from Scanpath. (arXiv:2108.05025v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Beibin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuechterlein_N/0/1/0/all/0/1">Nicholas Nuechterlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Barney_E/0/1/0/all/0/1">Erin Barney</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_C/0/1/0/all/0/1">Claire Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minah Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahony_M/0/1/0/all/0/1">Monique Mahony</a>, <a href="http://arxiv.org/find/cs/1/au:+Atyabi_A/0/1/0/all/0/1">Adham Atyabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Li Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventola_P/0/1/0/all/0/1">Pamela Ventola</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapiro_L/0/1/0/all/0/1">Linda Shapiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Shic_F/0/1/0/all/0/1">Frederick Shic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05025">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying oculomotor behaviors relevant for eye-tracking applications is a
critical but often challenging task. Aiming to automatically learn and extract
knowledge from existing eye-tracking data, we develop a novel method that
creates rich representations of oculomotor scanpaths to facilitate the learning
of downstream tasks. The proposed stimulus-agnostic Oculomotor Behavior
Framework (OBF) model learns human oculomotor behaviors from unsupervised and
semi-supervised tasks, including reconstruction, predictive coding, fixation
identification, and contrastive learning tasks. The resultant pre-trained OBF
model can be used in a variety of applications. Our pre-trained model
outperforms baseline approaches and traditional scanpath methods in autism
spectrum disorder and viewed-stimulus classification tasks. Ablation
experiments further show our proposed method could achieve even better results
with larger model sizes and more diverse eye-tracking training datasets,
supporting the model&#x27;s potential for future eye-tracking applications. Open
source code: this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logic Explained Networks. (arXiv:2108.05149v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1">Gabriele Ciravegna</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1">Pietro Barbiero</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1">Francesco Giannini</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1">Marco Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Maggini_M/0/1/0/all/0/1">Marco Maggini</a>, <a href="http://arxiv.org/find/cs/1/au:+Melacci_S/0/1/0/all/0/1">Stefano Melacci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05149">
                                    <div class="article-summary-box-inner">
                                        <span>The large and still increasing popularity of deep learning clashes with a
major limit of neural network architectures, that consists in their lack of
capability in providing human-understandable motivations of their decisions. In
situations in which the machine is expected to support the decision of human
experts, providing a comprehensible explanation is a feature of crucial
importance. The language used to communicate the explanations must be formal
enough to be implementable in a machine and friendly enough to be
understandable by a wide audience. In this paper, we propose a general approach
to Explainable Artificial Intelligence in the case of neural architectures,
showing how a mindful design of the networks leads to a family of interpretable
deep learning models called Logic Explained Networks (LENs). LENs only require
their inputs to be human-understandable predicates, and they provide
explanations in terms of simple First-Order Logic (FOL) formulas involving such
predicates. LENs are general enough to cover a large number of scenarios.
Amongst them, we consider the case in which LENs are directly used as special
classifiers with the capability of being explainable, or when they act as
additional networks with the role of creating the conditions for making a
black-box classifier explainable by FOL formulas. Despite supervised learning
problems are mostly emphasized, we also show that LENs can learn and provide
explanations in unsupervised learning settings. Experimental results on several
datasets and tasks show that LENs may yield better classifications than
established white-box models, such as decision trees and Bayesian rule lists,
while providing more compact and meaningful explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimation of Fair Ranking Metrics with Incomplete Judgments. (arXiv:2108.05152v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirnap_O/0/1/0/all/0/1">&#xd6;mer K&#x131;rnap</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1">Fernando Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1">Asia Biega</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekstrand_M/0/1/0/all/0/1">Michael Ekstrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Carterette_B/0/1/0/all/0/1">Ben Carterette</a>, <a href="http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1">Emine Y&#x131;lmaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05152">
                                    <div class="article-summary-box-inner">
                                        <span>There is increasing attention to evaluating the fairness of search system
ranking decisions. These metrics often consider the membership of items to
particular groups, often identified using protected attributes such as gender
or ethnicity. To date, these metrics typically assume the availability and
completeness of protected attribute labels of items. However, the protected
attributes of individuals are rarely present, limiting the application of fair
ranking metrics in large scale systems. In order to address this problem, we
propose a sampling strategy and estimation technique for four fair ranking
metrics. We formulate a robust and unbiased estimator which can operate even
with very limited number of labeled items. We evaluate our approach using both
simulated and real world data. Our experimental results demonstrate that our
method can estimate this family of fair ranking metrics and provides a robust,
reliable alternative to exhaustive or random data annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion. (arXiv:2108.04927v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1">Alessandro Suglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qiaozi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Thattai_G/0/1/0/all/0/1">Govind Thattai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1">Gaurav Sukhatme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04927">
                                    <div class="article-summary-box-inner">
                                        <span>Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?. (arXiv:2108.04893v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+pourmirzaei_M/0/1/0/all/0/1">Mahdi pourmirzaei</a>, <a href="http://arxiv.org/find/cs/1/au:+montazer_g/0/1/0/all/0/1">gholam ali montazer</a>, <a href="http://arxiv.org/find/cs/1/au:+esmaili_f/0/1/0/all/0/1">farzaneh esmaili</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04893">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress of Self-Supervised Learning (SSL) demonstrates the capability
of these methods in computer vision field. However, this progress could not
show any promises for fine-grained tasks such as Head Pose estimation. In this
article, we have tried to answer a question: How SSL can be used for Head Pose
estimation? In general, there are two main approaches to use SSL: 1. Using
pre-trained weights which can be done via weights pre-training on ImageNet or
via SSL tasks. 2. Leveraging SSL as an auxiliary co-training task besides of
Supervised Learning (SL) tasks at the same time. In this study, modified
versions of jigsaw puzzling and rotation as SSL pre-text tasks are used and the
best architecture for our proposed Hybrid Multi-Task Learning (HMTL) is found.
Finally, the HopeNet method as a baseline is selected and the impact of SSL
pre-training and ImageNet pre-training on both HMTL and SL are compared. The
error rate reduced by the HTML method up to 11% compare to the SL. Moreover,
HMTL method showed that it was good with all kinds of initial weights: random,
ImageNet and SSL pre-training weights. Also, it was observed, when puzzled
images are used for SL alone, the average error rate placed between SL and HMTL
which showed the importance of local spatial features compare to global spatial
features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision. (arXiv:2108.04869v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Usman_B/0/1/0/all/0/1">Ben Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_A/0/1/0/all/0/1">Andrea Tagliasacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sud_A/0/1/0/all/0/1">Avneesh Sud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04869">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, huge strides were made in monocular and multi-view pose estimation
with known camera parameters, whereas pose estimation from multiple cameras
with unknown positions and orientations received much less attention. In this
paper, we show how to train a neural model that can perform accurate 3D pose
and camera estimation, takes into account joint location uncertainty due
occlusion from multiple views, and requires only 2D keypoint data for training.
Our method outperforms both classical bundle adjustment and weakly-supervised
monocular 3D baselines on the well-established Human3.6M dataset, as well as
the more challenging in-the-wild Ski-Pose PTZ dataset with moving cameras. We
provide an extensive ablation study separating the error due to the camera
model, number of cameras, initialization, and image-space joint localization
from the additional error introduced by our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Driver Behavior Profiling leveraging Recurrent Neural Networks. (arXiv:2108.05079v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Young Ah Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kyung Ho Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1">Eunji Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Huy Kang Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05079">
                                    <div class="article-summary-box-inner">
                                        <span>In the era of intelligent transportation, driver behavior profiling has
become a beneficial technology as it provides knowledge regarding the driver&#x27;s
aggressiveness. Previous approaches achieved promising driver behavior
profiling performance through establishing statistical heuristics rules or
supervised learning-based models. Still, there exist limits that the
practitioner should prepare a labeled dataset, and prior approaches could not
classify aggressive behaviors which are not known a priori. In pursuit of
improving the aforementioned drawbacks, we propose a novel approach to driver
behavior profiling leveraging an unsupervised learning paradigm. First, we cast
the driver behavior profiling problem as anomaly detection. Second, we
established recurrent neural networks that predict the next feature vector
given a sequence of feature vectors. We trained the model with normal driver
data only. As a result, our model yields high regression error given a sequence
of aggressive driver behavior and low error given at a sequence of normal
driver behavior. We figured this difference of error between normal and
aggressive driver behavior can be an adequate flag for driver behavior
profiling and accomplished a precise performance in experiments. Lastly, we
further analyzed the optimal level of sequence length for identifying each
aggressive driver behavior. We expect the proposed approach to be a useful
baseline for unsupervised driver behavior profiling and contribute to the
efficient, intelligent transportation ecosystem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Learning for Noisy Supervision. (arXiv:2108.05092v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiangchao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05092">
                                    <div class="article-summary-box-inner">
                                        <span>Learning with noisy labels has gained the enormous interest in the robust
deep learning area. Recent studies have empirically disclosed that utilizing
dual networks can enhance the performance of single network but without
theoretic proof. In this paper, we propose Cooperative Learning (CooL)
framework for noisy supervision that analytically explains the effects of
leveraging dual or multiple networks. Specifically, the simple but efficient
combination in CooL yields a more reliable risk minimization for unseen clean
data. A range of experiments have been conducted on several benchmarks with
both synthetic and real-world settings. Extensive results indicate that CooL
outperforms several state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep2Lead: A distributed deep learning application for small molecule lead optimization. (arXiv:2108.05183v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chawdhury_T/0/1/0/all/0/1">Tarun Kumar Chawdhury</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Grant_D/0/1/0/all/0/1">David J. Grant</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Jin_H/0/1/0/all/0/1">Hyun Yong Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05183">
                                    <div class="article-summary-box-inner">
                                        <span>Lead optimization is a key step in drug discovery to produce potent and
selective compounds. Historically, in silico screening and structure-based
small molecule designing facilitated the processes. Although the recent
application of deep learning to drug discovery piloted the possibility of their
in silico application lead optimization steps, the real-world application is
lacking due to the tool availability. Here, we developed a single user
interface application, called Deep2Lead. Our web-based application integrates
VAE and DeepPurpose DTI and allows a user to quickly perform a lead
optimization task with no prior programming experience.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Turning Your Strength against You: Detecting and Mitigating Robust and Universal Adversarial Patch Attack. (arXiv:2108.05075v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zitao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dash_P/0/1/0/all/0/1">Pritam Dash</a>, <a href="http://arxiv.org/find/cs/1/au:+Pattabiraman_K/0/1/0/all/0/1">Karthik Pattabiraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05075">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial patch attack against image classification deep neural networks
(DNNs), in which the attacker can inject arbitrary distortions within a bounded
region of an image, is able to generate adversarial perturbations that are
robust (i.e., remain adversarial in physical world) and universal (i.e., remain
adversarial on any input). It is thus important to detect and mitigate such
attack to ensure the security of DNNs.

This work proposes Jujutsu, a technique to detect and mitigate robust and
universal adversarial patch attack. Jujutsu leverages the universal property of
the patch attack for detection. It uses explainable AI technique to identify
suspicious features that are potentially malicious, and verify their
maliciousness by transplanting the suspicious features to new images. An
adversarial patch continues to exhibit the malicious behavior on the new images
and thus can be detected based on prediction consistency. Jujutsu leverages the
localized nature of the patch attack for mitigation, by randomly masking the
suspicious features to &quot;remove&quot; adversarial perturbations. However, the network
might fail to classify the images as some of the contents are removed (masked).
Therefore, Jujutsu uses image inpainting for synthesizing alternative contents
from the pixels that are masked, which can reconstruct the &quot;clean&quot; image for
correct prediction. We evaluate Jujutsu on five DNNs on two datasets, and show
that Jujutsu achieves superior performance and significantly outperforms
existing techniques. Jujutsu can further defend against various variants of the
basic attack, including 1) physical-world attack; 2) attacks that target
diverse classes; 3) attacks that use patches in different shapes and 4)
adaptive attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProAI: An Efficient Embedded AI Hardware for Automotive Applications - a Benchmark Study. (arXiv:2108.05170v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mantowsky_S/0/1/0/all/0/1">Sven Mantowsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Heuer_F/0/1/0/all/0/1">Falk Heuer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bukhari_S/0/1/0/all/0/1">Syed Saqib Bukhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Keckeisen_M/0/1/0/all/0/1">Michael Keckeisen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1">Georg Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05170">
                                    <div class="article-summary-box-inner">
                                        <span>Development in the field of Single Board Computers (SBC) have been increasing
for several years. They provide a good balance between computing performance
and power consumption which is usually required for mobile platforms, like
application in vehicles for Advanced Driver Assistance Systems (ADAS) and
Autonomous Driving (AD). However, there is an ever-increasing need of more
powerful and efficient SBCs which can run power intensive Deep Neural Networks
(DNNs) in real-time and can also satisfy necessary functional safety
requirements such as Automotive Safety Integrity Level (ASIL). ProAI is being
developed by ZF mainly to run powerful and efficient applications such as
multitask DNNs and on top of that it also has the required safety certification
for AD. In this work, we compare and discuss state of the art SBC on the basis
of power intensive multitask DNN architecture called Multitask-CenterNet with
respect to performance measures such as, FPS and power efficiency. As an
automotive supercomputer, ProAI delivers an excellent combination of
performance and efficiency, managing nearly twice the number of FPS per watt
than a modern workstation laptop and almost four times compared to the Jetson
Nano. Furthermore, it was also shown that there is still power in reserve for
further and more complex tasks on the ProAI, based on the CPU and GPU
utilization during the benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Managing ML Pipelines: Feature Stores and the Coming Wave of Embedding Ecosystems. (arXiv:2108.05053v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Orr_L/0/1/0/all/0/1">Laurel Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanyal_A/0/1/0/all/0/1">Atindriyo Sanyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiao Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_K/0/1/0/all/0/1">Karan Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Leszczynski_M/0/1/0/all/0/1">Megan Leszczynski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05053">
                                    <div class="article-summary-box-inner">
                                        <span>The industrial machine learning pipeline requires iterating on model
features, training and deploying models, and monitoring deployed models at
scale. Feature stores were developed to manage and standardize the engineer&#x27;s
workflow in this end-to-end pipeline, focusing on traditional tabular feature
data. In recent years, however, model development has shifted towards using
self-supervised pretrained embeddings as model features. Managing these
embeddings and the downstream systems that use them introduces new challenges
with respect to managing embedding training data, measuring embedding quality,
and monitoring downstream models that use embeddings. These challenges are
largely unaddressed in standard feature stores. Our goal in this tutorial is to
introduce the feature store system and discuss the challenges and current
solutions to managing these new embedding-centric pipelines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ULTRA: An Unbiased Learning To Rank Algorithm Toolbox. (arXiv:2108.05073v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_A/0/1/0/all/0/1">Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05073">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to rank systems has become an important aspect of our daily life.
However, the implicit user feedback that is used to train many learning to rank
models is usually noisy and suffered from user bias (i.e., position bias).
Thus, obtaining an unbiased model using biased feedback has become an important
research field for IR. Existing studies on unbiased learning to rank (ULTR) can
be generalized into two families-algorithms that attain unbiasedness with
logged data, offline learning, and algorithms that achieve unbiasedness by
estimating unbiased parameters with real-time user interactions, namely online
learning. While there exist many algorithms from both families, there lacks a
unified way to compare and benchmark them. As a result, it can be challenging
for researchers to choose the right technique for their problems or for people
who are new to the field to learn and understand existing algorithms. To solve
this problem, we introduced ULTRA, which is a flexible, extensible, and easily
configure ULTR toolbox. Its key features include support for multiple ULTR
algorithms with configurable hyperparameters, a variety of built-in click
models that can be used separately to simulate clicks, different ranking model
architecture and evaluation metrics, and simple learning to rank pipeline
creation. In this paper, we discuss the general framework of ULTR, briefly
describe the algorithms in ULTRA, detailed the structure, and pipeline of the
toolbox. We experimented on all the algorithms supported by ultra and showed
that the toolbox performance is reasonable. Our toolbox is an important
resource for researchers to conduct experiments on ULTR algorithms with
different configurations as well as testing their own algorithms with the
supported features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel algorithms for mining of frequent itemsets. (arXiv:2108.05038v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kessl_R/0/1/0/all/0/1">Robert Kessl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05038">
                                    <div class="article-summary-box-inner">
                                        <span>In the recent decade companies started collecting of large amount of data.
Without a proper analyse, the data are usually useless. The field of analysing
the data is called data mining. Unfortunately, the amount of data is quite
large: the data do not fit into main memory and the processing time can become
quite huge. Therefore, we need parallel data mining algorithms. One of the
popular and important data mining algorithm is the algorithm for generation of
so called frequent itemsets. The problem of mining of frequent itemsets can be
explained on the following example: customers goes in a store put into theirs
baskets some goods; the owner of the store collects the baskets and wants to
know the set of goods that are bought together in at least p% of the baskets.
Currently, the sequential algorithms for mining of frequent itemsets are quite
good in the means of performance. However, the parallel algorithms for mining
of frequent itemsets still do not achieve good speedup. In this thesis, we
develop a parallel method for mining of frequent itemsets that can be used for
an arbitrary depth first search sequential algorithms on a distributed memory
parallel computer. Our method achieves speedup of ~ 6 on 10 processors. The
method is based on an approximate estimation of processor load from a database
sample - however it always computes the set of frequent itemsets from the whole
database. In this thesis, we show a theory underlying our method and show the
performance of the estimation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SoK: How Robust is Image Classification Deep Neural Network Watermarking? (Extended Version). (arXiv:2108.04974v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lukas_N/0/1/0/all/0/1">Nils Lukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_E/0/1/0/all/0/1">Edward Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinda Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerschbaum_F/0/1/0/all/0/1">Florian Kerschbaum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04974">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Network (DNN) watermarking is a method for provenance
verification of DNN models. Watermarking should be robust against watermark
removal attacks that derive a surrogate model that evades provenance
verification. Many watermarking schemes that claim robustness have been
proposed, but their robustness is only validated in isolation against a
relatively small set of attacks. There is no systematic, empirical evaluation
of these claims against a common, comprehensive set of removal attacks. This
uncertainty about a watermarking scheme&#x27;s robustness causes difficulty to trust
their deployment in practice. In this paper, we evaluate whether recently
proposed watermarking schemes that claim robustness are robust against a large
set of removal attacks. We survey methods from the literature that (i) are
known removal attacks, (ii) derive surrogate models but have not been evaluated
as removal attacks, and (iii) novel removal attacks. Weight shifting and smooth
retraining are novel removal attacks adapted to the DNN watermarking schemes
surveyed in this paper. We propose taxonomies for watermarking schemes and
removal attacks. Our empirical evaluation includes an ablation study over sets
of parameters for each attack and watermarking scheme on the CIFAR-10 and
ImageNet datasets. Surprisingly, none of the surveyed watermarking schemes is
robust in practice. We find that schemes fail to withstand adaptive attacks and
known methods for deriving surrogate models that have not been evaluated as
removal attacks. This points to intrinsic flaws in how robustness is currently
evaluated. We show that watermarking schemes need to be evaluated against a
more extensive set of removal attacks with a more realistic adversary model.
Our source code and a complete dataset of evaluation results are publicly
available, which allows to independently verify our conclusions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning strange attractors with reservoir systems. (arXiv:2108.05024v1 [math.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Grigoryeva_L/0/1/0/all/0/1">Lyudmila Grigoryeva</a>, <a href="http://arxiv.org/find/math/1/au:+Hart_A/0/1/0/all/0/1">Allen Hart</a>, <a href="http://arxiv.org/find/math/1/au:+Ortega_J/0/1/0/all/0/1">Juan-Pablo Ortega</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05024">
                                    <div class="article-summary-box-inner">
                                        <span>This paper shows that the celebrated Embedding Theorem of Takens is a
particular case of a much more general statement according to which, randomly
generated linear state-space representations of generic observations of an
invertible dynamical system carry in their wake an embedding of the phase space
dynamics into the chosen Euclidean state space. This embedding coincides with a
natural generalized synchronization that arises in this setup and that yields a
topological conjugacy between the state-space dynamics driven by the generic
observations of the dynamical system and the dynamical system itself. This
result provides additional tools for the representation, learning, and analysis
of chaotic attractors and sheds additional light on the reservoir computing
phenomenon that appears in the context of recurrent neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Pairwise Learning To Rank For Search Autocomplete. (arXiv:2108.04976v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1">Kai Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_D/0/1/0/all/0/1">Da Kuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04976">
                                    <div class="article-summary-box-inner">
                                        <span>Autocomplete (a.k.a &quot;Query Auto-Completion&quot;, &quot;AC&quot;) suggests full queries
based on a prefix typed by customer. Autocomplete has been a core feature of
commercial search engine. In this paper, we propose a novel context-aware
neural network based pairwise ranker (DeepPLTR) to improve AC ranking, DeepPLTR
leverages contextual and behavioral features to rank queries by minimizing a
pairwise loss, based on a fully-connected neural network structure. Compared to
LambdaMART ranker, DeepPLTR shows +3.90% MeanReciprocalRank (MRR) lift in
offline evaluation, and yielded +0.06% (p &lt; 0.1) Gross Merchandise Value (GMV)
lift in an Amazon&#x27;s online A/B experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple black-box universal adversarial attacks on medical image classification based on deep neural networks. (arXiv:2108.04979v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koga_K/0/1/0/all/0/1">Kazuki Koga</a>, <a href="http://arxiv.org/find/cs/1/au:+Takemoto_K/0/1/0/all/0/1">Kazuhiro Takemoto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04979">
                                    <div class="article-summary-box-inner">
                                        <span>Universal adversarial attacks, which hinder most deep neural network (DNN)
tasks using only a small single perturbation called a universal adversarial
perturbation (UAP), is a realistic security threat to the practical application
of a DNN. In particular, such attacks cause serious problems in medical
imaging. Given that computer-based systems are generally operated under a
black-box condition in which only queries on inputs are allowed and outputs are
accessible, the impact of UAPs seems to be limited because well-used algorithms
for generating UAPs are limited to a white-box condition in which adversaries
can access the model weights and loss gradients. Nevertheless, we demonstrate
that UAPs are easily generatable using a relatively small dataset under
black-box conditions. In particular, we propose a method for generating UAPs
using a simple hill-climbing search based only on DNN outputs and demonstrate
the validity of the proposed method using representative DNN-based medical
image classifications. Black-box UAPs can be used to conduct both non-targeted
and targeted attacks. Overall, the black-box UAPs showed high attack success
rates (40% to 90%), although some of them had relatively low success rates
because the method only utilizes limited information to generate UAPs. The
vulnerability of black-box UAPs was observed in several model architectures.
The results indicate that adversaries can also generate UAPs through a simple
procedure under the black-box condition to foil or control DNN-based medical
image diagnoses, and that UAPs are a more realistic security threat.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder. (arXiv:2108.05028v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Hanwen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1">Peng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Juwei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05028">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art (SOTA) few-shot learning (FSL) methods suffer significant
performance drop in the presence of domain differences between source and
target datasets. The strong discrimination ability on the source dataset does
not necessarily translate to high classification accuracy on the target
dataset. In this work, we address this cross-domain few-shot learning (CDFSL)
problem by boosting the generalization capability of the model. Specifically,
we teach the model to capture broader variations of the feature distributions
with a novel noise-enhanced supervised autoencoder (NSAE). NSAE trains the
model by jointly reconstructing inputs and predicting the labels of inputs as
well as their reconstructed pairs. Theoretical analysis based on intra-class
correlation (ICC) shows that the feature embeddings learned from NSAE have
stronger discrimination and generalization abilities in the target domain. We
also take advantage of NSAE structure and propose a two-step fine-tuning
procedure that achieves better adaption and improves classification performance
in the target domain. Extensive experiments and ablation studies are conducted
to demonstrate the effectiveness of the proposed method. Experimental results
show that our proposed method consistently outperforms SOTA methods under
various conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LightMove: A Lightweight Next-POI Recommendation for Taxicab Rooftop Advertising. (arXiv:2108.04993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1">Jinsung Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">Soyoung Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jo_M/0/1/0/all/0/1">Minju Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Seunghyeon Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1">Noseong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seonghoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chiyoung Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile digital billboards are an effective way to augment brand-awareness.
Among various such mobile billboards, taxicab rooftop devices are emerging in
the market as a brand new media. Motov is a leading company in South Korea in
the taxicab rooftop advertising market. In this work, we present a lightweight
yet accurate deep learning-based method to predict taxicabs&#x27; next locations to
better prepare for targeted advertising based on demographic information of
locations. Considering the fact that next POI recommendation datasets are
frequently sparse, we design our presented model based on neural ordinary
differential equations (NODEs), which are known to be robust to
sparse/incorrect input, with several enhancements. Our model, which we call
LightMove, has a larger prediction accuracy, a smaller number of parameters,
and/or a smaller training/inference time, when evaluating with various
datasets, in comparison with state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DQ-GAT: Towards Safe and Efficient Autonomous Driving with Deep Q-Learning and Graph Attention Networks. (arXiv:2108.05030v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1">Peide Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hengli Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05030">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous driving in multi-agent and dynamic traffic scenarios is
challenging, where the behaviors of other road agents are uncertain and hard to
model explicitly, and the ego-vehicle should apply complicated negotiation
skills with them to achieve both safe and efficient driving in various
settings, such as giving way, merging and taking turns. Traditional planning
methods are largely rule-based and scale poorly in these complex dynamic
scenarios, often leading to reactive or even overly conservative behaviors.
Therefore, they require tedious human efforts to maintain workability.
Recently, deep learning-based methods have shown promising results with better
generalization capability but less hand engineering effort. However, they are
either implemented with supervised imitation learning (IL) that suffers from
the dataset bias and distribution mismatch problems, or trained with deep
reinforcement learning (DRL) but focus on one specific traffic scenario. In
this work, we propose DQ-GAT to achieve scalable and proactive autonomous
driving, where graph attention-based networks are used to implicitly model
interactions, and asynchronous deep Q-learning is employed to train the network
end-to-end in an unsupervised manner. Extensive experiments through a
high-fidelity driving simulation show that our method can better trade-off
safety and efficiency in both seen and unseen scenarios, achieving higher goal
success rates than the baselines (at most 4.7$\times$) with comparable task
completion time. Demonstration videos are available at
https://caipeide.github.io/dq-gat/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Creutzfeldt-Jakob Disease Prediction Using Machine Learning Techniques. (arXiv:2108.04972v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhakta_A/0/1/0/all/0/1">Arnav Bhakta</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrne_C/0/1/0/all/0/1">Carolyn Byrne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04972">
                                    <div class="article-summary-box-inner">
                                        <span>Creutzfeldt-Jakob disease (CJD) is a rapidly progressive and fatal
neurodegenerative disease, that causes approximately 350 deaths in the United
States every year. In specific, it is a prion disease that is caused by a
misfolded prion protein, termed $PrP^{Sc}$, which is the infectious form of the
prion protein $PrP^{C}$. Rather than being recycled by the body, the $PrP^{Sc}$
aggregates in the brain as plaques, leading to neurodegeneration of surrounding
cells and the spongiform characteristics of the pathology. However, there has
been very little research done into factors that can affect one&#x27;s chances of
acquiring $PrP^{Sc}$. In this paper, Elastic Net Regression, Long Short-Term
Memory Recurrent Neural Network Architectures, and Random Forest have been used
to predict Creutzfeldt-Jakob Disease Levels in the United States. New variables
were created as data for the models to use on the basis of common factors that
are known to affect CJD, such as soil, food, and water quality. Based on the
root mean square error (RMSE), mean bias error (MBE), and mean absolute error
(MAE) values, the study reveals the high impact of unhealthy lifestyle choices,
CO$_{2}$ Levels, Pesticide Usage, and Potash K$_{2}$O Usage on CJD Levels. In
doing so, the study highlights new avenues of research for CJD prevention and
detection, as well as potential causes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Brief Review of Machine Learning Techniques for Protein Phosphorylation Sites Prediction. (arXiv:2108.04951v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Esmaili_F/0/1/0/all/0/1">Farzaneh Esmaili</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pourmirzaei_M/0/1/0/all/0/1">Mahdi Pourmirzaei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramazi_S/0/1/0/all/0/1">Shahin Ramazi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yavari_E/0/1/0/all/0/1">Elham Yavari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04951">
                                    <div class="article-summary-box-inner">
                                        <span>Reversible Post-Translational Modifications (PTMs) have vital roles in
extending the functional diversity of proteins and effect meaningfully the
regulation of protein functions in prokaryotic and eukaryotic organisms. PTMs
have happened as crucial molecular regulatory mechanisms that are utilized to
regulate diverse cellular processes. Nevertheless, among the most well-studied
PTMs can say mainly types of proteins are containing phosphorylation and
significant roles in many biological processes. Disorder in this modification
can be caused by multiple diseases including neurological disorders and
cancers. Therefore, it is necessary to predict the phosphorylation of target
residues in an uncharacterized amino acid sequence. Most experimental
techniques for predicting phosphorylation are time-consuming, costly, and
error-prone. By the way, computational methods have replaced these techniques.
These days, a vast amount of phosphorylation data is publicly accessible
through many online databases. In this study, at first, all datasets of PTMs
that include phosphorylation sites (p-sites) were comprehensively reviewed.
Furthermore, we showed that there are basically two main approaches for
phosphorylation prediction by machine learning: End-to-End and conventional. We
gave an overview for both of them. Also, we introduced 15 important feature
extraction techniques which mostly have been used for conventional machine
learning methods</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Multi-Resolution Attention with Linear Complexity. (arXiv:2108.04962v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yunpu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidl_T/0/1/0/all/0/1">Thomas Seidl</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04962">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have improved the state-of-the-art across numerous tasks in
sequence modeling. Besides the quadratic computational and memory complexity
w.r.t the sequence length, the self-attention mechanism only processes
information at the same scale, i.e., all attention heads are in the same
resolution, resulting in the limited power of the Transformer. To remedy this,
we propose a novel and efficient structure named Adaptive Multi-Resolution
Attention (AdaMRA for short), which scales linearly to sequence length in terms
of time and space. Specifically, we leverage a multi-resolution multi-head
attention mechanism, enabling attention heads to capture long-range contextual
information in a coarse-to-fine fashion. Moreover, to capture the potential
relations between query representation and clues of different attention
granularities, we leave the decision of which resolution of attention to use to
query, which further improves the model&#x27;s capacity compared to vanilla
Transformer. In an effort to reduce complexity, we adopt kernel attention
without degrading the performance. Extensive experiments on several benchmarks
demonstrate the effectiveness and efficiency of our model by achieving a
state-of-the-art performance-efficiency-memory trade-off. To facilitate AdaMRA
utilization by the scientific community, the code implementation will be made
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image-based Generator Architecture for Synthetic Image Refinement. (arXiv:2108.04957v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasser_A/0/1/0/all/0/1">Alex Nasser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04957">
                                    <div class="article-summary-box-inner">
                                        <span>Proposed are alternative generator architectures for Boundary Equilibrium
Generative Adversarial Networks, motivated by Learning from Simulated and
Unsupervised Images through Adversarial Training. It disentangles the need for
a noise-based latent space. The generator will operate mainly as a refiner
network to gain a photo-realistic presentation of the given synthetic images.
It also attempts to resolve the latent space&#x27;s poorly understood properties by
eliminating the need for noise injection and replacing it with an image-based
concept. The new flexible and simple generator architecture will also give the
power to control the trade-off between restrictive refinement and
expressiveness ability. Contrary to other available methods, this architecture
will not require a paired or unpaired dataset of real and synthetic images for
the training phase. Only a relatively small set of real images would suffice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Order Identification to Address Confounding: Binary Variables. (arXiv:2108.04947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1">Joe Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Inaoka_Y/0/1/0/all/0/1">Yusuke Inaoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04947">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers an extension of the linear non-Gaussian acyclic model
(LiNGAM) that determines the causal order among variables from a dataset when
the variables are expressed by a set of linear equations, including noise. In
particular, we assume that the variables are binary. The existing LiNGAM
assumes that no confounding is present, which is restrictive in practice. Based
on the concept of independent component analysis (ICA), this paper proposes an
extended framework in which the mutual information among the noises is
minimized. Another significant contribution is to reduce the realization of the
shortest path problem. The distance between each pair of nodes expresses an
associated mutual information value, and the path with the minimum sum (KL
divergence) is sought. Although $p!$ mutual information values should be
compared, this paper dramatically reduces the computation when no confounding
is present. The proposed algorithm finds the globally optimal solution, while
the existing locally greedily seek the order based on hypothesis testing. We
use the best estimator in the sense of Bayes/MDL that correctly detects
independence for mutual information estimation. Experiments using artificial
and actual data show that the proposed version of LiNGAM achieves significantly
better performance, particularly when confounding is present.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retiring Adult: New Datasets for Fair Machine Learning. (arXiv:2108.04884v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Frances Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1">Moritz Hardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1">John Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04884">
                                    <div class="article-summary-box-inner">
                                        <span>Although the fairness community has recognized the importance of data,
researchers in the area primarily rely on UCI Adult when it comes to tabular
data. Derived from a 1994 US Census survey, this dataset has appeared in
hundreds of research papers where it served as the basis for the development
and comparison of many algorithmic fairness interventions. We reconstruct a
superset of the UCI Adult data from available US Census sources and reveal
idiosyncrasies of the UCI Adult dataset that limit its external validity. Our
primary contribution is a suite of new datasets derived from US Census surveys
that extend the existing data ecosystem for research on fair machine learning.
We create prediction tasks relating to income, employment, health,
transportation, and housing. The data span multiple years and all states of the
United States, allowing researchers to study temporal shift and geographic
variation. We highlight a broad initial sweep of new empirical insights
relating to trade-offs between fairness criteria, performance of algorithmic
interventions, and the role of distribution shift based on our new datasets.
Our findings inform ongoing debates, challenge some existing narratives, and
point to future research directions. Our datasets are available at
https://github.com/zykls/folktables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models. (arXiv:2108.04949v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zehao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_C/0/1/0/all/0/1">Chong Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Songzi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Adekkanattu_P/0/1/0/all/0/1">Prakash Adekkanattu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_J/0/1/0/all/0/1">Jyotishman Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1">Thomas J. George</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_W/0/1/0/all/0/1">William R. Hogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04949">
                                    <div class="article-summary-box-inner">
                                        <span>Social and behavioral determinants of health (SBDoH) have important roles in
shaping people&#x27;s health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients&#x27; SBDoH factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal learning of quantum Hamiltonians from high-temperature Gibbs states. (arXiv:2108.04842v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Haah_J/0/1/0/all/0/1">Jeongwan Haah</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kothari_R/0/1/0/all/0/1">Robin Kothari</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04842">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of learning a Hamiltonian $H$ to precision
$\varepsilon$, supposing we are given copies of its Gibbs state
$\rho&#x3D;\exp(-\beta H)/\operatorname{Tr}(\exp(-\beta H))$ at a known inverse
temperature $\beta$. Anshu, Arunachalam, Kuwahara, and Soleimanifar (Nature
Physics, 2021) recently studied the sample complexity (number of copies of
$\rho$ needed) of this problem for geometrically local $N$-qubit Hamiltonians.
In the high-temperature (low $\beta$) regime, their algorithm has sample
complexity poly$(N, 1/\beta,1/\varepsilon)$ and can be implemented with
polynomial, but suboptimal, time complexity.

In this paper, we study the same question for a more general class of
Hamiltonians. We show how to learn the coefficients of a Hamiltonian to error
$\varepsilon$ with sample complexity $S &#x3D; O(\log N/(\beta\varepsilon)^{2})$ and
time complexity linear in the sample size, $O(S N)$. Furthermore, we prove a
matching lower bound showing that our algorithm&#x27;s sample complexity is optimal,
and hence our time complexity is also optimal.

In the appendix, we show that virtually the same algorithm can be used to
learn $H$ from a real-time evolution unitary $e^{-it H}$ in a small $t$ regime
with similar sample and time complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear approximability of two-layer neural networks: A comprehensive analysis based on spectral decay. (arXiv:2108.04964v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Long_J/0/1/0/all/0/1">Jihao Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1">Lei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04964">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a spectral-based approach to study the linear
approximation of two-layer neural networks. We first consider the case of
single neuron and show that the linear approximability, quantified by the
Kolmogorov width, is controlled by the eigenvalue decay of an associate kernel.
Then, we show that similar results also hold for two-layer neural networks.
This spectral-based approach allows us to obtain upper bounds, lower bounds,
and explicit hard examples in a united manner. In particular, these bounds
imply that for networks activated by smooth functions, restricting the norms of
inner-layer weights may significantly impair the expressiveness. By contrast,
for non-smooth activation functions, such as ReLU, the network expressiveness
is independent of the inner-layer weight norms. In addition, we prove that for
a family of non-smooth activation functions, including ReLU, approximating any
single neuron with random features suffers from the \emph{curse of
dimensionality}. This provides an explicit separation of expressiveness between
neural networks and random feature models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of ODE2VAE with Examples. (arXiv:2108.04899v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koyuncu_B/0/1/0/all/0/1">Batuhan Koyuncu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04899">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models aim to learn underlying distributions that generate
the observed data. Given the fact that the generative distribution may be
complex and intractable, deep latent variable models use probabilistic
frameworks to learn more expressive joint probability distributions over the
data and their low-dimensional hidden variables. Learning complex probability
distributions over sequential data without any supervision is a difficult task
for deep generative models. Ordinary Differential Equation Variational
Auto-Encoder (ODE2VAE) is a deep latent variable model that aims to learn
complex distributions over high-dimensional sequential data and their
low-dimensional representations. ODE2VAE infers continuous latent dynamics of
the high-dimensional input in a low-dimensional hierarchical latent space. The
hierarchical organization of the continuous latent space embeds a
physics-guided inductive bias in the model. In this paper, we analyze the
latent representations inferred by the ODE2VAE model over three different
physical motion datasets: bouncing balls, projectile motion, and simple
pendulum. Through our experiments, we explore the effects of the physics-guided
inductive bias of the ODE2VAE model over the learned dynamical latent
representations. We show that the model is able to learn meaningful latent
representations to an extent without any supervision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Distinction Between &quot;Conditional Average Treatment Effects&quot; (CATE) and &quot;Individual Treatment Effects&quot; (ITE) Under Ignorability Assumptions. (arXiv:2108.04939v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vegetabile_B/0/1/0/all/0/1">Brian G. Vegetabile</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04939">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen a swell in methods that focus on estimating
&quot;individual treatment effects&quot;. These methods are often focused on the
estimation of heterogeneous treatment effects under ignorability assumptions.
This paper hopes to draw attention to the fact that there is nothing
necessarily &quot;individual&quot; about such effects under ignorability assumptions and
isolating individual effects may require additional assumptions. Such
individual effects, more often than not, are more precisely described as
&quot;conditional average treatment effects&quot; and confusion between the two has the
potential to hinder advances in personalized and individualized effect
estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A data-driven peridynamic continuum model for upscaling molecular dynamics. (arXiv:2108.04883v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+You_H/0/1/0/all/0/1">Huaiqian You</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Yu_Y/0/1/0/all/0/1">Yue Yu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Silling_S/0/1/0/all/0/1">Stewart Silling</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+DElia_M/0/1/0/all/0/1">Marta D&#x27;Elia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04883">
                                    <div class="article-summary-box-inner">
                                        <span>Nonlocal models, including peridynamics, often use integral operators that
embed lengthscales in their definition. However, the integrands in these
operators are difficult to define from the data that are typically available
for a given physical system, such as laboratory mechanical property tests. In
contrast, molecular dynamics (MD) does not require these integrands, but it
suffers from computational limitations in the length and time scales it can
address. To combine the strengths of both methods and to obtain a
coarse-grained, homogenized continuum model that efficiently and accurately
captures materials&#x27; behavior, we propose a learning framework to extract, from
MD data, an optimal Linear Peridynamic Solid (LPS) model as a surrogate for MD
displacements. To maximize the accuracy of the learnt model we allow the
peridynamic influence function to be partially negative, while preserving the
well-posedness of the resulting model. To achieve this, we provide sufficient
well-posedness conditions for discretized LPS models with sign-changing
influence functions and develop a constrained optimization algorithm that
minimizes the equation residual while enforcing such solvability conditions.
This framework guarantees that the resulting model is mathematically
well-posed, physically consistent, and that it generalizes well to settings
that are different from the ones used during training. We illustrate the
efficacy of the proposed approach with several numerical tests for single layer
graphene. Our two-dimensional tests show the robustness of the proposed
algorithm on validation data sets that include thermal noise, different domain
shapes and external loadings, and discretizations substantially different from
the ones used for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuCoMiD: A Multitask Convolutional Learning Framework for miRNA-Disease Association Prediction. (arXiv:2108.04820v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Dong_T/0/1/0/all/0/1">Thi Ngan Dong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khosla_M/0/1/0/all/0/1">Megha Khosla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04820">
                                    <div class="article-summary-box-inner">
                                        <span>Growing evidence from recent studies implies that microRNA or miRNA could
serve as biomarkers in various complex human diseases. Since wet-lab
experiments are expensive and time-consuming, computational techniques for
miRNA-disease association prediction have attracted a lot of attention in
recent years. Data scarcity is one of the major challenges in building reliable
machine learning models. Data scarcity combined with the use of pre-calculated
hand-crafted input features has led to problems of overfitting and data
leakage.

We overcome the limitations of existing works by proposing a novel
multi-tasking convolution-based approach, which we refer to as MuCoMiD. MuCoMiD
allows automatic feature extraction while incorporating knowledge from 4
heterogeneous biological information sources (interactions between
miRNA/diseases and protein-coding genes (PCG), miRNA family information, and
disease ontology) in a multi-task setting which is a novel perspective and has
not been studied before. The use of multi-channel convolutions allows us to
extract expressive representations while keeping the model linear and,
therefore, simple. To effectively test the generalization capability of our
model, we construct large-scale experiments on standard benchmark datasets as
well as our proposed larger independent test sets and case studies. MuCoMiD
shows an improvement of at least 5% in 5-fold CV evaluation on HMDDv2.0 and
HMDDv3.0 datasets and at least 49% on larger independent test sets with unseen
miRNA and diseases over state-of-the-art approaches. We share our code for
reproducibility and future research at
https://git.l3s.uni-hannover.de/dong/cmtt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Excited state, non-adiabatic dynamics of large photoswitchable molecules using a chemically transferable machine learning potential. (arXiv:2108.04879v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Axelrod_S/0/1/0/all/0/1">Simon Axelrod</a>, <a href="http://arxiv.org/find/physics/1/au:+Shakhnovich_E/0/1/0/all/0/1">Eugene Shakhnovich</a>, <a href="http://arxiv.org/find/physics/1/au:+Gomez_Bombarelli_R/0/1/0/all/0/1">Rafael G&#xf3;mez-Bombarelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04879">
                                    <div class="article-summary-box-inner">
                                        <span>Light-induced chemical processes are ubiquitous in nature and have widespread
technological applications. For example, the photoisomerization of azobenzene
allows a drug with an azo scaffold to be activated with light. In principle,
photoswitches with useful reactive properties, such as high isomerization
yields, can be identified through virtual screening with reactive simulations.
In practice these simulations are rarely used for screening, since they require
hundreds of trajectories and expensive quantum chemical methods to account for
non-adiabatic excited state effects. Here we introduce a neural network
potential to accelerate such simulations for azobenzene derivatives. The model,
which is based on diabatic states, is called the \textit{diabatic artificial
neural network} (DANN). The network is six orders of magnitude faster than the
quantum chemistry method used for training. DANN is transferable to molecules
outside the training set, predicting quantum yields for unseen species that are
correlated with experiment. We use the model to virtually screen 3,100
hypothetical molecules, and identify several species with extremely high
quantum yields. Our results pave the way for fast and accurate virtual
screening of photoactive compounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flow-based SVDD for anomaly detection. (arXiv:2108.04907v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sendera_M/0/1/0/all/0/1">Marcin Sendera</a>, <a href="http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1">Marek &#x15a;mieja</a>, <a href="http://arxiv.org/find/cs/1/au:+Maziarka_L/0/1/0/all/0/1">&#x141;ukasz Maziarka</a>, <a href="http://arxiv.org/find/cs/1/au:+Struski_L/0/1/0/all/0/1">&#x141;ukasz Struski</a>, <a href="http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1">Przemys&#x142;aw Spurek</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1">Jacek Tabor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04907">
                                    <div class="article-summary-box-inner">
                                        <span>We propose FlowSVDD -- a flow-based one-class classifier for anomaly/outliers
detection that realizes a well-known SVDD principle using deep learning tools.
Contrary to other approaches to deep SVDD, the proposed model is instantiated
using flow-based models, which naturally prevents from collapsing of bounding
hypersphere into a single point. Experiments show that FlowSVDD achieves
comparable results to the current state-of-the-art methods and significantly
outperforms related deep SVDD methods on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection. (arXiv:2108.04867v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiaoran Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1">Riley Simmons-Edler</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daewon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jackel_L/0/1/0/all/0/1">Larry Jackel</a>, <a href="http://arxiv.org/find/cs/1/au:+Howard_R/0/1/0/all/0/1">Richard Howard</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04867">
                                    <div class="article-summary-box-inner">
                                        <span>Perceiving obstacles and avoiding collisions is fundamental to the safe
operation of a robot system, particularly when the robot must operate in highly
dynamic human environments. Proximity detection using on-robot sensors can be
used to avoid or mitigate impending collisions. However, existing proximity
sensing methods are orientation and placement dependent, resulting in blind
spots even with large numbers of sensors. In this paper, we introduce the
phenomenon of the Leaky Surface Wave (LSW), a novel sensing modality, and
present AuraSense, a proximity detection system using the LSW. AuraSense is the
first system to realize no-dead-spot proximity sensing for robot arms. It
requires only a single pair of piezoelectric transducers, and can easily be
applied to off-the-shelf robots with minimal modifications. We further
introduce a set of signal processing techniques and a lightweight neural
network to address the unique challenges in using the LSW for proximity
sensing. Finally, we demonstrate a prototype system consisting of a single
piezoelectric element pair on a robot manipulator, which validates our design.
We conducted several micro benchmark experiments and performed more than 2000
on-robot proximity detection trials with various potential robot arm materials,
colliding objects, approach patterns, and robot movement patterns. AuraSense
achieves 100% and 95.3% true positive proximity detection rates when the arm
approaches static and mobile obstacles respectively, with a true negative rate
over 99%, showing the real-world viability of this system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Consensus Representation Learning for Attributed Graph. (arXiv:2108.04822v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changshu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Liangjian Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1">Zhao Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1">Guangchun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Ling Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04822">
                                    <div class="article-summary-box-inner">
                                        <span>Attempting to fully exploit the rich information of topological structure and
node features for attributed graph, we introduce self-supervised learning
mechanism to graph representation learning and propose a novel Self-supervised
Consensus Representation Learning (SCRL) framework. In contrast to most
existing works that only explore one graph, our proposed SCRL method treats
graph from two perspectives: topology graph and feature graph. We argue that
their embeddings should share some common information, which could serve as a
supervisory signal. Specifically, we construct the feature graph of node
features via k-nearest neighbor algorithm. Then graph convolutional network
(GCN) encoders extract features from two graphs respectively. Self-supervised
loss is designed to maximize the agreement of the embeddings of the same node
in the topology graph and the feature graph. Extensive experiments on real
citation networks and social networks demonstrate the superiority of our
proposed SCRL over the state-of-the-art methods on semi-supervised node
classification task. Meanwhile, compared with its main competitors, SCRL is
rather efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-like feature explanation for tabular data. (arXiv:2108.04855v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Konstantinov_A/0/1/0/all/0/1">Andrei V. Konstantinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Utkin_L/0/1/0/all/0/1">Lev V. Utkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04855">
                                    <div class="article-summary-box-inner">
                                        <span>A new method for local and global explanation of the machine learning
black-box model predictions by tabular data is proposed. It is implemented as a
system called AFEX (Attention-like Feature EXplanation) and consisting of two
main parts. The first part is a set of the one-feature neural subnetworks which
aim to get a specific representation for every feature in the form of a basis
of shape functions. The subnetworks use shortcut connections with trainable
parameters to improve the network performance. The second part of AFEX produces
shape functions of features as the weighted sum of the basis shape functions
where weights are computed by using an attention-like mechanism. AFEX
identifies pairwise interactions between features based on pairwise
multiplications of shape functions corresponding to different features. A
modification of AFEX with incorporating an additional surrogate model which
approximates the black-box model is proposed. AFEX is trained end-to-end on a
whole dataset only once such that it does not require to train neural networks
again in the explanation stage. Numerical experiments with synthetic and real
data illustrate AFEX.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1">Andreas Madsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04840">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing (NLP) models have become increasingly more
complex and widespread. With recent developments in neural networks, a growing
concern is whether it is responsible to use these models. Concerns such as
safety and ethics can be partially addressed by providing explanations.
Furthermore, when models do fail, providing explanations is paramount for
accountability purposes. To this end, interpretability serves to provide these
explanations in terms that are understandable to humans. Central to what is
understandable is how explanations are communicated. Therefore, this survey
provides a categorization of how recent interpretability methods communicate
explanations and discusses the methods in depth. Furthermore, the survey
focuses on post-hoc methods, which provide explanations after a model is
learned and generally model-agnostic. A common concern for this class of
methods is whether they accurately reflect the model. Hence, how these post-hoc
methods are evaluated is discussed throughout the paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variable-Length Music Score Infilling via XLNet and Musically Specialized Positional Encoding. (arXiv:2108.05064v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chin-Jui Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chun-Yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05064">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a new self-attention based model for music score
infilling, i.e., to generate a polyphonic music sequence that fills in the gap
between given past and future contexts. While existing approaches can only fill
in a short segment with a fixed number of notes, or a fixed time span between
the past and future contexts, our model can infill a variable number of notes
(up to 128) for different time spans. We achieve so with three major technical
contributions. First, we adapt XLNet, an autoregressive model originally
proposed for unsupervised model pre-training, to music score infilling. Second,
we propose a new, musically specialized positional encoding called relative bar
encoding that better informs the model of notes&#x27; position within the past and
future context. Third, to capitalize relative bar encoding, we perform
look-ahead onset prediction to predict the onset of a note one time step before
predicting the other attributes of the note. We compare our proposed model with
two strong baselines and show that our model is superior in both objective and
subjective analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Sided Box Filter for Edge Preserving Image Smoothing. (arXiv:2108.05021v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1">Yuanhao Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05021">
                                    <div class="article-summary-box-inner">
                                        <span>Image smoothing is a fundamental task in signal processing. For such task,
box filter is well-known. However, box filter can not keep some features of the
signal, such as edges, corners and the jump in the step function. In this
paper, we present a one-sided box filter that can smooth the signal but keep
the discontinuous features in the signal. More specifically, we perform box
filter on eight one-sided windows, leading to a one-sided box filter that can
preserve corners and edges. Our filter inherits the constant $O(1)$
computational complexity of the original box filter with respect to the window
size and also the linear $O(N)$ computational complexity with respect to the
total number of samples. We performance several experiments to show the
efficiency and effectiveness of this filter. We further compare our filter with
other the-state-of-the-art edge preserving methods. Our filter can be deployed
in a large range of applications where the classical box filter is adopted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth Infused Binaural Audio Generation using Hierarchical Cross-Modal Attention. (arXiv:2108.04906v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parida_K/0/1/0/all/0/1">Kranti Kumar Parida</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Siddharth Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Matiyali_N/0/1/0/all/0/1">Neeraj Matiyali</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_G/0/1/0/all/0/1">Gaurav Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04906">
                                    <div class="article-summary-box-inner">
                                        <span>Binaural audio gives the listener the feeling of being in the recording place
and enhances the immersive experience if coupled with AR/VR. But the problem
with binaural audio recording is that it requires a specialized setup which is
not possible to fabricate within handheld devices as compared to traditional
mono audio that can be recorded with a single microphone. In order to overcome
this drawback, prior works have tried to uplift the mono recorded audio to
binaural audio as a post processing step conditioning on the visual input. But
all the prior approaches missed other most important information required for
the task, i.e. distance of different sound producing objects from the recording
setup. In this work, we argue that the depth map of the scene can act as a
proxy for encoding distance information of objects in the scene and show that
adding depth features along with image features improves the performance both
qualitatively and quantitatively. We propose a novel encoder-decoder
architecture, where we use a hierarchical attention mechanism to encode the
image and depth feature extracted from individual transformer backbone, with
audio features at each layer of the decoder.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-11">2021-08-11</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Robust Named Entity Understanding for Voice Assistants. (arXiv:2005.14408v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidharan_D/0/1/0/all/0/1">Deepak Muralidharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1">Joel Ruben Antony Moniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Sida Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kao_J/0/1/0/all/0/1">Justine Kao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1">Stephen Pulman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1">Atish Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1">Ray Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yinying Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_V/0/1/0/all/0/1">Vivek Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1">Mubarak Seyed Ibrahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_G/0/1/0/all/0/1">Gang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dun_N/0/1/0/all/0/1">Nan Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yidan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+O_A/0/1/0/all/0/1">Andy O</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitkara_P/0/1/0/all/0/1">Pooja Chitkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1">Alkesh Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tayal_K/0/1/0/all/0/1">Kushal Tayal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Roger Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Grasch_P/0/1/0/all/0/1">Peter Grasch</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Jason D. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.14408">
                                    <div class="article-summary-box-inner">
                                        <span>Named Entity Recognition (NER) and Entity Linking (EL) play an essential role
in voice assistant interaction, but are challenging due to the special
difficulties associated with spoken user queries. In this paper, we propose a
novel architecture that jointly solves the NER and EL tasks by combining them
in a joint reranking module. We show that our proposed framework improves NER
accuracy by up to 3.13% and EL accuracy by up to 3.6% in F1 score. The features
used also lead to better accuracies in other natural language understanding
tasks, such as domain classification and semantic parsing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Vaccine and Social Media: Exploring Emotions and Discussions on Twitter. (arXiv:2108.04816v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karami_A/0/1/0/all/0/1">Amir Karami</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Michael Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldschmidt_B/0/1/0/all/0/1">Bailey Goldschmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyajieff_H/0/1/0/all/0/1">Hannah R. Boyajieff</a>, <a href="http://arxiv.org/find/cs/1/au:+Najafabadi_M/0/1/0/all/0/1">Mahdi M. Najafabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04816">
                                    <div class="article-summary-box-inner">
                                        <span>Public response to COVID-19 vaccines is the key success factor to control the
COVID-19 pandemic. To understand the public response, there is a need to
explore public opinion. Traditional surveys are expensive and time-consuming,
address limited health topics, and obtain small-scale data. Twitter can provide
a great opportunity to understand public opinion regarding COVID-19 vaccines.
The current study proposes an approach using computational and human coding
methods to collect and analyze a large number of tweets to provide a wider
perspective on the COVID-19 vaccine. This study identifies the sentiment of
tweets and their temporal trend, discovers major topics, compares topics of
negative and non-negative tweets, and discloses top topics of negative and
non-negative tweets. Our findings show that the negative sentiment regarding
the COVID-19 vaccine had a decreasing trend between November 2020 and February
2021. We found Twitter users have discussed a wide range of topics from
vaccination sites to the 2020 U.S. election between November 2020 and February
2021. The findings show that there was a significant difference between
negative and non-negative tweets regarding the weight of most topics. Our
results also indicate that the negative and non-negative tweets had different
topic priorities and focuses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Zero Resource Speech Challenge 2021: Spoken language modelling. (arXiv:2104.14700v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dunbar_E/0/1/0/all/0/1">Ewan Dunbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernard_M/0/1/0/all/0/1">Mathieu Bernard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilakis_N/0/1/0/all/0/1">Nicolas Hamilakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tu Anh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Seyssel_M/0/1/0/all/0/1">Maureen de Seyssel</a>, <a href="http://arxiv.org/find/cs/1/au:+Roze_P/0/1/0/all/0/1">Patricia Roz&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Riviere_M/0/1/0/all/0/1">Morgane Rivi&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1">Emmanuel Dupoux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14700">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Zero Resource Speech Challenge 2021, which asks participants
to learn a language model directly from audio, without any text or labels. The
challenge is based on the Libri-light dataset, which provides up to 60k hours
of audio from English audio books without any associated text. We provide a
pipeline baseline system consisting on an encoder based on contrastive
predictive coding (CPC), a quantizer ($k$-means) and a standard language model
(BERT or LSTM). The metrics evaluate the learned representations at the
acoustic (ABX discrimination), lexical (spot-the-word), syntactic
(acceptability judgment) and semantic levels (similarity judgment). We present
an overview of the eight submitted systems from four groups and discuss the
main results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Headed Span-Based Projective Dependency Parsing. (arXiv:2108.04750v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Songlin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04750">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a headed span-based method for projective dependency parsing. In a
projective tree, the subtree rooted at each word occurs in a contiguous
sequence (i.e., span) in the surface order, we call the span-headword pair
\textit{headed span}. In this view, a projective tree can be regarded as a
collection of headed spans. It is similar to the case in constituency parsing
since a constituency tree can be regarded as a collection of constituent spans.
Span-based methods decompose the score of a constituency tree sorely into the
score of constituent spans and use the CYK algorithm for global training and
exact inference, obtaining state-of-the-art results in constituency parsing.
Inspired by them, we decompose the score of a dependency tree into the score of
headed spans. We use neural networks to score headed spans and design a novel
$O(n^3)$ dynamic programming algorithm to enable global training and exact
inference. We evaluate our method on PTB, CTB, and UD, achieving
state-of-the-art or comparable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting Incongruity-Based Features for Humor Recognition. (arXiv:2012.12007v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yubo Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_P/0/1/0/all/0/1">Pearl Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12007">
                                    <div class="article-summary-box-inner">
                                        <span>Humor recognition has been widely studied as a text classification problem
using data-driven approaches. However, most existing work does not examine the
actual joke mechanism to understand humor. We break down any joke into two
distinct components: the set-up and the punchline, and further explore the
special relationship between them. Inspired by the incongruity theory of humor,
we model the set-up as the part developing semantic uncertainty, and the
punchline disrupting audience expectations. With increasingly powerful language
models, we were able to feed the set-up along with the punchline into the GPT-2
language model, and calculate the uncertainty and surprisal values of the
jokes. By conducting experiments on the SemEval 2021 Task 7 dataset, we found
that these two features have better capabilities of telling jokes from
non-jokes, compared with existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning for Grounded Instruction Generation by Observing Human Following Behavior. (arXiv:2108.04812v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kojima_N/0/1/0/all/0/1">Noriyuki Kojima</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhr_A/0/1/0/all/0/1">Alane Suhr</a>, <a href="http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1">Yoav Artzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04812">
                                    <div class="article-summary-box-inner">
                                        <span>We study continual learning for natural language instruction generation, by
observing human users&#x27; instruction execution. We focus on a collaborative
scenario, where the system both acts and delegates tasks to human users using
natural language. We compare user execution of generated instructions to the
original system intent as an indication to the system&#x27;s success communicating
its intent. We show how to use this signal to improve the system&#x27;s ability to
generate instructions via contextual bandit learning. In interaction with real
users, our system demonstrates dramatic improvements in its ability to generate
language over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making Transformers Solve Compositional Tasks. (arXiv:2108.04378v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Onta%7Bn%7D%7Bo%7Dn_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1">Joshua Ainslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cvicek_V/0/1/0/all/0/1">Vaclav Cvicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisher_Z/0/1/0/all/0/1">Zachary Fisher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04378">
                                    <div class="article-summary-box-inner">
                                        <span>Several studies have reported the inability of Transformer models to
generalize compositionally, a key type of generalization in many NLP tasks such
as semantic parsing. In this paper we explore the design space of Transformer
models showing that the inductive biases given to the model by several design
decisions significantly impact compositional generalization. Through this
exploration, we identified Transformer configurations that generalize
compositionally significantly better than previously reported in the literature
in a diverse set of compositional tasks, and that achieve state-of-the-art
results in a semantic parsing compositional generalization benchmark (COGS),
and a string edit operation composition benchmark (PCFG).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hope Speech detection in under-resourced Kannada language. (arXiv:2108.04616v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1">Adeep Hande</a>, <a href="http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1">Ruba Priyadharshini</a>, <a href="http://arxiv.org/find/cs/1/au:+Sampath_A/0/1/0/all/0/1">Anbukkarasi Sampath</a>, <a href="http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1">Kingston Pal Thamburaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandran_P/0/1/0/all/0/1">Prabakaran Chandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04616">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous methods have been developed to monitor the spread of negativity in
modern years by eliminating vulgar, offensive, and fierce comments from social
media platforms. However, there are relatively lesser amounts of study that
converges on embracing positivity, reinforcing supportive and reassuring
content in online forums. Consequently, we propose creating an English-Kannada
Hope speech dataset, KanHope and comparing several experiments to benchmark the
dataset. The dataset consists of 6,176 user-generated comments in code mixed
Kannada scraped from YouTube and manually annotated as bearing hope speech or
Not-hope speech. In addition, we introduce DC-BERT4HOPE, a dual-channel model
that uses the English translation of KanHope for additional training to promote
hope speech detection. The approach achieves a weighted F1-score of 0.756,
bettering other models. Henceforth, KanHope aims to instigate research in
Kannada while broadly promoting researchers to take a pragmatic approach
towards online content that encourages, positive, and supportive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BROS: A Layout-Aware Pre-trained Language Model for Understanding Documents. (arXiv:2108.04539v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_T/0/1/0/all/0/1">Teakgyu Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_M/0/1/0/all/0/1">Mingi Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonseok Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nam_D/0/1/0/all/0/1">Daehyun Nam</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sungrae Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04539">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding documents from their visual snapshots is an emerging problem
that requires both advanced computer vision and NLP methods. The recent advance
in OCR enables the accurate recognition of text blocks, yet it is still
challenging to extract key information from documents due to the diversity of
their layouts. Although recent studies on pre-trained language models show the
importance of incorporating layout information on this task, the conjugation of
texts and their layouts still follows the style of BERT optimized for
understanding the 1D text. This implies there is room for further improvement
considering the 2D nature of text layouts. This paper introduces a pre-trained
language model, BERT Relying On Spatiality (BROS), which effectively utilizes
the information included in individual text blocks and their layouts.
Specifically, BROS encodes spatial information by utilizing relative positions
and learns spatial dependencies between OCR blocks with a novel area-masking
strategy. These two novel approaches lead to an efficient encoding of spatial
layout information highlighted by the robust performance of BROS under
low-resource environments. We also introduce a general-purpose parser that can
be combined with BROS to extract key information even when there is no order
information between text blocks. BROS shows its superiority on four public
benchmarks---FUNSD, SROIE*, CORD, and SciTSR---and its robustness in practical
cases where order information of text blocks is not available. Further
experiments with a varying number of training examples demonstrate the high
training efficiency of our approach. Our code will be open to the public.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">It&#x27;s not what you said, it&#x27;s how you said it: discriminative perception of speech as a multichannel communication system. (arXiv:2105.00260v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wallbridge_S/0/1/0/all/0/1">Sarenne Wallbridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Bell_P/0/1/0/all/0/1">Peter Bell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Catherine Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00260">
                                    <div class="article-summary-box-inner">
                                        <span>People convey information extremely effectively through spoken interaction
using multiple channels of information transmission: the lexical channel of
what is said, and the non-lexical channel of how it is said. We propose
studying human perception of spoken communication as a means to better
understand how information is encoded across these channels, focusing on the
question &#x27;What characteristics of communicative context affect listener&#x27;s
expectations of speech?&#x27;. To investigate this, we present a novel behavioural
task testing whether listeners can discriminate between the true utterance in a
dialogue and utterances sampled from other contexts with the same lexical
content. We characterize how perception - and subsequent discriminative
capability - is affected by different degrees of additional contextual
information across both the lexical and non-lexical channel of speech. Results
demonstrate that people can effectively discriminate between different prosodic
realisations, that non-lexical context is informative, and that this channel
provides more salient information than the lexical channel, highlighting the
importance of the non-lexical channel in spoken interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Commonsense Knowledge Helps with Natural Language Tasks: A Survey of Recent Resources and Methodologies. (arXiv:2108.04674v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yubo Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_P/0/1/0/all/0/1">Pearl Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04674">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we give an overview of commonsense reasoning in natural
language processing, which requires a deeper understanding of the contexts and
usually involves inference over implicit external knowledge. We first review
some popular commonsense knowledge bases and commonsense reasoning benchmarks,
but give more emphasis on the methodologies, including recent approaches that
aim at solving some general natural language problems that take advantage of
external knowledge bases. Finally, we discuss some future directions in pushing
the boundary of commonsense reasoning in natural language processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyEuroVoc: A Tool for Multilingual Legal Document Classification with EuroVoc Descriptors. (arXiv:2108.01139v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1">Andrei-Marius Avram</a>, <a href="http://arxiv.org/find/cs/1/au:+Pais_V/0/1/0/all/0/1">Vasile Pais</a>, <a href="http://arxiv.org/find/cs/1/au:+Tufis_D/0/1/0/all/0/1">Dan Tufis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01139">
                                    <div class="article-summary-box-inner">
                                        <span>EuroVoc is a multilingual thesaurus that was built for organizing the
legislative documentary of the European Union institutions. It contains
thousands of categories at different levels of specificity and its descriptors
are targeted by legal texts in almost thirty languages. In this work we propose
a unified framework for EuroVoc classification on 22 languages by fine-tuning
modern Transformer-based pretrained language models. We study extensively the
performance of our trained models and show that they significantly improve the
results obtained by a similar tool - JEX - on the same dataset. The code and
the fine-tuned models were open sourced, together with a programmatic interface
that eases the process of loading the weights of a trained model and of
classifying a new document.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMPARE: A Taxonomy and Dataset of Comparison Discussions in Peer Reviews. (arXiv:2108.04366v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shruti Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04366">
                                    <div class="article-summary-box-inner">
                                        <span>Comparing research papers is a conventional method to demonstrate progress in
experimental research. We present COMPARE, a taxonomy and a dataset of
comparison discussions in peer reviews of research papers in the domain of
experimental deep learning. From a thorough observation of a large set of
review sentences, we build a taxonomy of categories in comparison discussions
and present a detailed annotation scheme to analyze this. Overall, we annotate
117 reviews covering 1,800 sentences. We experiment with various methods to
identify comparison sentences in peer reviews and report a maximum F1 Score of
0.49. We also pretrain two language models specifically on ML, NLP, and CV
paper abstracts and reviews to learn informative representations of peer
reviews. The annotated dataset and the pretrained models are available at
https://github.com/shruti-singh/COMPARE .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FairyTailor: A Multimodal Generative Framework for Storytelling. (arXiv:2108.04324v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bensaid_E/0/1/0/all/0/1">Eden Bensaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Martino_M/0/1/0/all/0/1">Mauro Martino</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoover_B/0/1/0/all/0/1">Benjamin Hoover</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>, <a href="http://arxiv.org/find/cs/1/au:+Strobelt_H/0/1/0/all/0/1">Hendrik Strobelt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04324">
                                    <div class="article-summary-box-inner">
                                        <span>Storytelling is an open-ended task that entails creative thinking and
requires a constant flow of ideas. Natural language generation (NLG) for
storytelling is especially challenging because it requires the generated text
to follow an overall theme while remaining creative and diverse to engage the
reader. In this work, we introduce a system and a web-based demo, FairyTailor,
for human-in-the-loop visual story co-creation. Users can create a cohesive
children&#x27;s fairytale by weaving generated texts and retrieved images with their
input. FairyTailor adds another modality and modifies the text generation
process to produce a coherent and creative sequence of text and images. To our
knowledge, this is the first dynamic tool for multimodal story generation that
allows interactive co-formation of both texts and images. It allows users to
give feedback on co-created stories and share their results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lifelong Intent Detection via Multi-Strategy Rebalancing. (arXiv:2108.04445v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaoyan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shizhu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04445">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional Intent Detection (ID) models are usually trained offline, which
relies on a fixed dataset and a predefined set of intent classes. However, in
real-world applications, online systems usually involve continually emerging
new user intents, which pose a great challenge to the offline training
paradigm. Recently, lifelong learning has received increasing attention and is
considered to be the most promising solution to this challenge. In this paper,
we propose Lifelong Intent Detection (LID), which continually trains an ID
model on new data to learn newly emerging intents while avoiding
catastrophically forgetting old data. Nevertheless, we find that existing
lifelong learning methods usually suffer from a serious imbalance between old
and new data in the LID task. Therefore, we propose a novel lifelong learning
method, Multi-Strategy Rebalancing (MSR), which consists of cosine
normalization, hierarchical knowledge distillation, and inter-class margin loss
to alleviate the multiple negative effects of the imbalance problem.
Experimental results demonstrate the effectiveness of our method, which
significantly outperforms previous state-of-the-art lifelong learning methods
on the ATIS, SNIPS, HWU64, and CLINC150 benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Audio Captioning using Transfer Learning and Reconstruction Latent Space Similarity Regularization. (arXiv:2108.04692v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koh_A/0/1/0/all/0/1">Andrew Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Fuzhao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1">Eng Siong Chng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04692">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we examine the use of Transfer Learning using Pretrained Audio
Neural Networks (PANNs), and propose an architecture that is able to better
leverage the acoustic features provided by PANNs for the Automated Audio
Captioning Task. We also introduce a novel self-supervised objective,
Reconstruction Latent Space Similarity Regularization (RLSSR). The RLSSR module
supplements the training of the model by minimizing the similarity between the
encoder and decoder embedding. The combination of both methods allows us to
surpass state of the art results by a significant margin on the Clotho dataset
across several metrics and benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMUSED: An Annotation Framework of Multi-modal Social Media Data. (arXiv:2010.00502v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00502">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a semi-automated framework called AMUSED for
gathering multi-modal annotated data from the multiple social media platforms.
The framework is designed to mitigate the issues of collecting and annotating
social media data by cohesively combining machine and human in the data
collection process. From a given list of the articles from professional news
media or blog, AMUSED detects links to the social media posts from news
articles and then downloads contents of the same post from the respective
social media platform to gather details about that specific post. The framework
is capable of fetching the annotated data from multiple platforms like Twitter,
YouTube, Reddit. The framework aims to reduce the workload and problems behind
the data annotation from the social media platforms. AMUSED can be applied in
multiple application domains, as a use case, we have implemented the framework
for collecting COVID-19 misinformation data from different social media
platforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLSEBERT: Contrastive Learning for Syntax Enhanced Code Pre-Trained Model. (arXiv:2108.04556v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yasheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pingyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Meng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yadao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Li Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04556">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained models for programming languages have proven their significant
values in various code-related tasks, such as code search, code clone
detection, and code translation. Currently, most pre-trained models treat a
code snippet as a sequence of tokens or only focus on the data flow between
code identifiers. However, rich code syntax and hierarchy are ignored which can
provide important structure information and semantic rules of codes to help
enhance code representations. In addition, although the BERT-based code
pre-trained models achieve high performance on many downstream tasks, the
native derived sequence representations of BERT are proven to be of
low-quality, it performs poorly on code matching and similarity tasks. To
address these problems, we propose CLSEBERT, a Constrastive Learning Framework
for Syntax Enhanced Code Pre-Trained Model, to deal with various code
intelligence tasks. In the pre-training stage, we consider the code syntax and
hierarchy contained in the Abstract Syntax Tree (AST) and leverage the
constrastive learning to learn noise-invariant code representations. Besides
the masked language modeling (MLM), we also introduce two novel pre-training
objectives. One is to predict the edges between nodes in the abstract syntax
tree, and the other is to predict the types of code tokens. Through extensive
experiments on four code intelligence tasks, we successfully show the
effectiveness of our proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sampling-Based Minimum Bayes Risk Decoding for Neural Machine Translation. (arXiv:2108.04718v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eikema_B/0/1/0/all/0/1">Bryan Eikema</a>, <a href="http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1">Wilker Aziz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04718">
                                    <div class="article-summary-box-inner">
                                        <span>In neural machine translation (NMT), we search for the mode of the model
distribution to form predictions. The mode as well as other high probability
translations found by beam search have been shown to often be inadequate in a
number of ways. This prevents practitioners from improving translation quality
through better search, as these idiosyncratic translations end up being
selected by the decoding algorithm, a problem known as the beam search curse.
Recently, a sampling-based approximation to minimum Bayes risk (MBR) decoding
has been proposed as an alternative decision rule for NMT that would likely not
suffer from the same problems. We analyse this approximation and establish that
it has no equivalent to the beam search curse, i.e. better search always leads
to better translations. We also design different approximations aimed at
decoupling the cost of exploration from the cost of robust estimation of
expected utility. This allows for exploration of much larger hypothesis spaces,
which we show to be beneficial. We also show that it can be beneficial to make
use of strategies like beam search and nucleus sampling to construct hypothesis
spaces efficiently. We show on three language pairs (English into and from
German, Romanian, and Nepali) that MBR can improve upon beam search with
moderate computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Subset Pruning of Transformer Heads. (arXiv:2108.04657v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaoda Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04657">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-head attention, a collection of several attention mechanisms that
independently attend to different parts of the input, is the key ingredient in
the Transformer (Vaswaniet al., 2017). Recent work has shown, however, that a
large proportion of the heads in a Transformer&#x27;s multi-head attention mechanism
can be safely pruned away without significantly harming the performance of the
model; such pruning leads to models that are noticeably smaller and faster in
practice. Our work introduces a new head pruning technique that we term
differentiable subset pruning. Intuitively, our method learns per-head
importance variables and then enforces a user-specified hard constraint on the
number of unpruned heads. The importance variables are learned via stochastic
gradient descent. We conduct experiments on natural language inference and
machine translation; we show that differentiable subset pruning performs
comparably or better than Voita et al. (2019) while offering the same exact
control over the number of heads as Michel et al. (2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SnowflakeNet: Point Cloud Completion by Snowflake Point Deconvolution with Skip-Transformer. (arXiv:2108.04444v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_P/0/1/0/all/0/1">Peng Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1">Xin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Shen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yan-Pei Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1">Pengfei Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wen Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04444">
                                    <div class="article-summary-box-inner">
                                        <span>Point cloud completion aims to predict a complete shape in high accuracy from
its partial observation. However, previous methods usually suffered from
discrete nature of point cloud and unstructured prediction of points in local
regions, which makes it hard to reveal fine local geometric details on the
complete shape. To resolve this issue, we propose SnowflakeNet with Snowflake
Point Deconvolution (SPD) to generate the complete point clouds. The
SnowflakeNet models the generation of complete point clouds as the
snowflake-like growth of points in 3D space, where the child points are
progressively generated by splitting their parent points after each SPD. Our
insight of revealing detailed geometry is to introduce skip-transformer in SPD
to learn point splitting patterns which can fit local regions the best.
Skip-transformer leverages attention mechanism to summarize the splitting
patterns used in the previous SPD layer to produce the splitting in the current
SPD layer. The locally compact and structured point cloud generated by SPD is
able to precisely capture the structure characteristic of 3D shape in local
patches, which enables the network to predict highly detailed geometries, such
as smooth regions, sharp edges and corners. Our experimental results outperform
the state-of-the-art point cloud completion methods under widely used
benchmarks. Code will be available at
https://github.com/AllenXiangX/SnowflakeNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-domain Collaborative Feature Representation for Robust Visual Object Tracking. (arXiv:2108.04521v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1">Bo Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yingkai Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1">Baocai Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04521">
                                    <div class="article-summary-box-inner">
                                        <span>Jointly exploiting multiple different yet complementary domain information
has been proven to be an effective way to perform robust object tracking. This
paper focuses on effectively representing and utilizing complementary features
from the frame domain and event domain for boosting object tracking performance
in challenge scenarios. Specifically, we propose Common Features Extractor
(CFE) to learn potential common representations from the RGB domain and event
domain. For learning the unique features of the two domains, we utilize a
Unique Extractor for Event (UEE) based on Spiking Neural Networks to extract
edge cues in the event domain which may be missed in RGB in some challenging
conditions, and a Unique Extractor for RGB (UER) based on Deep Convolutional
Neural Networks to extract texture and semantic information in RGB domain.
Extensive experiments on standard RGB benchmark and real event tracking dataset
demonstrate the effectiveness of the proposed approach. We show our approach
outperforms all compared state-of-the-art tracking algorithms and verify
event-based data is a powerful cue for tracking in challenging scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Canonical 3D Object Representation for Fine-Grained Recognition. (arXiv:2108.04628v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joung_S/0/1/0/all/0/1">Sunghun Joung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungryong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1">Ig-Jae Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kwanghoon Sohn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04628">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for fine-grained object recognition that learns
to recover object variation in 3D space from a single image, trained on an
image collection without using any ground-truth 3D annotation. We accomplish
this by representing an object as a composition of 3D shape and its appearance,
while eliminating the effect of camera viewpoint, in a canonical configuration.
Unlike conventional methods modeling spatial variation in 2D images only, our
method is capable of reconfiguring the appearance feature in a canonical 3D
space, thus enabling the subsequent object classifier to be invariant under 3D
geometric variation. Our representation also allows us to go beyond existing
methods, by incorporating 3D shape variation as an additional cue for object
recognition. To learn the model without ground-truth 3D annotation, we deploy a
differentiable renderer in an analysis-by-synthesis framework. By incorporating
3D shape and appearance jointly in a deep representation, our method learns the
discriminative representation of the object and achieves competitive
performance on fine-grained image recognition and vehicle re-identification. We
also demonstrate that the performance of 3D shape reconstruction is improved by
learning fine-grained shape deformation in a boosting manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Camera Trajectory Forecasting with Trajectory Tensors. (arXiv:2108.04694v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Styles_O/0/1/0/all/0/1">Olly Styles</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_T/0/1/0/all/0/1">Tanaya Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1">Victor Sanchez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04694">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the problem of multi-camera trajectory forecasting (MCTF), which
involves predicting the trajectory of a moving object across a network of
cameras. While multi-camera setups are widespread for applications such as
surveillance and traffic monitoring, existing trajectory forecasting methods
typically focus on single-camera trajectory forecasting (SCTF), limiting their
use for such applications. Furthermore, using a single camera limits the
field-of-view available, making long-term trajectory forecasting impossible. We
address these shortcomings of SCTF by developing an MCTF framework that
simultaneously uses all estimated relative object locations from several
viewpoints and predicts the object&#x27;s future location in all possible
viewpoints. Our framework follows a Which-When-Where approach that predicts in
which camera(s) the objects appear and when and where within the camera views
they appear. To this end, we propose the concept of trajectory tensors: a new
technique to encode trajectories across multiple camera views and the
associated uncertainties. We develop several encoder-decoder MCTF models for
trajectory tensors and present extensive experiments on our own database
(comprising 600 hours of video data from 15 camera views) created particularly
for the MCTF task. Results show that our trajectory tensor models outperform
coordinate trajectory-based MCTF models and existing SCTF methods adapted for
MCTF. Code is available from: https://github.com/olly-styles/Trajectory-Tensors</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relation-aware Compositional Zero-shot Learning for Attribute-Object Pair Recognition. (arXiv:2108.04603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Ziwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_Y/0/1/0/all/0/1">Yongkang Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1">Mohan Kankanhalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04603">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel model for recognizing images with composite
attribute-object concepts, notably for composite concepts that are unseen
during model training. We aim to explore the three key properties required by
the task --- relation-aware, consistent, and decoupled --- to learn rich and
robust features for primitive concepts that compose attribute-object pairs. To
this end, we propose the Blocked Message Passing Network (BMP-Net). The model
consists of two modules. The concept module generates semantically meaningful
features for primitive concepts, whereas the visual module extracts visual
features for attributes and objects from input images. A message passing
mechanism is used in the concept module to capture the relations between
primitive concepts. Furthermore, to prevent the model from being biased towards
seen composite concepts and reduce the entanglement between attributes and
objects, we propose a blocking mechanism that equalizes the information
available to the model for both seen and unseen concepts. Extensive experiments
and ablation studies on two benchmarks show the efficacy of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MotionInput v2.0 supporting DirectX: A modular library of open-source gesture-based machine learning and computer vision methods for interacting and controlling existing software with a webcam. (arXiv:2108.04357v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kummen_A/0/1/0/all/0/1">Ashild Kummen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassan_A/0/1/0/all/0/1">Ali Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganeva_T/0/1/0/all/0/1">Teodora Ganeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qianying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaw_R/0/1/0/all/0/1">Robert Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratwatte_C/0/1/0/all/0/1">Chenuka Ratwatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Almazov_E/0/1/0/all/0/1">Emil Almazov</a>, <a href="http://arxiv.org/find/cs/1/au:+Visram_S/0/1/0/all/0/1">Sheena Visram</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_A/0/1/0/all/0/1">Andrew Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebire_N/0/1/0/all/0/1">Neil J Sebire</a>, <a href="http://arxiv.org/find/cs/1/au:+Stott_L/0/1/0/all/0/1">Lee Stott</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_Y/0/1/0/all/0/1">Yvonne Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_G/0/1/0/all/0/1">Graham Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamedally_D/0/1/0/all/0/1">Dean Mohamedally</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04357">
                                    <div class="article-summary-box-inner">
                                        <span>Touchless computer interaction has become an important consideration during
the COVID-19 pandemic period. Despite progress in machine learning and computer
vision that allows for advanced gesture recognition, an integrated collection
of such open-source methods and a user-customisable approach to utilising them
in a low-cost solution for touchless interaction in existing software is still
missing. In this paper, we introduce the MotionInput v2.0 application. This
application utilises published open-source libraries and additional gesture
definitions developed to take the video stream from a standard RGB webcam as
input. It then maps human motion gestures to input operations for existing
applications and games. The user can choose their own preferred way of
interacting from a series of motion types, including single and bi-modal hand
gesturing, full-body repetitive or extremities-based exercises, head and facial
movements, eye tracking, and combinations of the above. We also introduce a
series of bespoke gesture recognition classifications as DirectInput triggers,
including gestures for idle states, auto calibration, depth capture from a 2D
RGB webcam stream and tracking of facial motions such as mouth motions,
winking, and head direction with rotation. Three use case areas assisted the
development of the modules: creativity software, office and clinical software,
and gaming software. A collection of open-source libraries has been integrated
and provide a layer of modular gesture mapping on top of existing mouse and
keyboard controls in Windows via DirectX. With ease of access to webcams
integrated into most laptops and desktop computers, touchless computing becomes
more available with MotionInput v2.0, in a federated and locally processed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Metric Learning for Open World Semantic Segmentation. (arXiv:2108.04562v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cen_J/0/1/0/all/0/1">Jun Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_P/0/1/0/all/0/1">Peng Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Junhao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Michael Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04562">
                                    <div class="article-summary-box-inner">
                                        <span>Classical close-set semantic segmentation networks have limited ability to
detect out-of-distribution (OOD) objects, which is important for
safety-critical applications such as autonomous driving. Incrementally learning
these OOD objects with few annotations is an ideal way to enlarge the knowledge
base of the deep learning models. In this paper, we propose an open world
semantic segmentation system that includes two modules: (1) an open-set
semantic segmentation module to detect both in-distribution and OOD objects.
(2) an incremental few-shot learning module to gradually incorporate those OOD
objects into its existing knowledge base. This open world semantic segmentation
system behaves like a human being, which is able to identify OOD objects and
gradually learn them with corresponding supervision. We adopt the Deep Metric
Learning Network (DMLNet) with contrastive clustering to implement open-set
semantic segmentation. Compared to other open-set semantic segmentation
methods, our DMLNet achieves state-of-the-art performance on three challenging
open-set semantic segmentation datasets without using additional data or
generative models. On this basis, two incremental few-shot learning methods are
further proposed to progressively improve the DMLNet with the annotations of
OOD objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Method Towards CVPR 2021 Image Matching Challenge. (arXiv:2108.04453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1">Xiaopeng Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dehao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Ran Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1">Zheng Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haotian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04453">
                                    <div class="article-summary-box-inner">
                                        <span>This report describes Megvii-3D team&#x27;s approach towards CVPR 2021 Image
Matching Workshop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds. (arXiv:2108.04728v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chaoda Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiantao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Weibing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04728">
                                    <div class="article-summary-box-inner">
                                        <span>Current 3D single object tracking approaches track the target based on a
feature comparison between the target template and the search area. However,
due to the common occlusion in LiDAR scans, it is non-trivial to conduct
accurate feature comparisons on severe sparse and incomplete shapes. In this
work, we exploit the ground truth bounding box given in the first frame as a
strong cue to enhance the feature description of the target object, enabling a
more accurate feature comparison in a simple yet effective way. In particular,
we first propose the BoxCloud, an informative and robust representation, to
depict an object using the point-to-box relation. We further design an
efficient box-aware feature fusion module, which leverages the aforementioned
BoxCloud for reliable feature matching and embedding. Integrating the proposed
general components into an existing model P2B, we construct a superior
box-aware tracker (BAT). Experiments confirm that our proposed BAT outperforms
the previous state-of-the-art by a large margin on both KITTI and NuScenes
benchmarks, achieving a 12.8% improvement in terms of precision while running
~20% faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BIDCD - Bosch Industrial Depth Completion Dataset. (arXiv:2108.04706v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Botach_A/0/1/0/all/0/1">Adam Botach</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_Y/0/1/0/all/0/1">Yuri Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_Y/0/1/0/all/0/1">Yakov Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapiro_Y/0/1/0/all/0/1">Yoel Shapiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1">Dotan Di Castro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04706">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce BIDCD - the Bosch Industrial Depth Completion Dataset. BIDCD is
a new RGBD dataset of metallic industrial objects, collected with a depth
camera mounted on a robotic manipulator. The main purpose of this dataset is to
facilitate the training of domain-specific depth completion models, to be used
in logistics and manufacturing tasks. We trained a State-of-the-Art depth
completion model on this dataset, and report the results, setting an initial
benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Known Operator Learning and Hybrid Machine Learning in Medical Imaging --- A Review of the Past, the Present, and the Future. (arXiv:2108.04543v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1">Andreas Maier</a>, <a href="http://arxiv.org/find/cs/1/au:+Kostler_H/0/1/0/all/0/1">Harald K&#xf6;stler</a>, <a href="http://arxiv.org/find/cs/1/au:+Heisig_M/0/1/0/all/0/1">Marco Heisig</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauss_P/0/1/0/all/0/1">Patrick Krauss</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seung Hee Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04543">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we perform a review of the state-of-the-art of hybrid
machine learning in medical imaging. We start with a short summary of the
general developments of the past in machine learning and how general and
specialized approaches have been in competition in the past decades. A
particular focus will be the theoretical and experimental evidence pro and
contra hybrid modelling. Next, we inspect several new developments regarding
hybrid machine learning with a particular focus on so-called known operator
learning and how hybrid approaches gain more and more momentum across
essentially all applications in medical imaging and medical image analysis. As
we will point out by numerous examples, hybrid models are taking over in image
reconstruction and analysis. Even domains such as physical simulation and
scanner and acquisition design are being addressed using machine learning grey
box modelling approaches. Towards the end of the article, we will investigate a
few future directions and point out relevant areas in which hybrid modelling,
meta learning, and other domains will likely be able to drive the
state-of-the-art ahead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Breast Cancer Classification: Enhanced Tangent Function. (arXiv:2108.04663v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thapa_A/0/1/0/all/0/1">Ashu Thapa</a>, <a href="http://arxiv.org/find/eess/1/au:+Alsadoon_A/0/1/0/all/0/1">Abeer Alsadoon</a>, <a href="http://arxiv.org/find/eess/1/au:+Prasad_P/0/1/0/all/0/1">P.W.C. Prasad</a>, <a href="http://arxiv.org/find/eess/1/au:+Bajaj_S/0/1/0/all/0/1">Simi Bajaj</a>, <a href="http://arxiv.org/find/eess/1/au:+Alsadoon_O/0/1/0/all/0/1">Omar Hisham Alsadoon</a>, <a href="http://arxiv.org/find/eess/1/au:+Rashid_T/0/1/0/all/0/1">Tarik A. Rashid</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_R/0/1/0/all/0/1">Rasha S. Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Jerew_O/0/1/0/all/0/1">Oday D. Jerew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04663">
                                    <div class="article-summary-box-inner">
                                        <span>Background and Aim: Recently, deep learning using convolutional neural
network has been used successfully to classify the images of breast cells
accurately. However, the accuracy of manual classification of those
histopathological images is comparatively low. This research aims to increase
the accuracy of the classification of breast cancer images by utilizing a
Patch-Based Classifier (PBC) along with deep learning architecture.
Methodology: The proposed system consists of a Deep Convolutional Neural
Network (DCNN) that helps in enhancing and increasing the accuracy of the
classification process. This is done by the use of the Patch-based Classifier
(PBC). CNN has completely different layers where images are first fed through
convolutional layers using hyperbolic tangent function together with the
max-pooling layer, drop out layers, and SoftMax function for classification.
Further, the output obtained is fed to a patch-based classifier that consists
of patch-wise classification output followed by majority voting. Results: The
results are obtained throughout the classification stage for breast cancer
images that are collected from breast-histology datasets. The proposed solution
improves the accuracy of classification whether or not the images had normal,
benign, in-situ, or invasive carcinoma from 87% to 94% with a decrease in
processing time from 0.45 s to 0.2s on average. Conclusion: The proposed
solution focused on increasing the accuracy of classifying cancer in the breast
by enhancing the image contrast and reducing the vanishing gradient. Finally,
this solution for the implementation of the Contrast Limited Adaptive Histogram
Equalization (CLAHE) technique and modified tangent function helps in
increasing the accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TrUMAn: Trope Understanding in Movies and Animations. (arXiv:2108.04542v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_P/0/1/0/all/0/1">Po-Wei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_B/0/1/0/all/0/1">Bing-Chen Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wen-Feng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Ke-Jyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04542">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding and comprehending video content is crucial for many real-world
applications such as search and recommendation systems. While recent progress
of deep learning has boosted performance on various tasks using visual cues,
deep cognition to reason intentions, motivation, or causality remains
challenging. Existing datasets that aim to examine video reasoning capability
focus on visual signals such as actions, objects, relations, or could be
answered utilizing text bias. Observing this, we propose a novel task, along
with a new dataset: Trope Understanding in Movies and Animations (TrUMAn),
intending to evaluate and develop learning systems beyond visual signals.
Tropes are frequently used storytelling devices for creative works. By coping
with the trope understanding task and enabling the deep cognition skills of
machines, we are optimistic that data mining applications and algorithms could
be taken to the next level. To tackle the challenging TrUMAn dataset, we
present a Trope Understanding and Storytelling (TrUSt) with a new Conceptual
Storyteller module, which guides the video encoder by performing video
storytelling on a latent space. The generated story embedding is then fed into
the trope understanding model to provide further signals. Experimental results
demonstrate that state-of-the-art learning systems on existing tasks reach only
12.01% of accuracy with raw input signals. Also, even in the oracle case with
human-annotated descriptions, BERT contextual embedding achieves at most 28% of
accuracy. Our proposed TrUSt boosts the model performance and reaches 13.94%
performance. We also provide detailed analysis topave the way for future
research. TrUMAn is publicly available
at:https://www.cmlab.csie.ntu.edu.tw/project/trope</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hand Pose Classification Based on Neural Networks. (arXiv:2108.04529v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1">Rashmi Bakshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04529">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, deep learning models are applied to a segment of a robust
hand-washing dataset that has been created with the help of 30 volunteers. This
work demonstrates the classification of presence of one hand, two hands and no
hand in the scene based on transfer learning. The pre-trained model; simplest
NN from Keras library is utilized to train the network with 704 images of hand
gestures and the predictions are carried out for the input image. Due to the
controlled and restricted dataset, 100% accuracy is achieved during the
training with correct predictions for the input image. Complete handwashing
dataset with dense models such as AlexNet for video classification for hand
hygiene stages will be used in the future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Multi-Object Detection and Tracking with Camera-LiDAR Fusion for Autonomous Driving. (arXiv:2108.04602v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kemiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Q/0/1/0/all/0/1">Qi Hao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04602">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-object tracking (MOT) with camera-LiDAR fusion demands accurate results
of object detection, affinity computation and data association in real time.
This paper presents an efficient multi-modal MOT framework with online joint
detection and tracking schemes and robust data association for autonomous
driving applications. The novelty of this work includes: (1) development of an
end-to-end deep neural network for joint object detection and correlation using
2D and 3D measurements; (2) development of a robust affinity computation module
to compute occlusion-aware appearance and motion affinities in 3D space; (3)
development of a comprehensive data association module for joint optimization
among detection confidences, affinities and start-end probabilities. The
experiment results on the KITTI tracking benchmark demonstrate the superior
performance of the proposed method in terms of both tracking accuracy and
processing speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASMR: Learning Attribute-Based Person Search with Adaptive Semantic Margin Regularizer. (arXiv:2108.04533v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeong_B/0/1/0/all/0/1">Boseung Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jicheol Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1">Suha Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04533">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute-based person search is the task of finding person images that are
best matched with a set of text attributes given as query. The main challenge
of this task is the large modality gap between attributes and images. To reduce
the gap, we present a new loss for learning cross-modal embeddings in the
context of attribute-based person search. We regard a set of attributes as a
category of people sharing the same traits. In a joint embedding space of the
two modalities, our loss pulls images close to their person categories for
modality alignment. More importantly, it pushes apart a pair of person
categories by a margin determined adaptively by their semantic distance, where
the distance metric is learned end-to-end so that the loss considers importance
of each attribute when relating person categories. Our loss guided by the
adaptive semantic margin leads to more discriminative and semantically
well-arranged distributions of person images. As a consequence, it enables a
simple embedding model to achieve state-of-the-art records on public benchmarks
without bells and whistles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">White blood cell subtype detection and classification. (arXiv:2108.04614v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Praveen_N/0/1/0/all/0/1">Nalla Praveen</a>, <a href="http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1">Narinder Singh Punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04614">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning has endless applications in the health care industry. White
blood cell classification is one of the interesting and promising area of
research. The classification of the white blood cells plays an important part
in the medical diagnosis. In practise white blood cell classification is
performed by the haematologist by taking a small smear of blood and careful
examination under the microscope. The current procedures to identify the white
blood cell subtype is more time taking and error-prone. The computer aided
detection and diagnosis of the white blood cells tend to avoid the human error
and reduce the time taken to classify the white blood cells. In the recent
years several deep learning approaches have been developed in the context of
classification of the white blood cells that are able to identify but are
unable to localize the positions of white blood cells in the blood cell image.
Following this, the present research proposes to utilize YOLOv3 object
detection technique to localize and classify the white blood cells with
bounding boxes. With exhaustive experimental analysis, the proposed work is
found to detect the white blood cell with 99.2% accuracy and classify with 90%
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Reverse Image Search Engine for NASAWorldview. (arXiv:2108.04479v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sodani_A/0/1/0/all/0/1">Abhigya Sodani</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_M/0/1/0/all/0/1">Michael Levy</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1">Meher Anand Kasam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04479">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers often spend weeks sifting through decades of unlabeled satellite
imagery(on NASA Worldview) in order to develop datasets on which they can start
conducting research. We developed an interactive, scalable and fast image
similarity search engine (which can take one or more images as the query image)
that automatically sifts through the unlabeled dataset reducing dataset
generation time from weeks to minutes. In this work, we describe key components
of the end to end pipeline. Our similarity search system was created to be able
to identify similar images from a potentially petabyte scale database that are
similar to an input image, and for this we had to break down each query image
into its features, which were generated by a classification layer stripped CNN
trained in a supervised manner. To store and search these features efficiently,
we had to make several scalability improvements. To improve the speed, reduce
the storage, and shrink memory requirements for embedding search, we add a
fully connected layer to our CNN make all images into a 128 length vector
before entering the classification layers. This helped us compress the size of
our image features from 2048 (for ResNet, which was initially tried as our
featurizer) to 128 for our new custom model. Additionally, we utilize existing
approximate nearest neighbor search libraries to significantly speed up
embedding search. Our system currently searches over our entire database of
images at 5 seconds per query on a single virtual machine in the cloud. In the
future, we would like to incorporate a SimCLR based featurizing model which
could be trained without any labelling by a human (since the classification
aspect of the model is irrelevant to this use case).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CPNet: Cross-Parallel Network for Efficient Anomaly Detection. (arXiv:2108.04454v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Youngsaeng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">David Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1">Hanseok Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04454">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection in video streams is a challengingproblem because of the
scarcity of abnormal events andthe difficulty of accurately annotating them.To
allevi-ate these issues, unsupervised learning-based predictionmethods have
been previously applied. These approachestrain the model with only normal
events and predict a fu-ture frame from a sequence of preceding frames by use
ofencoder-decoder architectures so that they result in smallprediction errors
on normal events but large errors on ab-normal events. The architecture,
however, comes with thecomputational burden as some anomaly detection tasks
re-quire low computational cost without sacrificing perfor-mance. In this
paper, Cross-Parallel Network (CPNet) forefficient anomaly detection is
proposed here to minimizecomputations without performance drops. It consists
ofNsmaller parallel U-Net, each of which is designed to handlea single input
frame, to make the calculations significantlymore efficient. Additionally, an
inter-network shift moduleis incorporated to capture temporal relationships
among se-quential frames to enable more accurate future predictions.The
quantitative results show that our model requires lesscomputational cost than
the baseline U-Net while deliver-ing equivalent performance in anomaly
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Iterative Self-consistent Parallel Magnetic Resonance Imaging Reconstruction based on Nonlocal Low-Rank Regularization. (arXiv:2108.04517v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_T/0/1/0/all/0/1">Ting Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jizhong Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04517">
                                    <div class="article-summary-box-inner">
                                        <span>Iterative self-consistent parallel imaging reconstruction (SPIRiT) is an
effective self-calibrated reconstruction model for parallel magnetic resonance
imaging (PMRI). The joint L1 norm of wavelet coefficients and joint total
variation (TV) regularization terms are incorporated into the SPIRiT model to
improve the reconstruction performance. The simultaneous two-directional
low-rankness (STDLR) in k-space data is incorporated into SPIRiT to realize
improved reconstruction. Recent methods have exploited the nonlocal
self-similarity (NSS) of images by imposing nonlocal low-rankness of similar
patches to achieve a superior performance. To fully utilize both the NSS in
Magnetic resonance (MR) images and calibration consistency in the k-space
domain, we propose a nonlocal low-rank (NLR)-SPIRiT model by incorporating NLR
regularization into the SPIRiT model. We apply the weighted nuclear norm (WNN)
as a surrogate of the rank and employ the Nash equilibrium (NE) formulation and
alternating direction method of multipliers (ADMM) to efficiently solve the
NLR-SPIRiT model. The experimental results demonstrate the superior performance
of NLR-SPIRiT over the state-of-the-art methods via three objective metrics and
visual comparison.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised classification of radiology images with NoTeacher: A Teacher that is not Mean. (arXiv:2108.04423v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Unnikrishnan_B/0/1/0/all/0/1">Balagopal Unnikrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaram_S/0/1/0/all/0/1">Shafa Balaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Foo_C/0/1/0/all/0/1">Chuan Sheng Foo</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnaswamy_P/0/1/0/all/0/1">Pavitra Krishnaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04423">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models achieve strong performance for radiology image
classification, but their practical application is bottlenecked by the need for
large labeled training datasets. Semi-supervised learning (SSL) approaches
leverage small labeled datasets alongside larger unlabeled datasets and offer
potential for reducing labeling cost. In this work, we introduce NoTeacher, a
novel consistency-based SSL framework which incorporates probabilistic
graphical models. Unlike Mean Teacher which maintains a teacher network updated
via a temporal ensemble, NoTeacher employs two independent networks, thereby
eliminating the need for a teacher network. We demonstrate how NoTeacher can be
customized to handle a range of challenges in radiology image classification.
Specifically, we describe adaptations for scenarios with 2D and 3D inputs, uni
and multi-label classification, and class distribution mismatch between labeled
and unlabeled portions of the training data. In realistic empirical evaluations
on three public benchmark datasets spanning the workhorse modalities of
radiology (X-Ray, CT, MRI), we show that NoTeacher achieves over 90-95% of the
fully supervised AUROC with less than 5-15% labeling budget. Further, NoTeacher
outperforms established SSL methods with minimal hyperparameter tuning, and has
implications as a principled and practical option for semisupervised learning
in radiology applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FoodLogoDet-1500: A Dataset for Large-Scale Food Logo Detection via Multi-Scale Feature Decoupling Network. (arXiv:2108.04644v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1">Qiang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_W/0/1/0/all/0/1">Weiqing Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_S/0/1/0/all/0/1">Sujuan Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yuanjie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shuqiang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04644">
                                    <div class="article-summary-box-inner">
                                        <span>Food logo detection plays an important role in the multimedia for its wide
real-world applications, such as food recommendation of the self-service shop
and infringement detection on e-commerce platforms. A large-scale food logo
dataset is urgently needed for developing advanced food logo detection
algorithms. However, there are no available food logo datasets with food brand
information. To support efforts towards food logo detection, we introduce the
dataset FoodLogoDet-1500, a new large-scale publicly available food logo
dataset, which has 1,500 categories, about 100,000 images and about 150,000
manually annotated food logo objects. We describe the collection and annotation
process of FoodLogoDet-1500, analyze its scale and diversity, and compare it
with other logo datasets. To the best of our knowledge, FoodLogoDet-1500 is the
first largest publicly available high-quality dataset for food logo detection.
The challenge of food logo detection lies in the large-scale categories and
similarities between food logo categories. For that, we propose a novel food
logo detection method Multi-scale Feature Decoupling Network (MFDNet), which
decouples classification and regression into two branches and focuses on the
classification branch to solve the problem of distinguishing multiple food logo
categories. Specifically, we introduce the feature offset module, which
utilizes the deformation-learning for optimal classification offset and can
effectively obtain the most representative features of classification in
detection. In addition, we adopt a balanced feature pyramid in MFDNet, which
pays attention to global information, balances the multi-scale feature maps,
and enhances feature extraction capability. Comprehensive experiments on
FoodLogoDet-1500 and other two benchmark logo datasets demonstrate the
effectiveness of the proposed method. The FoodLogoDet-1500 can be found at this
https URL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facial Behavior Analysis using 4D Curvature Statistics for Presentation Attack Detection. (arXiv:1910.06056v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thummel_M/0/1/0/all/0/1">Martin Th&#xfc;mmel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sickert_S/0/1/0/all/0/1">Sven Sickert</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.06056">
                                    <div class="article-summary-box-inner">
                                        <span>The human face has a high potential for biometric identification due to its
many individual traits. At the same time, such identification is vulnerable to
biometric copies. These presentation attacks pose a great challenge in
unsupervised authentication settings. As a countermeasure, we propose a method
that automatically analyzes the plausibility of facial behavior based on a
sequence of 3D face scans. A compact feature representation measures facial
behavior using the temporal curvature change. Finally, we train our method only
on genuine faces in an anomaly detection scenario. Our method can detect
presentation attacks using elastic 3D masks, bent photographs with eye holes,
and monitor replay-attacks. For evaluation, we recorded a challenging database
containing such cases using a high-quality 3D sensor. It features 109 4D face
scans including eleven different types of presentation attacks. We achieve
error rates of 11% and 6% for APCER and BPCER, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multi-Granular Spatio-Temporal Graph Network for Skeleton-based Action Recognition. (arXiv:2108.04536v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tailin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Desen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04536">
                                    <div class="article-summary-box-inner">
                                        <span>The task of skeleton-based action recognition remains a core challenge in
human-centred scene understanding due to the multiple granularities and large
variation in human motion. Existing approaches typically employ a single neural
representation for different motion patterns, which has difficulty in capturing
fine-grained action classes given limited training data. To address the
aforementioned problems, we propose a novel multi-granular spatio-temporal
graph network for skeleton-based action classification that jointly models the
coarse- and fine-grained skeleton motion patterns. To this end, we develop a
dual-head graph network consisting of two interleaved branches, which enables
us to extract features at two spatio-temporal resolutions in an effective and
efficient manner. Moreover, our network utilises a cross-head communication
strategy to mutually enhance the representations of both heads. We conducted
extensive experiments on three large-scale datasets, namely NTU RGB+D 60, NTU
RGB+D 120, and Kinetics-Skeleton, and achieves the state-of-the-art performance
on all the benchmarks, which validates the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Gibson Benchmark (iGibson 0.5): A Benchmark for Interactive Navigation in Cluttered Environments. (arXiv:1910.14442v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">William B. Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasimbeg_P/0/1/0/all/0/1">Priya Kasimbeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_M/0/1/0/all/0/1">Micael Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1">Alexander Toshev</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.14442">
                                    <div class="article-summary-box-inner">
                                        <span>We present Interactive Gibson Benchmark, the first comprehensive benchmark
for training and evaluating Interactive Navigation: robot navigation strategies
where physical interaction with objects is allowed and even encouraged to
accomplish a task. For example, the robot can move objects if needed in order
to clear a path leading to the goal location. Our benchmark comprises two novel
elements: 1) a new experimental setup, the Interactive Gibson Environment
(iGibson 0.5), which simulates high fidelity visuals of indoor scenes, and high
fidelity physical dynamics of the robot and common objects found in these
scenes; 2) a set of Interactive Navigation metrics which allows one to study
the interplay between navigation and physical interaction. We present and
evaluate multiple learning-based baselines in Interactive Gibson, and provide
insights into regimes of navigation with different trade-offs between
navigation path efficiency and disturbance of surrounding objects. We make our
benchmark publicly
available(https://sites.google.com/view/interactivegibsonenv) and encourage
researchers from all disciplines in robotics (e.g. planning, learning, control)
to propose, evaluate, and compare their Interactive Navigation solutions in
Interactive Gibson.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Machine Learning Techniques for Detecting and Diagnosing COVID-19 from Imaging. (arXiv:2108.04344v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panday_A/0/1/0/all/0/1">Aishwarza Panday</a>, <a href="http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1">Muhammad Ashad Kabir</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1">Nihad Karim Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04344">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the limited availability and high cost of the reverse
transcription-polymerase chain reaction (RT-PCR) test, many studies have
proposed machine learning techniques for detecting COVID-19 from medical
imaging. The purpose of this study is to systematically review, assess, and
synthesize research articles that have used different machine learning
techniques to detect and diagnose COVID-19 from chest X-ray and CT scan images.
A structured literature search was conducted in the relevant bibliographic
databases to ensure that the survey solely centered on reproducible and
high-quality research. We selected papers based on our inclusion criteria. In
this survey, we reviewed $98$ articles that fulfilled our inclusion criteria.
We have surveyed a complete pipeline of chest imaging analysis techniques
related to COVID-19, including data collection, pre-processing, feature
extraction, classification, and visualization. We have considered CT scans and
X-rays as both are widely used to describe the latest developments in medical
imaging to detect COVID-19. This survey provides researchers with valuable
insights into different machine learning techniques and their performance in
the detection and diagnosis of COVID-19 from chest imaging. At the end, the
challenges and limitations in detecting COVID-19 using machine learning
techniques and the future direction of research are discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-repository of screening mammography classifiers. (arXiv:2108.04800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stadnick_B/0/1/0/all/0/1">Benjamin Stadnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Witowski_J/0/1/0/all/0/1">Jan Witowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajiv_V/0/1/0/all/0/1">Vishwaesh Rajiv</a>, <a href="http://arxiv.org/find/cs/1/au:+Chledowski_J/0/1/0/all/0/1">Jakub Ch&#x142;&#x119;dowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamout_F/0/1/0/all/0/1">Farah E. Shamout</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1">Krzysztof J. Geras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04800">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial intelligence (AI) is transforming medicine and showing promise in
improving clinical diagnosis. In breast cancer screening, several recent
studies show that AI has the potential to improve radiologists&#x27; accuracy,
subsequently helping in early cancer diagnosis and reducing unnecessary workup.
As the number of proposed models and their complexity grows, it is becoming
increasingly difficult to re-implement them in order to reproduce the results
and to compare different approaches. To enable reproducibility of research in
this application area and to enable comparison between different methods, we
release a meta-repository containing deep learning models for classification of
screening mammograms. This meta-repository creates a framework that enables the
evaluation of machine learning models on any private or public screening
mammography data set. At its inception, our meta-repository contains five
state-of-the-art models with open-source implementations and cross-platform
compatibility. We compare their performance on five international data sets:
two private New York University breast cancer screening data sets as well as
three public (DDSM, INbreast and Chinese Mammography Database) data sets. Our
framework has a flexible design that can be generalized to other medical image
analysis tasks. The meta-repository is available at
https://www.github.com/nyukat/mammography_metarepository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U-Net-and-a-half: Convolutional network for biomedical image segmentation using multiple expert-driven annotations. (arXiv:2108.04658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kers_J/0/1/0/all/0/1">Jesper Kers</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassol_C/0/1/0/all/0/1">Clarissa A. Cassol</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_J/0/1/0/all/0/1">Joris J. Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Idrees_N/0/1/0/all/0/1">Najia Idrees</a>, <a href="http://arxiv.org/find/cs/1/au:+Farber_A/0/1/0/all/0/1">Alik Farber</a>, <a href="http://arxiv.org/find/cs/1/au:+Haroon_S/0/1/0/all/0/1">Samir Haroon</a>, <a href="http://arxiv.org/find/cs/1/au:+Daly_K/0/1/0/all/0/1">Kevin P. Daly</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1">Suvranu Ganguli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitalia_V/0/1/0/all/0/1">Vipul C. Chitalia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolachalama_V/0/1/0/all/0/1">Vijaya B. Kolachalama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04658">
                                    <div class="article-summary-box-inner">
                                        <span>Development of deep learning systems for biomedical segmentation often
requires access to expert-driven, manually annotated datasets. If more than a
single expert is involved in the annotation of the same images, then the
inter-expert agreement is not necessarily perfect, and no single expert
annotation can precisely capture the so-called ground truth of the regions of
interest on all images. Also, it is not trivial to generate a reference
estimate using annotations from multiple experts. Here we present a deep neural
network, defined as U-Net-and-a-half, which can simultaneously learn from
annotations performed by multiple experts on the same set of images.
U-Net-and-a-half contains a convolutional encoder to generate features from the
input images, multiple decoders that allow simultaneous learning from image
masks obtained from annotations that were independently generated by multiple
experts, and a shared low-dimensional feature space. To demonstrate the
applicability of our framework, we used two distinct datasets from digital
pathology and radiology, respectively. Specifically, we trained two separate
models using pathologist-driven annotations of glomeruli on whole slide images
of human kidney biopsies (10 patients), and radiologist-driven annotations of
lumen cross-sections of human arteriovenous fistulae obtained from
intravascular ultrasound images (10 patients), respectively. The models based
on U-Net-and-a-half exceeded the performance of the traditional U-Net models
trained on single expert annotations alone, thus expanding the scope of
multitask learning in the context of biomedical image segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Natural Numerical Networks for Natura 2000 habitats classification by satellite images. (arXiv:2108.04327v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Mikula_K/0/1/0/all/0/1">Karol Mikula</a>, <a href="http://arxiv.org/find/math/1/au:+Kollar_M/0/1/0/all/0/1">Michal Kollar</a>, <a href="http://arxiv.org/find/math/1/au:+Ozvat_A/0/1/0/all/0/1">Aneta A. Ozvat</a>, <a href="http://arxiv.org/find/math/1/au:+Ambroz_M/0/1/0/all/0/1">Martin Ambroz</a>, <a href="http://arxiv.org/find/math/1/au:+Cahojova_L/0/1/0/all/0/1">Lucia Cahojova</a>, <a href="http://arxiv.org/find/math/1/au:+Jarolimek_I/0/1/0/all/0/1">Ivan Jarolimek</a>, <a href="http://arxiv.org/find/math/1/au:+Sibik_J/0/1/0/all/0/1">Jozef Sibik</a>, <a href="http://arxiv.org/find/math/1/au:+Sibikova_M/0/1/0/all/0/1">Maria Sibikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04327">
                                    <div class="article-summary-box-inner">
                                        <span>Natural numerical networks are introduced as a new classification algorithm
based on the numerical solution of nonlinear partial differential equations of
forward-backward diffusion type on complete graphs. The proposed natural
numerical network is applied to open important environmental and nature
conservation task, the automated identification of protected habitats by using
satellite images. In the natural numerical network, the forward diffusion
causes the movement of points in a feature space toward each other. The
opposite effect, keeping the points away from each other, is caused by backward
diffusion. This yields the desired classification. The natural numerical
network contains a few parameters that are optimized in the learning phase of
the method. After learning parameters and optimizing the topology of the
network graph, classification necessary for habitat identification is
performed. A relevancy map for each habitat is introduced as a tool for
validating the classification and finding new Natura 2000 habitat appearances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Effect of the Loss on Generalization: Empirical Study on Synthetic Lung Nodule Data. (arXiv:2108.04815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baltatzis_V/0/1/0/all/0/1">Vasileios Baltatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Folgoc_L/0/1/0/all/0/1">Loic Le Folgoc</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_S/0/1/0/all/0/1">Sam Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzanera_O/0/1/0/all/0/1">Octavio E. Martinez Manzanera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bintsi_K/0/1/0/all/0/1">Kyriaki-Margarita Bintsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1">Arjun Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1">Sujal Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04815">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) are widely used for image classification
in a variety of fields, including medical imaging. While most studies deploy
cross-entropy as the loss function in such tasks, a growing number of
approaches have turned to a family of contrastive learning-based losses. Even
though performance metrics such as accuracy, sensitivity and specificity are
regularly used for the evaluation of CNN classifiers, the features that these
classifiers actually learn are rarely identified and their effect on the
classification performance on out-of-distribution test samples is
insufficiently explored. In this paper, motivated by the real-world task of
lung nodule classification, we investigate the features that a CNN learns when
trained and tested on different distributions of a synthetic dataset with
controlled modes of variation. We show that different loss functions lead to
different features being learned and consequently affect the generalization
ability of the classifier on unseen data. This study provides some important
insights into the design of deep learning solutions for medical imaging tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R4Dyn: Exploring Radar for Self-Supervised Monocular Depth Estimation of Dynamic Scenes. (arXiv:2108.04814v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gasperini_S/0/1/0/all/0/1">Stefano Gasperini</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_P/0/1/0/all/0/1">Patrick Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dallabetta_V/0/1/0/all/0/1">Vinzenz Dallabetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/cs/1/au:+Busam_B/0/1/0/all/0/1">Benjamin Busam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04814">
                                    <div class="article-summary-box-inner">
                                        <span>While self-supervised monocular depth estimation in driving scenarios has
achieved comparable performance to supervised approaches, violations of the
static world assumption can still lead to erroneous depth predictions of
traffic participants, posing a potential safety issue. In this paper, we
present R4Dyn, a novel set of techniques to use cost-efficient radar data on
top of a self-supervised depth estimation framework. In particular, we show how
radar can be used during training as weak supervision signal, as well as an
extra input to enhance the estimation robustness at inference time. Since
automotive radars are readily available, this allows to collect training data
from a variety of existing vehicles. Moreover, by filtering and expanding the
signal to make it compatible with learning-based approaches, we address radar
inherent issues, such as noise and sparsity. With R4Dyn we are able to overcome
a major limitation of self-supervised depth estimation, i.e. the prediction of
traffic participants. We substantially improve the estimation on dynamic
objects, such as cars by 37% on the challenging nuScenes dataset, hence
demonstrating that radar is a valuable additional sensor for monocular depth
estimation in autonomous vehicles. Additionally, we plan on making the code
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Sparse Adversarial Attack on Sequence-based Gait Recognition. (arXiv:2002.09674v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Ziwen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tieniu Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.09674">
                                    <div class="article-summary-box-inner">
                                        <span>Gait recognition is widely used in social security applications due to its
advantages in long-distance human identification. Recently, sequence-based
methods have achieved high accuracy by learning abundant temporal and spatial
information. However, their robustness under adversarial attacks has not been
clearly explored. In this paper, we demonstrate that the state-of-the-art gait
recognition model is vulnerable to such attacks. To this end, we propose a
novel temporal sparse adversarial attack method. Different from previous
additive noise models which add perturbations on original samples, we employ a
generative adversarial network based architecture to semantically generate
adversarial high-quality gait silhouettes or video frames. Moreover, by
sparsely substituting or inserting a few adversarial gait silhouettes, the
proposed method ensures its imperceptibility and achieves a high attack success
rate. The experimental results show that if only one-fortieth of the frames are
attacked, the accuracy of the target model drops dramatically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperparameter Analysis for Derivative Compressive Sampling. (arXiv:2108.04355v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rabbi_M/0/1/0/all/0/1">Md Fazle Rabbi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04355">
                                    <div class="article-summary-box-inner">
                                        <span>Derivative compressive sampling (DCS) is a signal reconstruction method from
measurements of the spatial gradient with sub-Nyquist sampling rate.
Applications of DCS include optical image reconstruction, photometric stereo,
and shape-from-shading. In this work, we study the sensitivity of DCS with
respect to algorithmic hyperparameters using a brute-force search algorithm. We
perform experiments on a dataset of surface images and deduce guidelines for
the user to setup values for the hyperparameters for improved signal recovery
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AASeg: Attention Aware Network for Real Time Semantic Segmentation. (arXiv:2108.04349v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04349">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a new network named Attention Aware Network (AASeg)
for real time semantic image segmentation. Our network incorporates spatial and
channel information using Spatial Attention (SA) and Channel Attention (CA)
modules respectively. It also uses dense local multi-scale context information
using Multi Scale Context (MSC) module. The feature maps are concatenated
individually to produce the final segmentation map. We demonstrate the
effectiveness of our method using a comprehensive analysis, quantitative
experimental results and ablation study using Cityscapes, ADE20K and Camvid
datasets. Our network performs better than most previous architectures with a
74.4\% Mean IOU on Cityscapes test dataset while running at 202.7 FPS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUNet: Symmetric Undistortion Network for Rolling Shutter Correction. (arXiv:2108.04775v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_B/0/1/0/all/0/1">Bin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yuchao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Mingyi He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04775">
                                    <div class="article-summary-box-inner">
                                        <span>The vast majority of modern consumer-grade cameras employ a rolling shutter
mechanism, leading to image distortions if the camera moves during image
acquisition. In this paper, we present a novel deep network to solve the
generic rolling shutter correction problem with two consecutive frames. Our
pipeline is symmetrically designed to predict the global shutter image
corresponding to the intermediate time of these two frames, which is difficult
for existing methods because it corresponds to a camera pose that differs most
from the two frames. First, two time-symmetric dense undistortion flows are
estimated by using well-established principles: pyramidal construction,
warping, and cost volume processing. Then, both rolling shutter images are
warped into a common global shutter one in the feature space, respectively.
Finally, a symmetric consistency constraint is constructed in the image decoder
to effectively aggregate the contextual cues of two rolling shutter images,
thereby recovering the high-quality global shutter image. Extensive experiments
with both synthetic and real data from public benchmarks demonstrate the
superiority of our proposed approach over the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Open Domain Adaption Framework (AODA): Sketch-to-Photo Synthesis. (arXiv:2108.04351v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1">Amey Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Satish_M/0/1/0/all/0/1">Mega Satish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04351">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims to demonstrate the efficiency of the Adversarial Open Domain
Adaption framework for sketch-to-photo synthesis. The unsupervised open domain
adaption for generating realistic photos from a hand-drawn sketch is
challenging as there is no such sketch of that class for training data. The
absence of learning supervision and the huge domain gap between both the
freehand drawing and picture domains make it hard. We present an approach that
learns both sketch-to-photo and photo-to-sketch generation to synthesise the
missing freehand drawings from pictures. Due to the domain gap between
synthetic sketches and genuine ones, the generator trained on false drawings
may produce unsatisfactory results when dealing with drawings of lacking
classes. To address this problem, we offer a simple but effective open-domain
sampling and optimization method that tricks the generator into considering
false drawings as genuine. Our approach generalises the learnt sketch-to-photo
and photo-to-sketch mappings from in-domain input to open-domain categories. On
the Scribble and SketchyCOCO datasets, we compared our technique to the most
current competing methods. For many types of open-domain drawings, our model
outperforms impressive results in synthesising accurate colour, substance, and
retaining the structural layout.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VirtualConductor: Music-driven Conducting Video Generation System. (arXiv:2108.04350v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Delong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Feng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04350">
                                    <div class="article-summary-box-inner">
                                        <span>In this demo, we present VirtualConductor, a system that can generate
conducting video from any given music and a single user&#x27;s image. First, a
large-scale conductor motion dataset is collected and constructed. Then, we
propose Audio Motion Correspondence Network (AMCNet) and adversarial-perceptual
learning to learn the cross-modal relationship and generate diverse, plausible,
music-synchronized motion. Finally, we combine 3D animation rendering and a
pose transfer model to synthesize conducting video from a single given user&#x27;s
image. Therefore, any user can become a virtual conductor through the system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AnyoneNet: Synchronized Speech and Talking Head Generation for arbitrary person. (arXiv:2108.04325v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1">Qicong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jihua Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharenborg/0/1/0/all/0/1">Scharenborg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04325">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically generating videos in which synthesized speech is synchronized
with lip movements in a talking head has great potential in many human-computer
interaction scenarios. In this paper, we present an automatic method to
generate synchronized speech and talking-head videos on the basis of text and a
single face image of an arbitrary person as input. In contrast to previous
text-driven talking head generation methods, which can only synthesize the
voice of a specific person, the proposed method is capable of synthesizing
speech for any person that is inaccessible in the training stage. Specifically,
the proposed method decomposes the generation of synchronized speech and
talking head videos into two stages, i.e., a text-to-speech (TTS) stage and a
speech-driven talking head generation stage. The proposed TTS module is a
face-conditioned multi-speaker TTS model that gets the speaker identity
information from face images instead of speech, which allows us to synthesize a
personalized voice on the basis of the input face image. To generate the
talking head videos from the face images, a facial landmark-based method that
can predict both lip movements and head rotations is proposed. Extensive
experiments demonstrate that the proposed method is able to generate
synchronized speech and talking head videos for arbitrary persons and
non-persons. Synthesized speech shows consistency with the given face regarding
to the synthesized voice&#x27;s timbre and one&#x27;s appearance in the image, and the
proposed landmark-based talking head method outperforms the state-of-the-art
landmark-based method on generating natural talking head videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Olfactory Bulb Segmentation on High Resolutional T2-Weighted MRI. (arXiv:2108.04267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Estrada_S/0/1/0/all/0/1">Santiago Estrada</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Ran Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diers_K/0/1/0/all/0/1">Kersten Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Weiyi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehses_P/0/1/0/all/0/1">Philipp Ehses</a>, <a href="http://arxiv.org/find/cs/1/au:+Stocker_T/0/1/0/all/0/1">Tony St&#xf6;cker</a>, <a href="http://arxiv.org/find/cs/1/au:+Breteler_M/0/1/0/all/0/1">Monique M.B Breteler</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_M/0/1/0/all/0/1">Martin Reuter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04267">
                                    <div class="article-summary-box-inner">
                                        <span>The neuroimage analysis community has neglected the automated segmentation of
the olfactory bulb (OB) despite its crucial role in olfactory function. The
lack of an automatic processing method for the OB can be explained by its
challenging properties. Nonetheless, recent advances in MRI acquisition
techniques and resolution have allowed raters to generate more reliable manual
annotations. Furthermore, the high accuracy of deep learning methods for
solving semantic segmentation problems provides us with an option to reliably
assess even small structures. In this work, we introduce a novel, fast, and
fully automated deep learning pipeline to accurately segment OB tissue on
sub-millimeter T2-weighted (T2w) whole-brain MR images. To this end, we
designed a three-stage pipeline: (1) Localization of a region containing both
OBs using FastSurferCNN, (2) Segmentation of OB tissue within the localized
region through four independent AttFastSurferCNN - a novel deep learning
architecture with a self-attention mechanism to improve modeling of contextual
information, and (3) Ensemble of the predicted label maps. The OB pipeline
exhibits high performance in terms of boundary delineation, OB localization,
and volume estimation across a wide range of ages in 203 participants of the
Rhineland Study. Moreover, it also generalizes to scans of an independent
dataset never encountered during training, the Human Connectome Project (HCP),
with different acquisition parameters and demographics, evaluated in 30 cases
at the native 0.7mm HCP resolution, and the default 0.8mm pipeline resolution.
We extensively validated our pipeline not only with respect to segmentation
accuracy but also to known OB volume effects, where it can sensitively
replicate age effects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual SLAM with Graph-Cut Optimized Multi-Plane Reconstruction. (arXiv:2108.04281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_F/0/1/0/all/0/1">Fangwen Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yaxu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambach_J/0/1/0/all/0/1">Jason Rambach</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagani_A/0/1/0/all/0/1">Alain Pagani</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04281">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a semantic planar SLAM system that improves pose
estimation and mapping using cues from an instance planar segmentation network.
While the mainstream approaches are using RGB-D sensors, employing a monocular
camera with such a system still faces challenges such as robust data
association and precise geometric model fitting. In the majority of existing
work, geometric model estimation problems such as homography estimation and
piece-wise planar reconstruction (PPR) are usually solved by standard (greedy)
RANSAC separately and sequentially. However, setting the inlier-outlier
threshold is difficult in absence of information about the scene (i.e. the
scale). In this work, we revisit these problems and argue that two mentioned
geometric models (homographies/3D planes) can be solved by minimizing an energy
function that exploits the spatial coherence, i.e. with graph-cut optimization,
which also tackles the practical issue when the output of a trained CNN is
inaccurate. Moreover, we propose an adaptive parameter setting strategy based
on our experiments, and report a comprehensive evaluation on various
open-source datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FairyTailor: A Multimodal Generative Framework for Storytelling. (arXiv:2108.04324v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bensaid_E/0/1/0/all/0/1">Eden Bensaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Martino_M/0/1/0/all/0/1">Mauro Martino</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoover_B/0/1/0/all/0/1">Benjamin Hoover</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>, <a href="http://arxiv.org/find/cs/1/au:+Strobelt_H/0/1/0/all/0/1">Hendrik Strobelt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04324">
                                    <div class="article-summary-box-inner">
                                        <span>Storytelling is an open-ended task that entails creative thinking and
requires a constant flow of ideas. Natural language generation (NLG) for
storytelling is especially challenging because it requires the generated text
to follow an overall theme while remaining creative and diverse to engage the
reader. In this work, we introduce a system and a web-based demo, FairyTailor,
for human-in-the-loop visual story co-creation. Users can create a cohesive
children&#x27;s fairytale by weaving generated texts and retrieved images with their
input. FairyTailor adds another modality and modifies the text generation
process to produce a coherent and creative sequence of text and images. To our
knowledge, this is the first dynamic tool for multimodal story generation that
allows interactive co-formation of both texts and images. It allows users to
give feedback on co-created stories and share their results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning architectures for generalized immunofluorescence based nuclear image segmentation. (arXiv:1907.12975v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kromp_F/0/1/0/all/0/1">Florian Kromp</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1">Lukas Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozsaky_E/0/1/0/all/0/1">Eva Bozsaky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambros_I/0/1/0/all/0/1">Inge Ambros</a>, <a href="http://arxiv.org/find/cs/1/au:+Doerr_W/0/1/0/all/0/1">Wolfgang Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Taschner_Mandl_S/0/1/0/all/0/1">Sabine Taschner-Mandl</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambros_P/0/1/0/all/0/1">Peter Ambros</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.12975">
                                    <div class="article-summary-box-inner">
                                        <span>Separating and labeling each instance of a nucleus (instance-aware
segmentation) is the key challenge in segmenting single cell nuclei on
fluorescence microscopy images. Deep Neural Networks can learn the implicit
transformation of a nuclear image into a probability map indicating the class
membership of each pixel (nucleus or background), but the use of
post-processing steps to turn the probability map into a labeled object mask is
error-prone. This especially accounts for nuclear images of tissue sections and
nuclear images across varying tissue preparations. In this work, we aim to
evaluate the performance of state-of-the-art deep learning architectures to
segment nuclei in fluorescence images of various tissue origins and sample
preparation types without post-processing. We compare architectures that
operate on pixel to pixel translation and an architecture that operates on
object detection and subsequent locally applied segmentation. In addition, we
propose a novel strategy to create artificial images to extend the training
set. We evaluate the influence of ground truth annotation quality, image scale
and segmentation complexity on segmentation performance. Results show that
three out of four deep learning architectures (U-Net, U-Net with ResNet34
backbone, Mask R-CNN) can segment fluorescent nuclear images on most of the
sample preparation types and tissue origins with satisfactory segmentation
performance. Mask R-CNN, an architecture designed to address instance aware
segmentation tasks, outperforms other architectures. Equal nuclear mean size,
consistent nuclear annotations and the use of artificially generated images
result in overall acceptable precision and recall across different tissues and
sample preparation types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VMAF And Variants: Towards A Unified VQA. (arXiv:2103.07770v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Topiwala_P/0/1/0/all/0/1">Pankaj Topiwala</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_W/0/1/0/all/0/1">Wei Dai</a>, <a href="http://arxiv.org/find/eess/1/au:+Pian_J/0/1/0/all/0/1">Jiangfeng Pian</a>, <a href="http://arxiv.org/find/eess/1/au:+Biondi_K/0/1/0/all/0/1">Katalina Biondi</a>, <a href="http://arxiv.org/find/eess/1/au:+Krovvidi_A/0/1/0/all/0/1">Arvind Krovvidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07770">
                                    <div class="article-summary-box-inner">
                                        <span>Video quality assessment (VQA) is now a fastgrowing subject, beginning to
mature in the full reference (FR) case, while the burgeoning no reference (NR)
case remains challenging. We investigate variants of the popular VMAF video
quality assessment algorithm for the FR case, using support vector regression
and feedforward neural networks, and extend it to the NR case, using the same
learning architectures, to develop a partially unified framework for VQA. When
heavily trained, algorithms such as VMAF perform well on test datasets, with
90%+ match; but predicting performance in the wild is better done by
training/testing from scratch, as we do. Even from scratch, we achieve 90%+
performance in FR, with gains over VMAF. And we greatly reduce complexity vs.
leading recent NR algorithms, VIDEVAL, RAPIQUE, yet exceed 80% in SRCC. In our
preliminary testing, we find the improvements in trainability, while also
constraining computational complexity, as quite encouraging, suggesting further
study and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RetrievalFuse: Neural 3D Scene Reconstruction with a Database. (arXiv:2104.00024v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siddiqui_Y/0/1/0/all/0/1">Yawar Siddiqui</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fangchang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Q/0/1/0/all/0/1">Qi Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Angela Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00024">
                                    <div class="article-summary-box-inner">
                                        <span>3D reconstruction of large scenes is a challenging problem due to the
high-complexity nature of the solution space, in particular for generative
neural networks. In contrast to traditional generative learned models which
encode the full generative process into a neural network and can struggle with
maintaining local details at the scene level, we introduce a new method that
directly leverages scene geometry from the training database. First, we learn
to synthesize an initial estimate for a 3D scene, constructed by retrieving a
top-k set of volumetric chunks from the scene database. These candidates are
then refined to a final scene generation with an attention-based refinement
that can effectively select the most consistent set of geometry from the
candidates and combine them together to create an output scene, facilitating
transfer of coherent structures and local detail from train scene geometry. We
demonstrate our neural scene reconstruction with a database for the tasks of 3D
super resolution and surface reconstruction from sparse point clouds, showing
that our approach enables generation of more coherent, accurate 3D scenes,
improving on average by over 8% in IoU over state-of-the-art scene
reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Search on Binary Codes by Weighted Hamming Distance. (arXiv:2009.08591v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1">Zhenyu Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuesheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruixin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08591">
                                    <div class="article-summary-box-inner">
                                        <span>Weighted Hamming distance, as a similarity measure between binary codes and
binary queries, provides superior accuracy in search tasks than Hamming
distance. However, how to efficiently and accurately find $K$ binary codes that
have the smallest weighted Hamming distance to the query remains an open issue.
In this paper, a fast search algorithm is proposed to perform the
non-exhaustive search for $K$ nearest binary codes by weighted Hamming
distance. By using binary codes as direct bucket indices in a hash table, the
search algorithm generates a sequence to probe the buckets based on the
independence characteristic of the weights for each bit. Furthermore, a fast
search framework based on the proposed search algorithm is designed to solve
the problem of long binary codes. Specifically, long binary codes are split
into substrings and multiple hash tables are built on them. Then, the search
algorithm probes the buckets to obtain candidates according to the generated
substring indices, and a merging algorithm is proposed to find the nearest
binary codes by merging the candidates. Theoretical analysis and experimental
results demonstrate that the search algorithm improves the search accuracy
compared to other non-exhaustive algorithms and provides orders-of-magnitude
faster search than the linear scan baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCTSteg: A Monte Carlo Tree Search-based Reinforcement Learning Framework for Universal Non-additive Steganography. (arXiv:2103.13689v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_X/0/1/0/all/0/1">Xianbo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13689">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has shown that non-additive image steganographic frameworks
effectively improve security performance through adjusting distortion
distribution. However, as far as we know, all of the existing non-additive
proposals are based on handcrafted policies, and can only be applied to a
specific image domain, which heavily prevent non-additive steganography from
releasing its full potentiality. In this paper, we propose an automatic
non-additive steganographic distortion learning framework called MCTSteg to
remove the above restrictions. Guided by the reinforcement learning paradigm,
we combine Monte Carlo Tree Search (MCTS) and steganalyzer-based environmental
model to build MCTSteg. MCTS makes sequential decisions to adjust distortion
distribution without human intervention. Our proposed environmental model is
used to obtain feedbacks from each decision. Due to its self-learning
characteristic and domain-independent reward function, MCTSteg has become the
first reported universal non-additive steganographic framework which can work
in both spatial and JPEG domains. Extensive experimental results show that
MCTSteg can effectively withstand the detection of both hand-crafted
feature-based and deep-learning-based steganalyzers. In both spatial and JPEG
domains, the security performance of MCTSteg steadily outperforms the state of
the art by a clear margin under different scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation. (arXiv:2108.04547v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weilun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04547">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning shows great potential in unpaired image-to-image
translation, but sometimes the translated results are in poor quality and the
contents are not preserved consistently. In this paper, we uncover that the
negative examples play a critical role in the performance of contrastive
learning for image translation. The negative examples in previous methods are
randomly sampled from the patches of different positions in the source image,
which are not effective to push the positive examples close to the query
examples. To address this issue, we present instance-wise hard Negative Example
Generation for Contrastive learning in Unpaired image-to-image
Translation~(NEGCUT). Specifically, we train a generator to produce negative
examples online. The generator is novel from two perspectives: 1) it is
instance-wise which means that the generated examples are based on the input
image, and 2) it can generate hard negative examples since it is trained with
an adversarial loss. With the generator, the performance of unpaired
image-to-image translation is significantly improved. Experiments on three
benchmark datasets demonstrate that the proposed NEGCUT framework achieves
state-of-the-art performance compared to previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection. (arXiv:2107.12664v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shi-Xue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaobin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongfa Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xu-Cheng Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12664">
                                    <div class="article-summary-box-inner">
                                        <span>Arbitrary shape text detection is a challenging task due to the high
complexity and variety of scene texts. In this work, we propose a novel
adaptive boundary proposal network for arbitrary shape text detection, which
can learn to directly produce accurate boundary for arbitrary shape text
without any post-processing. Our method mainly consists of a boundary proposal
model and an innovative adaptive boundary deformation model. The boundary
proposal model constructed by multi-layer dilated convolutions is adopted to
produce prior information (including classification map, distance field, and
direction field) and coarse boundary proposals. The adaptive boundary
deformation model is an encoder-decoder network, in which the encoder mainly
consists of a Graph Convolutional Network (GCN) and a Recurrent Neural Network
(RNN). It aims to perform boundary deformation in an iterative way for
obtaining text instance shape guided by prior information from the boundary
proposal model. In this way, our method can directly and efficiently generate
accurate text boundaries without complex post-processing. Extensive experiments
on publicly available datasets demonstrate the state-of-the-art performance of
our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TBNet:Two-Stream Boundary-aware Network for Generic Image Manipulation Localization. (arXiv:2108.04508v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhiyong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_W/0/1/0/all/0/1">Weili Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04508">
                                    <div class="article-summary-box-inner">
                                        <span>Finding tampered regions in images is a hot research topic in machine
learning and computer vision. Although many image manipulation location
algorithms have been proposed, most of them only focus on the RGB images with
different color spaces, and the frequency information that contains the
potential tampering clues is often ignored. In this work, a novel end-to-end
two-stream boundary-aware network (abbreviated as TBNet) is proposed for
generic image manipulation localization in which the RGB stream, the frequency
stream, and the boundary artifact location are explored in a unified framework.
Specifically, we first design an adaptive frequency selection module (AFS) to
adaptively select the appropriate frequency to mine inconsistent statistics and
eliminate the interference of redundant statistics. Then, an adaptive
cross-attention fusion module (ACF) is proposed to adaptively fuse the RGB
feature and the frequency feature. Finally, the boundary artifact location
network (BAL) is designed to locate the boundary artifacts for which the
parameters are jointly updated by the outputs of the ACF, and its results are
further fed into the decoder. Thus, the parameters of the RGB stream, the
frequency stream, and the boundary artifact location network are jointly
optimized, and their latent complementary relationships are fully mined. The
results of extensive experiments performed on four public benchmarks of the
image manipulation localization task, namely, CASIA1.0, COVER, Carvalho, and
In-The-Wild, demonstrate that the proposed TBNet can significantly outperform
state-of-the-art generic image manipulation localization methods in terms of
both MCC and F1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning point embedding for 3D data processing. (arXiv:2107.08565v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+li_Y/0/1/0/all/0/1">Yuan li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08565">
                                    <div class="article-summary-box-inner">
                                        <span>Among 2D convolutional networks on point clouds, point-based approaches
consume point clouds of fixed size directly. By analysis of PointNet, a pioneer
in introducing deep learning into point sets, we reveal that current
point-based methods are essentially spatial relationship processing networks.
In this paper, we take a different approach. Our architecture, named PE-Net,
learns the representation of point clouds in high-dimensional space, and
encodes the unordered input points to feature vectors, which standard 2D CNNs
can be applied to. The recommended network can adapt to changes in the number
of input points which is the limit of current methods. Experiments show that in
the tasks of classification and part segmentation, PE-Net achieves the
state-of-the-art performance in multiple challenging datasets, such as ModelNet
and ShapeNetPart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FusionPainting: Multimodal Fusion with Adaptive Attention for 3D Object Detection. (arXiv:2106.12449v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shaoqing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dingfu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Junbo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bin_Z/0/1/0/all/0/1">Zhou Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liangjun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12449">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate detection of obstacles in 3D is an essential task for autonomous
driving and intelligent transportation. In this work, we propose a general
multimodal fusion framework FusionPainting to fuse the 2D RGB image and 3D
point clouds at a semantic level for boosting the 3D object detection task.
Especially, the FusionPainting framework consists of three main modules: a
multi-modal semantic segmentation module, an adaptive attention-based semantic
fusion module, and a 3D object detector. First, semantic information is
obtained for 2D images and 3D Lidar point clouds based on 2D and 3D
segmentation approaches. Then the segmentation results from different sensors
are adaptively fused based on the proposed attention-based semantic fusion
module. Finally, the point clouds painted with the fused semantic label are
sent to the 3D detector for obtaining the 3D objection results. The
effectiveness of the proposed framework has been verified on the large-scale
nuScenes detection benchmark by comparing it with three different baselines.
The experimental results show that the fusion strategy can significantly
improve the detection performance compared to the methods using only point
clouds, and the methods using point clouds only painted with 2D segmentation
information. Furthermore, the proposed approach outperforms other
state-of-the-art methods on the nuScenes testing benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty Quantification using Variational Inference for Biomedical Image Segmentation. (arXiv:2008.07588v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.07588">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning motivated by convolutional neural networks has been highly
successful in a range of medical imaging problems like image classification,
image segmentation, image synthesis etc. However for validation and
interpretability, not only do we need the predictions made by the model but
also how confident it is while making those predictions. This is important in
safety critical applications for the people to accept it. In this work, we used
an encoder decoder architecture based on variational inference techniques for
segmenting brain tumour images. We evaluate our work on the publicly available
BRATS dataset using Dice Similarity Coefficient (DSC) and Intersection Over
Union (IOU) as the evaluation metrics. Our model is able to segment brain
tumours while taking into account both aleatoric uncertainty and epistemic
uncertainty in a principled bayesian manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MiniVLM: A Smaller and Faster Vision-Language Model. (arXiv:2012.06946v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaowei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiujun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06946">
                                    <div class="article-summary-box-inner">
                                        <span>Recent vision-language (VL) studies have shown remarkable progress by
learning generic representations from massive image-text pairs with transformer
models and then fine-tuning on downstream VL tasks. While existing research has
been focused on achieving high accuracy with large pre-trained models, building
a lightweight model is of great value in practice but is less explored. In this
paper, we propose a smaller and faster VL model, MiniVLM, which can be
finetuned with good performance on various downstream tasks like its larger
counterpart. MiniVLM consists of two modules, a vision feature extractor and a
transformer-based vision-language fusion module. We design a Two-stage
Efficient feature Extractor (TEE), inspired by the one-stage EfficientDet
network, to significantly reduce the time cost of visual feature extraction by
$95\%$, compared to a baseline model. We adopt the MiniLM structure to reduce
the computation cost of the transformer module after comparing different
compact BERT models. In addition, we improve the MiniVLM pre-training by adding
$7M$ Open Images data, which are pseudo-labeled by a state-of-the-art
captioning model. We also pre-train with high-quality image tags obtained from
a strong tagging model to enhance cross-modality alignment. The large models
are used offline without adding any overhead in fine-tuning and inference. With
the above design choices, our MiniVLM reduces the model size by $73\%$ and the
inference time cost by $94\%$ while being able to retain $94-97\%$ of the
accuracy on multiple VL tasks. We hope that MiniVLM helps ease the use of the
state-of-the-art VL research for on-the-edge applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Camera Convolutional Color Constancy. (arXiv:2011.11890v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Afifi_M/0/1/0/all/0/1">Mahmoud Afifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1">Jonathan T. Barron</a>, <a href="http://arxiv.org/find/cs/1/au:+LeGendre_C/0/1/0/all/0/1">Chloe LeGendre</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yun-Ta Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleibel_F/0/1/0/all/0/1">Francois Bleibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11890">
                                    <div class="article-summary-box-inner">
                                        <span>We present &quot;Cross-Camera Convolutional Color Constancy&quot; (C5), a
learning-based method, trained on images from multiple cameras, that accurately
estimates a scene&#x27;s illuminant color from raw images captured by a new camera
previously unseen during training. C5 is a hypernetwork-like extension of the
convolutional color constancy (CCC) approach: C5 learns to generate the weights
of a CCC model that is then evaluated on the input image, with the CCC weights
dynamically adapted to different input content. Unlike prior cross-camera color
constancy models, which are usually designed to be agnostic to the spectral
properties of test-set images from unobserved cameras, C5 approaches this
problem through the lens of transductive inference: additional unlabeled images
are provided as input to the model at test time, which allows the model to
calibrate itself to the spectral properties of the test-set camera during
inference. C5 achieves state-of-the-art accuracy for cross-camera color
constancy on several datasets, is fast to evaluate (~7 and ~90 ms per image on
a GPU or CPU, respectively), and requires little memory (~2 MB), and, thus, is
a practical solution to the problem of calibration-free automatic white balance
for mobile photography.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Devil is in the Channels: Mutual-Channel Loss for Fine-Grained Image Classification. (arXiv:2002.04264v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Dongliang Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yifeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhunia_A/0/1/0/all/0/1">Ayan Kumar Bhunia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoxu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhanyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Ming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04264">
                                    <div class="article-summary-box-inner">
                                        <span>Key for solving fine-grained image categorization is finding discriminate and
local regions that correspond to subtle visual traits. Great strides have been
made, with complex networks designed specifically to learn part-level
discriminate feature representations. In this paper, we show it is possible to
cultivate subtle details without the need for overly complicated network
designs or training mechanisms -- a single loss is all it takes. The main trick
lies with how we delve into individual feature channels early on, as opposed to
the convention of starting from a consolidated feature map. The proposed loss
function, termed as mutual-channel loss (MC-Loss), consists of two
channel-specific components: a discriminality component and a diversity
component. The discriminality component forces all feature channels belonging
to the same class to be discriminative, through a novel channel-wise attention
mechanism. The diversity component additionally constraints channels so that
they become mutually exclusive on spatial-wise. The end result is therefore a
set of feature channels that each reflects different locally discriminative
regions for a specific class. The MC-Loss can be trained end-to-end, without
the need for any bounding-box/part annotations, and yields highly
discriminative regions during inference. Experimental results show our MC-Loss
when implemented on top of common base networks can achieve state-of-the-art
performance on all four fine-grained categorization datasets (CUB-Birds,
FGVC-Aircraft, Flowers-102, and Stanford-Cars). Ablative studies further
demonstrate the superiority of MC-Loss when compared with other recently
proposed general-purpose losses for visual classification, on two different
base networks. Code available at
https://github.com/dongliangchang/Mutual-Channel-Loss</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Loss for Mobile Neural Networks. (arXiv:2107.11170v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrahamyan_L/0/1/0/all/0/1">Lusine Abrahamyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziatchin_V/0/1/0/all/0/1">Valentin Ziatchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deligiannis_N/0/1/0/all/0/1">Nikos Deligiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11170">
                                    <div class="article-summary-box-inner">
                                        <span>Compact convolutional neural networks (CNNs) have witnessed exceptional
improvements in performance in recent years. However, they still fail to
provide the same predictive power as CNNs with a large number of parameters.
The diverse and even abundant features captured by the layers is an important
characteristic of these successful CNNs. However, differences in this
characteristic between large CNNs and their compact counterparts have rarely
been investigated. In compact CNNs, due to the limited number of parameters,
abundant features are unlikely to be obtained, and feature diversity becomes an
essential characteristic. Diverse features present in the activation maps
derived from a data point during model inference may indicate the presence of a
set of unique descriptors necessary to distinguish between objects of different
classes. In contrast, data points with low feature diversity may not provide a
sufficient amount of unique descriptors to make a valid prediction; we refer to
them as random predictions. Random predictions can negatively impact the
optimization process and harm the final performance. This paper proposes
addressing the problem raised by random predictions by reshaping the standard
cross-entropy to make it biased toward data points with a limited number of
unique descriptive features. Our novel Bias Loss focuses the training on a set
of valuable data points and prevents the vast number of samples with poor
learning features from misleading the optimization process. Furthermore, to
show the importance of diversity, we present a family of SkipNet models whose
architectures are brought to boost the number of unique descriptors in the last
layers. Our Skipnet-M can achieve 1% higher classification accuracy than
MobileNetV3 Large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Enhanced Prohibited Items Recognition Model. (arXiv:2102.12256v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rong_T/0/1/0/all/0/1">Tianze Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hongxiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yichao Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12256">
                                    <div class="article-summary-box-inner">
                                        <span>We proposed a new modeling method to promote the performance of prohibited
items recognition via X-ray image. We analyzed the characteristics of
prohibited items and X-ray images. We found the fact that the scales of some
items are too small to be recognized which encumber the model performance. Then
we adopted a set of data augmentation and modified the model to adapt the field
of prohibited items recognition. The Convolutional Block Attention Module(CBAM)
and rescoring mechanism has been assembled into the model. By the modification,
our model achieved a mAP of 89.9% on SIXray10, mAP of 74.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Solution to Product detection in Densely Packed Scenes. (arXiv:2007.11946v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rong_T/0/1/0/all/0/1">Tianze Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanjia Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hongxiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yichao Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11946">
                                    <div class="article-summary-box-inner">
                                        <span>This work is a solution to densely packed scenes dataset SKU-110k. Our work
is modified from Cascade R-CNN. To solve the problem, we proposed a random crop
strategy to ensure both the sampling rate and input scale is relatively
sufficient as a contrast to the regular random crop. And we adopted some of
trick and optimized the hyper-parameters. To grasp the essential feature of the
densely packed scenes, we analysis the stages of a detector and investigate the
bottleneck which limits the performance. As a result, our method obtains 58.7
mAP on test set of SKU-110k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Data Hiding Using Inverse Gradient Attention. (arXiv:2011.10850v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Honglei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yuanzhouhan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yidong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10850">
                                    <div class="article-summary-box-inner">
                                        <span>Data hiding is the procedure of encoding desired information into an image to
resist potential noises while ensuring the embedded image has little perceptual
perturbations from the original image. Recently, with the tremendous successes
gained by deep neural networks in various fields, data hiding areas have
attracted increasing number of attentions. The neglect of considering the pixel
sensitivity within the cover image of deep neural methods will inevitably
affect the model robustness for information hiding. Targeting at the problem,
in this paper, we propose a novel deep data hiding scheme with Inverse Gradient
Attention (IGA), combing the ideas of adversarial learning and attention
mechanism to endow different sensitivity to different pixels. With the proposed
component, the model can spotlight pixels with more robustness for embedding
data. Empirically, extensive experiments show that the proposed model
outperforms the state-of-the-art methods on two prevalent datasets under
multiple settings. Besides, we further identify and discuss the connections
between the proposed inverse gradient attention and high-frequency regions
within images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmentation of VHR EO Images using Unsupervised Learning. (arXiv:2108.04222v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sudipan Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1">Lichao Mou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_M/0/1/0/all/0/1">Muhammad Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiao Xiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04222">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation is a crucial step in many Earth observation tasks.
Large quantity of pixel-level annotation is required to train deep networks for
semantic segmentation. Earth observation techniques are applied to varieties of
applications and since classes vary widely depending on the applications,
therefore, domain knowledge is often required to label Earth observation
images, impeding availability of labeled training data in many Earth
observation applications. To tackle these challenges, in this paper we propose
an unsupervised semantic segmentation method that can be trained using just a
single unlabeled scene. Remote sensing scenes are generally large. The proposed
method exploits this property to sample smaller patches from the larger scene
and uses deep clustering and contrastive learning to refine the weights of a
lightweight deep model composed of a series of the convolution layers along
with an embedded channel attention. After unsupervised training on the target
image/scene, the model automatically segregates the major classes present in
the scene and produces the segmentation map. Experimental results on the
Vaihingen dataset demonstrate the efficacy of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No-Reference Image Quality Assessment by Hallucinating Pristine Features. (arXiv:2108.04165v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Baoliang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lingyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1">Chenqi Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hanwei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04165">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a no-reference (NR) image quality assessment (IQA)
method via feature level pseudo-reference (PR) hallucination. The proposed
quality assessment framework is grounded on the prior models of natural image
statistical behaviors and rooted in the view that the perceptually meaningful
features could be well exploited to characterize the visual quality. Herein,
the PR features from the distorted images are learned by a mutual learning
scheme with the pristine reference as the supervision, and the discriminative
characteristics of PR features are further ensured with the triplet
constraints. Given a distorted image for quality inference, the feature level
disentanglement is performed with an invertible neural layer for final quality
prediction, leading to the PR and the corresponding distortion features for
comparison. The effectiveness of our proposed method is demonstrated on four
popular IQA databases, and superior performance on cross-database evaluation
also reveals the high generalization capability of our method. The
implementation of our method is publicly available on
https://github.com/Baoliang93/FPR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Featureswith Split-and-Share Module. (arXiv:2108.04500v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaemin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minseok Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jongchan Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dong-Geol Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04500">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) have shown state-of-the-art
performances in various computer vision tasks. Advances on CNN architectures
have focused mainly on designing convolutional blocks of the feature
extractors, but less on the classifiers that exploit extracted features. In
this work, we propose Split-and-Share Module (SSM),a classifier that splits a
given feature into parts, which are partially shared by multiple
sub-classifiers. Our intuition is that the more the features are shared, the
more common they will become, and SSM can encourage such structural
characteristics in the split features. SSM can be easily integrated into any
architecture without bells and whistles. We have extensively validated the
efficacy of SSM on ImageNet-1K classification task, andSSM has shown consistent
and significant improvements over baseline architectures. In addition, we
analyze the effect of SSM using the Grad-CAM visualization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attribute Guided Sparse Tensor-Based Model for Person Re-Identification. (arXiv:2108.04352v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taherkhani_F/0/1/0/all/0/1">Fariborz Taherkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabouei_A/0/1/0/all/0/1">Ali Dabouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04352">
                                    <div class="article-summary-box-inner">
                                        <span>Visual perception of a person is easily influenced by many factors such as
camera parameters, pose and viewpoint variations. These variations make person
Re-Identification (ReID) a challenging problem. Nevertheless, human attributes
usually stand as robust visual properties to such variations. In this paper, we
propose a new method to leverage features from human attributes for person
ReID. Our model uses a tensor to non-linearly fuse identity and attribute
features, and then forces the parameters of the tensor in the loss function to
generate discriminative fused features for ReID. Since tensor-based methods
usually contain a large number of parameters, training all of these parameters
becomes very slow, and the chance of overfitting increases as well. To address
this issue, we propose two new techniques based on Structural Sparsity Learning
(SSL) and Tensor Decomposition (TD) methods to create an accurate and stable
learning problem. We conducted experiments on several standard pedestrian
datasets, and experimental results indicate that our tensor-based approach
significantly improves person ReID baselines and also outperforms state of the
art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoVideo: An Automated Video Action Recognition System. (arXiv:2108.04212v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_Z/0/1/0/all/0/1">Zaid Pervaiz Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Sirui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Anmoll Kumar Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1">Mohammad Qazim Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1">Kwei-Herng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaben Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_N/0/1/0/all/0/1">Na Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04212">
                                    <div class="article-summary-box-inner">
                                        <span>Action recognition is a crucial task for video understanding. In this paper,
we present AutoVideo, a Python system for automated video action recognition.
It currently supports seven action recognition algorithms and various
pre-processing modules. Unlike the existing libraries that only provide model
zoos, AutoVideo is built with the standard pipeline language. The basic
building block is primitive, which wraps a pre-processing module or an
algorithm with some hyperparameters. AutoVideo is highly modular and
extendable. It can be easily combined with AutoML searchers. The pipeline
language is quite general so that we can easily enrich AutoVideo with
algorithms for various other video-related tasks in the future. AutoVideo is
released under MIT license at https://github.com/datamllab/autovideo</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poisoning the Unlabeled Dataset of Semi-Supervised Learning. (arXiv:2105.01622v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01622">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised machine learning models learn from a (small) set of labeled
training examples, and a (large) set of unlabeled training examples.
State-of-the-art models can reach within a few percentage points of
fully-supervised training, while requiring 100x less labeled data.

We study a new class of vulnerabilities: poisoning attacks that modify the
unlabeled dataset. In order to be useful, unlabeled datasets are given strictly
less review than labeled datasets, and adversaries can therefore poison them
easily. By inserting maliciously-crafted unlabeled examples totaling just 0.1%
of the dataset size, we can manipulate a model trained on this poisoned dataset
to misclassify arbitrary examples at test time (as any desired label). Our
attacks are highly effective across datasets and semi-supervised learning
methods.

We find that more accurate methods (thus more likely to be used) are
significantly more vulnerable to poisoning attacks, and as such better training
methods are unlikely to prevent this attack. To counter this we explore the
space of defenses, and propose two methods that mitigate our attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IGibson 1.0: a Simulation Environment for Interactive Tasks in Large Realistic Scenes. (arXiv:2012.02924v6 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Linxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_DArpino_C/0/1/0/all/0/1">Claudia P&#xe9;rez-D&#x27;Arpino</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1">Shyamal Buch</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_L/0/1/0/all/0/1">Lyne P. Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_M/0/1/0/all/0/1">Micael E. Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Josiah Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02924">
                                    <div class="article-summary-box-inner">
                                        <span>We present iGibson 1.0, a novel simulation environment to develop robotic
solutions for interactive tasks in large-scale realistic scenes. Our
environment contains 15 fully interactive home-sized scenes with 108 rooms
populated with rigid and articulated objects. The scenes are replicas of
real-world homes, with distribution and the layout of objects aligned to those
of the real world. iGibson 1.0 integrates several key features to facilitate
the study of interactive tasks: i) generation of high-quality virtual sensor
signals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain
randomization to change the materials of the objects (both visual and physical)
and/or their shapes, iii) integrated sampling-based motion planners to generate
collision-free trajectories for robot bases and arms, and iv) intuitive
human-iGibson interface that enables efficient collection of human
demonstrations. Through experiments, we show that the full interactivity of the
scenes enables agents to learn useful visual representations that accelerate
the training of downstream manipulation tasks. We also show that iGibson 1.0
features enable the generalization of navigation agents, and that the
human-iGibson interface and integrated motion planners facilitate efficient
imitation learning of human demonstrated (mobile) manipulation behaviors.
iGibson 1.0 is open-source, equipped with comprehensive examples and
documentation. For more information, visit our project website:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tasks Structure Regularization in Multi-Task Learning for Improving Facial Attribute Prediction. (arXiv:2108.04353v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taherkhani_F/0/1/0/all/0/1">Fariborz Taherkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabouei_A/0/1/0/all/0/1">Ali Dabouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04353">
                                    <div class="article-summary-box-inner">
                                        <span>The great success of Convolutional Neural Networks (CNN) for facial attribute
prediction relies on a large amount of labeled images. Facial image datasets
are usually annotated by some commonly used attributes (e.g., gender), while
labels for the other attributes (e.g., big nose) are limited which causes their
prediction challenging. To address this problem, we use a new Multi-Task
Learning (MTL) paradigm in which a facial attribute predictor uses the
knowledge of other related attributes to obtain a better generalization
performance. Here, we leverage MLT paradigm in two problem settings. First, it
is assumed that the structure of the tasks (e.g., grouping pattern of facial
attributes) is known as a prior knowledge, and parameters of the tasks (i.e.,
predictors) within the same group are represented by a linear combination of a
limited number of underlying basis tasks. Here, a sparsity constraint on the
coefficients of this linear combination is also considered such that each task
is represented in a more structured and simpler manner. Second, it is assumed
that the structure of the tasks is unknown, and then structure and parameters
of the tasks are learned jointly by using a Laplacian regularization framework.
Our MTL methods are compared with competing methods for facial attribute
prediction to show its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Morphometry of Closed, Implicit Surfaces. (arXiv:2108.04354v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Besler_B/0/1/0/all/0/1">Bryce A Besler</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemp_T/0/1/0/all/0/1">Tannis D. Kemp</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalski_A/0/1/0/all/0/1">Andrew S. Michalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Forkert_N/0/1/0/all/0/1">Nils D. Forkert</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_S/0/1/0/all/0/1">Steven K. Boyd</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04354">
                                    <div class="article-summary-box-inner">
                                        <span>Anatomical structures such as the hippocampus, liver, and bones can be
analyzed as orientable, closed surfaces. This permits the computation of
volume, surface area, mean curvature, Gaussian curvature, and the
Euler-Poincar\&#x27;e characteristic as well as comparison of these morphometrics
between structures of different topology. The structures are commonly
represented implicitly in curve evolution problems as the zero level set of an
embedding. Practically, binary images of anatomical structures are embedded
using a signed distance transform. However, quantization prevents the accurate
computation of curvatures, leading to considerable errors in morphometry. This
paper presents a fast, simple embedding procedure for accurate local
morphometry as the zero crossing of the Gaussian blurred binary image. The
proposed method was validated based on the femur and fourth lumbar vertebrae of
50 clinical computed tomography datasets. The results show that the signed
distance transform leads to large quantization errors in the computed local
curvature. Global validation of morphometry using regression and Bland-Altman
analysis revealed that the coefficient of determination for the average mean
curvature is improved from 93.8% with the signed distance transform to 100%
with the proposed method. For the surface area, the proportional bias is
improved from -5.0% for the signed distance transform to +0.6% for the proposed
method. The Euler-Poincar\&#x27;e characteristic is improved from unusable in the
signed distance transform to 98% accuracy for the proposed method. The proposed
method enables an improved local and global evaluation of curvature for
purposes of morphometry on closed, implicit surfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniNet: A Unified Scene Understanding Network and Exploring Multi-Task Relationships through the Lens of Adversarial Attacks. (arXiv:2108.04584v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gurulingan_N/0/1/0/all/0/1">NareshKumar Gurulingan</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04584">
                                    <div class="article-summary-box-inner">
                                        <span>Scene understanding is crucial for autonomous systems which intend to operate
in the real world. Single task vision networks extract information only based
on some aspects of the scene. In multi-task learning (MTL), on the other hand,
these single tasks are jointly learned, thereby providing an opportunity for
tasks to share information and obtain a more comprehensive understanding. To
this end, we develop UniNet, a unified scene understanding network that
accurately and efficiently infers vital vision tasks including object
detection, semantic segmentation, instance segmentation, monocular depth
estimation, and monocular instance depth prediction. As these tasks look at
different semantic and geometric information, they can either complement or
conflict with each other. Therefore, understanding inter-task relationships can
provide useful cues to enable complementary information sharing. We evaluate
the task relationships in UniNet through the lens of adversarial attacks based
on the notion that they can exploit learned biases and task interactions in the
neural network. Extensive experiments on the Cityscapes dataset, using
untargeted and targeted attacks reveal that semantic tasks strongly interact
amongst themselves, and the same holds for geometric tasks. Additionally, we
show that the relationship between semantic and geometric tasks is asymmetric
and their interaction becomes weaker as we move towards higher-level
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Select, Substitute, Search: A New Benchmark for Knowledge-Augmented Visual Question Answering. (arXiv:2103.05568v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Aman Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothyari_M/0/1/0/all/0/1">Mayank Kothyari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vishwajeet Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1">Soumen Chakrabarti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05568">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal IR, spanning text corpus, knowledge graph and images, called
outside knowledge visual question answering (OKVQA), is of much recent
interest. However, the popular data set has serious limitations. A surprisingly
large fraction of queries do not assess the ability to integrate cross-modal
information. Instead, some are independent of the image, some depend on
speculation, some require OCR or are otherwise answerable from the image alone.
To add to the above limitations, frequency-based guessing is very effective
because of (unintended) widespread answer overlaps between the train and test
folds. Overall, it is hard to determine when state-of-the-art systems exploit
these weaknesses rather than really infer the answers, because they are opaque
and their &#x27;reasoning&#x27; process is uninterpretable. An equally important
limitation is that the dataset is designed for the quantitative assessment only
of the end-to-end answer retrieval task, with no provision for assessing the
correct(semantic) interpretation of the input query. In response, we identify a
key structural idiom in OKVQA ,viz., S3 (select, substitute and search), and
build a new data set and challenge around it. Specifically, the questioner
identifies an entity in the image and asks a question involving that entity
which can be answered only by consulting a knowledge graph or corpus passage
mentioning the entity. Our challenge consists of (i)OKVQAS3, a subset of OKVQA
annotated based on the structural idiom and (ii)S3VQA, a new dataset built from
scratch. We also present a neural but structurally transparent OKVQA system,
S3, that explicitly addresses our challenge dataset, and outperforms recent
competitive baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedded Knowledge Distillation in Depth-Level Dynamic Neural Network. (arXiv:2103.00793v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Shuchang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Ting-Bing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00793">
                                    <div class="article-summary-box-inner">
                                        <span>In real applications, different computation-resource devices need
different-depth networks (e.g., ResNet-18/34/50) with high-accuracy. Usually,
existing methods either design multiple networks and train them independently,
or construct depth-level/width-level dynamic neural networks which is hard to
prove the accuracy of each sub-net. In this article, we propose an elegant
Depth-Level Dynamic Neural Network (DDNN) integrated different-depth sub-nets
of similar architectures. To improve the generalization of sub-nets, we design
the Embedded-Knowledge-Distillation (EKD) training mechanism for the DDNN to
implement knowledge transfer from the teacher (full-net) to multiple students
(sub-nets). Specifically, the Kullback-Leibler (KL) divergence is introduced to
constrain the posterior class probability consistency between full-net and
sub-nets, and self-attention distillation on the same resolution feature of
different depth is addressed to drive more abundant feature representations of
sub-nets. Thus, we can obtain multiple high-accuracy sub-nets simultaneously in
a DDNN via the online knowledge distillation in each training iteration without
extra computation cost. Extensive experiments on CIFAR-10/100, and ImageNet
datasets demonstrate that sub-nets in DDNN with EKD training achieve better
performance than individually training networks while preserving the original
performance of full-nets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An optical biomimetic eyes with interested object imaging. (arXiv:2108.04236v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shimei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shangyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_M/0/1/0/all/0/1">Miao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiaofang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chuangxue Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kunyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shuxin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yuer Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1">Ting Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04236">
                                    <div class="article-summary-box-inner">
                                        <span>We presented an optical system to perform imaging interested objects in
complex scenes, like the creature easy see the interested prey in the hunt for
complex environments. It utilized Deep-learning network to learn the interested
objects&#x27;s vision features and designed the corresponding &quot;imaging matrices&quot;,
furthermore the learned matrixes act as the measurement matrix to complete
compressive imaging with a single-pixel camera, finally we can using the
compressed image data to only image the interested objects without the rest
objects and backgrounds of the scenes with the previous Deep-learning network.
Our results demonstrate that no matter interested object is single feature or
rich details, the interference can be successfully filtered out and this idea
can be applied in some common applications that effectively improve the
performance. This bio-inspired optical system can act as the creature eye to
achieve success on interested-based object imaging, object detection, object
recognition and object tracking, etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UIBert: Learning Generic Multimodal Representations for UI Understanding. (arXiv:2107.13731v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_C/0/1/0/all/0/1">Chongyang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_X/0/1/0/all/0/1">Xiaoxue Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Ying Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunkara_S/0/1/0/all/0/1">Srinivas Sunkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1">Abhinav Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jindong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1">Blaise Aguera y Arcas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13731">
                                    <div class="article-summary-box-inner">
                                        <span>To improve the accessibility of smart devices and to simplify their usage,
building models which understand user interfaces (UIs) and assist users to
complete their tasks is critical. However, unique challenges are proposed by
UI-specific characteristics, such as how to effectively leverage multimodal UI
features that involve image, text, and structural metadata and how to achieve
good performance when high-quality labeled data is unavailable. To address such
challenges we introduce UIBert, a transformer-based joint image-text model
trained through novel pre-training tasks on large-scale unlabeled UI data to
learn generic feature representations for a UI and its components. Our key
intuition is that the heterogeneous features in a UI are self-aligned, i.e.,
the image and text features of UI components, are predictive of each other. We
propose five pretraining tasks utilizing this self-alignment among different
features of a UI component and across various components in the same UI. We
evaluate our method on nine real-world downstream UI tasks where UIBert
outperforms strong multimodal baselines by up to 9.26% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable AI and susceptibility to adversarial attacks: a case study in classification of breast ultrasound images. (arXiv:2108.04345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rasaee_H/0/1/0/all/0/1">Hamza Rasaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivaz_H/0/1/0/all/0/1">Hassan Rivaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04345">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound is a non-invasive imaging modality that can be conveniently used
to classify suspicious breast nodules and potentially detect the onset of
breast cancer. Recently, Convolutional Neural Networks (CNN) techniques have
shown promising results in classifying ultrasound images of the breast into
benign or malignant. However, CNN inference acts as a black-box model, and as
such, its decision-making is not interpretable. Therefore, increasing effort
has been dedicated to explaining this process, most notably through GRAD-CAM
and other techniques that provide visual explanations into inner workings of
CNNs. In addition to interpretation, these methods provide clinically important
information, such as identifying the location for biopsy or treatment. In this
work, we analyze how adversarial assaults that are practically undetectable may
be devised to alter these importance maps dramatically. Furthermore, we will
show that this change in the importance maps can come with or without altering
the classification result, rendering them even harder to detect. As such, care
must be taken when using these importance maps to shed light on the inner
workings of deep learning. Finally, we utilize Multi-Task Learning (MTL) and
propose a new network based on ResNet-50 to improve the classification
accuracies. Our sensitivity and specificity is comparable to the state of the
art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Creating synthetic meteorology satellite visible light images during night based on GAN method. (arXiv:2108.04330v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wencong_C/0/1/0/all/0/1">CHENG Wencong</a> (1) ((1) Beijing Aviation Meteorological Institute)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04330">
                                    <div class="article-summary-box-inner">
                                        <span>Meteorology satellite visible light images is critical for meteorology
support and forecast. However, there is no such kind of data during night time.
To overcome this, we propose a method based on deep learning to create
synthetic satellite visible light images during night. Specifically, to produce
more realistic products, we train a Generative Adversarial Networks (GAN) model
to generate visible light images given the corresponding satellite infrared
images and numerical weather prediction(NWP) products. To better model the
nonlinear relationship from infrared data and NWP products to visible light
images, we propose to use the channel-wise attention mechanics, e.g., SEBlock
to quantitative weight the input channels. The experiments based on the ECMWF
NWP products and FY-4A meteorology satellite visible light and infrared
channels date show that the proposed methods can be effective to create
realistic synthetic satellite visible light images during night.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Master Faces for Dictionary Attacks with a Network-Assisted Latent Space Evolution. (arXiv:2108.01077v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shmelkin_R/0/1/0/all/0/1">Ron Shmelkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedlander_T/0/1/0/all/0/1">Tomer Friedlander</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01077">
                                    <div class="article-summary-box-inner">
                                        <span>A master face is a face image that passes face-based identity-authentication
for a large portion of the population. These faces can be used to impersonate,
with a high probability of success, any user, without having access to any
user-information. We optimize these faces, by using an evolutionary algorithm
in the latent embedding space of the StyleGAN face generator. Multiple
evolutionary strategies are compared, and we propose a novel approach that
employs a neural network in order to direct the search in the direction of
promising samples, without adding fitness evaluations. The results we present
demonstrate that it is possible to obtain a high coverage of the LFW identities
(over 40%) with less than 10 master faces, for three leading deep face
recognition systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Gradient Adversarial Attack. (arXiv:2108.04204v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zheng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yunpei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chuanqi Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1">Tao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04204">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, research on adversarial attacks has become a hot spot.
Although current literature on the transfer-based adversarial attack has
achieved promising results for improving the transferability to unseen
black-box models, it still leaves a long way to go. Inspired by the idea of
meta-learning, this paper proposes a novel architecture called Meta Gradient
Adversarial Attack (MGAA), which is plug-and-play and can be integrated with
any existing gradient-based attack method for improving the cross-model
transferability. Specifically, we randomly sample multiple models from a model
zoo to compose different tasks and iteratively simulate a white-box attack and
a black-box attack in each task. By narrowing the gap between the gradient
directions in white-box and black-box attacks, the transferability of
adversarial examples on the black-box setting can be improved. Extensive
experiments on the CIFAR10 and ImageNet datasets show that our architecture
outperforms the state-of-the-art methods for both black-box and white-box
attack settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">INeRF: Inverting Neural Radiance Fields for Pose Estimation. (arXiv:2012.05877v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yen_Chen_L/0/1/0/all/0/1">Lin Yen-Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1">Pete Florence</a>, <a href="http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1">Jonathan T. Barron</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Alberto Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05877">
                                    <div class="article-summary-box-inner">
                                        <span>We present iNeRF, a framework that performs mesh-free pose estimation by
&quot;inverting&quot; a Neural RadianceField (NeRF). NeRFs have been shown to be
remarkably effective for the task of view synthesis - synthesizing
photorealistic novel views of real-world scenes or objects. In this work, we
investigate whether we can apply analysis-by-synthesis via NeRF for mesh-free,
RGB-only 6DoF pose estimation - given an image, find the translation and
rotation of a camera relative to a 3D object or scene. Our method assumes that
no object mesh models are available during either training or test time.
Starting from an initial pose estimate, we use gradient descent to minimize the
residual between pixels rendered from a NeRF and pixels in an observed image.
In our experiments, we first study 1) how to sample rays during pose refinement
for iNeRF to collect informative gradients and 2) how different batch sizes of
rays affect iNeRF on a synthetic dataset. We then show that for complex
real-world scenes from the LLFF dataset, iNeRF can improve NeRF by estimating
the camera poses of novel images and using these images as additional training
data for NeRF. Finally, we show iNeRF can perform category-level object pose
estimation, including object instances not seen during training, with RGB
images by inverting a NeRF model inferred from a single view.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic Boundaries While Suppressing Artifacts. (arXiv:2011.11962v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hung_A/0/1/0/all/0/1">Alex Ling Yu Hung</a>, <a href="http://arxiv.org/find/eess/1/au:+Galeotti_J/0/1/0/all/0/1">John Galeotti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11962">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound 3D compounding is important for volumetric reconstruction, but as
of yet there is no consensus on best practices for compounding. Ultrasound
images depend on probe direction and the path sound waves pass through, so when
multiple intersecting B-scans of the same spot from different perspectives
yield different pixel values, there is not a single, ideal representation for
compounding (i.e. combining) the overlapping pixel values. Current popular
methods inevitably suppress or altogether leave out bright or dark regions that
are useful, and potentially introduce new artifacts. In this work, we establish
a new algorithm to compound the overlapping pixels from different view points
in ultrasound. We uniquely leverage Laplacian and Gaussian Pyramids to preserve
the maximum boundary contrast without overemphasizing noise and speckle. We
evaluate our algorithm by comparing ours with previous algorithms, and we show
that our approach not only preserves both light and dark details, but also
somewhat suppresses artifacts, rather than amplifying them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Cut by Watching Movies. (arXiv:2108.04294v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pardo_A/0/1/0/all/0/1">Alejandro Pardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1">Fabian Caba Heilbron</a>, <a href="http://arxiv.org/find/cs/1/au:+Alcazar_J/0/1/0/all/0/1">Juan Le&#xf3;n Alc&#xe1;zar</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04294">
                                    <div class="article-summary-box-inner">
                                        <span>Video content creation keeps growing at an incredible pace; yet, creating
engaging stories remains challenging and requires non-trivial video editing
expertise. Many video editing components are astonishingly hard to automate
primarily due to the lack of raw video materials. This paper focuses on a new
task for computational video editing, namely the task of raking cut
plausibility. Our key idea is to leverage content that has already been edited
to learn fine-grained audiovisual patterns that trigger cuts. To do this, we
first collected a data source of more than 10K videos, from which we extract
more than 255K cuts. We devise a model that learns to discriminate between real
and artificial cuts via contrastive learning. We set up a new task and a set of
baselines to benchmark video cut generation. We observe that our proposed model
outperforms the baselines by large margins. To demonstrate our model in
real-world applications, we conduct human studies in a collection of unedited
videos. The results show that our model does a better job at cutting than
random and alternative baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development. (arXiv:2108.04308v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scheuerman_M/0/1/0/all/0/1">Morgan Klaus Scheuerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Denton_E/0/1/0/all/0/1">Emily Denton</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanna_A/0/1/0/all/0/1">Alex Hanna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04308">
                                    <div class="article-summary-box-inner">
                                        <span>Data is a crucial component of machine learning. The field is reliant on data
to train, validate, and test models. With increased technical capabilities,
machine learning research has boomed in both academic and industry settings,
and one major focus has been on computer vision. Computer vision is a popular
domain of machine learning increasingly pertinent to real-world applications,
from facial recognition in policing to object detection for autonomous
vehicles. Given computer vision&#x27;s propensity to shape machine learning research
and impact human life, we seek to understand disciplinary practices around
dataset documentation - how data is collected, curated, annotated, and packaged
into datasets for computer vision researchers and practitioners to use for
model tuning and development. Specifically, we examine what dataset
documentation communicates about the underlying values of vision data and the
larger practices and goals of computer vision as a field. To conduct this
study, we collected a corpus of about 500 computer vision datasets, from which
we sampled 114 dataset publications across different vision tasks. Through both
a structured and thematic content analysis, we document a number of values
around accepted data practices, what makes desirable data, and the treatment of
humans in the dataset construction process. We discuss how computer vision
datasets authors value efficiency at the expense of care; universality at the
expense of contextuality; impartiality at the expense of positionality; and
model work at the expense of data work. Many of the silenced values we identify
sit in opposition with social computing practices. We conclude with suggestions
on how to better incorporate silenced values into the dataset creation and
curation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDLS: A Top-Down Layer Searching Algorithm for Generating Counterfactual Visual Explanation. (arXiv:2108.04238v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Haocheng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Caleb Chen Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04238">
                                    <div class="article-summary-box-inner">
                                        <span>Explanation of AI, as well as fairness of algorithms&#x27; decisions and the
transparency of the decision model, are becoming more and more important. And
it is crucial to design effective and human-friendly techniques when opening
the black-box model. Counterfactual conforms to the human way of thinking and
provides a human-friendly explanation, and its corresponding explanation
algorithm refers to a strategic alternation of a given data point so that its
model output is &quot;counter-facted&quot;, i.e. the prediction is reverted. In this
paper, we adapt counterfactual explanation over fine-grained image
classification problem. We demonstrated an adaptive method that could give a
counterfactual explanation by showing the composed counterfactual feature map
using top-down layer searching algorithm (TDLS). We have proved that our TDLS
algorithm could provide more flexible counterfactual visual explanation in an
efficient way using VGG-16 model on Caltech-UCSD Birds 200 dataset. At the end,
we discussed several applicable scenarios of counterfactual visual
explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Transfer Learning for Identifications of Slope Surface Cracks. (arXiv:2108.04235v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuting Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_G/0/1/0/all/0/1">Gang Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04235">
                                    <div class="article-summary-box-inner">
                                        <span>Geohazards such as landslides have caused great losses to the safety of
people&#x27;s lives and property, which is often accompanied with surface cracks. If
such surface cracks could be identified in time, it is of great significance
for the monitoring and early warning of geohazards. Currently, the most common
method for crack identification is manual detection, which is with low
efficiency and accuracy. In this paper, a deep transfer learning framework is
proposed to effectively and efficiently identify slope surface cracks for the
sake of fast monitoring and early warning of geohazards such as landslides. The
essential idea is to employ transfer learning by training (a) the large sample
dataset of concrete cracks and (b) the small sample dataset of soil and rock
masses cracks. In the proposed framework, (1) pretrained cracks identification
models are constructed based on the large sample dataset of concrete cracks;
(2) refined cracks identification models are further constructed based on the
small sample dataset of soil and rock masses cracks. The proposed framework
could be applied to conduct UAV surveys on high-steep slopes to realize the
monitoring and early warning of landslides to ensure the safety of people&#x27;s
lives and property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Method Towards CVPR 2021 SimLocMatch Challenge. (arXiv:2108.04466v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bi_X/0/1/0/all/0/1">Xiaopeng Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Ran Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1">Zheng Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haotian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04466">
                                    <div class="article-summary-box-inner">
                                        <span>This report describes Megvii-3D team&#x27;s approach to-wards SimLocMatch
Challenge @ CVPR 2021 Image Matching Workshop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Neural Cellular Automata. (arXiv:2108.04328v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Otte_M/0/1/0/all/0/1">Maximilian Otte</a>, <a href="http://arxiv.org/find/cs/1/au:+Delfosse_Q/0/1/0/all/0/1">Quentin Delfosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Czech_J/0/1/0/all/0/1">Johannes Czech</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04328">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the interaction between cells, the recently introduced concept
of Neural Cellular Automata shows promising results in a variety of tasks. So
far, this concept was mostly used to generate images for a single scenario. As
each scenario requires a new model, this type of generation seems contradictory
to the adaptability of cells in nature. To address this contradiction, we
introduce a concept using different initial environments as input while using a
single Neural Cellular Automata to produce several outputs. Additionally, we
introduce GANCA, a novel algorithm that combines Neural Cellular Automata with
Generative Adversarial Networks, allowing for more generalization through
adversarial training. The experiments show that a single model is capable of
learning several images when presented with different inputs, and that the
adversarially trained model improves drastically on out-of-distribution data
compared to a supervised trained model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantics-STGCNN: A Semantics-guided Spatial-Temporal Graph Convolutional Network for Multi-class Trajectory Prediction. (arXiv:2108.04740v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rainbow_B/0/1/0/all/0/1">Ben A. Rainbow</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_Q/0/1/0/all/0/1">Qianhui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04740">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the movement trajectories of multiple classes of road users in
real-world scenarios is a challenging task due to the diverse trajectory
patterns. While recent works of pedestrian trajectory prediction successfully
modelled the influence of surrounding neighbours based on the relative
distances, they are ineffective on multi-class trajectory prediction. This is
because they ignore the impact of the implicit correlations between different
types of road users on the trajectory to be predicted - for example, a nearby
pedestrian has a different level of influence from a nearby car. In this paper,
we propose to introduce class information into a graph convolutional neural
network to better predict the trajectory of an individual. We embed the class
labels of the surrounding objects into the label adjacency matrix (LAM), which
is combined with the velocity-based adjacency matrix (VAM) comprised of the
objects&#x27; velocity, thereby generating a semantics-guided graph adjacency (SAM).
SAM effectively models semantic information with trainable parameters to
automatically learn the embedded label features that will contribute to the
fixed velocity-based trajectory. Such information of spatial and temporal
dependencies is passed to a graph convolutional and temporal convolutional
network to estimate the predicted trajectory distributions. We further propose
new metrics, known as Average2 Displacement Error (aADE) and Average Final
Displacement Error (aFDE), that assess network accuracy more accurately. We
call our framework Semantics-STGCNN. It consistently shows superior performance
to the state-of-the-arts in existing and the newly proposed metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multigranular Visual-Semantic Embedding for Cloth-Changing Person Re-identification. (arXiv:2108.04527v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Hongwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_W/0/1/0/all/0/1">Weili Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1">Weizhi Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04527">
                                    <div class="article-summary-box-inner">
                                        <span>Person reidentification (ReID) is a very hot research topic in machine
learning and computer vision, and many person ReID approaches have been
proposed; however, most of these methods assume that the same person has the
same clothes within a short time interval, and thus their visual appearance
must be similar. However, in an actual surveillance environment, a given person
has a great probability of changing clothes after a long time span, and they
also often take different personal belongings with them. When the existing
person ReID methods are applied in this type of case, almost all of them fail.
To date, only a few works have focused on the cloth-changing person ReID task,
but since it is very difficult to extract generalized and robust features for
representing people with different clothes, their performances need to be
improved. Moreover, visual-semantic information is often ignored. To solve
these issues, in this work, a novel multigranular visual-semantic embedding
algorithm (MVSE) is proposed for cloth-changing person ReID, where visual
semantic information and human attributes are embedded into the network, and
the generalized features of human appearance can be well learned to effectively
solve the problem of clothing changes. Specifically, to fully represent a
person with clothing changes, a multigranular feature representation scheme
(MGR) is employed to focus on the unchanged part of the human, and then a cloth
desensitization network (CDN) is designed to improve the feature robustness of
the approach for the person with different clothing, where different high-level
human attributes are fully utilized. Moreover, to further solve the issue of
pose changes and occlusion under different camera perspectives, a partially
semantically aligned network (PSA) is proposed to obtain the visual-semantic
information that is used to align the human attributes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reference-based Defect Detection Network. (arXiv:2108.04456v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhaoyang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_H/0/1/0/all/0/1">Hongyang Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04456">
                                    <div class="article-summary-box-inner">
                                        <span>The defect detection task can be regarded as a realistic scenario of object
detection in the computer vision field and it is widely used in the industrial
field. Directly applying vanilla object detector to defect detection task can
achieve promising results, while there still exists challenging issues that
have not been solved. The first issue is the texture shift which means a
trained defect detector model will be easily affected by unseen texture, and
the second issue is partial visual confusion which indicates that a partial
defect box is visually similar with a complete box. To tackle these two
problems, we propose a Reference-based Defect Detection Network (RDDN).
Specifically, we introduce template reference and context reference to against
those two problems, respectively. Template reference can reduce the texture
shift from image, feature or region levels, and encourage the detectors to
focus more on the defective area as a result. We can use either well-aligned
template images or the outputs of a pseudo template generator as template
references in this work, and they are jointly trained with detectors by the
supervision of normal samples. To solve the partial visual confusion issue, we
propose to leverage the carried context information of context reference, which
is the concentric bigger box of each region proposal, to perform more accurate
region classification and regression. Experiments on two defect detection
datasets demonstrate the effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptable image quality assessment using meta-reinforcement learning of task amenability. (arXiv:2108.04359v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saeed_S/0/1/0/all/0/1">Shaheer U. Saeed</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yunguan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavrinides_V/0/1/0/all/0/1">Vasilis Stavrinides</a>, <a href="http://arxiv.org/find/cs/1/au:+Baum_Z/0/1/0/all/0/1">Zachary M. C. Baum</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qianye Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rusu_M/0/1/0/all/0/1">Mirabela Rusu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Richard E. Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonn_G/0/1/0/all/0/1">Geoffrey A. Sonn</a>, <a href="http://arxiv.org/find/cs/1/au:+Noble_J/0/1/0/all/0/1">J. Alison Noble</a>, <a href="http://arxiv.org/find/cs/1/au:+Barratt_D/0/1/0/all/0/1">Dean C. Barratt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yipeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04359">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of many medical image analysis tasks are strongly associated
with image data quality. When developing modern deep learning algorithms,
rather than relying on subjective (human-based) image quality assessment (IQA),
task amenability potentially provides an objective measure of task-specific
image quality. To predict task amenability, an IQA agent is trained using
reinforcement learning (RL) with a simultaneously optimised task predictor,
such as a classification or segmentation neural network. In this work, we
develop transfer learning or adaptation strategies to increase the adaptability
of both the IQA agent and the task predictor so that they are less dependent on
high-quality, expert-labelled training data. The proposed transfer learning
strategy re-formulates the original RL problem for task amenability in a
meta-reinforcement learning (meta-RL) framework. The resulting algorithm
facilitates efficient adaptation of the agent to different definitions of image
quality, each with its own Markov decision process environment including
different images, labels and an adaptable task predictor. Our work demonstrates
that the IQA agents pre-trained on non-expert task labels can be adapted to
predict task amenability as defined by expert task labels, using only a small
set of expert labels. Using 6644 clinical ultrasound images from 249 prostate
cancer patients, our results for image classification and segmentation tasks
show that the proposed IQA method can be adapted using data with as few as
respective 19.7% and 29.6% expert-reviewed consensus labels and still achieve
comparable IQA and task performance, which would otherwise require a training
dataset with 100% expert labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANmapper: geographical content filling. (arXiv:2108.04232v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Abraham Noah Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1">Filip Biljecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04232">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new method to create spatial data using a generative adversarial
network (GAN). Our contribution uses coarse and widely available geospatial
data to create maps of less available features at the finer scale in the built
environment, bypassing their traditional acquisition techniques (e.g. satellite
imagery or land surveying). In the work, we employ land use data and road
networks as input to generate building footprints, and conduct experiments in 9
cities around the world. The method, which we implement in a tool we release
openly, enables generating approximate maps of the urban form, and it is
generalisable to augment other types of geoinformation, enhancing the
completeness and quality of spatial data infrastructure. It may be especially
useful in locations missing detailed and high-resolution data and those that
are mapped with uncertain or heterogeneous quality, such as much of
OpenStreetMap. The quality of the results is influenced by the urban form and
scale. In most cases, experiments suggest promising performance as the method
tends to truthfully indicate the locations, amount, and shape of buildings. The
work has the potential to support several applications, such as energy,
climate, and urban morphology studies in areas previously lacking required
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Robust Lane Detection Associated with Quaternion Hardy Filter. (arXiv:2108.04356v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1">Wenshan Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Dong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kou_K/0/1/0/all/0/1">Kit Ian Kou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04356">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, a robust color-edge feature extraction method based on the
Quaternion Hardy filter is proposed. The Quaternion Hardy filter is an emerging
edge detection theory. It is along with the Poisson and conjugate Poisson
smoothing kernels to handle various types of noise. Combining with the
Quaternion Hardy filter, Jin&#x27;s color gradient operator and Hough transform, the
color-edge feature detection algorithm is proposed and applied to the lane
marking detection. Experiments are presented to demonstrate the validity of the
proposed algorithm. The results are accurate and robust with respect to the
complex environment lane markings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class dependency based learning using Bi-LSTM coupled with the transfer learning of VGG16 for the diagnosis of Tuberculosis from chest x-rays. (arXiv:2108.04329v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdary_G/0/1/0/all/0/1">G Jignesh Chowdary</a>, <a href="http://arxiv.org/find/cs/1/au:+G_S/0/1/0/all/0/1">Suganya G</a>, <a href="http://arxiv.org/find/cs/1/au:+M_P/0/1/0/all/0/1">Premalatha M</a>, <a href="http://arxiv.org/find/cs/1/au:+K_K/0/1/0/all/0/1">Karunamurthy K</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04329">
                                    <div class="article-summary-box-inner">
                                        <span>Tuberculosis is an infectious disease that is leading to the death of
millions of people across the world. The mortality rate of this disease is high
in patients suffering from immuno-compromised disorders. The early diagnosis of
this disease can save lives and can avoid further complications. But the
diagnosis of TB is a very complex task. The standard diagnostic tests still
rely on traditional procedures developed in the last century. These procedures
are slow and expensive. So this paper presents an automatic approach for the
diagnosis of TB from posteroanterior chest x-rays. This is a two-step approach,
where in the first step the lung regions are segmented from the chest x-rays
using the graph cut method, and then in the second step the transfer learning
of VGG16 combined with Bi-directional LSTM is used for extracting high-level
discriminative features from the segmented lung regions and then classification
is performed using a fully connected layer. The proposed model is evaluated
using data from two publicly available databases namely Montgomery Country set
and Schezien set. The proposed model achieved accuracy and sensitivity of
97.76%, 97.01% and 96.42%, 94.11% on Schezien and Montgomery county datasets.
This model enhanced the diagnostic accuracy of TB by 0.7% and 11.68% on
Schezien and Montgomery county datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Aware Universal Style Transfer. (arXiv:2108.04441v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1">Kibeom Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1">Seogkyu Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Huan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_H/0/1/0/all/0/1">Hyeran Byun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04441">
                                    <div class="article-summary-box-inner">
                                        <span>Style transfer aims to reproduce content images with the styles from
reference images. Existing universal style transfer methods successfully
deliver arbitrary styles to original images either in an artistic or a
photo-realistic way. However, the range of &#x27;arbitrary style&#x27; defined by
existing works is bounded in the particular domain due to their structural
limitation. Specifically, the degrees of content preservation and stylization
are established according to a predefined target domain. As a result, both
photo-realistic and artistic models have difficulty in performing the desired
style transfer for the other domain. To overcome this limitation, we propose a
unified architecture, Domain-aware Style Transfer Networks (DSTN) that transfer
not only the style but also the property of domain (i.e., domainness) from a
given reference image. To this end, we design a novel domainness indicator that
captures the domainness value from the texture and structural features of
reference images. Moreover, we introduce a unified framework with domain-aware
skip connection to adaptively transfer the stroke and palette to the input
contents guided by the domainness indicator. Our extensive experiments validate
that our model produces better qualitative results and outperforms previous
methods in terms of proxy metrics on both artistic and photo-realistic
stylizations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SP-GAN: Sphere-Guided 3D Shape Generation and Manipulation. (arXiv:2108.04476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruihui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_K/0/1/0/all/0/1">Ka-Hei Hui</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04476">
                                    <div class="article-summary-box-inner">
                                        <span>We present SP-GAN, a new unsupervised sphere-guided generative model for
direct synthesis of 3D shapes in the form of point clouds. Compared with
existing models, SP-GAN is able to synthesize diverse and high-quality shapes
with fine details and promote controllability for part-aware shape generation
and manipulation, yet trainable without any parts annotations. In SP-GAN, we
incorporate a global prior (uniform points on a sphere) to spatially guide the
generative process and attach a local prior (a random latent code) to each
sphere point to provide local details. The key insight in our design is to
disentangle the complex 3D shape generation task into a global shape modeling
and a local structure adjustment, to ease the learning process and enhance the
shape generation quality. Also, our model forms an implicit dense
correspondence between the sphere points and points in every generated shape,
enabling various forms of structure-aware shape manipulations such as part
editing, part-wise shape interpolation, and multi-shape part composition, etc.,
beyond the existing generative models. Experimental results, which include both
visual and quantitative evaluations, demonstrate that our model is able to
synthesize diverse point clouds with fine details and less noise, as compared
with the state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RaftMLP: Do MLP-based Models Dream of Winning Over Computer Vision?. (arXiv:2108.04384v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tatsunami_Y/0/1/0/all/0/1">Yuki Tatsunami</a>, <a href="http://arxiv.org/find/cs/1/au:+Taki_M/0/1/0/all/0/1">Masato Taki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04384">
                                    <div class="article-summary-box-inner">
                                        <span>For the past ten years, CNN has reigned supreme in the world of computer
vision, but recently, Transformer is on the rise. However, the quadratic
computational cost of self-attention has become a severe problem of practice.
There has been much research on architectures without CNN and self-attention in
this context. In particular, MLP-Mixer is a simple idea designed using MLPs and
hit an accuracy comparable to the Vision Transformer. However, the only
inductive bias in this architecture is the embedding of tokens. Thus, there is
still a possibility to build a non-convolutional inductive bias into the
architecture itself, and we built in an inductive bias using two simple ideas.
A way is to divide the token-mixing block vertically and horizontally. Another
way is to make spatial correlations denser among some channels of token-mixing.
With this approach, we were able to improve the accuracy of the MLP-Mixer while
reducing its parameters and computational complexity. Compared to other
MLP-based models, the proposed model, named RaftMLP has a good balance of
computational complexity, the number of parameters, and actual memory usage. In
addition, our work indicates that MLP-based models have the potential to
replace CNNs by adopting inductive bias. The source code in PyTorch version is
available at \url{https://github.com/okojoalg/raft-mlp}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Character Recognition using Visual Explanations Derived from the Human Visual System and Deep Networks. (arXiv:2108.04558v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ralekar_C/0/1/0/all/0/1">Chetan Ralekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1">Shubham Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_T/0/1/0/all/0/1">Tapan Kumar Gandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1">Santanu Chaudhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04558">
                                    <div class="article-summary-box-inner">
                                        <span>Human observers engage in selective information uptake when classifying
visual patterns. The same is true of deep neural networks, which currently
constitute the best performing artificial vision systems. Our goal is to
examine the congruence, or lack thereof, in the information-gathering
strategies of the two systems. We have operationalized our investigation as a
character recognition task. We have used eye-tracking to assay the spatial
distribution of information hotspots for humans via fixation maps and an
activation mapping technique for obtaining analogous distributions for deep
networks through visualization maps. Qualitative comparison between
visualization maps and fixation maps reveals an interesting correlate of
congruence. The deep learning model considered similar regions in character,
which humans have fixated in the case of correctly classified characters. On
the other hand, when the focused regions are different for humans and deep
nets, the characters are typically misclassified by the latter. Hence, we
propose to use the visual fixation maps obtained from the eye-tracking
experiment as a supervisory input to align the model&#x27;s focus on relevant
character regions. We find that such supervision improves the model&#x27;s
performance significantly and does not require any additional parameters. This
approach has the potential to find applications in diverse domains such as
medical analysis and surveillance in which explainability helps to determine
system fidelity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Procedural Adversarial Noise Attack And Defense. (arXiv:2108.04409v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiaoyang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Huilin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Wancheng Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04409">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) are vulnerable to adversarial examples which
would inveigle neural networks to make prediction errors with small per-
turbations on the input images. Researchers have been devoted to promoting the
research on the universal adversarial perturbations (UAPs) which are
gradient-free and have little prior knowledge on data distributions. Procedural
adversarial noise at- tack is a data-free universal perturbation generation
method. In this paper, we propose two universal adversarial perturbation (UAP)
generation methods based on procedural noise functions: Simplex noise and
Worley noise. In our framework, the shading which disturbs visual
classification is generated with rendering technology. Without changing the
semantic representations, the adversarial examples generated via our methods
show superior performance on the attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FT-TDR: Frequency-guided Transformer and Top-Down Refinement Network for Blind Face Inpainting. (arXiv:2108.04424v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junke Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shaoxiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04424">
                                    <div class="article-summary-box-inner">
                                        <span>Blind face inpainting refers to the task of reconstructing visual contents
without explicitly indicating the corrupted regions in a face image.
Inherently, this task faces two challenges: (1) how to detect various mask
patterns of different shapes and contents; (2) how to restore visually
plausible and pleasing contents in the masked regions. In this paper, we
propose a novel two-stage blind face inpainting method named Frequency-guided
Transformer and Top-Down Refinement Network (FT-TDR) to tackle these
challenges. Specifically, we first use a transformer-based network to detect
the corrupted regions to be inpainted as masks by modeling the relation among
different patches. We also exploit the frequency modality as complementary
information for improved detection results and capture the local contextual
incoherence to enhance boundary consistency. Then a top-down refinement network
is proposed to hierarchically restore features at different levels and generate
contents that are semantically consistent with the unmasked face regions.
Extensive experiments demonstrate that our method outperforms current
state-of-the-art blind and non-blind face inpainting methods qualitatively and
quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Architecture Selection in Differentiable NAS. (arXiv:2108.04392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruochen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Minhao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04392">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable Neural Architecture Search is one of the most popular Neural
Architecture Search (NAS) methods for its search efficiency and simplicity,
accomplished by jointly optimizing the model weight and architecture parameters
in a weight-sharing supernet via gradient-based algorithms. At the end of the
search phase, the operations with the largest architecture parameters will be
selected to form the final architecture, with the implicit assumption that the
values of architecture parameters reflect the operation strength. While much
has been discussed about the supernet&#x27;s optimization, the architecture
selection process has received little attention. We provide empirical and
theoretical analysis to show that the magnitude of architecture parameters does
not necessarily indicate how much the operation contributes to the supernet&#x27;s
performance. We propose an alternative perturbation-based architecture
selection that directly measures each operation&#x27;s influence on the supernet. We
re-evaluate several differentiable NAS methods with the proposed architecture
selection and find that it is able to extract significantly improved
architectures from the underlying supernets consistently. Furthermore, we find
that several failure modes of DARTS can be greatly alleviated with the proposed
selection method, indicating that much of the poor generalization observed in
DARTS can be attributed to the failure of magnitude-based architecture
selection rather than entirely the optimization of its supernet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Nets for Diabetic Retinopathy Screening in Bangladeshi Patients. (arXiv:2108.04358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haque_A/0/1/0/all/0/1">Ayaan Haque</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutradhar_I/0/1/0/all/0/1">Ipsita Sutradhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahziba Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Mehedi Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_M/0/1/0/all/0/1">Malabika Sarker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04358">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetes is one of the most prevalent chronic diseases in Bangladesh, and as
a result, Diabetic Retinopathy (DR) is widespread in the population. DR, an eye
illness caused by diabetes, can lead to blindness if it is not identified and
treated in its early stages. Unfortunately, diagnosis of DR requires medically
trained professionals, but Bangladesh has limited specialists in comparison to
its population. Moreover, the screening process is often expensive, prohibiting
many from receiving timely and proper diagnosis. To address the problem, we
introduce a deep learning algorithm which screens for different stages of DR.
We use a state-of-the-art CNN architecture to diagnose patients based on
retinal fundus imagery. This paper is an experimental evaluation of the
algorithm we developed for DR diagnosis and screening specifically for
Bangladeshi patients. We perform this validation study using separate pools of
retinal image data of real patients from a hospital and field studies in
Bangladesh. Our results show that the algorithm is effective at screening
Bangladeshi eyes even when trained on a public dataset which is out of domain,
and can accurately determine the stage of DR as well, achieving an overall
accuracy of 92.27\% and 93.02\% on two validation sets of Bangladeshi eyes. The
results confirm the ability of the algorithm to be used in real clinical
settings and applications due to its high accuracy and classwise metrics. Our
algorithm is implemented in the application Drishti, which is used to screen
for DR in patients living in rural areas in Bangladesh, where access to
professional screening is limited.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stroke Correspondence by Labeling Closed Areas. (arXiv:2108.04393v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miyauchi_R/0/1/0/all/0/1">Ryoma Miyauchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukusato_T/0/1/0/all/0/1">Tsukasa Fukusato</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Haoran Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyata_K/0/1/0/all/0/1">Kazunori Miyata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04393">
                                    <div class="article-summary-box-inner">
                                        <span>Constructing stroke correspondences between keyframes is one of the most
important processes in the production pipeline of hand-drawn inbetweening
frames. This process requires time-consuming manual work imposing a tremendous
burden on the animators. We propose a method to estimate stroke correspondences
between raster character images (keyframes) without vectorization processes.
First, the proposed system separates the closed areas in each keyframe and
estimates the correspondences between closed areas by using the characteristics
of shape, depth, and closed area connection. Second, the proposed system
estimates stroke correspondences from the estimated closed area
correspondences. We demonstrate the effectiveness of our method by performing a
user study and comparing the proposed system with conventional approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMUSED: An Annotation Framework of Multi-modal Social Media Data. (arXiv:2010.00502v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00502">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a semi-automated framework called AMUSED for
gathering multi-modal annotated data from the multiple social media platforms.
The framework is designed to mitigate the issues of collecting and annotating
social media data by cohesively combining machine and human in the data
collection process. From a given list of the articles from professional news
media or blog, AMUSED detects links to the social media posts from news
articles and then downloads contents of the same post from the respective
social media platform to gather details about that specific post. The framework
is capable of fetching the annotated data from multiple platforms like Twitter,
YouTube, Reddit. The framework aims to reduce the workload and problems behind
the data annotation from the social media platforms. AMUSED can be applied in
multiple application domains, as a use case, we have implemented the framework
for collecting COVID-19 misinformation data from different social media
platforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSO: Personalized Cold Start Modules for Large-scale Recommender Systems. (arXiv:2108.04690v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Shangfeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Haobin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhichen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jianying Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Honghuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+PinghuaGong/0/1/0/all/0/1">PinghuaGong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04690">
                                    <div class="article-summary-box-inner">
                                        <span>Recommendation for new users, also called user cold start, has been a
well-recognized challenge for online recommender systems. Most existing methods
view the crux as the lack of initial data. However, in this paper, we argue
that there are neglected problems: 1) New users&#x27; behaviour follows much
different distributions from regular users. 2) Although personalized features
are involved, heavily imbalanced samples prevent the model from balancing
new/regular user distributions, as if the personalized features are
overwhelmed. We name the problem as the &#x60;&#x60;submergence&quot; of personalization. To
tackle this problem, we propose a novel module: Personalized COld Start MOdules
(POSO). Considering from a model architecture perspective, POSO personalizes
existing modules by introducing multiple user-group-specialized sub-modules.
Then, it fuses their outputs by personalized gates, resulting in comprehensive
representations. In such way, POSO projects imbalanced features to even
modules. POSO can be flexibly integrated into many existing modules and
effectively improves their performance with negligible computational overheads.
The proposed method shows remarkable advantage in industrial scenario. It has
been deployed on the large-scale recommender system of Kwai, and improves new
user Watch Time by a large margin (+7.75%). Moreover, POSO can be further
generalized to regular users, inactive users and returning users (+2%-3% on
Watch Time), as well as item cold start (+3.8% on Watch Time). Its
effectiveness has also been verified on public dataset (MovieLens 20M). We
believe such practical experience can be well generalized to other scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Quality Related Search Query Suggestions using Deep Reinforcement Learning. (arXiv:2108.04452v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bodigutla_P/0/1/0/all/0/1">Praveen Kumar Bodigutla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04452">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;High Quality Related Search Query Suggestions&quot; task aims at recommending
search queries which are real, accurate, diverse, relevant and engaging.
Obtaining large amounts of query-quality human annotations is expensive. Prior
work on supervised query suggestion models suffered from selection and exposure
bias, and relied on sparse and noisy immediate user-feedback (e.g., clicks),
leading to low quality suggestions. Reinforcement Learning techniques employed
to reformulate a query using terms from search results, have limited
scalability to large-scale industry applications. To recommend high quality
related search queries, we train a Deep Reinforcement Learning model to predict
the query a user would enter next. The reward signal is composed of long-term
session-based user feedback, syntactic relatedness and estimated naturalness of
generated query. Over the baseline supervised model, our proposed approach
achieves a significant relative improvement in terms of recommendation
diversity (3%), down-stream user-engagement (4.2%) and per-sentence word
repetitions (82%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully Hyperbolic Graph Convolution Network for Recommendation. (arXiv:2108.04607v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1">Fenyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04607">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Graph Convolution Network (GCN) based methods have achieved
outstanding performance for recommendation. These methods embed users and items
in Euclidean space, and perform graph convolution on user-item interaction
graphs. However, real-world datasets usually exhibit tree-like hierarchical
structures, which make Euclidean space less effective in capturing user-item
relationship. In contrast, hyperbolic space, as a continuous analogue of a
tree-graph, provides a promising alternative. In this paper, we propose a fully
hyperbolic GCN model for recommendation, where all operations are performed in
hyperbolic space. Utilizing the advantage of hyperbolic space, our method is
able to embed users/items with less distortion and capture user-item
interaction relationship more accurately. Extensive experiments on public
benchmark datasets show that our method outperforms both Euclidean and
hyperbolic counterparts and requires far lower embedding dimensionality to
achieve comparable performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Latent Relation Modeling for Collaborative Metric Learning. (arXiv:2108.04655v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Viet-Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1">Guillaume Salha-Galvan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1">Romain Hennequin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moussallam_M/0/1/0/all/0/1">Manuel Moussallam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04655">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative Metric Learning (CML) recently emerged as a powerful paradigm
for recommendation based on implicit feedback collaborative filtering. However,
standard CML methods learn fixed user and item representations, which fails to
capture the complex interests of users. Existing extensions of CML also either
ignore the heterogeneity of user-item relations, i.e. that a user can
simultaneously like very different items, or the latent item-item relations,
i.e. that a user&#x27;s preference for an item depends, not only on its intrinsic
characteristics, but also on items they previously interacted with. In this
paper, we present a hierarchical CML model that jointly captures latent
user-item and item-item relations from implicit data. Our approach is inspired
by translation mechanisms from knowledge graph embedding and leverages
memory-based attention networks. We empirically show the relevance of this
joint relational modeling, by outperforming existing CML models on
recommendation tasks on several real-world datasets. Our experiments also
emphasize the limits of current CML relational models on very sparse datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End User Behavior Retrieval in Click-Through RatePrediction Model. (arXiv:2108.04468v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_C/0/1/0/all/0/1">Changhua Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1">Shanshan Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1">Junfeng Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_W/0/1/0/all/0/1">Wenwu Ou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04468">
                                    <div class="article-summary-box-inner">
                                        <span>Click-Through Rate (CTR) prediction is one of the core tasks in recommender
systems (RS). It predicts a personalized click probability for each user-item
pair. Recently, researchers have found that the performance of CTR model can be
improved greatly by taking user behavior sequence into consideration,
especially long-term user behavior sequence. The report on an e-commerce
website shows that 23\% of users have more than 1000 clicks during the past 5
months. Though there are numerous works focus on modeling sequential user
behaviors, few works can handle long-term user behavior sequence due to the
strict inference time constraint in real world system. Two-stage methods are
proposed to push the limit for better performance. At the first stage, an
auxiliary task is designed to retrieve the top-$k$ similar items from long-term
user behavior sequence. At the second stage, the classical attention mechanism
is conducted between the candidate item and $k$ items selected in the first
stage. However, information gap happens between retrieval stage and the main
CTR task. This goal divergence can greatly diminishing the performance gain of
long-term user sequence. In this paper, inspired by Reformer, we propose a
locality-sensitive hashing (LSH) method called ETA (End-to-end Target
Attention) which can greatly reduce the training and inference cost and make
the end-to-end training with long-term user behavior sequence possible. Both
offline and online experiments confirm the effectiveness of our model. We
deploy ETA into a large-scale real world E-commerce system and achieve extra
3.1\% improvements on GMV (Gross Merchandise Value) compared to a two-stage
long user sequence CTR model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Localized Graph Collaborative Filtering. (arXiv:2108.04475v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chaozhuo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mingzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04475">
                                    <div class="article-summary-box-inner">
                                        <span>User-item interactions in recommendations can be naturally de-noted as a
user-item bipartite graph. Given the success of graph neural networks (GNNs) in
graph representation learning, GNN-based C methods have been proposed to
advance recommender systems. These methods often make recommendations based on
the learned user and item embeddings. However, we found that they do not
perform well wit sparse user-item graphs which are quite common in real-world
recommendations. Therefore, in this work, we introduce a novel perspective to
build GNN-based CF methods for recommendations which leads to the proposed
framework Localized Graph Collaborative Filtering (LGCF). One key advantage of
LGCF is that it does not need to learn embeddings for each user and item, which
is challenging in sparse scenarios.

Alternatively, LGCF aims at encoding useful CF information into a localized
graph and making recommendations based on such graph. Extensive experiments on
various datasets validate the effectiveness of LGCF especially in sparse
scenarios. Furthermore, empirical results demonstrate that LGCF provides
complementary information to the embedding-based CF model which can be utilized
to boost recommendation performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce. (arXiv:2107.08598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuesi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huzhang_G/0/1/0/all/0/1">Guangda Huzhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1">Qianying Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Da_Q/0/1/0/all/0/1">Qing Da</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08598">
                                    <div class="article-summary-box-inner">
                                        <span>Ensemble models in E-commerce combine predictions from multiple sub-models
for ranking and revenue improvement. Industrial ensemble models are typically
deep neural networks, following the supervised learning paradigm to infer
conversion rate given inputs from sub-models. However, this process has the
following two problems. Firstly, the point-wise scoring approach disregards the
relationships between items and leads to homogeneous displayed results, while
diversified display benefits user experience and revenue. Secondly, the
learning paradigm focuses on the ranking metrics and does not directly optimize
the revenue. In our work, we propose a new Learning-To-Ensemble (LTE) framework
RAEGO, which replaces the ensemble model with a contextual Rank Aggregator (RA)
and explores the best weights of sub-models by the Evaluator-Generator
Optimization (EGO). To achieve the best online performance, we propose a new
rank aggregation algorithm TournamentGreedy as a refinement of classic rank
aggregators, which also produces the best average weighted Kendall Tau Distance
(KTD) amongst all the considered algorithms with quadratic time complexity.
Under the assumption that the best output list should be Pareto Optimal on the
KTD metric for sub-models, we show that our RA algorithm has higher efficiency
and coverage in exploring the optimal weights. Combined with the idea of
Bayesian Optimization and gradient descent, we solve the online contextual
Black-Box Optimization task that finds the optimal weights for sub-models given
a chosen RA model. RA-EGO has been deployed in our online system and has
improved the revenue significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep generative model for probabilistic energy forecasting in power systems: normalizing flows. (arXiv:2106.09370v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanaspeze_A/0/1/0/all/0/1">Antoine Wehenkel Damien Lanaspeze</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornelusse_B/0/1/0/all/0/1">Bertrand Corn&#xe9;lusse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutera_A/0/1/0/all/0/1">Antonio Sutera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09370">
                                    <div class="article-summary-box-inner">
                                        <span>Greater direct electrification of end-use sectors with a higher share of
renewables is one of the pillars to power a carbon-neutral society by 2050.
However, in contrast to conventional power plants, renewable energy is subject
to uncertainty raising challenges for their interaction with power systems.
Scenario-based probabilistic forecasting models have become an important tool
to equip decision-makers. This paper proposes to present to the power systems
forecasting practitioners a recent deep learning technique, the normalizing
flows, to produce accurate scenario-based probabilistic forecasts that are
crucial to face the new challenges in power systems applications. The strength
of this technique is to directly learn the stochastic multivariate distribution
of the underlying process by maximizing the likelihood. Through comprehensive
empirical evaluations using the open data of the Global Energy Forecasting
Competition 2014, we demonstrate that this methodology is competitive with
other state-of-the-art deep learning generative models: generative adversarial
networks and variational autoencoders. The models producing weather-based wind,
solar power, and load scenarios are properly compared both in terms of forecast
value, by considering the case study of an energy retailer, and quality using
several complementary metrics. The numerical experiments are simple and easily
reproducible. Thus, we hope it will encourage other forecasting practitioners
to test and use normalizing flows in power system applications such as bidding
on electricity markets, scheduling of power systems with high renewable energy
sources penetration, energy management of virtual power plan or microgrids, and
unit commitment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdvRush: Searching for Adversarially Robust Neural Architectures. (arXiv:2108.01289v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1">Jisoo Mok</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1">Byunggook Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1">Hyeokjun Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01289">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks continue to awe the world with their remarkable
performance. Their predictions, however, are prone to be corrupted by
adversarial examples that are imperceptible to humans. Current efforts to
improve the robustness of neural networks against adversarial examples are
focused on developing robust training methods, which update the weights of a
neural network in a more robust direction. In this work, we take a step beyond
training of the weight parameters and consider the problem of designing an
adversarially robust neural architecture with high intrinsic robustness. We
propose AdvRush, a novel adversarial robustness-aware neural architecture
search algorithm, based upon a finding that independent of the training method,
the intrinsic robustness of a neural network can be represented with the
smoothness of its input loss landscape. Through a regularizer that favors a
candidate architecture with a smoother input loss landscape, AdvRush
successfully discovers an adversarially robust neural architecture. Along with
a comprehensive theoretical motivation for AdvRush, we conduct an extensive
amount of experiments to demonstrate the efficacy of AdvRush on various
benchmark datasets. Notably, on CIFAR-10, AdvRush achieves 55.91% robust
accuracy under FGSM attack after standard training and 50.04% robust accuracy
under AutoAttack after 7-step PGD adversarial training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoVideo: An Automated Video Action Recognition System. (arXiv:2108.04212v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_Z/0/1/0/all/0/1">Zaid Pervaiz Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Sirui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Anmoll Kumar Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1">Mohammad Qazim Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1">Kwei-Herng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaben Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_N/0/1/0/all/0/1">Na Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04212">
                                    <div class="article-summary-box-inner">
                                        <span>Action recognition is a crucial task for video understanding. In this paper,
we present AutoVideo, a Python system for automated video action recognition.
It currently supports seven action recognition algorithms and various
pre-processing modules. Unlike the existing libraries that only provide model
zoos, AutoVideo is built with the standard pipeline language. The basic
building block is primitive, which wraps a pre-processing module or an
algorithm with some hyperparameters. AutoVideo is highly modular and
extendable. It can be easily combined with AutoML searchers. The pipeline
language is quite general so that we can easily enrich AutoVideo with
algorithms for various other video-related tasks in the future. AutoVideo is
released under MIT license at https://github.com/datamllab/autovideo</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning architectures for generalized immunofluorescence based nuclear image segmentation. (arXiv:1907.12975v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kromp_F/0/1/0/all/0/1">Florian Kromp</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1">Lukas Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozsaky_E/0/1/0/all/0/1">Eva Bozsaky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambros_I/0/1/0/all/0/1">Inge Ambros</a>, <a href="http://arxiv.org/find/cs/1/au:+Doerr_W/0/1/0/all/0/1">Wolfgang Doerr</a>, <a href="http://arxiv.org/find/cs/1/au:+Taschner_Mandl_S/0/1/0/all/0/1">Sabine Taschner-Mandl</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambros_P/0/1/0/all/0/1">Peter Ambros</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.12975">
                                    <div class="article-summary-box-inner">
                                        <span>Separating and labeling each instance of a nucleus (instance-aware
segmentation) is the key challenge in segmenting single cell nuclei on
fluorescence microscopy images. Deep Neural Networks can learn the implicit
transformation of a nuclear image into a probability map indicating the class
membership of each pixel (nucleus or background), but the use of
post-processing steps to turn the probability map into a labeled object mask is
error-prone. This especially accounts for nuclear images of tissue sections and
nuclear images across varying tissue preparations. In this work, we aim to
evaluate the performance of state-of-the-art deep learning architectures to
segment nuclei in fluorescence images of various tissue origins and sample
preparation types without post-processing. We compare architectures that
operate on pixel to pixel translation and an architecture that operates on
object detection and subsequent locally applied segmentation. In addition, we
propose a novel strategy to create artificial images to extend the training
set. We evaluate the influence of ground truth annotation quality, image scale
and segmentation complexity on segmentation performance. Results show that
three out of four deep learning architectures (U-Net, U-Net with ResNet34
backbone, Mask R-CNN) can segment fluorescent nuclear images on most of the
sample preparation types and tissue origins with satisfactory segmentation
performance. Mask R-CNN, an architecture designed to address instance aware
segmentation tasks, outperforms other architectures. Equal nuclear mean size,
consistent nuclear annotations and the use of artificially generated images
result in overall acceptable precision and recall across different tissues and
sample preparation types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack. (arXiv:2106.06895v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Odetola_T/0/1/0/all/0/1">Tolulope Odetola</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalid_F/0/1/0/all/0/1">Faiq Khalid</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandefur_T/0/1/0/all/0/1">Travis Sandefur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammed_H/0/1/0/all/0/1">Hawzhin Mohammed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1">Syed Rafay Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06895">
                                    <div class="article-summary-box-inner">
                                        <span>To reduce the time-to-market and access to state-of-the-art techniques, CNN
hardware mapping and deployment on embedded accelerators are often outsourced
to untrusted third parties, which is going to be more prevalent in futuristic
artificial intelligence of things (AIoT) systems. These AIoT systems anticipate
horizontal collaboration among different resource-constrained AIoT node
devices, where CNN layers are partitioned and these devices collaboratively
compute complex CNN tasks. This horizontal collaboration opens another attack
surface to the CNN-based application, like inserting the hardware Trojans (HT)
into the embedded accelerators designed for the CNN. Therefore, there is a dire
need to explore this attack surface for designing secure embedded hardware
accelerators for CNNs. Towards this goal, in this paper, we exploited this
attack surface to propose an HT-based attack called FeSHI. Since in horizontal
collaboration of RC AIoT devices different sections of CNN architectures are
outsourced to different untrusted third parties, the attacker may not know the
input image, but it has access to the layer-by-layer output feature maps
information for the assigned sections of the CNN architecture. This attack
exploits the statistical distribution, i.e., Gaussian distribution, of the
layer-by-layer feature maps of the CNN to design two triggers for stealthy HT
with a very low probability of triggering. Also, three different novel,
stealthy and effective trigger designs are proposed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Developing Open Source Educational Resources for Machine Learning and Data Science. (arXiv:2107.14330v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bothmann_L/0/1/0/all/0/1">Ludwig Bothmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Strickroth_S/0/1/0/all/0/1">Sven Strickroth</a>, <a href="http://arxiv.org/find/cs/1/au:+Casalicchio_G/0/1/0/all/0/1">Giuseppe Casalicchio</a>, <a href="http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1">David R&#xfc;gamer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1">Marius Lindauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheipl_F/0/1/0/all/0/1">Fabian Scheipl</a>, <a href="http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14330">
                                    <div class="article-summary-box-inner">
                                        <span>Education should not be a privilege but a common good. It should be openly
accessible to everyone, with as few barriers as possible; even more so for key
technologies such as Machine Learning (ML) and Data Science (DS). Open
Educational Resources (OER) are a crucial factor for greater educational
equity. In this paper, we describe the specific requirements for OER in ML and
DS and argue that it is especially important for these fields to make source
files publicly available, leading to Open Source Educational Resources (OSER).
We present our view on the collaborative development of OSER, the challenges
this poses, and first steps towards their solutions. We outline how OSER can be
used for blended learning scenarios and share our experiences in university
education. Finally, we discuss additional challenges such as credit assignment
or granting certificates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding the Condensation of Two-layer Neural Networks at Initial Training. (arXiv:2105.11686v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhi-Qin John Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hanxu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yaoyu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11686">
                                    <div class="article-summary-box-inner">
                                        <span>Studying the implicit regularization effect of the nonlinear training
dynamics of neural networks (NNs) is important for understanding why
over-parameterized neural networks often generalize well on real dataset.
Empirically, for two-layer NN, existing works have shown that input weights of
hidden neurons (the input weight of a hidden neuron consists of the weight from
its input layer to the hidden neuron and its bias term) condense on isolated
orientations with a small initialization. The condensation dynamics implies
that NNs can learn features from the training data with a network configuration
effectively equivalent to a much smaller network during the training. In this
work, we show that the multiple roots of activation function at origin
(referred as &#x60;&#x60;multiplicity&#x27;&#x27;) is a key factor for understanding the
condensation at the initial stage of training. Our experiments of multilayer
networks suggest that the maximal number of condensed orientations is twice the
multiplicity of the activation function used. Our theoretical analysis of
two-layer networks confirms experiments for two cases, one is for the
activation function of multiplicity one, which contains many common activation
functions, and the other is for the one-dimensional input. This work makes a
step towards understanding how small initialization implicitly leads NNs to
condensation at initial training stage, which lays a foundation for the future
study of the nonlinear dynamics of NNs and its implicit regularization effect
at a later stage of training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedded Knowledge Distillation in Depth-Level Dynamic Neural Network. (arXiv:2103.00793v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Shuchang Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Ting-Bing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00793">
                                    <div class="article-summary-box-inner">
                                        <span>In real applications, different computation-resource devices need
different-depth networks (e.g., ResNet-18/34/50) with high-accuracy. Usually,
existing methods either design multiple networks and train them independently,
or construct depth-level/width-level dynamic neural networks which is hard to
prove the accuracy of each sub-net. In this article, we propose an elegant
Depth-Level Dynamic Neural Network (DDNN) integrated different-depth sub-nets
of similar architectures. To improve the generalization of sub-nets, we design
the Embedded-Knowledge-Distillation (EKD) training mechanism for the DDNN to
implement knowledge transfer from the teacher (full-net) to multiple students
(sub-nets). Specifically, the Kullback-Leibler (KL) divergence is introduced to
constrain the posterior class probability consistency between full-net and
sub-nets, and self-attention distillation on the same resolution feature of
different depth is addressed to drive more abundant feature representations of
sub-nets. Thus, we can obtain multiple high-accuracy sub-nets simultaneously in
a DDNN via the online knowledge distillation in each training iteration without
extra computation cost. Extensive experiments on CIFAR-10/100, and ImageNet
datasets demonstrate that sub-nets in DDNN with EKD training achieve better
performance than individually training networks while preserving the original
performance of full-nets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel Density Estimation by Stagewise Algorithm with a Simple Dictionary. (arXiv:2107.13430v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nishida_K/0/1/0/all/0/1">Kiheiji Nishida</a>, <a href="http://arxiv.org/find/stat/1/au:+Naito_K/0/1/0/all/0/1">Kanta Naito</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13430">
                                    <div class="article-summary-box-inner">
                                        <span>This study proposes multivariate kernel density estimation by stagewise
minimization algorithm based on $U$-divergence and a simple dictionary. The
dictionary consists of an appropriate scalar bandwidth matrix and a part of the
original data. The resulting estimator brings us data-adaptive weighting
parameters and bandwidth matrices, and realizes a sparse representation of
kernel density estimation. We develop the non-asymptotic error bound of
estimator obtained via the proposed stagewise minimization algorithm. It is
confirmed from simulation studies that the proposed estimator performs
competitive to or sometime better than other well-known density estimators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks. (arXiv:2102.03322v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoeve_M/0/1/0/all/0/1">Maartje ter Hoeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolomei_G/0/1/0/all/0/1">Gabriele Tolomei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>, <a href="http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1">Fabrizio Silvestri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03322">
                                    <div class="article-summary-box-inner">
                                        <span>Given the increasing promise of Graph Neural Networks (GNNs) in real-world
applications, several methods have been developed for explaining their
predictions. So far, these methods have primarily focused on generating
subgraphs that are especially relevant for a particular prediction. However,
such methods do not provide a clear opportunity for recourse: given a
prediction, we want to understand how the prediction can be changed in order to
achieve a more desirable outcome. In this work, we propose a method for
generating counterfactual (CF) explanations for GNNs: the minimal perturbation
to the input (graph) data such that the prediction changes. Using only edge
deletions, we find that our method, CF-GNNExplainer can generate CF
explanations for the majority of instances across three widely used datasets
for GNN explanations, while removing less than 3 edges on average, with at
least 94\% accuracy. This indicates that CF-GNNExplainer primarily removes
edges that are crucial for the original predictions, resulting in minimal CF
explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuralDP Differentially private neural networks by design. (arXiv:2107.14582v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/cs/1/au:+Makowski_M/0/1/0/all/0/1">Marcus R. Makowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14582">
                                    <div class="article-summary-box-inner">
                                        <span>The application of differential privacy to the training of deep neural
networks holds the promise of allowing large-scale (decentralized) use of
sensitive data while providing rigorous privacy guarantees to the individual.
The predominant approach to differentially private training of neural networks
is DP-SGD, which relies on norm-based gradient clipping as a method for
bounding sensitivity, followed by the addition of appropriately calibrated
Gaussian noise. In this work we propose NeuralDP, a technique for privatising
activations of some layer within a neural network, which by the post-processing
properties of differential privacy yields a differentially private network. We
experimentally demonstrate on two datasets (MNIST and Pediatric Pneumonia
Dataset (PPD)) that our method offers substantially improved privacy-utility
trade-offs compared to DP-SGD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Adversarial Attacks on Driving Safety in Vision-Based Autonomous Vehicles. (arXiv:2108.02940v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jindi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Kejie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaohua Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02940">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, many deep learning models have been adopted in autonomous
driving. At the same time, these models introduce new vulnerabilities that may
compromise the safety of autonomous vehicles. Specifically, recent studies have
demonstrated that adversarial attacks can cause a significant decline in
detection precision of deep learning-based 3D object detection models. Although
driving safety is the ultimate concern for autonomous driving, there is no
comprehensive study on the linkage between the performance of deep learning
models and the driving safety of autonomous vehicles under adversarial attacks.
In this paper, we investigate the impact of two primary types of adversarial
attacks, perturbation attacks and patch attacks, on the driving safety of
vision-based autonomous vehicles rather than the detection precision of deep
learning models. In particular, we consider two state-of-the-art models in
vision-based 3D object detection, Stereo R-CNN and DSGN. To evaluate driving
safety, we propose an end-to-end evaluation framework with a set of driving
safety performance metrics. By analyzing the results of our extensive
evaluation experiments, we find that (1) the attack&#x27;s impact on the driving
safety of autonomous vehicles and the attack&#x27;s impact on the precision of 3D
object detectors are decoupled, and (2) the DSGN model demonstrates stronger
robustness to adversarial attacks than the Stereo R-CNN model. In addition, we
further investigate the causes behind the two findings with an ablation study.
The findings of this paper provide a new perspective to evaluate adversarial
attacks and guide the selection of deep learning models in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Causal Inference in Heterogeneous Observational Data. (arXiv:2107.11732v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1">Ruoxuan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Koenecke_A/0/1/0/all/0/1">Allison Koenecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Powell_M/0/1/0/all/0/1">Michael Powell</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11732">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing observational data from multiple sources can be useful for
increasing statistical power to detect a treatment effect; however, practical
constraints such as privacy considerations may restrict individual-level
information sharing across data sets. This paper develops federated methods
that only utilize summary-level information from heterogeneous data sets. Our
federated methods provide doubly-robust point estimates of treatment effects as
well as variance estimates. We derive the asymptotic distributions of our
federated estimators, which are shown to be asymptotically equivalent to the
corresponding estimators from the combined, individual-level data. We show that
to achieve these properties, federated methods should be adjusted based on
conditions such as whether models are correctly specified and stable across
heterogeneous data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCTSteg: A Monte Carlo Tree Search-based Reinforcement Learning Framework for Universal Non-additive Steganography. (arXiv:2103.13689v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_X/0/1/0/all/0/1">Xianbo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13689">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has shown that non-additive image steganographic frameworks
effectively improve security performance through adjusting distortion
distribution. However, as far as we know, all of the existing non-additive
proposals are based on handcrafted policies, and can only be applied to a
specific image domain, which heavily prevent non-additive steganography from
releasing its full potentiality. In this paper, we propose an automatic
non-additive steganographic distortion learning framework called MCTSteg to
remove the above restrictions. Guided by the reinforcement learning paradigm,
we combine Monte Carlo Tree Search (MCTS) and steganalyzer-based environmental
model to build MCTSteg. MCTS makes sequential decisions to adjust distortion
distribution without human intervention. Our proposed environmental model is
used to obtain feedbacks from each decision. Due to its self-learning
characteristic and domain-independent reward function, MCTSteg has become the
first reported universal non-additive steganographic framework which can work
in both spatial and JPEG domains. Extensive experimental results show that
MCTSteg can effectively withstand the detection of both hand-crafted
feature-based and deep-learning-based steganalyzers. In both spatial and JPEG
domains, the security performance of MCTSteg steadily outperforms the state of
the art by a clear margin under different scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Average Treatment Effects via Orthogonal Regularization. (arXiv:2101.08490v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hatt_T/0/1/0/all/0/1">Tobias Hatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1">Stefan Feuerriegel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08490">
                                    <div class="article-summary-box-inner">
                                        <span>Decision-making often requires accurate estimation of treatment effects from
observational data. This is challenging as outcomes of alternative decisions
are not observed and have to be estimated. Previous methods estimate outcomes
based on unconfoundedness but neglect any constraints that unconfoundedness
imposes on the outcomes. In this paper, we propose a novel regularization
framework for estimating average treatment effects that exploits
unconfoundedness. To this end, we formalize unconfoundedness as an
orthogonality constraint, which ensures that the outcomes are orthogonal to the
treatment assignment. This orthogonality constraint is then included in the
loss function via a regularization. Based on our regularization framework, we
develop deep orthogonal networks for unconfounded treatments (DONUT), which
learn outcomes that are orthogonal to the treatment assignment. Using a variety
of benchmark datasets for estimating average treatment effects, we demonstrate
that DONUT outperforms the state-of-the-art substantially.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Distance Measure for Privacy-preserving Process Mining based on Feature Learning. (arXiv:2107.06578v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosel_F/0/1/0/all/0/1">Fabian R&#xf6;sel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahrenkrog_Petersen_S/0/1/0/all/0/1">Stephan A. Fahrenkrog-Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Aa_H/0/1/0/all/0/1">Han van der Aa</a>, <a href="http://arxiv.org/find/cs/1/au:+Weidlich_M/0/1/0/all/0/1">Matthias Weidlich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06578">
                                    <div class="article-summary-box-inner">
                                        <span>To enable process analysis based on an event log without compromising the
privacy of individuals involved in process execution, a log may be anonymized.
Such anonymization strives to transform a log so that it satisfies provable
privacy guarantees, while largely maintaining its utility for process analysis.
Existing techniques perform anonymization using simple, syntactic measures to
identify suitable transformation operations. This way, the semantics of the
activities referenced by the events in a trace are neglected, potentially
leading to transformations in which events of unrelated activities are merged.
To avoid this and incorporate the semantics of activities during anonymization,
we propose to instead incorporate a distance measure based on feature learning.
Specifically, we show how embeddings of events enable the definition of a
distance measure for traces to guide event log anonymization. Our experiments
with real-world data indicate that anonymization using this measure, compared
to a syntactic one, yields logs that are closer to the original log in various
dimensions and, hence, have higher utility for process analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Master Faces for Dictionary Attacks with a Network-Assisted Latent Space Evolution. (arXiv:2108.01077v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shmelkin_R/0/1/0/all/0/1">Ron Shmelkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedlander_T/0/1/0/all/0/1">Tomer Friedlander</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01077">
                                    <div class="article-summary-box-inner">
                                        <span>A master face is a face image that passes face-based identity-authentication
for a large portion of the population. These faces can be used to impersonate,
with a high probability of success, any user, without having access to any
user-information. We optimize these faces, by using an evolutionary algorithm
in the latent embedding space of the StyleGAN face generator. Multiple
evolutionary strategies are compared, and we propose a novel approach that
employs a neural network in order to direct the search in the direction of
promising samples, without adding fitness evaluations. The results we present
demonstrate that it is possible to obtain a high coverage of the LFW identities
(over 40%) with less than 10 master faces, for three leading deep face
recognition systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Training Set Debugging for Linear Regression. (arXiv:2006.09009v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaomin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaojin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Loh_P/0/1/0/all/0/1">Po-Ling Loh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09009">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate problems in penalized $M$-estimation, inspired by applications
in machine learning debugging. Data are collected from two pools, one
containing data with possibly contaminated labels, and the other which is known
to contain only cleanly labeled points. We first formulate a general
statistical algorithm for identifying buggy points and provide rigorous
theoretical guarantees under the assumption that the data follow a linear
model. We then present two case studies to illustrate the results of our
general theory and the dependence of our estimator on clean versus buggy
points. We further propose an algorithm for tuning parameter selection of our
Lasso-based algorithm and provide corresponding theoretical guarantees.
Finally, we consider a two-person &quot;game&quot; played between a bug generator and a
debugger, where the debugger can augment the contaminated data set with cleanly
labeled versions of points in the original data pool. We establish a
theoretical result showing a sufficient condition under which the bug generator
can always fool the debugger. Nonetheless, we provide empirical results showing
that such a situation may not occur in practice, making it possible for natural
augmentation strategies combined with our Lasso debugging algorithm to succeed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Deep Reinforcement Learning for POMDPs. (arXiv:2102.12344v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1">Lingheng Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorbet_R/0/1/0/all/0/1">Rob Gorbet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulic_D/0/1/0/all/0/1">Dana Kuli&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12344">
                                    <div class="article-summary-box-inner">
                                        <span>A promising characteristic of Deep Reinforcement Learning (DRL) is its
capability to learn optimal policy in an end-to-end manner without relying on
feature engineering. However, most approaches assume a fully observable state
space, i.e. fully observable Markov Decision Processes (MDPs). In real-world
robotics, this assumption is unpractical, because of issues such as sensor
sensitivity limitations and sensor noise, and the lack of knowledge about
whether the observation design is complete or not. These scenarios lead to
Partially Observable MDPs (POMDPs). In this paper, we propose
Long-Short-Term-Memory-based Twin Delayed Deep Deterministic Policy Gradient
(LSTM-TD3) by introducing a memory component to TD3, and compare its
performance with other DRL algorithms in both MDPs and POMDPs. Our results
demonstrate the significant advantages of the memory component in addressing
POMDPs, including the ability to handle missing and noisy observation data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Super-Convergence with a Large Cyclical Learning Rate. (arXiv:2102.10734v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1">Samet Oymak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10734">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional wisdom dictates that learning rate should be in the stable
regime so that gradient-based algorithms don&#x27;t blow up. This letter introduces
a simple scenario where an unstably large learning rate scheme leads to a super
fast convergence, with the convergence rate depending only logarithmically on
the condition number of the problem. Our scheme uses a Cyclical Learning Rate
(CLR) where we periodically take one large unstable step and several small
stable steps to compensate for the instability. These findings also help
explain the empirical observations of [Smith and Topin, 2019] where they show
that CLR with a large maximum learning rate can dramatically accelerate
learning and lead to so-called &quot;super-convergence&quot;. We prove that our scheme
excels in the problems where Hessian exhibits a bimodal spectrum and the
eigenvalues can be grouped into two clusters (small and large). The unstably
large step is the key to enabling fast convergence over the small
eigen-spectrum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Intrusion Prevention Policies through Optimal Stopping. (arXiv:2106.07160v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hammar_K/0/1/0/all/0/1">Kim Hammar</a>, <a href="http://arxiv.org/find/cs/1/au:+Stadler_R/0/1/0/all/0/1">Rolf Stadler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07160">
                                    <div class="article-summary-box-inner">
                                        <span>We study automated intrusion prevention using reinforcement learning. In a
novel approach, we formulate the problem of intrusion prevention as an optimal
stopping problem. This formulation allows us insight into the structure of the
optimal policies, which turn out to be threshold based. Since the computation
of the optimal defender policy using dynamic programming is not feasible for
practical cases, we approximate the optimal policy through reinforcement
learning in a simulation environment. To define the dynamics of the simulation,
we emulate the target infrastructure and collect measurements. Our evaluations
show that the learned policies are close to optimal and that they indeed can be
expressed using thresholds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyEuroVoc: A Tool for Multilingual Legal Document Classification with EuroVoc Descriptors. (arXiv:2108.01139v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1">Andrei-Marius Avram</a>, <a href="http://arxiv.org/find/cs/1/au:+Pais_V/0/1/0/all/0/1">Vasile Pais</a>, <a href="http://arxiv.org/find/cs/1/au:+Tufis_D/0/1/0/all/0/1">Dan Tufis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.01139">
                                    <div class="article-summary-box-inner">
                                        <span>EuroVoc is a multilingual thesaurus that was built for organizing the
legislative documentary of the European Union institutions. It contains
thousands of categories at different levels of specificity and its descriptors
are targeted by legal texts in almost thirty languages. In this work we propose
a unified framework for EuroVoc classification on 22 languages by fine-tuning
modern Transformer-based pretrained language models. We study extensively the
performance of our trained models and show that they significantly improve the
results obtained by a similar tool - JEX - on the same dataset. The code and
the fine-tuned models were open sourced, together with a programmatic interface
that eases the process of loading the weights of a trained model and of
classifying a new document.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Globally Optimal Hierarchical Reinforcement Learning for Linearly-Solvable Markov Decision Processes. (arXiv:2106.15380v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Infante_G/0/1/0/all/0/1">Guillermo Infante</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1">Anders Jonsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_V/0/1/0/all/0/1">Vicen&#xe7; G&#xf3;mez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15380">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a novel approach to hierarchical reinforcement
learning for linearly-solvable Markov decision processes. Our approach assumes
that the state space is partitioned, and the subtasks consist in moving between
the partitions. We represent value functions on several levels of abstraction,
and use the compositionality of subtasks to estimate the optimal values of the
states in each partition. The policy is implicitly defined on these optimal
value estimates, rather than being decomposed among the subtasks. As a
consequence, our approach can learn the globally optimal policy, and does not
suffer from the non-stationarity of high-level decisions. If several partitions
have equivalent dynamics, the subtasks of those partitions can be shared. If
the set of boundary states is smaller than the entire state space, our approach
can have significantly smaller sample complexity than that of a flat learner,
and we validate this empirically in several experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Loss for Mobile Neural Networks. (arXiv:2107.11170v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrahamyan_L/0/1/0/all/0/1">Lusine Abrahamyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziatchin_V/0/1/0/all/0/1">Valentin Ziatchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deligiannis_N/0/1/0/all/0/1">Nikos Deligiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11170">
                                    <div class="article-summary-box-inner">
                                        <span>Compact convolutional neural networks (CNNs) have witnessed exceptional
improvements in performance in recent years. However, they still fail to
provide the same predictive power as CNNs with a large number of parameters.
The diverse and even abundant features captured by the layers is an important
characteristic of these successful CNNs. However, differences in this
characteristic between large CNNs and their compact counterparts have rarely
been investigated. In compact CNNs, due to the limited number of parameters,
abundant features are unlikely to be obtained, and feature diversity becomes an
essential characteristic. Diverse features present in the activation maps
derived from a data point during model inference may indicate the presence of a
set of unique descriptors necessary to distinguish between objects of different
classes. In contrast, data points with low feature diversity may not provide a
sufficient amount of unique descriptors to make a valid prediction; we refer to
them as random predictions. Random predictions can negatively impact the
optimization process and harm the final performance. This paper proposes
addressing the problem raised by random predictions by reshaping the standard
cross-entropy to make it biased toward data points with a limited number of
unique descriptive features. Our novel Bias Loss focuses the training on a set
of valuable data points and prevents the vast number of samples with poor
learning features from misleading the optimization process. Furthermore, to
show the importance of diversity, we present a family of SkipNet models whose
architectures are brought to boost the number of unique descriptors in the last
layers. Our Skipnet-M can achieve 1% higher classification accuracy than
MobileNetV3 Large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChemiRise: a data-driven retrosynthesis engine. (arXiv:2108.04682v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Sun_X/0/1/0/all/0/1">Xiangyan Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_K/0/1/0/all/0/1">Ke Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Lin_Y/0/1/0/all/0/1">Yuquan Lin</a>, <a href="http://arxiv.org/find/physics/1/au:+Wu_L/0/1/0/all/0/1">Lingjie Wu</a>, <a href="http://arxiv.org/find/physics/1/au:+Xing_H/0/1/0/all/0/1">Haoming Xing</a>, <a href="http://arxiv.org/find/physics/1/au:+Gao_M/0/1/0/all/0/1">Minghong Gao</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Tan_S/0/1/0/all/0/1">Suocheng Tan</a>, <a href="http://arxiv.org/find/physics/1/au:+Ni_Z/0/1/0/all/0/1">Zekun Ni</a>, <a href="http://arxiv.org/find/physics/1/au:+Han_Q/0/1/0/all/0/1">Qi Han</a>, <a href="http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1">Junqiu Wu</a>, <a href="http://arxiv.org/find/physics/1/au:+Fan_J/0/1/0/all/0/1">Jie Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04682">
                                    <div class="article-summary-box-inner">
                                        <span>We have developed an end-to-end, retrosynthesis system, named ChemiRise, that
can propose complete retrosynthesis routes for organic compounds rapidly and
reliably. The system was trained on a processed patent database of over 3
million organic reactions. Experimental reactions were atom-mapped, clustered,
and extracted into reaction templates. We then trained a graph convolutional
neural network-based one-step reaction proposer using template embeddings and
developed a guiding algorithm on the directed acyclic graph (DAG) of chemical
compounds to find the best candidate to explore. The atom-mapping algorithm and
the one-step reaction proposer were benchmarked against previous studies and
showed better results. The final product was demonstrated by retrosynthesis
routes reviewed and rated by human experts, showing satisfying functionality
and a potential productivity boost in real-life use cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Infinitely Deep Bayesian Neural Networks with Stochastic Differential Equations. (arXiv:2102.06559v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xu_W/0/1/0/all/0/1">Winnie Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_R/0/1/0/all/0/1">Ricky T.Q. Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xuechen Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06559">
                                    <div class="article-summary-box-inner">
                                        <span>We perform scalable approximate inference in a continuous-depth Bayesian
neural network family. In this model class, uncertainty about separate weights
in each layer gives hidden units that follow a stochastic differential
equation. We demonstrate gradient-based stochastic variational inference in
this infinite-parameter setting, producing arbitrarily-flexible approximate
posteriors. We also derive a novel gradient estimator that approaches zero
variance as the approximate posterior over weights approaches the true
posterior. This approach brings continuous-depth Bayesian neural nets to a
competitive comparison against discrete-depth alternatives, while inheriting
the memory-efficient training and tunable precision of Neural ODEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Select, Substitute, Search: A New Benchmark for Knowledge-Augmented Visual Question Answering. (arXiv:2103.05568v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Aman Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothyari_M/0/1/0/all/0/1">Mayank Kothyari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vishwajeet Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1">Soumen Chakrabarti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05568">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal IR, spanning text corpus, knowledge graph and images, called
outside knowledge visual question answering (OKVQA), is of much recent
interest. However, the popular data set has serious limitations. A surprisingly
large fraction of queries do not assess the ability to integrate cross-modal
information. Instead, some are independent of the image, some depend on
speculation, some require OCR or are otherwise answerable from the image alone.
To add to the above limitations, frequency-based guessing is very effective
because of (unintended) widespread answer overlaps between the train and test
folds. Overall, it is hard to determine when state-of-the-art systems exploit
these weaknesses rather than really infer the answers, because they are opaque
and their &#x27;reasoning&#x27; process is uninterpretable. An equally important
limitation is that the dataset is designed for the quantitative assessment only
of the end-to-end answer retrieval task, with no provision for assessing the
correct(semantic) interpretation of the input query. In response, we identify a
key structural idiom in OKVQA ,viz., S3 (select, substitute and search), and
build a new data set and challenge around it. Specifically, the questioner
identifies an entity in the image and asks a question involving that entity
which can be answered only by consulting a knowledge graph or corpus passage
mentioning the entity. Our challenge consists of (i)OKVQAS3, a subset of OKVQA
annotated based on the structural idiom and (ii)S3VQA, a new dataset built from
scratch. We also present a neural but structurally transparent OKVQA system,
S3, that explicitly addresses our challenge dataset, and outperforms recent
competitive baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poisoning the Unlabeled Dataset of Semi-Supervised Learning. (arXiv:2105.01622v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01622">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised machine learning models learn from a (small) set of labeled
training examples, and a (large) set of unlabeled training examples.
State-of-the-art models can reach within a few percentage points of
fully-supervised training, while requiring 100x less labeled data.

We study a new class of vulnerabilities: poisoning attacks that modify the
unlabeled dataset. In order to be useful, unlabeled datasets are given strictly
less review than labeled datasets, and adversaries can therefore poison them
easily. By inserting maliciously-crafted unlabeled examples totaling just 0.1%
of the dataset size, we can manipulate a model trained on this poisoned dataset
to misclassify arbitrary examples at test time (as any desired label). Our
attacks are highly effective across datasets and semi-supervised learning
methods.

We find that more accurate methods (thus more likely to be used) are
significantly more vulnerable to poisoning attacks, and as such better training
methods are unlikely to prevent this attack. To counter this we explore the
space of defenses, and propose two methods that mitigate our attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GIPA: General Information Propagation Algorithm for Graph Learning. (arXiv:2105.06035v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1">Qinkai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhixiong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guowei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xintan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yongchao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06035">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have been popularly used in analyzing
graph-structured data, showing promising results in various applications such
as node classification, link prediction and network recommendation. In this
paper, we present a new graph attention neural network, namely GIPA, for
attributed graph data learning. GIPA consists of three key components:
attention, feature propagation and aggregation. Specifically, the attention
component introduces a new multi-layer perceptron based multi-head to generate
better non-linear feature mapping and representation than conventional
implementations such as dot-product. The propagation component considers not
only node features but also edge features, which differs from existing GNNs
that merely consider node features. The aggregation component uses a residual
connection to generate the final embedding. We evaluate the performance of GIPA
using the Open Graph Benchmark proteins (ogbn-proteins for short) dataset. The
experimental results reveal that GIPA can beat the state-of-the-art models in
terms of prediction accuracy, e.g., GIPA achieves an average test ROC-AUC of
$0.8700\pm 0.0010$ and outperforms all the previous methods listed in the
ogbn-proteins leaderboard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning for Grounded Instruction Generation by Observing Human Following Behavior. (arXiv:2108.04812v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kojima_N/0/1/0/all/0/1">Noriyuki Kojima</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhr_A/0/1/0/all/0/1">Alane Suhr</a>, <a href="http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1">Yoav Artzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04812">
                                    <div class="article-summary-box-inner">
                                        <span>We study continual learning for natural language instruction generation, by
observing human users&#x27; instruction execution. We focus on a collaborative
scenario, where the system both acts and delegates tasks to human users using
natural language. We compare user execution of generated instructions to the
original system intent as an indication to the system&#x27;s success communicating
its intent. We show how to use this signal to improve the system&#x27;s ability to
generate instructions via contextual bandit learning. In interaction with real
users, our system demonstrates dramatic improvements in its ability to generate
language over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novel Compressible Adaptive Spectral Mixture Kernels for Gaussian Processes with Sparse Time and Phase Delay Structures. (arXiv:1808.00560v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yijue Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1">Feng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchiori_E/0/1/0/all/0/1">Elena Marchiori</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodoridis_S/0/1/0/all/0/1">Sergios Theodoridis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1808.00560">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral mixture (SM) kernels comprise a powerful class of kernels for
Gaussian processes (GPs) capable of discovering structurally complex patterns
and modeling negative covariances. Being a linear superposition of
quasi-periodical kernel components, the state-of-the-art SM kernel does not
consider component compression and dependency structures between components. In
this paper, we investigate the benefits of component compression and modeling
of both time and phase delay structures between basis components in the SM
kernel. By verifying the presence of dependencies between function components
using Gaussian conditionals and posterior covariance, we first propose a new SM
kernel variant with a time and phase delay dependency structure (SMD) and then
provide a structure adaptation (SA) algorithm for the SMD. The SMD kernel is
constructed in two steps: first, time delay and phase delay are incorporated
into each basis component; next, cross-convolution between a basis component
and the reversed complex conjugate of another basis component is performed,
which yields a complex-valued and positive definite kernel incorporating
dependency structures between basis components. The model compression and
dependency sparsity of the SMD kernel can be obtained by using automatic
pruning in SA. We perform a thorough comparative experimental analysis of the
SMD on both synthetic and real-life datasets. The results corroborate the
efficacy of the dependency structure and SA in the SMD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Backdoor. (arXiv:2006.11890v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1">Zhaohan Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Ren Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shouling Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Ting Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11890">
                                    <div class="article-summary-box-inner">
                                        <span>One intriguing property of deep neural networks (DNNs) is their inherent
vulnerability to backdoor attacks -- a trojan model responds to
trigger-embedded inputs in a highly predictable manner while functioning
normally otherwise. Despite the plethora of prior work on DNNs for continuous
data (e.g., images), the vulnerability of graph neural networks (GNNs) for
discrete-structured data (e.g., graphs) is largely unexplored, which is highly
concerning given their increasing use in security-sensitive domains. To bridge
this gap, we present GTA, the first backdoor attack on GNNs. Compared with
prior work, GTA departs in significant ways: graph-oriented -- it defines
triggers as specific subgraphs, including both topological structures and
descriptive features, entailing a large design spectrum for the adversary;
input-tailored -- it dynamically adapts triggers to individual graphs, thereby
optimizing both attack effectiveness and evasiveness; downstream model-agnostic
-- it can be readily launched without knowledge regarding downstream models or
fine-tuning strategies; and attack-extensible -- it can be instantiated for
both transductive (e.g., node classification) and inductive (e.g., graph
classification) tasks, constituting severe threats for a range of
security-critical applications. Through extensive evaluation using benchmark
datasets and state-of-the-art models, we demonstrate the effectiveness of GTA.
We further provide analytical justification for its effectiveness and discuss
potential countermeasures, pointing to several promising research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Baseline for Shapley Values in MLPs: from Missingness to Neutrality. (arXiv:2006.04896v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Izzo_C/0/1/0/all/0/1">Cosimo Izzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1">Aldo Lipani</a>, <a href="http://arxiv.org/find/cs/1/au:+Okhrati_R/0/1/0/all/0/1">Ramin Okhrati</a>, <a href="http://arxiv.org/find/cs/1/au:+Medda_F/0/1/0/all/0/1">Francesca Medda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04896">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have gained momentum based on their accuracy, but their
interpretability is often criticised. As a result, they are labelled as black
boxes. In response, several methods have been proposed in the literature to
explain their predictions. Among the explanatory methods, Shapley values is a
feature attribution method favoured for its robust theoretical foundation.
However, the analysis of feature attributions using Shapley values requires
choosing a baseline that represents the concept of missingness. An arbitrary
choice of baseline could negatively impact the explanatory power of the method
and possibly lead to incorrect interpretations. In this paper, we present a
method for choosing a baseline according to a neutrality value: as a parameter
selected by decision-makers, the point at which their choices are determined by
the model predictions being either above or below it. Hence, the proposed
baseline is set based on a parameter that depends on the actual use of the
model. This procedure stands in contrast to how other baselines are set, i.e.
without accounting for how the model is used. We empirically validate our
choice of baseline in the context of binary classification tasks, using two
datasets: a synthetic dataset and a dataset derived from the financial domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U-Net-and-a-half: Convolutional network for biomedical image segmentation using multiple expert-driven annotations. (arXiv:2108.04658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kers_J/0/1/0/all/0/1">Jesper Kers</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassol_C/0/1/0/all/0/1">Clarissa A. Cassol</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_J/0/1/0/all/0/1">Joris J. Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Idrees_N/0/1/0/all/0/1">Najia Idrees</a>, <a href="http://arxiv.org/find/cs/1/au:+Farber_A/0/1/0/all/0/1">Alik Farber</a>, <a href="http://arxiv.org/find/cs/1/au:+Haroon_S/0/1/0/all/0/1">Samir Haroon</a>, <a href="http://arxiv.org/find/cs/1/au:+Daly_K/0/1/0/all/0/1">Kevin P. Daly</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1">Suvranu Ganguli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitalia_V/0/1/0/all/0/1">Vipul C. Chitalia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolachalama_V/0/1/0/all/0/1">Vijaya B. Kolachalama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04658">
                                    <div class="article-summary-box-inner">
                                        <span>Development of deep learning systems for biomedical segmentation often
requires access to expert-driven, manually annotated datasets. If more than a
single expert is involved in the annotation of the same images, then the
inter-expert agreement is not necessarily perfect, and no single expert
annotation can precisely capture the so-called ground truth of the regions of
interest on all images. Also, it is not trivial to generate a reference
estimate using annotations from multiple experts. Here we present a deep neural
network, defined as U-Net-and-a-half, which can simultaneously learn from
annotations performed by multiple experts on the same set of images.
U-Net-and-a-half contains a convolutional encoder to generate features from the
input images, multiple decoders that allow simultaneous learning from image
masks obtained from annotations that were independently generated by multiple
experts, and a shared low-dimensional feature space. To demonstrate the
applicability of our framework, we used two distinct datasets from digital
pathology and radiology, respectively. Specifically, we trained two separate
models using pathologist-driven annotations of glomeruli on whole slide images
of human kidney biopsies (10 patients), and radiologist-driven annotations of
lumen cross-sections of human arteriovenous fistulae obtained from
intravascular ultrasound images (10 patients), respectively. The models based
on U-Net-and-a-half exceeded the performance of the traditional U-Net models
trained on single expert annotations alone, thus expanding the scope of
multitask learning in the context of biomedical image segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Factors Aware Dual-Attentional Knowledge Tracing. (arXiv:2108.04741v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Moyu Zhang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinning Zhu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chunhong Zhang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yang Ji</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Feng Pan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Changchuan Yin</a> (1) ((1) Beijing University of Posts and Telecommunications)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04741">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing demands of personalized learning, knowledge tracing has
become important which traces students&#x27; knowledge states based on their
historical practices. Factor analysis methods mainly use two kinds of factors
which are separately related to students and questions to model students&#x27;
knowledge states. These methods use the total number of attempts of students to
model students&#x27; learning progress and hardly highlight the impact of the most
recent relevant practices. Besides, current factor analysis methods ignore rich
information contained in questions. In this paper, we propose Multi-Factors
Aware Dual-Attentional model (MF-DAKT) which enriches question representations
and utilizes multiple factors to model students&#x27; learning progress based on a
dual-attentional mechanism. More specifically, we propose a novel
student-related factor which records the most recent attempts on relevant
concepts of students to highlight the impact of recent exercises. To enrich
questions representations, we use a pre-training method to incorporate two
kinds of question information including questions&#x27; relation and difficulty
level. We also add a regularization term about questions&#x27; difficulty level to
restrict pre-trained question representations to fine-tuning during the process
of predicting students&#x27; performance. Moreover, we apply a dual-attentional
mechanism to differentiate contributions of factors and factor interactions to
final prediction in different practice records. At last, we conduct experiments
on several real-world datasets and results show that MF-DAKT can outperform
existing knowledge tracing methods. We also conduct several studies to validate
the effects of each component of MF-DAKT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Applications of Deep Neural Networks. (arXiv:2009.05673v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heaton_J/0/1/0/all/0/1">Jeff Heaton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05673">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is a group of exciting new technologies for neural networks.
Through a combination of advanced training techniques and neural network
architectural components, it is now possible to create neural networks that can
handle tabular data, images, text, and audio as both input and output. Deep
learning allows a neural network to learn hierarchies of information in a way
that is like the function of the human brain. This course will introduce the
student to classic neural network structures, Convolution Neural Networks
(CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU),
General Adversarial Networks (GAN), and reinforcement learning. Application of
these architectures to computer vision, time series, security, natural language
processing (NLP), and data generation will be covered. High-Performance
Computing (HPC) aspects will demonstrate how deep learning can be leveraged
both on graphical processing units (GPUs), as well as grids. Focus is primarily
upon the application of deep learning to problems, with some introduction to
mathematical foundations. Readers will use the Python programming language to
implement deep learning using Google TensorFlow and Keras. It is not necessary
to know Python prior to this book; however, familiarity with at least one
programming language is assumed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedPAGE: A Fast Local Stochastic Gradient Method for Communication-Efficient Federated Learning. (arXiv:2108.04755v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haoyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhize Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04755">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Averaging (FedAvg, also known as Local-SGD) (McMahan et al., 2017)
is a classical federated learning algorithm in which clients run multiple local
SGD steps before communicating their update to an orchestrating server. We
propose a new federated learning algorithm, FedPAGE, able to further reduce the
communication complexity by utilizing the recent optimal PAGE method (Li et
al., 2021) instead of plain SGD in FedAvg. We show that FedPAGE uses much fewer
communication rounds than previous local methods for both federated convex and
nonconvex optimization. Concretely, 1) in the convex setting, the number of
communication rounds of FedPAGE is $O(\frac{N^{3/4}}{S\epsilon})$, improving
the best-known result $O(\frac{N}{S\epsilon})$ of SCAFFOLD (Karimireddy et
al.,2020) by a factor of $N^{1/4}$, where $N$ is the total number of clients
(usually is very large in federated learning), $S$ is the sampled subset of
clients in each communication round, and $\epsilon$ is the target error; 2) in
the nonconvex setting, the number of communication rounds of FedPAGE is
$O(\frac{\sqrt{N}+S}{S\epsilon^2})$, improving the best-known result
$O(\frac{N^{2/3}}{S^{2/3}\epsilon^2})$ of SCAFFOLD (Karimireddy et al.,2020) by
a factor of $N^{1/6}S^{1/3}$, if the sampled clients $S\leq \sqrt{N}$. Note
that in both settings, the communication cost for each round is the same for
both FedPAGE and SCAFFOLD. As a result, FedPAGE achieves new state-of-the-art
results in terms of communication complexity for both federated convex and
nonconvex optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The information of attribute uncertainties: what convolutional neural networks can learn about errors in input data. (arXiv:2108.04742v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_N/0/1/0/all/0/1">Nat&#xe1;lia V. N. Rodrigues</a>, <a href="http://arxiv.org/find/cs/1/au:+Abramo_L/0/1/0/all/0/1">L. Raul Abramo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirata_N/0/1/0/all/0/1">Nina S. Hirata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04742">
                                    <div class="article-summary-box-inner">
                                        <span>Errors in measurements are key to weighting the value of data, but are often
neglected in Machine Learning (ML). We show how Convolutional Neural Networks
(CNNs) are able to learn about the context and patterns of signal and noise,
leading to improvements in the performance of classification methods. We
construct a model whereby two classes of objects follow an underlying Gaussian
distribution, and where the features (the input data) have varying, but known,
levels of noise. This model mimics the nature of scientific data sets, where
the noises arise as realizations of some random processes whose underlying
distributions are known. The classification of these objects can then be
performed using standard statistical techniques (e.g., least-squares
minimization or Markov-Chain Monte Carlo), as well as ML techniques. This
allows us to take advantage of a maximum likelihood approach to object
classification, and to measure the amount by which the ML methods are
incorporating the information in the input data uncertainties. We show that,
when each data point is subject to different levels of noise (i.e., noises with
different distribution functions), that information can be learned by the CNNs,
raising the ML performance to at least the same level of the least-squares
method -- and sometimes even surpassing it. Furthermore, we show that, with
varying noise levels, the confidence of the ML classifiers serves as a proxy
for the underlying cumulative distribution function, but only if the
information about specific input data uncertainties is provided to the CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advanced Dropout: A Model-free Methodology for Bayesian Dropout Optimization. (arXiv:2010.05244v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhanyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_a/0/1/0/all/0/1">and Jianjun Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guoqiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jing-Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zheng-Hua Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jun Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05244">
                                    <div class="article-summary-box-inner">
                                        <span>Due to lack of data, overfitting ubiquitously exists in real-world
applications of deep neural networks (DNNs). We propose advanced dropout, a
model-free methodology, to mitigate overfitting and improve the performance of
DNNs. The advanced dropout technique applies a model-free and easily
implemented distribution with parametric prior, and adaptively adjusts dropout
rate. Specifically, the distribution parameters are optimized by stochastic
gradient variational Bayes in order to carry out an end-to-end training. We
evaluate the effectiveness of the advanced dropout against nine dropout
techniques on seven computer vision datasets (five small-scale datasets and two
large-scale datasets) with various base models. The advanced dropout
outperforms all the referred techniques on all the datasets.We further compare
the effectiveness ratios and find that advanced dropout achieves the highest
one on most cases. Next, we conduct a set of analysis of dropout rate
characteristics, including convergence of the adaptive dropout rate, the
learned distributions of dropout masks, and a comparison with dropout rate
generation without an explicit distribution. In addition, the ability of
overfitting prevention is evaluated and confirmed. Finally, we extend the
application of the advanced dropout to uncertainty inference, network pruning,
text classification, and regression. The proposed advanced dropout is also
superior to the corresponding referred methods. Codes are available at
https://github.com/PRIS-CV/AdvancedDropout.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Into the Unknown: Active Monitoring of Neural Networks. (arXiv:2009.06429v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lukina_A/0/1/0/all/0/1">Anna Lukina</a>, <a href="http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1">Christian Schilling</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1">Thomas A. Henzinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06429">
                                    <div class="article-summary-box-inner">
                                        <span>Neural-network classifiers achieve high accuracy when predicting the class of
an input that they were trained to identify. Maintaining this accuracy in
dynamic environments, where inputs frequently fall outside the fixed set of
initially known classes, remains a challenge. The typical approach is to detect
inputs from novel classes and retrain the classifier on an augmented dataset.
However, not only the classifier but also the detection mechanism needs to
adapt in order to distinguish between newly learned and yet unknown input
classes. To address this challenge, we introduce an algorithmic framework for
active monitoring of a neural network. A monitor wrapped in our framework
operates in parallel with the neural network and interacts with a human user
via a series of interpretable labeling queries for incremental adaptation. In
addition, we propose an adaptive quantitative monitor to improve precision. An
experimental evaluation on a diverse set of benchmarks with varying numbers of
classes confirms the benefits of our active monitoring framework in dynamic
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent neural network-based Internal Model Control of unknown nonlinear stable systems. (arXiv:2108.04585v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bonassi_F/0/1/0/all/0/1">Fabio Bonassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Scattolini_R/0/1/0/all/0/1">Riccardo Scattolini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04585">
                                    <div class="article-summary-box-inner">
                                        <span>Owing to their superior modeling capabilities, gated Recurrent Neural
Networks (RNNs), such as Gated Recurrent Units (GRUs) and Long Short-Term
Memory networks (LSTMs), have become popular tools for learning dynamical
systems. This paper aims to discuss how these networks can be adopted for the
synthesis of Internal Model Control (IMC) architectures. To this end, a first
gated RNN is used to learn a model of the unknown input-output stable plant.
Then, another gated RNN approximating the model inverse is trained. The
proposed scheme is able to cope with the saturation of the control variables,
and it can be deployed on low-power embedded controllers since it does not
require any online computation. The approach is then tested on the Quadruple
Tank benchmark system, resulting in satisfactory closed-loop performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirical Analysis on Effectiveness of NLP Methods for Predicting Code Smell. (arXiv:2108.04656v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Himanshu Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulanikar_A/0/1/0/all/0/1">Abhiram Anand Gulanikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_L/0/1/0/all/0/1">Lov Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Neti_L/0/1/0/all/0/1">Lalita Bhanu Murthy Neti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04656">
                                    <div class="article-summary-box-inner">
                                        <span>A code smell is a surface indicator of an inherent problem in the system,
most often due to deviation from standard coding practices on the developers
part during the development phase. Studies observe that code smells made the
code more susceptible to call for modifications and corrections than code that
did not contain code smells. Restructuring the code at the early stage of
development saves the exponentially increasing amount of effort it would
require to address the issues stemming from the presence of these code smells.
Instead of using traditional features to detect code smells, we use user
comments to manually construct features to predict code smells. We use three
Extreme learning machine kernels over 629 packages to identify eight code
smells by leveraging feature engineering aspects and using sampling techniques.
Our findings indicate that the radial basis functional kernel performs best out
of the three kernel methods with a mean accuracy of 98.52.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Utilizing Concept Drift for Measuring the Effectiveness of Policy Interventions: The Case of the COVID-19 Pandemic. (arXiv:2012.03728v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baier_L/0/1/0/all/0/1">Lucas Baier</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_N/0/1/0/all/0/1">Niklas K&#xfc;hl</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoffer_J/0/1/0/all/0/1">Jakob Sch&#xf6;ffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Satzger_G/0/1/0/all/0/1">Gerhard Satzger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03728">
                                    <div class="article-summary-box-inner">
                                        <span>As a reaction to the high infectiousness and lethality of the COVID-19 virus,
countries around the world have adopted drastic policy measures to contain the
pandemic. However, it remains unclear which effect these measures, so-called
non-pharmaceutical interventions (NPIs), have on the spread of the virus. In
this article, we use machine learning and apply drift detection methods in a
novel way to predict the time lag of policy interventions with respect to the
development of daily case numbers of COVID-19 across 9 European countries and
28 US states. Our analysis shows that there are, on average, more than two
weeks between NPI enactment and a drift in the case numbers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep tree-ensembles for multi-output prediction. (arXiv:2011.02829v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nakano_F/0/1/0/all/0/1">Felipe Kenji Nakano</a>, <a href="http://arxiv.org/find/cs/1/au:+Pliakos_K/0/1/0/all/0/1">Konstantinos Pliakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vens_C/0/1/0/all/0/1">Celine Vens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02829">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep neural networks have expanded the state-of-art in various
scientific fields and provided solutions to long standing problems across
multiple application domains. Nevertheless, they also suffer from weaknesses
since their optimal performance depends on massive amounts of training data and
the tuning of an extended number of parameters. As a countermeasure, some
deep-forest methods have been recently proposed, as efficient and low-scale
solutions. Despite that, these approaches simply employ label classification
probabilities as induced features and primarily focus on traditional
classification and regression tasks, leaving multi-output prediction
under-explored. Moreover, recent work has demonstrated that tree-embeddings are
highly representative, especially in structured output prediction. In this
direction, we propose a novel deep tree-ensemble (DTE) model, where every layer
enriches the original feature set with a representation learning component
based on tree-embeddings. In this paper, we specifically focus on two
structured output prediction tasks, namely multi-label classification and
multi-target regression. We conducted experiments using multiple benchmark
datasets and the obtained results confirm that our method provides superior
results to state-of-the-art methods in both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Reinforcement Learning for Data Processing and Analytics. (arXiv:2108.04526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1">Qingpeng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Can Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yiyuan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongle Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Meihui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04526">
                                    <div class="article-summary-box-inner">
                                        <span>Data processing and analytics are fundamental and pervasive. Algorithms play
a vital role in data processing and analytics where many algorithm designs have
incorporated heuristics and general rules from human knowledge and experience
to improve their effectiveness. Recently, reinforcement learning, deep
reinforcement learning (DRL) in particular, is increasingly explored and
exploited in many areas because it can learn better strategies in complicated
environments it is interacting with than statically designed algorithms.
Motivated by this trend, we provide a comprehensive review of recent works
focusing on utilizing deep reinforcement learning to improve data processing
and analytics. First, we present an introduction to key concepts, theories, and
methods in deep reinforcement learning. Next, we discuss deep reinforcement
learning deployment on database systems, facilitating data processing and
analytics in various aspects, including data organization, scheduling, tuning,
and indexing. Then, we survey the application of deep reinforcement learning in
data processing and analytics, ranging from data preparation, natural language
interface to healthcare, fintech, etc. Finally, we discuss important open
challenges and future research directions of using deep reinforcement learning
in data processing and analytics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Sample Size, Dimensionality, and Generalization in Covariate Shift Adaptation. (arXiv:2010.01184v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Polo_F/0/1/0/all/0/1">Felipe Maia Polo</a>, <a href="http://arxiv.org/find/stat/1/au:+Vicente_R/0/1/0/all/0/1">Renato Vicente</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01184">
                                    <div class="article-summary-box-inner">
                                        <span>In supervised learning, training and test datasets are often sampled from
distinct distributions. Domain adaptation techniques are thus required.
Covariate shift adaptation yields good generalization performance when domains
differ only by the marginal distribution of features. Covariate shift
adaptation is usually implemented using importance weighting, which may fail,
according to common wisdom, due to small effective sample sizes (ESS). Previous
research argues this scenario is more common in high-dimensional settings.
However, how effective sample size, dimensionality, and model
performance/generalization are formally related in supervised learning,
considering the context of covariate shift adaptation, is still somewhat
obscure in the literature. Thus, a main challenge is presenting a unified
theory connecting those points. Hence, in this paper, we focus on building a
unified view connecting the ESS, data dimensionality, and generalization in the
context of covariate shift adaptation. Moreover, we also demonstrate how
dimensionality reduction or feature selection can increase the ESS, and argue
that our results support dimensionality reduction before covariate shift
adaptation as a good practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Laplace for Bayesian neural networks. (arXiv:2011.10443v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Unlu_A/0/1/0/all/0/1">Ali Unlu</a>, <a href="http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1">Laurence Aitchison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10443">
                                    <div class="article-summary-box-inner">
                                        <span>We develop variational Laplace for Bayesian neural networks (BNNs) which
exploits a local approximation of the curvature of the likelihood to estimate
the ELBO without the need for stochastic sampling of the neural-network
weights. The Variational Laplace objective is simple to evaluate, as it is (in
essence) the log-likelihood, plus weight-decay, plus a squared-gradient
regularizer. Variational Laplace gave better test performance and expected
calibration errors than maximum a-posteriori inference and standard
sampling-based variational inference, despite using the same variational
approximate posterior. Finally, we emphasise care needed in benchmarking
standard VI as there is a risk of stopping before the variance parameters have
converged. We show that early-stopping can be avoided by increasing the
learning rate for the variance parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty Quantification using Variational Inference for Biomedical Image Segmentation. (arXiv:2008.07588v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.07588">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning motivated by convolutional neural networks has been highly
successful in a range of medical imaging problems like image classification,
image segmentation, image synthesis etc. However for validation and
interpretability, not only do we need the predictions made by the model but
also how confident it is while making those predictions. This is important in
safety critical applications for the people to accept it. In this work, we used
an encoder decoder architecture based on variational inference techniques for
segmenting brain tumour images. We evaluate our work on the publicly available
BRATS dataset using Dice Similarity Coefficient (DSC) and Intersection Over
Union (IOU) as the evaluation metrics. Our model is able to segment brain
tumours while taking into account both aleatoric uncertainty and epistemic
uncertainty in a principled bayesian manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPCA: A Probabilistic Framework for Gaussian Process Embedded Channel Attention. (arXiv:2003.04575v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Dongliang Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhanyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guoqiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jun Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.04575">
                                    <div class="article-summary-box-inner">
                                        <span>Channel attention mechanisms have been commonly applied in many visual tasks
for effective performance improvement. It is able to reinforce the informative
channels as well as to suppress the useless channels. Recently, different
channel attention modules have been proposed and implemented in various ways.
Generally speaking, they are mainly based on convolution and pooling
operations. In this paper, we propose Gaussian process embedded channel
attention (GPCA) module and further interpret the channel attention schemes in
a probabilistic way. The GPCA module intends to model the correlations among
the channels, which are assumed to be captured by beta distributed variables.
As the beta distribution cannot be integrated into the end-to-end training of
convolutional neural networks (CNNs) with a mathematically tractable solution,
we utilize an approximation of the beta distribution to solve this problem. To
specify, we adapt a Sigmoid-Gaussian approximation, in which the Gaussian
distributed variables are transferred into the interval [0,1]. The Gaussian
process is then utilized to model the correlations among different channels. In
this case, a mathematically tractable solution is derived. The GPCA module can
be efficiently implemented and integrated into the end-to-end training of the
CNNs. Experimental results demonstrate the promising performance of the
proposed GPCA module. Codes are available at https://github.com/PRIS-CV/GPCA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Study on Predictability of Software Code Smell Using Deep Learning Models. (arXiv:2108.04659v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Himanshu Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_T/0/1/0/all/0/1">Tanmay G. Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_L/0/1/0/all/0/1">Lov Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Neti_L/0/1/0/all/0/1">Lalita Bhanu Murthy Neti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_A/0/1/0/all/0/1">Aneesh Krishna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04659">
                                    <div class="article-summary-box-inner">
                                        <span>Code Smell, similar to a bad smell, is a surface indication of something
tainted but in terms of software writing practices. This metric is an
indication of a deeper problem lies within the code and is associated with an
issue which is prominent to experienced software developers with acceptable
coding practices. Recent studies have often observed that codes having code
smells are often prone to a higher probability of change in the software
development cycle. In this paper, we developed code smell prediction models
with the help of features extracted from source code to predict eight types of
code smell. Our work also presents the application of data sampling techniques
to handle class imbalance problem and feature selection techniques to find
relevant feature sets. Previous studies had made use of techniques such as
Naive - Bayes and Random forest but had not explored deep learning methods to
predict code smell. A total of 576 distinct Deep Learning models were trained
using the features and datasets mentioned above. The study concluded that the
deep learning models which used data from Synthetic Minority Oversampling
Technique gave better results in terms of accuracy, AUC with the accuracy of
some models improving from 88.47 to 96.84.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Latent Relation Modeling for Collaborative Metric Learning. (arXiv:2108.04655v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Viet-Anh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1">Guillaume Salha-Galvan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1">Romain Hennequin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moussallam_M/0/1/0/all/0/1">Manuel Moussallam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04655">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative Metric Learning (CML) recently emerged as a powerful paradigm
for recommendation based on implicit feedback collaborative filtering. However,
standard CML methods learn fixed user and item representations, which fails to
capture the complex interests of users. Existing extensions of CML also either
ignore the heterogeneity of user-item relations, i.e. that a user can
simultaneously like very different items, or the latent item-item relations,
i.e. that a user&#x27;s preference for an item depends, not only on its intrinsic
characteristics, but also on items they previously interacted with. In this
paper, we present a hierarchical CML model that jointly captures latent
user-item and item-item relations from implicit data. Our approach is inspired
by translation mechanisms from knowledge graph embedding and leverages
memory-based attention networks. We empirically show the relevance of this
joint relational modeling, by outperforming existing CML models on
recommendation tasks on several real-world datasets. Our experiments also
emphasize the limits of current CML relational models on very sparse datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-repository of screening mammography classifiers. (arXiv:2108.04800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stadnick_B/0/1/0/all/0/1">Benjamin Stadnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Witowski_J/0/1/0/all/0/1">Jan Witowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajiv_V/0/1/0/all/0/1">Vishwaesh Rajiv</a>, <a href="http://arxiv.org/find/cs/1/au:+Chledowski_J/0/1/0/all/0/1">Jakub Ch&#x142;&#x119;dowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamout_F/0/1/0/all/0/1">Farah E. Shamout</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1">Krzysztof J. Geras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04800">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial intelligence (AI) is transforming medicine and showing promise in
improving clinical diagnosis. In breast cancer screening, several recent
studies show that AI has the potential to improve radiologists&#x27; accuracy,
subsequently helping in early cancer diagnosis and reducing unnecessary workup.
As the number of proposed models and their complexity grows, it is becoming
increasingly difficult to re-implement them in order to reproduce the results
and to compare different approaches. To enable reproducibility of research in
this application area and to enable comparison between different methods, we
release a meta-repository containing deep learning models for classification of
screening mammograms. This meta-repository creates a framework that enables the
evaluation of machine learning models on any private or public screening
mammography data set. At its inception, our meta-repository contains five
state-of-the-art models with open-source implementations and cross-platform
compatibility. We compare their performance on five international data sets:
two private New York University breast cancer screening data sets as well as
three public (DDSM, INbreast and Chinese Mammography Database) data sets. Our
framework has a flexible design that can be generalized to other medical image
analysis tasks. The meta-repository is available at
https://www.github.com/nyukat/mammography_metarepository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing Effects of The COVID-19 Pandemic on Road Traffic Safety: The Cases of New York City, Los Angeles, and Boston. (arXiv:2108.04787v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karadla_L/0/1/0/all/0/1">Lahari Karadla</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weizi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04787">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 pandemic has resulted in significant social and economic impacts
throughout the world. In addition to the health consequences, the impacts on
traffic behaviors have also been sudden and dramatic. We have analyzed how the
road traffic safety of New York City, Los Angeles, and Boston in the U.S. have
been impacted by the pandemic and corresponding local government orders and
restrictions. To be specific, we have studied the accident hotspots&#x27;
distributions before and after the outbreak of the pandemic and found that
traffic accidents have shifted in both location and time compared to previous
years. In addition, we have studied the road network characteristics in those
hotspot regions with the hope to understand the underlying cause of the hotspot
shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Synthetic Over-sampling method with Minority and Majority classes for imbalance problems. (arXiv:2011.04170v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khorshidi_H/0/1/0/all/0/1">Hadi A. Khorshidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Aickelin_U/0/1/0/all/0/1">Uwe Aickelin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Class imbalance is a substantial challenge in classifying many real-world
cases. Synthetic over-sampling methods have been effective to improve the
performance of classifiers for imbalance problems. However, most synthetic
over-sampling methods generate non-diverse synthetic instances within the
convex hull formed by the existing minority instances as they only concentrate
on the minority class and ignore the vast information provided by the majority
class. They also often do not perform well for extremely imbalanced data as the
fewer the minority instances, the less information to generate synthetic
instances. Moreover, existing methods that generate synthetic instances using
the majority class distributional information cannot perform effectively when
the majority class has a multi-modal distribution. We propose a new method to
generate diverse and adaptable synthetic instances using Synthetic
Over-sampling with Minority and Majority classes (SOMM). SOMM generates
synthetic instances diversely within the minority data space. It updates the
generated instances adaptively to the neighbourhood including both classes.
Thus, SOMM performs well for both binary and multiclass imbalance problems. We
examine the performance of SOMM for binary and multiclass problems using
benchmark data sets for different imbalance levels. The empirical results show
the superiority of SOMM compared to other existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Driven VRP: A Neural Network Model to Learn Hidden Preferences for VRP. (arXiv:2108.04578v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mandi_J/0/1/0/all/0/1">Jayanta Mandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Canoy_R/0/1/0/all/0/1">Rocsildes Canoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucarey_V/0/1/0/all/0/1">V&#xed;ctor Bucarey</a>, <a href="http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1">Tias Guns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04578">
                                    <div class="article-summary-box-inner">
                                        <span>The traditional Capacitated Vehicle Routing Problem (CVRP) minimizes the
total distance of the routes under the capacity constraints of the vehicles.
But more often, the objective involves multiple criteria including not only the
total distance of the tour but also other factors such as travel costs, travel
time, and fuel consumption.Moreover, in reality, there are numerous implicit
preferences ingrained in the minds of the route planners and the drivers.
Drivers, for instance, have familiarity with certain neighborhoods and
knowledge of the state of roads, and often consider the best places for rest
and lunch breaks. This knowledge is difficult to formulate and balance when
operational routing decisions have to be made. This motivates us to learn the
implicit preferences from past solutions and to incorporate these learned
preferences in the optimization process. These preferences are in the form of
arc probabilities, i.e., the more preferred a route is, the higher is the joint
probability. The novelty of this work is the use of a neural network model to
estimate the arc probabilities, which allows for additional features and
automatic parameter estimation. This first requires identifying suitable
features, neural architectures and loss functions, taking into account that
there is typically few data available. We investigate the difference with a
prior weighted Markov counting approach, and study the applicability of neural
networks in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Gibson Benchmark (iGibson 0.5): A Benchmark for Interactive Navigation in Cluttered Environments. (arXiv:1910.14442v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">William B. Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasimbeg_P/0/1/0/all/0/1">Priya Kasimbeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_M/0/1/0/all/0/1">Micael Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1">Alexander Toshev</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.14442">
                                    <div class="article-summary-box-inner">
                                        <span>We present Interactive Gibson Benchmark, the first comprehensive benchmark
for training and evaluating Interactive Navigation: robot navigation strategies
where physical interaction with objects is allowed and even encouraged to
accomplish a task. For example, the robot can move objects if needed in order
to clear a path leading to the goal location. Our benchmark comprises two novel
elements: 1) a new experimental setup, the Interactive Gibson Environment
(iGibson 0.5), which simulates high fidelity visuals of indoor scenes, and high
fidelity physical dynamics of the robot and common objects found in these
scenes; 2) a set of Interactive Navigation metrics which allows one to study
the interplay between navigation and physical interaction. We present and
evaluate multiple learning-based baselines in Interactive Gibson, and provide
insights into regimes of navigation with different trade-offs between
navigation path efficiency and disturbance of surrounding objects. We make our
benchmark publicly
available(https://sites.google.com/view/interactivegibsonenv) and encourage
researchers from all disciplines in robotics (e.g. planning, learning, control)
to propose, evaluate, and compare their Interactive Navigation solutions in
Interactive Gibson.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Robust Named Entity Understanding for Voice Assistants. (arXiv:2005.14408v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidharan_D/0/1/0/all/0/1">Deepak Muralidharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1">Joel Ruben Antony Moniz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Sida Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kao_J/0/1/0/all/0/1">Justine Kao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulman_S/0/1/0/all/0/1">Stephen Pulman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1">Atish Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1">Ray Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yinying Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_V/0/1/0/all/0/1">Vivek Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1">Mubarak Seyed Ibrahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_G/0/1/0/all/0/1">Gang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dun_N/0/1/0/all/0/1">Nan Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yidan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+O_A/0/1/0/all/0/1">Andy O</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitkara_P/0/1/0/all/0/1">Pooja Chitkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1">Alkesh Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tayal_K/0/1/0/all/0/1">Kushal Tayal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Roger Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Grasch_P/0/1/0/all/0/1">Peter Grasch</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1">Jason D. Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.14408">
                                    <div class="article-summary-box-inner">
                                        <span>Named Entity Recognition (NER) and Entity Linking (EL) play an essential role
in voice assistant interaction, but are challenging due to the special
difficulties associated with spoken user queries. In this paper, we propose a
novel architecture that jointly solves the NER and EL tasks by combining them
in a joint reranking module. We show that our proposed framework improves NER
accuracy by up to 3.13% and EL accuracy by up to 3.6% in F1 score. The features
used also lead to better accuracies in other natural language understanding
tasks, such as domain classification and semantic parsing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label-informed Graph Structure Learning for Node Classification. (arXiv:2108.04595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1">Fenyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04595">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have achieved great success among various
domains. Nevertheless, most GNN methods are sensitive to the quality of graph
structures. To tackle this problem, some studies exploit different graph
structure learning strategies to refine the original graph structure. However,
these methods only consider feature information while ignoring available label
information. In this paper, we propose a novel label-informed graph structure
learning framework which incorporates label information explicitly through a
class transition matrix. We conduct extensive experiments on seven node
classification benchmark datasets and the results show that our method
outperforms or matches the state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor-based computation of metastable and coherent sets. (arXiv:1908.04741v3 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nuske_F/0/1/0/all/0/1">Feliks N&#xfc;ske</a>, <a href="http://arxiv.org/find/math/1/au:+Gelss_P/0/1/0/all/0/1">Patrick Gel&#xdf;</a>, <a href="http://arxiv.org/find/math/1/au:+Klus_S/0/1/0/all/0/1">Stefan Klus</a>, <a href="http://arxiv.org/find/math/1/au:+Clementi_C/0/1/0/all/0/1">Cecilia Clementi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.04741">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen rapid advances in the data-driven analysis of
dynamical systems based on Koopman operator theory and related approaches. On
the other hand, low-rank tensor product approximations -- in particular the
tensor train (TT) format -- have become a valuable tool for the solution of
large-scale problems in a number of fields. In this work, we combine
Koopman-based models and the TT format, enabling their application to
high-dimensional problems in conjunction with a rich set of basis functions or
features. We derive efficient algorithms to obtain a reduced matrix
representation of the system&#x27;s evolution operator starting from an appropriate
low-rank representation of the data. These algorithms can be applied to both
stationary and non-stationary systems. We establish the infinite-data limit of
these matrix representations, and demonstrate our methods&#x27; capabilities using
several benchmark data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Levels From Nothing. (arXiv:2002.05259v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bontrager_P/0/1/0/all/0/1">Philip Bontrager</a>, <a href="http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1">Julian Togelius</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05259">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning for procedural content generation has recently become an
active area of research. Levels vary in both form and function and are mostly
unrelated to each other across games. This has made it difficult to assemble
suitably large datasets to bring machine learning to level design in the same
way as it&#x27;s been used for image generation. Here we propose Generative Playing
Networks which design levels for itself to play. The algorithm is built in two
parts; an agent that learns to play game levels, and a generator that learns
the distribution of playable levels. As the agent learns and improves its
ability, the space of playable levels, as defined by the agent, grows. The
generator targets the agent&#x27;s playability estimates to then update its
understanding of what constitutes a playable level. We call this process of
learning the distribution of data found through self-discovery with an
environment, self-supervised inductive learning. Unlike previous approaches to
procedural content generation, Generative Playing Networks are end-to-end
differentiable and do not require human-designed examples or domain knowledge.
We demonstrate the capability of this framework by training an agent and level
generator for a 2D dungeon crawler game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Maximize Influence. (arXiv:2108.04623v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panagopoulos_G/0/1/0/all/0/1">George Panagopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tziortziotis_N/0/1/0/all/0/1">Nikolaos Tziortziotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1">Fragkiskos D. Malliaros</a>, <a href="http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1">Michalis Vazirgiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04623">
                                    <div class="article-summary-box-inner">
                                        <span>As the field of machine learning for combinatorial optimization advances,
traditional problems are resurfaced and readdressed through this new
perspective. The overwhelming majority of the literature focuses on small graph
problems, while several real-world problems are devoted to large graphs. Here,
we focus on two such problems that are related: influence estimation, a
\#P-hard counting problem, and influence maximization, an NP-hard problem. We
develop GLIE, a Graph Neural Network (GNN) that inherently parameterizes an
upper bound of influence estimation and train it on small simulated graphs.
Experiments show that GLIE can provide accurate predictions faster than the
alternatives for graphs 10 times larger than the train set. More importantly,
it can be used on arbitrary large graphs for influence maximization, as the
predictions can rank effectively seed sets even when the accuracy deteriorates.
To showcase this, we propose a version of a standard Influence Maximization
(IM) algorithm where we substitute traditional influence estimation with the
predictions of GLIE.We also transfer GLIE into a reinforcement learning model
that learns how to choose seeds to maximize influence sequentially using GLIE&#x27;s
hidden representations and predictions. The final results show that the
proposed methods surpasses a previous GNN-RL approach and perform on par with a
state-of-the-art IM algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning for Transition State Calculation. (arXiv:2108.04698v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gu_S/0/1/0/all/0/1">Shuting Gu</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1">Hongqiao Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_X/0/1/0/all/0/1">Xiang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04698">
                                    <div class="article-summary-box-inner">
                                        <span>The transition state (TS) calculation is a grand challenge for computational
intensive energy function. The traditional methods need to evaluate the
gradients of the energy function at a very large number of locations. To reduce
the number of expensive computations of the true gradients, we propose an
active learning framework consisting of a statistical surrogate model, Gaussian
process regression (GPR) for the energy function, and a single-walker dynamics
method, gentle accent dynamics (GAD), for the saddle-type transition states. TS
is detected by the GAD applied to the GPR surrogate for the gradient vector and
the Hessian matrix. Our key ingredient for efficiency improvements is an active
learning method which sequentially designs the most informative locations and
takes evaluations of the original model at these locations to train GPR. We
formulate this active learning task as the optimal experimental design problem
and propose a very efficient sample-based sub-optimal criterion to construct
the optimal locations. We show that the new method significantly decreases the
required number of energy or force evaluations of the original model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spiderweb nanomechanical resonators via Bayesian optimization: inspired by nature and guided by machine learning. (arXiv:2108.04809v1 [cond-mat.mes-hall])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Shin_D/0/1/0/all/0/1">Dongil Shin</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Cupertino_A/0/1/0/all/0/1">Andrea Cupertino</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Jong_M/0/1/0/all/0/1">Matthijs H. J. de Jong</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Steeneken_P/0/1/0/all/0/1">Peter G. Steeneken</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Bessa_M/0/1/0/all/0/1">Miguel A. Bessa</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Norte_R/0/1/0/all/0/1">Richard A. Norte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04809">
                                    <div class="article-summary-box-inner">
                                        <span>From ultra-sensitive detectors of fundamental forces to quantum networks and
sensors, mechanical resonators are enabling next-generation technologies to
operate in room temperature environments. Currently, silicon nitride
nanoresonators stand as a leading microchip platform in these advances by
allowing for mechanical resonators whose motion is remarkably isolated from
ambient thermal noise. However, to date, human intuition has remained the
driving force behind design processes. Here, inspired by nature and guided by
machine learning, a spiderweb nanomechanical resonator is developed that
exhibits vibration modes which are isolated from ambient thermal environments
via a novel &quot;torsional soft-clamping&quot; mechanism discovered by the data-driven
optimization algorithm. This bio-inspired resonator is then fabricated;
experimentally confirming a new paradigm in mechanics with quality factors
above 1 billion in room temperature environments. In contrast to other
state-of-the-art resonators, this milestone is achieved with a compact design
which does not require sub-micron lithographic features or complex phononic
bandgaps, making it significantly easier and cheaper to manufacture at large
scales. Here we demonstrate the ability of machine learning to work in tandem
with human intuition to augment creative possibilities and uncover new
strategies in computing and nanotechnology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Quality Related Search Query Suggestions using Deep Reinforcement Learning. (arXiv:2108.04452v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bodigutla_P/0/1/0/all/0/1">Praveen Kumar Bodigutla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04452">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;High Quality Related Search Query Suggestions&quot; task aims at recommending
search queries which are real, accurate, diverse, relevant and engaging.
Obtaining large amounts of query-quality human annotations is expensive. Prior
work on supervised query suggestion models suffered from selection and exposure
bias, and relied on sparse and noisy immediate user-feedback (e.g., clicks),
leading to low quality suggestions. Reinforcement Learning techniques employed
to reformulate a query using terms from search results, have limited
scalability to large-scale industry applications. To recommend high quality
related search queries, we train a Deep Reinforcement Learning model to predict
the query a user would enter next. The reward signal is composed of long-term
session-based user feedback, syntactic relatedness and estimated naturalness of
generated query. Over the baseline supervised model, our proposed approach
achieves a significant relative improvement in terms of recommendation
diversity (3%), down-stream user-engagement (4.2%) and per-sentence word
repetitions (82%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An empirical investigation into audio pipeline approaches for classifying bird species. (arXiv:2108.04449v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Behr_D/0/1/0/all/0/1">David Behr</a>, <a href="http://arxiv.org/find/cs/1/au:+Maina_C/0/1/0/all/0/1">Ciira wa Maina</a>, <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04449">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is an investigation into aspects of an audio classification
pipeline that will be appropriate for the monitoring of bird species on edges
devices. These aspects include transfer learning, data augmentation and model
optimization. The hope is that the resulting models will be good candidates to
deploy on edge devices to monitor bird populations. Two classification
approaches will be taken into consideration, one which explores the
effectiveness of a traditional Deep Neural Network(DNN) and another that makes
use of Convolutional layers.This study aims to contribute empirical evidence of
the merits and demerits of each approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Binary Complex Neural Network Acceleration on FPGA. (arXiv:2108.04811v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hongwu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shanglin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Weitze_S/0/1/0/all/0/1">Scott Weitze</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Sahidul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1">Tong Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Minghu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Mimi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04811">
                                    <div class="article-summary-box-inner">
                                        <span>Being able to learn from complex data with phase information is imperative
for many signal processing applications. Today&#x27; s real-valued deep neural
networks (DNNs) have shown efficiency in latent information analysis but fall
short when applied to the complex domain. Deep complex networks (DCN), in
contrast, can learn from complex data, but have high computational costs;
therefore, they cannot satisfy the instant decision-making requirements of many
deployable systems dealing with short observations or short signal bursts.
Recent, Binarized Complex Neural Network (BCNN), which integrates DCNs with
binarized neural networks (BNN), shows great potential in classifying complex
data in real-time. In this paper, we propose a structural pruning based
accelerator of BCNN, which is able to provide more than 5000 frames/s inference
throughput on edge devices. The high performance comes from both the algorithm
and hardware sides. On the algorithm side, we conduct structural pruning to the
original BCNN models and obtain 20 $\times$ pruning rates with negligible
accuracy loss; on the hardware side, we propose a novel 2D convolution
operation accelerator for the binary complex neural network. Experimental
results show that the proposed design works with over 90% utilization and is
able to achieve the inference throughput of 5882 frames/s and 4938 frames/s for
complex NIN-Net and ResNet-18 using CIFAR-10 dataset and Alveo U280 Board.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A proof of convergence for the gradient descent optimization method with random initializations in the training of neural networks with ReLU activation for piecewise linear target functions. (arXiv:2108.04620v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/math/1/au:+Riekert_A/0/1/0/all/0/1">Adrian Riekert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04620">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient descent (GD) type optimization methods are the standard instrument
to train artificial neural networks (ANNs) with rectified linear unit (ReLU)
activation. Despite the great success of GD type optimization methods in
numerical simulations for the training of ANNs with ReLU activation, it remains
- even in the simplest situation of the plain vanilla GD optimization method
with random initializations and ANNs with one hidden layer - an open problem to
prove (or disprove) the conjecture that the risk of the GD optimization method
converges in the training of such ANNs to zero as the width of the ANNs, the
number of independent random initializations, and the number of GD steps
increase to infinity. In this article we prove this conjecture in the situation
where the probability distribution of the input data is equivalent to the
continuous uniform distribution on a compact interval, where the probability
distributions for the random initializations of the ANN parameters are standard
normal distributions, and where the target function under consideration is
continuous and piecewise affine linear. Roughly speaking, the key ingredients
in our mathematical convergence analysis are (i) to prove that suitable sets of
global minima of the risk functions are \emph{twice continuously differentiable
submanifolds of the ANN parameter spaces}, (ii) to prove that the Hessians of
the risk functions on these sets of global minima satisfy an appropriate
\emph{maximal rank condition}, and, thereafter, (iii) to apply the machinery in
[Fehrman, B., Gess, B., Jentzen, A., Convergence rates for the stochastic
gradient descent method for non-convex objective functions. J. Mach. Learn.
Res. 21(136): 1--48, 2020] to establish convergence of the GD optimization
method with random initializations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Learning and Testing Decision Tree. (arXiv:2108.04587v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bshouty_N/0/1/0/all/0/1">Nader H. Bshouty</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddad_Zaknoon_C/0/1/0/all/0/1">Catherine A. Haddad-Zaknoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04587">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study learning and testing decision tree of size and depth
that are significantly smaller than the number of attributes $n$.

Our main result addresses the problem of poly$(n,1/\epsilon)$ time algorithms
with poly$(s,1/\epsilon)$ query complexity (independent of $n$) that
distinguish between functions that are decision trees of size $s$ from
functions that are $\epsilon$-far from any decision tree of size
$\phi(s,1/\epsilon)$, for some function $\phi &gt; s$. The best known result is
the recent one that follows from Blank, Lange and Tan,~\cite{BlancLT20}, that
gives $\phi(s,1/\epsilon)&#x3D;2^{O((\log^3s)/\epsilon^3)}$. In this paper, we give
a new algorithm that achieves $\phi(s,1/\epsilon)&#x3D;2^{O(\log^2 (s/\epsilon))}$.

Moreover, we study the testability of depth-$d$ decision tree and give a {\it
distribution free} tester that distinguishes between depth-$d$ decision tree
and functions that are $\epsilon$-far from depth-$d^2$ decision tree. In
particular, for decision trees of size $s$, the above result holds in the
distribution-free model when the tree depth is $O(\log(s/\epsilon))$.

We also give other new results in learning and testing of size-$s$ decision
trees and depth-$d$ decision trees that follow from results in the literature
and some results we prove in this paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R4Dyn: Exploring Radar for Self-Supervised Monocular Depth Estimation of Dynamic Scenes. (arXiv:2108.04814v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gasperini_S/0/1/0/all/0/1">Stefano Gasperini</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_P/0/1/0/all/0/1">Patrick Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dallabetta_V/0/1/0/all/0/1">Vinzenz Dallabetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/cs/1/au:+Busam_B/0/1/0/all/0/1">Benjamin Busam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04814">
                                    <div class="article-summary-box-inner">
                                        <span>While self-supervised monocular depth estimation in driving scenarios has
achieved comparable performance to supervised approaches, violations of the
static world assumption can still lead to erroneous depth predictions of
traffic participants, posing a potential safety issue. In this paper, we
present R4Dyn, a novel set of techniques to use cost-efficient radar data on
top of a self-supervised depth estimation framework. In particular, we show how
radar can be used during training as weak supervision signal, as well as an
extra input to enhance the estimation robustness at inference time. Since
automotive radars are readily available, this allows to collect training data
from a variety of existing vehicles. Moreover, by filtering and expanding the
signal to make it compatible with learning-based approaches, we address radar
inherent issues, such as noise and sparsity. With R4Dyn we are able to overcome
a major limitation of self-supervised depth estimation, i.e. the prediction of
traffic participants. We substantially improve the estimation on dynamic
objects, such as cars by 37% on the challenging nuScenes dataset, hence
demonstrating that radar is a valuable additional sensor for monocular depth
estimation in autonomous vehicles. Additionally, we plan on making the code
publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlation Clustering Reconstruction in Semi-Adversarial Models. (arXiv:2108.04729v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chierichetti_F/0/1/0/all/0/1">Flavio Chierichetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Panconesi_A/0/1/0/all/0/1">Alessandro Panconesi</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_G/0/1/0/all/0/1">Giuseppe Re</a>, <a href="http://arxiv.org/find/cs/1/au:+Trevisan_L/0/1/0/all/0/1">Luca Trevisan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04729">
                                    <div class="article-summary-box-inner">
                                        <span>Correlation Clustering is an important clustering problem with many
applications. We study the reconstruction version of this problem in which one
is seeking to reconstruct a latent clustering that has been corrupted by random
noise and adversarial modifications.

Concerning the latter, we study a standard &quot;post-adversarial&quot; model, in which
adversarial modifications come after the noise, and also introduce and analyze
a &quot;pre-adversarial&quot; model in which adversarial modifications come before the
noise. Given an input coming from such a semi-adversarial generative model, the
goal is to reconstruct almost perfectly and with high probability the latent
clustering.

We focus on the case where the hidden clusters have equal size and show the
following. In the pre-adversarial setting, spectral algorithms are optimal, in
the sense that they reconstruct all the way to the information-theoretic
threshold beyond which no reconstruction is possible. In contrast, in the
post-adversarial setting their ability to restore the hidden clusters stops
before the threshold, but the gap is optimally filled by SDP-based algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniNet: A Unified Scene Understanding Network and Exploring Multi-Task Relationships through the Lens of Adversarial Attacks. (arXiv:2108.04584v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gurulingan_N/0/1/0/all/0/1">NareshKumar Gurulingan</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04584">
                                    <div class="article-summary-box-inner">
                                        <span>Scene understanding is crucial for autonomous systems which intend to operate
in the real world. Single task vision networks extract information only based
on some aspects of the scene. In multi-task learning (MTL), on the other hand,
these single tasks are jointly learned, thereby providing an opportunity for
tasks to share information and obtain a more comprehensive understanding. To
this end, we develop UniNet, a unified scene understanding network that
accurately and efficiently infers vital vision tasks including object
detection, semantic segmentation, instance segmentation, monocular depth
estimation, and monocular instance depth prediction. As these tasks look at
different semantic and geometric information, they can either complement or
conflict with each other. Therefore, understanding inter-task relationships can
provide useful cues to enable complementary information sharing. We evaluate
the task relationships in UniNet through the lens of adversarial attacks based
on the notion that they can exploit learned biases and task interactions in the
neural network. Extensive experiments on the Cityscapes dataset, using
untargeted and targeted attacks reveal that semantic tasks strongly interact
amongst themselves, and the same holds for geometric tasks. Additionally, we
show that the relationship between semantic and geometric tasks is asymmetric
and their interaction becomes weaker as we move towards higher-level
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bandit Algorithms for Precision Medicine. (arXiv:2108.04782v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1">Yangyi Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_Z/0/1/0/all/0/1">Ziping Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04782">
                                    <div class="article-summary-box-inner">
                                        <span>The Oxford English Dictionary defines precision medicine as &quot;medical care
designed to optimize efficiency or therapeutic benefit for particular groups of
patients, especially by using genetic or molecular profiling.&quot; It is not an
entirely new idea: physicians from ancient times have recognized that medical
treatment needs to consider individual variations in patient characteristics.
However, the modern precision medicine movement has been enabled by a
confluence of events: scientific advances in fields such as genetics and
pharmacology, technological advances in mobile devices and wearable sensors,
and methodological advances in computing and data sciences.

This chapter is about bandit algorithms: an area of data science of special
relevance to precision medicine. With their roots in the seminal work of
Bellman, Robbins, Lai and others, bandit algorithms have come to occupy a
central place in modern data science ( Lattimore and Szepesvari, 2020). Bandit
algorithms can be used in any situation where treatment decisions need to be
made to optimize some health outcome. Since precision medicine focuses on the
use of patient characteristics to guide treatment, contextual bandit algorithms
are especially useful since they are designed to take such information into
account. The role of bandit algorithms in areas of precision medicine such as
mobile health and digital phenotyping has been reviewed before (Tewari and
Murphy, 2017; Rabbi et al., 2019). Since these reviews were published, bandit
algorithms have continued to find uses in mobile health and several new topics
have emerged in the research on bandit algorithms. This chapter is written for
quantitative researchers in fields such as statistics, machine learning, and
operations research who might be interested in knowing more about the
algorithmic and mathematical details of bandit algorithms that have been used
in mobile health.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowdsourced Databases and Sui Generis Rights. (arXiv:2108.04727v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almeida_G/0/1/0/all/0/1">Gon&#xe7;alo Sim&#xf5;es de Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Abreu_G/0/1/0/all/0/1">Gon&#xe7;alo Faria Abreu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04727">
                                    <div class="article-summary-box-inner">
                                        <span>In this study we propose a new concept of databases (crowdsourced databases),
adding a new conceptual approach to the debate on legal protection of databases
in Europe. We also summarise the current legal framework and current indexing
and web scraping practices - it would not be prudent to suggest a new theory
without contextualising it in the legal and practical context in which it is
developed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PRECODE - A Generic Model Extension to Prevent Deep Gradient Leakage. (arXiv:2108.04725v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scheliga_D/0/1/0/all/0/1">Daniel Scheliga</a>, <a href="http://arxiv.org/find/cs/1/au:+Mader_P/0/1/0/all/0/1">Patrick M&#xe4;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeland_M/0/1/0/all/0/1">Marco Seeland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04725">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative training of neural networks leverages distributed data by
exchanging gradient information between different clients. Although training
data entirely resides with the clients, recent work shows that training data
can be reconstructed from such exchanged gradient information. To enhance
privacy, gradient perturbation techniques have been proposed. However, they
come at the cost of reduced model performance, increased convergence time, or
increased data demand. In this paper, we introduce PRECODE, a PRivacy EnhanCing
mODulE that can be used as generic extension for arbitrary model architectures.
We propose a simple yet effective realization of PRECODE using variational
modeling. The stochastic sampling induced by variational modeling effectively
prevents privacy leakage from gradients and in turn preserves privacy of data
owners. We evaluate PRECODE using state of the art gradient inversion attacks
on two different model architectures trained on three datasets. In contrast to
commonly used defense mechanisms, we find that our proposed modification
consistently reduces the attack success rate to 0% while having almost no
negative impact on model training and final performance. As a result, PRECODE
reveals a promising path towards privacy enhancing model extensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bandits with Partially Observable Confounded Data. (arXiv:2006.06731v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1">Guy Tennenholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1">Uri Shalit</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>, <a href="http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1">Yonathan Efroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06731">
                                    <div class="article-summary-box-inner">
                                        <span>We study linear contextual bandits with access to a large, confounded,
offline dataset that was sampled from some fixed policy. We show that this
problem is closely related to a variant of the bandit problem with side
information. We construct a linear bandit algorithm that takes advantage of the
projected information, and prove regret bounds. Our results demonstrate the
ability to take advantage of confounded offline data. Particularly, we prove
regret bounds that improve current bounds by a factor related to the visible
dimensionality of the contexts in the data. Our results indicate that
confounded offline data can significantly improve online learning algorithms.
Finally, we demonstrate various characteristics of our approach through
synthetic simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Benefits of Implicit Regularization from SGD in Least Squares Problems. (arXiv:2108.04552v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1">Difan Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Quanquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dean P. Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04552">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient descent (SGD) exhibits strong algorithmic regularization
effects in practice, which has been hypothesized to play an important role in
the generalization of modern machine learning approaches. In this work, we seek
to understand these issues in the simpler setting of linear regression
(including both underparameterized and overparameterized regimes), where our
goal is to make sharp instance-based comparisons of the implicit regularization
afforded by (unregularized) average SGD with the explicit regularization of
ridge regression. For a broad class of least squares problem instances (that
are natural in high-dimensional settings), we show: (1) for every problem
instance and for every ridge parameter, (unregularized) SGD, when provided with
logarithmically more samples than that provided to the ridge algorithm,
generalizes no worse than the ridge solution (provided SGD uses a tuned
constant stepsize); (2) conversely, there exist instances (in this wide problem
class) where optimally-tuned ridge regression requires quadratically more
samples than SGD in order to have the same generalization performance. Taken
together, our results show that, up to the logarithmic factors, the
generalization performance of SGD is always no worse than that of ridge
regression in a wide range of overparameterized problems, and, in fact, could
be much better for some problem instances. More generally, our results show how
algorithmic regularization has important consequences even in simpler
(overparameterized) convex settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imitation Learning by Reinforcement Learning. (arXiv:2108.04763v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ciosek_K/0/1/0/all/0/1">Kamil Ciosek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04763">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation Learning algorithms learn a policy from demonstrations of expert
behavior. Somewhat counterintuitively, we show that, for deterministic experts,
imitation learning can be done by reduction to reinforcement learning, which is
commonly considered more difficult. We conduct experiments which confirm that
our reduction works well in practice for a continuous control task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ABC-FL: Anomalous and Benign client Classification in Federated Learning. (arXiv:2108.04551v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Hyejun Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Joonyong Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1">Tai Myung Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04551">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning is a distributed machine learning framework designed for
data privacy preservation i.e., local data remain private throughout the entire
training and testing procedure. Federated Learning is gaining popularity
because it allows one to use machine learning techniques while preserving
privacy. However, it inherits the vulnerabilities and susceptibilities raised
in deep learning techniques. For instance, Federated Learning is particularly
vulnerable to data poisoning attacks that may deteriorate its performance and
integrity due to its distributed nature and inaccessibility to the raw data. In
addition, it is extremely difficult to correctly identify malicious clients due
to the non-Independently and/or Identically Distributed (non-IID) data. The
real-world data can be complex and diverse, making them hardly distinguishable
from the malicious data without direct access to the raw data. Prior research
has focused on detecting malicious clients while treating only the clients
having IID data as benign. In this study, we propose a method that detects and
classifies anomalous clients from benign clients when benign ones have non-IID
data. Our proposed method leverages feature dimension reduction, dynamic
clustering, and cosine similarity-based clipping. The experimental results
validates that our proposed method not only classifies the malicious clients
but also alleviates their negative influences from the entire procedure. Our
findings may be used in future studies to effectively eliminate anomalous
clients when building a model with diverse data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Composite Optimization with Compression. (arXiv:2108.04448v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1">Kun Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04448">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized optimization and communication compression have exhibited their
great potential in accelerating distributed machine learning by mitigating the
communication bottleneck in practice. While existing decentralized algorithms
with communication compression mostly focus on the problems with only smooth
components, we study the decentralized stochastic composite optimization
problem with a potentially non-smooth component. A \underline{Prox}imal
gradient \underline{L}in\underline{EA}r convergent \underline{D}ecentralized
algorithm with compression, Prox-LEAD, is proposed with rigorous theoretical
analyses in the general stochastic setting and the finite-sum setting. Our
theorems indicate that Prox-LEAD works with arbitrary compression precision,
and it tremendously reduces the communication cost almost for free. The
superiorities of the proposed algorithms are demonstrated through the
comparison with state-of-the-art algorithms in terms of convergence
complexities and numerical experiments. Our algorithmic framework also
generally enlightens the compressed communication on other primal-dual
algorithms by reducing the impact of inexact iterations, which might be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Known Operator Learning and Hybrid Machine Learning in Medical Imaging --- A Review of the Past, the Present, and the Future. (arXiv:2108.04543v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1">Andreas Maier</a>, <a href="http://arxiv.org/find/cs/1/au:+Kostler_H/0/1/0/all/0/1">Harald K&#xf6;stler</a>, <a href="http://arxiv.org/find/cs/1/au:+Heisig_M/0/1/0/all/0/1">Marco Heisig</a>, <a href="http://arxiv.org/find/cs/1/au:+Krauss_P/0/1/0/all/0/1">Patrick Krauss</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Seung Hee Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04543">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we perform a review of the state-of-the-art of hybrid
machine learning in medical imaging. We start with a short summary of the
general developments of the past in machine learning and how general and
specialized approaches have been in competition in the past decades. A
particular focus will be the theoretical and experimental evidence pro and
contra hybrid modelling. Next, we inspect several new developments regarding
hybrid machine learning with a particular focus on so-called known operator
learning and how hybrid approaches gain more and more momentum across
essentially all applications in medical imaging and medical image analysis. As
we will point out by numerous examples, hybrid models are taking over in image
reconstruction and analysis. Even domains such as physical simulation and
scanner and acquisition design are being addressed using machine learning grey
box modelling approaches. Towards the end of the article, we will investigate a
few future directions and point out relevant areas in which hybrid modelling,
meta learning, and other domains will likely be able to drive the
state-of-the-art ahead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Generic Multimodal Architecture for Batch and Streaming Big Data Integration. (arXiv:2108.04343v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yousfi_S/0/1/0/all/0/1">Siham Yousfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhanoui_M/0/1/0/all/0/1">Maryem Rhanoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiadmi_D/0/1/0/all/0/1">Dalila Chiadmi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04343">
                                    <div class="article-summary-box-inner">
                                        <span>Big Data are rapidly produced from various heterogeneous data sources. They
are of different types (text, image, video or audio) and have different levels
of reliability and completeness. One of the most interesting architectures that
deal with the large amount of emerging data at high velocity is called the
lambda architecture. In fact, it combines two different processing layers
namely batch and speed layers, each providing specific views of data while
ensuring robustness, fast and scalable data processing. However, most papers
dealing with the lambda architecture are focusing one single type of data
generally produced by a single data source. Besides, the layers of the
architecture are implemented independently, or, at best, are combined to
perform basic processing without assessing either the data reliability or
completeness. Therefore, inspired by the lambda architecture, we propose in
this paper a generic multimodal architecture that combines both batch and
streaming processing in order to build a complete, global and accurate insight
in near-real-time based on the knowledge extracted from multiple heterogeneous
Big Data sources. Our architecture uses batch processing to analyze the data
structures and contents, build the learning models and calculate the
reliability index of the involved sources, while the streaming processing uses
the built-in models of the batch layer to immediately process incoming data and
rapidly provide results. We validate our architecture in the context of urban
traffic management systems in order to detect congestions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for Demand Driven Services in Logistics and Transportation Systems: A Survey. (arXiv:2108.04462v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1">Zefang Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1">Tao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1">Tong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Depeng/0/1/0/all/0/1">Depeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04462">
                                    <div class="article-summary-box-inner">
                                        <span>Recent technology development brings the booming of numerous new
Demand-Driven Services (DDS) into urban lives, including ridesharing, on-demand
delivery, express systems and warehousing. In DDS, a service loop is an
elemental structure, including its service worker, the service providers and
corresponding service targets. The service workers should transport either
humans or parcels from the providers to the target locations. Various planning
tasks within DDS can thus be classified into two individual stages: 1)
Dispatching, which is to form service loops from demand/supply distributions,
and 2)Routing, which is to decide specific serving orders within the
constructed loops. Generating high-quality strategies in both stages is
important to develop DDS but faces several challenging. Meanwhile, deep
reinforcement learning (DRL) has been developed rapidly in recent years. It is
a powerful tool to solve these problems since DRL can learn a parametric model
without relying on too many problem-based assumptions and optimize long-term
effect by learning sequential decisions. In this survey, we first define DDS,
then highlight common applications and important decision/control problems
within. For each problem, we comprehensively introduce the existing DRL
solutions, and further summarize them in
\textit{https://github.com/tsinghua-fib-lab/DDS\_Survey}. We also introduce
open simulation environments for development and evaluation of DDS
applications. Finally, we analyze remaining challenges and discuss further
research opportunities in DRL solutions for DDS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Architecture Selection in Differentiable NAS. (arXiv:2108.04392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruochen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Minhao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04392">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable Neural Architecture Search is one of the most popular Neural
Architecture Search (NAS) methods for its search efficiency and simplicity,
accomplished by jointly optimizing the model weight and architecture parameters
in a weight-sharing supernet via gradient-based algorithms. At the end of the
search phase, the operations with the largest architecture parameters will be
selected to form the final architecture, with the implicit assumption that the
values of architecture parameters reflect the operation strength. While much
has been discussed about the supernet&#x27;s optimization, the architecture
selection process has received little attention. We provide empirical and
theoretical analysis to show that the magnitude of architecture parameters does
not necessarily indicate how much the operation contributes to the supernet&#x27;s
performance. We propose an alternative perturbation-based architecture
selection that directly measures each operation&#x27;s influence on the supernet. We
re-evaluate several differentiable NAS methods with the proposed architecture
selection and find that it is able to extract significantly improved
architectures from the underlying supernets consistently. Furthermore, we find
that several failure modes of DARTS can be greatly alleviated with the proposed
selection method, indicating that much of the poor generalization observed in
DARTS can be attributed to the failure of magnitude-based architecture
selection rather than entirely the optimization of its supernet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computational complexity of Inexact Proximal Point Algorithm for Convex Optimization under Holderian Growth. (arXiv:2108.04482v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrascu_A/0/1/0/all/0/1">Andrei Patrascu</a>, <a href="http://arxiv.org/find/cs/1/au:+Irofti_P/0/1/0/all/0/1">Paul Irofti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04482">
                                    <div class="article-summary-box-inner">
                                        <span>Several decades ago the Proximal Point Algorithm (PPA) started to gain much
attraction for both abstract operator theory and the numerical optimization
communities. Even in modern applications, researchers still use proximal
minimization theory to design scalable algorithms that overcome nonsmoothness
in high dimensional models. Several remarkable references as
\cite{Fer:91,Ber:82constrained,Ber:89parallel,Tom:11} analyzed the tight local
relations between the convergence rate of PPA and the regularity of the
objective function. However, without taking into account the concrete
computational effort paid for computing each PPA iteration, any iteration
complexity remains abstract and purely informative. In this manuscript we aim
to evaluate the computational complexity of practical PPA in terms of
(proximal) gradient/subgradient iterations, which might allow a fair
positioning of the famous PPA numerical performance in the class of first order
methods. First, we derive nonasymptotic iteration complexity estimates of exact
and inexact PPA to minimize convex functions under $\gamma-$Holderian growth:
$\BigO{\log(1/\epsilon)}$ (for $\gamma \in [1,2]$) and
$\BigO{1/\epsilon^{\gamma - 2}}$ (for $\gamma &gt; 2$). In particular, we recover
well-known results on exact PPA: finite convergence for sharp minima and linear
convergence for quadratic growth, even under presence of inexactness. Second,
assuming that an usual (proximal) gradient/subgradient method subroutine is
employed to compute inexact PPA iteration, we show novel computational
complexity bounds on a restarted variant of the inexact PPA, available when no
information on the growth of the objective function is known. In the numerical
experiments we confirm the practical performance and implementability of our
schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable AI and susceptibility to adversarial attacks: a case study in classification of breast ultrasound images. (arXiv:2108.04345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rasaee_H/0/1/0/all/0/1">Hamza Rasaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivaz_H/0/1/0/all/0/1">Hassan Rivaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04345">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound is a non-invasive imaging modality that can be conveniently used
to classify suspicious breast nodules and potentially detect the onset of
breast cancer. Recently, Convolutional Neural Networks (CNN) techniques have
shown promising results in classifying ultrasound images of the breast into
benign or malignant. However, CNN inference acts as a black-box model, and as
such, its decision-making is not interpretable. Therefore, increasing effort
has been dedicated to explaining this process, most notably through GRAD-CAM
and other techniques that provide visual explanations into inner workings of
CNNs. In addition to interpretation, these methods provide clinically important
information, such as identifying the location for biopsy or treatment. In this
work, we analyze how adversarial assaults that are practically undetectable may
be devised to alter these importance maps dramatically. Furthermore, we will
show that this change in the importance maps can come with or without altering
the classification result, rendering them even harder to detect. As such, care
must be taken when using these importance maps to shed light on the inner
workings of deep learning. Finally, we utilize Multi-Task Learning (MTL) and
propose a new network based on ResNet-50 to improve the classification
accuracies. Our sensitivity and specificity is comparable to the state of the
art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Knowledge Tracing via Adversarial Training. (arXiv:2108.04430v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaopeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhijie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jie Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1">Mingyu Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_M/0/1/0/all/0/1">Maojing Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jun Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04430">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of knowledge tracing (KT) where the goal is to trace the
students&#x27; knowledge mastery over time so as to make predictions on their future
performance. Owing to the good representation capacity of deep neural networks
(DNNs), recent advances on KT have increasingly concentrated on exploring DNNs
to improve the performance of KT. However, we empirically reveal that the DNNs
based KT models may run the risk of overfitting, especially on small datasets,
leading to limited generalization. In this paper, by leveraging the current
advances in adversarial training (AT), we propose an efficient AT based KT
method (ATKT) to enhance KT model&#x27;s generalization and thus push the limit of
KT. Specifically, we first construct adversarial perturbations and add them on
the original interaction embeddings as adversarial examples. The original and
adversarial examples are further used to jointly train the KT model, forcing it
is not only to be robust to the adversarial examples, but also to enhance the
generalization over the original ones. To better implement AT, we then present
an efficient attentive-LSTM model as KT backbone, where the key is a proposed
knowledge hidden state attention module that adaptively aggregates information
from previous knowledge hidden states while simultaneously highlighting the
importance of current knowledge hidden state to make a more accurate
prediction. Extensive experiments on four public benchmark datasets demonstrate
that our ATKT achieves new state-of-the-art performance. Code is available at:
\color{blue} {\url{https://github.com/xiaopengguo/ATKT}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalizable Model-and-Data Driven Approach for Open-Set RFF Authentication. (arXiv:2108.04436v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1">Renjie Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanzhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiabao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1">Aiqun Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1">Derrick Wing Kwan Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Swindlehurst_A/0/1/0/all/0/1">A. Lee Swindlehurst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04436">
                                    <div class="article-summary-box-inner">
                                        <span>Radio-frequency fingerprints~(RFFs) are promising solutions for realizing
low-cost physical layer authentication. Machine learning-based methods have
been proposed for RFF extraction and discrimination. However, most existing
methods are designed for the closed-set scenario where the set of devices is
remains unchanged. These methods can not be generalized to the RFF
discrimination of unknown devices. To enable the discrimination of RFF from
both known and unknown devices, we propose a new end-to-end deep learning
framework for extracting RFFs from raw received signals. The proposed framework
comprises a novel preprocessing module, called neural synchronization~(NS),
which incorporates the data-driven learning with signal processing priors as an
inductive bias from communication-model based processing. Compared to
traditional carrier synchronization techniques, which are static, this module
estimates offsets by two learnable deep neural networks jointly trained by the
RFF extractor. Additionally, a hypersphere representation is proposed to
further improve the discrimination of RFF. Theoretical analysis shows that such
a data-and-model framework can better optimize the mutual information between
device identity and the RFF, which naturally leads to better performance.
Experimental results verify that the proposed RFF significantly outperforms
purely data-driven DNN-design and existing handcrafted RFF methods in terms of
both discrimination and network generalizability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisit the Fundamental Theorem of Linear Algebra. (arXiv:2108.04432v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04432">
                                    <div class="article-summary-box-inner">
                                        <span>This survey is meant to provide an introduction to the fundamental theorem of
linear algebra and the theories behind them. Our goal is to give a rigorous
introduction to the readers with prior exposure to linear algebra.
Specifically, we provide some details and proofs of some results from (Strang,
1993). We then describe the fundamental theorem of linear algebra from
different views and find the properties and relationships behind the views. The
fundamental theorem of linear algebra is essential in many fields, such as
electrical engineering, computer science, machine learning, and deep learning.
This survey is primarily a summary of purpose, significance of important
theories behind it.

The sole aim of this survey is to give a self-contained introduction to
concepts and mathematical tools in theory behind the fundamental theorem of
linear algebra and rigorous analysis in order to seamlessly introduce its
properties in four subspaces in subsequent sections. However, we clearly
realize our inability to cover all the useful and interesting results and given
the paucity of scope to present this discussion, e.g., the separated analysis
of the (orthogonal) projection matrices. We refer the reader to literature in
the field of linear algebra for a more detailed introduction to the related
fields. Some excellent examples include (Rose, 1982; Strang, 2009; Trefethen
and Bau III, 1997; Strang, 2019, 2021).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularized Sequential Latent Variable Models with Adversarial Neural Networks. (arXiv:2108.04496v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Ming Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04496">
                                    <div class="article-summary-box-inner">
                                        <span>The recurrent neural networks (RNN) with richly distributed internal states
and flexible non-linear transition functions, have overtaken the dynamic
Bayesian networks such as the hidden Markov models (HMMs) in the task of
modeling highly structured sequential data. These data, such as from speech and
handwriting, often contain complex relationships between the underlaying
variational factors and the observed data. The standard RNN model has very
limited randomness or variability in its structure, coming from the output
conditional probability model. This paper will present different ways of using
high level latent random variables in RNN to model the variability in the
sequential data, and the training method of such RNN model under the VAE
(Variational Autoencoder) principle. We will explore possible ways of using
adversarial method to train a variational RNN model. Contrary to competing
approaches, our approach has theoretical optimum in the model training and
provides better model training stability. Our approach also improves the
posterior approximation in the variational inference network by a separated
adversarial training step. Numerical results simulated from TIMIT speech data
show that reconstruction loss and evidence lower bound converge to the same
level and adversarial training loss converges to 0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Nets for Diabetic Retinopathy Screening in Bangladeshi Patients. (arXiv:2108.04358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haque_A/0/1/0/all/0/1">Ayaan Haque</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutradhar_I/0/1/0/all/0/1">Ipsita Sutradhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahziba Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Mehedi Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_M/0/1/0/all/0/1">Malabika Sarker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04358">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetes is one of the most prevalent chronic diseases in Bangladesh, and as
a result, Diabetic Retinopathy (DR) is widespread in the population. DR, an eye
illness caused by diabetes, can lead to blindness if it is not identified and
treated in its early stages. Unfortunately, diagnosis of DR requires medically
trained professionals, but Bangladesh has limited specialists in comparison to
its population. Moreover, the screening process is often expensive, prohibiting
many from receiving timely and proper diagnosis. To address the problem, we
introduce a deep learning algorithm which screens for different stages of DR.
We use a state-of-the-art CNN architecture to diagnose patients based on
retinal fundus imagery. This paper is an experimental evaluation of the
algorithm we developed for DR diagnosis and screening specifically for
Bangladeshi patients. We perform this validation study using separate pools of
retinal image data of real patients from a hospital and field studies in
Bangladesh. Our results show that the algorithm is effective at screening
Bangladeshi eyes even when trained on a public dataset which is out of domain,
and can accurately determine the stage of DR as well, achieving an overall
accuracy of 92.27\% and 93.02\% on two validation sets of Bangladeshi eyes. The
results confirm the ability of the algorithm to be used in real clinical
settings and applications due to its high accuracy and classwise metrics. Our
algorithm is implemented in the application Drishti, which is used to screen
for DR in patients living in rural areas in Bangladesh, where access to
professional screening is limited.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Open Domain Adaption Framework (AODA): Sketch-to-Photo Synthesis. (arXiv:2108.04351v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1">Amey Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Satish_M/0/1/0/all/0/1">Mega Satish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04351">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims to demonstrate the efficiency of the Adversarial Open Domain
Adaption framework for sketch-to-photo synthesis. The unsupervised open domain
adaption for generating realistic photos from a hand-drawn sketch is
challenging as there is no such sketch of that class for training data. The
absence of learning supervision and the huge domain gap between both the
freehand drawing and picture domains make it hard. We present an approach that
learns both sketch-to-photo and photo-to-sketch generation to synthesise the
missing freehand drawings from pictures. Due to the domain gap between
synthetic sketches and genuine ones, the generator trained on false drawings
may produce unsatisfactory results when dealing with drawings of lacking
classes. To address this problem, we offer a simple but effective open-domain
sampling and optimization method that tricks the generator into considering
false drawings as genuine. Our approach generalises the learnt sketch-to-photo
and photo-to-sketch mappings from in-domain input to open-domain categories. On
the Scribble and SketchyCOCO datasets, we compared our technique to the most
current competing methods. For many types of open-domain drawings, our model
outperforms impressive results in synthesising accurate colour, substance, and
retaining the structural layout.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TDLS: A Top-Down Layer Searching Algorithm for Generating Counterfactual Visual Explanation. (arXiv:2108.04238v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Haocheng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Caleb Chen Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04238">
                                    <div class="article-summary-box-inner">
                                        <span>Explanation of AI, as well as fairness of algorithms&#x27; decisions and the
transparency of the decision model, are becoming more and more important. And
it is crucial to design effective and human-friendly techniques when opening
the black-box model. Counterfactual conforms to the human way of thinking and
provides a human-friendly explanation, and its corresponding explanation
algorithm refers to a strategic alternation of a given data point so that its
model output is &quot;counter-facted&quot;, i.e. the prediction is reverted. In this
paper, we adapt counterfactual explanation over fine-grained image
classification problem. We demonstrated an adaptive method that could give a
counterfactual explanation by showing the composed counterfactual feature map
using top-down layer searching algorithm (TDLS). We have proved that our TDLS
algorithm could provide more flexible counterfactual visual explanation in an
efficient way using VGG-16 model on Caltech-UCSD Birds 200 dataset. At the end,
we discussed several applicable scenarios of counterfactual visual
explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Enhanced Dynamic Mode Decomposition. (arXiv:2108.04433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curtis_C/0/1/0/all/0/1">Christopher W. Curtis</a>, <a href="http://arxiv.org/find/cs/1/au:+Alford_Lago_D/0/1/0/all/0/1">Daniel Jay Alford-Lago</a>, <a href="http://arxiv.org/find/cs/1/au:+Issan_O/0/1/0/all/0/1">Opal Issan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04433">
                                    <div class="article-summary-box-inner">
                                        <span>Koopman operator theory shows how nonlinear dynamical systems can be
represented as an infinite-dimensional, linear operator acting on a Hilbert
space of observables of the system. However, determining the relevant modes and
eigenvalues of this infinite-dimensional operator can be difficult. The
extended dynamic mode decomposition (EDMD) is one such method for generating
approximations to Koopman spectra and modes, but the EDMD method faces its own
set of challenges due to the need of user defined observables. To address this
issue, we explore the use of convolutional autoencoder networks to
simultaneously find optimal families of observables which also generate both
accurate embeddings of the flow into a space of observables and immersions of
the observables back into flow coordinates. This network results in a global
transformation of the flow and affords future state prediction via EDMD and the
decoder network. We call this method deep learning dynamic mode decomposition
(DLDMD). The method is tested on canonical nonlinear data sets and is shown to
produce results that outperform a standard DMD approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Procedural Adversarial Noise Attack And Defense. (arXiv:2108.04409v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiaoyang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Huilin Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Wancheng Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04409">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) are vulnerable to adversarial examples which
would inveigle neural networks to make prediction errors with small per-
turbations on the input images. Researchers have been devoted to promoting the
research on the universal adversarial perturbations (UAPs) which are
gradient-free and have little prior knowledge on data distributions. Procedural
adversarial noise at- tack is a data-free universal perturbation generation
method. In this paper, we propose two universal adversarial perturbation (UAP)
generation methods based on procedural noise functions: Simplex noise and
Worley noise. In our framework, the shading which disturbs visual
classification is generated with rendering technology. Without changing the
semantic representations, the adversarial examples generated via our methods
show superior performance on the attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaRNN: Adaptive Learning and Forecasting of Time Series. (arXiv:2108.04443v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yuntao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wenjie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Sinno Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chongjun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04443">
                                    <div class="article-summary-box-inner">
                                        <span>Time series has wide applications in the real world and is known to be
difficult to forecast. Since its statistical properties change over time, its
distribution also changes temporally, which will cause severe distribution
shift problem to existing methods. However, it remains unexplored to model the
time series in the distribution perspective. In this paper, we term this as
Temporal Covariate Shift (TCS). This paper proposes Adaptive RNNs (AdaRNN) to
tackle the TCS problem by building an adaptive model that generalizes well on
the unseen test data. AdaRNN is sequentially composed of two novel algorithms.
First, we propose Temporal Distribution Characterization to better characterize
the distribution information in the TS. Second, we propose Temporal
Distribution Matching to reduce the distribution mismatch in TS to learn the
adaptive TS model. AdaRNN is a general framework with flexible distribution
distances integrated. Experiments on human activity recognition, air quality
prediction, and financial analysis show that AdaRNN outperforms the latest
methods by a classification accuracy of 2.6% and significantly reduces the RMSE
by 9.0%. We also show that the temporal distribution matching algorithm can be
extended in Transformer structure to boost its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multi-Granular Spatio-Temporal Graph Network for Skeleton-based Action Recognition. (arXiv:2108.04536v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tailin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Desen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shidong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yu Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04536">
                                    <div class="article-summary-box-inner">
                                        <span>The task of skeleton-based action recognition remains a core challenge in
human-centred scene understanding due to the multiple granularities and large
variation in human motion. Existing approaches typically employ a single neural
representation for different motion patterns, which has difficulty in capturing
fine-grained action classes given limited training data. To address the
aforementioned problems, we propose a novel multi-granular spatio-temporal
graph network for skeleton-based action classification that jointly models the
coarse- and fine-grained skeleton motion patterns. To this end, we develop a
dual-head graph network consisting of two interleaved branches, which enables
us to extract features at two spatio-temporal resolutions in an effective and
efficient manner. Moreover, our network utilises a cross-head communication
strategy to mutually enhance the representations of both heads. We conducted
extensive experiments on three large-scale datasets, namely NTU RGB+D 60, NTU
RGB+D 120, and Kinetics-Skeleton, and achieves the state-of-the-art performance
on all the benchmarks, which validates the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor Principal Component Analysis in High Dimensional CP Models. (arXiv:2108.04428v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1">Yuefeng Han</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_C/0/1/0/all/0/1">Cun-Hui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04428">
                                    <div class="article-summary-box-inner">
                                        <span>The CP decomposition for high dimensional non-orthogonal spike tensors is an
important problem with broad applications across many disciplines. However,
previous works with theoretical guarantee typically assume restrictive
incoherence conditions on the basis vectors for the CP components. In this
paper, we propose new computationally efficient composite PCA and concurrent
orthogonalization algorithms for tensor CP decomposition with theoretical
guarantees under mild incoherence conditions. The composite PCA applies the
principal component or singular value decompositions twice, first to a matrix
unfolding of the tensor data to obtain singular vectors and then to the matrix
folding of the singular vectors obtained in the first step. It can be used as
an initialization for any iterative optimization schemes for the tensor CP
decomposition. The concurrent orthogonalization algorithm iteratively estimates
the basis vector in each mode of the tensor by simultaneously applying
projections to the orthogonal complements of the spaces generated by others CP
components in other modes. It is designed to improve the alternating least
squares estimator and other forms of the high order orthogonal iteration for
tensors with low or moderately high CP ranks. Our theoretical investigation
provides estimation accuracy and statistical convergence rates for the two
proposed algorithms. Our implementations on synthetic data demonstrate
significant practical superiority of our approach over existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Machine Learning: Methods, Challenges and Directions. (arXiv:2108.04417v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Runhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1">Nathalie Baracaldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_J/0/1/0/all/0/1">James Joshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04417">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) is increasingly being adopted in a wide variety of
application domains. Usually, a well-performing ML model, especially, emerging
deep neural network model, relies on a large volume of training data and
high-powered computational resources. The need for a vast volume of available
data raises serious privacy concerns because of the risk of leakage of highly
privacy-sensitive information and the evolving regulatory environments that
increasingly restrict access to and use of privacy-sensitive data. Furthermore,
a trained ML model may also be vulnerable to adversarial attacks such as
membership/property inference attacks and model inversion attacks. Hence,
well-designed privacy-preserving ML (PPML) solutions are crucial and have
attracted increasing research interest from academia and industry. More and
more efforts of PPML are proposed via integrating privacy-preserving techniques
into ML algorithms, fusing privacy-preserving approaches into ML pipeline, or
designing various privacy-preserving architectures for existing ML systems. In
particular, existing PPML arts cross-cut ML, system, security, and privacy;
hence, there is a critical need to understand state-of-art studies, related
challenges, and a roadmap for future research. This paper systematically
reviews and summarizes existing privacy-preserving approaches and proposes a
PGU model to guide evaluation for various PPML solutions through elaborately
decomposing their privacy-preserving functionalities. The PGU model is designed
as the triad of Phase, Guarantee, and technical Utility. Furthermore, we also
discuss the unique characteristics and challenges of PPML and outline possible
directions of future work that benefit a wide range of research communities
among ML, distributed systems, security, and privacy areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptable image quality assessment using meta-reinforcement learning of task amenability. (arXiv:2108.04359v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saeed_S/0/1/0/all/0/1">Shaheer U. Saeed</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yunguan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavrinides_V/0/1/0/all/0/1">Vasilis Stavrinides</a>, <a href="http://arxiv.org/find/cs/1/au:+Baum_Z/0/1/0/all/0/1">Zachary M. C. Baum</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qianye Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rusu_M/0/1/0/all/0/1">Mirabela Rusu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1">Richard E. Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonn_G/0/1/0/all/0/1">Geoffrey A. Sonn</a>, <a href="http://arxiv.org/find/cs/1/au:+Noble_J/0/1/0/all/0/1">J. Alison Noble</a>, <a href="http://arxiv.org/find/cs/1/au:+Barratt_D/0/1/0/all/0/1">Dean C. Barratt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yipeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04359">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of many medical image analysis tasks are strongly associated
with image data quality. When developing modern deep learning algorithms,
rather than relying on subjective (human-based) image quality assessment (IQA),
task amenability potentially provides an objective measure of task-specific
image quality. To predict task amenability, an IQA agent is trained using
reinforcement learning (RL) with a simultaneously optimised task predictor,
such as a classification or segmentation neural network. In this work, we
develop transfer learning or adaptation strategies to increase the adaptability
of both the IQA agent and the task predictor so that they are less dependent on
high-quality, expert-labelled training data. The proposed transfer learning
strategy re-formulates the original RL problem for task amenability in a
meta-reinforcement learning (meta-RL) framework. The resulting algorithm
facilitates efficient adaptation of the agent to different definitions of image
quality, each with its own Markov decision process environment including
different images, labels and an adaptable task predictor. Our work demonstrates
that the IQA agents pre-trained on non-expert task labels can be adapted to
predict task amenability as defined by expert task labels, using only a small
set of expert labels. Using 6644 clinical ultrasound images from 249 prostate
cancer patients, our results for image classification and segmentation tasks
show that the proposed IQA method can be adapted using data with as few as
respective 19.7% and 29.6% expert-reviewed consensus labels and still achieve
comparable IQA and task performance, which would otherwise require a training
dataset with 100% expert labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised classification of radiology images with NoTeacher: A Teacher that is not Mean. (arXiv:2108.04423v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Unnikrishnan_B/0/1/0/all/0/1">Balagopal Unnikrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaram_S/0/1/0/all/0/1">Shafa Balaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Foo_C/0/1/0/all/0/1">Chuan Sheng Foo</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnaswamy_P/0/1/0/all/0/1">Pavitra Krishnaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04423">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models achieve strong performance for radiology image
classification, but their practical application is bottlenecked by the need for
large labeled training datasets. Semi-supervised learning (SSL) approaches
leverage small labeled datasets alongside larger unlabeled datasets and offer
potential for reducing labeling cost. In this work, we introduce NoTeacher, a
novel consistency-based SSL framework which incorporates probabilistic
graphical models. Unlike Mean Teacher which maintains a teacher network updated
via a temporal ensemble, NoTeacher employs two independent networks, thereby
eliminating the need for a teacher network. We demonstrate how NoTeacher can be
customized to handle a range of challenges in radiology image classification.
Specifically, we describe adaptations for scenarios with 2D and 3D inputs, uni
and multi-label classification, and class distribution mismatch between labeled
and unlabeled portions of the training data. In realistic empirical evaluations
on three public benchmark datasets spanning the workhorse modalities of
radiology (X-Ray, CT, MRI), we show that NoTeacher achieves over 90-95% of the
fully supervised AUROC with less than 5-15% labeling budget. Further, NoTeacher
outperforms established SSL methods with minimal hyperparameter tuning, and has
implications as a principled and practical option for semisupervised learning
in radiology applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RaftMLP: Do MLP-based Models Dream of Winning Over Computer Vision?. (arXiv:2108.04384v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tatsunami_Y/0/1/0/all/0/1">Yuki Tatsunami</a>, <a href="http://arxiv.org/find/cs/1/au:+Taki_M/0/1/0/all/0/1">Masato Taki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04384">
                                    <div class="article-summary-box-inner">
                                        <span>For the past ten years, CNN has reigned supreme in the world of computer
vision, but recently, Transformer is on the rise. However, the quadratic
computational cost of self-attention has become a severe problem of practice.
There has been much research on architectures without CNN and self-attention in
this context. In particular, MLP-Mixer is a simple idea designed using MLPs and
hit an accuracy comparable to the Vision Transformer. However, the only
inductive bias in this architecture is the embedding of tokens. Thus, there is
still a possibility to build a non-convolutional inductive bias into the
architecture itself, and we built in an inductive bias using two simple ideas.
A way is to divide the token-mixing block vertically and horizontally. Another
way is to make spatial correlations denser among some channels of token-mixing.
With this approach, we were able to improve the accuracy of the MLP-Mixer while
reducing its parameters and computational complexity. Compared to other
MLP-based models, the proposed model, named RaftMLP has a good balance of
computational complexity, the number of parameters, and actual memory usage. In
addition, our work indicates that MLP-based models have the potential to
replace CNNs by adopting inductive bias. The source code in PyTorch version is
available at \url{https://github.com/okojoalg/raft-mlp}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AASeg: Attention Aware Network for Real Time Semantic Segmentation. (arXiv:2108.04349v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04349">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a new network named Attention Aware Network (AASeg)
for real time semantic image segmentation. Our network incorporates spatial and
channel information using Spatial Attention (SA) and Channel Attention (CA)
modules respectively. It also uses dense local multi-scale context information
using Multi Scale Context (MSC) module. The feature maps are concatenated
individually to produce the final segmentation map. We demonstrate the
effectiveness of our method using a comprehensive analysis, quantitative
experimental results and ablation study using Cityscapes, ADE20K and Camvid
datasets. Our network performs better than most previous architectures with a
74.4\% Mean IOU on Cityscapes test dataset while running at 202.7 FPS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diversity-aware Web APIs Recommendation with Compatibility Guarantee. (arXiv:2108.04389v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonga_W/0/1/0/all/0/1">Wenwen Gonga</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yulan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuyun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yucong Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yawei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chena_Y/0/1/0/all/0/1">Yifei Chena</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lianyong Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04389">
                                    <div class="article-summary-box-inner">
                                        <span>With the ever-increasing prevalence of web APIs (Application Programming
Interfaces) in enabling smart software developments, finding and composing a
list of existing web APIs that can corporately fulfil the software developers&#x27;
functional needs have become a promising way to develop a successful mobile
app, economically and conveniently. However, the big volume and diversity of
candidate web APIs put additional burden on the app developers&#x27; web APIs
selection decision-makings, since it is often a challenging task to
simultaneously guarantee the diversity and compatibility of the finally
selected a set of web APIs. Considering this challenge, a Diversity-aware and
Compatibility-driven web APIs Recommendation approach, namely DivCAR, is put
forward in this paper. First, to achieve diversity, DivCAR employs random walk
sampling technique on a pre-built correlation graph to generate diverse
correlation subgraphs. Afterwards, with the diverse correlation subgraphs, we
model the compatible web APIs recommendation problem to be a minimum group
Steiner tree search problem. Through solving the minimum group Steiner tree
search problem, manifold sets of compatible and diverse web APIs ranked are
returned to the app developers. At last, we design and enact a set of
experiments on a real-world dataset crawled from www.programmableWeb.com.
Experimental results validate the effectiveness and efficiency of our proposed
DivCAR approach in balancing the web APIs recommendation diversity and
compatibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Natural Numerical Networks for Natura 2000 habitats classification by satellite images. (arXiv:2108.04327v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Mikula_K/0/1/0/all/0/1">Karol Mikula</a>, <a href="http://arxiv.org/find/math/1/au:+Kollar_M/0/1/0/all/0/1">Michal Kollar</a>, <a href="http://arxiv.org/find/math/1/au:+Ozvat_A/0/1/0/all/0/1">Aneta A. Ozvat</a>, <a href="http://arxiv.org/find/math/1/au:+Ambroz_M/0/1/0/all/0/1">Martin Ambroz</a>, <a href="http://arxiv.org/find/math/1/au:+Cahojova_L/0/1/0/all/0/1">Lucia Cahojova</a>, <a href="http://arxiv.org/find/math/1/au:+Jarolimek_I/0/1/0/all/0/1">Ivan Jarolimek</a>, <a href="http://arxiv.org/find/math/1/au:+Sibik_J/0/1/0/all/0/1">Jozef Sibik</a>, <a href="http://arxiv.org/find/math/1/au:+Sibikova_M/0/1/0/all/0/1">Maria Sibikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04327">
                                    <div class="article-summary-box-inner">
                                        <span>Natural numerical networks are introduced as a new classification algorithm
based on the numerical solution of nonlinear partial differential equations of
forward-backward diffusion type on complete graphs. The proposed natural
numerical network is applied to open important environmental and nature
conservation task, the automated identification of protected habitats by using
satellite images. In the natural numerical network, the forward diffusion
causes the movement of points in a feature space toward each other. The
opposite effect, keeping the points away from each other, is caused by backward
diffusion. This yields the desired classification. The natural numerical
network contains a few parameters that are optimized in the learning phase of
the method. After learning parameters and optimizing the topology of the
network graph, classification necessary for habitat identification is
performed. A relevancy map for each habitat is introduced as a tool for
validating the classification and finding new Natura 2000 habitat appearances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MotionInput v2.0 supporting DirectX: A modular library of open-source gesture-based machine learning and computer vision methods for interacting and controlling existing software with a webcam. (arXiv:2108.04357v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kummen_A/0/1/0/all/0/1">Ashild Kummen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassan_A/0/1/0/all/0/1">Ali Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganeva_T/0/1/0/all/0/1">Teodora Ganeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1">Qianying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaw_R/0/1/0/all/0/1">Robert Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratwatte_C/0/1/0/all/0/1">Chenuka Ratwatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Almazov_E/0/1/0/all/0/1">Emil Almazov</a>, <a href="http://arxiv.org/find/cs/1/au:+Visram_S/0/1/0/all/0/1">Sheena Visram</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_A/0/1/0/all/0/1">Andrew Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebire_N/0/1/0/all/0/1">Neil J Sebire</a>, <a href="http://arxiv.org/find/cs/1/au:+Stott_L/0/1/0/all/0/1">Lee Stott</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_Y/0/1/0/all/0/1">Yvonne Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_G/0/1/0/all/0/1">Graham Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamedally_D/0/1/0/all/0/1">Dean Mohamedally</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04357">
                                    <div class="article-summary-box-inner">
                                        <span>Touchless computer interaction has become an important consideration during
the COVID-19 pandemic period. Despite progress in machine learning and computer
vision that allows for advanced gesture recognition, an integrated collection
of such open-source methods and a user-customisable approach to utilising them
in a low-cost solution for touchless interaction in existing software is still
missing. In this paper, we introduce the MotionInput v2.0 application. This
application utilises published open-source libraries and additional gesture
definitions developed to take the video stream from a standard RGB webcam as
input. It then maps human motion gestures to input operations for existing
applications and games. The user can choose their own preferred way of
interacting from a series of motion types, including single and bi-modal hand
gesturing, full-body repetitive or extremities-based exercises, head and facial
movements, eye tracking, and combinations of the above. We also introduce a
series of bespoke gesture recognition classifications as DirectInput triggers,
including gestures for idle states, auto calibration, depth capture from a 2D
RGB webcam stream and tracking of facial motions such as mouth motions,
winking, and head direction with rotation. Three use case areas assisted the
development of the modules: creativity software, office and clinical software,
and gaming software. A collection of open-source libraries has been integrated
and provide a layer of modular gesture mapping on top of existing mouse and
keyboard controls in Windows via DirectX. With ease of access to webcams
integrated into most laptops and desktop computers, touchless computing becomes
more available with MotionInput v2.0, in a federated and locally processed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Machine Learning Techniques for Detecting and Diagnosing COVID-19 from Imaging. (arXiv:2108.04344v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panday_A/0/1/0/all/0/1">Aishwarza Panday</a>, <a href="http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1">Muhammad Ashad Kabir</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1">Nihad Karim Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04344">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the limited availability and high cost of the reverse
transcription-polymerase chain reaction (RT-PCR) test, many studies have
proposed machine learning techniques for detecting COVID-19 from medical
imaging. The purpose of this study is to systematically review, assess, and
synthesize research articles that have used different machine learning
techniques to detect and diagnose COVID-19 from chest X-ray and CT scan images.
A structured literature search was conducted in the relevant bibliographic
databases to ensure that the survey solely centered on reproducible and
high-quality research. We selected papers based on our inclusion criteria. In
this survey, we reviewed $98$ articles that fulfilled our inclusion criteria.
We have surveyed a complete pipeline of chest imaging analysis techniques
related to COVID-19, including data collection, pre-processing, feature
extraction, classification, and visualization. We have considered CT scans and
X-rays as both are widely used to describe the latest developments in medical
imaging to detect COVID-19. This survey provides researchers with valuable
insights into different machine learning techniques and their performance in
the detection and diagnosis of COVID-19 from chest imaging. At the end, the
challenges and limitations in detecting COVID-19 using machine learning
techniques and the future direction of research are discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Olfactory Bulb Segmentation on High Resolutional T2-Weighted MRI. (arXiv:2108.04267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Estrada_S/0/1/0/all/0/1">Santiago Estrada</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Ran Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diers_K/0/1/0/all/0/1">Kersten Diers</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Weiyi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ehses_P/0/1/0/all/0/1">Philipp Ehses</a>, <a href="http://arxiv.org/find/cs/1/au:+Stocker_T/0/1/0/all/0/1">Tony St&#xf6;cker</a>, <a href="http://arxiv.org/find/cs/1/au:+Breteler_M/0/1/0/all/0/1">Monique M.B Breteler</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_M/0/1/0/all/0/1">Martin Reuter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04267">
                                    <div class="article-summary-box-inner">
                                        <span>The neuroimage analysis community has neglected the automated segmentation of
the olfactory bulb (OB) despite its crucial role in olfactory function. The
lack of an automatic processing method for the OB can be explained by its
challenging properties. Nonetheless, recent advances in MRI acquisition
techniques and resolution have allowed raters to generate more reliable manual
annotations. Furthermore, the high accuracy of deep learning methods for
solving semantic segmentation problems provides us with an option to reliably
assess even small structures. In this work, we introduce a novel, fast, and
fully automated deep learning pipeline to accurately segment OB tissue on
sub-millimeter T2-weighted (T2w) whole-brain MR images. To this end, we
designed a three-stage pipeline: (1) Localization of a region containing both
OBs using FastSurferCNN, (2) Segmentation of OB tissue within the localized
region through four independent AttFastSurferCNN - a novel deep learning
architecture with a self-attention mechanism to improve modeling of contextual
information, and (3) Ensemble of the predicted label maps. The OB pipeline
exhibits high performance in terms of boundary delineation, OB localization,
and volume estimation across a wide range of ages in 203 participants of the
Rhineland Study. Moreover, it also generalizes to scans of an independent
dataset never encountered during training, the Human Connectome Project (HCP),
with different acquisition parameters and demographics, evaluated in 30 cases
at the native 0.7mm HCP resolution, and the default 0.8mm pipeline resolution.
We extensively validated our pipeline not only with respect to segmentation
accuracy but also to known OB volume effects, where it can sensitively
replicate age effects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACE: A Novel Approach for the Statistical Analysis of Pairwise Connectivity. (arXiv:2108.04289v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Krempl/0/1/0/all/0/1">Krempl</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Georg/0/1/0/all/0/1">Georg</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kottke/0/1/0/all/0/1">Kottke</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Daniel/0/1/0/all/0/1">Daniel</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Minh_P/0/1/0/all/0/1">Pham Minh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tuan/0/1/0/all/0/1">Tuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04289">
                                    <div class="article-summary-box-inner">
                                        <span>Analysing correlations between streams of events is an important problem. It
arises for example in Neurosciences, when the connectivity of neurons should be
inferred from spike trains that record neurons&#x27; individual spiking activity.
While recently some approaches for inferring delayed synaptic connections have
been proposed, they are limited in the types of connectivities and delays they
are able to handle, or require computation-intensive procedures. This paper
proposes a faster and more flexible approach for analysing such delayed
correlated activity: a statistical approach for the Analysis of Connectivity in
spiking Events (ACE), based on the idea of hypothesis testing. It first
computes for any pair of a source and a target neuron the inter-spike delays
between subsequent source- and target-spikes. Then, it derives a null model for
the distribution of inter-spike delays for \emph{uncorrelated}~neurons.
Finally, it compares the observed distribution of inter-spike delays to this
null model and infers pairwise connectivity based on the Pearson&#x27;s Chi-squared
test statistic. Thus, ACE is capable to detect connections with a priori
unknown, non-discrete (and potentially large) inter-spike delays, which might
vary between pairs of neurons. Since ACE works incrementally, it has potential
for being used in online processing. In our experiments, we visualise the
advantages of ACE in varying experimental scenarios (except for one special
case) and in a state-of-the-art dataset which has been generated for
neuro-scientific research under most realistic conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Influenza Hemagglutinin Protein Sequences using Convolutional Neural Networks. (arXiv:2108.04240v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Chrysostomou_C/0/1/0/all/0/1">Charalambos Chrysostomou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alexandrou_F/0/1/0/all/0/1">Floris Alexandrou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Nicolaou_M/0/1/0/all/0/1">Mihalis A. Nicolaou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Seker_H/0/1/0/all/0/1">Huseyin Seker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04240">
                                    <div class="article-summary-box-inner">
                                        <span>The Influenza virus can be considered as one of the most severe viruses that
can infect multiple species with often fatal consequences to the hosts. The
Hemagglutinin (HA) gene of the virus can be a target for antiviral drug
development realised through accurate identification of its sub-types and
possible the targeted hosts. This paper focuses on accurately predicting if an
Influenza type A virus can infect specific hosts, and more specifically, Human,
Avian and Swine hosts, using only the protein sequence of the HA gene. In more
detail, we propose encoding the protein sequences into numerical signals using
the Hydrophobicity Index and subsequently utilising a Convolutional Neural
Network-based predictive model. The Influenza HA protein sequences used in the
proposed work are obtained from the Influenza Research Database (IRD).
Specifically, complete and unique HA protein sequences were used for avian,
human and swine hosts. The data obtained for this work was 17999 human-host
proteins, 17667 avian-host proteins and 9278 swine-host proteins. Given this
set of collected proteins, the proposed method yields as much as 10% higher
accuracy for an individual class (namely, Avian) and 5% higher overall accuracy
than in an earlier study. It is also observed that the accuracy for each class
in this work is more balanced than what was presented in this earlier study. As
the results show, the proposed model can distinguish HA protein sequences with
high accuracy whenever the virus under investigation can infect Human, Avian or
Swine hosts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Transfer Learning for Identifications of Slope Surface Cracks. (arXiv:2108.04235v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuting Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_G/0/1/0/all/0/1">Gang Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04235">
                                    <div class="article-summary-box-inner">
                                        <span>Geohazards such as landslides have caused great losses to the safety of
people&#x27;s lives and property, which is often accompanied with surface cracks. If
such surface cracks could be identified in time, it is of great significance
for the monitoring and early warning of geohazards. Currently, the most common
method for crack identification is manual detection, which is with low
efficiency and accuracy. In this paper, a deep transfer learning framework is
proposed to effectively and efficiently identify slope surface cracks for the
sake of fast monitoring and early warning of geohazards such as landslides. The
essential idea is to employ transfer learning by training (a) the large sample
dataset of concrete cracks and (b) the small sample dataset of soil and rock
masses cracks. In the proposed framework, (1) pretrained cracks identification
models are constructed based on the large sample dataset of concrete cracks;
(2) refined cracks identification models are further constructed based on the
small sample dataset of soil and rock masses cracks. The proposed framework
could be applied to conduct UAV surveys on high-steep slopes to realize the
monitoring and early warning of landslides to ensure the safety of people&#x27;s
lives and property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relation-aware Compositional Zero-shot Learning for Attribute-Object Pair Recognition. (arXiv:2108.04603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Ziwei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_Y/0/1/0/all/0/1">Yongkang Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1">Mohan Kankanhalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04603">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel model for recognizing images with composite
attribute-object concepts, notably for composite concepts that are unseen
during model training. We aim to explore the three key properties required by
the task --- relation-aware, consistent, and decoupled --- to learn rich and
robust features for primitive concepts that compose attribute-object pairs. To
this end, we propose the Blocked Message Passing Network (BMP-Net). The model
consists of two modules. The concept module generates semantically meaningful
features for primitive concepts, whereas the visual module extracts visual
features for attributes and objects from input images. A message passing
mechanism is used in the concept module to capture the relations between
primitive concepts. Furthermore, to prevent the model from being biased towards
seen composite concepts and reduce the entanglement between attributes and
objects, we propose a blocking mechanism that equalizes the information
available to the model for both seen and unseen concepts. Extensive experiments
and ablation studies on two benchmarks show the efficacy of the proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Open Framework for Analyzing and Modeling XR Network Traffic. (arXiv:2108.04577v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lecci_M/0/1/0/all/0/1">Mattia Lecci</a>, <a href="http://arxiv.org/find/cs/1/au:+Drago_M/0/1/0/all/0/1">Matteo Drago</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanella_A/0/1/0/all/0/1">Andrea Zanella</a>, <a href="http://arxiv.org/find/cs/1/au:+Zorzi_M/0/1/0/all/0/1">Michele Zorzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04577">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to recent advancements in the technology, eXtended Reality (XR)
applications are gaining a lot of momentum, and they will surely become
increasingly popular in the next decade. These new applications, however,
require a step forward also in terms of models to simulate and analyze this
type of traffic sources in modern communication networks, in order to guarantee
to the users state of the art performance and Quality of Experience (QoE).
Recognizing this need, in this work, we present a novel open-source traffic
model, which researchers can use as a starting point both for improvements of
the model itself and for the design of optimized algorithms for the
transmission of these peculiar data flows. Along with the mathematical model
and the code, we also share with the community the traces that we gathered for
our study, collected from freely available applications such as Minecraft VR,
Google Earth VR, and Virus Popper. Finally, we propose a roadmap for the
construction of an end-to-end framework that fills this gap in the current
state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Cut by Watching Movies. (arXiv:2108.04294v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pardo_A/0/1/0/all/0/1">Alejandro Pardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1">Fabian Caba Heilbron</a>, <a href="http://arxiv.org/find/cs/1/au:+Alcazar_J/0/1/0/all/0/1">Juan Le&#xf3;n Alc&#xe1;zar</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04294">
                                    <div class="article-summary-box-inner">
                                        <span>Video content creation keeps growing at an incredible pace; yet, creating
engaging stories remains challenging and requires non-trivial video editing
expertise. Many video editing components are astonishingly hard to automate
primarily due to the lack of raw video materials. This paper focuses on a new
task for computational video editing, namely the task of raking cut
plausibility. Our key idea is to leverage content that has already been edited
to learn fine-grained audiovisual patterns that trigger cuts. To do this, we
first collected a data source of more than 10K videos, from which we extract
more than 255K cuts. We devise a model that learns to discriminate between real
and artificial cuts via contrastive learning. We set up a new task and a set of
baselines to benchmark video cut generation. We observe that our proposed model
outperforms the baselines by large margins. To demonstrate our model in
real-world applications, we conduct human studies in a collection of unedited
videos. The results show that our model does a better job at cutting than
random and alternative baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCTSteg: A Monte Carlo Tree Search-based Reinforcement Learning Framework for Universal Non-additive Steganography. (arXiv:2103.13689v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_X/0/1/0/all/0/1">Xianbo Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13689">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has shown that non-additive image steganographic frameworks
effectively improve security performance through adjusting distortion
distribution. However, as far as we know, all of the existing non-additive
proposals are based on handcrafted policies, and can only be applied to a
specific image domain, which heavily prevent non-additive steganography from
releasing its full potentiality. In this paper, we propose an automatic
non-additive steganographic distortion learning framework called MCTSteg to
remove the above restrictions. Guided by the reinforcement learning paradigm,
we combine Monte Carlo Tree Search (MCTS) and steganalyzer-based environmental
model to build MCTSteg. MCTS makes sequential decisions to adjust distortion
distribution without human intervention. Our proposed environmental model is
used to obtain feedbacks from each decision. Due to its self-learning
characteristic and domain-independent reward function, MCTSteg has become the
first reported universal non-additive steganographic framework which can work
in both spatial and JPEG domains. Extensive experimental results show that
MCTSteg can effectively withstand the detection of both hand-crafted
feature-based and deep-learning-based steganalyzers. In both spatial and JPEG
domains, the security performance of MCTSteg steadily outperforms the state of
the art by a clear margin under different scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-08-10">2021-08-10</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rider: Reader-Guided Passage Reranking for Open-Domain Question Answering. (arXiv:2101.00294v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00294">
                                    <div class="article-summary-box-inner">
                                        <span>Current open-domain question answering systems often follow a
Retriever-Reader architecture, where the retriever first retrieves relevant
passages and the reader then reads the retrieved passages to form an answer. In
this paper, we propose a simple and effective passage reranking method, named
Reader-guIDEd Reranker (RIDER), which does not involve training and reranks the
retrieved passages solely based on the top predictions of the reader before
reranking. We show that RIDER, despite its simplicity, achieves 10 to 20
absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains
without refining the retriever or reader. In addition, RIDER, without any
training, outperforms state-of-the-art transformer-based supervised rerankers.
Remarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM
on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are
used as the reader input after passage reranking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Don&#x27;t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation. (arXiv:2106.15078v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zichao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_T/0/1/0/all/0/1">Tianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15078">
                                    <div class="article-summary-box-inner">
                                        <span>Neural text generation models are typically trained by maximizing
log-likelihood with the sequence cross entropy loss, which encourages an exact
token-by-token match between a target sequence with a generated sequence. Such
training objective is sub-optimal when the target sequence not perfect, e.g.,
when the target sequence is corrupted with noises, or when only weak sequence
supervision is available. To address this challenge, we propose a novel
Edit-Invariant Sequence Loss (EISL), which computes the matching loss of a
target n-gram with all n-grams in the generated sequence. EISL draws
inspirations from convolutional networks (ConvNets) which are shift-invariant
to images, hence is robust to the shift of n-grams to tolerate edits in the
target sequences. Moreover, the computation of EISL is essentially a
convolution operation with target n-grams as kernels, which is easy to
implement with existing libraries. To demonstrate the effectiveness of EISL, we
conduct experiments on three tasks: machine translation with noisy target
sequences, unsupervised text style transfer, and non-autoregressive machine
translation. Experimental results show our method significantly outperforms
cross entropy loss on these three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M6-T: Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Le Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xianyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Ang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiamang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Lin Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15082">
                                    <div class="article-summary-box-inner">
                                        <span>Mixture-of-Experts (MoE) models can achieve promising results with outrageous
large amount of parameters but constant computation cost, and thus it has
become a trend in model scaling. Still it is a mystery how MoE layers bring
quality gains by leveraging the parameters with sparse activation. In this
work, we investigate several key factors in sparse expert models. We observe
that load imbalance may not be a significant problem affecting model quality,
contrary to the perspectives of recent studies, while the number of sparsely
activated experts $k$ and expert capacity $C$ in top-$k$ routing can
significantly make a difference in this context. Furthermore, we take a step
forward to propose a simple method called expert prototyping that splits
experts into different prototypes and applies $k$ top-$1$ routing. This
strategy improves the model quality but maintains constant computational costs,
and our further exploration on extremely large-scale models reflects that it is
more effective in training larger models. We push the model scale to over $1$
trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in
comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model
achieves substantial speedup in convergence over the same-size baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generation-Augmented Retrieval for Open-domain Question Answering. (arXiv:2009.08553v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08553">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CausalBERT: Injecting Causal Knowledge Into Pre-trained Models with Minimal Supervision. (arXiv:2107.09852v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhongyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1">Xiao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1">Kuo Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09852">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown success in incorporating pre-trained models like BERT
to improve NLP systems. However, existing pre-trained models lack of causal
knowledge which prevents today&#x27;s NLP systems from thinking like humans. In this
paper, we investigate the problem of injecting causal knowledge into
pre-trained models. There are two fundamental problems: 1) how to collect
various granularities of causal pairs from unstructured texts; 2) how to
effectively inject causal knowledge into pre-trained models. To address these
issues, we extend the idea of CausalBERT from previous studies, and conduct
experiments on various datasets to evaluate its effectiveness. In addition, we
adopt a regularization-based method to preserve the already learned knowledge
with an extra regularization term while injecting causal knowledge. Extensive
experiments on 7 datasets, including four causal pair classification tasks, two
causal QA tasks and a causal inference task, demonstrate that CausalBERT
captures rich causal knowledge and outperforms all pre-trained models-based
state-of-the-art methods, achieving a new causal inference benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TellMeWhy: A Dataset for Answering Why-Questions in Narratives. (arXiv:2106.06132v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1">Yash Kumar Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06132">
                                    <div class="article-summary-box-inner">
                                        <span>Answering questions about why characters perform certain actions is central
to understanding and reasoning about narratives. Despite recent progress in QA,
it is not clear if existing models have the ability to answer &quot;why&quot; questions
that may require commonsense knowledge external to the input narrative. In this
work, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more
than 30k questions and free-form answers concerning why characters in short
narratives perform the actions described. For a third of this dataset, the
answers are not present within the narrative. Given the limitations of
automated evaluation for this task, we also present a systematized human
evaluation interface for this dataset. Our evaluation of state-of-the-art
models show that they are far below human performance on answering such
questions. They are especially worse on questions whose answers are external to
the narrative, thus providing a challenge for future QA and narrative
understanding research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExKaldi-RT: A Real-Time Automatic Speech Recognition Extension Toolkit of Kaldi. (arXiv:2104.01384v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Leow_C/0/1/0/all/0/1">Chee Siang Leow</a>, <a href="http://arxiv.org/find/eess/1/au:+Kobayashi_A/0/1/0/all/0/1">Akio Kobayashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Utsuro_T/0/1/0/all/0/1">Takehito Utsuro</a>, <a href="http://arxiv.org/find/eess/1/au:+Nishizaki_H/0/1/0/all/0/1">Hiromitsu Nishizaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01384">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the ExKaldi-RT online automatic speech recognition (ASR)
toolkit that is implemented based on the Kaldi ASR toolkit and Python language.
ExKaldi-RT provides tools for building online recognition pipelines. While
similar tools are available built on Kaldi, a key feature of ExKaldi-RT that it
works on Python, which has an easy-to-use interface that allows online ASR
system developers to develop original research, such as by applying neural
network-based signal processing and by decoding model trained with deep
learning frameworks. We performed benchmark experiments on the minimum
LibriSpeech corpus, and it showed that ExKaldi-RT could achieve competitive ASR
performance in real-time recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash Commands. (arXiv:2103.02523v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1">Mayank Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborti_T/0/1/0/all/0/1">Tathagata Chakraborti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1">Quchen Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gros_D/0/1/0/all/0/1">David Gros</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xi Victoria Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Maene_J/0/1/0/all/0/1">Jaron Maene</a>, <a href="http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1">Kartik Talamadupula</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1">Zhongwei Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1">Jules White</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02523">
                                    <div class="article-summary-box-inner">
                                        <span>The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of
natural language processing to the command line. Participants were tasked with
building models that can transform descriptions of command line tasks in
English to their Bash syntax. This is a report on the competition with details
of the task, metrics, data, attempted solutions, and lessons learned.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Commonsense Knowledge on Classifying False News and Determining Checkworthiness of Claims. (arXiv:2108.03731v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlicht_I/0/1/0/all/0/1">Ipek Baris Schlicht</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezerer_E/0/1/0/all/0/1">Erhan Sezerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tekir_S/0/1/0/all/0/1">Selma Tekir</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_O/0/1/0/all/0/1">Oul Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhers_Z/0/1/0/all/0/1">Zeyd Boukhers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03731">
                                    <div class="article-summary-box-inner">
                                        <span>Widespread and rapid dissemination of false news has made fact-checking an
indispensable requirement. Given its time-consuming and labor-intensive nature,
the task calls for an automated support to meet the demand. In this paper, we
propose to leverage commonsense knowledge for the tasks of false news
classification and check-worthy claim detection. Arguing that commonsense
knowledge is a factor in human believability, we fine-tune the BERT language
model with a commonsense question answering task and the aforementioned tasks
in a multi-task learning environment. For predicting fine-grained false news
types, we compare the proposed fine-tuned model&#x27;s performance with the false
news classification models on a public dataset as well as a newly collected
dataset. We compare the model&#x27;s performance with the single-task BERT model and
a state-of-the-art check-worthy claim detection tool to evaluate the
check-worthy claim detection. Our experimental analysis demonstrates that
commonsense knowledge can improve performance in both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Compositional Wikidata Questions. (arXiv:2108.03509v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1">Ruixiang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1">Rahul Aralikatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Lent_H/0/1/0/all/0/1">Heather Lent</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1">Daniel Hershcovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03509">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic parsing allows humans to leverage vast knowledge resources through
natural interaction. However, parsers are mostly designed for and evaluated on
English resources, such as CFQ (Keysers et al., 2020), the current standard
benchmark based on English data generated from grammar rules and oriented
towards Freebase, an outdated knowledge base. We propose a method for creating
a multilingual, parallel dataset of question-query pairs, grounded in Wikidata,
and introduce such a dataset called Compositional Wikidata Questions (CWQ). We
utilize this data to train and evaluate semantic parsers for Hebrew, Kannada,
Chinese and English, to better understand the current strengths and weaknesses
of multilingual semantic parsing. Experiments on zero-shot cross-lingual
transfer demonstrate that models fail to generate valid queries even with
pretrained multilingual encoders. Our methodology, dataset and results will
facilitate future research on semantic parsing in more realistic and diverse
settings than has been possible with existing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Notes on Coalgebras in Stylometry. (arXiv:2010.02733v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Doat_J/0/1/0/all/0/1">Jo&#xeb;l A. Doat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02733">
                                    <div class="article-summary-box-inner">
                                        <span>The syntactic behaviour of texts can highly vary depending on their contexts
(e.g. author, genre, etc.). From the standpoint of stylometry, it can be
helpful to objectively measure this behaviour. In this paper, we discuss how
coalgebras are used to formalise the notion of behaviour by embedding syntactic
features of a given text into probabilistic transition systems. By introducing
the behavioural distance, we are then able to quantitatively measure
differences between points in these systems and thus, comparing features of
different texts. Furthermore, the behavioural distance of points can be
approximated by a polynomial-time algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What do Bias Measures Measure?. (arXiv:2108.03362v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1">Sunipa Dev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_E/0/1/0/all/0/1">Emily Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jieyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yu Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanseverino_M/0/1/0/all/0/1">Mattie Sanseverino</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jiin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03362">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing (NLP) models propagate social biases about
protected attributes such as gender, race, and nationality. To create
interventions and mitigate these biases and associated harms, it is vital to be
able to detect and measure such biases. While many existing works propose bias
evaluation methodologies for different tasks, there remains a need to
cohesively understand what biases and normative harms each of these measures
captures and how different measures compare. To address this gap, this work
presents a comprehensive survey of existing bias measures in NLP as a function
of the associated NLP tasks, metrics, datasets, and social biases and
corresponding harms. This survey also organizes metrics into different
categories to present advantages and disadvantages. Finally, we propose a
documentation standard for bias measures to aid their development,
categorization, and appropriate usage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Offensive Expressions of Opinion in Context. (arXiv:2104.12227v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1">Francielle Alves Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1">Isabelle Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Goes_F/0/1/0/all/0/1">Fabiana Rodrigues de G&#xf3;es</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12227">
                                    <div class="article-summary-box-inner">
                                        <span>Classic information extraction techniques consist in building questions and
answers about the facts. Indeed, it is still a challenge to subjective
information extraction systems to identify opinions and feelings in context. In
sentiment-based NLP tasks, there are few resources to information extraction,
above all offensive or hateful opinions in context. To fill this important gap,
this short paper provides a new cross-lingual and contextual offensive lexicon,
which consists of explicit and implicit offensive and swearing expressions of
opinion, which were annotated in two different classes: context dependent and
context-independent offensive. In addition, we provide markers to identify hate
speech. Annotation approach was evaluated at the expression-level and achieves
high human inter-annotator agreement. The provided offensive lexicon is
available in Portuguese and English languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Context-Aware Translation Models Pay the Right Attention?. (arXiv:2105.06977v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1">Patrick Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Aditi Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06977">
                                    <div class="article-summary-box-inner">
                                        <span>Context-aware machine translation models are designed to leverage contextual
information, but often fail to do so. As a result, they inaccurately
disambiguate pronouns and polysemous words that require context for resolution.
In this paper, we ask several questions: What contexts do human translators use
to resolve ambiguous words? Are models paying large amounts of attention to the
same context? What if we explicitly train them to do so? To answer these
questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a
new English-French dataset comprising supporting context words for 14K
translations that professional translators found useful for pronoun
disambiguation. Using SCAT, we perform an in-depth analysis of the context used
to disambiguate, examining positional and lexical characteristics of the
supporting words. Furthermore, we measure the degree of alignment between the
model&#x27;s attention scores and the supporting context from SCAT, and apply a
guided attention strategy to encourage agreement between the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Let&#x27;s Stop Incorrect Comparisons in End-to-end Relation Extraction!. (arXiv:2009.10684v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taille_B/0/1/0/all/0/1">Bruno Taill&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1">Vincent Guigue</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10684">
                                    <div class="article-summary-box-inner">
                                        <span>Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language. (arXiv:2012.14353v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behaviour like online
harassment, cyberbullying, and hate speech. Numerous works have been proposed
to utilize textual data for social and anti-social behaviour analysis, by
predicting the contexts mostly for highly-resourced languages like English.
However, some languages are under-resourced, e.g., South Asian languages like
Bengali, that lack computational resources for accurate natural language
processing (NLP). In this paper, we propose an explainable approach for hate
speech detection from the under-resourced Bengali language, which we called
DeepHateExplainer. Bengali texts are first comprehensively preprocessed, before
classifying them into political, personal, geopolitical, and religious hates
using a neural ensemble method of transformer-based neural architectures (i.e.,
monolingual Bangla BERT-base, multilingual BERT-cased/uncased, and
XLM-RoBERTa). Important(most and least) terms are then identified using
sensitivity analysis and layer-wise relevance propagation(LRP), before
providing human-interpretable explanations. Finally, we compute
comprehensiveness and sufficiency scores to measure the quality of explanations
w.r.t faithfulness. Evaluations against machine learning~(linear and tree-based
models) and neural networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word
embeddings) baselines yield F1-scores of 78%, 91%, 89%, and 84%, for political,
personal, geopolitical, and religious hates, respectively, outperforming both
ML and DNN baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Retrieval of Tables and Texts Using Tri-encoder Models. (arXiv:2108.04049v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kostic_B/0/1/0/all/0/1">Bogdan Kosti&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04049">
                                    <div class="article-summary-box-inner">
                                        <span>Open-domain extractive question answering works well on textual data by first
retrieving candidate texts and then extracting the answer from those
candidates. However, some questions cannot be answered by text alone but
require information stored in tables. In this paper, we present an approach for
retrieving both texts and tables relevant to a question by jointly encoding
texts, tables and questions into a single vector space. To this end, we create
a new multi-modal dataset based on text and table datasets from related work
and compare the retrieval performance of different encoding schemata. We find
that dense vector embeddings of transformer models outperform sparse embeddings
on four out of six evaluation datasets. Comparing different dense embedding
models, tri-encoders, with one encoder for each question, text and table,
increase retrieval performance compared to bi-encoders with one encoder for the
question and one for both text and tables. We release the newly created
multi-modal dataset to the community so that it can be used for training and
evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Not quite there yet: Combining analogical patterns and encoder-decoder networks for cognitively plausible inflection. (arXiv:2108.03968v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Calderone_B/0/1/0/all/0/1">Basilio Calderone</a> (CLLE), <a href="http://arxiv.org/find/cs/1/au:+Hathout_N/0/1/0/all/0/1">Nabil Hathout</a> (CLLE), <a href="http://arxiv.org/find/cs/1/au:+Bonami_O/0/1/0/all/0/1">Olivier Bonami</a> (LLF UMR7110)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03968">
                                    <div class="article-summary-box-inner">
                                        <span>The paper presents four models submitted to Part 2 of the SIGMORPHON 2021
Shared Task 0, which aims at replicating human judgements on the inflection of
nonce lexemes. Our goal is to explore the usefulness of combining pre-compiled
analogical patterns with an encoder-decoder architecture. Two models are
designed using such patterns either in the input or the output of the network.
Two extra models controlled for the role of raw similarity of nonce inflected
forms to existing inflected forms in the same paradigm cell, and the role of
the type frequency of analogical patterns. Our strategy is entirely endogenous
in the sense that the models appealing solely to the data provided by the
SIGMORPHON organisers, without using external resources. Our model 2 ranks
second among all submitted systems, suggesting that the inclusion of analogical
patterns in the network architecture is useful in mimicking speakers&#x27;
predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Graph Augmented Political Perspective Detection in News Media. (arXiv:2108.03861v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shangbin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zilong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Minnan Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03861">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying political perspective in news media has become an important task
due to the rapid growth of political commentary and the increasingly polarized
ideologies. Previous approaches only focus on leveraging the semantic
information and leaves out the rich social and political context that helps
individuals understand political stances. In this paper, we propose a
perspective detection method that incorporates external knowledge of real-world
politics. Specifically, we construct a contemporary political knowledge graph
with 1,071 entities and 10,703 triples. We then build a heterogeneous
information network for each news document that jointly models article
semantics and external knowledge in knowledge graphs. Finally, we apply gated
relational graph convolutional networks and conduct political perspective
detection as graph-level classification. Extensive experiments show that our
method achieves the best performance and outperforms state-of-the-art methods
by 5.49\%. Numerous ablation studies further bear out the necessity of external
knowledge and the effectiveness of our graph-based approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models. (arXiv:2108.04024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                    <div class="article-summary-box-inner">
                                        <span>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Approach for Detecting Morphological Analogies. (arXiv:2108.03945v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03945">
                                    <div class="article-summary-box-inner">
                                        <span>Analogical proportions are statements of the form &quot;A is to B as C is to D&quot;
that are used for several reasoning and classification tasks in artificial
intelligence and natural language processing (NLP). For instance, there are
analogy based approaches to semantics as well as to morphology. In fact,
symbolic approaches were developed to solve or to detect analogies between
character strings, e.g., the axiomatic approach as well as that based on
Kolmogorov complexity. In this paper, we propose a deep learning approach to
detect morphological analogies, for instance, with reinflexion or conjugation.
We present empirical results that show that our framework is competitive with
the above-mentioned state of the art symbolic approaches. We also explore
empirically its transferability capacity across languages, which highlights
interesting similarities between them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Encoding Heterogeneous Social and Political Context for Entity Stance Prediction. (arXiv:2108.03881v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shangbin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zilong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Peisheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Minnan Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03881">
                                    <div class="article-summary-box-inner">
                                        <span>Political stance detection has become an important task due to the
increasingly polarized political ideologies. Most existing works focus on
identifying perspectives in news articles or social media posts, while social
entities, such as individuals and organizations, produce these texts and
actually take stances. In this paper, we propose the novel task of entity
stance prediction, which aims to predict entities&#x27; stances given their social
and political context. Specifically, we retrieve facts from Wikipedia about
social entities regarding contemporary U.S. politics. We then annotate social
entities&#x27; stances towards political ideologies with the help of domain experts.
After defining the task of entity stance prediction, we propose a graph-based
solution, which constructs a heterogeneous information network from collected
facts and adopts gated relational graph convolutional networks for
representation learning. Our model is then trained with a combination of
supervised, self-supervised and unsupervised loss functions, which are
motivated by multiple social and political phenomenons. We conduct extensive
experiments to compare our method with existing text and graph analysis
baselines. Our model achieves highest stance detection accuracy and yields
inspiring insights regarding social entity stances. We further conduct ablation
study and parameter analysis to study the mechanism and effectiveness of our
proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting and categorising the reactions to COVID-19 by the South African public -- A social media study. (arXiv:2006.06336v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1">Vukosi Marivate</a>, <a href="http://arxiv.org/find/cs/1/au:+Moodley_A/0/1/0/all/0/1">Avashlin Moodley</a>, <a href="http://arxiv.org/find/cs/1/au:+Saba_A/0/1/0/all/0/1">Athandiwe Saba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06336">
                                    <div class="article-summary-box-inner">
                                        <span>Social Media can be used to extract discussion topics during a disaster. With
the COVID-19 pandemic impact on South Africa, we need to understand how the law
and regulation promulgated by the government in response to the pandemic
contrasts with discussion topics social media users have been engaging in. In
this work, we expand on traditional media analysis by using Social Media
discussions driven by or directed to South African government officials. We
find topics that are similar as well as different in some cases. The findings
can inform further study into social media during disaster settings in South
Africa and beyond. This paper sets a framework for future analysis in
understanding the opinions of the public during a pandemic and how these
opinions can be distilled [in a semi-automated approach] to inform government
communication in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT-based distractor generation for Swedish reading comprehension questions using a small-scale dataset. (arXiv:2108.03973v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalpakchi_D/0/1/0/all/0/1">Dmytro Kalpakchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Boye_J/0/1/0/all/0/1">Johan Boye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03973">
                                    <div class="article-summary-box-inner">
                                        <span>An important part when constructing multiple-choice questions (MCQs) for
reading comprehension assessment are the distractors, the incorrect but
preferably plausible answer options. In this paper, we present a new BERT-based
method for automatically generating distractors using only a small-scale
dataset. We also release a new such dataset of Swedish MCQs (used for training
the model), and propose a methodology for assessing the generated distractors.
Evaluation shows that from a student&#x27;s perspective, our method generated one or
more plausible distractors for more than 50% of the MCQs in our test set. From
a teacher&#x27;s perspective, about 50% of the generated distractors were deemed
appropriate. We also do a thorough analysis of the results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Images really do the Talking? Analysing the significance of Images in Tamil Troll meme classification. (arXiv:2108.03886v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1">Siddhanth U Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1">Adeep Hande</a>, <a href="http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1">Ruba Priyadharshini</a>, <a href="http://arxiv.org/find/cs/1/au:+Thavareesan_S/0/1/0/all/0/1">Sajeetha Thavareesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakuntharaj_R/0/1/0/all/0/1">Ratnasingam Sakuntharaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Thangasamy_S/0/1/0/all/0/1">Sathiyaraj Thangasamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharathi_B/0/1/0/all/0/1">B Bharathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03886">
                                    <div class="article-summary-box-inner">
                                        <span>A meme is an part of media created to share an opinion or emotion across the
internet. Due to its popularity, memes have become the new forms of
communication on social media. However, due to its nature, they are being used
in harmful ways such as trolling and cyberbullying progressively. Various data
modelling methods create different possibilities in feature extraction and
turning them into beneficial information. The variety of modalities included in
data plays a significant part in predicting the results. We try to explore the
significance of visual features of images in classifying memes. Memes are a
blend of both image and text, where the text is embedded into the image. We try
to incorporate the memes as troll and non-trolling memes based on the images
and the text on them. However, the images are to be analysed and combined with
the text to increase performance. Our work illustrates different textual
analysis methods and contrasting multimodal methods ranging from simple merging
to cross attention to utilising both worlds&#x27; - best visual and textual
features. The fine-tuned cross-lingual language model, XLM, performed the best
in textual analysis, and the multimodal transformer performs the best in
multimodal analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facebook AI WMT21 News Translation Task Submission. (arXiv:2108.03265v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Chau Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1">Shruti Bhosale</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_J/0/1/0/all/0/1">James Cross</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1">Philipp Koehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Edunov_S/0/1/0/all/0/1">Sergey Edunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1">Angela Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03265">
                                    <div class="article-summary-box-inner">
                                        <span>We describe Facebook&#x27;s multilingual model submission to the WMT2021 shared
task on news translation. We participate in 14 language directions: English to
and from Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese. To
develop systems covering all these directions, we focus on multilingual models.
We utilize data from all available sources --- WMT, large-scale data mining,
and in-domain backtranslation --- to create high quality bilingual and
multilingual baselines. Subsequently, we investigate strategies for scaling
multilingual model size, such that one system has sufficient capacity for high
quality representations of all eight languages. Our final submission is an
ensemble of dense and sparse Mixture-of-Expert multilingual translation models,
followed by finetuning on in-domain news data and noisy channel reranking.
Compared to previous year&#x27;s winning submissions, our multilingual system
improved the translation quality on all language directions, with an average
improvement of 2.0 BLEU. In the WMT2021 task, our system ranks first in 10
directions based on automatic evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Model Evaluation in Open-ended Text Generation. (arXiv:2108.03578v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03578">
                                    <div class="article-summary-box-inner">
                                        <span>Although current state-of-the-art language models have achieved impressive
results in numerous natural language processing tasks, still they could not
solve the problem of producing repetitive, dull and sometimes inconsistent text
in open-ended text generation. Studies often attribute this problem to the
maximum likelihood training objective, and propose alternative approaches by
using stochastic decoding methods or altering the training objective. However,
there is still a lack of consistent evaluation metrics to directly compare the
efficacy of these solutions. In this work, we study different evaluation
metrics that have been proposed to evaluate quality, diversity and consistency
of machine-generated text. From there, we propose a practical pipeline to
evaluate language models in open-ended generation task, and research on how to
improve the model&#x27;s performance in all dimensions by leveraging different
auxiliary training objectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">#StayHome or #Marathon? Social Media Enhanced Pandemic Surveillance on Spatial-temporal Dynamic Graphs. (arXiv:2108.03670v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yichao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jyun-yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiusi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03670">
                                    <div class="article-summary-box-inner">
                                        <span>COVID-19 has caused lasting damage to almost every domain in public health,
society, and economy. To monitor the pandemic trend, existing studies rely on
the aggregation of traditional statistical models and epidemic spread theory.
In other words, historical statistics of COVID-19, as well as the population
mobility data, become the essential knowledge for monitoring the pandemic
trend. However, these solutions can barely provide precise prediction and
satisfactory explanations on the long-term disease surveillance while the
ubiquitous social media resources can be the key enabler for solving this
problem. For example, serious discussions may occur on social media before and
after some breaking events take place. These events, such as marathon and
parade, may impact the spread of the virus. To take advantage of the social
media data, we propose a novel framework, Social Media enhAnced pandemic
suRveillance Technique (SMART), which is composed of two modules: (i)
information extraction module to construct heterogeneous knowledge graphs based
on the extracted events and relationships among them; (ii) time series
prediction module to provide both short-term and long-term forecasts of the
confirmed cases and fatality at the state-level in the United States and to
discover risk factors for COVID-19 interventions. Extensive experiments show
that our method largely outperforms the state-of-the-art baselines by 7.3% and
7.4% in confirmed case/fatality prediction, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tiny Neural Models for Seq2Seq. (arXiv:2108.03340v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kandoor_A/0/1/0/all/0/1">Arun Kandoor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03340">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic parsing models with applications in task oriented dialog systems
require efficient sequence to sequence (seq2seq) architectures to be run
on-device. To this end, we propose a projection based encoder-decoder model
referred to as pQRNN-MAtt. Studies based on projection methods were restricted
to encoder-only models, and we believe this is the first study extending it to
seq2seq architectures. The resulting quantized models are less than 3.5MB in
size and are well suited for on-device latency critical applications. We show
that on MTOP, a challenging multilingual semantic parsing dataset, the average
model performance surpasses LSTM based seq2seq model that uses pre-trained
embeddings despite being 85x smaller. Furthermore, the model can be an
effective student for distilling large pre-trained models such as T5/BERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The HW-TSC&#x27;s Offline Speech Translation Systems for IWSLT 2021 Evaluation. (arXiv:2108.03845v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Minghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaxin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingtao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yujia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Shimin Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xingshan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liangyou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Ying Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03845">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes our work in participation of the IWSLT-2021 offline
speech translation task. Our system was built in a cascade form, including a
speaker diarization module, an Automatic Speech Recognition (ASR) module and a
Machine Translation (MT) module. We directly use the LIUM SpkDiarization tool
as the diarization module. The ASR module is trained with three ASR datasets
from different sources, by multi-source training, using a modified Transformer
encoder. The MT module is pretrained on the large-scale WMT news translation
dataset and fine-tuned on the TED corpus. Our method achieves 24.6 BLEU score
on the 2021 test set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Personalized Dialogue via Multi-Task Meta-Learning. (arXiv:2108.03377v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jing Yang Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Woon Seng Gan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03377">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional approaches to personalized dialogue generation typically require
a large corpus, as well as predefined persona information. However, in a
real-world setting, neither a large corpus of training data nor persona
information are readily available. To address these practical limitations, we
propose a novel multi-task meta-learning approach which involves training a
model to adapt to new personas without relying on a large corpus, or on any
predefined persona information. Instead, the model is tasked with generating
personalized responses based on only the dialogue context. Unlike prior work,
our approach leverages on the provided persona information only during training
via the introduction of an auxiliary persona reconstruction task. In this
paper, we introduce 2 frameworks that adopt the proposed multi-task
meta-learning approach: the Multi-Task Meta-Learning (MTML) framework, and the
Alternating Multi-Task Meta-Learning (AMTML) framework. Experimental results
show that utilizing MTML and AMTML results in dialogue responses with greater
persona consistency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Transferability of Neural Models of Morphological Analogies. (arXiv:2108.03938v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03938">
                                    <div class="article-summary-box-inner">
                                        <span>Analogical proportions are statements expressed in the form &quot;A is to B as C
is to D&quot; and are used for several reasoning and classification tasks in
artificial intelligence and natural language processing (NLP). In this paper,
we focus on morphological tasks and we propose a deep learning approach to
detect morphological analogies. We present an empirical study to see how our
framework transfers across languages, and that highlights interesting
similarities and differences between these languages. In view of these results,
we also discuss the possibility of building a multilingual morphological model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Summarization with Constrained Markov Decision Process. (arXiv:2108.03405v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1">Hou Pong Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03405">
                                    <div class="article-summary-box-inner">
                                        <span>We study controllable text summarization which allows users to gain control
on a particular attribute (e.g., length limit) of the generated summaries. In
this work, we propose a novel training framework based on Constrained Markov
Decision Process (CMDP), which conveniently includes a reward function along
with a set of constraints, to facilitate better summarization control. The
reward function encourages the generation to resemble the human-written
reference, while the constraints are used to explicitly prevent the generated
summaries from violating user-imposed requirements. Our framework can be
applied to control important attributes of summarization, including length,
covered entities, and abstractiveness, as we devise specific constraints for
each of these aspects. Extensive experiments on popular benchmarks show that
our CMDP framework helps generate informative summaries while complying with a
given attribute&#x27;s requirement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An empirical assessment of deep learning approaches to task-oriented dialog management. (arXiv:2108.03478v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matej%5Cr%7Bu%7D_L/0/1/0/all/0/1">Luk&#xe1;&#x161; Mat&#x11b;j&#x16f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Griol_D/0/1/0/all/0/1">David Griol</a>, <a href="http://arxiv.org/find/cs/1/au:+Callejas_Z/0/1/0/all/0/1">Zoraida Callejas</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_J/0/1/0/all/0/1">Jos&#xe9; Manuel Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchis_A/0/1/0/all/0/1">Araceli Sanchis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03478">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is providing very positive results in areas related to
conversational interfaces, such as speech recognition, but its potential
benefit for dialog management has still not been fully studied. In this paper,
we perform an assessment of different configurations for deep-learned dialog
management with three dialog corpora from different application domains and
varying in size, dimensionality and possible system responses. Our results have
allowed us to identify several aspects that can have an impact on accuracy,
including the approaches used for feature extraction, input representation,
context consideration and the hyper-parameters of the deep neural networks
employed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Translation of Low-Resource Indo-European Languages. (arXiv:2108.03739v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei-Rui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03739">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning has been an important technique for low-resource neural
machine translation. In this work, we build two systems to study how
relatedness can benefit the translation performance. The primary system adopts
machine translation model pre-trained on related language pair and the
contrastive system adopts that pre-trained on unrelated language pair. We show
that relatedness is not required for transfer learning to work but does benefit
the performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Similar Language Translation With Transfer Learning. (arXiv:2108.03533v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1">Ife Adebara</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03533">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate transfer learning based on pre-trained neural machine
translation models to translate between (low-resource) similar languages. This
work is part of our contribution to the WMT 2021 Similar Languages Translation
Shared Task where we submitted models for different language pairs, including
French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions. Our
models for Catalan-Spanish ($82.79$ BLEU) and Portuguese-Spanish ($87.11$ BLEU)
rank top 1 in the official shared task evaluation, and we are the only team to
submit models for the French-Bambara pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Zero-shot Language Modeling. (arXiv:2108.03334v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Maria Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03334">
                                    <div class="article-summary-box-inner">
                                        <span>Can we construct a neural model that is inductively biased towards learning
human languages? Motivated by this question, we aim at constructing an
informative prior over neural weights, in order to adapt quickly to held-out
languages in the task of character-level language modeling. We infer this
distribution from a sample of typologically diverse training languages via
Laplace approximation. The use of such a prior outperforms baseline models with
an uninformative prior (so-called &quot;fine-tuning&quot;) in both zero-shot and few-shot
settings. This shows that the prior is imbued with universal phonological
knowledge. Moreover, we harness additional language-specific side information
as distant supervision for held-out languages. Specifically, we condition
language models on features from typological databases, by concatenating them
to hidden states or generating weights with hyper-networks. These features
appear beneficial in the few-shot setting, but not in the zero-shot setting.
Since the paucity of digital texts affects the majority of the world&#x27;s
languages, we hope that these findings will help broaden the scope of
applications for language technology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-tuning GPT-3 for Russian Text Summarization. (arXiv:2108.03502v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikolich_A/0/1/0/all/0/1">Alexandr Nikolich</a>, <a href="http://arxiv.org/find/cs/1/au:+Puchkova_A/0/1/0/all/0/1">Arina Puchkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03502">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic summarization techniques aim to shorten and generalize information
given in the text while preserving its core message and the most relevant
ideas. This task can be approached and treated with a variety of methods,
however, not many attempts have been made to produce solutions specifically for
the Russian language despite existing localizations of the state-of-the-art
models. In this paper, we aim to showcase ruGPT3 ability to summarize texts,
fine-tuning it on the corpora of Russian news with their corresponding
human-generated summaries. Additionally, we employ hyperparameter tuning so
that the model&#x27;s output becomes less random and more tied to the original text.
We evaluate the resulting texts with a set of metrics, showing that our
solution can surpass the state-of-the-art model&#x27;s performance without
additional changes in architecture or loss function. Despite being able to
produce sensible summaries, our model still suffers from a number of flaws,
namely, it is prone to altering Named Entities present in the original text
(such as surnames, places, dates), deviating from facts stated in the given
document, and repeating the information in the summary.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offensive Language and Hate Speech Detection with Deep Learning and Transfer Learning. (arXiv:2108.03305v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_B/0/1/0/all/0/1">Bencheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jason Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ajay Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Umair_H/0/1/0/all/0/1">Hafiza Umair</a>, <a href="http://arxiv.org/find/cs/1/au:+Vovor_A/0/1/0/all/0/1">Atsu Vovor</a>, <a href="http://arxiv.org/find/cs/1/au:+Durzynski_N/0/1/0/all/0/1">Natalie Durzynski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03305">
                                    <div class="article-summary-box-inner">
                                        <span>Toxic online speech has become a crucial problem nowadays due to an
exponential increase in the use of internet by people from different cultures
and educational backgrounds. Differentiating if a text message belongs to hate
speech and offensive language is a key challenge in automatic detection of
toxic text content. In this paper, we propose an approach to automatically
classify tweets into three classes: Hate, offensive and Neither. Using public
tweet data set, we first perform experiments to build BI-LSTM models from empty
embedding and then we also try the same neural network architecture with
pre-trained Glove embedding. Next, we introduce a transfer learning approach
for hate speech detection using an existing pre-trained language model BERT
(Bidirectional Encoder Representations from Transformers), DistilBert
(Distilled version of BERT) and GPT-2 (Generative Pre-Training). We perform
hyper parameters tuning analysis of our best model (BI-LSTM) considering
different neural network architectures, learn-ratings and normalization methods
etc. After tuning the model and with the best combination of parameters, we
achieve over 92 percent accuracy upon evaluating it on test data. We also
create a class module which contains main functionality including text
classification, sentiment checking and text data augmentation. This model could
serve as an intermediate module between user and Twitter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Team PyKale (xy9) Submission to the EPIC-Kitchens 2021 Unsupervised Domain Adaptation Challenge for Action Recognition. (arXiv:2106.12023v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1">Tao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12023">
                                    <div class="article-summary-box-inner">
                                        <span>This report describes the technical details of our submission to the
EPIC-Kitchens 2021 Unsupervised Domain Adaptation Challenge for Action
Recognition. The EPIC-Kitchens dataset is more difficult than other video
domain adaptation datasets due to multi-tasks with more modalities. Firstly, to
participate in the challenge, we employ a transformer to capture the spatial
information from each modality. Secondly, we employ a temporal attention module
to model temporal-wise inter-dependency. Thirdly, we employ the adversarial
domain adaptation network to learn the general features between labeled source
and unlabeled target domain. Finally, we incorporate multiple modalities to
improve the performance by a three-stream network with late fusion. Our network
achieves the comparable performance with the state-of-the-art baseline T$A^3$N
and outperforms the baseline on top-1 accuracy for verb class and top-5
accuracies for all three tasks which are verb, noun and action. Under the team
name xy9, our submission achieved 5th place in terms of top-1 accuracy for verb
class and all top-5 accuracies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Deep Feature Calibration for Cross-Modal Joint Embedding Learning. (arXiv:2108.00705v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00705">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a two-phase deep feature calibration framework for
efficient learning of semantics enhanced text-image cross-modal joint
embedding, which clearly separates the deep feature calibration in data
preprocessing from training the joint embedding model. We use the Recipe1M
dataset for the technical description and empirical validation. In
preprocessing, we perform deep feature calibration by combining deep feature
engineering with semantic context features derived from raw text-image input
data. We leverage LSTM to identify key terms, NLP methods to produce ranking
scores for key terms before generating the key term feature. We leverage
wideResNet50 to extract and encode the image category semantics to help
semantic alignment of the learned recipe and image embeddings in the joint
latent space. In joint embedding learning, we perform deep feature calibration
by optimizing the batch-hard triplet loss function with soft-margin and double
negative sampling, also utilizing the category-based alignment loss and
discriminator-based alignment loss. Extensive experiments demonstrate that our
SEJE approach with the deep feature calibration significantly outperforms the
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Training Collaborative Object Detectors Adaptive to Bandwidth and Computation. (arXiv:2105.00591v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Assine_J/0/1/0/all/0/1">Juliano S. Assine</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_J/0/1/0/all/0/1">J. C. S. Santos Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00591">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, mobile deep-learning deployment progressed by leaps
and bounds, but solutions still struggle to accommodate its severe and
fluctuating operational restrictions, which include bandwidth, latency,
computation, and energy. In this work, we help to bridge that gap, introducing
the first configurable solution for object detection that manages the triple
communication-computation-accuracy trade-off with a single set of weights. Our
solution shows state-of-the-art results on COCO-2017, adding only a minor
penalty on the base EfficientDet-D2 architecture. Our design is robust to the
choice of base architecture and compressor and should adapt well for future
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aerial Map-Based Navigation Using Semantic Segmentation and Pattern Matching. (arXiv:2107.00689v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Youngjoo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00689">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel approach to map-based navigation system for
unmanned aircraft. The proposed system attempts label-to-label matching, not
image-to-image matching, between aerial images and a map database. By using
semantic segmentation, the ground objects are labelled and the configuration of
the objects is used to find the corresponding location in the map database. The
use of the deep learning technique as a tool for extracting high-level features
reduces the image-based localization problem to a pattern matching problem.
This paper proposes a pattern matching algorithm which does not require
altitude information or a camera model to estimate the absolute horizontal
position. The feasibility analysis with simulated images shows the proposed
map-based navigation can be realized with the proposed pattern matching
algorithm and it is able to provide positions given the labelled objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Applications of Deep Learning Techniques for Automated Multiple Sclerosis Detection Using Magnetic Resonance Imaging: A Review. (arXiv:2105.04881v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/eess/1/au:+Khodatars_M/0/1/0/all/0/1">Marjane Khodatars</a>, <a href="http://arxiv.org/find/eess/1/au:+Jafari_M/0/1/0/all/0/1">Mahboobeh Jafari</a>, <a href="http://arxiv.org/find/eess/1/au:+Moridian_P/0/1/0/all/0/1">Parisa Moridian</a>, <a href="http://arxiv.org/find/eess/1/au:+Rezaei_M/0/1/0/all/0/1">Mitra Rezaei</a>, <a href="http://arxiv.org/find/eess/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/eess/1/au:+Khozeimeh_F/0/1/0/all/0/1">Fahime Khozeimeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Gorriz_J/0/1/0/all/0/1">Juan Manuel Gorriz</a>, <a href="http://arxiv.org/find/eess/1/au:+Heras_J/0/1/0/all/0/1">J&#xf3;nathan Heras</a>, <a href="http://arxiv.org/find/eess/1/au:+Panahiazar_M/0/1/0/all/0/1">Maryam Panahiazar</a>, <a href="http://arxiv.org/find/eess/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1">U. Rajendra Acharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04881">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple Sclerosis (MS) is a type of brain disease which causes visual,
sensory, and motor problems for people with a detrimental effect on the
functioning of the nervous system. In order to diagnose MS, multiple screening
methods have been proposed so far; among them, magnetic resonance imaging (MRI)
has received considerable attention among physicians. MRI modalities provide
physicians with fundamental information about the structure and function of the
brain, which is crucial for the rapid diagnosis of MS lesions. Diagnosing MS
using MRI is time-consuming, tedious, and prone to manual errors. Hence,
computer aided diagnosis systems (CADS) based on artificial intelligence (AI)
methods have been proposed in recent years for accurate diagnosis of MS using
MRI neuroimaging modalities. In the AI field, automated MS diagnosis is being
conducted using (i) conventional machine learning and (ii) deep learning (DL)
techniques. The conventional machine learning approach is based on feature
extraction and selection by trial and error. In DL, these steps are performed
by the DL model itself. In this paper, a complete review of automated MS
diagnosis methods performed using DL techniques with MRI neuroimaging
modalities are discussed. Also, each work is thoroughly reviewed and discussed.
Finally, the most important challenges and future directions in the automated
MS diagnosis using DL techniques coupled with MRI modalities are presented in
detail.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. (arXiv:2107.12666v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zefeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Changxing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiyin Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12666">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-image person re-identification (ReID) aims to search for images
containing a person of interest using textual descriptions. However, due to the
significant modality gap and the large intra-class variance in textual
descriptions, text-to-image ReID remains a challenging problem. Accordingly, in
this paper, we propose a Semantically Self-Aligned Network (SSAN) to handle the
above problems. First, we propose a novel method that automatically extracts
semantically aligned part-level features from the two modalities. Second, we
design a multi-view non-local network that captures the relationships between
body parts, thereby establishing better correspondences between body parts and
noun phrases. Third, we introduce a Compound Ranking (CR) loss that makes use
of textual descriptions for other images of the same identity to provide extra
supervision, thereby effectively reducing the intra-class variance in textual
features. Finally, to expedite future research in text-to-image ReID, we build
a new database named ICFG-PEDES. Extensive experiments demonstrate that SSAN
outperforms state-of-the-art approaches by significant margins. Both the new
ICFG-PEDES database and the SSAN code are available at
https://github.com/zifyloo/SSAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enriching Local and Global Contexts for Temporal Action Localization. (arXiv:2107.12960v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zixin Zhu</a> (Xi&#x27;an jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1">Wei Tang</a> (University of Illinois at Chicago), <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a> (Wormpex AI Research)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12960">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively tackling the problem of temporal action localization (TAL)
necessitates a visual representation that jointly pursues two confounding
goals, i.e., fine-grained discrimination for temporal localization and
sufficient visual invariance for action classification. We address this
challenge by enriching both the local and global contexts in the popular
two-stage temporal localization framework, where action proposals are first
generated followed by action classification and temporal boundary regression.
Our proposed model, dubbed ContextLoc, can be divided into three sub-networks:
L-Net, G-Net and P-Net. L-Net enriches the local context via fine-grained
modeling of snippet-level features, which is formulated as a
query-and-retrieval process. G-Net enriches the global context via higher-level
modeling of the video-level representation. In addition, we introduce a novel
context adaptation module to adapt the global context to different proposals.
P-Net further models the context-aware inter-proposal relations. We explore two
existing models to be the P-Net in our experiments. The efficacy of our
proposed method is validated by experimental results on the THUMOS14 (54.3\% at
tIoU@0.5) and ActivityNet v1.3 (56.01\% at tIoU@0.5) datasets, which
outperforms recent states of the art. Code is available at
https://github.com/buxiangzhiren/ContextLoc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Product1M: Towards Weakly Supervised Instance-Level Product Retrieval via Cross-modal Pretraining. (arXiv:2107.14572v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xunlin Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yangxin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Minlong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14572">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, customer&#x27;s demands for E-commerce are more diversified, which
introduces more complications to the product retrieval industry. Previous
methods are either subject to single-modal input or perform supervised
image-level product retrieval, thus fail to accommodate real-life scenarios
where enormous weakly annotated multi-modal data are present. In this paper, we
investigate a more realistic setting that aims to perform weakly-supervised
multi-modal instance-level product retrieval among fine-grained product
categories. To promote the study of this challenging task, we contribute
Product1M, one of the largest multi-modal cosmetic datasets for real-world
instance-level retrieval. Notably, Product1M contains over 1 million
image-caption pairs and consists of two sample types, i.e., single-product and
multi-product samples, which encompass a wide variety of cosmetics brands. In
addition to the great diversity, Product1M enjoys several appealing
characteristics including fine-grained categories, complex combinations, and
fuzzy correspondence that well mimic the real-world scenes. Moreover, we
propose a novel model named Cross-modal contrAstive Product Transformer for
instance-level prodUct REtrieval (CAPTURE), that excels in capturing the
potential synergy between multi-modal inputs via a hybrid-stream transformer in
a self-supervised manner.CAPTURE generates discriminative instance features via
masked multi-modal learning as well as cross-modal contrastive pretraining and
it outperforms several SOTA cross-modal baselines. Extensive ablation studies
well demonstrate the effectiveness and the generalization capacity of our
model. Dataset and codes are available at https:
//github.com/zhanxlin/Product1M.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimizing Labeling Effort for Tree Skeleton Segmentation using an Automated Iterative Training Methodology. (arXiv:2010.08296v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Granland_K/0/1/0/all/0/1">Keenan Granland</a>, <a href="http://arxiv.org/find/cs/1/au:+Newbury_R/0/1/0/all/0/1">Rhys Newbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_D/0/1/0/all/0/1">David Ting</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08296">
                                    <div class="article-summary-box-inner">
                                        <span>Training of convolutional neural networks for semantic segmentation requires
accurate pixel-wise labeling which requires large amounts of human effort. The
human-in-the-loop method reduces labeling effort; however, it requires human
intervention for each image. This paper describes a general iterative training
methodology for semantic segmentation, Automating-the-Loop. This aims to
replicate the manual adjustments of the human-in-the-loop method with an
automated process, hence, drastically reducing labeling effort. Using the
application of detecting partially occluded apple tree segmentation, we compare
manually labeled annotations, self-training, human-in-the-loop, and
Automating-the-Loop methods in both the quality of the trained convolutional
neural networks, and the effort needed to create them. The convolutional neural
network (U-Net) performance is analyzed using traditional metrics and a new
metric, Complete Grid Scan, which promotes connectivity and low noise. It is
shown that in our application, the new Automating-the-Loop method greatly
reduces the labeling effort while producing comparable performance to both
human-in-the-loop and complete manual labeling methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Counting and Localization in Crowds:A Purely Point-Based Framework. (arXiv:2107.12746v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengkai Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12746">
                                    <div class="article-summary-box-inner">
                                        <span>Localizing individuals in crowds is more in accordance with the practical
demands of subsequent high-level crowd analysis tasks than simply counting.
However, existing localization based methods relying on intermediate
representations (\textit{i.e.}, density maps or pseudo boxes) serving as
learning targets are counter-intuitive and error-prone. In this paper, we
propose a purely point-based framework for joint crowd counting and individual
localization. For this framework, instead of merely reporting the absolute
counting error at image level, we propose a new metric, called density
Normalized Average Precision (nAP), to provide more comprehensive and more
precise performance evaluation. Moreover, we design an intuitive solution under
this framework, which is called Point to Point Network (P2PNet). P2PNet
discards superfluous steps and directly predicts a set of point proposals to
represent heads in an image, being consistent with the human annotation
results. By thorough analysis, we reveal the key step towards implementing such
a novel idea is to assign optimal learning targets for these proposals.
Therefore, we propose to conduct this crucial association in an one-to-one
matching manner using the Hungarian algorithm. The P2PNet not only
significantly surpasses state-of-the-art methods on popular counting
benchmarks, but also achieves promising localization accuracy. The codes will
be available at: https://github.com/TencentYoutuResearch/CrowdCounting-P2PNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Face Hallucination and Translation for Thermal to Visible Face Verification using Axial-GAN. (arXiv:2104.06534v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Immidisetti_R/0/1/0/all/0/1">Rakhil Immidisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuowen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06534">
                                    <div class="article-summary-box-inner">
                                        <span>Existing thermal-to-visible face verification approaches expect the thermal
and visible face images to be of similar resolution. This is unlikely in
real-world long-range surveillance systems, since humans are distant from the
cameras. To address this issue, we introduce the task of thermal-to-visible
face verification from low-resolution thermal images. Furthermore, we propose
Axial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution
visible images for matching. In the proposed approach we augment the GAN
framework with axial-attention layers which leverage the recent advances in
transformers for modelling long-range dependencies. We demonstrate the
effectiveness of the proposed method by evaluating on two different
thermal-visible face datasets. When compared to related state-of-the-art works,
our results show significant improvements in both image quality and face
verification performance, and are also much more efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Accurate Localization by Instance Search. (arXiv:2107.05005v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi-Geng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hui-Chu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05005">
                                    <div class="article-summary-box-inner">
                                        <span>Visual object localization is the key step in a series of object detection
tasks. In the literature, high localization accuracy is achieved with the
mainstream strongly supervised frameworks. However, such methods require
object-level annotations and are unable to detect objects of unknown
categories. Weakly supervised methods face similar difficulties. In this paper,
a self-paced learning framework is proposed to achieve accurate object
localization on the rank list returned by instance search. The proposed
framework mines the target instance gradually from the queries and their
corresponding top-ranked search results. Since a common instance is shared
between the query and the images in the rank list, the target visual instance
can be accurately localized even without knowing what the object category is.
In addition to performing localization on instance search, the issue of
few-shot object detection is also addressed under the same framework. Superior
performance over state-of-the-art methods is observed on both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection using Edge Computing in Video Surveillance System: Review. (arXiv:2107.02778v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrikar_D/0/1/0/all/0/1">Devashree R. Patrikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur Rajram Parate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02778">
                                    <div class="article-summary-box-inner">
                                        <span>The current concept of Smart Cities influences urban planners and researchers
to provide modern, secured and sustainable infrastructure and give a decent
quality of life to its residents. To fulfill this need video surveillance
cameras have been deployed to enhance the safety and well-being of the
citizens. Despite technical developments in modern science, abnormal event
detection in surveillance video systems is challenging and requires exhaustive
human efforts. In this paper, we surveyed various methodologies developed to
detect anomalies in intelligent video surveillance. Firstly, we revisit the
surveys on anomaly detection in the last decade. We then present a systematic
categorization of methodologies developed for ease of understanding.
Considering the notion of anomaly depends on context, we identify different
objects-of-interest and publicly available datasets in anomaly detection. Since
anomaly detection is considered a time-critical application of computer vision,
our emphasis is on anomaly detection using edge devices and approaches
explicitly designed for them. Further, we discuss the challenges and
opportunities involved in anomaly detection at the edge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-view: Diagnosis of COVID-19 using Chest CT. (arXiv:2108.03799v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jadhav_S/0/1/0/all/0/1">Shreeraj Jadhav</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_G/0/1/0/all/0/1">Gaofeng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zawin_M/0/1/0/all/0/1">Marlene Zawin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufman_A/0/1/0/all/0/1">Arie E. Kaufman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03799">
                                    <div class="article-summary-box-inner">
                                        <span>Significant work has been done towards deep learning (DL) models for
automatic lung and lesion segmentation and classification of COVID-19 on chest
CT data. However, comprehensive visualization systems focused on supporting the
dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a
visualization application specially tailored for radiologists to diagnose
COVID-19 from chest CT data. The system incorporates a complete pipeline of
automatic lungs segmentation, localization/ isolation of lung abnormalities,
followed by visualization, visual and DL analysis, and
measurement/quantification tools. Our system combines the traditional 2D
workflow of radiologists with newer 2D and 3D visualization techniques with DL
support for a more comprehensive diagnosis. COVID-view incorporates a novel DL
model for classifying the patients into positive/negative COVID-19 cases, which
acts as a reading aid for the radiologist using COVID-view and provides the
attention heatmap as an explainable DL for the model output. We designed and
evaluated COVID-view through suggestions, close feedback and conducting case
studies of real-world patient data by expert radiologists who have substantial
experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and
other forms of lung infections. We present requirements and task analysis for
the diagnosis of COVID-19 that motivate our design choices and results in a
practical system which is capable of handling real-world patient cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Persistence Curves: A canonical framework for summarizing persistence diagrams. (arXiv:1904.07768v4 [cs.CG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yu-Min Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawson_A/0/1/0/all/0/1">Austin Lawson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.07768">
                                    <div class="article-summary-box-inner">
                                        <span>Persistence diagrams are one of the main tools in the field of Topological
Data Analysis (TDA). They contain fruitful information about the shape of data.
The use of machine learning algorithms on the space of persistence diagrams
proves to be challenging as the space lacks an inner product. For that reason,
transforming these diagrams in a way that is compatible with machine learning
is an important topic currently researched in TDA. In this paper, our main
contribution consists of three components. First, we develop a general and
unifying framework of vectorizing diagrams that we call the \textit{Persistence
Curves} (PCs), and show that several well-known summaries, such as Persistence
Landscapes, fall under the PC framework. Second, we propose several new
summaries based on PC framework and provide a theoretical foundation for their
stability analysis. Finally, we apply proposed PCs to two
applications---texture classification and determining the parameters of a
discrete dynamical system; their performances are competitive with other TDA
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Re-energizing Domain Discriminator with Sample Relabeling for Adversarial Domain Adaptation. (arXiv:2103.11661v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11661">
                                    <div class="article-summary-box-inner">
                                        <span>Many unsupervised domain adaptation (UDA) methods exploit domain adversarial
training to align the features to reduce domain gap, where a feature extractor
is trained to fool a domain discriminator in order to have aligned feature
distributions. The discrimination capability of the domain classifier w.r.t the
increasingly aligned feature distributions deteriorates as training goes on,
thus cannot effectively further drive the training of feature extractor. In
this work, we propose an efficient optimization strategy named Re-enforceable
Adversarial Domain Adaptation (RADA) which aims to re-energize the domain
discriminator during the training by using dynamic domain labels. Particularly,
we relabel the well aligned target domain samples as source domain samples on
the fly. Such relabeling makes the less separable distributions more separable,
and thus leads to a more powerful domain classifier w.r.t. the new data
distributions, which in turn further drives feature alignment. Extensive
experiments on multiple UDA benchmarks demonstrate the effectiveness and
superiority of our RADA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adaptive Transfer Learning for Multicenter Glaucoma Classification in Fundus Retina Images. (arXiv:2105.03068v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bao_Y/0/1/0/all/0/1">Yiming Bao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Tong Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_L/0/1/0/all/0/1">Linyan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jianwei Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1">Juan Ye</a>, <a href="http://arxiv.org/find/eess/1/au:+Qian_D/0/1/0/all/0/1">Dahong Qian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03068">
                                    <div class="article-summary-box-inner">
                                        <span>The early diagnosis and screening of glaucoma are important for patients to
receive treatment in time and maintain eyesight. Nowadays, deep learning (DL)
based models have been successfully used for computer-aided diagnosis (CAD) of
glaucoma from retina fundus images. However, a DL model pre-trained using a
dataset from one hospital center may have poor performance on a dataset from
another new hospital center and therefore its applications in the real scene
are limited. In this paper, we propose a self-adaptive transfer learning (SATL)
strategy to fill the domain gap between multicenter datasets. Specifically, the
encoder of a DL model that is pre-trained on the source domain is used to
initialize the encoder of a reconstruction model. Then, the reconstruction
model is trained using only unlabeled image data from the target domain, which
makes the encoder in the model adapt itself to extract useful high-level
features both for target domain images encoding and glaucoma classification,
simultaneously. Experimental results demonstrate that the proposed SATL
strategy is effective in the domain adaptation task between one private and two
public glaucoma diagnosis datasets, i.e. pri-RFG, REFUGE, and LAG. Moreover,
the proposed strategy is completely independent of the source domain data,
which meets the real scene application and the privacy protection policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Negative Transfer. (arXiv:2009.00909v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) utilizes data or knowledge from one or more source
domains to facilitate the learning in a target domain. It is particularly
useful when the target domain has very few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., leveraging source
domain data/knowledge undesirably reduces the learning performance in the
target domain, has been a long-standing and challenging problem in TL. Various
approaches have been proposed in the literature to handle it. However, there
does not exist a systematic survey on the formulation of NT, the factors
leading to NT, and the algorithms that mitigate NT. This paper fills this gap,
by first introducing the definition of NT and its factors, then reviewing about
fifty representative approaches for overcoming NT, according to four
categories: secure transfer, domain similarity estimation, distant transfer,
and NT mitigation. NT in related fields, e.g., multi-task learning, lifelong
learning, and adversarial attacks, are also discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-stream Convolutional Networks for Multi-frame Face Anti-spoofing. (arXiv:2108.04032v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1">Xiya Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifeng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04032">
                                    <div class="article-summary-box-inner">
                                        <span>Face anti-spoofing is an important task to protect the security of face
recognition. Most of previous work either struggle to capture discriminative
and generalizable feature or rely on auxiliary information which is unavailable
for most of industrial product. Inspired by the video classification work, we
propose an efficient two-stream model to capture the key differences between
live and spoof faces, which takes multi-frames and RGB difference as input
respectively. Feature pyramid modules with two opposite fusion directions and
pyramid pooling modules are applied to enhance feature representation. We
evaluate the proposed method on the datasets of Siw, Oulu-NPU, CASIA-MFSD and
Replay-Attack. The results show that our model achieves the state-of-the-art
results on most of datasets&#x27; protocol with much less parameter size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening. (arXiv:2108.03815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03815">
                                    <div class="article-summary-box-inner">
                                        <span>To mitigate the inspector&#x27;s workload and improve the quality of the product,
computer vision-based anomaly detection (AD) techniques are gradually deployed
in real-world industrial scenarios. Recent anomaly analysis benchmarks progress
to generative models. The aim is to model the defect-free distribution so that
anomalies can be classified as out-of-distribution samples. Nevertheless, there
are two disturbing factors that need researchers and deployers to prioritize:
(i) the simplistic prior latent distribution inducing limited expressive
capability; (ii) the collapsed mutual-dependent features resulting in poor
generalization. In this paper, we propose a novel Patch-wise Wasserstein
AutoEncoder (P-WAE) architecture to alleviate those challenges. In particular,
a patch-wise variational inference model coupled with solving the jigsaw puzzle
is designed, which is a simple yet effective way to increase the expressiveness
and complexity of the latent manifold. This alleviates the blurry
reconstruction problem. In addition, the Hilbert-Schmidt Independence Criterion
(HSIC) bottleneck is introduced to constrain the over-regularization
representation. Comprehensive experiments, conducted on the MVTec AD dataset,
demonstrate the superior performance of our propo</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Multi-Scale Loss Optimization for Object Detection. (arXiv:2108.04014v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yihao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Juntao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1">Peng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianjiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1">Qi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04014">
                                    <div class="article-summary-box-inner">
                                        <span>With the continuous improvement of the performance of object detectors via
advanced model architectures, imbalance problems in the training process have
received more attention. It is a common paradigm in object detection frameworks
to perform multi-scale detection. However, each scale is treated equally during
training. In this paper, we carefully study the objective imbalance of
multi-scale detector training. We argue that the loss in each scale level is
neither equally important nor independent. Different from the existing
solutions of setting multi-task weights, we dynamically optimize the loss
weight of each scale level in the training process. Specifically, we propose an
Adaptive Variance Weighting (AVW) to balance multi-scale loss according to the
statistical variance. Then we develop a novel Reinforcement Learning
Optimization (RLO) to decide the weighting scheme probabilistically during
training. The proposed dynamic methods make better utilization of multi-scale
training loss without extra computational complexity and learnable parameters
for backpropagation. Experiments show that our approaches can consistently
boost the performance over various baseline detectors on Pascal VOC and MS COCO
benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Paint Transformer: Feed Forward Neural Painting with Stroke Prediction. (arXiv:2108.03798v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1">Ruifeng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03798">
                                    <div class="article-summary-box-inner">
                                        <span>Neural painting refers to the procedure of producing a series of strokes for
a given image and non-photo-realistically recreating it using neural networks.
While reinforcement learning (RL) based agents can generate a stroke sequence
step by step for this task, it is not easy to train a stable RL agent. On the
other hand, stroke optimization methods search for a set of stroke parameters
iteratively in a large search space; such low efficiency significantly limits
their prevalence and practicality. Different from previous methods, in this
paper, we formulate the task as a set prediction problem and propose a novel
Transformer-based framework, dubbed Paint Transformer, to predict the
parameters of a stroke set with a feed forward network. This way, our model can
generate a set of strokes in parallel and obtain the final painting of size 512
* 512 in near real time. More importantly, since there is no dataset available
for training the Paint Transformer, we devise a self-training pipeline such
that it can be trained without any off-the-shelf dataset while still achieving
excellent generalization capability. Experiments demonstrate that our method
achieves better painting performance than previous ones with cheaper training
and inference costs. Codes and models are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-based Differentiable Depth Sensor Simulation. (arXiv:2103.16563v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Planche_B/0/1/0/all/0/1">Benjamin Planche</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rajat Vikram Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16563">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient-based algorithms are crucial to modern computer-vision and graphics
applications, enabling learning-based optimization and inverse problems. For
example, photorealistic differentiable rendering pipelines for color images
have been proven highly valuable to applications aiming to map 2D and 3D
domains. However, to the best of our knowledge, no effort has been made so far
towards extending these gradient-based methods to the generation of depth
(2.5D) images, as simulating structured-light depth sensors implies solving
complex light transport and stereo-matching problems. In this paper, we
introduce a novel end-to-end differentiable simulation pipeline for the
generation of realistic 2.5D scans, built on physics-based 3D rendering and
custom block-matching algorithms. Each module can be differentiated w.r.t
sensor and scene parameters; e.g., to automatically tune the simulation for new
devices over some provided scans or to leverage the pipeline as a 3D-to-2.5D
transformer within larger computer-vision applications. Applied to the training
of deep-learning methods for various depth-based recognition tasks
(classification, pose estimation, semantic segmentation), our simulation
greatly improves the performance of the resulting models on real scans, thereby
demonstrating the fidelity and value of its synthetic depth data compared to
previous static simulations and learning-based domain adaptation schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Learning of Occlusion Aware Flow Guided 3D Geometry Perception with Adaptive Cross Weighted Loss from Monocular Videos. (arXiv:2108.03893v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiaojiao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guizhong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03893">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised deep learning-based 3D scene understanding methods can
overcome the difficulty of acquiring the densely labeled ground-truth and have
made a lot of advances. However, occlusions and moving objects are still some
of the major limitations. In this paper, we explore the learnable occlusion
aware optical flow guided self-supervised depth and camera pose estimation by
an adaptive cross weighted loss to address the above limitations. Firstly, we
explore to train the learnable occlusion mask fused optical flow network by an
occlusion-aware photometric loss with the temporally supplemental information
and backward-forward consistency of adjacent views. And then, we design an
adaptive cross-weighted loss between the depth-pose and optical flow loss of
the geometric and photometric error to distinguish the moving objects which
violate the static scene assumption. Our method shows promising results on
KITTI, Make3D, and Cityscapes datasets under multiple tasks. We also show good
generalization ability under a variety of challenging scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor Yard: One-Shot Algorithm of Hardware-Friendly Tensor-Train Decomposition for Convolutional Neural Networks. (arXiv:2108.04029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taskynov_A/0/1/0/all/0/1">Anuar Taskynov</a>, <a href="http://arxiv.org/find/cs/1/au:+Korviakov_V/0/1/0/all/0/1">Vladimir Korviakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazurenko_I/0/1/0/all/0/1">Ivan Mazurenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yepan Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04029">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays Deep Learning became widely used in many economic, technical and
scientific areas of human interest. It is clear that efficiency of solutions
based on Deep Neural Networks should consider not only quality metric for the
target task, but also latency and constraints of target platform design should
be taken into account. In this paper we present novel hardware-friendly
Tensor-Train decomposition implementation for Convolutional Neural Networks
together with Tensor Yard - one-shot training algorithm which optimizes an
order of decomposition of network layers. These ideas allow to accelerate
ResNet models on Ascend 310 NPU devices without significant loss of accuracy.
For example we accelerate ResNet-101 by 14.6% with drop by 0.5 of top-1
ImageNet accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Monocular Hand Pose Estimation on Embedded Systems. (arXiv:2102.07067v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1">Shan An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiajie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1">Dong Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Haogang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsintotas_K/0/1/0/all/0/1">Konstantinos A. Tsintotas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07067">
                                    <div class="article-summary-box-inner">
                                        <span>Hand pose estimation is a fundamental task in many human-robot
interaction-related applications. However, previous approaches suffer from
unsatisfying hand landmark predictions in real-world scenes and high
computation burden. In this paper, we propose a fast and accurate framework for
hand pose estimation, dubbed as &quot;FastHand&quot;. Using a lightweight encoder-decoder
network architecture, FastHand fulfills the requirements of practical
applications running on embedded devices. The encoder consists of deep layers
with a small number of parameters, while the decoder makes use of spatial
location information to obtain more accurate results. The evaluation took place
on two publicly available datasets demonstrating the improved performance of
the proposed pipeline compared to other state-of-the-art approaches. FastHand
offers high accuracy scores while reaching a speed of 25 frames per second on
an NVIDIA Jetson TX2 graphics processing unit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PASS: Protected Attribute Suppression System for Mitigating Bias in Face Recognition. (arXiv:2108.03764v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhar_P/0/1/0/all/0/1">Prithviraj Dhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleason_J/0/1/0/all/0/1">Joshua Gleason</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Aniket Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_C/0/1/0/all/0/1">Carlos D. Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03764">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition networks encode information about sensitive attributes while
being trained for identity classification. Such encoding has two major issues:
(a) it makes the face representations susceptible to privacy leakage (b) it
appears to contribute to bias in face recognition. However, existing bias
mitigation approaches generally require end-to-end training and are unable to
achieve high verification accuracy. Therefore, we present a descriptor-based
adversarial de-biasing approach called &#x60;Protected Attribute Suppression System
(PASS)&#x27;. PASS can be trained on top of descriptors obtained from any previously
trained high-performing network to classify identities and simultaneously
reduce encoding of sensitive attributes. This eliminates the need for
end-to-end training. As a component of PASS, we present a novel discriminator
training strategy that discourages a network from encoding protected attribute
information. We show the efficacy of PASS to reduce gender and skintone
information in descriptors from SOTA face recognition networks like Arcface. As
a result, PASS descriptors outperform existing baselines in reducing gender and
skintone bias on the IJB-C dataset, while maintaining a high verification
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models. (arXiv:2108.04024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                    <div class="article-summary-box-inner">
                                        <span>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FIFA: Fast Inference Approximation for Action Segmentation. (arXiv:2108.03894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Farha_Y/0/1/0/all/0/1">Yazan Abu Farha</a>, <a href="http://arxiv.org/find/cs/1/au:+Despinoy_F/0/1/0/all/0/1">Fabien Despinoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03894">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce FIFA, a fast approximate inference method for action
segmentation and alignment. Unlike previous approaches, FIFA does not rely on
expensive dynamic programming for inference. Instead, it uses an approximate
differentiable energy function that can be minimized using gradient-descent.
FIFA is a general approach that can replace exact inference improving its speed
by more than 5 times while maintaining its performance. FIFA is an anytime
inference algorithm that provides a better speed vs. accuracy trade-off
compared to exact inference. We apply FIFA on top of state-of-the-art
approaches for weakly supervised action segmentation and alignment as well as
fully supervised action segmentation. FIFA achieves state-of-the-art results on
most metrics on two action segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images. (arXiv:2108.03788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark. (arXiv:2108.03830v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhiqiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Baobei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03830">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular depth estimation aims at predicting depth from a single image or
video. Recently, self-supervised methods draw much attention, due to their free
of depth annotations and impressive performance on several daytime benchmarks,
such as KITTI and Cityscapes. However, they produce weird outputs in more
challenging nighttime scenarios because of low visibility and varying
illuminations, which bring weak textures and break brightness-consistency
assumption, respectively. To address these problems, in this paper we propose a
novel framework with several improvements: (1) we introduce Priors-Based
Regularization to learn distribution knowledge from unpaired depth maps and
prevent model from being incorrectly trained; (2) we leverage
Mapping-Consistent Image Enhancement module to enhance image visibility and
contrast while maintaining brightness consistency; and (3) we present
Statistics-Based Mask strategy to tune the number of removed pixels within
textureless regions, using dynamic statistics. Experimental results demonstrate
the effectiveness of each component. Meanwhile, our framework achieves
remarkable improvements and state-of-the-art results on two nighttime datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards to Robust and Generalized Medical Image Segmentation Framework. (arXiv:2108.03823v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yurong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03823">
                                    <div class="article-summary-box-inner">
                                        <span>To mitigate the radiologist&#x27;s workload, computer-aided diagnosis with the
capability to review and analyze medical images is gradually deployed. Deep
learning-based region of interest segmentation is among the most exciting use
cases. However, this paradigm is restricted in real-world clinical applications
due to poor robustness and generalization. The issue is more sinister with a
lack of training data. In this paper, we address the challenge from the
representation learning point of view. We investigate that the collapsed
representations, as one of the main reasons which caused poor robustness and
generalization, could be avoided through transfer learning. Therefore, we
propose a novel two-stage framework for robust generalized segmentation. In
particular, an unsupervised Tile-wise AutoEncoder (T-AE) pretraining
architecture is coined to learn meaningful representation for improving the
generalization and robustness of the downstream tasks. Furthermore, the learned
knowledge is transferred to the segmentation benchmark. Coupled with an image
reconstruction network, the representation keeps to be decoded, encouraging the
model to capture more semantic features. Experiments of lung segmentation on
multi chest X-ray datasets are conducted. Empirically, the related experimental
results demonstrate the superior generalization capability of the proposed
framework on unseen domains in terms of high performance and robustness to
corruption, especially under the scenario of the limited training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LatticeNet: Fast Spatio-Temporal Point Cloud Segmentation Using Permutohedral Lattices. (arXiv:2108.03917v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutt_P/0/1/0/all/0/1">Peer Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Quenzel_J/0/1/0/all/0/1">Jan Quenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03917">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) have shown outstanding performance
in the task of semantically segmenting images. Applying the same methods on 3D
data still poses challenges due to the heavy memory requirements and the lack
of structured data. Here, we propose LatticeNet, a novel approach for 3D
semantic segmentation, which takes raw point clouds as input. A PointNet
describes the local geometry which we embed into a sparse permutohedral
lattice. The lattice allows for fast convolutions while keeping a low memory
footprint. Further, we introduce DeformSlice, a novel learned data-dependent
interpolation for projecting lattice features back onto the point cloud. We
present results of 3D segmentation on multiple datasets where our method
achieves state-of-the-art performance. We also extend and evaluate our network
for instance and dynamic object segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical View Predictor: Unsupervised 3D Global Feature Learning through Hierarchical Prediction among Unordered Views. (arXiv:2108.03743v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Shen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zwicker_M/0/1/0/all/0/1">Matthias Zwicker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03743">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised learning of global features for 3D shape analysis is an
important research challenge because it avoids manual effort for supervised
information collection. In this paper, we propose a view-based deep learning
model called Hierarchical View Predictor (HVP) to learn 3D shape features from
unordered views in an unsupervised manner. To mine highly discriminative
information from unordered views, HVP performs a novel hierarchical view
prediction over a view pair, and aggregates the knowledge learned from the
predictions in all view pairs into a global feature. In a view pair, we pose
hierarchical view prediction as the task of hierarchically predicting a set of
image patches in a current view from its complementary set of patches, and in
addition, completing the current view and its opposite from any one of the two
sets of patches. Hierarchical prediction, in patches to patches, patches to
view and view to view, facilitates HVP to effectively learn the structure of 3D
shapes from the correlation between patches in the same view and the
correlation between a pair of complementary views. In addition, the employed
implicit aggregation over all view pairs enables HVP to learn global features
from unordered views. Our results show that HVP can outperform state-of-the-art
methods under large-scale 3D shape benchmarks in shape classification and
retrieval.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OVIS: Open-Vocabulary Visual Instance Search via Visual-Semantic Aligned Representation Learning. (arXiv:2108.03704v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kevin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Junsong Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03704">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the task of open-vocabulary visual instance search (OVIS). Given
an arbitrary textual search query, Open-vocabulary Visual Instance Search
(OVIS) aims to return a ranked list of visual instances, i.e., image patches,
that satisfies the search intent from an image database. The term &quot;open
vocabulary&quot; means that there are neither restrictions to the visual instance to
be searched nor restrictions to the word that can be used to compose the
textual search query. We propose to address such a search challenge via
visual-semantic aligned representation learning (ViSA). ViSA leverages massive
image-caption pairs as weak image-level (not instance-level) supervision to
learn a rich cross-modal semantic space where the representations of visual
instances (not images) and those of textual queries are aligned, thus allowing
us to measure the similarities between any visual instance and an arbitrary
textual query. To evaluate the performance of ViSA, we build two datasets named
OVIS40 and OVIS1600 and also introduce a pipeline for error analysis. Through
extensive experiments on the two datasets, we demonstrate ViSA&#x27;s ability to
search for visual instances in images not available during training given a
wide range of textual queries including those composed of uncommon words.
Experimental results show that ViSA achieves an mAP@50 of 21.9% on OVIS40 under
the most challenging setting and achieves an mAP@6 of 14.9% on OVIS1600
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Hierarchical Graph Reasoning with Semantic Coherence for Video-and-Language Inference. (arXiv:2107.12270v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juncheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Linchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haochen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yueting Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12270">
                                    <div class="article-summary-box-inner">
                                        <span>Video-and-Language Inference is a recently proposed task for joint
video-and-language understanding. This new task requires a model to draw
inference on whether a natural language statement entails or contradicts a
given video clip. In this paper, we study how to address three critical
challenges for this task: judging the global correctness of the statement
involved multiple semantic meanings, joint reasoning over video and subtitles,
and modeling long-range relationships and complex social interactions. First,
we propose an adaptive hierarchical graph network that achieves in-depth
understanding of the video over complex interactions. Specifically, it performs
joint reasoning over video and subtitles in three hierarchies, where the graph
structure is adaptively adjusted according to the semantic structures of the
statement. Secondly, we introduce semantic coherence learning to explicitly
encourage the semantic coherence of the adaptive hierarchical graph network
from three hierarchies. The semantic coherence learning can further improve the
alignment between vision and linguistics, and the coherence across a sequence
of video segments. Experimental results show that our method significantly
outperforms the baseline by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time Series Forecasting of New Cases and New Deaths Rate for COVID-19 using Deep Learning Methods. (arXiv:2104.15007v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ayoobi_N/0/1/0/all/0/1">Nooshin Ayoobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chofreh_A/0/1/0/all/0/1">Abdoulmohammad Gholamzadeh Chofreh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goni_F/0/1/0/all/0/1">Feybi Ariani Goni</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemes_J/0/1/0/all/0/1">Jiri Jaromir Klemes</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1">Amir Mosavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15007">
                                    <div class="article-summary-box-inner">
                                        <span>The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered real-time
forecasting of time series. Six different deep learning methods are examined on
the data adopted from the WHO website. Three methods are LSTM, Convolutional
LSTM, and GRU. The bidirectional extension is then considered for each method
to forecast the rate of new cases and new deaths in Australia and Iran
countries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Perspective Anomaly Detection. (arXiv:2105.09903v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1">Peter Jakob</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1">Manav Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1">Tobias Schmid-Schirling</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection is a critical problem in the manufacturing industry. In
many applications, images of objects to be analyzed are captured from multiple
perspectives which can be exploited to improve the robustness of anomaly
detection. In this work, we build upon the deep support vector data description
algorithm and address multi-perspective anomaly detection using three different
fusion techniques, i.e., early fusion, late fusion, and late fusion with
multiple decoders. We employ different augmentation techniques with a denoising
process to deal with scarce one-class data, which further improves the
performance (ROC AUC $&#x3D; 80\%$). Furthermore, we introduce the dices dataset,
which consists of over 2000 grayscale images of falling dices from multiple
perspectives, with 5\% of the images containing rare anomalies (e.g., drill
holes, sawing, or scratches). We evaluate our approach on the new dices dataset
using images from two different perspectives and also benchmark on the standard
MNIST dataset. Extensive experiments demonstrate that our proposed
{multi-perspective} approach exceeds the state-of-the-art {single-perspective
anomaly detection on both the MNIST and dices datasets}. To the best of our
knowledge, this is the first work that focuses on addressing multi-perspective
anomaly detection in images by jointly using different perspectives together
with one single objective function for anomaly detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pro-UIGAN: Progressive Face Hallucination from Occluded Thumbnails. (arXiv:2108.00602v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaobo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00602">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the task of hallucinating an authentic
high-resolution (HR) face from an occluded thumbnail. We propose a multi-stage
Progressive Upsampling and Inpainting Generative Adversarial Network, dubbed
Pro-UIGAN, which exploits facial geometry priors to replenish and upsample (8*)
the occluded and tiny faces (16*16 pixels). Pro-UIGAN iteratively (1) estimates
facial geometry priors for low-resolution (LR) faces and (2) acquires
non-occluded HR face images under the guidance of the estimated priors. Our
multi-stage hallucination network super-resolves and inpaints occluded LR faces
in a coarse-to-fine manner, thus reducing unwanted blurriness and artifacts
significantly. Specifically, we design a novel cross-modal transformer module
for facial priors estimation, in which an input face and its landmark features
are formulated as queries and keys, respectively. Such a design encourages
joint feature learning across the input facial and landmark features, and deep
feature correspondences will be discovered by attention. Thus, facial
appearance features and facial geometry priors are learned in a mutual
promotion manner. Extensive experiments demonstrate that our Pro-UIGAN achieves
visually pleasing HR faces, reaching superior performance in downstream tasks,
i.e., face alignment, face parsing, face recognition and expression
classification, compared with other state-of-the-art (SotA) methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLiT: Neural Architecture Search for Global and Local Image Transformer. (arXiv:2107.02960v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+yan_J/0/1/0/all/0/1">Junjie yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02960">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first Neural Architecture Search (NAS) method to find a
better transformer architecture for image recognition. Recently, transformers
without CNN-based backbones are found to achieve impressive performance for
image recognition. However, the transformer is designed for NLP tasks and thus
could be sub-optimal when directly used for image recognition. In order to
improve the visual representation ability for transformers, we propose a new
search space and searching algorithm. Specifically, we introduce a locality
module that models the local correlations in images explicitly with fewer
computational cost. With the locality module, our search space is defined to
let the search algorithm freely trade off between global and local information
as well as optimizing the low-level design choice in each module. To tackle the
problem caused by huge search space, a hierarchical neural architecture search
method is proposed to search the optimal vision transformer from two levels
separately with the evolutionary algorithm. Extensive experiments on the
ImageNet dataset demonstrate that our method can find more discriminative and
efficient transformer variants than the ResNet family (e.g., ResNet101) and the
baseline ViT for image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the computational demands underlying visual reasoning. (arXiv:2108.03603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaishnav_M/0/1/0/all/0/1">Mohit Vaishnav</a>, <a href="http://arxiv.org/find/cs/1/au:+Cadene_R/0/1/0/all/0/1">Remi Cadene</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1">Andrea Alamia</a>, <a href="http://arxiv.org/find/cs/1/au:+Linsley_D/0/1/0/all/0/1">Drew Linsley</a>, <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>, <a href="http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1">Thomas Serre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03603">
                                    <div class="article-summary-box-inner">
                                        <span>Visual understanding requires comprehending complex visual relations between
objects within a scene. Here, we seek to characterize the computational demands
for abstract visual reasoning. We do this by systematically assessing the
ability of modern deep convolutional neural networks (CNNs) to learn to solve
the Synthetic Visual Reasoning Test (SVRT) challenge, a collection of
twenty-three visual reasoning problems. Our analysis leads to a novel taxonomy
of visual reasoning tasks, which can be primarily explained by both the type of
relations (same-different vs. spatial-relation judgments) and the number of
relations used to compose the underlying rules. Prior cognitive neuroscience
work suggests that attention plays a key role in human&#x27;s visual reasoning
ability. To test this, we extended the CNNs with spatial and feature-based
attention mechanisms. In a second series of experiments, we evaluated the
ability of these attention networks to learn to solve the SVRT challenge and
found the resulting architectures to be much more efficient at solving the
hardest of these visual reasoning tasks. Most importantly, the corresponding
improvements on individual tasks partially explained the taxonomy. Overall,
this work advances our understanding of visual reasoning and yields testable
Neuroscience predictions regarding the need for feature-based vs. spatial
attention in visual reasoning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaAttN: Revisit Attention Mechanism in Arbitrary Neural Style Transfer. (arXiv:2108.03647v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Songhua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meiling Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhengxing Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03647">
                                    <div class="article-summary-box-inner">
                                        <span>Fast arbitrary neural style transfer has attracted widespread attention from
academic, industrial and art communities due to its flexibility in enabling
various applications. Existing solutions either attentively fuse deep style
feature into deep content feature without considering feature distributions, or
adaptively normalize deep content feature according to the style such that
their global statistics are matched. Although effective, leaving shallow
feature unexplored and without locally considering feature statistics, they are
prone to unnatural output with unpleasing local distortions. To alleviate this
problem, in this paper, we propose a novel attention and normalization module,
named Adaptive Attention Normalization (AdaAttN), to adaptively perform
attentive normalization on per-point basis. Specifically, spatial attention
score is learnt from both shallow and deep features of content and style
images. Then per-point weighted statistics are calculated by regarding a style
feature point as a distribution of attention-weighted output of all style
feature points. Finally, the content feature is normalized so that they
demonstrate the same local feature statistics as the calculated per-point
weighted style feature statistics. Besides, a novel local feature loss is
derived based on AdaAttN to enhance local visual quality. We also extend
AdaAttN to be ready for video style transfer with slight modifications.
Experiments demonstrate that our method achieves state-of-the-art arbitrary
image/video style transfer. Codes and models are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction. (arXiv:2012.06170v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Samyak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Yarlagadda_P/0/1/0/all/0/1">Pradeep Yarlagadda</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyoti_S/0/1/0/all/0/1">Shreyank Jyoti</a>, <a href="http://arxiv.org/find/cs/1/au:+Karthik_S/0/1/0/all/0/1">Shyamgopal Karthik</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_R/0/1/0/all/0/1">Ramanathan Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_V/0/1/0/all/0/1">Vineet Gandhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06170">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the ViNet architecture for audio-visual saliency prediction. ViNet
is a fully convolutional encoder-decoder architecture. The encoder uses visual
features from a network trained for action recognition, and the decoder infers
a saliency map via trilinear interpolation and 3D convolutions, combining
features from multiple hierarchies. The overall architecture of ViNet is
conceptually simple; it is causal and runs in real-time (60 fps). ViNet does
not use audio as input and still outperforms the state-of-the-art audio-visual
saliency prediction models on nine different datasets (three visual-only and
six audio-visual datasets). ViNet also surpasses human performance on the CC,
SIM and AUC metrics for the AVE dataset, and to our knowledge, it is the first
network to do so. We also explore a variation of ViNet architecture by
augmenting audio features into the decoder. To our surprise, upon sufficient
training, the network becomes agnostic to the input audio and provides the same
output irrespective of the input. Interestingly, we also observe similar
behaviour in the previous state-of-the-art models \cite{tsiami2020stavis} for
audio-visual saliency prediction. Our findings contrast with previous works on
deep learning-based audio-visual saliency prediction, suggesting a clear avenue
for future explorations incorporating audio in a more effective manner. The
code and pre-trained models are available at
https://github.com/samyak0210/ViNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An EM Framework for Online Incremental Learning of Semantic Segmentation. (arXiv:2108.03613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shipeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiale Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiangwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03613">
                                    <div class="article-summary-box-inner">
                                        <span>Incremental learning of semantic segmentation has emerged as a promising
strategy for visual scene interpretation in the open- world setting. However,
it remains challenging to acquire novel classes in an online fashion for the
segmentation task, mainly due to its continuously-evolving semantic label
space, partial pixelwise ground-truth annotations, and constrained data
availability. To ad- dress this, we propose an incremental learning strategy
that can fast adapt deep segmentation models without catastrophic forgetting,
using a streaming input data with pixel annotations on the novel classes only.
To this end, we develop a uni ed learning strategy based on the
Expectation-Maximization (EM) framework, which integrates an iterative
relabeling strategy that lls in the missing labels and a rehearsal-based
incremental learning step that balances the stability-plasticity of the model.
Moreover, our EM algorithm adopts an adaptive sampling method to select
informative train- ing data and a class-balancing training strategy in the
incremental model updates, both improving the e cacy of model learning. We
validate our approach on the PASCAL VOC 2012 and ADE20K datasets, and the
results demonstrate its superior performance over the existing incremental
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Visual Design Principles in Art and Architecture through Deep Convolutional Neural Networks. (arXiv:2108.04048v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_G/0/1/0/all/0/1">Gozdenur Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Cekmis_A/0/1/0/all/0/1">Asli Cekmis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yesilkaynak_V/0/1/0/all/0/1">Vahit Bugra Yesilkaynak</a>, <a href="http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1">Gozde Unal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04048">
                                    <div class="article-summary-box-inner">
                                        <span>Visual design is associated with the use of some basic design elements and
principles. Those are applied by the designers in the various disciplines for
aesthetic purposes, relying on an intuitive and subjective process. Thus,
numerical analysis of design visuals and disclosure of the aesthetic value
embedded in them are considered as hard. However, it has become possible with
emerging artificial intelligence technologies. This research aims at a neural
network model, which recognizes and classifies the design principles over
different domains. The domains include artwork produced since the late 20th
century; professional photos; and facade pictures of contemporary buildings.
The data collection and curation processes, including the production of
computationally-based synthetic dataset, is genuine. The proposed model learns
from the knowledge of myriads of original designs, by capturing the underlying
shared patterns. It is expected to consolidate design processes by providing an
aesthetic evaluation of the visual compositions with objectivity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Latent Semantic Graph for Video Captioning. (arXiv:2108.03662v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junyan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1">Bingzhang Hul Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagnucco_M/0/1/0/all/0/1">Maurice Pagnucco</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yu Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03662">
                                    <div class="article-summary-box-inner">
                                        <span>Video captioning aims to automatically generate natural language sentences
that can describe the visual contents of a given video. Existing generative
models like encoder-decoder frameworks cannot explicitly explore the
object-level interactions and frame-level information from complex
spatio-temporal data to generate semantic-rich captions. Our main contribution
is to identify three key problems in a joint framework for future video
summarization tasks. 1) Enhanced Object Proposal: we propose a novel
Conditional Graph that can fuse spatio-temporal information into latent object
proposal. 2) Visual Knowledge: Latent Proposal Aggregation is proposed to
dynamically extract visual words with higher semantic levels. 3) Sentence
Validation: A novel Discriminative Language Validator is proposed to verify
generated captions so that key semantic concepts can be effectively preserved.
Our experiments on two public datasets (MVSD and MSR-VTT) manifest significant
improvements over state-of-the-art approaches on all metrics, especially for
BLEU-4 and CIDEr. Our code is available at
https://github.com/baiyang4/D-LSG-Video-Caption.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PSGR: Pixel-wise Sparse Graph Reasoning for COVID-19 Pneumonia Segmentation in CT Images. (arXiv:2108.03809v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Haozhe Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoteng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1">Guixiang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Liang Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yong Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03809">
                                    <div class="article-summary-box-inner">
                                        <span>Automated and accurate segmentation of the infected regions in computed
tomography (CT) images is critical for the prediction of the pathological stage
and treatment response of COVID-19. Several deep convolutional neural networks
(DCNNs) have been designed for this task, whose performance, however, tends to
be suppressed by their limited local receptive fields and insufficient global
reasoning ability. In this paper, we propose a pixel-wise sparse graph
reasoning (PSGR) module and insert it into a segmentation network to enhance
the modeling of long-range dependencies for COVID-19 infected region
segmentation in CT images. In the PSGR module, a graph is first constructed by
projecting each pixel on a node based on the features produced by the
segmentation backbone, and then converted into a sparsely-connected graph by
keeping only K strongest connections to each uncertain pixel. The long-range
information reasoning is performed on the sparsely-connected graph to generate
enhanced features. The advantages of this module are two-fold: (1) the
pixel-wise mapping strategy not only avoids imprecise pixel-to-node projections
but also preserves the inherent information of each pixel for global reasoning;
and (2) the sparsely-connected graph construction results in effective
information retrieval and reduction of the noise propagation. The proposed
solution has been evaluated against four widely-used segmentation models on
three public datasets. The results show that the segmentation model equipped
with our PSGR module can effectively segment COVID-19 infected regions in CT
images, outperforming all other competing models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Vessel Navigation Visually Aided by Autonomous Unmanned Aerial Vehicles in Congested Harbors and Waterways. (arXiv:2108.03862v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sejersen_J/0/1/0/all/0/1">Jonas le Fevre Sejersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Figueiredo_R/0/1/0/all/0/1">Rui Pimentel de Figueiredo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kayacan_E/0/1/0/all/0/1">Erdal Kayacan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03862">
                                    <div class="article-summary-box-inner">
                                        <span>In the maritime sector, safe vessel navigation is of great importance,
particularly in congested harbors and waterways. The focus of this work is to
estimate the distance between an object of interest and potential obstacles
using a companion UAV. The proposed approach fuses GPS data with long-range
aerial images. First, we employ semantic segmentation DNN for discriminating
the vessel of interest, water, and potential solid objects using raw image
data. The network is trained with both real and images generated and
automatically labeled from a realistic AirSim simulation environment. Then, the
distances between the extracted vessel and non-water obstacle blobs are
computed using a novel GSD estimation algorithm. To the best of our knowledge,
this work is the first attempt to detect and estimate distances to unknown
objects from long-range visual data captured with conventional RGB cameras and
auxiliary absolute positioning systems (e.g. GPS). The simulation results
illustrate the accuracy and efficacy of the proposed method for visually aided
navigation of vessels assisted by UAV.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting. (arXiv:2107.12619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse-to-dense Feature Matching: Intra and Inter domain Cross-modal Learning in Domain Adaptation for 3D Semantic Segmentation. (arXiv:2107.14724v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Duo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yinjie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14724">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation is critical for success when confronting with the lack of
annotations in a new domain. As the huge time consumption of labeling process
on 3D point cloud, domain adaptation for 3D semantic segmentation is of great
expectation. With the rise of multi-modal datasets, large amount of 2D images
are accessible besides 3D point clouds. In light of this, we propose to further
leverage 2D data for 3D domain adaptation by intra and inter domain cross modal
learning. As for intra-domain cross modal learning, most existing works sample
the dense 2D pixel-wise features into the same size with sparse 3D point-wise
features, resulting in the abandon of numerous useful 2D features. To address
this problem, we propose Dynamic sparse-to-dense Cross Modal Learning (DsCML)
to increase the sufficiency of multi-modality information interaction for
domain adaptation. For inter-domain cross modal learning, we further advance
Cross Modal Adversarial Learning (CMAL) on 2D and 3D data which contains
different semantic content aiming to promote high-level modal complementarity.
We evaluate our model under various multi-modality domain adaptation settings
including day-to-night, country-to-country and dataset-to-dataset, brings large
improvements over both uni-modal and multi-modal domain adaptation methods on
all settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SVMAC: Unsupervised 3D Human Pose Estimation from a Single Image with Single-view-multi-angle Consistenty. (arXiv:2106.05616v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Cheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05616">
                                    <div class="article-summary-box-inner">
                                        <span>Recovering 3D human pose from 2D joints is still a challenging problem,
especially without any 3D annotation, video information, or multi-view
information. In this paper, we present an unsupervised GAN-based model
consisting of multiple weight-sharing generators to estimate a 3D human pose
from a single image without 3D annotations. In our model, we introduce
single-view-multi-angle consistency (SVMAC) to significantly improve the
estimation performance. With 2D joint locations as input, our model estimates a
3D pose and a camera simultaneously. During training, the estimated 3D pose is
rotated by random angles and the estimated camera projects the rotated 3D poses
back to 2D. The 2D reprojections will be fed into weight-sharing generators to
estimate the corresponding 3D poses and cameras, which are then mixed to impose
SVMAC constraints to self-supervise the training process. The experimental
results show that our method outperforms the state-of-the-art unsupervised
methods by 2.6% on Human 3.6M and 15.0% on MPI-INF-3DHP. Moreover, qualitative
results on MPII and LSP show that our method can generalize well to unknown
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MPI: Multi-receptive and Parallel Integration for Salient Object Detection. (arXiv:2108.03618v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Han Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cen_J/0/1/0/all/0/1">Jun Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ningzhong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Dong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03618">
                                    <div class="article-summary-box-inner">
                                        <span>The semantic representation of deep features is essential for image context
understanding, and effective fusion of features with different semantic
representations can significantly improve the model&#x27;s performance on salient
object detection. In this paper, a novel method called MPI is proposed for
salient object detection. Firstly, a multi-receptive enhancement module (MRE)
is designed to effectively expand the receptive fields of features from
different layers and generate features with different receptive fields. MRE can
enhance the semantic representation and improve the model&#x27;s perception of the
image context, which enables the model to locate the salient object accurately.
Secondly, in order to reduce the reuse of redundant information in the complex
top-down fusion method and weaken the differences between semantic features, a
relatively simple but effective parallel fusion strategy (PFS) is proposed. It
allows multi-scale features to better interact with each other, thus improving
the overall performance of the model. Experimental results on multiple datasets
demonstrate that the proposed method outperforms state-of-the-art methods under
different evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AA-RMVSNet: Adaptive Aggregation Recurrent Multi-view Stereo Network. (arXiv:2108.03824v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zizhuang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qingtian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_C/0/1/0/all/0/1">Chen Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yisong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03824">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel recurrent multi-view stereo network based
on long short-term memory (LSTM) with adaptive aggregation, namely AA-RMVSNet.
We firstly introduce an intra-view aggregation module to adaptively extract
image features by using context-aware convolution and multi-scale aggregation,
which efficiently improves the performance on challenging regions, such as thin
objects and large low-textured surfaces. To overcome the difficulty of varying
occlusion in complex scenes, we propose an inter-view cost volume aggregation
module for adaptive pixel-wise view aggregation, which is able to preserve
better-matched pairs among all views. The two proposed adaptive aggregation
modules are lightweight, effective and complementary regarding improving the
accuracy and completeness of 3D reconstruction. Instead of conventional 3D
CNNs, we utilize a hybrid network with recurrent structure for cost volume
regularization, which allows high-resolution reconstruction and finer
hypothetical plane sweep. The proposed network is trained end-to-end and
achieves excellent performance on various datasets. It ranks $1^{st}$ among all
submissions on Tanks and Temples benchmark and achieves competitive results on
DTU dataset, which exhibits strong generalizability and robustness.
Implementation of our method is available at
https://github.com/QT-Zhu/AA-RMVSNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection in Residential Video Surveillance on Edge Devices in IoT Framework. (arXiv:2107.04767v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur R. Parate</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhurchandi_K/0/1/0/all/0/1">Kishor M. Bhurchandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1">Ashwin G. Kothari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04767">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent resident surveillance is one of the most essential smart
community services. The increasing demand for security needs surveillance
systems to be able to detect anomalies in surveillance scenes. Employing
high-capacity computational devices for intelligent surveillance in residential
societies is costly and not feasible. Therefore, we propose anomaly detection
for intelligent surveillance using CPU-only edge devices. A modular framework
to capture object-level inferences and tracking is developed. To cope with
partial occlusions, posture deformations, and complex scenes, we employed
feature encoding and trajectory association governed by two metrices
complementing to each other. The elements of an anomaly detection framework are
optimized to run on CPU-only edge devices with sufficient frames per second
(FPS). The experimental results indicate the proposed method is feasible and
achieves satisfactory results in real-life scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RECALL: Replay-based Continual Learning in Semantic Segmentation. (arXiv:2108.03673v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maracani_A/0/1/0/all/0/1">Andrea Maracani</a>, <a href="http://arxiv.org/find/cs/1/au:+Michieli_U/0/1/0/all/0/1">Umberto Michieli</a>, <a href="http://arxiv.org/find/cs/1/au:+Toldo_M/0/1/0/all/0/1">Marco Toldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanuttigh_P/0/1/0/all/0/1">Pietro Zanuttigh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03673">
                                    <div class="article-summary-box-inner">
                                        <span>Deep networks allow to obtain outstanding results in semantic segmentation,
however they need to be trained in a single shot with a large amount of data.
Continual learning settings where new classes are learned in incremental steps
and previous training data is no longer available are challenging due to the
catastrophic forgetting phenomenon. Existing approaches typically fail when
several incremental steps are performed or in presence of a distribution shift
of the background class. We tackle these issues by recreating no longer
available data for the old classes and outlining a content inpainting scheme on
the background class. We propose two sources for replay data. The first resorts
to a generative adversarial network to sample from the class space of past
learning steps. The second relies on web-crawled data to retrieve images
containing examples of old classes from online databases. In both scenarios no
samples of past steps are stored, thus avoiding privacy concerns. Replay data
are then blended with new samples during the incremental steps. Our approach,
RECALL, outperforms state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Representation Learning for Rapid Intraoperative Diagnosis of Skull Base Tumors Imaged Using Stimulated Raman Histology. (arXiv:2108.03555v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Abhishek Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzey_J/0/1/0/all/0/1">Joseph Linzey</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rushikesh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sung Jik Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Sudharsan Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alber_D/0/1/0/all/0/1">Daniel Alber</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondepudi_A/0/1/0/all/0/1">Akhil Kondepudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Urias_E/0/1/0/all/0/1">Esteban Urias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandian_B/0/1/0/all/0/1">Balaji Pandian</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Holou_W/0/1/0/all/0/1">Wajd Al-Holou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_S/0/1/0/all/0/1">Steve Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1">B. Gregory Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Heth_J/0/1/0/all/0/1">Jason Heth</a>, <a href="http://arxiv.org/find/cs/1/au:+Freudiger_C/0/1/0/all/0/1">Chris Freudiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalsa_S/0/1/0/all/0/1">Siri Khalsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacione_D/0/1/0/all/0/1">Donato Pacione</a>, <a href="http://arxiv.org/find/cs/1/au:+Golfinos_J/0/1/0/all/0/1">John G. Golfinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Camelo_Piragua_S/0/1/0/all/0/1">Sandra Camelo-Piragua</a>, <a href="http://arxiv.org/find/cs/1/au:+Orringer_D/0/1/0/all/0/1">Daniel A. Orringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hollon_T/0/1/0/all/0/1">Todd Hollon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03555">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Accurate diagnosis of skull base tumors is essential for
providing personalized surgical treatment strategies. Intraoperative diagnosis
can be challenging due to tumor diversity and lack of intraoperative pathology
resources.

Objective: To develop an independent and parallel intraoperative pathology
workflow that can provide rapid and accurate skull base tumor diagnoses using
label-free optical imaging and artificial intelligence (AI).

Method: We used a fiber laser-based, label-free, non-consumptive,
high-resolution microscopy method ($&lt;$ 60 sec per 1 $\times$ 1 mm$^\text{2}$),
called stimulated Raman histology (SRH), to image a consecutive, multicenter
cohort of skull base tumor patients. SRH images were then used to train a
convolutional neural network (CNN) model using three representation learning
strategies: cross-entropy, self-supervised contrastive learning, and supervised
contrastive learning. Our trained CNN models were tested on a held-out,
multicenter SRH dataset.

Results: SRH was able to image the diagnostic features of both benign and
malignant skull base tumors. Of the three representation learning strategies,
supervised contrastive learning most effectively learned the distinctive and
diagnostic SRH image features for each of the skull base tumor types. In our
multicenter testing set, cross-entropy achieved an overall diagnostic accuracy
of 91.5%, self-supervised contrastive learning 83.9%, and supervised
contrastive learning 96.6%. Our trained model was able to identify tumor-normal
margins and detect regions of microscopic tumor infiltration in whole-slide SRH
images.

Conclusion: SRH with AI models trained using contrastive representation
learning can provide rapid and accurate intraoperative diagnosis of skull base
tumors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Foveated Reconstruction to Preserve Perceived Image Statistics. (arXiv:2108.03499v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Surace_L/0/1/0/all/0/1">Luca Surace</a> (Universit&#xe0; della Svizzera italiana), <a href="http://arxiv.org/find/cs/1/au:+Wernikowski_M/0/1/0/all/0/1">Marek Wernikowski</a> (West Pomeranian University of Technology), <a href="http://arxiv.org/find/cs/1/au:+Tursun_O/0/1/0/all/0/1">Okan Tursun</a> (Universit&#xe0; della Svizzera italiana), <a href="http://arxiv.org/find/cs/1/au:+Myszkowski_K/0/1/0/all/0/1">Karol Myszkowski</a> (Max Planck Institute for Informatics), <a href="http://arxiv.org/find/cs/1/au:+Mantiuk_R/0/1/0/all/0/1">Rados&#x142;aw Mantiuk</a> (West Pomeranian University of Technology), <a href="http://arxiv.org/find/cs/1/au:+Didyk_P/0/1/0/all/0/1">Piotr Didyk</a> (Universit&#xe0; della Svizzera italiana)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03499">
                                    <div class="article-summary-box-inner">
                                        <span>Foveated image reconstruction recovers full image from a sparse set of
samples distributed according to the human visual system&#x27;s retinal sensitivity
that rapidly drops with eccentricity. Recently, the use of Generative
Adversarial Networks was shown to be a promising solution for such a task as
they can successfully hallucinate missing image information. Like for other
supervised learning approaches, also for this one, the definition of the loss
function and training strategy heavily influences the output quality. In this
work, we pose the question of how to efficiently guide the training of foveated
reconstruction techniques such that they are fully aware of the human visual
system&#x27;s capabilities and limitations, and therefore, reconstruct visually
important image features. Due to the nature of GAN-based solutions, we
concentrate on the human&#x27;s sensitivity to hallucination for different input
sample densities. We present new psychophysical experiments, a dataset, and a
procedure for training foveated image reconstruction. The strategy provides
flexibility to the generator network by penalizing only perceptually important
deviations in the output. As a result, the method aims to preserve perceived
image statistics rather than natural image statistics. We evaluate our strategy
and compare it to alternative solutions using a newly trained objective metric
and user experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Deepfake Detection. (arXiv:2106.10705v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yuewei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhen_L/0/1/0/all/0/1">Liangli Zhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_R/0/1/0/all/0/1">Rick Siow Mong Goh</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10705">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose to utilize Automated Machine Learning to adaptively
search a neural architecture for deepfake detection. This is the first time to
employ automated machine learning for deepfake detection. Based on our explored
search space, our proposed method achieves competitive prediction accuracy
compared to previous methods. To improve the generalizability of our method,
especially when training data and testing data are manipulated by different
methods, we propose a simple yet effective strategy in our network learning
process: making it to estimate potential manipulation regions besides
predicting the real/fake labels. Unlike previous works manually design neural
networks, our method can relieve us from the high labor cost in network
construction. More than that, compared to previous works, our method depends
much less on prior knowledge, e.g., which manipulation method is utilized or
where exactly the fake image is manipulated. Extensive experimental results on
two benchmark datasets demonstrate the effectiveness of our proposed method for
deepfake detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Regularity Measures for Sample-wise Learning and Generalization. (arXiv:2108.03913v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaoning Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yuanqi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuehu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03913">
                                    <div class="article-summary-box-inner">
                                        <span>Fundamental machine learning theory shows that different samples contribute
unequally both in learning and testing processes. Contemporary studies on DNN
imply that such sample di?erence is rooted on the distribution of intrinsic
pattern information, namely sample regularity. Motivated by the recent
discovery on network memorization and generalization, we proposed a pair of
sample regularity measures for both processes with a formulation-consistent
representation. Specifically, cumulative binary training/generalizing loss
(CBTL/CBGL), the cumulative number of correct classi?cations of the
training/testing sample within training stage, is proposed to quantize the
stability in memorization-generalization process; while
forgetting/mal-generalizing events, i.e., the mis-classification of previously
learned or generalized sample, are utilized to represent the uncertainty of
sample regularity with respect to optimization dynamics. Experiments validated
the effectiveness and robustness of the proposed approaches for mini-batch SGD
optimization. Further applications on training/testing sample selection show
the proposed measures sharing the uni?ed computing procedure could benefit for
both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image reconstruction in light-sheet microscopy: spatially varying deconvolution and mixed noise. (arXiv:2108.03642v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Toader_B/0/1/0/all/0/1">Bogdan Toader</a>, <a href="http://arxiv.org/find/math/1/au:+Boulanger_J/0/1/0/all/0/1">Jerome Boulanger</a>, <a href="http://arxiv.org/find/math/1/au:+Korolev_Y/0/1/0/all/0/1">Yury Korolev</a>, <a href="http://arxiv.org/find/math/1/au:+Lenz_M/0/1/0/all/0/1">Martin O. Lenz</a>, <a href="http://arxiv.org/find/math/1/au:+Manton_J/0/1/0/all/0/1">James Manton</a>, <a href="http://arxiv.org/find/math/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Schonlieb</a>, <a href="http://arxiv.org/find/math/1/au:+Muresan_L/0/1/0/all/0/1">Leila Muresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03642">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of deconvolution for light-sheet microscopy, where the
data is corrupted by spatially varying blur and a combination of Poisson and
Gaussian noise. The spatial variation of the point spread function (PSF) of a
light-sheet microscope is determined by the interaction between the excitation
sheet and the detection objective PSF. First, we introduce a model of the image
formation process that incorporates this interaction, therefore capturing the
main characteristics of this imaging modality. Then, we formulate a variational
model that accounts for the combination of Poisson and Gaussian noise through a
data fidelity term consisting of the infimal convolution of the single noise
fidelities, first introduced in L. Calatroni et al. &quot;Infimal convolution of
data discrepancies for mixed noise removal&quot;, SIAM Journal on Imaging Sciences
10.3 (2017), 1196-1233. We establish convergence rates in a Bregman distance
under a source condition for the infimal convolution fidelity and a discrepancy
principle for choosing the value of the regularisation parameter. The inverse
problem is solved by applying the primal-dual hybrid gradient (PDHG) algorithm
in a novel way. Finally, numerical experiments performed on both simulated and
real data show superior reconstruction results in comparison with other
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DistillPose: Lightweight Camera Localization Using Auxiliary Learning. (arXiv:2108.03819v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abouelnaga_Y/0/1/0/all/0/1">Yehya Abouelnaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1">Mai Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilic_S/0/1/0/all/0/1">Slobodan Ilic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03819">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a lightweight retrieval-based pipeline to predict 6DOF camera
poses from RGB images. Our pipeline uses a convolutional neural network (CNN)
to encode a query image as a feature vector. A nearest neighbor lookup finds
the pose-wise nearest database image. A siamese convolutional neural network
regresses the relative pose from the nearest neighboring database image to the
query image. The relative pose is then applied to the nearest neighboring
absolute pose to obtain the query image&#x27;s final absolute pose prediction. Our
model is a distilled version of NN-Net that reduces its parameters by 98.87%,
information retrieval feature vector size by 87.5%, and inference time by
89.18% without a significant decrease in localization accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EigenGAN: Layer-Wise Eigen-Learning for GANs. (arXiv:2104.12476v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1">Meina Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12476">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies on Generative Adversarial Network (GAN) reveal that different
layers of a generative CNN hold different semantics of the synthesized images.
However, few GAN models have explicit dimensions to control the semantic
attributes represented in a specific layer. This paper proposes EigenGAN which
is able to unsupervisedly mine interpretable and controllable dimensions from
different generator layers. Specifically, EigenGAN embeds one linear subspace
with orthogonal basis into each generator layer. Via generative adversarial
training to learn a target distribution, these layer-wise subspaces
automatically discover a set of &quot;eigen-dimensions&quot; at each layer corresponding
to a set of semantic attributes or interpretable variations. By traversing the
coefficient of a specific eigen-dimension, the generator can produce samples
with continuous changes corresponding to a specific semantic attribute. Taking
the human face for example, EigenGAN can discover controllable dimensions for
high-level concepts such as pose and gender in the subspace of deep layers, as
well as low-level concepts such as hue and color in the subspace of shallow
layers. Moreover, in the linear case, we theoretically prove that our algorithm
derives the principal components as PCA does. Codes can be found in
https://github.com/LynnHo/EigenGAN-Tensorflow.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boundary-aware Graph Reasoning for Semantic Segmentation. (arXiv:2108.03791v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haoteng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Haozhe Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1">Liang Zhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03791">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a Boundary-aware Graph Reasoning (BGR) module to
learn long-range contextual features for semantic segmentation. Rather than
directly construct the graph based on the backbone features, our BGR module
explores a reasonable way to combine segmentation erroneous regions with the
graph construction scenario. Motivated by the fact that most hard-to-segment
pixels broadly distribute on boundary regions, our BGR module uses the boundary
score map as prior knowledge to intensify the graph node connections and
thereby guide the graph reasoning focus on boundary regions. In addition, we
employ an efficient graph convolution implementation to reduce the
computational cost, which benefits the integration of our BGR module into
current segmentation backbones. Extensive experiments on three challenging
segmentation benchmarks demonstrate the effectiveness of our proposed BGR
module for semantic segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Saliency-Associated Object Tracking. (arXiv:2108.03637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zikun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_W/0/1/0/all/0/1">Wenjie Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongpeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhenyu He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03637">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing trackers based on deep learning perform tracking in a holistic
strategy, which aims to learn deep representations of the whole target for
localizing the target. It is arduous for such methods to track targets with
various appearance variations. To address this limitation, another type of
methods adopts a part-based tracking strategy which divides the target into
equal patches and tracks all these patches in parallel. The target state is
inferred by summarizing the tracking results of these patches. A potential
limitation of such trackers is that not all patches are equally informative for
tracking. Some patches that are not discriminative may have adverse effects. In
this paper, we propose to track the salient local parts of the target that are
discriminative for tracking. In particular, we propose a fine-grained saliency
mining module to capture the local saliencies. Further, we design a
saliency-association modeling module to associate the captured saliencies
together to learn effective correlation representations between the exemplar
and the search image for state estimation. Extensive experiments on five
diverse datasets demonstrate that the proposed method performs favorably
against state-of-the-art trackers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning an Augmented RGB Representation with Cross-Modal Knowledge Distillation for Action Detection. (arXiv:2108.03619v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1">Rui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srijan Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Bremond_F/0/1/0/all/0/1">Francois Bremond</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03619">
                                    <div class="article-summary-box-inner">
                                        <span>In video understanding, most cross-modal knowledge distillation (KD) methods
are tailored for classification tasks, focusing on the discriminative
representation of the trimmed videos. However, action detection requires not
only categorizing actions, but also localizing them in untrimmed videos.
Therefore, transferring knowledge pertaining to temporal relations is critical
for this task which is missing in the previous cross-modal KD frameworks. To
this end, we aim at learning an augmented RGB representation for action
detection, taking advantage of additional modalities at training time through
KD. We propose a KD framework consisting of two levels of distillation. On one
hand, atomic-level distillation encourages the RGB student to learn the
sub-representation of the actions from the teacher in a contrastive manner. On
the other hand, sequence-level distillation encourages the student to learn the
temporal knowledge from the teacher, which consists of transferring the Global
Contextual Relations and the Action Boundary Saliency. The result is an
Augmented-RGB stream that can achieve competitive performance as the two-stream
network while using only RGB at inference time. Extensive experimental analysis
shows that our proposed distillation framework is generic and outperforms other
popular cross-modal distillation methods in action detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projection Matching. (arXiv:2108.03746v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chao_C/0/1/0/all/0/1">Chen Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Shen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zwicker_M/0/1/0/all/0/1">Matthias Zwicker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03746">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to generate 3D point clouds without 3D supervision is an important
but challenging problem. Current solutions leverage various differentiable
renderers to project the generated 3D point clouds onto a 2D image plane, and
train deep neural networks using the per-pixel difference with 2D ground truth
images. However, these solutions are still struggling to fully recover fine
structures of 3D shapes, such as thin tubes or planes. To resolve this issue,
we propose an unsupervised approach for 3D point cloud generation with fine
structures. Specifically, we cast 3D point cloud learning as a 2D projection
matching problem. Rather than using entire 2D silhouette images as a regular
pixel supervision, we introduce structure adaptive sampling to randomly sample
2D points within the silhouettes as an irregular point supervision, which
alleviates the consistency issue of sampling from different view angles. Our
method pushes the neural network to generate a 3D point cloud whose 2D
projections match the irregular point supervision from different view angles.
Our 2D projection matching approach enables the neural network to learn more
accurate structure information than using the per-pixel difference, especially
for fine and thin 3D structures. Our method can recover fine 3D structures from
2D silhouette images at different resolutions, and is robust to different
sampling methods and point number in irregular point supervision. Our method
outperforms others under widely used benchmarks. Our code, data and models are
available at https://github.com/chenchao15/2D\_projection\_matching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Net: A novel light weight framework for COVID-19 Diagnosis. (arXiv:2108.03786v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gammulle_H/0/1/0/all/0/1">Harshala Gammulle</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1">Tharindu Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03786">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel lightweight COVID-19 diagnosis framework using CT
scans. Our system utilises a novel two-stage approach to generate robust and
efficient diagnoses across heterogeneous patient level inputs. We use a
powerful backbone network as a feature extractor to capture discriminative
slice-level features. These features are aggregated by a lightweight network to
obtain a patient level diagnosis. The aggregation network is carefully designed
to have a small number of trainable parameters while also possessing sufficient
capacity to generalise to diverse variations within different CT volumes and to
adapt to noise introduced during the data acquisition. We achieve a significant
performance increase over the baselines when benchmarked on the SPGC COVID-19
Radiomics Dataset, despite having only 2.5 million trainable parameters and
requiring only 0.623 seconds on average to process a single patient&#x27;s CT volume
using an Nvidia-GeForce RTX 2080 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Selective Light Field Refocusing for Camera Arrays Using Bokeh Rendering and Superresolution. (arXiv:2108.03918v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jungang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1">Wei An</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03918">
                                    <div class="article-summary-box-inner">
                                        <span>Camera arrays provide spatial and angular information within a single
snapshot. With refocusing methods, focal planes can be altered after exposure.
In this letter, we propose a light field refocusing method to improve the
imaging quality of camera arrays. In our method, the disparity is first
estimated. Then, the unfocused region (bokeh) is rendered by using a
depth-based anisotropic filter. Finally, the refocused image is produced by a
reconstruction-based superresolution approach where the bokeh image is used as
a regularization term. Our method can selectively refocus images with focused
region being superresolved and bokeh being aesthetically rendered. Our method
also enables postadjustment of depth of field. We conduct experiments on both
public and self-developed datasets. Our method achieves superior visual
performance with acceptable computational cost as compared to other
state-of-the-art methods. Code is available at
https://github.com/YingqianWang/Selective-LF-Refocusing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alignment of Tractography Streamlines using Deformation Transfer via Parallel Transport. (arXiv:2108.03697v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lizarraga_A/0/1/0/all/0/1">Andrew Lizarraga</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">David Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubicki_A/0/1/0/all/0/1">Antoni Kubicki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahib_A/0/1/0/all/0/1">Ashish Sahib</a>, <a href="http://arxiv.org/find/cs/1/au:+Nunez_E/0/1/0/all/0/1">Elvis Nunez</a>, <a href="http://arxiv.org/find/cs/1/au:+Narr_K/0/1/0/all/0/1">Katherine Narr</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Shantanu H. Joshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03697">
                                    <div class="article-summary-box-inner">
                                        <span>We present a geometric framework for aligning white matter fiber tracts. By
registering fiber tracts between brains, one expects to see overlap of
anatomical structures that often provide meaningful comparisons across
subjects. However, the geometry of white matter tracts is highly heterogeneous,
and finding direct tract-correspondence across multiple individuals remains a
challenging problem. We present a novel deformation metric between tracts that
allows one to compare tracts while simultaneously obtaining a registration. To
accomplish this, fiber tracts are represented by an intrinsic mean along with
the deformation fields represented by tangent vectors from the mean. In this
setting, one can determine a parallel transport between tracts and then
register corresponding tangent vectors. We present the results of bundle
alignment on a population of 43 healthy adult subjects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rain Removal and Illumination Enhancement Done in One Go. (arXiv:2108.03873v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1">Yecong Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yuanshuo Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_M/0/1/0/all/0/1">Mingwen Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03873">
                                    <div class="article-summary-box-inner">
                                        <span>Rain removal plays an important role in the restoration of degraded images.
Recently, data-driven methods have achieved remarkable success. However, these
approaches neglect that the appearance of rain is often accompanied by low
light conditions, which will further degrade the image quality. Therefore, it
is very indispensable to jointly remove the rain and enhance the light for
real-world rain image restoration. In this paper, we aim to address this
problem from two aspects. First, we proposed a novel entangled network, namely
EMNet, which can remove the rain and enhance illumination in one go.
Specifically, two encoder-decoder networks interact complementary information
through entanglement structure, and parallel rain removal and illumination
enhancement. Considering that the encoder-decoder structure is unreliable in
preserving spatial details, we employ a detail recovery network to restore the
desired fine texture. Second, we present a new synthetic dataset, namely
DarkRain, to boost the development of rain image restoration algorithms in
practical scenarios. DarkRain not only contains different degrees of rain, but
also considers different lighting conditions, and more realistically simulates
the rainfall in the real world. EMNet is extensively evaluated on the proposed
benchmark and achieves state-of-the-art results. In addition, after a simple
transformation, our method outshines existing methods in both rain removal and
low-light image enhancement. The source code and dataset will be made publicly
available later.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Skeleton-Contrastive 3D Action Representation Learning. (arXiv:2108.03656v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thoker_F/0/1/0/all/0/1">Fida Mohammad Thoker</a>, <a href="http://arxiv.org/find/cs/1/au:+Doughty_H/0/1/0/all/0/1">Hazel Doughty</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G.M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03656">
                                    <div class="article-summary-box-inner">
                                        <span>This paper strives for self-supervised learning of a feature space suitable
for skeleton-based action recognition. Our proposal is built upon learning
invariances to input skeleton representations and various skeleton
augmentations via a noise contrastive estimation. In particular, we propose
inter-skeleton contrastive learning, which learns from multiple different input
skeleton representations in a cross-contrastive manner. In addition, we
contribute several skeleton-specific spatial and temporal augmentations which
further encourage the model to learn the spatio-temporal dynamics of skeleton
data. By learning similarities between different skeleton representations as
well as augmented views of the same sequence, the network is encouraged to
learn higher-level semantics of the skeleton data than when only using the
augmented views. Our approach achieves state-of-the-art performance for
self-supervised learning from skeleton data on the challenging PKU and NTU
datasets with multiple downstream tasks, including action recognition, action
retrieval and semi-supervised learning. Code is available at
https://github.com/fmthoker/skeleton-contrast.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis. (arXiv:2108.03880v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03880">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-View Stereo (MVS) is a core task in 3D computer vision. With the surge
of novel deep learning methods, learned MVS has surpassed the accuracy of
classical approaches, but still relies on building a memory intensive dense
cost volume. Novel View Synthesis (NVS) is a parallel line of research and has
recently seen an increase in popularity with Neural Radiance Field (NeRF)
models, which optimize a per scene radiance field. However, NeRF methods do not
generalize to novel scenes and are slow to train and test. We propose to bridge
the gap between these two methodologies with a novel network that can recover
3D scene geometry as a distance function, together with high-resolution color
images. Our method uses only a sparse set of images as input and can generalize
well to novel scenes. Additionally, we propose a coarse-to-fine sphere tracing
approach in order to significantly increase speed. We show on various datasets
that our method reaches comparable accuracy to per-scene optimized methods
while being able to generalize and running significantly faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly-Supervised Spatio-Temporal Anomaly Detection in Surveillance Video. (arXiv:2108.03825v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jie Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03825">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a novel task, referred to as Weakly-Supervised
Spatio-Temporal Anomaly Detection (WSSTAD) in surveillance video. Specifically,
given an untrimmed video, WSSTAD aims to localize a spatio-temporal tube (i.e.,
a sequence of bounding boxes at consecutive times) that encloses the abnormal
event, with only coarse video-level annotations as supervision during training.
To address this challenging task, we propose a dual-branch network which takes
as input the proposals with multi-granularities in both spatial-temporal
domains. Each branch employs a relationship reasoning module to capture the
correlation between tubes/videolets, which can provide rich contextual
information and complex entity relationships for the concept learning of
abnormal behaviors. Mutually-guided Progressive Refinement framework is set up
to employ dual-path mutual guidance in a recurrent manner, iteratively sharing
auxiliary supervision information across branches. It impels the learned
concepts of each branch to serve as a guide for its counterpart, which
progressively refines the corresponding branch and the whole framework.
Furthermore, we contribute two datasets, i.e., ST-UCF-Crime and STRA,
consisting of videos containing spatio-temporal abnormal annotations to serve
as the benchmarks for WSSTAD. We conduct extensive qualitative and quantitative
evaluations to demonstrate the effectiveness of the proposed approach and
analyze the key factors that contribute more to handle this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AMDet: A Tool for Mitotic Cell Detection in Histopathology Slides. (arXiv:2108.03676v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Williams_W/0/1/0/all/0/1">Walt Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_J/0/1/0/all/0/1">Jimmy Hall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03676">
                                    <div class="article-summary-box-inner">
                                        <span>Breast Cancer is the most prevalent cancer in the world. The World Health
Organization reports that the disease still affects a significant portion of
the developing world citing increased mortality rates in the majority of low to
middle income countries. The most popular protocol pathologists use for
diagnosing breast cancer is the Nottingham grading system which grades the
proliferation of tumors based on 3 major criteria, the most important of them
being mitotic cell count. The way in which pathologists evaluate mitotic cell
count is to subjectively and qualitatively analyze cells present in stained
slides of tissue and make a decision on its mitotic state i.e. is it mitotic or
not?This process is extremely inefficient and tiring for pathologists and so an
efficient, accurate, and fully automated tool to aid with the diagnosis is
extremely desirable. Fortunately, creating such a tool is made significantly
easier with the AutoML tool available from Microsoft Azure, however to the best
of our knowledge the AutoML tool has never been formally evaluated for use in
mitotic cell detection in histopathology images. This paper serves as an
evaluation of the AutoML tool for this purpose and will provide a first look on
how the tool handles this challenging problem. All code is available
athttps://github.com/WaltAFWilliams/AMDet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained Nonnegative Matrix Factorization for Blind Hyperspectral Unmixing incorporating Endmember Independence. (arXiv:2003.01041v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ekanayake_E/0/1/0/all/0/1">E.M.M.B. Ekanayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Weerasooriya_H/0/1/0/all/0/1">H.M.H.K. Weerasooriya</a>, <a href="http://arxiv.org/find/eess/1/au:+Ranasinghe_D/0/1/0/all/0/1">D.Y.L. Ranasinghe</a>, <a href="http://arxiv.org/find/eess/1/au:+Herath_S/0/1/0/all/0/1">S. Herath</a>, <a href="http://arxiv.org/find/eess/1/au:+Rathnayake_B/0/1/0/all/0/1">B. Rathnayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Godaliyadda_G/0/1/0/all/0/1">G.M.R.I. Godaliyadda</a>, <a href="http://arxiv.org/find/eess/1/au:+Ekanayake_M/0/1/0/all/0/1">M.P.B. Ekanayake</a>, <a href="http://arxiv.org/find/eess/1/au:+Herath_H/0/1/0/all/0/1">H.M.V.R. Herath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.01041">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral unmixing (HU) has become an important technique in exploiting
hyperspectral data since it decomposes a mixed pixel into a collection of
endmembers weighted by fractional abundances. The endmembers of a hyperspectral
image (HSI) are more likely to be generated by independent sources and be mixed
in a macroscopic degree before arriving at the sensor element of the imaging
spectrometer as mixed spectra. Over the past few decades, many attempts have
focused on imposing auxiliary constraints on the conventional nonnegative
matrix factorization (NMF) framework in order to effectively unmix these mixed
spectra. As a promising step toward finding an optimum constraint to extract
endmembers, this paper presents a novel blind HU algorithm, referred to as
Kurtosis-based Smooth Nonnegative Matrix Factorization (KbSNMF) which
incorporates a novel constraint based on the statistical independence of the
probability density functions of endmember spectra. Imposing this constraint on
the conventional NMF framework promotes the extraction of independent
endmembers while further enhancing the parts-based representation of data.
Experiments conducted on diverse synthetic HSI datasets (with numerous numbers
of endmembers, spectral bands, pixels, and noise levels) and three standard
real HSI datasets demonstrate the validity of the proposed KbSNMF algorithm
compared to several state-of-the-art NMF-based HU baselines. The proposed
algorithm exhibits superior performance especially in terms of extracting
endmember spectra from hyperspectral data; therefore, it could uplift the
performance of recent deep learning HU methods which utilize the endmember
spectra as supervisory input data for abundance extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bifold and Semantic Reasoning for Pedestrian Behavior Prediction. (arXiv:2012.03298v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rasouli_A/0/1/0/all/0/1">Amir Rasouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohani_M/0/1/0/all/0/1">Mohsen Rohani</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03298">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian behavior prediction is one of the major challenges for intelligent
driving systems. Pedestrians often exhibit complex behaviors influenced by
various contextual elements. To address this problem, we propose BiPed, a
multitask learning framework that simultaneously predicts trajectories and
actions of pedestrians by relying on multimodal data. Our method benefits from
1) a bifold encoding approach where different data modalities are processed
independently allowing them to develop their own representations, and jointly
to produce a representation for all modalities using shared parameters; 2) a
novel interaction modeling technique that relies on categorical semantic
parsing of the scenes to capture interactions between target pedestrians and
their surroundings; and 3) a bifold prediction mechanism that uses both
independent and shared decoding of multimodal representations. Using public
pedestrian behavior benchmark datasets for driving, PIE and JAAD, we highlight
the benefits of the proposed method for behavior prediction and show that our
model achieves state-of-the-art performance and improves trajectory and action
prediction by up to 22% and 9% respectively. We further investigate the
contributions of the proposed reasoning techniques via extensive ablation
studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FA-GAN: Fused Attentive Generative Adversarial Networks for MRI Image Super-Resolution. (arXiv:2108.03920v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Mingfeng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_M/0/1/0/all/0/1">Minghao Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Liying Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaocheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jucheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yongming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03920">
                                    <div class="article-summary-box-inner">
                                        <span>High-resolution magnetic resonance images can provide fine-grained anatomical
information, but acquiring such data requires a long scanning time. In this
paper, a framework called the Fused Attentive Generative Adversarial
Networks(FA-GAN) is proposed to generate the super-resolution MR image from
low-resolution magnetic resonance images, which can reduce the scanning time
effectively but with high resolution MR images. In the framework of the FA-GAN,
the local fusion feature block, consisting of different three-pass networks by
using different convolution kernels, is proposed to extract image features at
different scales. And the global feature fusion module, including the channel
attention module, the self-attention module, and the fusion operation, is
designed to enhance the important features of the MR image. Moreover, the
spectral normalization process is introduced to make the discriminator network
stable. 40 sets of 3D magnetic resonance images (each set of images contains
256 slices) are used to train the network, and 10 sets of images are used to
test the proposed method. The experimental results show that the PSNR and SSIM
values of the super-resolution magnetic resonance image generated by the
proposed FA-GAN method are higher than the state-of-the-art reconstruction
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DisCo: Remedy Self-supervised Learning on Lightweight Models with Distilled Contrastive Learning. (arXiv:2104.09124v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuting Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jia-Xin Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaowei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xing Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09124">
                                    <div class="article-summary-box-inner">
                                        <span>While self-supervised representation learning (SSL) has received widespread
attention from the community, recent research argue that its performance will
suffer a cliff fall when the model size decreases. The current method mainly
relies on contrastive learning to train the network and in this work, we
propose a simple yet effective Distilled Contrastive Learning (DisCo) to ease
the issue by a large margin. Specifically, we find the final embedding obtained
by the mainstream SSL methods contains the most fruitful information, and
propose to distill the final embedding to maximally transmit a teacher&#x27;s
knowledge to a lightweight model by constraining the last embedding of the
student to be consistent with that of the teacher. In addition, in the
experiment, we find that there exists a phenomenon termed Distilling BottleNeck
and present to enlarge the embedding dimension to alleviate this problem. Our
method does not introduce any extra parameter to lightweight models during
deployment. Experimental results demonstrate that our method achieves the
state-of-the-art on all lightweight models. Particularly, when
ResNet-101/ResNet-50 is used as teacher to teach EfficientNet-B0, the linear
result of EfficientNet-B0 on ImageNet is very close to ResNet-101/ResNet-50,
but the number of parameters of EfficientNet-B0 is only 9.4\%/16.3\% of
ResNet-101/ResNet-50. Code is available at https://github.
com/Yuting-Gao/DisCo-pytorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Latent Classes for Few-shot Segmentation. (arXiv:2103.15402v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lihe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1">Wei Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yinghuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15402">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot segmentation (FSS) aims to segment unseen classes given only a few
annotated samples. Existing methods suffer the problem of feature undermining,
i.e. potential novel classes are treated as background during training phase.
Our method aims to alleviate this problem and enhance the feature embedding on
latent novel classes. In our work, we propose a novel joint-training framework.
Based on conventional episodic training on support-query pairs, we add an
additional mining branch that exploits latent novel classes via transferable
sub-clusters, and a new rectification technique on both background and
foreground categories to enforce more stable prototypes. Over and above that,
our transferable sub-cluster has the ability to leverage extra unlabeled data
for further feature enhancement. Extensive experiments on two FSS benchmarks
demonstrate that our method outperforms previous state-of-the-art by a large
margin of 3.7% mIOU on PASCAL-5i and 7.0% mIOU on COCO-20i at the cost of 74%
fewer parameters and 2.5x faster inference speed. The source code is available
at https://github.com/LiheYoung/MiningFSS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                    <div class="article-summary-box-inner">
                                        <span>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MGIC: Multigrid-in-Channels Neural Network Architectures. (arXiv:2011.09128v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eliasof_M/0/1/0/all/0/1">Moshe Eliasof</a>, <a href="http://arxiv.org/find/cs/1/au:+Ephrath_J/0/1/0/all/0/1">Jonathan Ephrath</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruthotto_L/0/1/0/all/0/1">Lars Ruthotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Treister_E/0/1/0/all/0/1">Eran Treister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09128">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multigrid-in-channels (MGIC) approach that tackles the quadratic
growth of the number of parameters with respect to the number of channels in
standard convolutional neural networks (CNNs). Thereby our approach addresses
the redundancy in CNNs that is also exposed by the recent success of
lightweight CNNs. Lightweight CNNs can achieve comparable accuracy to standard
CNNs with fewer parameters; however, the number of weights still scales
quadratically with the CNN&#x27;s width. Our MGIC architectures replace each CNN
block with an MGIC counterpart that utilizes a hierarchy of nested grouped
convolutions of small group size to address this.

Hence, our proposed architectures scale linearly with respect to the
network&#x27;s width while retaining full coupling of the channels as in standard
CNNs.

Our extensive experiments on image classification, segmentation, and point
cloud classification show that applying this strategy to different
architectures like ResNet and MobileNetV3 reduces the number of parameters
while obtaining similar or better accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Image Transformation for Inducing Affect. (arXiv:1707.08148v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Afsheen Rafaqat Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohsen Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1707.08148">
                                    <div class="article-summary-box-inner">
                                        <span>Current image transformation and recoloring algorithms try to introduce
artistic effects in the photographed images, based on user input of target
image(s) or selection of pre-designed filters. These manipulations, although
intended to enhance the impact of an image on the viewer, do not include the
option of image transformation by specifying the affect information. In this
paper we present an automatic image-transformation method that transforms the
source image such that it can induce an emotional affect on the viewer, as
desired by the user. Our proposed novel image emotion transfer algorithm does
not require a user-specified target image. The proposed algorithm uses features
extracted from top layers of deep convolutional neural network and the
user-specified emotion distribution to select multiple target images from an
image database for color transformation, such that the resultant image has
desired emotional impact. Our method can handle more diverse set of photographs
than the previous methods. We conducted a detailed user study showing the
effectiveness of our proposed method. A discussion and reasoning of failure
cases has also been provided, indicating inherent limitation of color-transfer
based methods in the use of emotion assignment.

Project Page: this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning methods for automatic evaluation of delayed enhancement-MRI. The results of the EMIDEC challenge. (arXiv:2108.04016v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lalande_A/0/1/0/all/0/1">Alain Lalande</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhihao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pommier_T/0/1/0/all/0/1">Thibaut Pommier</a>, <a href="http://arxiv.org/find/cs/1/au:+Decourselle_T/0/1/0/all/0/1">Thomas Decourselle</a>, <a href="http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1">Abdul Qayyum</a>, <a href="http://arxiv.org/find/cs/1/au:+Salomon_M/0/1/0/all/0/1">Michel Salomon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginhac_D/0/1/0/all/0/1">Dominique Ginhac</a>, <a href="http://arxiv.org/find/cs/1/au:+Skandarani_Y/0/1/0/all/0/1">Youssef Skandarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Boucher_A/0/1/0/all/0/1">Arnaud Boucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahim_K/0/1/0/all/0/1">Khawla Brahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruijne_M/0/1/0/all/0/1">Marleen de Bruijne</a>, <a href="http://arxiv.org/find/cs/1/au:+Camarasa_R/0/1/0/all/0/1">Robin Camarasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Correia_T/0/1/0/all/0/1">Teresa M. Correia</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xue Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Girum_K/0/1/0/all/0/1">Kibrom B. Girum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennemuth_A/0/1/0/all/0/1">Anja Hennemuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Huellebrand_M/0/1/0/all/0/1">Markus Huellebrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_R/0/1/0/all/0/1">Raabid Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ivantsits_M/0/1/0/all/0/1">Matthias Ivantsits</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1">Craig Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rishabh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jixi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsekos_N/0/1/0/all/0/1">Nikolaos V. Tsekos</a>, <a href="http://arxiv.org/find/cs/1/au:+Varela_M/0/1/0/all/0/1">Marta Varela</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hannu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuncheng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Couturier_R/0/1/0/all/0/1">Raphael Couturier</a>, <a href="http://arxiv.org/find/cs/1/au:+Meriaudeau_F/0/1/0/all/0/1">Fabrice Meriaudeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04016">
                                    <div class="article-summary-box-inner">
                                        <span>A key factor for assessing the state of the heart after myocardial infarction
(MI) is to measure whether the myocardium segment is viable after reperfusion
or revascularization therapy. Delayed enhancement-MRI or DE-MRI, which is
performed several minutes after injection of the contrast agent, provides high
contrast between viable and nonviable myocardium and is therefore a method of
choice to evaluate the extent of MI. To automatically assess myocardial status,
the results of the EMIDEC challenge that focused on this task are presented in
this paper. The challenge&#x27;s main objectives were twofold. First, to evaluate if
deep learning methods can distinguish between normal and pathological cases.
Second, to automatically calculate the extent of myocardial infarction. The
publicly available database consists of 150 exams divided into 50 cases with
normal MRI after injection of a contrast agent and 100 cases with myocardial
infarction (and then with a hyperenhanced area on DE-MRI), whatever their
inclusion in the cardiac emergency department. Along with MRI, clinical
characteristics are also provided. The obtained results issued from several
works show that the automatic classification of an exam is a reachable task
(the best method providing an accuracy of 0.92), and the automatic segmentation
of the myocardium is possible. However, the segmentation of the diseased area
needs to be improved, mainly due to the small size of these areas and the lack
of contrast with the surrounding structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Human Reconstruction in the Wild with Collaborative Aerial Cameras. (arXiv:2108.03936v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1">Cherie Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_A/0/1/0/all/0/1">Andrew Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_H/0/1/0/all/0/1">Harry Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_R/0/1/0/all/0/1">Rohan Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonatti_R/0/1/0/all/0/1">Rogerio Bonatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03936">
                                    <div class="article-summary-box-inner">
                                        <span>Aerial vehicles are revolutionizing applications that require capturing the
3D structure of dynamic targets in the wild, such as sports, medicine, and
entertainment. The core challenges in developing a motion-capture system that
operates in outdoors environments are: (1) 3D inference requires multiple
simultaneous viewpoints of the target, (2) occlusion caused by obstacles is
frequent when tracking moving targets, and (3) the camera and vehicle state
estimation is noisy. We present a real-time aerial system for multi-camera
control that can reconstruct human motions in natural environments without the
use of special-purpose markers. We develop a multi-robot coordination scheme
that maintains the optimal flight formation for target reconstruction quality
amongst obstacles. We provide studies evaluating system performance in
simulation, and validate real-world performance using two drones while a target
performs activities such as jogging and playing soccer. Supplementary video:
https://youtu.be/jxt91vx0cns</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ManiSkill: Learning-from-Demonstrations Benchmark for Generalizable Manipulation Skills. (arXiv:2107.14483v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tongzhou Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_F/0/1/0/all/0/1">Fanbo Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Derek Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Stone Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
                                    <div class="article-summary-box-inner">
                                        <span>Learning generalizable manipulation skills is central for robots to achieve
task automation in environments with endless scene and object variations.
However, existing robot learning environments are limited in both scale and
diversity of 3D assets (especially of articulated objects), making it difficult
to train and evaluate the generalization ability of agents over novel objects.
In this work, we focus on object-level generalization and propose SAPIEN
Manipulation Skill Benchmark (abbreviated as ManiSkill), a large-scale
learning-from-demonstrations benchmark for articulated object manipulation with
3D visual input (point cloud and RGB-D image). ManiSkill supports object-level
variations by utilizing a rich and diverse set of articulated objects, and each
task is carefully designed for learning manipulations on a single category of
objects. We equip ManiSkill with a large number of high-quality demonstrations
to facilitate learning-from-demonstrations approaches and perform evaluations
on baseline algorithms. We believe that ManiSkill can encourage the robot
learning community to explore more on learning generalizable object
manipulation skills.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining a Convolutional Neural Network with Autoencoders to Predict the Survival Chance of COVID-19 Patients. (arXiv:2104.08954v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khozeimeh_F/0/1/0/all/0/1">Fahime Khozeimeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Izadi_N/0/1/0/all/0/1">Navid Hoseini Izadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joloudari_J/0/1/0/all/0/1">Javad Hassannataj Joloudari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1">Sadiq Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sani_Z/0/1/0/all/0/1">Zahra Alizadeh Sani</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Sheikh Mohammed Shariful Islam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08954">
                                    <div class="article-summary-box-inner">
                                        <span>COVID-19 has caused many deaths worldwide. The automation of the diagnosis of
this virus is highly desired. Convolutional neural networks (CNNs) have shown
outstanding classification performance on image datasets. To date, it appears
that COVID computer-aided diagnosis systems based on CNNs and clinical
information have not yet been analysed or explored. We propose a novel method,
named the CNN-AE, to predict the survival chance of COVID-19 patients using a
CNN trained with clinical information. Notably, the required resources to
prepare CT images are expensive and limited compared to those required to
collect clinical data, such as blood pressure, liver disease, etc. We evaluated
our method using a publicly available clinical dataset that we collected. The
dataset properties were carefully analysed to extract important features and
compute the correlations of features. A data augmentation procedure based on
autoencoders (AEs) was proposed to balance the dataset. The experimental
results revealed that the average accuracy of the CNN-AE (96.05%) was higher
than that of the CNN (92.49%). To demonstrate the generality of our
augmentation method, we trained some existing mortality risk prediction methods
on our dataset (with and without data augmentation) and compared their
performances. We also evaluated our method using another dataset for further
generality verification. To show that clinical data can be used for COVID-19
survival chance prediction, the CNN-AE was compared with multiple pre-trained
deep models that were tuned based on CT images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial-Temporal Transformer for Dynamic Scene Graph Generation. (arXiv:2107.12309v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1">Yuren Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wentong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ackermann_H/0/1/0/all/0/1">Hanno Ackermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Michael Ying Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12309">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic scene graph generation aims at generating a scene graph of the given
video. Compared to the task of scene graph generation from images, it is more
challenging because of the dynamic relationships between objects and the
temporal dependencies between frames allowing for a richer semantic
interpretation. In this paper, we propose Spatial-temporal Transformer
(STTran), a neural network that consists of two core modules: (1) a spatial
encoder that takes an input frame to extract spatial context and reason about
the visual relationships within a frame, and (2) a temporal decoder which takes
the output of the spatial encoder as input in order to capture the temporal
dependencies between frames and infer the dynamic relationships. Furthermore,
STTran is flexible to take varying lengths of videos as input without clipping,
which is especially important for long videos. Our method is validated on the
benchmark dataset Action Genome (AG). The experimental results demonstrate the
superior performance of our method in terms of dynamic scene graphs. Moreover,
a set of ablative studies is conducted and the effect of each proposed module
is justified. Code available at: https://github.com/yrcong/STTran.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TriTransNet: RGB-D Salient Object Detection with a Triplet Transformer Embedding Network. (arXiv:2108.03990v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhengyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhengzheng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1">Bin Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03990">
                                    <div class="article-summary-box-inner">
                                        <span>Salient object detection is the pixel-level dense prediction task which can
highlight the prominent object in the scene. Recently U-Net framework is widely
used, and continuous convolution and pooling operations generate multi-level
features which are complementary with each other. In view of the more
contribution of high-level features for the performance, we propose a triplet
transformer embedding module to enhance them by learning long-range
dependencies across layers. It is the first to use three transformer encoders
with shared weights to enhance multi-level features. By further designing scale
adjustment module to process the input, devising three-stream decoder to
process the output and attaching depth features to color features for the
multi-modal fusion, the proposed triplet transformer embedding network
(TriTransNet) achieves the state-of-the-art performance in RGB-D salient object
detection, and pushes the performance to a new level. Experimental results
demonstrate the effectiveness of the proposed modules and the competition of
TriTransNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Consistency Regularization for Semi-Supervised Transfer Learning. (arXiv:2103.02193v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Cheng-Zhong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02193">
                                    <div class="article-summary-box-inner">
                                        <span>While recent studies on semi-supervised learning have shown remarkable
progress in leveraging both labeled and unlabeled data, most of them presume a
basic setting of the model is randomly initialized. In this work, we consider
semi-supervised learning and transfer learning jointly, leading to a more
practical and competitive paradigm that can utilize both powerful pre-trained
models from source domain as well as labeled/unlabeled data in the target
domain. To better exploit the value of both pre-trained weights and unlabeled
target examples, we introduce adaptive consistency regularization that consists
of two complementary components: Adaptive Knowledge Consistency (AKC) on the
examples between the source and target model, and Adaptive Representation
Consistency (ARC) on the target model between labeled and unlabeled examples.
Examples involved in the consistency regularization are adaptively selected
according to their potential contributions to the target task. We conduct
extensive experiments on popular benchmarks including CIFAR-10, CUB-200, and
MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show
that our proposed adaptive consistency regularization outperforms
state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean
Teacher, and FixMatch. Moreover, our algorithm is orthogonal to existing
methods and thus able to gain additional improvements on top of MixMatch and
FixMatch. Our code is available at
https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRINet: A Dual-Representation Iterative Learning Network for Point Cloud Segmentation. (arXiv:2108.04023v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Maosheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuangjie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tongyi Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04023">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel and flexible architecture for point cloud segmentation
with dual-representation iterative learning. In point cloud processing,
different representations have their own pros and cons. Thus, finding suitable
ways to represent point cloud data structure while keeping its own internal
physical property such as permutation and scale-invariant is a fundamental
problem. Therefore, we propose our work, DRINet, which serves as the basic
network structure for dual-representation learning with great flexibility at
feature transferring and less computation cost, especially for large-scale
point clouds. DRINet mainly consists of two modules called Sparse Point-Voxel
Feature Extraction and Sparse Voxel-Point Feature Extraction. By utilizing
these two modules iteratively, features can be propagated between two different
representations. We further propose a novel multi-scale pooling layer for
pointwise locality learning to improve context information propagation. Our
network achieves state-of-the-art results for point cloud classification and
segmentation tasks on several datasets while maintaining high runtime
efficiency. For large-scale outdoor scenarios, our method outperforms
state-of-the-art methods with a real-time inference speed of 62ms per frame.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolution Neural Network Hyperparameter Optimization Using Simplified Swarm Optimization. (arXiv:2103.03995v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeh_W/0/1/0/all/0/1">Wei-Chang Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yi-Ping Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yun-Chia Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chyh-Ming Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03995">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) are widely used in image recognition.
Numerous CNN models, such as LeNet, AlexNet, VGG, ResNet, and GoogLeNet, have
been proposed by increasing the number of layers, to improve the performance of
CNNs. However, performance deteriorates beyond a certain number of layers.
Hence, hyperparameter optimisation is a more efficient way to improve CNNs. To
validate this concept, a new algorithm based on simplified swarm optimisation
is proposed to optimise the hyperparameters of the simplest CNN model, which is
LeNet. The results of experiments conducted on the MNIST, Fashion MNIST, and
Cifar10 datasets showed that the accuracy of the proposed algorithm is higher
than the original LeNet model and PSO-LeNet and that it has a high potential to
be extended to more complicated models, such as AlexNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence Rate of Projected Gradient Descent for a Back-Projection based Objective. (arXiv:2005.00959v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Tirer_T/0/1/0/all/0/1">Tom Tirer</a>, <a href="http://arxiv.org/find/math/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00959">
                                    <div class="article-summary-box-inner">
                                        <span>Ill-posed linear inverse problems appear in many scientific setups, and are
typically addressed by solving optimization problems, which are composed of
data fidelity and prior terms. Recently, several works have considered a
back-projection (BP) based fidelity term as an alternative to the common least
squares (LS), and demonstrated excellent results for popular inverse problems.
These works have also empirically shown that using the BP term, rather than the
LS term, requires fewer iterations of optimization algorithms. In this paper,
we examine the convergence rate of the projected gradient descent (PGD)
algorithm for the BP objective. Our analysis allows to identify an inherent
source for its faster convergence compared to using the LS objective, while
making only mild assumptions. We also analyze the more general proximal
gradient method under a relaxed contraction condition on the proximal mapping
of the prior. This analysis further highlights the advantage of BP when the
linear measurement operator is badly conditioned. Numerical experiments with
both $\ell_1$-norm and GAN-based priors corroborate our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely Guided Knowledge Distillation using Multiple Teacher Assistants. (arXiv:2009.08825v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Son_W/0/1/0/all/0/1">Wonchul Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_J/0/1/0/all/0/1">Jaemin Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Junyong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonjun Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08825">
                                    <div class="article-summary-box-inner">
                                        <span>With the success of deep neural networks, knowledge distillation which guides
the learning of a small student network from a large teacher network is being
actively studied for model compression and transfer learning. However, few
studies have been performed to resolve the poor learning issue of the student
network when the student and teacher model sizes significantly differ. In this
paper, we propose a densely guided knowledge distillation using multiple
teacher assistants that gradually decreases the model size to efficiently
bridge the large gap between the teacher and student networks. To stimulate
more efficient learning of the student network, we guide each teacher assistant
to every other smaller teacher assistants iteratively. Specifically, when
teaching a smaller teacher assistant at the next step, the existing larger
teacher assistants from the previous step are used as well as the teacher
network. Moreover, we design stochastic teaching where, for each mini-batch, a
teacher or teacher assistants are randomly dropped. This acts as a regularizer
to improve the efficiency of teaching of the student network. Thus, the student
can always learn salient distilled knowledge from the multiple sources. We
verified the effectiveness of the proposed method for a classification task
using CIFAR-10, CIFAR-100, and ImageNet. We also achieved significant
performance improvements with various backbone architectures such as ResNet,
WideResNet, and VGG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Exposing the Challenging Long Tail in Future Prediction of Traffic Actors. (arXiv:2103.12474v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makansi_O/0/1/0/all/0/1">Osama Makansi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_O/0/1/0/all/0/1">&#xd6;zg&#xfc;n Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Marrakchi_Y/0/1/0/all/0/1">Yassine Marrakchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12474">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the states of dynamic traffic actors into the future is important
for autonomous systems to operate safelyand efficiently. Remarkably, the most
critical scenarios aremuch less frequent and more complex than the
uncriticalones. Therefore, uncritical cases dominate the prediction. In this
paper, we address specifically the challenging scenarios at the long tail of
the dataset distribution. Our analysis shows that the common losses tend to
place challenging cases suboptimally in the embedding space. As a consequence,
we propose to supplement the usual loss with aloss that places challenging
cases closer to each other. This triggers sharing information among challenging
cases andlearning specific predictive features. We show on four public datasets
that this leads to improved performance on the challenging scenarios while the
overall performance stays stable. The approach is agnostic w.r.t. the used
network architecture, input modality or viewpoint, and can be integrated into
existing solutions easily. Code is available at
https://github.com/lmb-freiburg/Contrastive-Future-Trajectory-Prediction</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Camera Simulators. (arXiv:2104.05237v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1">Hao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1">Chenyang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_K/0/1/0/all/0/1">Ka Lung Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05237">
                                    <div class="article-summary-box-inner">
                                        <span>We present a controllable camera simulator based on deep neural networks to
synthesize raw image data under different camera settings, including exposure
time, ISO, and aperture. The proposed simulator includes an exposure module
that utilizes the principle of modern lens designs for correcting the luminance
level. It also contains a noise module using the noise level function and an
aperture module with adaptive attention to simulate the side effects on noise
and defocus blur. To facilitate the learning of a simulator model, we collect a
dataset of the 10,000 raw images of 450 scenes with different exposure
settings. Quantitative experiments and qualitative comparisons show that our
approach outperforms relevant baselines in raw data synthesize on multiple
cameras. Furthermore, the camera simulator enables various applications,
including large-aperture enhancement, HDR, auto exposure, and data augmentation
for training local feature detectors. Our work represents the first attempt to
simulate a camera sensor&#x27;s behavior leveraging both the advantage of
traditional raw sensor features and the power of data-driven deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intelligent Monitoring of Stress Induced by Water Deficiency in Plants using Deep Learning. (arXiv:2104.07911v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azimi_S/0/1/0/all/0/1">Shiva Azimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadhawan_R/0/1/0/all/0/1">Rohan Wadhawan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_T/0/1/0/all/0/1">Tapan K. Gandhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07911">
                                    <div class="article-summary-box-inner">
                                        <span>In the recent decade, high-throughput plant phenotyping techniques, which
combine non-invasive image analysis and machine learning, have been
successfully applied to identify and quantify plant health and diseases.
However, these techniques usually do not consider the progressive nature of
plant stress and often require images showing severe signs of stress to ensure
high confidence detection, thereby reducing the feasibility for early detection
and recovery of plants under stress. To overcome the problem mentioned above,
we propose a deep learning pipeline for the temporal analysis of the visual
changes induced in the plant due to stress and apply it for the specific case
of water stress identification in Chickpea plant shoot images. For this, we
have considered an image dataset of two chickpea varieties JG-62 and Pusa-372,
under three water stress conditions; control, young seedling, and before
flowering, captured over five months. We have employed a variant of the
Long-term Recurrent Convolutional Network (LRCN) to learn spatio-temporal
patterns from the chickpea plant dataset and use them for water stress
classification. Our model has achieved ceiling level classification performance
of 98.52% on JG-62 and 97.78% on Pusa-372 chickpea plant data and has
outperformed the state-of-the-art time-invariant technique by at least 14% for
both JG-62 and Pusa-372 species, to the best of our knowledge. Furthermore, our
LRCN model has demonstrated robustness to noisy input, with a less than 2.5%
dip in average model accuracy and a small standard deviation about the mean for
both species. Lastly, we have performed an ablation study to analyze the
performance of the LRCN model by decreasing the number of temporal session data
used for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BAOD: Budget-Aware Object Detection. (arXiv:1904.05443v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pardo_A/0/1/0/all/0/1">Alejandro Pardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengmeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.05443">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of object detection from a novel perspective in which
annotation budget constraints are taken into consideration, appropriately
coined Budget Aware Object Detection (BAOD). When provided with a fixed budget,
we propose a strategy for building a diverse and informative dataset that can
be used to optimally train a robust detector. We investigate both optimization
and learning-based methods to sample which images to annotate and what type of
annotation (strongly or weakly supervised) to annotate them with. We adopt a
hybrid supervised learning framework to train the object detector from both
these types of annotation. We conduct a comprehensive empirical study showing
that a handcrafted optimization method outperforms other selection techniques
including random sampling, uncertainty sampling and active learning. By
combining an optimal image/annotation selection scheme with hybrid supervised
learning to solve the BAOD problem, we show that one can achieve the
performance of a strongly supervised detector on PASCAL-VOC 2007 while saving
12.8% of its original annotation budget. Furthermore, when $100\%$ of the
budget is used, it surpasses this performance by 2.0 mAP percentage points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomy 2.0: Why is self-driving always 5 years away?. (arXiv:2107.08142v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ashesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1">Luca Del Pero</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1">Hugo Grimmett</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1">Peter Ondruska</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08142">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the numerous successes of machine learning over the past decade
(image recognition, decision-making, NLP, image synthesis), self-driving
technology has not yet followed the same trend. In this paper, we study the
history, composition, and development bottlenecks of the modern self-driving
stack. We argue that the slow progress is caused by approaches that require too
much hand-engineering, an over-reliance on road testing, and high fleet
deployment costs. We observe that the classical stack has several bottlenecks
that preclude the necessary scale needed to capture the long tail of rare
events. To resolve these problems, we outline the principles of Autonomy 2.0,
an ML-first approach to self-driving, as a viable alternative to the currently
adopted state-of-the-art. This approach is based on (i) a fully differentiable
AV stack trainable from human demonstrations, (ii) closed-loop data-driven
reactive simulation, and (iii) large-scale, low-cost data collections as
critical solutions towards scalability issues. We outline the general
architecture, survey promising works in this direction and propose key
challenges to be addressed by the community in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Refinement Network for Point Cloud Completion with Self-supervision. (arXiv:2010.08719v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1">Marcelo H Ang Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gim Hee Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08719">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds are often sparse and incomplete, which imposes difficulties for
real-world applications. Existing shape completion methods tend to generate
rough shapes without fine-grained details. Considering this, we introduce a
two-branch network for shape completion. The first branch is a cascaded shape
completion sub-network to synthesize complete objects, where we propose to use
the partial input together with the coarse output to preserve the object
details during the dense point reconstruction. The second branch is an
auto-encoder to reconstruct the original partial input. The two branches share
a same feature extractor to learn an accurate global feature for shape
completion. Furthermore, we propose two strategies to enable the training of
our network when ground truth data are not available. This is to mitigate the
dependence of existing approaches on large amounts of ground truth training
data that are often difficult to obtain in real-world applications.
Additionally, our proposed strategies are also able to improve the
reconstruction quality for fully supervised learning. We verify our approach in
self-supervised, semi-supervised and fully supervised settings with superior
performances. Quantitative and qualitative results on different datasets
demonstrate that our method achieves more realistic outputs than
state-of-the-art approaches on the point cloud completion task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Few-Shot Classification on the Oblique Manifold. (arXiv:2108.04009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guodong Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huimin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhaohui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuzhao Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04009">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) attempts to learn with limited data. In this work, we
perform the feature extraction in the Euclidean space and the geodesic distance
metric on the Oblique Manifold (OM). Specially, for better feature extraction,
we propose a non-parametric Region Self-attention with Spatial Pyramid Pooling
(RSSPP), which realizes a trade-off between the generalization and the
discriminative ability of the single image feature. Then, we embed the feature
to OM as a point. Furthermore, we design an Oblique Distance-based Classifier
(ODC) that achieves classification in the tangent spaces which better
approximate OM locally by learnable tangency points. Finally, we introduce a
new method for parameters initialization and a novel loss function in the
transductive settings. Extensive experiments demonstrate the effectiveness of
our algorithm and it outperforms state-of-the-art methods on the popular
benchmarks: mini-ImageNet, tiered-ImageNet, and Caltech-UCSD Birds-200-2011
(CUB).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Annotation for Visual Tracking via Selection and Refinement. (arXiv:2108.03821v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_K/0/1/0/all/0/1">Kenan Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jie Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianhua Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Huchuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xuesheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03821">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning based visual trackers entail offline pre-training on large
volumes of video datasets with accurate bounding box annotations that are
labor-expensive to achieve. We present a new framework to facilitate bounding
box annotations for video sequences, which investigates a
selection-and-refinement strategy to automatically improve the preliminary
annotations generated by tracking algorithms. A temporal assessment network
(T-Assess Net) is proposed which is able to capture the temporal coherence of
target locations and select reliable tracking results by measuring their
quality. Meanwhile, a visual-geometry refinement network (VG-Refine Net) is
also designed to further enhance the selected tracking results by considering
both target appearance and temporal geometry constraints, allowing inaccurate
tracking results to be corrected. The combination of the above two networks
provides a principled approach to ensure the quality of automatic video
annotation. Experiments on large scale tracking benchmarks demonstrate that our
method can deliver highly accurate bounding box annotations and significantly
reduce human labor by 94.0%, yielding an effective means to further boost
tracking performance with augmented training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransForensics: Image Forgery Localization with Dense Self-Attention. (arXiv:2108.03871v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jing Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhixin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shicai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_D/0/1/0/all/0/1">Di Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shiliang Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03871">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays advanced image editing tools and technical skills produce tampered
images more realistically, which can easily evade image forensic systems and
make authenticity verification of images more difficult. To tackle this
challenging problem, we introduce TransForensics, a novel image forgery
localization method inspired by Transformers. The two major components in our
framework are dense self-attention encoders and dense correction modules. The
former is to model global context and all pairwise interactions between local
patches at different scales, while the latter is used for improving the
transparency of the hidden layers and correcting the outputs from different
branches. Compared to previous traditional and deep learning methods,
TransForensics not only can capture discriminative representations and obtain
high-quality mask predictions but is also not limited by tampering types and
patch sequence orders. By conducting experiments on main benchmarks, we show
that TransForensics outperforms the stateof-the-art methods by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DanceIt: Music-inspired Dancing Video Synthesis. (arXiv:2009.08027v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yifan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08027">
                                    <div class="article-summary-box-inner">
                                        <span>Close your eyes and listen to music, one can easily imagine an actor dancing
rhythmically along with the music. These dance movements are usually made up of
dance movements you have seen before. In this paper, we propose to reproduce
such an inherent capability of the human-being within a computer vision system.
The proposed system consists of three modules. To explore the relationship
between music and dance movements, we propose a cross-modal alignment module
that focuses on dancing video clips, accompanied on pre-designed music, to
learn a system that can judge the consistency between the visual features of
pose sequences and the acoustic features of music. The learned model is then
used in the imagination module to select a pose sequence for the given music.
Such pose sequence selected from the music, however, is usually discontinuous.
To solve this problem, in the spatial-temporal alignment module we develop a
spatial alignment algorithm based on the tendency and periodicity of dance
movements to predict dance movements between discontinuous fragments. In
addition, the selected pose sequence is often misaligned with the music beat.
To solve this problem, we further develop a temporal alignment algorithm to
align the rhythm of music and dance. Finally, the processed pose sequence is
used to synthesize realistic dancing videos in the imagination module. The
generated dancing videos match the content and rhythm of the music.
Experimental results and subjective evaluations show that the proposed approach
can perform the function of generating promising dancing videos by inputting
music.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complementary Patch for Weakly Supervised Semantic Segmentation. (arXiv:2108.03852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1">Chaochen Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenyue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yuchao Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03852">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly Supervised Semantic Segmentation (WSSS) based on image-level labels
has been greatly advanced by exploiting the outputs of Class Activation Map
(CAM) to generate the pseudo labels for semantic segmentation. However, CAM
merely discovers seeds from a small number of regions, which may be
insufficient to serve as pseudo masks for semantic segmentation. In this paper,
we formulate the expansion of object regions in CAM as an increase in
information. From the perspective of information theory, we propose a novel
Complementary Patch (CP) Representation and prove that the information of the
sum of the CAMs by a pair of input images with complementary hidden (patched)
parts, namely CP Pair, is greater than or equal to the information of the
baseline CAM. Therefore, a CAM with more information related to object seeds
can be obtained by narrowing down the gap between the sum of CAMs generated by
the CP Pair and the original CAM. We propose a CP Network (CPN) implemented by
a triplet network and three regularization functions. To further improve the
quality of the CAMs, we propose a Pixel-Region Correlation Module (PRCM) to
augment the contextual information by using object-region relations between the
feature maps and the CAMs. Experimental results on the PASCAL VOC 2012 datasets
show that our proposed method achieves a new state-of-the-art in WSSS,
validating the effectiveness of our CP Representation and CPN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Novel Target Discovery Through Open-Set Domain Adaptation. (arXiv:2105.02432v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jing_T/0/1/0/all/0/1">Taotao Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongfu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhengming Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02432">
                                    <div class="article-summary-box-inner">
                                        <span>Open-set domain adaptation (OSDA) considers that the target domain contains
samples from novel categories unobserved in external source domain.
Unfortunately, existing OSDA methods always ignore the demand for the
information of unseen categories and simply recognize them as &quot;unknown&quot; set
without further explanation. This motivates us to understand the unknown
categories more specifically by exploring the underlying structures and
recovering their interpretable semantic attributes. In this paper, we propose a
novel framework to accurately identify the seen categories in target domain,
and effectively recover the semantic attributes for unseen categories.
Specifically, structure preserving partial alignment is developed to recognize
the seen categories through domain-invariant feature learning. Attribute
propagation over visual graph is designed to smoothly transit attributes from
seen to unseen categories via visual-semantic mapping. Moreover, two new
cross-main benchmarks are constructed to evaluate the proposed framework in the
novel and practical challenge. Experimental results on open-set recognition and
semantic recovery demonstrate the superiority of the proposed method over other
compared baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pedestrian Trajectory Prediction using Context-Augmented Transformer Networks. (arXiv:2012.01757v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saleh_K/0/1/0/all/0/1">Khaled Saleh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01757">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting the trajectory of pedestrians in shared urban traffic
environments is still considered one of the challenging problems facing the
development of autonomous vehicles (AVs). In the literature, this problem is
often tackled using recurrent neural networks (RNNs). Despite the powerful
capabilities of RNNs in capturing the temporal dependency in the pedestrians&#x27;
motion trajectories, they were argued to be challenged when dealing with longer
sequential data. Thus, in this work, we are introducing a framework based on
the transformer networks that were shown recently to be more efficient and
outperformed RNNs in many sequential-based tasks. We relied on a fusion of the
past positional information, agent interactions information and scene physical
semantics information as an input to our framework in order to provide a robust
trajectory prediction of pedestrians. We have evaluated our framework on two
real-life datasets of pedestrians in shared urban traffic environments and it
has outperformed the compared baseline approaches in both short-term and
long-term prediction horizons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Relative Order Attack in Deep Ranking. (arXiv:2103.05248v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChartPointFlow for Topology-Aware 3D Point Cloud Generation. (arXiv:2012.02346v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1">Takumi Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1">Takashi Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_K/0/1/0/all/0/1">Kuniaki Uehara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02346">
                                    <div class="article-summary-box-inner">
                                        <span>A point cloud serves as a representation of the surface of a
three-dimensional (3D) shape. Deep generative models have been adapted to model
their variations typically using a map from a ball-like set of latent
variables. However, previous approaches did not pay much attention to the
topological structure of a point cloud, despite that a continuous map cannot
express the varying numbers of holes and intersections. Moreover, a point cloud
is often composed of multiple subparts, and it is also difficult to express. In
this study, we propose ChartPointFlow, a flow-based generative model with
multiple latent labels for 3D point clouds. Each label is assigned to points in
an unsupervised manner. Then, a map conditioned on a label is assigned to a
continuous subset of a point cloud, similar to a chart of a manifold. This
enables our proposed model to preserve the topological structure with clear
boundaries, whereas previous approaches tend to generate blurry point clouds
and fail to generate holes. The experimental results demonstrate that
ChartPointFlow achieves state-of-the-art performance in terms of generation and
reconstruction compared with other point cloud generators. Moreover,
ChartPointFlow divides an object into semantic subparts using charts, and it
demonstrates superior performance in case of unsupervised segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlphaGAN: Fully Differentiable Architecture Search for Generative Adversarial Networks. (arXiv:2006.09134v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuesong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Guinan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09134">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) are formulated as minimax game
problems, whereby generators attempt to approach real data distributions by
virtue of adversarial learning against discriminators. The intrinsic problem
complexity poses the challenge to enhance the performance of generative
networks. In this work, we aim to boost model learning from the perspective of
network architectures, by incorporating recent progress on automated
architecture search into GANs. To this end, we propose a fully differentiable
search framework for generative adversarial networks, dubbed alphaGAN. The
searching process is formalized as solving a bi-level minimax optimization
problem, in which the outer-level objective aims for seeking a suitable network
architecture towards pure Nash Equilibrium conditioned on the generator and the
discriminator network parameters optimized with a traditional GAN loss in the
inner level. The entire optimization performs a first-order method by
alternately minimizing the two-level objective in a fully differentiable
manner, enabling architecture search to be completed in an enormous search
space. Extensive experiments on CIFAR-10 and STL-10 datasets show that our
algorithm can obtain high-performing architectures only with 3-GPU hours on a
single GPU in the search space comprised of approximate 2 ? 1011 possible
configurations. We also provide a comprehensive analysis on the behavior of the
searching process and the properties of searched architectures, which would
benefit further research on architectures for generative models. Pretrained
models and codes are available at https://github.com/yuesongtian/AlphaGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A distillation based approach for the diagnosis of diseases. (arXiv:2108.03470v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandyopadhyay_H/0/1/0/all/0/1">Hmrishav Bandyopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Dastidar_S/0/1/0/all/0/1">Shuvayan Ghosh Dastidar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_B/0/1/0/all/0/1">Bisakh Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1">Nibaran Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03470">
                                    <div class="article-summary-box-inner">
                                        <span>Presently, Covid-19 is a serious threat to the world at large. Efforts are
being made to reduce disease screening times and in the development of a
vaccine to resist this disease, even as thousands succumb to it everyday. We
propose a novel method of automated screening of diseases like Covid-19 and
pneumonia from Chest X-Ray images with the help of Computer Vision. Unlike
computer vision classification algorithms which come with heavy computational
costs, we propose a knowledge distillation based approach which allows us to
bring down the model depth, while preserving the accuracy. We make use of an
augmentation of the standard distillation module with an auxiliary intermediate
assistant network that aids in the continuity of the flow of information.
Following this approach, we are able to build an extremely light student
network, consisting of just 3 convolutional blocks without any compromise on
accuracy. We thus propose a method of classification of diseases which can not
only lead to faster screening, but can also operate seamlessly on low-end
devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation and Object Detection Towards Instance Segmentation: Breast Tumor Identification. (arXiv:2108.03287v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mejri_M/0/1/0/all/0/1">Mohamed Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mejri_A/0/1/0/all/0/1">Aymen Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mejri_O/0/1/0/all/0/1">Oumayma Mejri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fekih_C/0/1/0/all/0/1">Chiraz Fekih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03287">
                                    <div class="article-summary-box-inner">
                                        <span>Breast cancer is one of the factors that cause the increase of mortality of
women. The most widely used method for diagnosing this geological disease i.e.
breast cancer is the ultrasound scan. Several key features such as the
smoothness and the texture of the tumor captured through ultrasound scans
encode the abnormality of the breast tumors (malignant from benign). However,
ultrasound scans are often noisy and include irrelevant parts of the breast
that may bias the segmentation of eventual tumors. In this paper, we are going
to extract the region of interest ( i.e, bounding boxes of the tumors) and
feed-forward them to one semantic segmentation encoder-decoder structure based
on its classification (i.e, malignant or benign). the whole process aims to
build an instance-based segmenter from a semantic segmenter and an object
detector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Shot Object Affordance Detection in the Wild. (arXiv:2108.03658v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1">Wei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hongchen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03658">
                                    <div class="article-summary-box-inner">
                                        <span>Affordance detection refers to identifying the potential action possibilities
of objects in an image, which is a crucial ability for robot perception and
manipulation. To empower robots with this ability in unseen scenarios, we first
study the challenging one-shot affordance detection problem in this paper,
i.e., given a support image that depicts the action purpose, all objects in a
scene with the common affordance should be detected. To this end, we devise a
One-Shot Affordance Detection Network (OSAD-Net) that firstly estimates the
human action purpose and then transfers it to help detect the common affordance
from all candidate images. Through collaboration learning, OSAD-Net can capture
the common characteristics between objects having the same underlying
affordance and learn a good adaptation capability for perceiving unseen
affordances. Besides, we build a large-scale Purpose-driven Affordance Dataset
v2 (PADv2) by collecting and labeling 30k images from 39 affordance and 103
object categories. With complex scenes and rich annotations, our PADv2 dataset
can be used as a test bed to benchmark affordance detection methods and may
also facilitate downstream vision tasks, such as scene understanding, action
recognition, and robot manipulation. Specifically, we conducted comprehensive
experiments on PADv2 dataset by including 11 advanced models from several
related research fields. Experimental results demonstrate the superiority of
our model over previous representative ones in terms of both objective metrics
and visual quality. The benchmark suite is available at
https://github.com/lhc1224/OSAD Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Invertible Encoding for Learned Image Compression. (arXiv:2108.03690v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yueqi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1">Ka Leong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03690">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep learning based image compression methods have achieved
promising progress these days, the performance of these methods still cannot
match the latest compression standard Versatile Video Coding (VVC). Most of the
recent developments focus on designing a more accurate and flexible entropy
model that can better parameterize the distributions of the latent features.
However, few efforts are devoted to structuring a better transformation between
the image space and the latent feature space. In this paper, instead of
employing previous autoencoder style networks to build this transformation, we
propose an enhanced Invertible Encoding Network with invertible neural networks
(INNs) to largely mitigate the information loss problem for better compression.
Experimental results on the Kodak, CLIC, and Tecnick datasets show that our
method outperforms the existing learned image compression methods and
compression standards, including VVC (VTM 12.1), especially for high-resolution
images. Our source code is available at https://github.com/xyq7/InvCompress.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Voxel to Point: IoU-guided 3D Object Detection for Point Cloud with Voxel-to-Point Decoder. (arXiv:2108.03648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiale Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yong Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03648">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an Intersection-over-Union (IoU) guided two-stage
3D object detector with a voxel-to-point decoder. To preserve the necessary
information from all raw points and maintain the high box recall in voxel based
Region Proposal Network (RPN), we propose a residual voxel-to-point decoder to
extract the point features in addition to the map-view features from the voxel
based RPN. We use a 3D Region of Interest (RoI) alignment to crop and align the
features with the proposal boxes for accurately perceiving the object position.
The RoI-Aligned features are finally aggregated with the corner geometry
embeddings that can provide the potentially missing corner information in the
box refinement stage. We propose a simple and efficient method to align the
estimated IoUs to the refined proposal boxes as a more relevant localization
confidence. The comprehensive experiments on KITTI and Waymo Open Dataset
demonstrate that our method achieves significant improvements with novel
architectures against the existing methods. The code is available on Github
URL\footnote{\url{https://github.com/jialeli1/From-Voxel-to-Point}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ZiGAN: Fine-grained Chinese Calligraphy Font Generation via a Few-shot Style Transfer Approach. (arXiv:2108.03596v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1">Qi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bingfeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yi Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03596">
                                    <div class="article-summary-box-inner">
                                        <span>Chinese character style transfer is a very challenging problem because of the
complexity of the glyph shapes or underlying structures and large numbers of
existed characters, when comparing with English letters. Moreover, the
handwriting of calligraphy masters has a more irregular stroke and is difficult
to obtain in real-world scenarios. Recently, several GAN-based methods have
been proposed for font synthesis, but some of them require numerous reference
data and the other part of them have cumbersome preprocessing steps to divide
the character into different parts to be learned and transferred separately. In
this paper, we propose a simple but powerful end-to-end Chinese calligraphy
font generation framework ZiGAN, which does not require any manual operation or
redundant preprocessing to generate fine-grained target-style characters with
few-shot references. To be specific, a few paired samples from different
character styles are leveraged to attain a fine-grained correlation between
structures underlying different glyphs. To capture valuable style knowledge in
target and strengthen the coarse-grained understanding of character content, we
utilize multiple unpaired samples to align the feature distributions belonging
to different character styles. By doing so, only a few target Chinese
calligraphy characters are needed to generated expected style transferred
characters. Experiments demonstrate that our method has a state-of-the-art
generalization ability in few-shot Chinese character style transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Aware Mixup for Domain Adaptive Semantic Segmentation. (arXiv:2108.03557v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhengyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Qiqi Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jianping Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03557">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to adapt a model of the labeled
source domain to an unlabeled target domain. Although the domain shifts may
exist in various dimensions such as appearance, textures, etc, the contextual
dependency, which is generally shared across different domains, is neglected by
recent methods. In this paper, we utilize this important clue as explicit prior
knowledge and propose end-to-end Context-Aware Mixup (CAMix) for domain
adaptive semantic segmentation. Firstly, we design a contextual mask generation
strategy by leveraging accumulated spatial distributions and contextual
relationships. The generated contextual mask is critical in this work and will
guide the domain mixup. In addition, we define the significance mask to
indicate where the pixels are credible. To alleviate the over-alignment (e.g.,
early performance degradation), the source and target significance masks are
mixed based on the contextual mask into the mixed significance mask, and we
introduce a significance-reweighted consistency loss on it. Experimental
results show that the proposed method outperforms the state-of-the-art methods
by a large margin on two widely-used domain adaptation benchmarks, i.e., GTAV
$\rightarrow $ Cityscapes and SYNTHIA $\rightarrow $ Cityscapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BIGRoC: Boosting Image Generation via a Robust Classifier. (arXiv:2108.03702v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganz_R/0/1/0/all/0/1">Roy Ganz</a>, <a href="http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1">Michael Elad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03702">
                                    <div class="article-summary-box-inner">
                                        <span>The interest of the machine learning community in image synthesis has grown
significantly in recent years, with the introduction of a wide range of deep
generative models and means for training them. Such machines&#x27; ultimate goal is
to match the distributions of the given training images and the synthesized
ones. In this work, we propose a general model-agnostic technique for improving
the image quality and the distribution fidelity of generated images, obtained
by any generative model. Our method, termed BIGRoC (boosting image generation
via a robust classifier), is based on a post-processing procedure via the
guidance of a given robust classifier and without a need for additional
training of the generative model. Given a synthesized image, we propose to
update it through projected gradient steps over the robust classifier, in an
attempt to refine its recognition. We demonstrate this post-processing
algorithm on various image synthesis methods and show a significant improvement
of the generated images, both quantitatively and qualitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anchor-free 3D Single Stage Detector with Mask-Guided Attention for Point Cloud. (arXiv:2108.03634v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiale Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yong Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03634">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the existing single-stage and two-stage 3D object detectors are
anchor-based methods, while the efficient but challenging anchor-free
single-stage 3D object detection is not well investigated. Recent studies on 2D
object detection show that the anchor-free methods also are of great potential.
However, the unordered and sparse properties of point clouds prevent us from
directly leveraging the advanced 2D methods on 3D point clouds. We overcome
this by converting the voxel-based sparse 3D feature volumes into the sparse 2D
feature maps. We propose an attentive module to fit the sparse feature maps to
dense mostly on the object regions through the deformable convolution tower and
the supervised mask-guided attention. By directly regressing the 3D bounding
box from the enhanced and dense feature maps, we construct a novel single-stage
3D detector for point clouds in an anchor-free manner. We propose an IoU-based
detection confidence re-calibration scheme to improve the correlation between
the detection confidence score and the accuracy of the bounding box regression.
Our code is publicly available at \url{https://github.com/jialeli1/MGAF-3DSSD}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monte Carlo DropBlock for Modelling Uncertainty in Object Detection. (arXiv:2108.03614v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1">Kumari Deepshikha</a>, <a href="http://arxiv.org/find/cs/1/au:+Yelleni_S/0/1/0/all/0/1">Sai Harsha Yelleni</a>, <a href="http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1">P.K. Srijith</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1">C Krishna Mohan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03614">
                                    <div class="article-summary-box-inner">
                                        <span>With the advancements made in deep learning, computer vision problems like
object detection and segmentation have seen a great improvement in performance.
However, in many real-world applications such as autonomous driving vehicles,
the risk associated with incorrect predictions of objects is very high.
Standard deep learning models for object detection such as YOLO models are
often overconfident in their predictions and do not take into account the
uncertainty in predictions on out-of-distribution data. In this work, we
propose an efficient and effective approach to model uncertainty in object
detection and segmentation tasks using Monte-Carlo DropBlock (MC-DropBlock)
based inference. The proposed approach applies drop-block during training time
and test time on the convolutional layer of the deep learning models such as
YOLO. We show that this leads to a Bayesian convolutional neural network
capable of capturing the epistemic uncertainty in the model. Additionally, we
capture the aleatoric uncertainty using a Gaussian likelihood. We demonstrate
the effectiveness of the proposed approach on modeling uncertainty in object
detection and segmentation tasks using out-of-distribution experiments.
Experimental results show that MC-DropBlock improves the generalization,
calibration, and uncertainty modeling capabilities of YOLO models in object
detection and segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Membership Inference Attacks on Lottery Ticket Networks. (arXiv:2108.03506v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagmar_A/0/1/0/all/0/1">Aadesh Bagmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Maiya_S/0/1/0/all/0/1">Shishira R Maiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidwalka_S/0/1/0/all/0/1">Shruti Bidwalka</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amol Deshpande</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03506">
                                    <div class="article-summary-box-inner">
                                        <span>The vulnerability of the Lottery Ticket Hypothesis has not been studied from
the purview of Membership Inference Attacks. Through this work, we are the
first to empirically show that the lottery ticket networks are equally
vulnerable to membership inference attacks. A Membership Inference Attack (MIA)
is the process of determining whether a data sample belongs to a training set
of a trained model or not. Membership Inference Attacks could leak critical
information about the training data that can be used for targeted attacks.
Recent deep learning models often have very large memory footprints and a high
computational cost associated with training and drawing inferences. Lottery
Ticket Hypothesis is used to prune the networks to find smaller sub-networks
that at least match the performance of the original model in terms of test
accuracy in a similar number of iterations. We used CIFAR-10, CIFAR-100, and
ImageNet datasets to perform image classification tasks and observe that the
attack accuracies are similar. We also see that the attack accuracy varies
directly according to the number of classes in the dataset and the sparsity of
the network. We demonstrate that these attacks are transferable across models
with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Triplet Contrastive Learning for Brain Tumor Classification. (arXiv:2108.03611v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tian Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03611">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tumor is a common and fatal form of cancer which affects both adults
and children. The classification of brain tumors into different types is hence
a crucial task, as it greatly influences the treatment that physicians will
prescribe. In light of this, medical imaging techniques, especially those
applying deep convolutional networks followed by a classification layer, have
been developed to make possible computer-aided classification of brain tumor
types. In this paper, we present a novel approach of directly learning deep
embeddings for brain tumor types, which can be used for downstream tasks such
as classification. Along with using triplet loss variants, our approach applies
contrastive learning to performing unsupervised pre-training, combined with a
rare-case data augmentation module to effectively ameliorate the lack of data
problem in the brain tumor imaging analysis domain. We evaluate our method on
an extensive brain tumor dataset which consists of 27 different tumor classes,
out of which 13 are defined as rare. With a common encoder during all the
experiments, we compare our approach with a baseline classification-layer based
model, and the results well prove the effectiveness of our approach across all
measured metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WideCaps: A Wide Attention based Capsule Network for Image Classification. (arXiv:2108.03627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+J_P/0/1/0/all/0/1">Pawan S J</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rishi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_H/0/1/0/all/0/1">Hemanth Sai Ram Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Vani_M/0/1/0/all/0/1">M Vani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_J/0/1/0/all/0/1">Jeny Rajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03627">
                                    <div class="article-summary-box-inner">
                                        <span>The capsule network is a distinct and promising segment of the neural network
family that drew attention due to its unique ability to maintain the
equivariance property by preserving the spatial relationship amongst the
features. The capsule network has attained unprecedented success over image
classification tasks with datasets such as MNIST and affNIST by encoding the
characteristic features into the capsules and building the parse-tree
structure. However, on the datasets involving complex foreground and background
regions such as CIFAR-10, the performance of the capsule network is sub-optimal
due to its naive data routing policy and incompetence towards extracting
complex features. This paper proposes a new design strategy for capsule network
architecture for efficiently dealing with complex images. The proposed method
incorporates wide bottleneck residual modules and the Squeeze and Excitation
attention blocks upheld by the modified FM routing algorithm to address the
defined problem. A wide bottleneck residual module facilitates extracting
complex features followed by the squeeze and excitation attention block to
enable channel-wise attention by suppressing the trivial features. This setup
allows channel inter-dependencies at almost no computational cost, thereby
enhancing the representation ability of capsules on complex images. We
extensively evaluate the performance of the proposed model on three publicly
available datasets, namely CIFAR-10, Fashion MNIST, and SVHN, to outperform the
top-5 performance on CIFAR-10 and Fashion MNIST with highly competitive
performance on the SVHN dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Inductive and Transductive Learning for Video Object Segmentation. (arXiv:2108.03679v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yunyao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Ning Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wengang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03679">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised video object segmentation is a task of segmenting the target
object in a video sequence given only a mask annotation in the first frame. The
limited information available makes it an extremely challenging task. Most
previous best-performing methods adopt matching-based transductive reasoning or
online inductive learning. Nevertheless, they are either less discriminative
for similar instances or insufficient in the utilization of spatio-temporal
information. In this work, we propose to integrate transductive and inductive
learning into a unified framework to exploit the complementarity between them
for accurate and robust video object segmentation. The proposed approach
consists of two functional branches. The transduction branch adopts a
lightweight transformer architecture to aggregate rich spatio-temporal cues
while the induction branch performs online inductive learning to obtain
discriminative target information. To bridge these two diverse branches, a
two-head label encoder is introduced to learn the suitable target prior for
each of them. The generated mask encodings are further forced to be
disentangled to better retain their complementarity. Extensive experiments on
several prevalent benchmarks show that, without the need of synthetic training
data, the proposed approach sets a series of new state-of-the-art records. Code
is available at https://github.com/maoyunyao/JOINT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments. (arXiv:2108.03332v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_Z/0/1/0/all/0/1">Zheng Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1">Shyamal Buch</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">C. Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03332">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce BEHAVIOR, a benchmark for embodied AI with 100 activities in
simulation, spanning a range of everyday household chores such as cleaning,
maintenance, and food preparation. These activities are designed to be
realistic, diverse, and complex, aiming to reproduce the challenges that agents
must face in the real world. Building such a benchmark poses three fundamental
difficulties for each activity: definition (it can differ by time, place, or
person), instantiation in a simulator, and evaluation. BEHAVIOR addresses these
with three innovations. First, we propose an object-centric, predicate
logic-based description language for expressing an activity&#x27;s initial and goal
conditions, enabling generation of diverse instances for any activity. Second,
we identify the simulator-agnostic features required by an underlying
environment to support BEHAVIOR, and demonstrate its realization in one such
simulator. Third, we introduce a set of metrics to measure task progress and
efficiency, absolute and relative to human demonstrators. We include 500 human
demonstrations in virtual reality (VR) to serve as the human ground truth. Our
experiments demonstrate that even state of the art embodied AI solutions
struggle with the level of realism, diversity, and complexity imposed by the
activities in our benchmark. We make BEHAVIOR publicly available at
behavior.stanford.edu to facilitate and calibrate the development of new
embodied AI solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data. (arXiv:2108.03649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Rongrong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Changlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03649">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to joint depth and normal estimation for
time-of-flight (ToF) sensors. Our model learns to predict the high-quality
depth and normal maps jointly from ToF raw sensor data. To achieve this, we
meticulously constructed the first large-scale dataset (named ToF-100) with
paired raw ToF data and ground-truth high-resolution depth maps provided by an
industrial depth camera. In addition, we also design a simple but effective
framework for joint depth and normal estimation, applying a robust Chamfer loss
via jittering to improve the performance of our model. Our experiments
demonstrate that our proposed method can efficiently reconstruct
high-resolution depth and normal maps and significantly outperforms
state-of-the-art approaches. Our code and data will be available at
\url{https://github.com/hkustVisionRr/JointlyDepthNormalEstimation}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Light Field Reconstruction via Spatio-Angular Dense Network. (arXiv:2108.03635v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zexi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_H/0/1/0/all/0/1">Henry Wing Fung Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yuk Ying Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haisheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03635">
                                    <div class="article-summary-box-inner">
                                        <span>As an image sensing instrument, light field images can supply extra angular
information compared with monocular images and have facilitated a wide range of
measurement applications. Light field image capturing devices usually suffer
from the inherent trade-off between the angular and spatial resolutions. To
tackle this problem, several methods, such as light field reconstruction and
light field super-resolution, have been proposed but leaving two problems
unaddressed, namely domain asymmetry and efficient information flow. In this
paper, we propose an end-to-end Spatio-Angular Dense Network (SADenseNet) for
light field reconstruction with two novel components, namely correlation blocks
and spatio-angular dense skip connections to address them. The former performs
effective modeling of the correlation information in a way that conforms with
the domain asymmetry. And the latter consists of three kinds of connections
enhancing the information flow within two domains. Extensive experiments on
both real-world and synthetic datasets have been conducted to demonstrate that
the proposed SADenseNet&#x27;s state-of-the-art performance at significantly reduced
costs in memory and computation. The qualitative results show that the
reconstructed light field images are sharp with correct details and can serve
as pre-processing to improve the accuracy of related measurement applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepFH Segmentations for Superpixel-based Object Proposal Refinement. (arXiv:2108.03503v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilms_C/0/1/0/all/0/1">Christian Wilms</a>, <a href="http://arxiv.org/find/cs/1/au:+Frintrop_S/0/1/0/all/0/1">Simone Frintrop</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03503">
                                    <div class="article-summary-box-inner">
                                        <span>Class-agnostic object proposal generation is an important first step in many
object detection pipelines. However, object proposals of modern systems are
rather inaccurate in terms of segmentation and only roughly adhere to object
boundaries. Since typical refinement steps are usually not applicable to
thousands of proposals, we propose a superpixel-based refinement system for
object proposal generation systems. Utilizing precise superpixels and
superpixel pooling on deep features, we refine initial coarse proposals in an
end-to-end learned system. Furthermore, we propose a novel DeepFH segmentation,
which enriches the classic Felzenszwalb and Huttenlocher (FH) segmentation with
deep features leading to improved segmentation results and better object
proposal refinements. On the COCO dataset with LVIS annotations, we show that
our refinement based on DeepFH superpixels outperforms state-of-the-art methods
and leads to more precise object proposals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Discriminative Representation Learning for Unsupervised Person Re-identification. (arXiv:2108.03439v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isobe_T/0/1/0/all/0/1">Takashi Isobe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Lu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Yi Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shengjin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03439">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of unsupervised domain adaptation for
person re-ID where annotations are available for the source domain but not for
target. Previous methods typically follow a two-stage optimization pipeline,
where the network is first pre-trained on source and then fine-tuned on target
with pseudo labels created by feature clustering. Such methods sustain two main
limitations. (1) The label noise may hinder the learning of discriminative
features for recognizing target classes. (2) The domain gap may hinder
knowledge transferring from source to target. We propose three types of
technical schemes to alleviate these issues. First, we propose a cluster-wise
contrastive learning algorithm (CCL) by iterative optimization of feature
learning and cluster refinery to learn noise-tolerant representations in the
unsupervised manner. Second, we adopt a progressive domain adaptation (PDA)
strategy to gradually mitigate the domain gap between source and target data.
Third, we propose Fourier augmentation (FA) for further maximizing the class
separability of re-ID models by imposing extra constraints in the Fourier
space. We observe that these proposed schemes are capable of facilitating the
learning of discriminative feature representations. Experiments demonstrate
that our method consistently achieves notable improvements over the
state-of-the-art unsupervised re-ID methods on multiple benchmarks, e.g.,
surpassing MMT largely by 8.1\%, 9.9\%, 11.4\% and 11.1\% mAP on the
Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT tasks,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visible Watermark Removal via Self-calibrated Localization and Background Refinement. (arXiv:2108.03581v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jing Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Li Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1">Fengjun Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_T/0/1/0/all/0/1">Teng Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liqing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03581">
                                    <div class="article-summary-box-inner">
                                        <span>Superimposing visible watermarks on images provides a powerful weapon to cope
with the copyright issue. Watermark removal techniques, which can strengthen
the robustness of visible watermarks in an adversarial way, have attracted
increasing research interest. Modern watermark removal methods perform
watermark localization and background restoration simultaneously, which could
be viewed as a multi-task learning problem. However, existing approaches suffer
from incomplete detected watermark and degraded texture quality of restored
background. Therefore, we design a two-stage multi-task network to address the
above issues. The coarse stage consists of a watermark branch and a background
branch, in which the watermark branch self-calibrates the roughly estimated
mask and passes the calibrated mask to background branch to reconstruct the
watermarked area. In the refinement stage, we integrate multi-level features to
improve the texture quality of watermarked area. Extensive experiments on two
datasets demonstrate the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Bottleneck Approach to Spatial Attention Learning. (arXiv:2108.03418v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_Q/0/1/0/all/0/1">Qiuxia Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minhao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hanqiu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03418">
                                    <div class="article-summary-box-inner">
                                        <span>The selective visual attention mechanism in the human visual system (HVS)
restricts the amount of information to reach visual awareness for perceiving
natural scenes, allowing near real-time information processing with limited
computational capacity [Koch and Ullman, 1987]. This kind of selectivity acts
as an &#x27;Information Bottleneck (IB)&#x27;, which seeks a trade-off between
information compression and predictive accuracy. However, such information
constraints are rarely explored in the attention mechanism for deep neural
networks (DNNs). In this paper, we propose an IB-inspired spatial attention
module for DNN structures built for visual recognition. The module takes as
input an intermediate representation of the input image, and outputs a
variational 2D attention map that minimizes the mutual information (MI) between
the attention-modulated representation and the input, while maximizing the MI
between the attention-modulated representation and the task label. To further
restrict the information bypassed by the attention map, we quantize the
continuous attention scores to a set of learnable anchor values during
training. Extensive experiments show that the proposed IB-inspired spatial
attention mechanism can yield attention maps that neatly highlight the regions
of interest while suppressing backgrounds, and bootstrap standard DNN
structures for visual recognition tasks (e.g., image classification,
fine-grained recognition, cross-domain classification). The attention maps are
interpretable for the decision making of the DNNs as verified in the
experiments. Our code is available at https://github.com/ashleylqx/AIB.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ContinuityLearner: Geometric Continuity Feature Learning for Lane Segmentation. (arXiv:2108.03507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Haoyu Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yi Fang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03507">
                                    <div class="article-summary-box-inner">
                                        <span>Lane segmentation is a challenging issue in autonomous driving system
designing because lane marks show weak textural consistency due to occlusion or
extreme illumination but strong geometric continuity in traffic images, from
which general convolution neural networks (CNNs) are not capable of learning
semantic objects. To empower conventional CNNs in learning geometric clues of
lanes, we propose a deep network named ContinuityLearner to better learn
geometric prior within lane. Specifically, our proposed CNN-based paradigm
involves a novel Context-encoding image feature learning network to generate
class-dependent image feature maps and a new encoding layer to exploit the
geometric continuity feature representation by fusing both spatial and visual
information of lane together. The ContinuityLearner, performing on the
geometric continuity feature of lanes, is trained to directly predict the lane
in traffic scenarios with integrated and continuous instance semantic. The
experimental results on the CULane dataset and the Tusimple benchmark
demonstrate that our ContinuityLearner has superior performance over other
state-of-the-art techniques in lane segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled High Quality Salient Object Detection. (arXiv:2108.03551v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Lv Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Shouhong Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mofei Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03551">
                                    <div class="article-summary-box-inner">
                                        <span>Aiming at discovering and locating most distinctive objects from visual
scenes, salient object detection (SOD) plays an essential role in various
computer vision systems. Coming to the era of high resolution, SOD methods are
facing new challenges. The major limitation of previous methods is that they
try to identify the salient regions and estimate the accurate objects
boundaries simultaneously with a single regression task at low-resolution. This
practice ignores the inherent difference between the two difficult problems,
resulting in poor detection quality. In this paper, we propose a novel deep
learning framework for high-resolution SOD task, which disentangles the task
into a low-resolution saliency classification network (LRSCN) and a
high-resolution refinement network (HRRN). As a pixel-wise classification task,
LRSCN is designed to capture sufficient semantics at low-resolution to identify
the definite salient, background and uncertain image regions. HRRN is a
regression task, which aims at accurately refining the saliency value of pixels
in the uncertain region to preserve a clear object boundary at high-resolution
with limited GPU memory. It is worth noting that by introducing uncertainty
into the training process, our HRRN can well address the high-resolution
refinement task without using any high-resolution training data. Extensive
experiments on high-resolution saliency datasets as well as some widely used
saliency benchmarks show that the proposed method achieves superior performance
compared to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging. (arXiv:2108.03233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Saffar_A/0/1/0/all/0/1">A. Al-Saffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Stancombe_A/0/1/0/all/0/1">A. Stancombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_A/0/1/0/all/0/1">A. Zamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbosh_A/0/1/0/all/0/1">A. Abbosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03233">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject&#x27;s movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deformable Image Registration using Neural ODEs. (arXiv:2108.03443v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yifan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiahao_T/0/1/0/all/0/1">Tom Z.Jiahao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiancong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yushkevich_P/0/1/0/all/0/1">Paul A.Yushkevich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gee_J/0/1/0/all/0/1">James C.Gee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_M/0/1/0/all/0/1">M.Ani Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03443">
                                    <div class="article-summary-box-inner">
                                        <span>Deformable image registration, aiming to find spatial correspondence between
a given image pair, is one of the most critical problems in the domain of
medical image analysis. In this paper, we present a generic, fast, and accurate
diffeomorphic image registration framework that leverages neural ordinary
differential equations (NODEs). We model each voxel as a moving particle and
consider the set of all voxels in a 3D image as a high-dimensional dynamical
system whose trajectory determines the targeted deformation field. Compared
with traditional optimization-based methods, our framework reduces the running
time from tens of minutes to tens of seconds. Compared with recent data-driven
deep learning methods, our framework is more accessible since it does not
require large amounts of training data. Our experiments show that the
registration results of our method outperform state-of-the-arts under various
metrics, indicating that our modeling approach is well fitted for the task of
deformable image registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Portrait Shadow Removal via Generative Priors. (arXiv:2108.03466v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yingqing He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1">Yazhou Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianjia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03466">
                                    <div class="article-summary-box-inner">
                                        <span>Portrait images often suffer from undesirable shadows cast by casual objects
or even the face itself. While existing methods for portrait shadow removal
require training on a large-scale synthetic dataset, we propose the first
unsupervised method for portrait shadow removal without any training data. Our
key idea is to leverage the generative facial priors embedded in the
off-the-shelf pretrained StyleGAN2. To achieve this, we formulate the shadow
removal task as a layer decomposition problem: a shadowed portrait image is
constructed by the blending of a shadow image and a shadow-free image. We
propose an effective progressive optimization algorithm to learn the
decomposition process. Our approach can also be extended to portrait tattoo
removal and watermark removal. Qualitative and quantitative experiments on a
real-world portrait shadow dataset demonstrate that our approach achieves
comparable performance with supervised shadow removal methods. Our source code
is available at
https://github.com/YingqingHe/Shadow-Removal-via-Generative-Priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Indoor Layouts from Simple Point-Clouds. (arXiv:2108.03378v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_M/0/1/0/all/0/1">Md. Tareq Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohammed Eunus Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03378">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing a layout of indoor spaces has been a crucial part of growing
indoor location based services. One of the key challenges in the proliferation
of indoor location based services is the unavailability of indoor spatial maps
due to the complex nature of capturing an indoor space model (e.g., floor plan)
of an existing building. In this paper, we propose a system to automatically
generate floor plans that can recognize rooms from the point-clouds obtained
through smartphones like Google&#x27;s Tango. In particular, we propose two
approaches - a Recurrent Neural Network based approach using Pointer Network
and a Convolutional Neural Network based approach using Mask-RCNN to identify
rooms (and thereby floor plans) from point-clouds. Experimental results on
different datasets demonstrate approximately 0.80-0.90 Intersection-over-Union
scores, which show that our models can effectively identify the rooms and
regenerate the shapes of the rooms in heterogeneous environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of Aliasing on Generalization in Deep Convolutional Networks. (arXiv:2108.03489v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1">Rob Romijnders</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Goroshin_R/0/1/0/all/0/1">Ross Goroshin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03489">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NASOA: Towards Faster Task-oriented Online Fine-tuning with a Zoo of Models. (arXiv:2108.03434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1">Ning Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gengwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chuanlong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03434">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-tuning from pre-trained ImageNet models has been a simple, effective,
and popular approach for various computer vision tasks. The common practice of
fine-tuning is to adopt a default hyperparameter setting with a fixed
pre-trained model, while both of them are not optimized for specific tasks and
time constraints. Moreover, in cloud computing or GPU clusters where the tasks
arrive sequentially in a stream, faster online fine-tuning is a more desired
and realistic strategy for saving money, energy consumption, and CO2 emission.
In this paper, we propose a joint Neural Architecture Search and Online
Adaption framework named NASOA towards a faster task-oriented fine-tuning upon
the request of users. Specifically, NASOA first adopts an offline NAS to
identify a group of training-efficient networks to form a pretrained model zoo.
We propose a novel joint block and macro-level search space to enable a
flexible and efficient search. Then, by estimating fine-tuning performance via
an adaptive model by accumulating experience from the past tasks, an online
schedule generator is proposed to pick up the most suitable model and generate
a personalized training regime with respect to each desired task in a one-shot
fashion. The resulting model zoo is more training efficient than SOTA models,
e.g. 6x faster than RegNetY-16GF, and 1.7x faster than EfficientNetB3.
Experiments on multiple datasets also show that NASOA achieves much better
fine-tuning results, i.e. improving around 2.1% accuracy than the best
performance in RegNet series under various constraints and tasks; 40x faster
compared to the BOHB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stereo Waterdrop Removal with Row-wise Dilated Attention. (arXiv:2108.03457v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1">Dit-Yan Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03457">
                                    <div class="article-summary-box-inner">
                                        <span>Existing vision systems for autonomous driving or robots are sensitive to
waterdrops adhered to windows or camera lenses. Most recent waterdrop removal
approaches take a single image as input and often fail to recover the missing
content behind waterdrops faithfully. Thus, we propose a learning-based model
for waterdrop removal with stereo images. To better detect and remove
waterdrops from stereo images, we propose a novel row-wise dilated attention
module to enlarge attention&#x27;s receptive field for effective information
propagation between the two stereo images. In addition, we propose an attention
consistency loss between the ground-truth disparity map and attention scores to
enhance the left-right consistency in stereo images. Because of related
datasets&#x27; unavailability, we collect a real-world dataset that contains stereo
images with and without waterdrops. Extensive experiments on our dataset
suggest that our model outperforms state-of-the-art methods both quantitatively
and qualitatively. Our source code and the stereo waterdrop dataset are
available at
\href{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeafMask: Towards Greater Accuracy on Leaf Segmentation. (arXiv:2108.03568v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1">Ruohao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liao Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1">Dantong Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_J/0/1/0/all/0/1">Jun Yue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03568">
                                    <div class="article-summary-box-inner">
                                        <span>Leaf segmentation is the most direct and effective way for high-throughput
plant phenotype data analysis and quantitative researches of complex traits.
Currently, the primary goal of plant phenotyping is to raise the accuracy of
the autonomous phenotypic measurement. In this work, we present the LeafMask
neural network, a new end-to-end model to delineate each leaf region and count
the number of leaves, with two main components: 1) the mask assembly module
merging position-sensitive bases of each predicted box after non-maximum
suppression (NMS) and corresponding coefficients to generate original masks; 2)
the mask refining module elaborating leaf boundaries from the mask assembly
module by the point selection strategy and predictor. In addition, we also
design a novel and flexible multi-scale attention module for the dual
attention-guided mask (DAG-Mask) branch to effectively enhance information
expression and produce more accurate bases. Our main contribution is to
generate the final improved masks by combining the mask assembly module with
the mask refining module under the anchor-free instance segmentation paradigm.
We validate our LeafMask through extensive experiments on Leaf Segmentation
Challenge (LSC) dataset. Our proposed model achieves the 90.09% BestDice score
outperforming other state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adversarial Disentangling for Specific Domain Adaptation. (arXiv:2108.03553v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Qianyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Qiqi Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhengyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jianping Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lizhuang Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03553">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation aims to bridge the domain shifts between the source and
target domains. These shifts may span different dimensions such as fog,
rainfall, etc. However, recent methods typically do not consider explicit prior
knowledge on a specific dimension, thus leading to less desired adaptation
performance. In this paper, we study a practical setting called Specific Domain
Adaptation (SDA) that aligns the source and target domains in a
demanded-specific dimension. Within this setting, we observe the intra-domain
gap induced by different domainness (i.e., numerical magnitudes of this
dimension) is crucial when adapting to a specific domain. To address the
problem, we propose a novel Self-Adversarial Disentangling (SAD) framework. In
particular, given a specific dimension, we first enrich the source domain by
introducing a domainness creator with providing additional supervisory signals.
Guided by the created domainness, we design a self-adversarial regularizer and
two loss functions to jointly disentangle the latent representations into
domainness-specific and domainness-invariant features, thus mitigating the
intra-domain gap. Our method can be easily taken as a plug-and-play framework
and does not introduce any extra costs in the inference time. We achieve
consistent improvements over state-of-the-art methods in both object detection
and semantic segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Attention Mechanism and Knowledge Distillation for Lip Reading. (arXiv:2108.03543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elashmawy_S/0/1/0/all/0/1">Shahd Elashmawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramsis_M/0/1/0/all/0/1">Marian Ramsis</a>, <a href="http://arxiv.org/find/cs/1/au:+Eraqi_H/0/1/0/all/0/1">Hesham M. Eraqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Eldeshnawy_F/0/1/0/all/0/1">Farah Eldeshnawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mabrouk_H/0/1/0/all/0/1">Hadeel Mabrouk</a>, <a href="http://arxiv.org/find/cs/1/au:+Abugabal_O/0/1/0/all/0/1">Omar Abugabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakr_N/0/1/0/all/0/1">Nourhan Sakr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03543">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the advancement in the domain of audio and audio-visual speech
recognition, visual speech recognition systems are still quite under-explored
due to the visual ambiguity of some phonemes. In this work, we propose a new
lip-reading model that combines three contributions. First, the model front-end
adopts a spatio-temporal attention mechanism to help extract the informative
data from the input visual frames. Second, the model back-end utilizes a
sequence-level and frame-level Knowledge Distillation (KD) techniques that
allow leveraging audio data during the visual model training. Third, a data
preprocessing pipeline is adopted that includes facial landmarks
detection-based lip-alignment. On LRW lip-reading dataset benchmark, a
noticeable accuracy improvement is demonstrated; the spatio-temporal attention,
Knowledge Distillation, and lip-alignment contributions achieved 88.43%,
88.64%, and 88.37% respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">(Just) A Spoonful of Refinements Helps the Registration Error Go Down. (arXiv:2108.03257v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agostinho_S/0/1/0/all/0/1">S&#xe9;rgio Agostinho</a>, <a href="http://arxiv.org/find/cs/1/au:+Osep_A/0/1/0/all/0/1">Aljo&#x161;a O&#x161;ep</a>, <a href="http://arxiv.org/find/cs/1/au:+Bue_A/0/1/0/all/0/1">Alessio Del Bue</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03257">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle data-driven 3D point cloud registration. Given point
correspondences, the standard Kabsch algorithm provides an optimal rotation
estimate. This allows to train registration models in an end-to-end manner by
differentiating the SVD operation. However, given the initial rotation estimate
supplied by Kabsch, we show we can improve point correspondence learning during
model training by extending the original optimization problem. In particular,
we linearize the governing constraints of the rotation matrix and solve the
resulting linear system of equations. We then iteratively produce new solutions
by updating the initial estimate. Our experiments show that, by plugging our
differentiable layer to existing learning-based registration methods, we
improve the correspondence matching quality. This yields up to a 7% decrease in
rotation error for correspondence-based data-driven registration methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution. (arXiv:2108.03541v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1">Eric Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_V/0/1/0/all/0/1">Vishy Swaminathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03541">
                                    <div class="article-summary-box-inner">
                                        <span>Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
object&#x27;s visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Categorized Reflection Removal Dataset with Diverse Real-world Scenes. (arXiv:2108.03380v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1">Chenyang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuhua Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1">Chenyang Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yankun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wenxiu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1">Qiong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03380">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the lack of a large-scale reflection removal dataset with diverse
real-world scenes, many existing reflection removal methods are trained on
synthetic data plus a small amount of real-world data, which makes it difficult
to evaluate the strengths or weaknesses of different reflection removal methods
thoroughly. Furthermore, existing real-world benchmarks and datasets do not
categorize image data based on the types and appearances of reflection (e.g.,
smoothness, intensity), making it hard to analyze reflection removal methods.
Hence, we construct a new reflection removal dataset that is categorized,
diverse, and real-world (CDR). A pipeline based on RAW data is used to capture
perfectly aligned input images and transmission images. The dataset is
constructed using diverse glass types under various environments to ensure
diversity. By analyzing several reflection removal methods and conducting
extensive experiments on our dataset, we show that state-of-the-art reflection
removal methods generally perform well on blurry reflection but fail in
obtaining satisfying performance on other types of real-world reflection. We
believe our dataset can help develop novel methods to remove real-world
reflection better. Our dataset is available at
https://alexzhao-hugga.github.io/Real-World-Reflection-Removal/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Facial Representations from the Cycle-consistency of Face. (arXiv:2108.03427v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jia-Ren Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yong-Sheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1">Wei-Chen Chiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03427">
                                    <div class="article-summary-box-inner">
                                        <span>Faces manifest large variations in many aspects, such as identity,
expression, pose, and face styling. Therefore, it is a great challenge to
disentangle and extract these characteristics from facial images, especially in
an unsupervised manner. In this work, we introduce cycle-consistency in facial
characteristics as free supervisory signal to learn facial representations from
unlabeled facial images. The learning is realized by superimposing the facial
motion cycle-consistency and identity cycle-consistency constraints. The main
idea of the facial motion cycle-consistency is that, given a face with
expression, we can perform de-expression to a neutral face via the removal of
facial motion and further perform re-expression to reconstruct back to the
original face. The main idea of the identity cycle-consistency is to exploit
both de-identity into mean face by depriving the given neutral face of its
identity via feature re-normalization and re-identity into neutral face by
adding the personal attributes to the mean face. At training time, our model
learns to disentangle two distinct facial representations to be useful for
performing cycle-consistent face reconstruction. At test time, we use the
linear protocol scheme for evaluating facial representations on various tasks,
including facial expression recognition and head pose regression. We also can
directly apply the learnt facial representations to person recognition,
frontalization and image-to-image translation. Our experiments show that the
results of our approach is competitive with those of existing methods,
demonstrating the rich and unique information embedded in the disentangled
representations. Code is available at https://github.com/JiaRenChang/FaceCycle .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expressive Power and Loss Surfaces of Deep Learning Models. (arXiv:2108.03579v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dube_S/0/1/0/all/0/1">Simant Dube</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03579">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this paper are two-fold. The first goal is to serve as an
expository tutorial on the working of deep learning models which emphasizes
geometrical intuition about the reasons for success of deep learning. The
second goal is to complement the current results on the expressive power of
deep learning models and their loss surfaces with novel insights and results.
In particular, we describe how deep neural networks carve out manifolds
especially when the multiplication neurons are introduced. Multiplication is
used in dot products and the attention mechanism and it is employed in capsule
networks and self-attention based transformers. We also describe how random
polynomial, random matrix, spin glass and computational complexity perspectives
on the loss surfaces are interconnected.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Right to Talk: An Audio-Visual Transformer Approach. (arXiv:2108.03256v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Dat Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1">Chi Nhan Duong</a>, The <a href="http://arxiv.org/find/cs/1/au:+Vu_D/0/1/0/all/0/1">De Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hoang Anh Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1">Bhiksha Raj</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Khoa Luu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03256">
                                    <div class="article-summary-box-inner">
                                        <span>Turn-taking has played an essential role in structuring the regulation of a
conversation. The task of identifying the main speaker (who is properly taking
his/her turn of speaking) and the interrupters (who are interrupting or
reacting to the main speaker&#x27;s utterances) remains a challenging task. Although
some prior methods have partially addressed this task, there still remain some
limitations. Firstly, a direct association of Audio and Visual features may
limit the correlations to be extracted due to different modalities. Secondly,
the relationship across temporal segments helping to maintain the consistency
of localization, separation, and conversation contexts is not effectively
exploited. Finally, the interactions between speakers that usually contain the
tracking and anticipatory decisions about the transition to a new speaker are
usually ignored. Therefore, this work introduces a new Audio-Visual Transformer
approach to the problem of localization and highlighting the main speaker in
both audio and visual channels of a multi-speaker conversation video in the
wild. The proposed method exploits different types of correlations presented in
both visual and audio signals. The temporal audio-visual relationships across
spatial-temporal space are anticipated and optimized via the self-attention
mechanism in a Transformerstructure. Moreover, a newly collected dataset is
introduced for the main speaker detection. To the best of our knowledge, it is
one of the first studies that is able to automatically localize and highlight
the main speaker in both visual and audio channels in multi-speaker
conversation videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature-Supervised Action Modality Transfer. (arXiv:2108.03329v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thoker_F/0/1/0/all/0/1">Fida Mohammad Thoker</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03329">
                                    <div class="article-summary-box-inner">
                                        <span>This paper strives for action recognition and detection in video modalities
like RGB, depth maps or 3D-skeleton sequences when only limited
modality-specific labeled examples are available. For the RGB, and derived
optical-flow, modality many large-scale labeled datasets have been made
available. They have become the de facto pre-training choice when recognizing
or detecting new actions from RGB datasets that have limited amounts of labeled
examples available. Unfortunately, large-scale labeled action datasets for
other modalities are unavailable for pre-training. In this paper, our goal is
to recognize actions from limited examples in non-RGB video modalities, by
learning from large-scale labeled RGB data. To this end, we propose a two-step
training process: (i) we extract action representation knowledge from an
RGB-trained teacher network and adapt it to a non-RGB student network. (ii) we
then fine-tune the transfer model with available labeled examples of the target
modality. For the knowledge transfer we introduce feature-supervision
strategies, which rely on unlabeled pairs of two modalities (the RGB and the
target modality) to transfer feature level representations from the teacher to
the student network. Ablations and generalizations with two RGB source datasets
and two non-RGB target datasets demonstrate that an optical-flow teacher
provides better action transfer features than RGB for both depth maps and
3D-skeletons, even when evaluated on a different target domain, or for a
different task. Compared to alternative cross-modal action transfer methods we
show a good improvement in performance especially when labeled non-RGB examples
to learn from are scarce</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Action Localization Using Gated Recurrent Units. (arXiv:2108.03375v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khojasteh_H/0/1/0/all/0/1">Hassan Keshvari Khojasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadzade_H/0/1/0/all/0/1">Hoda Mohammadzade</a>, <a href="http://arxiv.org/find/cs/1/au:+Behroozi_H/0/1/0/all/0/1">Hamid Behroozi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03375">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal Action Localization (TAL) task in which the aim is to predict the
start and end of each action and its class label has many applications in the
real world. But due to its complexity, researchers have not reached great
results compared to the action recognition task. The complexity is related to
predicting precise start and end times for different actions in any video. In
this paper, we propose a new network based on Gated Recurrent Unit (GRU) and
two novel post-processing ideas for TAL task. Specifically, we propose a new
design for the output layer of the GRU resulting in the so-called GRU-Splitted
model. Moreover, linear interpolation is used to generate the action proposals
with precise start and end times. Finally, to rank the generated proposals
appropriately, we use a Learn to Rank (LTR) approach. We evaluated the
performance of the proposed method on Thumos14 dataset. Results show the
superiority of the performance of the proposed method compared to
state-of-the-art. Especially in the mean Average Precision (mAP) metric at
Intersection over Union (IoU) 0.7, we get 27.52% which is 5.12% better than
that of state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. (arXiv:2108.03272v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dharan_G/0/1/0/all/0/1">Gokul Dharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1">Tanish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1">Andrey Kurenkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing MR Image Segmentation with Realistic Adversarial Data Augmentation. (arXiv:2108.03429v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1">Huaqi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarroni_G/0/1/0/all/0/1">Giacomo Tarroni</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03429">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural networks on medical image segmentation tasks typically
relies on large labeled datasets for model training. However, acquiring and
manually labeling a large medical image set is resource-intensive, expensive,
and sometimes impractical due to data sharing and privacy issues. To address
this challenge, we propose an adversarial data augmentation approach to improve
the efficiency in utilizing training data and to enlarge the dataset via
simulated but realistic transformations. Specifically, we present a generic
task-driven learning framework, which jointly optimizes a data augmentation
model and a segmentation network during training, generating informative
examples to enhance network generalizability for the downstream task. The data
augmentation model utilizes a set of photometric and geometric image
transformations and chains them to simulate realistic complex imaging
variations that could exist in magnetic resonance (MR) imaging. The proposed
adversarial data augmentation does not rely on generative networks and can be
used as a plug-in module in general segmentation networks. It is
computationally efficient and applicable for both supervised and
semi-supervised learning. We analyze and evaluate the method on two MR image
segmentation tasks: cardiac segmentation and prostate segmentation. Results
show that the proposed approach can alleviate the need for labeled data while
improving model generalization ability, indicating its practical value in
medical imaging applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reducing Annotating Load: Active Learning with Synthetic Images in Surgical Instrument Segmentation. (arXiv:2108.03534v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Haonan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+King_D/0/1/0/all/0/1">Daniel King</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yun-Hsuan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Bly_R/0/1/0/all/0/1">Randall A. Bly</a>, <a href="http://arxiv.org/find/cs/1/au:+Moe_K/0/1/0/all/0/1">Kris S. Moe</a>, <a href="http://arxiv.org/find/cs/1/au:+Hannaford_B/0/1/0/all/0/1">Blake Hannaford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03534">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate instrument segmentation in endoscopic vision of robot-assisted
surgery is challenging due to reflection on the instruments and frequent
contacts with tissue. Deep neural networks (DNN) show competitive performance
and are in favor in recent years. However, the hunger of DNN for labeled data
poses a huge workload of annotation. Motivated by alleviating this workload, we
propose a general embeddable method to decrease the usage of labeled real
images, using active generated synthetic images. In each active learning
iteration, the most informative unlabeled images are first queried by active
learning and then labeled. Next, synthetic images are generated based on these
selected images. The instruments and backgrounds are cropped out and randomly
combined with each other with blending and fusion near the boundary. The
effectiveness of the proposed method is validated on 2 sinus surgery datasets
and 1 intraabdominal surgery dataset. The results indicate a considerable
improvement in performance, especially when the budget for annotation is small.
The effectiveness of different types of synthetic images, blending methods, and
external background are also studied. All the code is open-sourced at:
https://github.com/HaonanPeng/active_syn_generator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical image segmentation with imperfect 3D bounding boxes. (arXiv:2108.03300v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Redekop_E/0/1/0/all/0/1">Ekaterina Redekop</a>, <a href="http://arxiv.org/find/cs/1/au:+Chernyavskiy_A/0/1/0/all/0/1">Alexey Chernyavskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03300">
                                    <div class="article-summary-box-inner">
                                        <span>The development of high quality medical image segmentation algorithms depends
on the availability of large datasets with pixel-level labels. The challenges
of collecting such datasets, especially in case of 3D volumes, motivate to
develop approaches that can learn from other types of labels that are cheap to
obtain, e.g. bounding boxes. We focus on 3D medical images with their
corresponding 3D bounding boxes which are considered as series of per-slice
non-tight 2D bounding boxes. While current weakly-supervised approaches that
use 2D bounding boxes as weak labels can be applied to medical image
segmentation, we show that their success is limited in cases when the
assumption about the tightness of the bounding boxes breaks. We propose a new
bounding box correction framework which is trained on a small set of
pixel-level annotations to improve the tightness of a larger set of non-tight
bounding box annotations. The effectiveness of our solution is demonstrated by
evaluating a known weakly-supervised segmentation approach with and without the
proposed bounding box correction algorithm. When the tightness is improved by
our solution, the results of the weakly-supervised segmentation become much
closer to those of the fully-supervised one.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation. (arXiv:2108.03267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thanh-Dat Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1">Chi Nhan Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_S/0/1/0/all/0/1">Son Lam Phung</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainwater_C/0/1/0/all/0/1">Chase Rainwater</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Khoa Luu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03267">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation aims to predict pixel-level labels. It has become a
popular task in various computer vision applications. While fully supervised
segmentation methods have achieved high accuracy on large-scale vision
datasets, they are unable to generalize on a new test environment or a new
domain well. In this work, we first introduce a new Un-aligned Domain Score to
measure the efficiency of a learned model on a new target domain in
unsupervised manner. Then, we present the new Bijective Maximum
Likelihood(BiMaL) loss that is a generalized form of the Adversarial Entropy
Minimization without any assumption about pixel independence. We have evaluated
the proposed BiMaL on two domains. The proposed BiMaL approach consistently
outperforms the SOTA methods on empirical experiments on &quot;SYNTHIA to
Cityscapes&quot;, &quot;GTA5 to Cityscapes&quot;, and &quot;SYNTHIA to Vistas&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PSViT: Better Vision Transformer via Token Pooling and Attention Sharing. (arXiv:2108.03428v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03428">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we observe two levels of redundancies when applying vision
transformers (ViT) for image recognition. First, fixing the number of tokens
through the whole network produces redundant features at the spatial level.
Second, the attention maps among different transformer layers are redundant.
Based on the observations above, we propose a PSViT: a ViT with token Pooling
and attention Sharing to reduce the redundancy, effectively enhancing the
feature representation ability, and achieving a better speed-accuracy
trade-off. Specifically, in our PSViT, token pooling can be defined as the
operation that decreases the number of tokens at the spatial level. Besides,
attention sharing will be built between the neighboring transformer layers for
reusing the attention maps having a strong correlation among adjacent layers.
Then, a compact set of the possible combinations for different token pooling
and attention sharing mechanisms are constructed. Based on the proposed compact
set, the number of tokens in each layer and the choices of layers sharing
attention can be treated as hyper-parameters that are learned from data
automatically. Experimental results show that the proposed scheme can achieve
up to 6.6% accuracy improvement in ImageNet classification compared with the
DeiT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighborhood Consensus Contrastive Learning for Backward-Compatible Representation. (arXiv:2108.03372v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shengsen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yihang Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+YanBai/0/1/0/all/0/1">YanBai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Tao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1">Minghua Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_L/0/1/0/all/0/1">Lingyu Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03372">
                                    <div class="article-summary-box-inner">
                                        <span>In object re-identification (ReID), the development of deep learning
techniques often involves model update and deployment. It is unbearable to
re-extract image features of the large-scale gallery when deploying new models.
Therefore, backward-compatible representation is proposed to enable the &quot;new&quot;
features compatible with &quot;old&quot;&#x27; features, free from the re-extracting process.
The existing backward-compatible methods simply conduct constraints in the
embedding space or discriminative space and ignore the intra-class variance of
the old embeddings, resulting in a risk of damaging the discriminability of new
embeddings.

In this work, we propose a Neighborhood Consensus Contrastive Learning (NCCL)
method, which learns backward-compatible representation from a neighborhood
consensus perspective with both embedding structures and discriminative
knowledge. With NCCL, the new embeddings are aligned and improved with old
embeddings in a multi-cluster view. Besides, we also propose a scheme to filter
the old embeddings with low credibility, which can further improve the
compatibility robustness. Our method ensures backward compatibility without
impairing the accuracy of the new model. And it can even improve the new
model&#x27;s accuracy in most scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles. (arXiv:2108.03344v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuxiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_M/0/1/0/all/0/1">Mark W. Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreenath_K/0/1/0/all/0/1">Koushil Sreenath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03344">
                                    <div class="article-summary-box-inner">
                                        <span>The capabilities of autonomous flight with unmanned aerial vehicles (UAVs)
have significantly increased in recent times. However, basic problems such as
fast and robust geo-localization in GPS-denied environments still remain
unsolved. Existing research has primarily concentrated on improving the
accuracy of localization at the cost of long and varying computation time in
various situations, which often necessitates the use of powerful ground station
machines. In order to make image-based geo-localization online and pragmatic
for lightweight embedded systems on UAVs, we propose a framework that is
reliable in changing scenes, flexible about computing resource allocation and
adaptable to common camera placements. The framework is comprised of two
stages: offline database preparation and online inference. At the first stage,
color images and depth maps are rendered as seen from potential vehicle poses
quantized over the satellite and topography maps of anticipated flying areas. A
database is then populated with the global and local descriptors of the
rendered images. At the second stage, for each captured real-world query image,
top global matches are retrieved from the database and the vehicle pose is
further refined via local descriptor matching. We present field experiments of
image-based localization on two different UAV platforms to validate our
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Models for the First-stage Retrieval: A Comprehensive Review. (arXiv:2103.04831v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yinqiong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yixing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiafeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xueqi Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04831">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-stage ranking pipelines have been a practical solution in modern search
systems, where the first-stage retrieval is to return a subset of candidate
documents, and latter stages attempt to re-rank those candidates. Unlike
re-ranking stages going through quick technique shifts during past decades, the
first-stage retrieval has long been dominated by classical term-based models.
Unfortunately, these models suffer from the vocabulary mismatch problem, which
may block re-ranking stages from relevant documents at the very beginning.
Therefore, it has been a long-term desire to build semantic models for the
first-stage retrieval that can achieve high recall efficiently. Recently, we
have witnessed an explosive growth of research interests on the first-stage
semantic retrieval models. We believe it is the right time to survey current
status, learn from existing methods, and gain some insights for future
development. In this paper, we describe the current landscape of the
first-stage retrieval models under a unified framework to clarify the
connection between classical term-based retrieval methods, early semantic
retrieval methods and neural semantic retrieval methods. Moreover, we identify
some open challenges and envision some future directions, with the hope of
inspiring more researches on these important yet less investigated topics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Accurate Localization by Instance Search. (arXiv:2107.05005v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi-Geng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hui-Chu Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05005">
                                    <div class="article-summary-box-inner">
                                        <span>Visual object localization is the key step in a series of object detection
tasks. In the literature, high localization accuracy is achieved with the
mainstream strongly supervised frameworks. However, such methods require
object-level annotations and are unable to detect objects of unknown
categories. Weakly supervised methods face similar difficulties. In this paper,
a self-paced learning framework is proposed to achieve accurate object
localization on the rank list returned by instance search. The proposed
framework mines the target instance gradually from the queries and their
corresponding top-ranked search results. Since a common instance is shared
between the query and the images in the rank list, the target visual instance
can be accurately localized even without knowing what the object category is.
In addition to performing localization on instance search, the issue of
few-shot object detection is also addressed under the same framework. Superior
performance over state-of-the-art methods is observed on both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Relative Order Attack in Deep Ranking. (arXiv:2103.05248v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tag Embedding Based Personalized Point Of Interest Recommendation System. (arXiv:2004.06389v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Suraj Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1">Dwaipayan Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_M/0/1/0/all/0/1">Mandar Mitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06389">
                                    <div class="article-summary-box-inner">
                                        <span>Personalized Point of Interest recommendation is very helpful for satisfying
users&#x27; needs at new places. In this article, we propose a tag embedding based
method for Personalized Recommendation of Point Of Interest. We model the
relationship between tags corresponding to Point Of Interest. The model
provides representative embedding corresponds to a tag in a way that related
tags will be closer. We model Point of Interest-based on tag embedding and also
model the users (user profile) based on the Point Of Interest rated by them.
finally, we rank the user&#x27;s candidate Point Of Interest based on cosine
similarity between user&#x27;s embedding and Point of Interest&#x27;s embedding. Further,
we find the parameters required to model user by discrete optimizing over
different measures (like ndcg@5, MRR, ...). We also analyze the result while
considering the same parameters for all users and individual parameters for
each user. Along with it we also analyze the effect on the result while
changing the dataset to model the relationship between tags. Our method also
minimizes the privacy leak issue. We used TREC Contextual Suggestion 2016 Phase
2 dataset and have significant improvement over all the measures on the state
of the art method. It improves ndcg@5 by 12.8%, p@5 by 4.3%, and MRR by 7.8%,
which shows the effectiveness of the method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions. (arXiv:1811.00414v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00414">
                                    <div class="article-summary-box-inner">
                                        <span>A central roadblock to analyzing quantum algorithms on quantum states is the
lack of a comparable input model for classical algorithms. Inspired by recent
work of the author [E. Tang, STOC&#x27;19], we introduce such a model, where we
assume we can efficiently perform $\ell^2$-norm samples of input data, a
natural analogue to quantum algorithms that assume efficient state preparation
of classical data. Though this model produces less practical algorithms than
the (stronger) standard model of classical computation, it captures versions of
many of the features and nuances of quantum linear algebra algorithms. With
this model, we describe classical analogues to Lloyd, Mohseni, and Rebentrost&#x27;s
quantum algorithms for principal component analysis [Nat. Phys. 10, 631 (2014)]
and nearest-centroid clustering [arXiv:1307.0411]. Since they are only
polynomially slower, these algorithms suggest that the exponential speedups of
their quantum counterparts are simply an artifact of state preparation
assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generation-Augmented Retrieval for Open-domain Question Answering. (arXiv:2009.08553v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08553">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rider: Reader-Guided Passage Reranking for Open-Domain Question Answering. (arXiv:2101.00294v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1">Yuning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiawei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00294">
                                    <div class="article-summary-box-inner">
                                        <span>Current open-domain question answering systems often follow a
Retriever-Reader architecture, where the retriever first retrieves relevant
passages and the reader then reads the retrieved passages to form an answer. In
this paper, we propose a simple and effective passage reranking method, named
Reader-guIDEd Reranker (RIDER), which does not involve training and reranks the
retrieved passages solely based on the top predictions of the reader before
reranking. We show that RIDER, despite its simplicity, achieves 10 to 20
absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) gains
without refining the retriever or reader. In addition, RIDER, without any
training, outperforms state-of-the-art transformer-based supervised rerankers.
Remarkably, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 EM
on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are
used as the reader input after passage reranking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DCAP: Deep Cross Attentional Product Network for User Response Prediction. (arXiv:2105.08649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                    <div class="article-summary-box-inner">
                                        <span>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network&#x27;s benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Retrieval of Tables and Texts Using Tri-encoder Models. (arXiv:2108.04049v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kostic_B/0/1/0/all/0/1">Bogdan Kosti&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Risch_J/0/1/0/all/0/1">Julian Risch</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Timo M&#xf6;ller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04049">
                                    <div class="article-summary-box-inner">
                                        <span>Open-domain extractive question answering works well on textual data by first
retrieving candidate texts and then extracting the answer from those
candidates. However, some questions cannot be answered by text alone but
require information stored in tables. In this paper, we present an approach for
retrieving both texts and tables relevant to a question by jointly encoding
texts, tables and questions into a single vector space. To this end, we create
a new multi-modal dataset based on text and table datasets from related work
and compare the retrieval performance of different encoding schemata. We find
that dense vector embeddings of transformer models outperform sparse embeddings
on four out of six evaluation datasets. Comparing different dense embedding
models, tri-encoders, with one encoder for each question, text and table,
increase retrieval performance compared to bi-encoders with one encoder for the
question and one for both text and tables. We release the newly created
multi-modal dataset to the community so that it can be used for training and
evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DGEM: A New Dual-modal Graph Embedding Method in Recommendation System. (arXiv:2108.04031v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huimin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhuyun Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04031">
                                    <div class="article-summary-box-inner">
                                        <span>In the current deep learning based recommendation system, the embedding
method is generally employed to complete the conversion from the
high-dimensional sparse feature vector to the low-dimensional dense feature
vector. However, as the dimension of the input vector of the embedding layer is
too large, the addition of the embedding layer significantly slows down the
convergence speed of the entire neural network, which is not acceptable in
real-world scenarios. In addition, as the interaction between users and items
increases and the relationship between items becomes more complicated, the
embedding method proposed for sequence data is no longer suitable for graphic
data in the current real environment. Therefore, in this paper, we propose the
Dual-modal Graph Embedding Method (DGEM) to solve these problems. DGEM includes
two modes, static and dynamic. We first construct the item graph to extract the
graph structure and use random walk of unequal probability to capture the
high-order proximity between the items. Then we generate the graph embedding
vector through the Skip-Gram model, and finally feed the downstream deep neural
network for the recommendation task. The experimental results show that DGEM
can mine the high-order proximity between items and enhance the expression
ability of the recommendation model. Meanwhile it also improves the
recommendation performance by utilizing the time dependent relationship between
items.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models. (arXiv:2108.04024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Opazo_C/0/1/0/all/0/1">Cristian Rodriguez-Opazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1">Damien Teney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04024">
                                    <div class="article-summary-box-inner">
                                        <span>We extend the task of composed image retrieval, where an input query consists
of an image and short textual description of how to modify the image. Existing
methods have only been applied to non-complex images within narrow domains,
such as fashion products, thereby limiting the scope of study on in-depth
visual reasoning in rich image and language contexts. To address this issue, we
collect the Compose Image Retrieval on Real-life images (CIRR) dataset, which
consists of over 36,000 pairs of crowd-sourced, open-domain images with
human-generated modifying text. To extend current methods to the open-domain,
we propose CIRPLANT, a transformer based model that leverages rich pre-trained
vision-and-language (V&amp;L) knowledge for modifying visual features conditioned
on natural language. Retrieval is then done by nearest neighbor lookup on the
modified features. We demonstrate that with a relatively simple architecture,
CIRPLANT outperforms existing methods on open-domain images, while matching
state-of-the-art accuracy on the existing narrow datasets, such as fashion.
Together with the release of CIRR, we believe this work will inspire further
research on composed image retrieval.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IntenT5: Search Result Diversification using Causal Language Models. (arXiv:2108.04026v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+MacAvaney_S/0/1/0/all/0/1">Sean MacAvaney</a>, <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Murray_Smith_R/0/1/0/all/0/1">Roderick Murray-Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04026">
                                    <div class="article-summary-box-inner">
                                        <span>Search result diversification is a beneficial approach to overcome
under-specified queries, such as those that are ambiguous or multi-faceted.
Existing approaches often rely on massive query logs and interaction data to
generate a variety of possible query intents, which then can be used to re-rank
documents. However, relying on user interaction data is problematic because one
first needs a massive user base to build a sufficient log; public query logs
are insufficient on their own. Given the recent success of causal language
models (such as the Text-To-Text Transformer (T5) model) at text generation
tasks, we explore the capacity of these models to generate potential query
intents. We find that to encourage diversity in the generated queries, it is
beneficial to adapt the model by including a new Distributional Causal Language
Modeling (DCLM) objective during fine-tuning and a representation replacement
during inference. Across six standard evaluation benchmarks, we find that our
method (which we call IntenT5) improves search result diversity and attains
(and sometimes exceeds) the diversity obtained when using query suggestions
based on a proprietary query log. Our analysis shows that our approach is most
effective for multi-faceted queries and is able to generalize effectively to
queries that were unseen in training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Joint Embedding with Modality Alignments for Cross-Modal Retrieval of Recipes and Food Images. (arXiv:2108.03788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03788">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a three-tier modality alignment approach to learning
text-image joint embedding, coined as JEMA, for cross-modal retrieval of
cooking recipes and food images. The first tier improves recipe text embedding
by optimizing the LSTM networks with term extraction and ranking enhanced
sequence patterns, and optimizes the image embedding by combining the
ResNeXt-101 image encoder with the category embedding using wideResNet-50 with
word2vec. The second tier modality alignment optimizes the textual-visual joint
embedding loss function using a double batch-hard triplet loss with soft-margin
optimization. The third modality alignment incorporates two types of
cross-modality alignments as the auxiliary loss regularizations to further
reduce the alignment errors in the joint learning of the two modality-specific
embedding functions. The category-based cross-modal alignment aims to align the
image category with the recipe category as a loss regularization to the joint
embedding. The cross-modal discriminator-based alignment aims to add the
visual-textual embedding distribution alignment to further regularize the joint
embedding loss. Extensive experiments with the one-million recipes benchmark
dataset Recipe1M demonstrate that the proposed JEMA approach outperforms the
state-of-the-art cross-modal embedding methods for both image-to-recipe and
recipe-to-image retrievals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DoSSIER@COLIEE 2021: Leveraging dense retrieval and summarization-based re-ranking for case law retrieval. (arXiv:2108.03937v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1">Sophia Althammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Askari_A/0/1/0/all/0/1">Arian Askari</a>, <a href="http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1">Suzan Verberne</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03937">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present our approaches for the case law retrieval and the
legal case entailment task in the Competition on Legal Information
Extraction/Entailment (COLIEE) 2021. As first stage retrieval methods combined
with neural re-ranking methods using contextualized language models like BERT
achieved great performance improvements for information retrieval in the web
and news domain, we evaluate these methods for the legal domain. A distinct
characteristic of legal case retrieval is that the query case and case
description in the corpus tend to be long documents and therefore exceed the
input length of BERT. We address this challenge by combining lexical and dense
retrieval methods on the paragraph-level of the cases for the first stage
retrieval. Here we demonstrate that the retrieval on the paragraph-level
outperforms the retrieval on the document-level. Furthermore the experiments
suggest that dense retrieval methods outperform lexical retrieval. For
re-ranking we address the problem of long documents by summarizing the cases
and fine-tuning a BERT-based re-ranker with the summaries. Overall, our best
results were obtained with a combination of BM25 and dense passage retrieval
using domain-specific embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoolRank: Max/Min Pooling-based Ranking Loss for Listwise Learning &amp; Ranking Balance. (arXiv:2108.03586v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhizhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03586">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous neural retrieval models have been proposed in recent years. These
models learn to compute a ranking score between the given query and document.
The majority of existing models are trained in pairwise fashion using
human-judged labels directly without further calibration. The traditional
pairwise schemes can be time-consuming and require pre-defined
positive-negative document pairs for training, potentially leading to learning
bias due to document distribution mismatch between training and test
conditions. Some popular existing listwise schemes rely on the strong
pre-defined probabilistic assumptions and stark difference between relevant and
non-relevant documents for the given query, which may limit the model potential
due to the low-quality or ambiguous relevance labels. To address these
concerns, we turn to a physics-inspired ranking balance scheme and propose
PoolRank, a pooling-based listwise learning framework. The proposed scheme has
four major advantages: (1) PoolRank extracts training information from the best
candidates at the local level based on model performance and relative ranking
among abundant document candidates. (2) By combining four pooling-based loss
components in a multi-task learning fashion, PoolRank calibrates the ranking
balance for the partially relevant and the highly non-relevant documents
automatically without costly human inspection. (3) PoolRank can be easily
generalized to any neural retrieval model without requiring additional
learnable parameters or model structure modifications. (4) Compared to pairwise
learning and existing listwise learning schemes, PoolRank yields better ranking
performance for all studied retrieval models while retaining efficient
convergence rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions. (arXiv:2108.03357v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zang_T/0/1/0/all/0/1">Tianzi Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanmin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haobing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiadi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03357">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional recommendation systems are faced with two long-standing
obstacles, namely, data sparsity and cold-start problems, which promote the
emergence and development of Cross-Domain Recommendation (CDR). The core idea
of CDR is to leverage information collected from other domains to alleviate the
two problems in one domain. Over the last decade, many efforts have been
engaged for cross-domain recommendation. Recently, with the development of deep
learning and neural networks, a large number of methods have emerged. However,
there is a limited number of systematic surveys on CDR, especially regarding
the latest proposed methods as well as the recommendation scenarios and
recommendation tasks they address. In this survey paper, we first proposed a
two-level taxonomy of cross-domain recommendation which classifies different
recommendation scenarios and recommendation tasks. We then introduce and
summarize existing cross-domain recommendation approaches under different
recommendation scenarios in a structured manner. We also organize datasets
commonly used. We conclude this survey by providing several potential research
directions about this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbiased Cascade Bandits: Mitigating Exposure Bias in Online Learning to Rank Recommendation. (arXiv:2108.03440v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mansoury_M/0/1/0/all/0/1">Masoud Mansoury</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdollahpouri_H/0/1/0/all/0/1">Himan Abdollahpouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mobasher_B/0/1/0/all/0/1">Bamshad Mobasher</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Burke_R/0/1/0/all/0/1">Robin Burke</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabouri_M/0/1/0/all/0/1">Milad Sabouri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03440">
                                    <div class="article-summary-box-inner">
                                        <span>Exposure bias is a well-known issue in recommender systems where items and
suppliers are not equally represented in the recommendation results. This is
especially problematic when bias is amplified over time as a few popular items
are repeatedly over-represented in recommendation lists. This phenomenon can be
viewed as a recommendation feedback loop: the system repeatedly recommends
certain items at different time points and interactions of users with those
items will amplify bias towards those items over time. This issue has been
extensively studied in the literature on model-based or neighborhood-based
recommendation algorithms, but less work has been done on online recommendation
models such as those based on multi-armed Bandit algorithms. In this paper, we
study exposure bias in a class of well-known bandit algorithms known as Linear
Cascade Bandits. We analyze these algorithms on their ability to handle
exposure bias and provide a fair representation for items and suppliers in the
recommendation results. Our analysis reveals that these algorithms fail to
treat items and suppliers fairly and do not sufficiently explore the item space
for each user. To mitigate this bias, we propose a discounting factor and
incorporate it into these algorithms that controls the exposure of items at
each time step. To show the effectiveness of the proposed discounting factor on
mitigating exposure bias, we perform experiments on two datasets using three
cascading bandit algorithms and our experimental results show that the proposed
method improves the exposure fairness for items and suppliers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Transformers for Neural Cross-Domain Search. (arXiv:2108.03322v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1">Colin B. Clement</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1">Dawn Drain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1">Neel Sundaresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03322">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained transformers have recently clinched top spots in the gamut of
natural language tasks and pioneered solutions to software engineering tasks.
Even information retrieval has not been immune to the charm of the transformer,
though their large size and cost is generally a barrier to deployment. While
there has been much work in streamlining, caching, and modifying transformer
architectures for production, here we explore a new direction: distilling a
large pre-trained translation model into a lightweight bi-encoder which can be
efficiently cached and queried. We argue from a probabilistic perspective that
sequence-to-sequence models are a conceptually ideal---albeit highly
impractical---retriever. We derive a new distillation objective, implementing
it as a data augmentation scheme. Using natural language source code search as
a case study for cross-domain search, we demonstrate the validity of this idea
by significantly improving upon the current leader of the CodeSearchNet
challenge, a recent natural language code search benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Represent Human Motives for Goal-directed Web Browsing. (arXiv:2108.03350v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jyun-Yu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chia-Jung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Longqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarrafzadeh_B/0/1/0/all/0/1">Bahareh Sarrafzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hecht_B/0/1/0/all/0/1">Brent Hecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Teevan_J/0/1/0/all/0/1">Jaime Teevan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03350">
                                    <div class="article-summary-box-inner">
                                        <span>Motives or goals are recognized in psychology literature as the most
fundamental drive that explains and predicts why people do what they do,
including when they browse the web. Although providing enormous value, these
higher-ordered goals are often unobserved, and little is known about how to
leverage such goals to assist people&#x27;s browsing activities. This paper proposes
to take a new approach to address this problem, which is fulfilled through a
novel neural framework, Goal-directed Web Browsing (GoWeB). We adopt a
psychologically-sound taxonomy of higher-ordered goals and learn to build their
representations in a structure-preserving manner. Then we incorporate the
resulting representations for enhancing the experiences of common activities
people perform on the web. Experiments on large-scale data from Microsoft Edge
web browser show that GoWeB significantly outperforms competitive baselines for
in-session web page recommendation, re-visitation classification, and
goal-based web page grouping. A follow-up analysis further characterizes how
the variety of human motives can affect the difference observed in human
behavioral patterns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Profiling Web Archival Voids for Memento Routing. (arXiv:2108.03311v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1">Sawood Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weigle_M/0/1/0/all/0/1">Michele C. Weigle</a>, <a href="http://arxiv.org/find/cs/1/au:+Nelson_M/0/1/0/all/0/1">Michael L. Nelson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03311">
                                    <div class="article-summary-box-inner">
                                        <span>Prior work on web archive profiling were focused on Archival Holdings to
describe what is present in an archive. This work defines and explores Archival
Voids to establish a means to represent portions of URI spaces that are not
present in a web archive. Archival Holdings and Archival Voids profiles can
work independently or as complements to each other to maximize the Accuracy of
Memento Aggregators. We discuss various sources of truth that can be used to
create Archival Voids profiles. We use access logs from Arquivo.pt to create
various Archival Voids profiles and analyze them against our MemGator access
logs for evaluation. We find that we could have avoided more than 8% of
additional False Positives on top of the 60% Accuracy we got from profiling
Archival Holdings in our prior work, if Arquivo.pt were to provide an Archival
Voids profile based on URIs that were requested hundreds of times and never
returned any success responses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What a million Indian farmers say?: A crowdsourcing-based method for pest surveillance. (arXiv:2108.03374v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adhikari_P/0/1/0/all/0/1">Poonam Adhikari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ritesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyengar_S/0/1/0/all/0/1">S.R.S Iyengar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaur_R/0/1/0/all/0/1">Rishemjit Kaur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03374">
                                    <div class="article-summary-box-inner">
                                        <span>Many different technologies are used to detect pests in the crops, such as
manual sampling, sensors, and radar. However, these methods have scalability
issues as they fail to cover large areas, are uneconomical and complex. This
paper proposes a crowdsourced based method utilising the real-time farmer
queries gathered over telephones for pest surveillance. We developed
data-driven strategies by aggregating and analyzing historical data to find
patterns and get future insights into pest occurrence. We showed that it can be
an accurate and economical method for pest surveillance capable of enveloping a
large area with high spatio-temporal granularity. Forecasting the pest
population will help farmers in making informed decisions at the right time.
This will also help the government and policymakers to make the necessary
preparations as and when required and may also ensure food security.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BeatNet: CRNN and Particle Filtering for Online Joint Beat Downbeat and Meter Tracking. (arXiv:2108.03576v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Heydari_M/0/1/0/all/0/1">Mojtaba Heydari</a>, <a href="http://arxiv.org/find/eess/1/au:+Cwitkowitz_F/0/1/0/all/0/1">Frank Cwitkowitz</a>, <a href="http://arxiv.org/find/eess/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03576">
                                    <div class="article-summary-box-inner">
                                        <span>The online estimation of rhythmic information, such as beat positions,
downbeat positions, and meter, is critical for many real-time music
applications. Musical rhythm comprises complex hierarchical relationships
across time, rendering its analysis intrinsically challenging and at times
subjective. Furthermore, systems which attempt to estimate rhythmic information
in real-time must be causal and must produce estimates quickly and efficiently.
In this work, we introduce an online system for joint beat, downbeat, and meter
tracking, which utilizes causal convolutional and recurrent layers, followed by
a pair of sequential Monte Carlo particle filters applied during inference. The
proposed system does not need to be primed with a time signature in order to
perform downbeat tracking, and is instead able to estimate meter and adjust the
predictions over time. Additionally, we propose an information gate strategy to
significantly decrease the computational cost of particle filtering during the
inference step, making the system much faster than previous sampling-based
methods. Experiments on the GTZAN dataset, which is unseen during training,
show that the system outperforms various online beat and downbeat tracking
systems and achieves comparable performance to a baseline offline joint method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Neural Network Approach for Crop Selection and Yield Prediction in Bangladesh. (arXiv:2108.03320v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chisty_T/0/1/0/all/0/1">Tanjir Alam Chisty</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_A/0/1/0/all/0/1">Amitabha Chakrabarty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03320">
                                    <div class="article-summary-box-inner">
                                        <span>Agriculture is the essential ingredients to mankind which is a major source
of livelihood. Agriculture work in Bangladesh is mostly done in old ways which
directly affects our economy. In addition, institutions of agriculture are
working with manual data which cannot provide a proper solution for crop
selection and yield prediction. This paper shows the best way of crop selection
and yield prediction in minimum cost and effort. Artificial Neural Network is
considered robust tools for modeling and prediction. This algorithm aims to get
better output and prediction, as well as, support vector machine, Logistic
Regression, and random forest algorithm is also considered in this study for
comparing the accuracy and error rate. Moreover, all of these algorithms used
here are just to see how well they performed for a dataset which is over 0.3
million. We have collected 46 parameters such as maximum and minimum
temperature, average rainfall, humidity, climate, weather, and types of land,
types of chemical fertilizer, types of soil, soil structure, soil composition,
soil moisture, soil consistency, soil reaction and soil texture for applying
into this prediction process. In this paper, we have suggested using the deep
neural network for agricultural crop selection and yield prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score Matching Model for Unbounded Data Score. (arXiv:2106.05527v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongjun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seungjae Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kyungwoo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1">Wanmo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1">Il-Chul Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05527">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advance in diffusion models incorporates the Stochastic Differential
Equation (SDE), which brings the state-of-the art performance on image
generation tasks. This paper improves such diffusion models by analyzing the
model at the zero diffusion time. In real datasets, the score function diverges
as the diffusion time ($t$) decreases to zero, and this observation leads an
argument that the score estimation fails at $t&#x3D;0$ with any neural network
structure. Subsequently, we introduce Unbounded Diffusion Model (UDM) that
resolves the score diverging problem with an easily applicable modification to
any diffusion models. Additionally, we introduce a new SDE that overcomes the
theoretic and practical limitations of Variance Exploding SDE. On top of that,
the introduced Soft Truncation method improves the sample quality by mitigating
the loss scale issue that happens at $t&#x3D;0$. We further provide a theoretic
result of the proposed method to uncover the behind mechanism of the diffusion
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Neural Network for DrawiNg Networks, (DNN)^2. (arXiv:2108.03632v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Giovannangeli_L/0/1/0/all/0/1">Loann Giovannangeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lalanne_F/0/1/0/all/0/1">Frederic Lalanne</a>, <a href="http://arxiv.org/find/cs/1/au:+Auber_D/0/1/0/all/0/1">David Auber</a>, <a href="http://arxiv.org/find/cs/1/au:+Giot_R/0/1/0/all/0/1">Romain Giot</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourqui_R/0/1/0/all/0/1">Romain Bourqui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03632">
                                    <div class="article-summary-box-inner">
                                        <span>By leveraging recent progress of stochastic gradient descent methods, several
works have shown that graphs could be efficiently laid out through the
optimization of a tailored objective function. In the meantime, Deep Learning
(DL) techniques achieved great performances in many applications. We
demonstrate that it is possible to use DL techniques to learn a graph-to-layout
sequence of operations thanks to a graph-related objective function. In this
paper, we present a novel graph drawing framework called (DNN)^2: Deep Neural
Network for DrawiNg Networks. Our method uses Graph Convolution Networks to
learn a model. Learning is achieved by optimizing a graph topology related loss
function that evaluates (DNN)^2 generated layouts during training. Once
trained, the (DNN)^ model is able to quickly lay any input graph out. We
experiment (DNN)^2 and statistically compare it to optimization-based and
regular graph layout algorithms. The results show that (DNN)^2 performs well
and are encouraging as the Deep Learning approach to Graph Drawing is novel and
many leads for future works are identified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining machine learning and data assimilation to forecast dynamical systems from noisy partial observations. (arXiv:2108.03561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gottwald_G/0/1/0/all/0/1">Georg A. Gottwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Reich_S/0/1/0/all/0/1">Sebastian Reich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03561">
                                    <div class="article-summary-box-inner">
                                        <span>We present a supervised learning method to learn the propagator map of a
dynamical system from partial and noisy observations. In our computationally
cheap and easy-to-implement framework a neural network consisting of random
feature maps is trained sequentially by incoming observations within a data
assimilation procedure. By employing Takens&#x27; embedding theorem, the network is
trained on delay coordinates. We show that the combination of random feature
maps and data assimilation, called RAFDA, outperforms standard random feature
maps for which the dynamics is learned using batch data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Linear Policies for Robust Bipedal Locomotion on Terrains with Varying Slopes. (arXiv:2104.01662v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishna_L/0/1/0/all/0/1">Lokesh Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_U/0/1/0/all/0/1">Utkarsh A. Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Castillo_G/0/1/0/all/0/1">Guillermo A. Castillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hereid_A/0/1/0/all/0/1">Ayonga Hereid</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolathaya_S/0/1/0/all/0/1">Shishir Kolathaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01662">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, with a view toward deployment of light-weight control
frameworks for bipedal walking robots, we realize end-foot trajectories that
are shaped by a single linear feedback policy. We learn this policy via a
model-free and a gradient-free learning algorithm, Augmented Random Search
(ARS), in the two robot platforms Rabbit and Digit. Our contributions are
two-fold: a) By using torso and support plane orientation as inputs, we achieve
robust walking on slopes of up to 20 degrees in simulation. b) We demonstrate
additional behaviors like walking backwards, stepping-in-place, and recovery
from external pushes of up to 120 N. The end result is a robust and a fast
feedback control law for bipedal walking on terrains with varying slopes.
Towards the end, we also provide preliminary results of hardware transfer to
Digit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions. (arXiv:2108.03357v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zang_T/0/1/0/all/0/1">Tianzi Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanmin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haobing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruohan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jiadi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03357">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional recommendation systems are faced with two long-standing
obstacles, namely, data sparsity and cold-start problems, which promote the
emergence and development of Cross-Domain Recommendation (CDR). The core idea
of CDR is to leverage information collected from other domains to alleviate the
two problems in one domain. Over the last decade, many efforts have been
engaged for cross-domain recommendation. Recently, with the development of deep
learning and neural networks, a large number of methods have emerged. However,
there is a limited number of systematic surveys on CDR, especially regarding
the latest proposed methods as well as the recommendation scenarios and
recommendation tasks they address. In this survey paper, we first proposed a
two-level taxonomy of cross-domain recommendation which classifies different
recommendation scenarios and recommendation tasks. We then introduce and
summarize existing cross-domain recommendation approaches under different
recommendation scenarios in a structured manner. We also organize datasets
commonly used. We conclude this survey by providing several potential research
directions about this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks. (arXiv:2107.09804v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1">Saikat Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1">Mohammad Hossein Samavatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1">Kristin Barber</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1">Radu Teodorescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09804">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network (DNN) classifiers are powerful tools that drive a broad
spectrum of important applications, from image recognition to autonomous
vehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks
that affect virtually all state-of-the-art models. These attacks make small
imperceptible modifications to inputs that are sufficient to induce the DNNs to
produce the wrong classification.

In this paper we propose a novel, lightweight adversarial correction and/or
detection mechanism for image classifiers that relies on undervolting (running
a chip at a voltage that is slightly below its safe margin). We propose using
controlled undervolting of the chip running the inference process in order to
introduce a limited number of compute errors. We show that these errors disrupt
the adversarial input in a way that can be used either to correct the
classification or detect the input as adversarial. We evaluate the proposed
solution in an FPGA design and through software simulation. We evaluate 10
attacks and show average detection rates of 77% and 90% on two popular DNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BeatNet: CRNN and Particle Filtering for Online Joint Beat Downbeat and Meter Tracking. (arXiv:2108.03576v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Heydari_M/0/1/0/all/0/1">Mojtaba Heydari</a>, <a href="http://arxiv.org/find/eess/1/au:+Cwitkowitz_F/0/1/0/all/0/1">Frank Cwitkowitz</a>, <a href="http://arxiv.org/find/eess/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03576">
                                    <div class="article-summary-box-inner">
                                        <span>The online estimation of rhythmic information, such as beat positions,
downbeat positions, and meter, is critical for many real-time music
applications. Musical rhythm comprises complex hierarchical relationships
across time, rendering its analysis intrinsically challenging and at times
subjective. Furthermore, systems which attempt to estimate rhythmic information
in real-time must be causal and must produce estimates quickly and efficiently.
In this work, we introduce an online system for joint beat, downbeat, and meter
tracking, which utilizes causal convolutional and recurrent layers, followed by
a pair of sequential Monte Carlo particle filters applied during inference. The
proposed system does not need to be primed with a time signature in order to
perform downbeat tracking, and is instead able to estimate meter and adjust the
predictions over time. Additionally, we propose an information gate strategy to
significantly decrease the computational cost of particle filtering during the
inference step, making the system much faster than previous sampling-based
methods. Experiments on the GTZAN dataset, which is unseen during training,
show that the system outperforms various online beat and downbeat tracking
systems and achieves comparable performance to a baseline offline joint method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concept Drift Detection with Variable Interaction Networks. (arXiv:2108.03273v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zenisek_J/0/1/0/all/0/1">Jan Zenisek</a>, <a href="http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1">Gabriel Kronberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfartsberger_J/0/1/0/all/0/1">Josef Wolfartsberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_N/0/1/0/all/0/1">Norbert Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Affenzeller_M/0/1/0/all/0/1">Michael Affenzeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03273">
                                    <div class="article-summary-box-inner">
                                        <span>The current development of today&#x27;s production industry towards seamless
sensor-based monitoring is paving the way for concepts such as Predictive
Maintenance. By this means, the condition of plants and products in future
production lines will be continuously analyzed with the objective to predict
any kind of breakdown and trigger preventing actions proactively. Such
ambitious predictions are commonly performed with support of machine learning
algorithms. In this work, we utilize these algorithms to model complex systems,
such as production plants, by focusing on their variable interactions. The core
of this contribution is a sliding window based algorithm, designed to detect
changes of the identified interactions, which might indicate beginning
malfunctions in the context of a monitored production plant. Besides a detailed
description of the algorithm, we present results from experiments with a
synthetic dynamical system, simulating stable and drifting system behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Context-Aware Translation Models Pay the Right Attention?. (arXiv:2105.06977v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1">Patrick Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1">Danish Pruthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1">Aditi Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06977">
                                    <div class="article-summary-box-inner">
                                        <span>Context-aware machine translation models are designed to leverage contextual
information, but often fail to do so. As a result, they inaccurately
disambiguate pronouns and polysemous words that require context for resolution.
In this paper, we ask several questions: What contexts do human translators use
to resolve ambiguous words? Are models paying large amounts of attention to the
same context? What if we explicitly train them to do so? To answer these
questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a
new English-French dataset comprising supporting context words for 14K
translations that professional translators found useful for pronoun
disambiguation. Using SCAT, we perform an in-depth analysis of the context used
to disambiguate, examining positional and lexical characteristics of the
supporting words. Furthermore, we measure the degree of alignment between the
model&#x27;s attention scores and the supporting context from SCAT, and apply a
guided attention strategy to encourage agreement between the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A k-mer Based Approach for SARS-CoV-2 Variant Identification. (arXiv:2108.03465v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Sarwan Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sahoo_B/0/1/0/all/0/1">Bikram Sahoo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ullah_N/0/1/0/all/0/1">Naimat Ullah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zelikovskiy_A/0/1/0/all/0/1">Alexander Zelikovskiy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Patterson_M/0/1/0/all/0/1">Murray Patterson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Khan_I/0/1/0/all/0/1">Imdadullah Khan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03465">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid spread of the novel coronavirus (COVID-19) across the globe
and its continuous mutation, it is of pivotal importance to design a system to
identify different known (and unknown) variants of SARS-CoV-2. Identifying
particular variants helps to understand and model their spread patterns, design
effective mitigation strategies, and prevent future outbreaks. It also plays a
crucial role in studying the efficacy of known vaccines against each variant
and modeling the likelihood of breakthrough infections. It is well known that
the spike protein contains most of the information/variation pertaining to
coronavirus variants.

In this paper, we use spike sequences to classify different variants of the
coronavirus in humans. We show that preserving the order of the amino acids
helps the underlying classifiers to achieve better performance. We also show
that we can train our model to outperform the baseline algorithms using only a
small number of training samples ($1\%$ of the data). Finally, we show the
importance of the different amino acids which play a key role in identifying
variants and how they coincide with those reported by the USA&#x27;s Centers for
Disease Control and Prevention (CDC).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Graph Dimension with Cross-validated Eigenvalues. (arXiv:2108.03336v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_F/0/1/0/all/0/1">Fan Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Roch_S/0/1/0/all/0/1">Sebastien Roch</a>, <a href="http://arxiv.org/find/stat/1/au:+Rohe_K/0/1/0/all/0/1">Karl Rohe</a>, <a href="http://arxiv.org/find/stat/1/au:+Yu_S/0/1/0/all/0/1">Shuqi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03336">
                                    <div class="article-summary-box-inner">
                                        <span>In applied multivariate statistics, estimating the number of latent
dimensions or the number of clusters is a fundamental and recurring problem.
One common diagnostic is the scree plot, which shows the largest eigenvalues of
the data matrix; the user searches for a &quot;gap&quot; or &quot;elbow&quot; in the decreasing
eigenvalues; unfortunately, these patterns can hide beneath the bias of the
sample eigenvalues. This methodological problem is conceptually difficult
because, in many situations, there is only enough signal to detect a subset of
the $k$ population dimensions/eigenvectors. In this situation, one could argue
that the correct choice of $k$ is the number of detectable dimensions. We
alleviate these problems with cross-validated eigenvalues. Under a large class
of random graph models, without any parametric assumptions, we provide a
p-value for each sample eigenvector. It tests the null hypothesis that this
sample eigenvector is orthogonal to (i.e., uncorrelated with) the true latent
dimensions. This approach naturally adapts to problems where some dimensions
are not statistically detectable. In scenarios where all $k$ dimensions can be
estimated, we prove that our procedure consistently estimates $k$. In
simulations and a data example, the proposed estimator compares favorably to
alternative approaches in both computational and statistical performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data. (arXiv:2108.03649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Rongrong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Changlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03649">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to joint depth and normal estimation for
time-of-flight (ToF) sensors. Our model learns to predict the high-quality
depth and normal maps jointly from ToF raw sensor data. To achieve this, we
meticulously constructed the first large-scale dataset (named ToF-100) with
paired raw ToF data and ground-truth high-resolution depth maps provided by an
industrial depth camera. In addition, we also design a simple but effective
framework for joint depth and normal estimation, applying a robust Chamfer loss
via jittering to improve the performance of our model. Our experiments
demonstrate that our proposed method can efficiently reconstruct
high-resolution depth and normal maps and significantly outperforms
state-of-the-art approaches. Our code and data will be available at
\url{https://github.com/hkustVisionRr/JointlyDepthNormalEstimation}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Evolutionary Batch Size Orchestration for Scheduling Deep Learning Workloads in GPU Clusters. (arXiv:2108.03645v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1">Zhengda Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shenggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03645">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient GPU resource scheduling is essential to maximize resource
utilization and save training costs for the increasing amount of deep learning
workloads in shared GPU clusters. Existing GPU schedulers largely rely on
static policies to leverage the performance characteristics of deep learning
jobs. However, they can hardly reach optimal efficiency due to the lack of
elasticity. To address the problem, we propose ONES, an ONline Evolutionary
Scheduler for elastic batch size orchestration. ONES automatically manages the
elasticity of each job based on the training batch size, so as to maximize GPU
utilization and improve scheduling efficiency. It determines the batch size for
each job through an online evolutionary search that can continuously optimize
the scheduling decisions. We evaluate the effectiveness of ONES with 64 GPUs on
TACC&#x27;s Longhorn supercomputers. The results show that ONES can outperform the
prior deep learning schedulers with a significantly shorter average job
completion time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChartPointFlow for Topology-Aware 3D Point Cloud Generation. (arXiv:2012.02346v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1">Takumi Kimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1">Takashi Matsubara</a>, <a href="http://arxiv.org/find/cs/1/au:+Uehara_K/0/1/0/all/0/1">Kuniaki Uehara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02346">
                                    <div class="article-summary-box-inner">
                                        <span>A point cloud serves as a representation of the surface of a
three-dimensional (3D) shape. Deep generative models have been adapted to model
their variations typically using a map from a ball-like set of latent
variables. However, previous approaches did not pay much attention to the
topological structure of a point cloud, despite that a continuous map cannot
express the varying numbers of holes and intersections. Moreover, a point cloud
is often composed of multiple subparts, and it is also difficult to express. In
this study, we propose ChartPointFlow, a flow-based generative model with
multiple latent labels for 3D point clouds. Each label is assigned to points in
an unsupervised manner. Then, a map conditioned on a label is assigned to a
continuous subset of a point cloud, similar to a chart of a manifold. This
enables our proposed model to preserve the topological structure with clear
boundaries, whereas previous approaches tend to generate blurry point clouds
and fail to generate holes. The experimental results demonstrate that
ChartPointFlow achieves state-of-the-art performance in terms of generation and
reconstruction compared with other point cloud generators. Moreover,
ChartPointFlow divides an object into semantic subparts using charts, and it
demonstrates superior performance in case of unsupervised segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks. (arXiv:2108.03272v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Lingelbach_M/0/1/0/all/0/1">Michael Lingelbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gokmen_C/0/1/0/all/0/1">Cem Gokmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dharan_G/0/1/0/all/0/1">Gokul Dharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1">Tanish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1">Andrey Kurenkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gweon_H/0/1/0/all/0/1">Hyowon Gweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03272">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset will be publicly available at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A survey of statistical learning techniques as applied to inexpensive pediatric Obstructive Sleep Apnea data. (arXiv:2002.07873v3 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Winn_E/0/1/0/all/0/1">Emily T. Winn</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Vazquez_M/0/1/0/all/0/1">Marilyn Vazquez</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Loliencar_P/0/1/0/all/0/1">Prachi Loliencar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Taipale_K/0/1/0/all/0/1">Kaisa Taipale</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Heo_G/0/1/0/all/0/1">Giseon Heo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.07873">
                                    <div class="article-summary-box-inner">
                                        <span>Pediatric obstructive sleep apnea affects an estimated 1-5% of
elementary-school aged children and can lead to other detrimental health
problems. Swift diagnosis and treatment are critical to a child&#x27;s growth and
development, but the variability of symptoms and the complexity of the
available data make this a challenge. We take a first step in streamlining the
process by focusing on inexpensive data from questionnaires and craniofacial
measurements. We apply correlation networks, the Mapper algorithm from
topological data analysis, and singular value decomposition in a process of
exploratory data analysis. We then apply a variety of supervised and
unsupervised learning techniques from statistics, machine learning, and
topology, ranging from support vector machines to Bayesian classifiers and
manifold learning. Finally, we analyze the results of each of these methods and
discuss the implications for a multi-data-sourced algorithm moving forward.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kinematics clustering enables head impact subtyping for better traumatic brain injury prediction. (arXiv:2108.03498v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhan_X/0/1/0/all/0/1">Xianghao Zhan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yiheng Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1">Yuzhe Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Cecchi_N/0/1/0/all/0/1">Nicholas J. Cecchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Gevaert_O/0/1/0/all/0/1">Olivier Gevaert</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeineh_M/0/1/0/all/0/1">Michael M. Zeineh</a>, <a href="http://arxiv.org/find/stat/1/au:+Grant_G/0/1/0/all/0/1">Gerald A. Grant</a>, <a href="http://arxiv.org/find/stat/1/au:+Camarillo_D/0/1/0/all/0/1">David B. Camarillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03498">
                                    <div class="article-summary-box-inner">
                                        <span>Traumatic brain injury can be caused by various types of head impacts.
However, due to different kinematic characteristics, many brain injury risk
estimation models are not generalizable across the variety of impacts that
humans may sustain. The current definitions of head impact subtypes are based
on impact sources (e.g., football, traffic accident), which may not reflect the
intrinsic kinematic similarities of impacts across the impact sources. To
investigate the potential new definitions of impact subtypes based on
kinematics, 3,161 head impacts from various sources including simulation,
college football, mixed martial arts, and car racing were collected. We applied
the K-means clustering to cluster the impacts on 16 standardized temporal
features from head rotation kinematics. Then, we developed subtype-specific
ridge regression models for cumulative strain damage (using the threshold of
15%), which significantly improved the estimation accuracy compared with the
baseline method which mixed impacts from different sources and developed one
model (R^2 from 0.7 to 0.9). To investigate the effect of kinematic features,
we presented the top three critical features (maximum resultant angular
acceleration, maximum angular acceleration along the z-axis, maximum linear
acceleration along the y-axis) based on regression accuracy and used logistic
regression to find the critical points for each feature that partitioned the
subtypes. This study enables researchers to define head impact subtypes in a
data-driven manner, which leads to more generalizable brain injury risk
estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of Aliasing on Generalization in Deep Convolutional Networks. (arXiv:2108.03489v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Dumoulin_V/0/1/0/all/0/1">Vincent Dumoulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1">Rob Romijnders</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Goroshin_R/0/1/0/all/0/1">Ross Goroshin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03489">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Neuroimaging Analysis using Federated Learning with Homomorphic Encryption. (arXiv:2108.03437v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stripelis_D/0/1/0/all/0/1">Dimitris Stripelis</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleem_H/0/1/0/all/0/1">Hamza Saleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghai_T/0/1/0/all/0/1">Tanmay Ghai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhinagar_N/0/1/0/all/0/1">Nikhil Dhinagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1">Umang Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Anastasiou_C/0/1/0/all/0/1">Chrysovalantis Anastasiou</a>, <a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1">Srivatsan Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Naveed_M/0/1/0/all/0/1">Muhammad Naveed</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_P/0/1/0/all/0/1">Paul M. Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ambite_J/0/1/0/all/0/1">Jose Luis Ambite</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03437">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) enables distributed computation of machine learning
models over various disparate, remote data sources, without requiring to
transfer any individual data to a centralized location. This results in an
improved generalizability of models and efficient scaling of computation as
more sources and larger datasets are added to the federation. Nevertheless,
recent membership attacks show that private or sensitive personal data can
sometimes be leaked or inferred when model parameters or summary statistics are
shared with a central site, requiring improved security solutions. In this
work, we propose a framework for secure FL using fully-homomorphic encryption
(FHE). Specifically, we use the CKKS construction, an approximate, floating
point compatible scheme that benefits from ciphertext packing and rescaling. In
our evaluation on large-scale brain MRI datasets, we use our proposed secure FL
framework to train a deep learning model to predict a person&#x27;s age from
distributed MRI scans, a common benchmarking task, and demonstrate that there
is no degradation in the learning performance between the encrypted and
non-encrypted federated models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anchored-STFT and GNAA: An extension of STFT in conjunction with an adversarial data augmentation technique for the decoding of neural signals. (arXiv:2011.14694v4 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ali_O/0/1/0/all/0/1">Omair Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1">Muhammad Saif-ur-Rehman</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dyck_S/0/1/0/all/0/1">Susanne Dyck</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Iossifidis_I/0/1/0/all/0/1">Ioannis Iossifidis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Klaes_C/0/1/0/all/0/1">Christian Klaes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14694">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-computer interfaces (BCIs) enable communication between humans and
machines by translating brain activity into control commands.
Electroencephalography (EEG) signals are one of the most used brain signals in
non-invasive BCI applications but are often contaminated with noise. Therefore,
it is possible that meaningful patterns for classifying EEG signals are deeply
hidden. State-of-the-art deep-learning algorithms are successful in learning
hidden, meaningful patterns. However, the quality and the quantity of the
presented inputs is pivotal. Here, we propose a novel feature extraction method
called anchored Short Time Fourier Transform (anchored-STFT), which is an
advanced version of STFT, as it minimizes the trade-off between temporal and
spectral resolution presented by STFT. In addition, we propose a novel
augmentation method, called gradient norm adversarial augmentation (GNAA). GNAA
is not only an augmentation method but is also used to harness adversarial
inputs in EEG data, which not only improves the classification accuracy but
also enhances the robustness of the classifier. In addition, we also propose a
new CNN architecture, namely Skip-Net, for the classification of EEG signals.
The proposed pipeline outperforms all state-of-the-art methods and yields an
average classification accuracy of 90.7 % and 89.54 % on BCI competition II
dataset III and BCI competition IV dataset 2b, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Matters in Learning from Offline Human Demonstrations for Robot Manipulation. (arXiv:2108.03298v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1">Ajay Mandlekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Danfei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Josiah Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasiriany_S/0/1/0/all/0/1">Soroush Nasiriany</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1">Rohun Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03298">
                                    <div class="article-summary-box-inner">
                                        <span>Imitating human demonstrations is a promising approach to endow robots with
various manipulation capabilities. While recent advances have been made in
imitation learning and batch (offline) reinforcement learning, a lack of
open-source human datasets and reproducible learning methods make assessing the
state of the field difficult. In this paper, we conduct an extensive study of
six offline learning algorithms for robot manipulation on five simulated and
three real-world multi-stage manipulation tasks of varying complexity, and with
datasets of varying quality. Our study analyzes the most critical challenges
when learning from offline human data for manipulation. Based on the study, we
derive a series of lessons including the sensitivity to different algorithmic
design choices, the dependence on the quality of the demonstrations, and the
variability based on the stopping criteria due to the different objectives in
training and evaluation. We also highlight opportunities for learning from
human datasets, such as the ability to learn proficient policies on
challenging, multi-stage tasks beyond the scope of current reinforcement
learning methods, and the ability to easily scale to natural, real-world
manipulation scenarios where only raw sensory signals are available. We have
open-sourced our datasets and all algorithm implementations to facilitate
future research and fair comparisons in learning from human demonstration data.
Codebase, datasets, trained models, and more available at
https://arise-initiative.github.io/robomimic-web/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An empirical assessment of deep learning approaches to task-oriented dialog management. (arXiv:2108.03478v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matej%5Cr%7Bu%7D_L/0/1/0/all/0/1">Luk&#xe1;&#x161; Mat&#x11b;j&#x16f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Griol_D/0/1/0/all/0/1">David Griol</a>, <a href="http://arxiv.org/find/cs/1/au:+Callejas_Z/0/1/0/all/0/1">Zoraida Callejas</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_J/0/1/0/all/0/1">Jos&#xe9; Manuel Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchis_A/0/1/0/all/0/1">Araceli Sanchis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03478">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is providing very positive results in areas related to
conversational interfaces, such as speech recognition, but its potential
benefit for dialog management has still not been fully studied. In this paper,
we perform an assessment of different configurations for deep-learned dialog
management with three dialog corpora from different application domains and
varying in size, dimensionality and possible system responses. Our results have
allowed us to identify several aspects that can have an impact on accuracy,
including the approaches used for feature extraction, input representation,
context consideration and the hyper-parameters of the deep neural networks
employed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Let&#x27;s Stop Incorrect Comparisons in End-to-end Relation Extraction!. (arXiv:2009.10684v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taille_B/0/1/0/all/0/1">Bruno Taill&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1">Vincent Guigue</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10684">
                                    <div class="article-summary-box-inner">
                                        <span>Despite efforts to distinguish three different evaluation setups (Bekoulis et
al., 2018), numerous end-to-end Relation Extraction (RE) articles present
unreliable performance comparison to previous work. In this paper, we first
identify several patterns of invalid comparisons in published papers and
describe them to avoid their propagation. We then propose a small empirical
study to quantify the impact of the most common mistake and evaluate it leads
to overestimating the final RE performance by around 5% on ACE05. We also seize
this opportunity to study the unexplored ablations of two recent developments:
the use of language model pretraining (specifically BERT) and span-level NER.
This meta-analysis emphasizes the need for rigor in the report of both the
evaluation setting and the datasets statistics and we call for unifying the
evaluation setting in end-to-end RE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SMOTified-GAN for class imbalanced pattern classification problems. (arXiv:2108.03235v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Anuraganand Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Prabhat Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Rohitash Chandra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03235">
                                    <div class="article-summary-box-inner">
                                        <span>Class imbalance in a dataset is a major problem for classifiers that results
in poor prediction with a high true positive rate (TPR) but a low true negative
rate (TNR) for a majority positive training dataset. Generally, the
pre-processing technique of oversampling of minority class(es) are used to
overcome this deficiency. Our focus is on using the hybridization of Generative
Adversarial Network (GAN) and Synthetic Minority Over-Sampling Technique
(SMOTE) to address class imbalanced problems. We propose a novel two-phase
oversampling approach that has the synergy of SMOTE and GAN. The initial data
of minority class(es) generated by SMOTE is further enhanced by GAN that
produces better quality samples. We named it SMOTified-GAN as GAN works on
pre-sampled minority data produced by SMOTE rather than randomly generating the
samples itself. The experimental results prove the sample quality of minority
class(es) has been improved in a variety of tested benchmark datasets. Its
performance is improved by up to 9\% from the next best algorithm tested on
F1-score measurements. Its time complexity is also reasonable which is around
$O(N^2d^2T)$ for a sequential algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Dynamic Mode Decomposition: Balancing Accuracy and Expressiveness in Koopman Approximations. (arXiv:2108.03712v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Haseli_M/0/1/0/all/0/1">Masih Haseli</a>, <a href="http://arxiv.org/find/eess/1/au:+Cortes_J/0/1/0/all/0/1">Jorge Cort&#xe9;s</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03712">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles the data-driven approximation of unknown dynamical systems
using Koopman-operator methods. Given a dictionary of functions, these methods
approximate the projection of the action of the operator on the
finite-dimensional subspace spanned by the dictionary. We propose the Tunable
Symmetric Subspace Decomposition algorithm to refine the dictionary, balancing
its expressiveness and accuracy. Expressiveness corresponds to the ability of
the dictionary to describe the evolution of as many observables as possible and
accuracy corresponds to the ability to correctly predict their evolution. Based
on the observation that Koopman-invariant subspaces give rise to exact
predictions, we reason that prediction accuracy is a function of the degree of
invariance of the subspace generated by the dictionary and provide a
data-driven measure to measure invariance proximity. The proposed algorithm
iteratively prunes the initial functional space to identify a refined
dictionary of functions that satisfies the desired level of accuracy while
retaining as much of the original expressiveness as possible. We provide a full
characterization of the algorithm properties and show that it generalizes both
Extended Dynamic Mode Decomposition and Symmetric Subspace Decomposition.
Simulations on planar systems show the effectiveness of the proposed methods in
producing Koopman approximations of tunable accuracy that capture relevant
information about the dynamical system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expressive Power and Loss Surfaces of Deep Learning Models. (arXiv:2108.03579v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dube_S/0/1/0/all/0/1">Simant Dube</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03579">
                                    <div class="article-summary-box-inner">
                                        <span>The goals of this paper are two-fold. The first goal is to serve as an
expository tutorial on the working of deep learning models which emphasizes
geometrical intuition about the reasons for success of deep learning. The
second goal is to complement the current results on the expressive power of
deep learning models and their loss surfaces with novel insights and results.
In particular, we describe how deep neural networks carve out manifolds
especially when the multiplication neurons are introduced. Multiplication is
used in dot products and the attention mechanism and it is employed in capsule
networks and self-attention based transformers. We also describe how random
polynomial, random matrix, spin glass and computational complexity perspectives
on the loss surfaces are interconnected.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Large Data Sets with Incremental Estimation of Low-density Separating Hyperplanes. (arXiv:2108.03442v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hofmeyr_D/0/1/0/all/0/1">David P. Hofmeyr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03442">
                                    <div class="article-summary-box-inner">
                                        <span>An efficient method for obtaining low-density hyperplane separators in the
unsupervised context is proposed. Low density separators can be used to obtain
a partition of a set of data based on their allocations to the different sides
of the separators. The proposed method is based on applying stochastic gradient
descent to the integrated density on the hyperplane with respect to a
convolution of the underlying distribution and a smoothing kernel. In the case
where the bandwidth of the smoothing kernel is decreased towards zero, the bias
of these updates with respect to the true underlying density tends to zero, and
convergence to a minimiser of the density on the hyperplane can be obtained. A
post-processing of the partition induced by a collection of low-density
hyperplanes yields an efficient and accurate clustering method which is capable
of automatically selecting an appropriate number of clusters. Experiments with
the proposed approach show that it is highly competitive in terms of both speed
and accuracy when compared with relevant benchmarks. Code to implement the
proposed approach is available in the form of an R package from
https://github.com/DavidHofmeyr/iMDH.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ManiSkill: Learning-from-Demonstrations Benchmark for Generalizable Manipulation Skills. (arXiv:2107.14483v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tongzhou Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_F/0/1/0/all/0/1">Fanbo Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Derek Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuanlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1">Stone Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhiwei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14483">
                                    <div class="article-summary-box-inner">
                                        <span>Learning generalizable manipulation skills is central for robots to achieve
task automation in environments with endless scene and object variations.
However, existing robot learning environments are limited in both scale and
diversity of 3D assets (especially of articulated objects), making it difficult
to train and evaluate the generalization ability of agents over novel objects.
In this work, we focus on object-level generalization and propose SAPIEN
Manipulation Skill Benchmark (abbreviated as ManiSkill), a large-scale
learning-from-demonstrations benchmark for articulated object manipulation with
3D visual input (point cloud and RGB-D image). ManiSkill supports object-level
variations by utilizing a rich and diverse set of articulated objects, and each
task is carefully designed for learning manipulations on a single category of
objects. We equip ManiSkill with a large number of high-quality demonstrations
to facilitate learning-from-demonstrations approaches and perform evaluations
on baseline algorithms. We believe that ManiSkill can encourage the robot
learning community to explore more on learning generalizable object
manipulation skills.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VeRLPy: Python Library for Verification of Digital Designs with Reinforcement Learning. (arXiv:2108.03978v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shibu_A/0/1/0/all/0/1">Aebel Joe Shibu</a>, <a href="http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1">Sadhana S</a>, <a href="http://arxiv.org/find/cs/1/au:+N_S/0/1/0/all/0/1">Shilpa N</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratyush Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03978">
                                    <div class="article-summary-box-inner">
                                        <span>Digital hardware is verified by comparing its behavior against a reference
model on a range of randomly generated input signals. The random generation of
the inputs hopes to achieve sufficient coverage of the different parts of the
design. However, such coverage is often difficult to achieve, amounting to
large verification efforts and delays. An alternative is to use Reinforcement
Learning (RL) to generate the inputs by learning to prioritize those inputs
which can more efficiently explore the design under test. In this work, we
present VeRLPy an open-source library to allow RL-driven verification with
limited additional engineering overhead. This contributes to two broad
movements within the EDA community of (a) moving to open-source toolchains and
(b) reducing barriers for development with Python support. We also demonstrate
the use of VeRLPy for a few designs and establish its value over randomly
generated input signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Training Collaborative Object Detectors Adaptive to Bandwidth and Computation. (arXiv:2105.00591v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Assine_J/0/1/0/all/0/1">Juliano S. Assine</a>, <a href="http://arxiv.org/find/cs/1/au:+Filho_J/0/1/0/all/0/1">J. C. S. Santos Filho</a>, <a href="http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1">Eduardo Valle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00591">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, mobile deep-learning deployment progressed by leaps
and bounds, but solutions still struggle to accommodate its severe and
fluctuating operational restrictions, which include bandwidth, latency,
computation, and energy. In this work, we help to bridge that gap, introducing
the first configurable solution for object detection that manages the triple
communication-computation-accuracy trade-off with a single set of weights. Our
solution shows state-of-the-art results on COCO-2017, adding only a minor
penalty on the base EfficientDet-D2 architecture. Our design is robust to the
choice of base architecture and compressor and should adapt well for future
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Role of Global Labels in Few-Shot Classification and How to Infer Them. (arXiv:2108.04055v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1">Massimiliano Pontil</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciliberto_C/0/1/0/all/0/1">Carlo Ciliberto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04055">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) is a central problem in meta-learning, where learners
must quickly adapt to new tasks given limited training data. Surprisingly,
recent works have outperformed meta-learning methods tailored to FSL by casting
it as standard supervised learning to jointly classify all classes shared
across tasks. However, this approach violates the standard FSL setting by
requiring global labels shared across tasks, which are often unavailable in
practice. In this paper, we show why solving FSL via standard classification is
theoretically advantageous. This motivates us to propose Meta Label Learning
(MeLa), a novel algorithm that infers global labels and obtains robust few-shot
models via standard classification. Empirically, we demonstrate that MeLa
outperforms meta-learning competitors and is comparable to the oracle setting
where ground truth labels are given. We provide extensive ablation studies to
highlight the key properties of the proposed strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing thermodynamic trajectories using evolutionary and gradient-based reinforcement learning. (arXiv:1903.08543v4 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beeler_C/0/1/0/all/0/1">Chris Beeler</a>, <a href="http://arxiv.org/find/cs/1/au:+Yahorau_U/0/1/0/all/0/1">Uladzimir Yahorau</a>, <a href="http://arxiv.org/find/cs/1/au:+Coles_R/0/1/0/all/0/1">Rory Coles</a>, <a href="http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1">Kyle Mills</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitelam_S/0/1/0/all/0/1">Stephen Whitelam</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1">Isaac Tamblyn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.08543">
                                    <div class="article-summary-box-inner">
                                        <span>Using a model heat engine, we show that neural network-based reinforcement
learning can identify thermodynamic trajectories of maximal efficiency. We
consider both gradient and gradient-free reinforcement learning. We use an
evolutionary learning algorithm to evolve a population of neural networks,
subject to a directive to maximize the efficiency of a trajectory composed of a
set of elementary thermodynamic processes; the resulting networks learn to
carry out the maximally-efficient Carnot, Stirling, or Otto cycles. When given
an additional irreversible process, this evolutionary scheme learns a
previously unknown thermodynamic cycle. Gradient-based reinforcement learning
is able to learn the Stirling cycle, whereas an evolutionary approach achieves
the optimal Carnot cycle. Our results show how the reinforcement learning
strategies developed for game playing can be applied to solve physical problems
conditioned upon path-extensive order parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maxmin Q-learning: Controlling the Estimation Bias of Q-learning. (arXiv:2002.06487v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1">Qingfeng Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1">Yangchen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fyshe_A/0/1/0/all/0/1">Alona Fyshe</a>, <a href="http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1">Martha White</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06487">
                                    <div class="article-summary-box-inner">
                                        <span>Q-learning suffers from overestimation bias, because it approximates the
maximum action value using the maximum estimated action value. Algorithms have
been proposed to reduce overestimation bias, but we lack an understanding of
how bias interacts with performance, and the extent to which existing
algorithms mitigate bias. In this paper, we 1) highlight that the effect of
overestimation bias on learning efficiency is environment-dependent; 2) propose
a generalization of Q-learning, called \emph{Maxmin Q-learning}, which provides
a parameter to flexibly control bias; 3) show theoretically that there exists a
parameter choice for Maxmin Q-learning that leads to unbiased estimation with a
lower approximation variance than Q-learning; and 4) prove the convergence of
our algorithm in the tabular case, as well as convergence of several previous
Q-learning variants, using a novel Generalized Q-learning framework. We
empirically verify that our algorithm better controls estimation bias in toy
environments, and that it achieves superior performance on several benchmark
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alternating linear scheme in a Bayesian framework for low-rank tensor approximation. (arXiv:2012.11228v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Menzen_C/0/1/0/all/0/1">Clara Menzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kok_M/0/1/0/all/0/1">Manon Kok</a>, <a href="http://arxiv.org/find/cs/1/au:+Batselier_K/0/1/0/all/0/1">Kim Batselier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11228">
                                    <div class="article-summary-box-inner">
                                        <span>Multiway data often naturally occurs in a tensorial format which can be
approximately represented by a low-rank tensor decomposition. This is useful
because complexity can be significantly reduced and the treatment of
large-scale data sets can be facilitated. In this paper, we find a low-rank
representation for a given tensor by solving a Bayesian inference problem. This
is achieved by dividing the overall inference problem into sub-problems where
we sequentially infer the posterior distribution of one tensor decomposition
component at a time. This leads to a probabilistic interpretation of the
well-known iterative algorithm alternating linear scheme (ALS). In this way,
the consideration of measurement noise is enabled, as well as the incorporation
of application-specific prior knowledge and the uncertainty quantification of
the low-rank tensor estimate. To compute the low-rank tensor estimate from the
posterior distributions of the tensor decomposition components, we present an
algorithm that performs the unscented transform in tensor train format.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Uncertainty for Improved Static Malware Detection Under Extreme False Positive Constraints. (arXiv:2108.04081v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Andre T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1">Edward Raff</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1">Charles Nicholas</a>, <a href="http://arxiv.org/find/cs/1/au:+Holt_J/0/1/0/all/0/1">James Holt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04081">
                                    <div class="article-summary-box-inner">
                                        <span>The detection of malware is a critical task for the protection of computing
environments. This task often requires extremely low false positive rates (FPR)
of 0.01% or even lower, for which modern machine learning has no readily
available tools. We introduce the first broad investigation of the use of
uncertainty for malware detection across multiple datasets, models, and feature
types. We show how ensembling and Bayesian treatments of machine learning
methods for static malware detection allow for improved identification of model
errors, uncovering of new malware families, and predictive performance under
extreme false positive constraints. In particular, we improve the true positive
rate (TPR) at an actual realized FPR of 1e-5 from an expected 0.69 for previous
methods to 0.80 on the best performing model class on the Sophos industry scale
dataset. We additionally demonstrate how previous works have used an evaluation
protocol that can lead to misleading results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MGIC: Multigrid-in-Channels Neural Network Architectures. (arXiv:2011.09128v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eliasof_M/0/1/0/all/0/1">Moshe Eliasof</a>, <a href="http://arxiv.org/find/cs/1/au:+Ephrath_J/0/1/0/all/0/1">Jonathan Ephrath</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruthotto_L/0/1/0/all/0/1">Lars Ruthotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Treister_E/0/1/0/all/0/1">Eran Treister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09128">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multigrid-in-channels (MGIC) approach that tackles the quadratic
growth of the number of parameters with respect to the number of channels in
standard convolutional neural networks (CNNs). Thereby our approach addresses
the redundancy in CNNs that is also exposed by the recent success of
lightweight CNNs. Lightweight CNNs can achieve comparable accuracy to standard
CNNs with fewer parameters; however, the number of weights still scales
quadratically with the CNN&#x27;s width. Our MGIC architectures replace each CNN
block with an MGIC counterpart that utilizes a hierarchy of nested grouped
convolutions of small group size to address this.

Hence, our proposed architectures scale linearly with respect to the
network&#x27;s width while retaining full coupling of the channels as in standard
CNNs.

Our extensive experiments on image classification, segmentation, and point
cloud classification show that applying this strategy to different
architectures like ResNet and MobileNetV3 reduces the number of parameters
while obtaining similar or better accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear Level Set Learning for Function Approximation on Sparse Data with Applications to Parametric Differential Equations. (arXiv:2104.14072v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gruber_A/0/1/0/all/0/1">Anthony Gruber</a>, <a href="http://arxiv.org/find/stat/1/au:+Gunzburger_M/0/1/0/all/0/1">Max Gunzburger</a>, <a href="http://arxiv.org/find/stat/1/au:+Ju_L/0/1/0/all/0/1">Lili Ju</a>, <a href="http://arxiv.org/find/stat/1/au:+Teng_Y/0/1/0/all/0/1">Yuankai Teng</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14072">
                                    <div class="article-summary-box-inner">
                                        <span>A dimension reduction method based on the &quot;Nonlinear Level set Learning&quot;
(NLL) approach is presented for the pointwise prediction of functions which
have been sparsely sampled. Leveraging geometric information provided by the
Implicit Function Theorem, the proposed algorithm effectively reduces the input
dimension to the theoretical lower bound with minor accuracy loss, providing a
one-dimensional representation of the function which can be used for regression
and sensitivity analysis. Experiments and applications are presented which
compare this modified NLL with the original NLL and the Active Subspaces (AS)
method. While accommodating sparse input data, the proposed algorithm is shown
to train quickly and provide a much more accurate and informative reduction
than either AS or the original NLL on two example functions with
high-dimensional domains, as well as two state-dependent quantities depending
on the solutions to parametric differential equations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Net: A novel light weight framework for COVID-19 Diagnosis. (arXiv:2108.03786v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gammulle_H/0/1/0/all/0/1">Harshala Gammulle</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1">Tharindu Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1">Sridha Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03786">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel lightweight COVID-19 diagnosis framework using CT
scans. Our system utilises a novel two-stage approach to generate robust and
efficient diagnoses across heterogeneous patient level inputs. We use a
powerful backbone network as a feature extractor to capture discriminative
slice-level features. These features are aggregated by a lightweight network to
obtain a patient level diagnosis. The aggregation network is carefully designed
to have a small number of trainable parameters while also possessing sufficient
capacity to generalise to diverse variations within different CT volumes and to
adapt to noise introduced during the data acquisition. We achieve a significant
performance increase over the baselines when benchmarked on the SPGC COVID-19
Radiomics Dataset, despite having only 2.5 million trainable parameters and
requiring only 0.623 seconds on average to process a single patient&#x27;s CT volume
using an Nvidia-GeForce RTX 2080 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Effect of Training Parameters and Mechanisms on Decentralized Federated Learning based on MNIST Dataset. (arXiv:2108.03508v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuofan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_K/0/1/0/all/0/1">Kaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdallah_C/0/1/0/all/0/1">Chaouki Abdallah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03508">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning is an algorithm suited for training models on
decentralized data, but the requirement of a central &quot;server&quot; node is a
bottleneck. In this document, we first introduce the notion of Decentralized
Federated Learning (DFL). We then perform various experiments on different
setups, such as changing model aggregation frequency, switching from
independent and identically distributed (IID) dataset partitioning to non-IID
partitioning with partial global sharing, using different optimization methods
across clients, and breaking models into segments with partial sharing. All
experiments are run on the MNIST handwritten digits dataset. We observe that
those altered training procedures are generally robust, albeit non-optimal. We
also observe failures in training when the variance between model weights is
too large. The open-source experiment code is accessible through
GitHub\footnote{Code was uploaded at
\url{https://github.com/zhzhang2018/DecentralizedFL}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction. (arXiv:2006.03041v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yuting Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1">Yuejie Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuantao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03041">
                                    <div class="article-summary-box-inner">
                                        <span>Asynchronous Q-learning aims to learn the optimal action-value function (or
Q-function) of a Markov decision process (MDP), based on a single trajectory of
Markovian samples induced by a behavior policy. Focusing on a
$\gamma$-discounted MDP with state space $\mathcal{S}$ and action space
$\mathcal{A}$, we demonstrate that the $\ell_{\infty}$-based sample complexity
of classical asynchronous Q-learning --- namely, the number of samples needed
to yield an entrywise $\varepsilon$-accurate estimate of the Q-function --- is
at most on the order of $\frac{1}{\mu_{\min}(1-\gamma)^5\varepsilon^2}+
\frac{t_{mix}}{\mu_{\min}(1-\gamma)}$ up to some logarithmic factor, provided
that a proper constant learning rate is adopted. Here, $t_{mix}$ and
$\mu_{\min}$ denote respectively the mixing time and the minimum state-action
occupancy probability of the sample trajectory. The first term of this bound
matches the sample complexity in the synchronous case with independent samples
drawn from the stationary distribution of the trajectory. The second term
reflects the cost taken for the empirical distribution of the Markovian
trajectory to reach a steady state, which is incurred at the very beginning and
becomes amortized as the algorithm runs. Encouragingly, the above bound
improves upon the state-of-the-art result \cite{qu2020finite} by a factor of at
least $|\mathcal{S}||\mathcal{A}|$ for all scenarios, and by a factor of at
least $t_{mix}|\mathcal{S}||\mathcal{A}|$ for any sufficiently small accuracy
level $\varepsilon$. Further, we demonstrate that the scaling on the effective
horizon $\frac{1}{1-\gamma}$ can be improved by means of variance reduction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Intelligent Healthcare Systems: A Comprehensive Survey. (arXiv:2108.04087v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdellatif_A/0/1/0/all/0/1">Alaa Awad Abdellatif</a>, <a href="http://arxiv.org/find/cs/1/au:+Mhaisen_N/0/1/0/all/0/1">Naram Mhaisen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chkirbene_Z/0/1/0/all/0/1">Zina Chkirbene</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Amr Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1">Aiman Erbad</a>, <a href="http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1">Mohsen Guizani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04087">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid increase in the percentage of chronic disease patients along with
the recent pandemic pose immediate threats on healthcare expenditure and
elevate causes of death. This calls for transforming healthcare systems away
from one-on-one patient treatment into intelligent health systems, to improve
services, access and scalability, while reducing costs. Reinforcement Learning
(RL) has witnessed an intrinsic breakthrough in solving a variety of complex
problems for diverse applications and services. Thus, we conduct in this paper
a comprehensive survey of the recent models and techniques of RL that have been
developed/used for supporting Intelligent-healthcare (I-health) systems. This
paper can guide the readers to deeply understand the state-of-the-art regarding
the use of RL in the context of I-health. Specifically, we first present an
overview for the I-health systems challenges, architecture, and how RL can
benefit these systems. We then review the background and mathematical modeling
of different RL, Deep RL (DRL), and multi-agent RL models. After that, we
provide a deep literature review for the applications of RL in I-health
systems. In particular, three main areas have been tackled, i.e., edge
intelligence, smart core network, and dynamic treatment regimes. Finally, we
highlight emerging challenges and outline future research directions in driving
the future success of RL in I-health systems, which opens the door for
exploring some interesting and unsolved problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Consistency Regularization for Semi-Supervised Transfer Learning. (arXiv:2103.02193v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1">Abulikemu Abuduweili</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xingjian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Humphrey Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Cheng-Zhong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02193">
                                    <div class="article-summary-box-inner">
                                        <span>While recent studies on semi-supervised learning have shown remarkable
progress in leveraging both labeled and unlabeled data, most of them presume a
basic setting of the model is randomly initialized. In this work, we consider
semi-supervised learning and transfer learning jointly, leading to a more
practical and competitive paradigm that can utilize both powerful pre-trained
models from source domain as well as labeled/unlabeled data in the target
domain. To better exploit the value of both pre-trained weights and unlabeled
target examples, we introduce adaptive consistency regularization that consists
of two complementary components: Adaptive Knowledge Consistency (AKC) on the
examples between the source and target model, and Adaptive Representation
Consistency (ARC) on the target model between labeled and unlabeled examples.
Examples involved in the consistency regularization are adaptively selected
according to their potential contributions to the target task. We conduct
extensive experiments on popular benchmarks including CIFAR-10, CUB-200, and
MURA, by fine-tuning the ImageNet pre-trained ResNet-50 model. Results show
that our proposed adaptive consistency regularization outperforms
state-of-the-art semi-supervised learning techniques such as Pseudo Label, Mean
Teacher, and FixMatch. Moreover, our algorithm is orthogonal to existing
methods and thus able to gain additional improvements on top of MixMatch and
FixMatch. Our code is available at
https://github.com/SHI-Labs/Semi-Supervised-Transfer-Learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting False Data Injection Attacks in Smart Grids with Modeling Errors: A Deep Transfer Learning Based Approach. (arXiv:2104.06307v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_B/0/1/0/all/0/1">Bowen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_F/0/1/0/all/0/1">Fanghong Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wen_C/0/1/0/all/0/1">Changyun Wen</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_R/0/1/0/all/0/1">Ruilong Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_W/0/1/0/all/0/1">Wen-An Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06307">
                                    <div class="article-summary-box-inner">
                                        <span>Most traditional false data injection attack (FDIA) detection approaches rely
on a key assumption, i.e., the power system can be accurately modeled. However,
the transmission line parameters are dynamic and cannot be accurately known
during operation and thus the involved modeling errors should not be neglected.
In this paper, an illustrative case has revealed that modeling errors in
transmission lines significantly weaken the detection effectiveness of
conventional FDIA approaches. To tackle this issue, we propose an FDIA
detection mechanism from the perspective of transfer learning. Specifically,
the simulated power system is treated as a source domain, which provides
abundant simulated normal and attack data. The real world&#x27;s running system
whose transmission line parameters are unknown is taken as a target domain
where sufficient real normal data are collected for tracking the latest system
states online. The designed transfer strategy that aims at making full use of
data in hand is divided into two optimization stages. In the first stage, a
deep neural network (DNN) is built by simultaneously optimizing several
well-designed objective terms with both simulated data and real data, and then
it is fine-tuned via real data in the second stage. Several case studies on the
IEEE 14-bus and 118-bus systems verify the effectiveness of the proposed
mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning. (arXiv:2010.03110v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sontakke_S/0/1/0/all/0/1">Sumedh A. Sontakke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1">Arash Mehrjou</a>, <a href="http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1">Laurent Itti</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03110">
                                    <div class="article-summary-box-inner">
                                        <span>Animals exhibit an innate ability to learn regularities of the world through
interaction. By performing experiments in their environment, they are able to
discern the causal factors of variation and infer how they affect the world&#x27;s
dynamics. Inspired by this, we attempt to equip reinforcement learning agents
with the ability to perform experiments that facilitate a categorization of the
rolled-out trajectories, and to subsequently infer the causal factors of the
environment in a hierarchical manner. We introduce {\em causal curiosity}, a
novel intrinsic reward, and show that it allows our agents to learn optimal
sequences of actions and discover causal factors in the dynamics of the
environment. The learned behavior allows the agents to infer a binary quantized
representation for the ground-truth causal factors in every environment.
Additionally, we find that these experimental behaviors are semantically
meaningful (e.g., our agents learn to lift blocks to categorize them by
weight), and are learnt in a self-supervised manner with approximately 2.5
times less data than conventional supervised planners. We show that these
behaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or
other downstream tasks). Finally, we show that the knowledge of causal factor
representations aids zero-shot learning for more complex tasks. Visit
https://sites.google.com/usc.edu/causal-curiosity/home for website.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Gravity: enhancing mobility flows generation with deep neural networks and geographic information. (arXiv:2012.00489v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simini_F/0/1/0/all/0/1">Filippo Simini</a>, <a href="http://arxiv.org/find/cs/1/au:+Barlacchi_G/0/1/0/all/0/1">Gianni Barlacchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luca_M/0/1/0/all/0/1">Massimiliano Luca</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappalardo_L/0/1/0/all/0/1">Luca Pappalardo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00489">
                                    <div class="article-summary-box-inner">
                                        <span>The movements of individuals within and among cities influence critical
aspects of our society, such as well-being, the spreading of epidemics, and the
quality of the environment. When information about mobility flows is not
available for a particular region of interest, we must rely on mathematical
models to generate them. In this work, we propose the Deep Gravity model, an
effective method to generate flow probabilities that exploits many variables
(e.g., land use, road network, transport, food, health facilities) extracted
from voluntary geographic data, and uses deep neural networks to discover
non-linear relationships between those variables and mobility flows. Our
experiments, conducted on mobility flows in England, Italy, and New York State,
show that Deep Gravity has good geographic generalization capability, achieving
a significant increase in performance (especially in densely populated regions
of interest) with respect to the classic gravity model and models that do not
use deep neural networks or geographic data. We also show how flows generated
by Deep Gravity may be explained in terms of the geographic features using
explainable AI techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-learning sparse PCA for multimode process monitoring. (arXiv:2108.03449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Donghua Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Maoyin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03449">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel sparse principal component analysis algorithm
with self-learning ability for successive modes, where synaptic intelligence is
employed to measure the importance of variables and a regularization term is
added to preserve the learned knowledge of previous modes. Different from
traditional multimode monitoring methods, the monitoring model is updated based
on the current model and new data when a new mode arrives, thus delivering
prominent performance for sequential modes. Besides, the computation and
storage resources are saved in the long run, because it is not necessary to
retrain the model from scratch frequently and store data from previous modes.
More importantly, the model furnishes excellent interpretability owing to the
sparsity of parameters. Finally, a numerical case and a practical pulverizing
system are adopted to illustrate the effectiveness of the proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Indoor Layouts from Simple Point-Clouds. (arXiv:2108.03378v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_M/0/1/0/all/0/1">Md. Tareq Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohammed Eunus Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03378">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing a layout of indoor spaces has been a crucial part of growing
indoor location based services. One of the key challenges in the proliferation
of indoor location based services is the unavailability of indoor spatial maps
due to the complex nature of capturing an indoor space model (e.g., floor plan)
of an existing building. In this paper, we propose a system to automatically
generate floor plans that can recognize rooms from the point-clouds obtained
through smartphones like Google&#x27;s Tango. In particular, we propose two
approaches - a Recurrent Neural Network based approach using Pointer Network
and a Convolutional Neural Network based approach using Mask-RCNN to identify
rooms (and thereby floor plans) from point-clouds. Experimental results on
different datasets demonstrate approximately 0.80-0.90 Intersection-over-Union
scores, which show that our models can effectively identify the rooms and
regenerate the shapes of the rooms in heterogeneous environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent Graph Neural Networks for Rumor Detection in Online Forums. (arXiv:2108.03548v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Di Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartel_J/0/1/0/all/0/1">Jacob Bartel</a>, <a href="http://arxiv.org/find/cs/1/au:+Palowitch_J/0/1/0/all/0/1">John Palowitch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03548">
                                    <div class="article-summary-box-inner">
                                        <span>The widespread adoption of online social networks in daily life has created a
pressing need for effectively classifying user-generated content. This work
presents techniques for classifying linked content spread on forum websites --
specifically, links to news articles or blogs -- using user interaction signals
alone. Importantly, online forums such as Reddit do not have a user-generated
social graph, which is assumed in social network behavioral-based
classification settings. Using Reddit as a case-study, we show how to obtain a
derived social graph, and use this graph, Reddit post sequences, and comment
trees as inputs to a Recurrent Graph Neural Network (R-GNN) encoder. We train
the R-GNN on news link categorization and rumor detection, showing superior
results to recent baselines. Our code is made publicly available at
https://github.com/google-research/social_cascades.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time Series Forecasting of New Cases and New Deaths Rate for COVID-19 using Deep Learning Methods. (arXiv:2104.15007v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ayoobi_N/0/1/0/all/0/1">Nooshin Ayoobi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifrazi_D/0/1/0/all/0/1">Danial Sharifrazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1">Roohallah Alizadehsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1">Afshin Shoeibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1">Juan M. Gorriz</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosaei_H/0/1/0/all/0/1">Hossein Moosaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chofreh_A/0/1/0/all/0/1">Abdoulmohammad Gholamzadeh Chofreh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goni_F/0/1/0/all/0/1">Feybi Ariani Goni</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemes_J/0/1/0/all/0/1">Jiri Jaromir Klemes</a>, <a href="http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1">Amir Mosavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.15007">
                                    <div class="article-summary-box-inner">
                                        <span>The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered real-time
forecasting of time series. Six different deep learning methods are examined on
the data adopted from the WHO website. Three methods are LSTM, Convolutional
LSTM, and GRU. The bidirectional extension is then considered for each method
to forecast the rate of new cases and new deaths in Australia and Iran
countries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Missing Data Estimation in Temporal Multilayer Position-aware Graph Neural Network (TMP-GNN). (arXiv:2108.03400v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Najafi_B/0/1/0/all/0/1">Bahareh Najafi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parsaeefard_S/0/1/0/all/0/1">Saeedeh Parsaeefard</a>, <a href="http://arxiv.org/find/cs/1/au:+Leon_Garcia_A/0/1/0/all/0/1">Alberto Leon-Garcia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03400">
                                    <div class="article-summary-box-inner">
                                        <span>GNNs have been proven to perform highly effective in various node-level,
edge-level, and graph-level prediction tasks in several domains. Existing
approaches mainly focus on static graphs. However, many graphs change over time
with their edge may disappear, or node or edge attribute may alter from one
time to the other. It is essential to consider such evolution in representation
learning of nodes in time varying graphs. In this paper, we propose a Temporal
Multilayered Position-aware Graph Neural Network (TMP-GNN), a node embedding
approach for dynamic graph that incorporates the interdependence of temporal
relations into embedding computation. We evaluate the performance of TMP-GNN on
two different representations of temporal multilayered graphs. The performance
is assessed against the most popular GNNs on node-level prediction tasks. Then,
we incorporate TMP-GNN into a deep learning framework to estimate missing data
and compare the performance with their corresponding competent GNNs from our
former experiment, and a baseline method. Experimental results on four
real-world datasets yield up to 58% of lower ROC AUC for pairwise node
classification task, and 96% of lower MAE in missing feature estimation,
particularly for graphs with a relatively high number of nodes and lower mean
degree of connectivity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging. (arXiv:2108.03233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Saffar_A/0/1/0/all/0/1">A. Al-Saffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Stancombe_A/0/1/0/all/0/1">A. Stancombe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_A/0/1/0/all/0/1">A. Zamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbosh_A/0/1/0/all/0/1">A. Abbosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03233">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject&#x27;s movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collapsing the Decision Tree: the Concurrent Data Predictor. (arXiv:2108.03887v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alb_C/0/1/0/all/0/1">Cristian Alb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03887">
                                    <div class="article-summary-box-inner">
                                        <span>A family of concurrent data predictors is derived from the decision tree
classifier by removing the limitation of sequentially evaluating attributes. By
evaluating attributes concurrently, the decision tree collapses into a flat
structure. Experiments indicate improvements of the prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smooth Symbolic Regression: Transformation of Symbolic Regression into a Real-valued Optimization Problem. (arXiv:2108.03274v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pitzer_E/0/1/0/all/0/1">Erik Pitzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1">Gabriel Kronberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03274">
                                    <div class="article-summary-box-inner">
                                        <span>The typical methods for symbolic regression produce rather abrupt changes in
solution candidates. In this work, we have tried to transform symbolic
regression from an optimization problem, with a landscape that is so rugged
that typical analysis methods do not produce meaningful results, to one that
can be compared to typical and very smooth real-valued problems. While the
ruggedness might not interfere with the performance of optimization, it
restricts the possibilities of analysis. Here, we have explored different
aspects of a transformation and propose a simple procedure to create
real-valued optimization problems from symbolic regression problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Jointly Attacking Graph Neural Network and its Explanations. (arXiv:2108.03388v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wenqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Han Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xianfeng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu Aggarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03388">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have boosted the performance for many
graph-related tasks. Despite the great success, recent studies have shown that
GNNs are highly vulnerable to adversarial attacks, where adversaries can
mislead the GNNs&#x27; prediction by modifying graphs. On the other hand, the
explanation of GNNs (GNNExplainer) provides a better understanding of a trained
GNN model by generating a small subgraph and features that are most influential
for its prediction. In this paper, we first perform empirical studies to
validate that GNNExplainer can act as an inspection tool and have the potential
to detect the adversarial perturbations for graphs. This finding motivates us
to further initiate a new problem investigation: Whether a graph neural network
and its explanations can be jointly attacked by modifying graphs with malicious
desires? It is challenging to answer this question since the goals of
adversarial attacks and bypassing the GNNExplainer essentially contradict each
other. In this work, we give a confirmative answer to this question by
proposing a novel attack framework (GEAttack), which can attack both a GNN
model and its explanations by simultaneously exploiting their vulnerabilities.
Extensive experiments on two explainers (GNNExplainer and PGExplainer) under
various real-world datasets demonstrate the effectiveness of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilevel Graph Matching Networks for Deep Graph Similarity Learning. (arXiv:2007.04395v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiang Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Saizhuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengfei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fangli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alex X. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chunming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shouling Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04395">
                                    <div class="article-summary-box-inner">
                                        <span>While the celebrated graph neural networks yield effective representations
for individual nodes of a graph, there has been relatively less success in
extending to the task of graph similarity learning. Recent work on graph
similarity learning has considered either global-level graph-graph interactions
or low-level node-node interactions, however ignoring the rich cross-level
interactions (e.g., between each node of one graph and the other whole graph).
In this paper, we propose a multi-level graph matching network (MGMN) framework
for computing the graph similarity between any pair of graph-structured objects
in an end-to-end fashion. In particular, the proposed MGMN consists of a
node-graph matching network for effectively learning cross-level interactions
between each node of one graph and the other whole graph, and a siamese graph
neural network to learn global-level interactions between two input graphs.
Furthermore, to compensate for the lack of standard benchmark datasets, we have
created and collected a set of datasets for both the graph-graph classification
and graph-graph regression tasks with different sizes in order to evaluate the
effectiveness and robustness of our models. Comprehensive experiments
demonstrate that MGMN consistently outperforms state-of-the-art baseline models
on both the graph-graph classification and graph-graph regression tasks.
Compared with previous work, MGMN also exhibits stronger robustness as the
sizes of the two input graphs increase.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning. (arXiv:2108.03353v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bryan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhourong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Grossman_T/0/1/0/all/0/1">Tovi Grossman</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03353">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile User Interface Summarization generates succinct language descriptions
of mobile screens for conveying important contents and functionalities of the
screen, which can be useful for many language-based application scenarios. We
present Screen2Words, a novel screen summarization approach that automatically
encapsulates essential information of a UI screen into a coherent language
phrase. Summarizing mobile screens requires a holistic understanding of the
multi-modal data of mobile UIs, including text, image, structures as well as UI
semantics, motivating our multi-modal learning approach. We collected and
analyzed a large-scale screen summarization dataset annotated by human workers.
Our dataset contains more than 112k language summarization across $\sim$22k
unique UI screens. We then experimented with a set of deep models with
different configurations. Our evaluation of these models with both automatic
accuracy metrics and human rating shows that our approach can generate
high-quality summaries for mobile screens. We demonstrate potential use cases
of Screen2Words and open-source our dataset and model to lay the foundations
for further bridging language and user interfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HetEmotionNet: Two-Stream Heterogeneous Graph Recurrent Neural Network for Multi-modal Emotion Recognition. (arXiv:2108.03354v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Ziyu Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhiyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiangheng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Caijie Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03354">
                                    <div class="article-summary-box-inner">
                                        <span>The research on human emotion under multimedia stimulation based on
physiological signals is an emerging field, and important progress has been
achieved for emotion recognition based on multi-modal signals. However, it is
challenging to make full use of the complementarity among
spatial-spectral-temporal domain features for emotion recognition, as well as
model the heterogeneity and correlation among multi-modal signals. In this
paper, we propose a novel two-stream heterogeneous graph recurrent neural
network, named HetEmotionNet, fusing multi-modal physiological signals for
emotion recognition. Specifically, HetEmotionNet consists of the
spatial-temporal stream and the spatial-spectral stream, which can fuse
spatial-spectral-temporal domain features in a unified framework. Each stream
is composed of the graph transformer network for modeling the heterogeneity,
the graph convolutional network for modeling the correlation, and the gated
recurrent unit for capturing the temporal domain or spectral domain dependency.
Extensive experiments on two real-world datasets demonstrate that our proposed
model achieves better performance than state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Augmentation for Deep Neural Networks Using 1-D Time Series Vibration Data. (arXiv:2108.03288v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faysal_A/0/1/0/all/0/1">Atik Faysal</a>, <a href="http://arxiv.org/find/cs/1/au:+Keng_N/0/1/0/all/0/1">Ngui Wai Keng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1">M. H. Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03288">
                                    <div class="article-summary-box-inner">
                                        <span>Time-series data are one of the fundamental types of raw data representation
used in data-driven techniques. In machine condition monitoring, time-series
vibration data are overly used in data mining for deep neural networks.
Typically, vibration data is converted into images for classification using
Deep Neural Networks (DNNs), and scalograms are the most effective form of
image representation. However, the DNN classifiers require huge labeled
training samples to reach their optimum performance. So, many forms of data
augmentation techniques are applied to the classifiers to compensate for the
lack of training samples. However, the scalograms are graphical representations
where the existing augmentation techniques suffer because they either change
the graphical meaning or have too much noise in the samples that change the
physical meaning. In this study, a data augmentation technique named ensemble
augmentation is proposed to overcome this limitation. This augmentation method
uses the power of white noise added in ensembles to the original samples to
generate real-like samples. After averaging the signal with ensembles, a new
signal is obtained that contains the characteristics of the original signal.
The parameters for the ensemble augmentation are validated using a simulated
signal. The proposed method is evaluated using 10 class bearing vibration data
using three state-of-the-art Transfer Learning (TL) models, namely,
Inception-V3, MobileNet-V2, and ResNet50. Augmented samples are generated in
two increments: the first increment generates the same number of fake samples
as the training samples, and in the second increment, the number of samples is
increased gradually. The outputs from the proposed method are compared with no
augmentation, augmentations using deep convolution generative adversarial
network (DCGAN), and several geometric transformation-based augmentations...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Iterative Pre-Conditioning for Expediting the Gradient-Descent Method: The Distributed Linear Least-Squares Problem. (arXiv:2008.02856v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chakrabarti_K/0/1/0/all/0/1">Kushal Chakrabarti</a>, <a href="http://arxiv.org/find/math/1/au:+Gupta_N/0/1/0/all/0/1">Nirupam Gupta</a>, <a href="http://arxiv.org/find/math/1/au:+Chopra_N/0/1/0/all/0/1">Nikhil Chopra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02856">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers the multi-agent linear least-squares problem in a
server-agent network. In this problem, the system comprises multiple agents,
each having a set of local data points, that are connected to a server. The
goal for the agents is to compute a linear mathematical model that optimally
fits the collective data points held by all the agents, without sharing their
individual local data points. This goal can be achieved, in principle, using
the server-agent variant of the traditional iterative gradient-descent method.
The gradient-descent method converges linearly to a solution, and its rate of
convergence is lower bounded by the conditioning of the agents&#x27; collective data
points. If the data points are ill-conditioned, the gradient-descent method may
require a large number of iterations to converge.

We propose an iterative pre-conditioning technique that mitigates the
deleterious effect of the conditioning of data points on the rate of
convergence of the gradient-descent method. We rigorously show that the
resulting pre-conditioned gradient-descent method, with the proposed iterative
pre-conditioning, achieves superlinear convergence when the least-squares
problem has a unique solution. In general, the convergence is linear with
improved rate of convergence in comparison to the traditional gradient-descent
method and the state-of-the-art accelerated gradient-descent methods. We
further illustrate the improved rate of convergence of our proposed algorithm
through experiments on different real-world least-squares problems in both
noise-free and noisy computation environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Whittle Index for A Class of Restless Bandits with Imperfect Observations. (arXiv:2108.03812v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Keqin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Ting Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03812">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a class of restless bandit problems that finds a broad
application area in stochastic optimization, reinforcement learning and
operations research. In our model, there are $N$ independent $2$-state Markov
processes that may be observed and accessed for accruing rewards. The
observation is error-prone, i.e., both false alarm and miss detection may
happen. Furthermore, the user can only choose a subset of $M~(M&lt;N)$ processes
to observe at each discrete time. If a process in state~$1$ is correctly
observed, then it will offer some reward. Due to the partial and imperfect
observation model, the system is formulated as a restless multi-armed bandit
problem with an information state space of uncountable cardinality. Restless
bandit problems with finite state spaces are PSPACE-HARD in general. In this
paper, we establish a low-complexity algorithm that achieves a strong
performance for this class of restless bandits. Under certain conditions, we
theoretically prove the existence (indexability) of Whittle index and its
equivalence to our algorithm. When those conditions do not hold, we show by
numerical experiments the near-optimal performance of our algorithm in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixture of Linear Models Co-supervised by Deep Neural Networks. (arXiv:2108.04035v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_B/0/1/0/all/0/1">Beomseok Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04035">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network (DNN) models have achieved phenomenal success for
applications in many domains, ranging from academic research in science and
engineering to industry and business. The modeling power of DNN is believed to
have come from the complexity and over-parameterization of the model, which on
the other hand has been criticized for the lack of interpretation. Although
certainly not true for every application, in some applications, especially in
economics, social science, healthcare industry, and administrative decision
making, scientists or practitioners are resistant to use predictions made by a
black-box system for multiple reasons. One reason is that a major purpose of a
study can be to make discoveries based upon the prediction function, e.g., to
reveal the relationships between measurements. Another reason can be that the
training dataset is not large enough to make researchers feel completely sure
about a purely data-driven result. Being able to examine and interpret the
prediction function will enable researchers to connect the result with existing
knowledge or gain insights about new directions to explore. Although classic
statistical models are much more explainable, their accuracy often falls
considerably below DNN. In this paper, we propose an approach to fill the gap
between relatively simple explainable models and DNN such that we can more
flexibly tune the trade-off between interpretability and accuracy. Our main
idea is a mixture of discriminative models that is trained with the guidance
from a DNN. Although mixtures of discriminative models have been studied
before, our way of generating the mixture is quite different.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness Under Feature Exemptions: Counterfactual and Observational Measures. (arXiv:2006.07986v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sanghamitra Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_P/0/1/0/all/0/1">Praveen Venkatesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mardziel_P/0/1/0/all/0/1">Piotr Mardziel</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1">Anupam Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_P/0/1/0/all/0/1">Pulkit Grover</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07986">
                                    <div class="article-summary-box-inner">
                                        <span>With the growing use of ML in highly consequential domains, quantifying
disparity with respect to protected attributes, e.g., gender, race, etc., is
important. While quantifying disparity is essential, sometimes the needs of an
occupation may require the use of certain features that are critical in a way
that any disparity that can be explained by them might need to be exempted.
E.g., in hiring a software engineer for a safety-critical application,
coding-skills may be weighed strongly, whereas name, zip code, or reference
letters may be used only to the extent that they do not add disparity. In this
work, we propose an information-theoretic decomposition of the total disparity
(a quantification inspired from counterfactual fairness) into two components: a
non-exempt component which quantifies the part that cannot be accounted for by
the critical features, and an exempt component that quantifies the remaining
disparity. This decomposition allows one to check if the disparity arose purely
due to the critical features (inspired from the business necessity defense of
disparate impact law) and also enables selective removal of the non-exempt
component if desired. We arrive at this decomposition through canonical
examples that lead to a set of desirable properties (axioms) that a measure of
non-exempt disparity should satisfy. Our proposed measure satisfies all of
them. Our quantification bridges ideas of causality, Simpson&#x27;s paradox, and a
body of work from information theory called Partial Information Decomposition.
We also obtain an impossibility result showing that no observational measure
can satisfy all the desirable properties, leading us to relax our goals and
examine observational measures that satisfy only some of them. We perform case
studies to show how one can audit/train models while reducing non-exempt
disparity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Multiobjective Minimax Optimization and Applications. (arXiv:2108.03837v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noarov_G/0/1/0/all/0/1">Georgy Noarov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_M/0/1/0/all/0/1">Mallesh Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03837">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a simple but general online learning framework, in which at
every round, an adaptive adversary introduces a new game, consisting of an
action space for the learner, an action space for the adversary, and a vector
valued objective function that is convex-concave in every coordinate. The
learner and the adversary then play in this game. The learner&#x27;s goal is to play
so as to minimize the maximum coordinate of the cumulative vector-valued loss.
The resulting one-shot game is not convex-concave, and so the minimax theorem
does not apply. Nevertheless, we give a simple algorithm that can compete with
the setting in which the adversary must announce their action first, with
optimally diminishing regret.

We demonstrate the power of our simple framework by using it to derive
optimal bounds and algorithms across a variety of domains. This includes no
regret learning: we can recover optimal algorithms and bounds for minimizing
external regret, internal regret, adaptive regret, multigroup regret,
subsequence regret, and a notion of regret in the sleeping experts setting.
Next, we use it to derive a variant of Blackwell&#x27;s Approachability Theorem,
which we term &quot;Fast Polytope Approachability&quot;. Finally, we are able to recover
recently derived algorithms and bounds for online adversarial multicalibration
and related notions (mean-conditioned moment multicalibration, and prediction
interval multivalidity).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language. (arXiv:2012.14353v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behaviour like online
harassment, cyberbullying, and hate speech. Numerous works have been proposed
to utilize textual data for social and anti-social behaviour analysis, by
predicting the contexts mostly for highly-resourced languages like English.
However, some languages are under-resourced, e.g., South Asian languages like
Bengali, that lack computational resources for accurate natural language
processing (NLP). In this paper, we propose an explainable approach for hate
speech detection from the under-resourced Bengali language, which we called
DeepHateExplainer. Bengali texts are first comprehensively preprocessed, before
classifying them into political, personal, geopolitical, and religious hates
using a neural ensemble method of transformer-based neural architectures (i.e.,
monolingual Bangla BERT-base, multilingual BERT-cased/uncased, and
XLM-RoBERTa). Important(most and least) terms are then identified using
sensitivity analysis and layer-wise relevance propagation(LRP), before
providing human-interpretable explanations. Finally, we compute
comprehensiveness and sufficiency scores to measure the quality of explanations
w.r.t faithfulness. Evaluations against machine learning~(linear and tree-based
models) and neural networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word
embeddings) baselines yield F1-scores of 78%, 91%, 89%, and 84%, for political,
personal, geopolitical, and religious hates, respectively, outperforming both
ML and DNN baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stereo Waterdrop Removal with Row-wise Dilated Attention. (arXiv:2108.03457v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zifan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_N/0/1/0/all/0/1">Na Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1">Dit-Yan Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03457">
                                    <div class="article-summary-box-inner">
                                        <span>Existing vision systems for autonomous driving or robots are sensitive to
waterdrops adhered to windows or camera lenses. Most recent waterdrop removal
approaches take a single image as input and often fail to recover the missing
content behind waterdrops faithfully. Thus, we propose a learning-based model
for waterdrop removal with stereo images. To better detect and remove
waterdrops from stereo images, we propose a novel row-wise dilated attention
module to enlarge attention&#x27;s receptive field for effective information
propagation between the two stereo images. In addition, we propose an attention
consistency loss between the ground-truth disparity map and attention scores to
enhance the left-right consistency in stereo images. Because of related
datasets&#x27; unavailability, we collect a real-world dataset that contains stereo
images with and without waterdrops. Extensive experiments on our dataset
suggest that our model outperforms state-of-the-art methods both quantitatively
and qualitatively. Our source code and the stereo waterdrop dataset are
available at
\href{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}{https://github.com/VivianSZF/Stereo-Waterdrop-Removal}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Negative Transfer. (arXiv:2009.00909v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) utilizes data or knowledge from one or more source
domains to facilitate the learning in a target domain. It is particularly
useful when the target domain has very few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., leveraging source
domain data/knowledge undesirably reduces the learning performance in the
target domain, has been a long-standing and challenging problem in TL. Various
approaches have been proposed in the literature to handle it. However, there
does not exist a systematic survey on the formulation of NT, the factors
leading to NT, and the algorithms that mitigate NT. This paper fills this gap,
by first introducing the definition of NT and its factors, then reviewing about
fifty representative approaches for overcoming NT, according to four
categories: secure transfer, domain similarity estimation, distant transfer,
and NT mitigation. NT in related fields, e.g., multi-task learning, lifelong
learning, and adversarial attacks, are also discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Assisted Security Analysis of 5G-Network-Connected Systems. (arXiv:2108.03514v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_T/0/1/0/all/0/1">Tanujay Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Aaraj_N/0/1/0/all/0/1">Najwa Aaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1">Niraj K. Jha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03514">
                                    <div class="article-summary-box-inner">
                                        <span>The core network architecture of telecommunication systems has undergone a
paradigm shift in the fifth-generation (5G)networks. 5G networks have
transitioned to software-defined infrastructures, thereby reducing their
dependence on hardware-based network functions. New technologies, like network
function virtualization and software-defined networking, have been incorporated
in the 5G core network (5GCN) architecture to enable this transition. This has
resulted in significant improvements in efficiency, performance, and robustness
of the networks. However, this has also made the core network more vulnerable,
as software systems are generally easier to compromise than hardware systems.
In this article, we present a comprehensive security analysis framework for the
5GCN. The novelty of this approach lies in the creation and analysis of attack
graphs of the software-defined and virtualized 5GCN through machine learning.
This analysis points to 119 novel possible exploits in the 5GCN. We demonstrate
that these possible exploits of 5GCN vulnerabilities generate five novel
attacks on the 5G Authentication and Key Agreement protocol. We combine the
attacks at the network, protocol, and the application layers to generate
complex attack vectors. In a case study, we use these attack vectors to find
four novel security loopholes in WhatsApp running on a 5G network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                    <div class="article-summary-box-inner">
                                        <span>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Model Evaluation in Open-ended Text Generation. (arXiv:2108.03578v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">An Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03578">
                                    <div class="article-summary-box-inner">
                                        <span>Although current state-of-the-art language models have achieved impressive
results in numerous natural language processing tasks, still they could not
solve the problem of producing repetitive, dull and sometimes inconsistent text
in open-ended text generation. Studies often attribute this problem to the
maximum likelihood training objective, and propose alternative approaches by
using stochastic decoding methods or altering the training objective. However,
there is still a lack of consistent evaluation metrics to directly compare the
efficacy of these solutions. In this work, we study different evaluation
metrics that have been proposed to evaluate quality, diversity and consistency
of machine-generated text. From there, we propose a practical pipeline to
evaluate language models in open-ended generation task, and research on how to
improve the model&#x27;s performance in all dimensions by leveraging different
auxiliary training objectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1">Pratik Ramprasad</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1">Yuantong Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1">Will Wei Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1">Guang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03706">
                                    <div class="article-summary-box-inner">
                                        <span>The recent emergence of reinforcement learning has created a demand for
robust statistical inference methods for the parameter estimates computed using
these algorithms. Existing methods for statistical inference in online learning
are restricted to settings involving independently sampled observations, while
existing statistical inference methods in reinforcement learning (RL) are
limited to the batch setting. The online bootstrap is a flexible and efficient
approach for statistical inference in linear stochastic approximation
algorithms, but its efficacy in settings involving Markov noise, such as RL,
has yet to be explored. In this paper, we study the use of the online bootstrap
method for statistical inference in RL. In particular, we focus on the temporal
difference (TD) learning and Gradient TD (GTD) learning algorithms, which are
themselves special instances of linear stochastic approximation under Markov
noise. The method is shown to be distributionally consistent for statistical
inference in policy evaluation, and numerical experiments are included to
demonstrate the effectiveness of this algorithm at statistical inference tasks
across a range of real RL environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Transformers for Neural Cross-Domain Search. (arXiv:2108.03322v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1">Colin B. Clement</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1">Dawn Drain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1">Neel Sundaresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03322">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained transformers have recently clinched top spots in the gamut of
natural language tasks and pioneered solutions to software engineering tasks.
Even information retrieval has not been immune to the charm of the transformer,
though their large size and cost is generally a barrier to deployment. While
there has been much work in streamlining, caching, and modifying transformer
architectures for production, here we explore a new direction: distilling a
large pre-trained translation model into a lightweight bi-encoder which can be
efficiently cached and queried. We argue from a probabilistic perspective that
sequence-to-sequence models are a conceptually ideal---albeit highly
impractical---retriever. We derive a new distillation objective, implementing
it as a data augmentation scheme. Using natural language source code search as
a case study for cross-domain search, we demonstrate the validity of this idea
by significantly improving upon the current leader of the CodeSearchNet
challenge, a recent natural language code search benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bob and Alice Go to a Bar: Reasoning About Future With Probabilistic Programs. (arXiv:2108.03834v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolpin_D/0/1/0/all/0/1">David Tolpin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobkin_T/0/1/0/all/0/1">Tomer Dobkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03834">
                                    <div class="article-summary-box-inner">
                                        <span>Agent preferences should be specified stochastically rather than
deterministically. Planning as inference with stochastic preferences naturally
describes agent behaviors, does not require introducing rewards and exponential
weighing of behaviors, and allows to reason about agents using the solid
foundation of Bayesian statistics. Stochastic conditioning is the formalism
behind agents with stochastic preferences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised learning of anomalous diffusion data. (arXiv:2108.03411v1 [cond-mat.stat-mech])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Munoz_Gil_G/0/1/0/all/0/1">Gorka Mu&#xf1;oz-Gil</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Corominas_G/0/1/0/all/0/1">Guillem Guig&#xf3; i Corominas</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lewenstein_M/0/1/0/all/0/1">Maciej Lewenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03411">
                                    <div class="article-summary-box-inner">
                                        <span>The characterization of diffusion processes is a keystone in our
understanding of a variety of physical phenomena. Many of these deviate from
Brownian motion, giving rise to anomalous diffusion. Various theoretical models
exists nowadays to describe such processes, but their application to
experimental setups is often challenging, due to the stochastic nature of the
phenomena and the difficulty to harness reliable data. The latter often
consists on short and noisy trajectories, which are hard to characterize with
usual statistical approaches. In recent years, we have witnessed an impressive
effort to bridge theory and experiments by means of supervised machine learning
techniques, with astonishing results. In this work, we explore the use of
unsupervised methods in anomalous diffusion data. We show that the main
diffusion characteristics can be learnt without the need of any labelling of
the data. We use such method to discriminate between anomalous diffusion models
and extract their physical parameters. Moreover, we explore the feasibility of
finding novel types of diffusion, in this case represented by compositions of
existing diffusion models. At last, we showcase the use of the method in
experimental data and demonstrate its advantages for cases where supervised
learning is not applicable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Last Iterate Convergence in Overparameterized GANs. (arXiv:2108.03491v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_E/0/1/0/all/0/1">Elbert Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03491">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we showed that the Implicit Update and Predictive Methods
dynamics introduced in prior work satisfy last iterate convergence to a
neighborhood around the optimum in overparameterized GANs, where the size of
the neighborhood shrinks with the width of the neural network. This is in
contrast to prior results, which only guaranteed average iterate convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge-augmented Graph Transformers: Global Self-attention is Enough for Graphs. (arXiv:2108.03348v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussain_M/0/1/0/all/0/1">Md Shamim Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaki_M/0/1/0/all/0/1">Mohammed J. Zaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_D/0/1/0/all/0/1">Dharmashankar Subramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03348">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer neural networks have achieved state-of-the-art results for
unstructured data such as text and images but their adoption for
graph-structured data has been limited. This is partly due to the difficulty in
incorporating complex structural information in the basic transformer
framework. We propose a simple yet powerful extension to the transformer -
residual edge channels. The resultant framework, which we call Edge-augmented
Graph Transformer (EGT), can directly accept, process and output structural
information as well as node information. This simple addition allows us to use
global self-attention, the key element of transformers, directly for graphs and
comes with the benefit of long-range interaction among nodes. Moreover, the
edge channels allow the structural information to evolve from layer to layer,
and prediction tasks on edges can be derived directly from these channels. In
addition to that, we introduce positional encodings based on Singular Value
Decomposition which can improve the performance of EGT. Our framework, which
relies on global node feature aggregation, achieves better performance compared
to Graph Convolutional Networks (GCN), which rely on local feature aggregation
within a neighborhood. We verify the performance of EGT in a supervised
learning setting on a wide range of experiments on benchmark datasets. Our
findings indicate that convolutional aggregation is not an essential inductive
bias for graphs and global self-attention can serve as a flexible and adaptive
alternative to graph convolution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Representation for Electric Vehicle Charging Station Operations using Reinforcement Learning. (arXiv:2108.03236v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwon_K/0/1/0/all/0/1">Kyung-bin Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03236">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively operating electrical vehicle charging station (EVCS) is crucial
for enabling the rapid transition of electrified transportation. To solve this
problem using reinforcement learning (RL), the dimension of state/action spaces
scales with the number of EVs and is thus very large and time-varying. This
dimensionality issue affects the efficiency and convergence properties of
generic RL algorithms. We develop aggregation schemes that are based on the
emergency of EV charging, namely the laxity value. A least-laxity first (LLF)
rule is adopted to consider only the total charging power of the EVCS which
ensures the feasibility of individual EV schedules. In addition, we propose an
equivalent state aggregation that can guarantee to attain the same optimal
policy. Based on the proposed representation, policy gradient method is used to
find the best parameters for the linear Gaussian policy . Numerical results
have validated the performance improvement of the proposed representation
approaches in attaining higher rewards and more effective policies as compared
to existing approximation based approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FIFA: Fast Inference Approximation for Action Segmentation. (arXiv:2108.03894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Farha_Y/0/1/0/all/0/1">Yazan Abu Farha</a>, <a href="http://arxiv.org/find/cs/1/au:+Despinoy_F/0/1/0/all/0/1">Fabien Despinoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03894">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce FIFA, a fast approximate inference method for action
segmentation and alignment. Unlike previous approaches, FIFA does not rely on
expensive dynamic programming for inference. Instead, it uses an approximate
differentiable energy function that can be minimized using gradient-descent.
FIFA is a general approach that can replace exact inference improving its speed
by more than 5 times while maintaining its performance. FIFA is an anytime
inference algorithm that provides a better speed vs. accuracy trade-off
compared to exact inference. We apply FIFA on top of state-of-the-art
approaches for weakly supervised action segmentation and alignment as well as
fully supervised action segmentation. FIFA achieves state-of-the-art results on
most metrics on two action segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Some thoughts on catastrophic forgetting and how to learn an algorithm. (arXiv:2108.03940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_M/0/1/0/all/0/1">Miguel Ruiz-Garcia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03940">
                                    <div class="article-summary-box-inner">
                                        <span>The work of McCloskey and Cohen popularized the concept of catastrophic
interference. They used a neural network that tried to learn addition using two
groups of examples as two different tasks. In their case, learning the second
task rapidly deteriorated the acquired knowledge about the previous one. This
could be a symptom of a fundamental problem: addition is an algorithmic task
that should not be learned through pattern recognition. We propose to use a
neural network with a different architecture that can be trained to recover the
correct algorithm for the addition of binary numbers. We test it in the setting
proposed by McCloskey and Cohen and training on random examples one by one. The
neural network not only does not suffer from catastrophic forgetting but it
improves its predictive power on unseen pairs of numbers as training
progresses. This work emphasizes the importance that neural network
architecture has for the emergence of catastrophic forgetting and introduces a
neural network that is able to learn an algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Ashwin Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1">Adriel Saporta</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1">Steven QH Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1">Du Nguyen Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tan Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1">Pierre Chambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1">Matthew P. Lungren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1">Curtis P. Langlotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Federated Learning: Balancing Communication and Computing Costs. (arXiv:2107.12048v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenyi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12048">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized federated learning (DFL) is a powerful framework of distributed
machine learning and decentralized stochastic gradient descent (SGD) is a
driving engine for DFL. The performance of decentralized SGD is jointly
influenced by communication-efficiency and convergence rate. In this paper, we
propose a general decentralized federated learning framework to strike a
balance between communication-efficiency and convergence performance. The
proposed framework performs both multiple local updates and multiple inter-node
communications periodically, unifying traditional decentralized SGD methods. We
establish strong convergence guarantees for the proposed DFL algorithm without
the assumption of convex objective function. The balance of communication and
computation rounds is essential to optimize decentralized federated learning
under constrained communication and computation resources. For further
improving communication-efficiency of DFL, compressed communication is applied
to DFL, named DFL with compressed communication (C-DFL). The proposed C-DFL
exhibits linear convergence for strongly convex objectives. Experiment results
based on MNIST and CIFAR-10 datasets illustrate the superiority of DFL over
traditional decentralized SGD methods and show that C-DFL further enhances
communication-efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Relative Order Attack in Deep Ranking. (arXiv:2103.05248v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1">Zhenxing Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05248">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies unveil the vulnerabilities of deep ranking models, where an
imperceptible perturbation can trigger dramatic changes in the ranking result.
While previous attempts focus on manipulating absolute ranks of certain
candidates, the possibility of adjusting their relative order remains
under-explored. In this paper, we formulate a new adversarial attack against
deep ranking systems, i.e., the Order Attack, which covertly alters the
relative order among a selected set of candidates according to an
attacker-specified permutation, with limited interference to other unrelated
candidates. Specifically, it is formulated as a triplet-style loss imposing an
inequality chain reflecting the specified permutation. However, direct
optimization of such white-box objective is infeasible in a real-world attack
scenario due to various black-box limitations. To cope with them, we propose a
Short-range Ranking Correlation metric as a surrogate objective for black-box
Order Attack to approximate the white-box method. The Order Attack is evaluated
on the Fashion-MNIST and Stanford-Online-Products datasets under both white-box
and black-box threat models. The black-box attack is also successfully
implemented on a major e-commerce platform. Comprehensive experimental
evaluations demonstrate the effectiveness of the proposed methods, revealing a
new type of ranking model vulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DCAP: Deep Cross Attentional Product Network for User Response Prediction. (arXiv:2105.08649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                    <div class="article-summary-box-inner">
                                        <span>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network&#x27;s benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Dimensionality Reduction for Comparative Analysis. (arXiv:2106.15481v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fujiwara_T/0/1/0/all/0/1">Takanori Fujiwara</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xinhai Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kwan-Liu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15481">
                                    <div class="article-summary-box-inner">
                                        <span>Finding the similarities and differences between groups of datasets is a
fundamental analysis task. For high-dimensional data, dimensionality reduction
(DR) methods are often used to find the characteristics of each group. However,
existing DR methods provide limited capability and flexibility for such
comparative analysis as each method is designed only for a narrow analysis
target, such as identifying factors that most differentiate groups. This paper
presents an interactive DR framework where we integrate our new DR method,
called ULCA (unified linear comparative analysis), with an interactive visual
interface. ULCA unifies two DR schemes, discriminant analysis and contrastive
learning, to support various comparative analysis tasks. To provide flexibility
for comparative analysis, we develop an optimization algorithm that enables
analysts to interactively refine ULCA results. Additionally, the interactive
visualization interface facilitates interpretation and refinement of the ULCA
results. We evaluate ULCA and the optimization algorithm to show their
efficiency as well as present multiple case studies using real-world datasets
to demonstrate the usefulness of this framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution. (arXiv:2108.03541v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1">Eric Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Tu Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_V/0/1/0/all/0/1">Vishy Swaminathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1">John Collomosse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03541">
                                    <div class="article-summary-box-inner">
                                        <span>Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
object&#x27;s visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Biological Variables and Social Determinants to Predict Malaria and Anemia among Children in Senegal. (arXiv:2108.03601v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sow_B/0/1/0/all/0/1">Boubacar Sow</a>, <a href="http://arxiv.org/find/cs/1/au:+Suguri_H/0/1/0/all/0/1">Hiroki Suguri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhtar_H/0/1/0/all/0/1">Hamid Mukhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_H/0/1/0/all/0/1">Hafiz Farooq Ahmad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03601">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating machine learning techniques in healthcare becomes very common
nowadays, and it contributes positively to improving clinical care and health
decisions planning. Anemia and malaria are two life-threatening diseases in
Africa that affect the red blood cells and reduce hemoglobin production. This
paper focuses on analyzing child health data in Senegal using four machine
learning algorithms in Python: KNN, Random Forests, SVM, and Na\&quot;ive Bayes. Our
task aims to investigate large-scale data from The Demographic and Health
Survey (DHS) and to find out hidden information for anemia and malaria. We
present two classification models for the two blood disorders using biological
variables and social determinants. The findings of this research will
contribute to improving child healthcare in Senegal by eradicating anemia and
malaria, and decreasing the child mortality rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differential Evolution for Neural Architecture Search. (arXiv:2012.06400v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awad_N/0/1/0/all/0/1">Noor Awad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1">Neeratyoy Mallik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06400">
                                    <div class="article-summary-box-inner">
                                        <span>Neural architecture search (NAS) methods rely on a search strategy for
deciding which architectures to evaluate next and a performance estimation
strategy for assessing their performance (e.g., using full evaluations,
multi-fidelity evaluations, or the one-shot model). In this paper, we focus on
the search strategy. We introduce the simple yet powerful evolutionary
algorithm of differential evolution to the NAS community. Using the simplest
performance evaluation strategy of full evaluations, we comprehensively compare
this search strategy to regularized evolution and Bayesian optimization and
demonstrate that it yields improved and more robust results for 13 tabular NAS
benchmarks based on NAS-Bench-101, NAS-Bench-1Shot1, NAS-Bench-201 and NAS-HPO
bench.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Algorithms to Analyze the Road Traffic Crashes. (arXiv:2108.03490v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Mahnaz Rafia Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenny_I/0/1/0/all/0/1">Israt Jahan Jenny</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayon_M/0/1/0/all/0/1">Moniruzzaman Nayon</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Md. Rajibul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Amiruzzaman_M/0/1/0/all/0/1">Md Amiruzzaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdullah_Al_Wadud_M/0/1/0/all/0/1">M. Abdullah-Al-Wadud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03490">
                                    <div class="article-summary-box-inner">
                                        <span>Selecting an appropriate clustering method as well as an optimal number of
clusters in road accident data is at times confusing and difficult. This paper
analyzes shortcomings of different existing techniques applied to cluster
accident-prone areas and recommends using Density-Based Spatial Clustering of
Applications with Noise (DBSCAN) and Ordering Points To Identify the Clustering
Structure (OPTICS) to overcome them. Comparative performance analysis based on
real-life data on the recorded cases of road accidents in North Carolina also
show more effectiveness and efficiency achieved by these algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Membership Inference Attacks on Lottery Ticket Networks. (arXiv:2108.03506v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagmar_A/0/1/0/all/0/1">Aadesh Bagmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Maiya_S/0/1/0/all/0/1">Shishira R Maiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidwalka_S/0/1/0/all/0/1">Shruti Bidwalka</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amol Deshpande</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03506">
                                    <div class="article-summary-box-inner">
                                        <span>The vulnerability of the Lottery Ticket Hypothesis has not been studied from
the purview of Membership Inference Attacks. Through this work, we are the
first to empirically show that the lottery ticket networks are equally
vulnerable to membership inference attacks. A Membership Inference Attack (MIA)
is the process of determining whether a data sample belongs to a training set
of a trained model or not. Membership Inference Attacks could leak critical
information about the training data that can be used for targeted attacks.
Recent deep learning models often have very large memory footprints and a high
computational cost associated with training and drawing inferences. Lottery
Ticket Hypothesis is used to prune the networks to find smaller sub-networks
that at least match the performance of the original model in terms of test
accuracy in a similar number of iterations. We used CIFAR-10, CIFAR-100, and
ImageNet datasets to perform image classification tasks and observe that the
attack accuracies are similar. We also see that the attack accuracy varies
directly according to the number of classes in the dataset and the sparsity of
the network. We demonstrate that these attacks are transferable across models
with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporation of Deep Neural Network &amp; Reinforcement Learning with Domain Knowledge. (arXiv:2107.14613v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karn_A/0/1/0/all/0/1">Aryan Karn</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Ashutosh Acharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14613">
                                    <div class="article-summary-box-inner">
                                        <span>We present a study of the manners by which Domain information has been
incorporated when building models with Neural Networks. Integrating space data
is uniquely important to the development of Knowledge understanding model, as
well as other fields that aid in understanding information by utilizing the
human-machine interface and Reinforcement Learning. On numerous such occasions,
machine-based model development may profit essentially from the human
information on the world encoded in an adequately exact structure. This paper
inspects expansive ways to affect encode such information as sensible and
mathematical limitations and portrays methods and results that came to a couple
of subcategories under all of those methodologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Source Separation in Polyphonic Music Recordings Using Deep Neural Networks Trained via Policy Gradients. (arXiv:2107.04235v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schulze_S/0/1/0/all/0/1">S&#xf6;ren Schulze</a>, <a href="http://arxiv.org/find/eess/1/au:+Leuschner_J/0/1/0/all/0/1">Johannes Leuschner</a>, <a href="http://arxiv.org/find/eess/1/au:+King_E/0/1/0/all/0/1">Emily J. King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04235">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method for the blind separation of sounds of musical instruments
in audio signals. We describe the individual tones via a parametric model,
training a dictionary to capture the relative amplitudes of the harmonics. The
model parameters are predicted via a U-Net, which is a type of deep neural
network. The network is trained without ground truth information, based on the
difference between the model prediction and the individual time frames of the
short-time Fourier transform. Since some of the model parameters do not yield a
useful backpropagation gradient, we model them stochastically and employ the
policy gradient instead. To provide phase information and account for
inaccuracies in the dictionary-based representation, we also let the network
output a direct prediction, which we then use to resynthesize the audio signals
for the individual instruments. Due to the flexibility of the neural network,
inharmonicity can be incorporated seamlessly and no preprocessing of the input
spectra is required. Our algorithm yields high-quality separation results with
particularly low interference on a variety of different audio samples, both
acoustic and synthetic, provided that the sample contains enough data for the
training and that the spectral characteristics of the musical instruments are
sufficiently stable to be approximated by the dictionary.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomy 2.0: Why is self-driving always 5 years away?. (arXiv:2107.08142v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Ashesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1">Luca Del Pero</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1">Hugo Grimmett</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1">Peter Ondruska</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08142">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the numerous successes of machine learning over the past decade
(image recognition, decision-making, NLP, image synthesis), self-driving
technology has not yet followed the same trend. In this paper, we study the
history, composition, and development bottlenecks of the modern self-driving
stack. We argue that the slow progress is caused by approaches that require too
much hand-engineering, an over-reliance on road testing, and high fleet
deployment costs. We observe that the classical stack has several bottlenecks
that preclude the necessary scale needed to capture the long tail of rare
events. To resolve these problems, we outline the principles of Autonomy 2.0,
an ML-first approach to self-driving, as a viable alternative to the currently
adopted state-of-the-art. This approach is based on (i) a fully differentiable
AV stack trainable from human demonstrations, (ii) closed-loop data-driven
reactive simulation, and (iii) large-scale, low-cost data collections as
critical solutions towards scalability issues. We outline the general
architecture, survey promising works in this direction and propose key
challenges to be addressed by the community in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonconvex sparse regularization for deep neural networks and its optimality. (arXiv:2003.11769v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Ohn_I/0/1/0/all/0/1">Ilsang Ohn</a>, <a href="http://arxiv.org/find/math/1/au:+Kim_Y/0/1/0/all/0/1">Yongdai Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.11769">
                                    <div class="article-summary-box-inner">
                                        <span>Recent theoretical studies proved that deep neural network (DNN) estimators
obtained by minimizing empirical risk with a certain sparsity constraint can
attain optimal convergence rates for regression and classification problems.
However, the sparsity constraint requires to know certain properties of the
true model, which are not available in practice. Moreover, computation is
difficult due to the discrete nature of the sparsity constraint. In this paper,
we propose a novel penalized estimation method for sparse DNNs, which resolves
the aforementioned problems existing in the sparsity constraint. We establish
an oracle inequality for the excess risk of the proposed sparse-penalized DNN
estimator and derive convergence rates for several learning tasks. In
particular, we prove that the sparse-penalized estimator can adaptively attain
minimax convergence rates for various nonparametric regression problems. For
computation, we develop an efficient gradient-based optimization algorithm that
guarantees the monotonic reduction of the objective function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">M6-T: Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Le Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xianyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Ang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiamang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Di Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Lin Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15082">
                                    <div class="article-summary-box-inner">
                                        <span>Mixture-of-Experts (MoE) models can achieve promising results with outrageous
large amount of parameters but constant computation cost, and thus it has
become a trend in model scaling. Still it is a mystery how MoE layers bring
quality gains by leveraging the parameters with sparse activation. In this
work, we investigate several key factors in sparse expert models. We observe
that load imbalance may not be a significant problem affecting model quality,
contrary to the perspectives of recent studies, while the number of sparsely
activated experts $k$ and expert capacity $C$ in top-$k$ routing can
significantly make a difference in this context. Furthermore, we take a step
forward to propose a simple method called expert prototyping that splits
experts into different prototypes and applies $k$ top-$1$ routing. This
strategy improves the model quality but maintains constant computational costs,
and our further exploration on extremely large-scale models reflects that it is
more effective in training larger models. We push the model scale to over $1$
trillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in
comparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model
achieves substantial speedup in convergence over the same-size baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint AP Probing and Scheduling: A Contextual Bandit Approach. (arXiv:2108.03297v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tianyi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Ding Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_P/0/1/0/all/0/1">Parth H. Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zizhan Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03297">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a set of APs with unknown data rates that cooperatively serve a
mobile client. The data rate of each link is i.i.d. sampled from a distribution
that is unknown a priori. In contrast to traditional link scheduling problems
under uncertainty, we assume that in each time step, the device can probe a
subset of links before deciding which one to use. We model this problem as a
contextual bandit problem with probing (CBwP) and present an efficient
algorithm. We further establish the regret of our algorithm for links with
Bernoulli data rates. Our CBwP model is a novel extension of the classic
contextual bandit model and can potentially be applied to a large class of
sequential decision-making problems that involve joint probing and play under
uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Deep Reinforcement Learning for Multi-Agent Systems with Continuous Action Spaces. (arXiv:2108.03952v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheebaelhamd_Z/0/1/0/all/0/1">Ziyad Sheebaelhamd</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisis_K/0/1/0/all/0/1">Konstantinos Zisis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nisioti_A/0/1/0/all/0/1">Athina Nisioti</a>, <a href="http://arxiv.org/find/cs/1/au:+Gkouletsos_D/0/1/0/all/0/1">Dimitris Gkouletsos</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1">Dario Pavllo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_J/0/1/0/all/0/1">Jonas Kohler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03952">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent control problems constitute an interesting area of application
for deep reinforcement learning models with continuous action spaces. Such
real-world applications, however, typically come with critical safety
constraints that must not be violated. In order to ensure safety, we enhance
the well-known multi-agent deep deterministic policy gradient (MADDPG)
framework by adding a safety layer to the deep policy network. %which
automatically corrects invalid actions. In particular, we extend the idea of
linearizing the single-step transition dynamics, as was done for single-agent
systems in Safe DDPG (Dalal et al., 2018), to multi-agent settings. We
additionally propose to circumvent infeasibility problems in the action
correction step using soft constraints (Kerrigan &amp; Maciejowski, 2000). Results
from the theory of exact penalty functions can be used to guarantee constraint
satisfaction of the soft constraints under mild assumptions. We empirically
find that the soft formulation achieves a dramatic decrease in constraint
violations, making safety available even during the learning procedure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fed-BEV: A Federated Learning Framework for Modelling Energy Consumption of Battery Electric Vehicles. (arXiv:2108.04036v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04036">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing interest in the roll-out of electric
vehicles (EVs) in the global automotive market. Compared to conventional
internal combustion engine vehicles (ICEVs), EVs can not only help users reduce
monetary costs in their daily commuting, but also can effectively help mitigate
the increasing level of traffic emissions produced in cities. Among many
others, battery electric vehicles (BEVs) exclusively use chemical energy stored
in their battery packs for propulsion. Hence, it becomes important to
understand how much energy can be consumed by such vehicles in various traffic
scenarios towards effective energy management. To address this challenge, we
propose a novel framework in this paper by leveraging the federated learning
approaches for modelling energy consumption for BEVs (Fed-BEV). More
specifically, a group of BEVs involved in the Fed-BEV framework can learn from
each other to jointly enhance their energy consumption model. We present the
design of the proposed system architecture and implementation details in a
co-simulation environment. Finally, comparative studies and simulation results
are discussed to illustrate the efficacy of our proposed framework for accurate
energy modelling of BEVs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting. (arXiv:2107.12619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Hyperparameters in Stochastic Gradient Descent with Momentum. (arXiv:2108.03947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Bin Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03947">
                                    <div class="article-summary-box-inner">
                                        <span>Following the same routine as [SSJ20], we continue to present the theoretical
analysis for stochastic gradient descent with momentum (SGD with momentum) in
this paper. Differently, for SGD with momentum, we demonstrate it is the two
hyperparameters together, the learning rate and the momentum coefficient, that
play the significant role for the linear rate of convergence in non-convex
optimization. Our analysis is based on the use of a hyperparameters-dependent
stochastic differential equation (hp-dependent SDE) that serves as a continuous
surrogate for SGD with momentum. Similarly, we establish the linear convergence
for the continuous-time formulation of SGD with momentum and obtain an explicit
expression for the optimal linear rate by analyzing the spectrum of the
Kramers-Fokker-Planck operator. By comparison, we demonstrate how the optimal
linear rate of convergence and the final gap for SGD only about the learning
rate varies with the momentum coefficient increasing from zero to one when the
momentum is introduced. Then, we propose a mathematical interpretation why the
SGD with momentum converges faster and more robust about the learning rate than
the standard SGD in practice. Finally, we show the Nesterov momentum under the
existence of noise has no essential difference with the standard momentum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Based Reinforcement Learning via Latent-Space Collocation. (arXiv:2106.13229v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rybkin_O/0/1/0/all/0/1">Oleh Rybkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chuning Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagabandi_A/0/1/0/all/0/1">Anusha Nagabandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1">Kostas Daniilidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13229">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to plan into the future while utilizing only raw high-dimensional
observations, such as images, can provide autonomous agents with broad
capabilities. Visual model-based reinforcement learning (RL) methods that plan
future actions directly have shown impressive results on tasks that require
only short-horizon reasoning, however, these methods struggle on temporally
extended tasks. We argue that it is easier to solve long-horizon tasks by
planning sequences of states rather than just actions, as the effects of
actions greatly compound over time and are harder to optimize. To achieve this,
we draw on the idea of collocation, which has shown good results on
long-horizon tasks in optimal control literature, and adapt it to the
image-based setting by utilizing learned latent state space models. The
resulting latent collocation method (LatCo) optimizes trajectories of latent
states, which improves over previously proposed shooting methods for visual
model-based RL on tasks with sparse rewards and long-term goals. Videos and
code at https://orybkin.github.io/latco/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Machine learning approach for rapid disaster response based on multi-modal data. The case of housing &amp; shelter needs. (arXiv:2108.00887v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ochoa_K/0/1/0/all/0/1">Karla Saldana Ochoa</a>, <a href="http://arxiv.org/find/cs/1/au:+Comes_T/0/1/0/all/0/1">Tina Comes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00887">
                                    <div class="article-summary-box-inner">
                                        <span>Along with climate change, more frequent extreme events, such as flooding and
tropical cyclones, threaten the livelihoods and wellbeing of poor and
vulnerable populations. One of the most immediate needs of people affected by a
disaster is finding shelter. While the proliferation of data on disasters is
already helping to save lives, identifying damages in buildings, assessing
shelter needs, and finding appropriate places to establish emergency shelters
or settlements require a wide range of data to be combined rapidly. To address
this gap and make a headway in comprehensive assessments, this paper proposes a
machine learning workflow that aims to fuse and rapidly analyse multimodal
data. This workflow is built around open and online data to ensure scalability
and broad accessibility. Based on a database of 19 characteristics for more
than 200 disasters worldwide, a fusion approach at the decision level was used.
This technique allows the collected multimodal data to share a common semantic
space that facilitates the prediction of individual variables. Each fused
numerical vector was fed into an unsupervised clustering algorithm called
Self-Organizing-Maps (SOM). The trained SOM serves as a predictor for future
cases, allowing predicting consequences such as total deaths, total people
affected, and total damage, and provides specific recommendations for
assessments in the shelter and housing sector. To achieve such prediction, a
satellite image from before the disaster and the geographic and demographic
conditions are shown to the trained model, which achieved a prediction accuracy
of 62 %</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ranger21: a synergistic deep learning optimizer. (arXiv:2106.13731v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wright_L/0/1/0/all/0/1">Less Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeure_N/0/1/0/all/0/1">Nestor Demeure</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13731">
                                    <div class="article-summary-box-inner">
                                        <span>As optimizers are critical to the performances of neural networks, every year
a large number of papers innovating on the subject are published. However,
while most of these publications provide incremental improvements to existing
algorithms, they tend to be presented as new optimizers rather than composable
algorithms. Thus, many worthwhile improvements are rarely seen out of their
initial publication. Taking advantage of this untapped potential, we introduce
Ranger21, a new optimizer which combines AdamW with eight components, carefully
selected after reviewing and testing ideas from the literature. We found that
the resulting optimizer provides significantly improved validation accuracy and
training speed, smoother training curves, and is even able to train a ResNet50
on ImageNet2012 without Batch Normalization layers. A problem on which AdamW
stays systematically stuck in a bad initial state.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Quantum Potentials by Deep Neural Network and Metropolis Sampling. (arXiv:2106.03126v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Hong_R/0/1/0/all/0/1">Rui Hong</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1">Peng-Fei Zhou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Xi_B/0/1/0/all/0/1">Bin Xi</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ji_A/0/1/0/all/0/1">An-Chun Ji</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03126">
                                    <div class="article-summary-box-inner">
                                        <span>The hybridizations of machine learning and quantum physics have caused
essential impacts to the methodology in both fields. Inspired by quantum
potential neural network, we here propose to solve the potential in the
Schrodinger equation provided the eigenstate, by combining Metropolis sampling
with deep neural network, which we dub as Metropolis potential neural network
(MPNN). A loss function is proposed to explicitly involve the energy in the
optimization for its accurate evaluation. Benchmarking on the harmonic
oscillator and hydrogen atom, MPNN shows excellent accuracy and stability on
predicting not just the potential to satisfy the Schrodinger equation, but also
the eigen-energy. Our proposal could be potentially applied to the ab-initio
simulations, and to inversely solving other partial differential equations in
physics and beyond.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to &quot;Improve&quot; Prediction Using Behavior Modification. (arXiv:2008.12138v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shmueli_G/0/1/0/all/0/1">Galit Shmueli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tafti_A/0/1/0/all/0/1">Ali Tafti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12138">
                                    <div class="article-summary-box-inner">
                                        <span>Many internet platforms that collect behavioral big data use it to predict
user behavior for internal purposes and for their business customers (e.g.,
advertisers, insurers, security forces, governments, political consulting
firms) who utilize the predictions for personalization, targeting, and other
decision-making. Improving predictive accuracy is therefore extremely valuable.
Data science researchers design algorithms, models, and approaches to improve
prediction. Prediction is also improved with larger and richer data. Beyond
improving algorithms and data, platforms can stealthily achieve better
prediction accuracy by &quot;pushing&quot; users&#x27; behaviors towards their predicted
values, using behavior modification techniques, thereby demonstrating more
certain predictions. Such apparent &quot;improved&quot; prediction can unintentionally
result from employing reinforcement learning algorithms that combine prediction
and behavior modification. This strategy is absent from the machine learning
and statistics literature. Investigating its properties requires integrating
causal with predictive notation. To this end, we incorporate Pearl&#x27;s causal
do(.) operator into the predictive vocabulary. We then decompose the expected
prediction error given behavior modification, and identify the components
impacting predictive power. Our derivation elucidates implications of such
behavior modification to data scientists, platforms, their customers, and the
humans whose behavior is manipulated. Behavior modification can make users&#x27;
behavior more predictable and even more homogeneous; yet this apparent
predictability might not generalize when customers use predictions in practice.
Outcomes pushed towards their predictions can be at odds with customers&#x27;
intentions, and harmful to manipulated users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Face Hallucination and Translation for Thermal to Visible Face Verification using Axial-GAN. (arXiv:2104.06534v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Immidisetti_R/0/1/0/all/0/1">Rakhil Immidisetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuowen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06534">
                                    <div class="article-summary-box-inner">
                                        <span>Existing thermal-to-visible face verification approaches expect the thermal
and visible face images to be of similar resolution. This is unlikely in
real-world long-range surveillance systems, since humans are distant from the
cameras. To address this issue, we introduce the task of thermal-to-visible
face verification from low-resolution thermal images. Furthermore, we propose
Axial-Generative Adversarial Network (Axial-GAN) to synthesize high-resolution
visible images for matching. In the proposed approach we augment the GAN
framework with axial-attention layers which leverage the recent advances in
transformers for modelling long-range dependencies. We demonstrate the
effectiveness of the proposed method by evaluating on two different
thermal-visible face datasets. When compared to related state-of-the-art works,
our results show significant improvements in both image quality and face
verification performance, and are also much more efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complex Transformer: A Framework for Modeling Complex-Valued Sequence. (arXiv:1910.10202v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Muqiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Martin Q. Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yao-Hung Hubert Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10202">
                                    <div class="article-summary-box-inner">
                                        <span>While deep learning has received a surge of interest in a variety of fields
in recent years, major deep learning models barely use complex numbers.
However, speech, signal and audio data are naturally complex-valued after
Fourier Transform, and studies have shown a potentially richer representation
of complex nets. In this paper, we propose a Complex Transformer, which
incorporates the transformer model as a backbone for sequence modeling; we also
develop attention and encoder-decoder network operating for complex input. The
model achieves state-of-the-art performance on the MusicNet dataset and an
In-phase Quadrature (IQ) signal dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence Rate of Projected Gradient Descent for a Back-Projection based Objective. (arXiv:2005.00959v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Tirer_T/0/1/0/all/0/1">Tom Tirer</a>, <a href="http://arxiv.org/find/math/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00959">
                                    <div class="article-summary-box-inner">
                                        <span>Ill-posed linear inverse problems appear in many scientific setups, and are
typically addressed by solving optimization problems, which are composed of
data fidelity and prior terms. Recently, several works have considered a
back-projection (BP) based fidelity term as an alternative to the common least
squares (LS), and demonstrated excellent results for popular inverse problems.
These works have also empirically shown that using the BP term, rather than the
LS term, requires fewer iterations of optimization algorithms. In this paper,
we examine the convergence rate of the projected gradient descent (PGD)
algorithm for the BP objective. Our analysis allows to identify an inherent
source for its faster convergence compared to using the LS objective, while
making only mild assumptions. We also analyze the more general proximal
gradient method under a relaxed contraction condition on the proximal mapping
of the prior. This analysis further highlights the advantage of BP when the
linear measurement operator is badly conditioned. Numerical experiments with
both $\ell_1$-norm and GAN-based priors corroborate our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mis-spoke or mis-lead: Achieving Robustness in Multi-Agent Communicative Reinforcement Learning. (arXiv:2108.03803v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wanqi Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Wei Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabinovich_Z/0/1/0/all/0/1">Zinovi Rabinovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Obraztsova_S/0/1/0/all/0/1">Svetlana Obraztsova</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_C/0/1/0/all/0/1">Chai Kiat Yeo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03803">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies in multi-agent communicative reinforcement learning (MACRL)
demonstrate that multi-agent coordination can be significantly improved when
communication between agents is allowed. Meanwhile, advances in adversarial
machine learning (ML) have shown that ML and reinforcement learning (RL) models
are vulnerable to a variety of attacks that significantly degrade the
performance of learned behaviours. However, despite the obvious and growing
importance, the combination of adversarial ML and MACRL remains largely
uninvestigated. In this paper, we make the first step towards conducting
message attacks on MACRL methods. In our formulation, one agent in the
cooperating group is taken over by an adversary and can send malicious messages
to disrupt a deployed MACRL-based coordinated strategy during the deployment
phase. We further our study by developing a defence method via message
reconstruction. Finally, we address the resulting arms race, i.e., we consider
the ability of the malicious agent to adapt to the changing and improving
defensive communicative policies of the benign agents. Specifically, we model
the adversarial MACRL problem as a two-player zero-sum game and then utilize
Policy-Space Response Oracle to achieve communication robustness. Empirically,
we demonstrate that MACRL methods are vulnerable to message attacks while our
defence method the game-theoretic framework can effectively improve the
robustness of MACRL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning Local Reduced Density Matrices for Many-body Hamiltonian Estimation. (arXiv:2012.03019v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Ma_X/0/1/0/all/0/1">Xinran Ma</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tu_Z/0/1/0/all/0/1">Z. C. Tu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Human experts cannot efficiently access the physical information of quantum
many-body states by simply &quot;reading&quot; the coefficients, but have to reply on the
previous knowledge such as order parameters and quantum measurements. In this
work, we demonstrate that convolutional neural network (CNN) can learn from the
coefficients of local reduced density matrices to estimate the physical
parameters of the many-body Hamiltonians, such as coupling strengths and
magnetic fields, provided the states as the ground states. We propose QubismNet
that consists of two main parts: the Qubism map that visualizes the ground
states (or the purified reduced density matrices) as images, and a CNN that
maps the images to the target physical parameters. By assuming certain
constraints on the training set for the sake of balance, QubismNet exhibits
impressive powers of learning and generalization on several quantum spin
models. While the training samples are restricted to the states from certain
ranges of the parameters, QubismNet can accurately estimate the parameters of
the states beyond such training regions. For instance, our results show that
QubismNet can estimate the magnetic fields near the critical point by learning
from the states away from the critical vicinity. Our work illuminates a
data-driven way to infer the Hamiltonians that give the designed ground states,
and therefore would benefit the existing and future generalizations of quantum
technologies such as Hamiltonian-based quantum simulations and state
tomography.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolution Neural Network Hyperparameter Optimization Using Simplified Swarm Optimization. (arXiv:2103.03995v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeh_W/0/1/0/all/0/1">Wei-Chang Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yi-Ping Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yun-Chia Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Chyh-Ming Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03995">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) are widely used in image recognition.
Numerous CNN models, such as LeNet, AlexNet, VGG, ResNet, and GoogLeNet, have
been proposed by increasing the number of layers, to improve the performance of
CNNs. However, performance deteriorates beyond a certain number of layers.
Hence, hyperparameter optimisation is a more efficient way to improve CNNs. To
validate this concept, a new algorithm based on simplified swarm optimisation
is proposed to optimise the hyperparameters of the simplest CNN model, which is
LeNet. The results of experiments conducted on the MNIST, Fashion MNIST, and
Cifar10 datasets showed that the accuracy of the proposed algorithm is higher
than the original LeNet model and PSO-LeNet and that it has a high potential to
be extended to more complicated models, such as AlexNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Interpretable Probabilistic Model for Short-Term Solar Power Forecasting Using Natural Gradient Boosting. (arXiv:2108.04058v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mitrentsis_G/0/1/0/all/0/1">Georgios Mitrentsis</a>, <a href="http://arxiv.org/find/stat/1/au:+Lens_H/0/1/0/all/0/1">Hendrik Lens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04058">
                                    <div class="article-summary-box-inner">
                                        <span>The stochastic nature of photovoltaic (PV) power has led both academia and
industry to a large amount of research work aiming at the development of
accurate PV power forecasting models. However, most of those models are based
on machine learning algorithms and are considered as black boxes which do not
provide any insight or explanation about their predictions. Therefore, their
direct implementation in environments, where transparency is required, and the
trust associated with their predictions may be questioned. To this end, we
propose a two stage probabilistic forecasting framework able to generate highly
accurate, reliable, and sharp forecasts yet offering full transparency on both
the point forecasts and the prediction intervals (PIs). In the first stage, we
exploit natural gradient boosting (NGBoost) for yielding probabilistic
forecasts while in the second stage, we calculate the Shapley additive
explanation (SHAP) values in order to fully understand why a prediction was
made. To highlight the performance and the applicability of the proposed
framework, real data from two PV parks located in Southern Germany are
employed. Initially, the natural gradient boosting is thoroughly compared with
two state-of-the-art algorithms, namely Gaussian process and lower upper bound
estimation, in a wide range of forecasting metrics. Secondly, a detailed
analysis of the model&#x27;s complex nonlinear relationships and interaction effects
between the various features is presented. The latter allows us to interpret
the model, identify some learned physical properties, explain individual
predictions, reduce the computational requirements for the training without
jeopardizing the model accuracy, detect possible bugs, and gain trust in the
model. Finally, we conclude that the model was able to develop nonlinear
relationships following human logic and intuition based on learned physical
properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Co-learning: Learning from Noisy Labels with Self-supervision. (arXiv:2108.04063v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Cheng Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1">Jun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04063">
                                    <div class="article-summary-box-inner">
                                        <span>Noisy labels, resulting from mistakes in manual labeling or webly data
collecting for supervised learning, can cause neural networks to overfit the
misleading information and degrade the generalization performance.
Self-supervised learning works in the absence of labels and thus eliminates the
negative impact of noisy labels. Motivated by co-training with both supervised
learning view and self-supervised learning view, we propose a simple yet
effective method called Co-learning for learning with noisy labels. Co-learning
performs supervised learning and self-supervised learning in a cooperative way.
The constraints of intrinsic similarity with the self-supervised module and the
structural similarity with the noisily-supervised module are imposed on a
shared common feature encoder to regularize the network to maximize the
agreement between the two constraints. Co-learning is compared with peer
methods on corrupted data from benchmark datasets fairly, and extensive results
are provided which demonstrate that Co-learning is superior to many
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can a CNN trained on the Ising model detect the phase transition of the $q$-state Potts model?. (arXiv:2104.03632v3 [cond-mat.dis-nn] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Fukushima_K/0/1/0/all/0/1">Kimihiko Fukushima</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sakai_K/0/1/0/all/0/1">Kazumitsu Sakai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03632">
                                    <div class="article-summary-box-inner">
                                        <span>Employing a deep convolutional neural network (deep CNN) trained on spin
configurations of the 2D Ising model and the temperatures, we examine whether
the deep CNN can detect the phase transition of the 2D $q$-state Potts model.
To this end, we generate binarized images of spin configurations of the
$q$-state Potts model ($q\ge 3$) by replacing the spin variables
$\{0,1,\dots,\lfloor q/2\rfloor-1\}$ and $\{\lfloor q/2\rfloor,\dots,q-1\}$
with $\{0\}$ and $\{1\}$, respectively. Then, we input these images to the
trained CNN to output the predicted temperatures. The binarized images of the
$q$-state Potts model are entirely different from Ising spin configurations,
particularly at the transition temperature. Moreover, our CNN model is not
trained on the information about whether phases are ordered/disordered but is
naively trained by Ising spin configurations labeled with temperatures at which
they are generated. Nevertheless, the deep CNN can detect the transition point
with high accuracy, regardless of the type of transition. We also find that, in
the high-temperature region, the CNN outputs the temperature based on the
internal energy, whereas, in the low-temperature region, the output depends on
the magnetization and possibly the internal energy as well. However, in the
vicinity of the transition point, the CNN may use more general factors to
detect the transition point.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-Aware Partitioning of Machine Learning Applications for Optimal Energy Use in Batteryless Systems. (arXiv:2108.04059v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Andres Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tretter_A/0/1/0/all/0/1">Andreas Tretter</a>, <a href="http://arxiv.org/find/cs/1/au:+Hager_P/0/1/0/all/0/1">Pascal Alexander Hager</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanmugarajah_P/0/1/0/all/0/1">Praveenth Sanmugarajah</a>, <a href="http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1">Luca Benini</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiele_L/0/1/0/all/0/1">Lothar Thiele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04059">
                                    <div class="article-summary-box-inner">
                                        <span>Sensing systems powered by energy harvesting have traditionally been designed
to tolerate long periods without energy. As the Internet of Things (IoT)
evolves towards a more transient and opportunistic execution paradigm, reducing
energy storage costs will be key for its economic and ecologic viability.
However, decreasing energy storage in harvesting systems introduces reliability
issues. Transducers only produce intermittent energy at low voltage and current
levels, making guaranteed task completion a challenge. Existing ad hoc methods
overcome this by buffering enough energy either for single tasks, incurring
large data-retention overheads, or for one full application cycle, requiring a
large energy buffer. We present Julienning: an automated method for optimizing
the total energy cost of batteryless applications. Using a custom specification
model, developers can describe transient applications as a set of atomically
executed kernels with explicit data dependencies. Our optimization flow can
partition data- and energy-intensive applications into multiple execution
cycles with bounded energy consumption. By leveraging interkernel data
dependencies, these energy-bounded execution cycles minimize the number of
system activations and nonvolatile data transfers, and thus the total energy
overhead. We validate our methodology with two batteryless cameras running
energy-intensive machine learning applications. Results demonstrate that
compared to ad hoc solutions, our method can reduce the required energy storage
by over 94% while only incurring a 0.12% energy overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Limitations of machine learning for building energy prediction. (arXiv:2106.13475v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miller_C/0/1/0/all/0/1">Clayton Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Picchetti_B/0/1/0/all/0/1">Bianca Picchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chun Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantelic_J/0/1/0/all/0/1">Jovan Pantelic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13475">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning for building energy prediction has exploded in popularity in
recent years, yet understanding its limitations and potential for improvement
are lacking. The ASHRAE Great Energy Predictor III (GEPIII) Kaggle competition
was the largest building energy meter machine learning competition ever held
with 4,370 participants who submitted 39,403 predictions. The test data set
included two years of hourly electricity, hot water, chilled water, and steam
readings from 2,380 meters in 1,448 buildings at 16 locations. This paper
analyzes the various sources and types of residual model error from an
aggregation of the competition&#x27;s top 50 solutions. This analysis reveals the
limitations for machine learning using the standard model inputs of historical
meter, weather, and basic building metadata. The types of error are classified
according to the amount of time errors occur in each instance, abrupt versus
gradual behavior, the magnitude of error, and whether the error existed on
single buildings or several buildings at once from a single location. The
results show machine learning models have errors within a range of
acceptability on 79.1% of the test data. Lower magnitude model errors occur in
16.1% of the test data. These discrepancies can likely be addressed through
additional training data sources or innovations in machine learning. Higher
magnitude errors occur in 4.8% of the test data and are unlikely to be
accurately predicted regardless of innovation. There is a diversity of error
behavior depending on the energy meter type (electricity prediction models have
unacceptable error in under 10% of test data, while hot water is over 60%) and
building use type (public service less than 14%, while technology/science is
just over 46%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combinatorial Bandits under Strategic Manipulations. (arXiv:2102.12722v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baoxiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12722">
                                    <div class="article-summary-box-inner">
                                        <span>Strategic behavior against sequential learning methods, such as &quot;click
framing&quot; in real recommendation systems, has been widely observed. Motivated by
such behavior we study the problem of combinatorial multi-armed bandits (CMAB)
under strategic manipulations of rewards, where each arm can modify the emitted
reward signals for its own interest. This characterization of the adversarial
behavior is a relaxation of previously well-studied settings such as
adversarial attacks and adversarial corruption. We propose a strategic variant
of the combinatorial UCB algorithm, which has a regret of at most $O(m\log T +
m B_{max})$ under strategic manipulations, where $T$ is the time horizon, $m$
is the number of arms, and $B_{max}$ is the maximum budget of an arm. We
provide lower bounds on the budget for arms to incur certain regret of the
bandit algorithm. Extensive experiments on online worker selection for
crowdsourcing systems, online influence maximization and online recommendations
with both synthetic and real datasets corroborate our theoretical findings on
robustness and regret bounds, in a variety of regimes of manipulation budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Householder Activations for Provable Robustness against Adversarial Attacks. (arXiv:2108.04062v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Surbhi Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04062">
                                    <div class="article-summary-box-inner">
                                        <span>Training convolutional neural networks (CNNs) with a strict Lipschitz
constraint under the l_{2} norm is useful for provable adversarial robustness,
interpretable gradients and stable training. While 1-Lipschitz CNNs can be
designed by enforcing a 1-Lipschitz constraint on each layer, training such
networks requires each layer to have an orthogonal Jacobian matrix (for all
inputs) to prevent gradients from vanishing during backpropagation. A layer
with this property is said to be Gradient Norm Preserving (GNP). To construct
expressive GNP activation functions, we first prove that the Jacobian of any
GNP piecewise linear function is only allowed to change via Householder
transformations for the function to be continuous. Building on this result, we
introduce a class of nonlinear GNP activations with learnable Householder
transformations called Householder activations. A householder activation
parameterized by the vector $\mathbf{v}$ outputs $(\mathbf{I} -
2\mathbf{v}\mathbf{v}^{T})\mathbf{z}$ for its input $\mathbf{z}$ if
$\mathbf{v}^{T}\mathbf{z} \leq 0$; otherwise it outputs $\mathbf{z}$. Existing
GNP activations such as $\mathrm{MaxMin}$ can be viewed as special cases of
$\mathrm{HH}$ activations for certain settings of these transformations. Thus,
networks with $\mathrm{HH}$ activations have higher expressive power than those
with $\mathrm{MaxMin}$ activations. Although networks with $\mathrm{HH}$
activations have nontrivial provable robustness against adversarial attacks, we
further boost their robustness by (i) introducing a certificate regularization
and (ii) relaxing orthogonalization of the last layer of the network. Our
experiments on CIFAR-10 and CIFAR-100 show that our regularized networks with
$\mathrm{HH}$ activations lead to significant improvements in both the standard
and provable robust accuracy over the prior works (gain of 3.65\% and 4.46\% on
CIFAR-100 respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty quantification for industrial design using dictionaries of reduced order models. (arXiv:2108.04012v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Daniel_T/0/1/0/all/0/1">Thomas Daniel</a>, <a href="http://arxiv.org/find/stat/1/au:+Casenave_F/0/1/0/all/0/1">Fabien Casenave</a>, <a href="http://arxiv.org/find/stat/1/au:+Akkari_N/0/1/0/all/0/1">Nissrine Akkari</a>, <a href="http://arxiv.org/find/stat/1/au:+Ryckelynck_D/0/1/0/all/0/1">David Ryckelynck</a>, <a href="http://arxiv.org/find/stat/1/au:+Rey_C/0/1/0/all/0/1">Christian Rey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04012">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the dictionary-based ROM-net (Reduced Order Model) framework [T.
Daniel, F. Casenave, N. Akkari, D. Ryckelynck, Model order reduction assisted
by deep neural networks (ROM-net), Advanced modeling and Simulation in
Engineering Sciences 7 (16), 2020] and summarize the underlying methodologies
and their recent improvements. The main contribution of this work is the
application of the complete workflow to a real-life industrial model of an
elastoviscoplastic high-pressure turbine blade subjected to thermal,
centrifugal and pressure loadings, for the quantification of the uncertainty on
dual quantities (such as the accumulated plastic strain and the stress tensor),
generated by the uncertainty on the temperature loading field. The
dictionary-based ROM-net computes predictions of dual quantities of interest
for 1008 Monte Carlo draws of the temperature loading field in 2 hours and 48
minutes, which corresponds to a speedup greater than 600 with respect to a
reference parallel solver using domain decomposition, with a relative error in
the order of 2%. Another contribution of this work consists in the derivation
of a meta-model to reconstruct the dual quantities of interest over the
complete mesh from their values on the reduced integration points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving high-dimensional optimal stopping problems using deep learning. (arXiv:1908.01602v3 [cs.CE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">Sebastian Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheridito_P/0/1/0/all/0/1">Patrick Cheridito</a>, <a href="http://arxiv.org/find/cs/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Welti_T/0/1/0/all/0/1">Timo Welti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01602">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays many financial derivatives, such as American or Bermudan options,
are of early exercise type. Often the pricing of early exercise options gives
rise to high-dimensional optimal stopping problems, since the dimension
corresponds to the number of underlying assets. High-dimensional optimal
stopping problems are, however, notoriously difficult to solve due to the
well-known curse of dimensionality. In this work, we propose an algorithm for
solving such problems, which is based on deep learning and computes, in the
context of early exercise option pricing, both approximations of an optimal
exercise strategy and the price of the considered option. The proposed
algorithm can also be applied to optimal stopping problems that arise in other
areas where the underlying stochastic process can be efficiently simulated. We
present numerical results for a large number of example problems, which include
the pricing of many high-dimensional American and Bermudan options, such as
Bermudan max-call options in up to 5000 dimensions. Most of the obtained
results are compared to reference values computed by exploiting the specific
problem design or, where available, to reference values from the literature.
These numerical results suggest that the proposed algorithm is highly effective
in the case of many underlyings, in terms of both accuracy and speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles. (arXiv:2108.03981v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1">Xinhang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_T/0/1/0/all/0/1">Tianhao Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1">Chen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03981">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Deep Learning (FDL) is helping to realize distributed machine
learning in the Internet of Vehicles (IoV). However, FDL&#x27;s global model needs
multiple clients to upload learning model parameters, thus still existing
unavoidable communication overhead and data privacy risks. The recently
proposed Swarm Learning (SL) provides a decentralized machine-learning approach
uniting edge computing and blockchain-based coordination without the need for a
central coordinator. This paper proposes a Swarm-Federated Deep Learning
framework in the IoV system (IoV-SFDL) that integrates SL into the FDL
framework. The IoV-SFDL organizes vehicles to generate local SL models with
adjacent vehicles based on the blockchain empowered SL, then aggregates the
global FDL model among different SL groups with a proposed credibility weights
prediction algorithm. Extensive experimental results demonstrate that compared
with the baseline frameworks, the proposed IoV-SFDL framework achieves a 16.72%
reduction in edge-to-global communication overhead while improving about 5.02%
in model performance with the same training iterations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning and Certification under Instance-targeted Poisoning. (arXiv:2105.08709v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Ji Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1">Mohammad Mahmoody</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08709">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study PAC learnability and certification of predictions
under instance-targeted poisoning attacks, where the adversary who knows the
test instance may change a fraction of the training set with the goal of
fooling the learner at the test instance. Our first contribution is to
formalize the problem in various settings and to explicitly model subtle
aspects such as the proper or improper nature of the learning, learner&#x27;s
randomness, and whether (or not) adversary&#x27;s attack can depend on it. Our main
result shows that when the budget of the adversary scales sublinearly with the
sample complexity, (improper) PAC learnability and certification are
achievable; in contrast, when the adversary&#x27;s budget grows linearly with the
sample complexity, the adversary can potentially drive up the expected 0-1 loss
to one. We also study distribution-specific PAC learning in the same attack
model and show that proper learning with certification is possible for learning
half spaces under natural distributions. Finally, we empirically study the
robustness of K nearest neighbour, logistic regression, multi-layer perceptron,
and convolutional neural network on real data sets against targeted-poisoning
attacks. Our experimental results show that many models, especially
state-of-the-art neural networks, are indeed vulnerable to these strong
attacks. Interestingly, we observe that methods with high standard accuracy
might be more vulnerable to instance-targeted poisoning attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Mechanically Driven Full-Field Quantities of Interest with Deep Learning-Based Metamodels. (arXiv:2108.03995v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohammadzadeh_S/0/1/0/all/0/1">S. Mohammadzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lejeune_E/0/1/0/all/0/1">E. Lejeune</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03995">
                                    <div class="article-summary-box-inner">
                                        <span>Using simulation to predict the mechanical behavior of heterogeneous
materials has applications ranging from topology optimization to multi-scale
structural analysis. However, full-fidelity simulation techniques such as
Finite Element Analysis can be prohibitively computationally expensive when
they are used to explore the massive input parameter space of heterogeneous
materials. Therefore, there has been significant recent interest in machine
learning-based models that, once trained, can predict mechanical behavior at a
fraction of the computational cost. Over the past several years, research in
this area has been focused mainly on predicting single Quantities of Interest
(QoIs). However, there has recently been an increased interest in a more
challenging problem: predicting full-field QoI (e.g., displacement/strain
fields, damage fields) for mechanical problems. Due to the added complexity of
full-field information, network architectures that perform well on single QoI
problems may perform poorly in the full-field QoI problem setting. The work
presented in this paper is twofold. First, we made a significant extension to
the Mechanical MNIST dataset designed to enable the investigation of full field
QoI prediction. Specifically, we added Finite Element simulation results of
quasi-static brittle fracture in a heterogeneous material captured with the
phase-field method. Second, we established strong baseline performance for
predicting full-field QoI with MultiRes-WNet architecture. In addition to
presenting the results in this paper, we have released our model implementation
and the Mechanical MNIST Crack Path dataset under open-source licenses. We
anticipate that future researchers will directly use our model architecture on
related datasets and potentially design models that exceed the baseline
performance for predicting full-field QoI established in this paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Deep Learning for Partial Differential Equation Parameter Discovery with Sparse and Noisy Data. (arXiv:2108.04085v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Bonneville_C/0/1/0/all/0/1">Christophe Bonneville</a>, <a href="http://arxiv.org/find/math/1/au:+Earls_C/0/1/0/all/0/1">Christopher J. Earls</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04085">
                                    <div class="article-summary-box-inner">
                                        <span>Scientific machine learning has been successfully applied to inverse problems
and PDE discoveries in computational physics. One caveat of current methods
however is the need for large amounts of (clean) data in order to recover full
system responses or underlying physical models. Bayesian methods may be
particularly promising to overcome these challenges as they are naturally less
sensitive to sparse and noisy data. In this paper, we propose to use Bayesian
neural networks (BNN) in order to: 1) Recover the full system states from
measurement data (e.g. temperature, velocity field, etc.). We use Hamiltonian
Monte-Carlo to sample the posterior distribution of a deep and dense BNN, and
show that it is possible to accurately capture physics of varying complexity
without overfitting. 2) Recover the parameters in the underlying partial
differential equation (PDE) governing the physical system. Using the trained
BNN as a surrogate of the system response, we generate datasets of derivatives
potentially comprising the latent PDE of the observed system and perform a
Bayesian linear regression (BLR) between the successive derivatives in space
and time to recover the original PDE parameters. We take advantage of the
confidence intervals on the BNN outputs and introduce the spatial derivative
variance into the BLR likelihood to discard the influence of highly uncertain
surrogate data points, which allows for more accurate parameter discovery. We
demonstrate our approach on a handful of example applied to physics and
non-linear dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Perspective Anomaly Detection. (arXiv:2105.09903v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1">Peter Jakob</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1">Manav Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1">Tobias Schmid-Schirling</a>, <a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1">Abhinav Valada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09903">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection is a critical problem in the manufacturing industry. In
many applications, images of objects to be analyzed are captured from multiple
perspectives which can be exploited to improve the robustness of anomaly
detection. In this work, we build upon the deep support vector data description
algorithm and address multi-perspective anomaly detection using three different
fusion techniques, i.e., early fusion, late fusion, and late fusion with
multiple decoders. We employ different augmentation techniques with a denoising
process to deal with scarce one-class data, which further improves the
performance (ROC AUC $&#x3D; 80\%$). Furthermore, we introduce the dices dataset,
which consists of over 2000 grayscale images of falling dices from multiple
perspectives, with 5\% of the images containing rare anomalies (e.g., drill
holes, sawing, or scratches). We evaluate our approach on the new dices dataset
using images from two different perspectives and also benchmark on the standard
MNIST dataset. Extensive experiments demonstrate that our proposed
{multi-perspective} approach exceeds the state-of-the-art {single-perspective
anomaly detection on both the MNIST and dices datasets}. To the best of our
knowledge, this is the first work that focuses on addressing multi-perspective
anomaly detection in images by jointly using different perspectives together
with one single objective function for anomaly detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-free inference of unseen attractors: Reconstructing phase space features from a single noisy trajectory using reservoir computing. (arXiv:2108.04074v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1">Andr&#xe9; R&#xf6;hm</a>, <a href="http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1">Daniel J. Gauthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1">Ingo Fischer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04074">
                                    <div class="article-summary-box-inner">
                                        <span>Reservoir computers are powerful tools for chaotic time series prediction.
They can be trained to approximate phase space flows and can thus both predict
future values to a high accuracy, as well as reconstruct the general properties
of a chaotic attractor without requiring a model. In this work, we show that
the ability to learn the dynamics of a complex system can be extended to
systems with co-existing attractors, here a 4-dimensional extension of the
well-known Lorenz chaotic system. We demonstrate that a reservoir computer can
infer entirely unexplored parts of the phase space: a properly trained
reservoir computer can predict the existence of attractors that were never
approached during training and therefore are labelled as unseen. We provide
examples where attractor inference is achieved after training solely on a
single noisy trajectory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unifying Heterogenous Electronic Health Records Systems via Text-Based Code Embedding. (arXiv:2108.03625v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hur_K/0/1/0/all/0/1">Kyunghoon Hur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jiyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jungwoo Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_W/0/1/0/all/0/1">Wesley Price</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Hak Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Edward Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03625">
                                    <div class="article-summary-box-inner">
                                        <span>Substantial increase in the use of Electronic Health Records (EHRs) has
opened new frontiers for predictive healthcare. However, while EHR systems are
nearly ubiquitous, they lack a unified code system for representing medical
concepts. Heterogeneous formats of EHR present a substantial barrier for the
training and deployment of state-of-the-art deep learning models at scale. To
overcome this problem, we introduce Description-based Embedding, DescEmb, a
code-agnostic description-based representation learning framework for
predictive modeling on EHR. DescEmb takes advantage of the flexibility of
neural language understanding models while maintaining a neutral approach that
can be combined with prior frameworks for task-specific representation learning
or predictive modeling. We tested our model&#x27;s capacity on various experiments
including prediction tasks, transfer learning and pooled learning. DescEmb
shows higher performance in overall experiments compared to code-based
approach, opening the door to a text-based approach in predictive healthcare
research that is not constrained by EHR structure nor special domain knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster Rates of Differentially Private Stochastic Convex Optimization. (arXiv:2108.00331v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jinyan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00331">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we revisit the problem of Differentially Private Stochastic
Convex Optimization (DP-SCO) and provide excess population risks for some
special classes of functions that are faster than the previous results of
general convex and strongly convex functions. In the first part of the paper,
we study the case where the population risk function satisfies the Tysbakov
Noise Condition (TNC) with some parameter $\theta&gt;1$. Specifically, we first
show that under some mild assumptions on the loss functions, there is an
algorithm whose output could achieve an upper bound of
$\tilde{O}((\frac{1}{\sqrt{n}}+\frac{\sqrt{d\log
\frac{1}{\delta}}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $(\epsilon,
\delta)$-DP when $\theta\geq 2$, here $n$ is the sample size and $d$ is the
dimension of the space. Then we address the inefficiency issue, improve the
upper bounds by $\text{Poly}(\log n)$ factors and extend to the case where
$\theta\geq \bar{\theta}&gt;1$ for some known $\bar{\theta}$. Next we show that
the excess population risk of population functions satisfying TNC with
parameter $\theta&gt;1$ is always lower bounded by
$\Omega((\frac{d}{n\epsilon})^\frac{\theta}{\theta-1}) $ and
$\Omega((\frac{\sqrt{d\log
\frac{1}{\delta}}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $\epsilon$-DP and
$(\epsilon, \delta)$-DP, respectively. In the second part, we focus on a
special case where the population risk function is strongly convex. Unlike the
previous studies, here we assume the loss function is {\em non-negative} and
{\em the optimal value of population risk is sufficiently small}. With these
additional assumptions, we propose a new method whose output could achieve an
upper bound of
$O(\frac{d\log\frac{1}{\delta}}{n^2\epsilon^2}+\frac{1}{n^{\tau}})$ for any
$\tau\geq 1$ in $(\epsilon,\delta)$-DP model if the sample size $n$ is
sufficiently large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Deep Learning for Mobile Edge Computing: A Survey on Communication Efficiency and Trustworthiness. (arXiv:2108.03980v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuwei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochiai_H/0/1/0/all/0/1">Hideya Ochiai</a>, <a href="http://arxiv.org/find/cs/1/au:+Esaki_H/0/1/0/all/0/1">Hiroshi Esaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03980">
                                    <div class="article-summary-box-inner">
                                        <span>A wider coverage and a better solution to latency reduction in 5G
necessitates its combination with mobile edge computing (MEC) technology.
Decentralized deep learning (DDL) as a promising solution to privacy-preserving
data processing for millions of edge smart devices, it leverages federated
learning within the networking of local models, without disclosing a client&#x27;s
raw data. Especially, in industries such as finance and healthcare where
sensitive data of transactions and personal medical records is cautiously
maintained, DDL facilitates the collaboration among these institutes to improve
the performance of local models, while protecting data privacy of participating
clients. In this survey paper, we demonstrate technical fundamentals of DDL for
benefiting many walks of society through decentralized learning. Furthermore,
we offer a comprehensive overview of recent challenges of DDL and the most
relevant solutions from novel perspectives of communication efficiency and
trustworthiness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An EM Framework for Online Incremental Learning of Semantic Segmentation. (arXiv:2108.03613v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shipeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiale Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiangwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Songyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuming He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03613">
                                    <div class="article-summary-box-inner">
                                        <span>Incremental learning of semantic segmentation has emerged as a promising
strategy for visual scene interpretation in the open- world setting. However,
it remains challenging to acquire novel classes in an online fashion for the
segmentation task, mainly due to its continuously-evolving semantic label
space, partial pixelwise ground-truth annotations, and constrained data
availability. To ad- dress this, we propose an incremental learning strategy
that can fast adapt deep segmentation models without catastrophic forgetting,
using a streaming input data with pixel annotations on the novel classes only.
To this end, we develop a uni ed learning strategy based on the
Expectation-Maximization (EM) framework, which integrates an iterative
relabeling strategy that lls in the missing labels and a rehearsal-based
incremental learning step that balances the stability-plasticity of the model.
Moreover, our EM algorithm adopts an adaptive sampling method to select
informative train- ing data and a class-balancing training strategy in the
incremental model updates, both improving the e cacy of model learning. We
validate our approach on the PASCAL VOC 2012 and ADE20K datasets, and the
results demonstrate its superior performance over the existing incremental
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Streamwise GAN Vocoder for Wideband Speech Coding at Very Low Bit Rate. (arXiv:2108.04051v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mustafa_A/0/1/0/all/0/1">Ahmed Mustafa</a>, <a href="http://arxiv.org/find/eess/1/au:+Buthe_J/0/1/0/all/0/1">Jan B&#xfc;the</a>, <a href="http://arxiv.org/find/eess/1/au:+Korse_S/0/1/0/all/0/1">Srikanth Korse</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_K/0/1/0/all/0/1">Kishan Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Fuchs_G/0/1/0/all/0/1">Guillaume Fuchs</a>, <a href="http://arxiv.org/find/eess/1/au:+Pia_N/0/1/0/all/0/1">Nicola Pia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04051">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, GAN vocoders have seen rapid progress in speech synthesis, starting
to outperform autoregressive models in perceptual quality with much higher
generation speed. However, autoregressive vocoders are still the common choice
for neural generation of speech signals coded at very low bit rates. In this
paper, we present a GAN vocoder which is able to generate wideband speech
waveforms from parameters coded at 1.6 kbit/s. The proposed model is a modified
version of the StyleMelGAN vocoder that can run in frame-by-frame manner,
making it suitable for streaming applications. The experimental results show
that the proposed model significantly outperforms prior autoregressive vocoders
like LPCNet for very low bit rate speech coding, with computational complexity
of about 5 GMACs, providing a new state of the art in this domain. Moreover,
this streamwise adversarial vocoder delivers quality competitive to advanced
speech codecs such as EVS at 5.9 kbit/s on clean speech, which motivates
further usage of feed-forward fully-convolutional models for low bit rate
speech coding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Majority Voting in Digital Hardware. (arXiv:2108.03979v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Baumgartner_S/0/1/0/all/0/1">Stefan Baumgartner</a>, <a href="http://arxiv.org/find/eess/1/au:+Huemer_M/0/1/0/all/0/1">Mario Huemer</a>, <a href="http://arxiv.org/find/eess/1/au:+Lunglmayr_M/0/1/0/all/0/1">Michael Lunglmayr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03979">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, machine learning methods became increasingly important for a
manifold number of applications. However, they often suffer from high
computational requirements impairing their efficient use in real-time systems,
even when employing dedicated hardware accelerators. Ensemble learning methods
are especially suitable for hardware acceleration since they can be constructed
from individual learners of low complexity and thus offer large parallelization
potential. For classification, the outputs of these learners are typically
combined by majority voting, which often represents the bottleneck of a
hardware accelerator for ensemble inference. In this work, we present a novel
architecture that allows obtaining a majority decision in a number of clock
cycles that is logarithmic in the number of inputs. We show, that for the
example application of handwritten digit recognition a random forest processing
engine employing this majority decision architecture implemented on an FPGA
allows the classification of more than seven million images per second.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DGEM: A New Dual-modal Graph Embedding Method in Recommendation System. (arXiv:2108.04031v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huimin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rongwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhuyun Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04031">
                                    <div class="article-summary-box-inner">
                                        <span>In the current deep learning based recommendation system, the embedding
method is generally employed to complete the conversion from the
high-dimensional sparse feature vector to the low-dimensional dense feature
vector. However, as the dimension of the input vector of the embedding layer is
too large, the addition of the embedding layer significantly slows down the
convergence speed of the entire neural network, which is not acceptable in
real-world scenarios. In addition, as the interaction between users and items
increases and the relationship between items becomes more complicated, the
embedding method proposed for sequence data is no longer suitable for graphic
data in the current real environment. Therefore, in this paper, we propose the
Dual-modal Graph Embedding Method (DGEM) to solve these problems. DGEM includes
two modes, static and dynamic. We first construct the item graph to extract the
graph structure and use random walk of unequal probability to capture the
high-order proximity between the items. Then we generate the graph embedding
vector through the Skip-Gram model, and finally feed the downstream deep neural
network for the recommendation task. The experimental results show that DGEM
can mine the high-order proximity between items and enhance the expression
ability of the recommendation model. Meanwhile it also improves the
recommendation performance by utilizing the time dependent relationship between
items.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework for Joint Unsupervised Learning of Cluster-Aware Embedding for Heterogeneous Networks. (arXiv:2108.03953v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1">Rayyan Ahmad Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinsteuber_M/0/1/0/all/0/1">Martin Kleinsteuber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03953">
                                    <div class="article-summary-box-inner">
                                        <span>Heterogeneous Information Network (HIN) embedding refers to the
low-dimensional projections of the HIN nodes that preserve the HIN structure
and semantics. HIN embedding has emerged as a promising research field for
network analysis as it enables downstream tasks such as clustering and node
classification. In this work, we propose \ours for joint learning of cluster
embeddings as well as cluster-aware HIN embedding. We assume that the connected
nodes are highly likely to fall in the same cluster, and adopt a variational
approach to preserve the information in the pairwise relations in a
cluster-aware manner. In addition, we deploy contrastive modules to
simultaneously utilize the information in multiple meta-paths, thereby
alleviating the meta-path selection problem - a challenge faced by many of the
famous HIN embedding approaches. The HIN embedding, thus learned, not only
improves the clustering performance but also preserves pairwise proximity as
well as the high-order HIN structure. We show the effectiveness of our approach
by comparing it with many competitive baselines on three real-world datasets on
clustering and downstream node classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Active Learning for Active Class Selection. (arXiv:2108.03891v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kottke_D/0/1/0/all/0/1">Daniel Kottke</a>, <a href="http://arxiv.org/find/cs/1/au:+Krempl_G/0/1/0/all/0/1">Georg Krempl</a>, <a href="http://arxiv.org/find/cs/1/au:+Stecklina_M/0/1/0/all/0/1">Marianne Stecklina</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekowski_C/0/1/0/all/0/1">Cornelius Styp von Rekowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabsch_T/0/1/0/all/0/1">Tim Sabsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Minh_T/0/1/0/all/0/1">Tuan Pham Minh</a>, <a href="http://arxiv.org/find/cs/1/au:+Deliano_M/0/1/0/all/0/1">Matthias Deliano</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiliopoulou_M/0/1/0/all/0/1">Myra Spiliopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03891">
                                    <div class="article-summary-box-inner">
                                        <span>In machine learning, active class selection (ACS) algorithms aim to actively
select a class and ask the oracle to provide an instance for that class to
optimize a classifier&#x27;s performance while minimizing the number of requests. In
this paper, we propose a new algorithm (PAL-ACS) that transforms the ACS
problem into an active learning task by introducing pseudo instances. These are
used to estimate the usefulness of an upcoming instance for each class using
the performance gain model from probabilistic active learning. Our experimental
evaluation (on synthetic and real data) shows the advantages of our algorithm
compared to state-of-the-art algorithms. It effectively prefers the sampling of
difficult classes and thereby improves the classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LatticeNet: Fast Spatio-Temporal Point Cloud Segmentation Using Permutohedral Lattices. (arXiv:2108.03917v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosu_R/0/1/0/all/0/1">Radu Alexandru Rosu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutt_P/0/1/0/all/0/1">Peer Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Quenzel_J/0/1/0/all/0/1">Jan Quenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03917">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) have shown outstanding performance
in the task of semantically segmenting images. Applying the same methods on 3D
data still poses challenges due to the heavy memory requirements and the lack
of structured data. Here, we propose LatticeNet, a novel approach for 3D
semantic segmentation, which takes raw point clouds as input. A PointNet
describes the local geometry which we embed into a sparse permutohedral
lattice. The lattice allows for fast convolutions while keeping a low memory
footprint. Further, we introduce DeformSlice, a novel learned data-dependent
interpolation for projecting lattice features back onto the point cloud. We
present results of 3D segmentation on multiple datasets where our method
achieves state-of-the-art performance. We also extend and evaluate our network
for instance and dynamic object segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum. (arXiv:2108.04033v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosendo_D/0/1/0/all/0/1">Daniel Rosendo</a> (KerData), <a href="http://arxiv.org/find/cs/1/au:+Costan_A/0/1/0/all/0/1">Alexandru Costan</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoniu_G/0/1/0/all/0/1">Gabriel Antoniu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonin_M/0/1/0/all/0/1">Matthieu Simonin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombardo_J/0/1/0/all/0/1">Jean-Christophe Lombardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Joly_A/0/1/0/all/0/1">Alexis Joly</a>, <a href="http://arxiv.org/find/cs/1/au:+Valduriez_P/0/1/0/all/0/1">Patrick Valduriez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04033">
                                    <div class="article-summary-box-inner">
                                        <span>In more and more application areas, we are witnessing the emergence of
complex workflows that combine computing, analytics and learning. They often
require a hybrid execution infrastructure with IoT devices interconnected to
cloud/HPC systems (aka Computing Continuum). Such workflows are subject to
complex constraints and requirements in terms of performance, resource usage,
energy consumption and financial costs. This makes it challenging to optimize
their configuration and deployment. We propose a methodology to support the
optimization of real-life applications on the Edge-to-Cloud Continuum. We
implement it as an extension of E2Clab, a previously proposed framework
supporting the complete experimental cycle across the Edge-to-Cloud Continuum.
Our approach relies on a rigorous analysis of possible configurations in a
controlled testbed environment to understand their behaviour and related
performance trade-offs. We illustrate our methodology by optimizing Pl@ntNet, a
world-wide plant identification application. Our methodology can be generalized
to other applications in the Edge-to-Cloud Continuum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Regularity Measures for Sample-wise Learning and Generalization. (arXiv:2108.03913v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaoning Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yuanqi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuehu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03913">
                                    <div class="article-summary-box-inner">
                                        <span>Fundamental machine learning theory shows that different samples contribute
unequally both in learning and testing processes. Contemporary studies on DNN
imply that such sample di?erence is rooted on the distribution of intrinsic
pattern information, namely sample regularity. Motivated by the recent
discovery on network memorization and generalization, we proposed a pair of
sample regularity measures for both processes with a formulation-consistent
representation. Specifically, cumulative binary training/generalizing loss
(CBTL/CBGL), the cumulative number of correct classi?cations of the
training/testing sample within training stage, is proposed to quantize the
stability in memorization-generalization process; while
forgetting/mal-generalizing events, i.e., the mis-classification of previously
learned or generalized sample, are utilized to represent the uncertainty of
sample regularity with respect to optimization dynamics. Experiments validated
the effectiveness and robustness of the proposed approaches for mini-batch SGD
optimization. Further applications on training/testing sample selection show
the proposed measures sharing the uni?ed computing procedure could benefit for
both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FederatedNILM: A Distributed and Privacy-preserving Framework for Non-intrusive Load Monitoring based on Federated Deep Learning. (arXiv:2108.03591v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Shuang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fanlin Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xizhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03591">
                                    <div class="article-summary-box-inner">
                                        <span>Non-intrusive load monitoring (NILM), which usually utilizes machine learning
methods and is effective in disaggregating smart meter readings from the
household-level into appliance-level consumptions, can help to analyze
electricity consumption behaviours of users and enable practical smart energy
and smart grid applications. However, smart meters are privately owned and
distributed, which make real-world applications of NILM challenging. To this
end, this paper develops a distributed and privacy-preserving federated deep
learning framework for NILM (FederatedNILM), which combines federated learning
with a state-of-the-art deep learning architecture to conduct NILM for the
classification of typical states of household appliances. Through extensive
comparative experiments, the effectiveness of the proposed FederatedNILM
framework is demonstrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Difficulty of Generalizing Reinforcement Learning Framework for Combinatorial Optimization. (arXiv:2108.03713v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pashazadeh_M/0/1/0/all/0/1">Mostafa Pashazadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03713">
                                    <div class="article-summary-box-inner">
                                        <span>Combinatorial optimization problems (COPs) on the graph with real-life
applications are canonical challenges in Computer Science. The difficulty of
finding quality labels for problem instances holds back leveraging supervised
learning across combinatorial problems. Reinforcement learning (RL) algorithms
have recently been adopted to solve this challenge automatically. The
underlying principle of this approach is to deploy a graph neural network (GNN)
for encoding both the local information of the nodes and the graph-structured
data in order to capture the current state of the environment. Then, it is
followed by the actor to learn the problem-specific heuristics on its own and
make an informed decision at each state for finally reaching a good solution.
Recent studies on this subject mainly focus on a family of combinatorial
problems on the graph, such as the travel salesman problem, where the proposed
model aims to find an ordering of vertices that optimizes a given objective
function. We use the security-aware phone clone allocation in the cloud as a
classical quadratic assignment problem (QAP) to investigate whether or not deep
RL-based model is generally applicable to solve other classes of such hard
problems. Extensive empirical evaluation shows that existing RL-based model may
not generalize to QAP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network. (arXiv:2108.03857v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahriar_S/0/1/0/all/0/1">Sakib Shahriar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03857">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;Art is the lie that enables us to realize the truth.&quot; - Pablo Picasso. For
centuries, humans have dedicated themselves to producing arts to convey their
imagination. The advancement in technology and deep learning in particular, has
caught the attention of many researchers trying to investigate whether art
generation is possible by computers and algorithms. Using generative
adversarial networks (GANs), applications such as synthesizing photorealistic
human faces and creating captions automatically from images were realized. This
survey takes a comprehensive look at the recent works using GANs for generating
visual arts, music, and literary text. A performance comparison and description
of the various GAN architecture are also presented. Finally, some of the key
challenges in art generation using GANs are highlighted along with
recommendations for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Anomaly Detection for Internet of Things in Hierarchical Edge Computing: A Contextual-Bandit Approach. (arXiv:2108.03872v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_M/0/1/0/all/0/1">Mao V. Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q.S. Quek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03872">
                                    <div class="article-summary-box-inner">
                                        <span>The advances in deep neural networks (DNN) have significantly enhanced
real-time detection of anomalous data in IoT applications. However, the
complexity-accuracy-delay dilemma persists: complex DNN models offer higher
accuracy, but typical IoT devices can barely afford the computation load, and
the remedy of offloading the load to the cloud incurs long delay. In this
paper, we address this challenge by proposing an adaptive anomaly detection
scheme with hierarchical edge computing (HEC). Specifically, we first construct
multiple anomaly detection DNN models with increasing complexity, and associate
each of them to a corresponding HEC layer. Then, we design an adaptive model
selection scheme that is formulated as a contextual-bandit problem and solved
by using a reinforcement learning policy network. We also incorporate a
parallelism policy training method to accelerate the training process by taking
advantage of distributed models. We build an HEC testbed using real IoT
devices, implement and evaluate our contextual-bandit approach with both
univariate and multivariate IoT datasets. In comparison with both baseline and
state-of-the-art schemes, our adaptive approach strikes the best accuracy-delay
tradeoff on the univariate dataset, and achieves the best accuracy and F1-score
on the multivariate dataset with only negligibly longer delay than the best
(but inflexible) scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio Spectral Enhancement: Leveraging Autoencoders for Low Latency Reconstruction of Long, Lossy Audio Sequences. (arXiv:2108.03703v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deshpande_D/0/1/0/all/0/1">Darshan Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Abichandani_H/0/1/0/all/0/1">Harshavardhan Abichandani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03703">
                                    <div class="article-summary-box-inner">
                                        <span>With active research in audio compression techniques yielding substantial
breakthroughs, spectral reconstruction of low-quality audio waves remains a
less indulged topic. In this paper, we propose a novel approach for
reconstructing higher frequencies from considerably longer sequences of
low-quality MP3 audio waves. Our technique involves inpainting audio
spectrograms with residually stacked autoencoder blocks by manipulating
individual amplitude and phase values in relation to perceptual differences.
Our architecture presents several bottlenecks while preserving the spectral
structure of the audio wave via skip-connections. We also compare several task
metrics and demonstrate our visual guide to loss selection. Moreover, we show
how to leverage differential quantization techniques to reduce the initial
model size by more than half while simultaneously reducing inference time,
which is crucial in real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Hyperparameter Optimization for Differentially Private Deep Learning. (arXiv:2108.03888v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Priyanshu_A/0/1/0/all/0/1">Aman Priyanshu</a>, <a href="http://arxiv.org/find/cs/1/au:+Naidu_R/0/1/0/all/0/1">Rakshit Naidu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1">Fatemehsadat Mireshghallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1">Mohammad Malekzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03888">
                                    <div class="article-summary-box-inner">
                                        <span>Tuning the hyperparameters in the differentially private stochastic gradient
descent (DPSGD) is a fundamental challenge. Unlike the typical SGD, private
datasets cannot be used many times for hyperparameter search in DPSGD; e.g.,
via a grid search. Therefore, there is an essential need for algorithms that,
within a given search space, can find near-optimal hyperparameters for the best
achievable privacy-utility tradeoffs efficiently. We formulate this problem
into a general optimization framework for establishing a desirable
privacy-utility tradeoff, and systematically study three cost-effective
algorithms for being used in the proposed framework: evolutionary, Bayesian,
and reinforcement learning. Our experiments, for hyperparameter tuning in DPSGD
conducted on MNIST and CIFAR-10 datasets, show that these three algorithms
significantly outperform the widely used grid search baseline. As this paper
offers a first-of-a-kind framework for hyperparameter tuning in DPSGD, we
discuss existing challenges and open directions for future studies. As we
believe our work has implications to be utilized in the pipeline of private
deep learning, we open-source our code at
https://github.com/AmanPriyanshu/DP-HyperparamTuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Approach for Detecting Morphological Analogies. (arXiv:2108.03945v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alsaidi_S/0/1/0/all/0/1">Safa Alsaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_A/0/1/0/all/0/1">Amandine Decker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lay_P/0/1/0/all/0/1">Puthineath Lay</a>, <a href="http://arxiv.org/find/cs/1/au:+Marquer_E/0/1/0/all/0/1">Esteban Marquer</a>, <a href="http://arxiv.org/find/cs/1/au:+Murena_P/0/1/0/all/0/1">Pierre-Alexandre Murena</a>, <a href="http://arxiv.org/find/cs/1/au:+Couceiro_M/0/1/0/all/0/1">Miguel Couceiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03945">
                                    <div class="article-summary-box-inner">
                                        <span>Analogical proportions are statements of the form &quot;A is to B as C is to D&quot;
that are used for several reasoning and classification tasks in artificial
intelligence and natural language processing (NLP). For instance, there are
analogy based approaches to semantics as well as to morphology. In fact,
symbolic approaches were developed to solve or to detect analogies between
character strings, e.g., the axiomatic approach as well as that based on
Kolmogorov complexity. In this paper, we propose a deep learning approach to
detect morphological analogies, for instance, with reinflexion or conjugation.
We present empirical results that show that our framework is competitive with
the above-mentioned state of the art symbolic approaches. We also explore
empirically its transferability capacity across languages, which highlights
interesting similarities between them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAF-GNN: Multi-adaptive Spatiotemporal-flow Graph Neural Network for Traffic Speed Forecasting. (arXiv:2108.03594v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yaobin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weitang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhongyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zixuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_T/0/1/0/all/0/1">Tingyun Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingwei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03594">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic forecasting is a core element of intelligent traffic monitoring
system. Approaches based on graph neural networks have been widely used in this
task to effectively capture spatial and temporal dependencies of road networks.
However, these approaches can not effectively define the complicated network
topology. Besides, their cascade network structures have limitations in
transmitting distinct features in the time and space dimensions. In this paper,
we propose a Multi-adaptive Spatiotemporal-flow Graph Neural Network (MAF-GNN)
for traffic speed forecasting. MAF-GNN introduces an effective Multi-adaptive
Adjacency Matrices Mechanism to capture multiple latent spatial dependencies
between traffic nodes. Additionally, we propose Spatiotemporal-flow Modules
aiming to further enhance feature propagation in both time and space
dimensions. MAF-GNN achieves better performance than other models on two
real-world datasets of public traffic network, METR-LA and PeMS-Bay,
demonstrating the effectiveness of the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust 1-bit Compressive Sensing with Partial Gaussian Circulant Matrices and Generative Priors. (arXiv:2108.03570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhaoqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Subhroshekhar Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarlett_J/0/1/0/all/0/1">Jonathan Scarlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03570">
                                    <div class="article-summary-box-inner">
                                        <span>In 1-bit compressive sensing, each measurement is quantized to a single bit,
namely the sign of a linear function of an unknown vector, and the goal is to
accurately recover the vector. While it is most popular to assume a standard
Gaussian sensing matrix for 1-bit compressive sensing, using structured sensing
matrices such as partial Gaussian circulant matrices is of significant
practical importance due to their faster matrix operations. In this paper, we
provide recovery guarantees for a correlation-based optimization algorithm for
robust 1-bit compressive sensing with randomly signed partial Gaussian
circulant matrices and generative models. Under suitable assumptions, we match
guarantees that were previously only known to hold for i.i.d.~Gaussian matrices
that require significantly more computation. We make use of a practical
iterative algorithm, and perform numerical experiments on image datasets to
corroborate our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Accurate Human Activity Recognition for Embedded Devices Using Multi-level Distillation. (arXiv:2107.07331v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Runze Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haiyong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1">Xuechun Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhiqing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yida Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07331">
                                    <div class="article-summary-box-inner">
                                        <span>Human Activity Recognition (HAR) based on IMU sensors is a crucial area in
ubiquitous computing. Because of the trend of deploying AI on IoT devices or
smartphones, more researchers are designing different HAR models for embedded
devices. Deployment of models in embedded devices can help enhance the
efficiency of HAR. We propose a multi-level HAR modeling pipeline called
Stage-Logits-Memory Distillation (SMLDist) for constructing deep convolutional
HAR models with embedded hardware support. SMLDist includes stage distillation,
memory distillation, and logits distillation. Stage distillation constrains the
learning direction of the intermediate features. The teacher model teaches the
student models how to explain and store the inner relationship among
high-dimensional features based on Hopfield networks in memory distillation.
Logits distillation builds logits distilled by a smoothed conditional rule to
preserve the probability distribution and enhance the softer target accuracy.
We compare the accuracy, F1 macro score, and energy cost on embedded platforms
of a MobileNet V3 model built by our SMLDist with those of various
state-of-the-art HAR frameworks. The product model has a good balance with
robustness and efficiency. SMLDist can also compress models with a minor
performance loss at an equal compression ratio to other advanced knowledge
distillation methods on seven public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GNNIE: GNN Inference Engine with Load-balancing and Graph-Specific Caching. (arXiv:2105.10554v2 [cs.AR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1">Sudipta Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Manasi_S/0/1/0/all/0/1">Susmita Dey Manasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunal_K/0/1/0/all/0/1">Kishor Kunal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramprasath_S/0/1/0/all/0/1">S. Ramprasath</a>, <a href="http://arxiv.org/find/cs/1/au:+Sapatnekar_S/0/1/0/all/0/1">Sachin S. Sapatnekar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10554">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNN) analysis engines are vital for real-world
problems that use large graph models. Challenges for a GNN hardware platform
include the ability to (a) host a variety of GNNs, (b) handle high sparsity in
input vertex feature vectors and the graph adjacency matrix and the
accompanying random memory access patterns, and (c) maintain load-balanced
computation in the face of uneven workloads, induced by high sparsity and
power-law vertex degree distributions. This paper proposes GNNIE, an
accelerator designed to run a broad range of GNNs. It tackles workload
imbalance by (i)~splitting vertex feature operands into blocks, (ii)~reordering
and redistributing computations, (iii)~using a novel flexible MAC architecture.
It adopts a graph-specific, degree-aware caching policy that is well suited to
real-world graph characteristics. The policy enhances on-chip data reuse and
avoids random memory access to DRAM.

GNNIE achieves average speedups of 21233x over a CPU and 699x over a GPU over
multiple datasets on graph attention networks (GATs), graph convolutional
networks (GCNs), GraphSAGE, GINConv, and DiffPool. Compared to prior
approaches, GNNIE achieves an average speedup of 35x over HyGCN (which cannot
implement GATs) for GCN, GraphSAGE, and GINConv, and, using 3.4x fewer
processing units, an average speedup of 2.1x over AWB-GCN (which runs only
GCNs).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathfinder: Parallel quasi-Newton variational inference. (arXiv:2108.03782v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Carpenter_B/0/1/0/all/0/1">Bob Carpenter</a>, <a href="http://arxiv.org/find/stat/1/au:+Gelman_A/0/1/0/all/0/1">Andrew Gelman</a>, <a href="http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1">Aki Vehtari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03782">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Pathfinder, a variational method for approximately sampling from
differentiable log densities. Starting from a random initialization, Pathfinder
locates normal approximations to the target density along a quasi-Newton
optimization path, with local covariance estimated using the inverse Hessian
estimates produced by the optimizer. Pathfinder returns draws from the
approximation with the lowest estimated Kullback-Leibler (KL) divergence to the
true posterior. We evaluate Pathfinder on a wide range of posterior
distributions, demonstrating that its approximate draws are better than those
from automatic differentiation variational inference (ADVI) and comparable to
those produced by short chains of dynamic Hamiltonian Monte Carlo (HMC), as
measured by 1-Wasserstein distance. Compared to ADVI and short dynamic HMC
runs, Pathfinder requires one to two orders of magnitude fewer log density and
gradient evaluations, with greater reductions for more challenging posteriors.
Importance resampling over multiple runs of Pathfinder improves the diversity
of approximate draws, reducing 1-Wasserstein distance further and providing a
measure of robustness to optimization failures on plateaus, saddle points, or
in minor modes. The Monte Carlo KL-divergence estimates are embarrassingly
parallelizable in the core Pathfinder algorithm, as are multiple runs in the
resampling version, further increasing Pathfinder&#x27;s speed advantage with
multiple cores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EVGen: Adversarial Networks for Learning Electric Vehicle Charging Loads and Hidden Representations. (arXiv:2108.03762v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Buechler_R/0/1/0/all/0/1">Robert Buechler</a>, <a href="http://arxiv.org/find/cs/1/au:+Balogun_E/0/1/0/all/0/1">Emmanuel Balogun</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1">Arun Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_R/0/1/0/all/0/1">Ram Rajagopal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03762">
                                    <div class="article-summary-box-inner">
                                        <span>The nexus between transportation, the power grid, and consumer behavior is
more pronounced than ever before as the race to decarbonize the transportation
sector intensifies. Electrification in the transportation sector has led to
technology shifts and rapid deployment of electric vehicles (EVs). The
potential increase in stochastic and spatially heterogeneous charging load
presents a unique challenge that is not well studied, and will have significant
impacts on grid operations, emissions, and system reliability if not managed
effectively. Realistic scenario generators can help operators prepare, and
machine learning can be leveraged to this end. In this work, we develop
generative adversarial networks (GANs) to learn distributions of electric
vehicle (EV) charging sessions and disentangled representations. We show that
this model structure successfully parameterizes unlabeled temporal and power
patterns without supervision and is able to generate synthetic data conditioned
on these parameters. We benchmark the generation capability of this model with
Gaussian Mixture Models (GMMs), and empirically show that our proposed model
framework is better at capturing charging distributions and temporal dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning for Future Wireless Networks: A Comprehensive Survey. (arXiv:2102.07572v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cong T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1">Nguyen Van Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_N/0/1/0/all/0/1">Nam H. Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saputra_Y/0/1/0/all/0/1">Yuris Mulya Saputra</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1">Dinh Thai Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Diep N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1">Quoc-Viet Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1">Eryk Dutkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Won-Joo Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07572">
                                    <div class="article-summary-box-inner">
                                        <span>With outstanding features, Machine Learning (ML) has been the backbone of
numerous applications in wireless networks. However, the conventional ML
approaches have been facing many challenges in practical implementation, such
as the lack of labeled data, the constantly changing wireless environments, the
long training process, and the limited capacity of wireless devices. These
challenges, if not addressed, will impede the effectiveness and applicability
of ML in future wireless networks. To address these problems, Transfer Learning
(TL) has recently emerged to be a very promising solution. The core idea of TL
is to leverage and synthesize distilled knowledge from similar tasks as well as
from valuable experiences accumulated from the past to facilitate the learning
of new problems. Doing so, TL techniques can reduce the dependence on labeled
data, improve the learning speed, and enhance the ML methods&#x27; robustness to
different wireless environments. This article aims to provide a comprehensive
survey on applications of TL in wireless networks. Particularly, we first
provide an overview of TL including formal definitions, classification, and
various types of TL techniques. We then discuss diverse TL approaches proposed
to address emerging issues in wireless networks. The issues include spectrum
management, localization, signal recognition, security, human activity
recognition and caching, which are all important to next-generation networks
such as 5G and beyond. Finally, we highlight important challenges, open issues,
and future research directions of TL in future wireless networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training of deep residual networks with stochastic MG/OPT. (arXiv:2108.04052v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Planta_C/0/1/0/all/0/1">Cyrill von Planta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopanicakova_A/0/1/0/all/0/1">Alena Kopanicakova</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_R/0/1/0/all/0/1">Rolf Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.04052">
                                    <div class="article-summary-box-inner">
                                        <span>We train deep residual networks with a stochastic variant of the nonlinear
multigrid method MG/OPT. To build the multilevel hierarchy, we use the
dynamical systems viewpoint specific to residual networks. We report
significant speed-ups and additional robustness for training MNIST on deep
residual networks. Our numerical experiments also indicate that multilevel
training can be used as a pruning technique, as many of the auxiliary networks
have accuracies comparable to the original network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Dimensional Differentially Private Stochastic Optimization with Heavy-tailed Data. (arXiv:2107.11136v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_S/0/1/0/all/0/1">Shuo Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hanshen Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11136">
                                    <div class="article-summary-box-inner">
                                        <span>As one of the most fundamental problems in machine learning, statistics and
differential privacy, Differentially Private Stochastic Convex Optimization
(DP-SCO) has been extensively studied in recent years. However, most of the
previous work can only handle either regular data distribution or irregular
data in the low dimensional space case. To better understand the challenges
arising from irregular data distribution, in this paper we provide the first
study on the problem of DP-SCO with heavy-tailed data in the high dimensional
space. In the first part we focus on the problem over some polytope constraint
(such as the $\ell_1$-norm ball). We show that if the loss function is smooth
and its gradient has bounded second order moment, it is possible to get a (high
probability) error bound (excess population risk) of $\tilde{O}(\frac{\log
d}{(n\epsilon)^\frac{1}{3}})$ in the $\epsilon$-DP model, where $n$ is the
sample size and $d$ is the dimensionality of the underlying space. Next, for
LASSO, if the data distribution that has bounded fourth-order moments, we
improve the bound to $\tilde{O}(\frac{\log d}{(n\epsilon)^\frac{2}{5}})$ in the
$(\epsilon, \delta)$-DP model. In the second part of the paper, we study sparse
learning with heavy-tailed data. We first revisit the sparse linear model and
propose a truncated DP-IHT method whose output could achieve an error of
$\tilde{O}(\frac{s^{*2}\log d}{n\epsilon})$, where $s^*$ is the sparsity of the
underlying parameter. Then we study a more general problem over the sparsity
({\em i.e.,} $\ell_0$-norm) constraint, and show that it is possible to achieve
an error of $\tilde{O}(\frac{s^{*\frac{3}{2}}\log d}{n\epsilon})$, which is
also near optimal up to a factor of $\tilde{O}{(\sqrt{s^*})}$, if the loss
function is smooth and strongly convex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Piecewise Linear Units Improve Deep Neural Networks. (arXiv:2108.00700v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Inturrisi_J/0/1/0/all/0/1">Jordan Inturrisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khoo_S/0/1/0/all/0/1">Sui Yang Khoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouzani_A/0/1/0/all/0/1">Abbas Kouzani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagliarella_R/0/1/0/all/0/1">Riccardo Pagliarella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00700">
                                    <div class="article-summary-box-inner">
                                        <span>The activation function is at the heart of a deep neural networks
nonlinearity; the choice of the function has great impact on the success of
training. Currently, many practitioners prefer the Rectified Linear Unit (ReLU)
due to its simplicity and reliability, despite its few drawbacks. While most
previous functions proposed to supplant ReLU have been hand-designed, recent
work on learning the function during training has shown promising results. In
this paper we propose an adaptive piecewise linear activation function, the
Piecewise Linear Unit (PiLU), which can be learned independently for each
dimension of the neural network. We demonstrate how PiLU is a generalised
rectifier unit and note its similarities with the Adaptive Piecewise Linear
Units, namely adaptive and piecewise linear. Across a distribution of 30
experiments, we show that for the same model architecture, hyperparameters, and
pre-processing, PiLU significantly outperforms ReLU: reducing classification
error by 18.53% on CIFAR-10 and 13.13% on CIFAR-100, for a minor increase in
the number of neurons. Further work should be dedicated to exploring
generalised piecewise linear units, as well as verifying these results across
other challenging domains and larger problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems. (arXiv:2008.10581v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Aman Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+OKelly_M/0/1/0/all/0/1">Matthew O&#x27;Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1">Russ Tedrake</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchi_J/0/1/0/all/0/1">John Duchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10581">
                                    <div class="article-summary-box-inner">
                                        <span>Learning-based methodologies increasingly find applications in
safety-critical domains like autonomous driving and medical robotics. Due to
the rare nature of dangerous events, real-world testing is prohibitively
expensive and unscalable. In this work, we employ a probabilistic approach to
safety evaluation in simulation, where we are concerned with computing the
probability of dangerous events. We develop a novel rare-event simulation
method that combines exploration, exploitation, and optimization techniques to
find failure modes and estimate their rate of occurrence. We provide rigorous
guarantees for the performance of our method in terms of both statistical and
computational efficiency. Finally, we demonstrate the efficacy of our approach
on a variety of scenarios, illustrating its usefulness as a tool for rapid
sensitivity analysis and model comparison that are essential to developing and
testing safety-critical autonomous systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlphaGAN: Fully Differentiable Architecture Search for Generative Adversarial Networks. (arXiv:2006.09134v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuesong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Guinan Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09134">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) are formulated as minimax game
problems, whereby generators attempt to approach real data distributions by
virtue of adversarial learning against discriminators. The intrinsic problem
complexity poses the challenge to enhance the performance of generative
networks. In this work, we aim to boost model learning from the perspective of
network architectures, by incorporating recent progress on automated
architecture search into GANs. To this end, we propose a fully differentiable
search framework for generative adversarial networks, dubbed alphaGAN. The
searching process is formalized as solving a bi-level minimax optimization
problem, in which the outer-level objective aims for seeking a suitable network
architecture towards pure Nash Equilibrium conditioned on the generator and the
discriminator network parameters optimized with a traditional GAN loss in the
inner level. The entire optimization performs a first-order method by
alternately minimizing the two-level objective in a fully differentiable
manner, enabling architecture search to be completed in an enormous search
space. Extensive experiments on CIFAR-10 and STL-10 datasets show that our
algorithm can obtain high-performing architectures only with 3-GPU hours on a
single GPU in the search space comprised of approximate 2 ? 1011 possible
configurations. We also provide a comprehensive analysis on the behavior of the
searching process and the properties of searched architectures, which would
benefit further research on architectures for generative models. Pretrained
models and codes are available at https://github.com/yuesongtian/AlphaGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Weak Supervision Approach to Detecting Visual Anomalies for Automated Testing of Graphics Units. (arXiv:1912.04138v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szeskin_A/0/1/0/all/0/1">Adi Szeskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Faivishevsky_L/0/1/0/all/0/1">Lev Faivishevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Muppalla_A/0/1/0/all/0/1">Ashwin K Muppalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Armon_A/0/1/0/all/0/1">Amitai Armon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1">Tom Hope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.04138">
                                    <div class="article-summary-box-inner">
                                        <span>We present a deep learning system for testing graphics units by detecting
novel visual corruptions in videos. Unlike previous work in which manual
tagging was required to collect labeled training data, our weak supervision
method is fully automatic and needs no human labelling. This is achieved by
reproducing driver bugs that increase the probability of generating
corruptions, and by making use of ideas and methods from the Multiple Instance
Learning (MIL) setting. In our experiments, we significantly outperform
unsupervised methods such as GAN-based models and discover novel corruptions
undetected by baselines, while adhering to strict requirements on accuracy and
efficiency of our real-time system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Transfer with von Neumann Conditional Divergence. (arXiv:2108.03531v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shaker_A/0/1/0/all/0/1">Ammar Shaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shujian Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03531">
                                    <div class="article-summary-box-inner">
                                        <span>The similarity of feature representations plays a pivotal role in the success
of domain adaptation and generalization. Feature similarity includes both the
invariance of marginal distributions and the closeness of conditional
distributions given the desired response $y$ (e.g., class labels).
Unfortunately, traditional methods always learn such features without fully
taking into consideration the information in $y$, which in turn may lead to a
mismatch of the conditional distributions or the mix-up of discriminative
structures underlying data distributions. In this work, we introduce the
recently proposed von Neumann conditional divergence to improve the
transferability across multiple domains. We show that this new divergence is
differentiable and eligible to easily quantify the functional dependence
between features and $y$. Given multiple source tasks, we integrate this
divergence to capture discriminative information in $y$ and design novel
learning objectives assuming those source tasks are observed either
simultaneously or sequentially. In both scenarios, we obtain favorable
performance against state-of-the-art methods in terms of smaller generalization
error on new tasks and less catastrophic forgetting on source tasks (in the
sequential setup).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions. (arXiv:1811.00414v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_E/0/1/0/all/0/1">Ewin Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00414">
                                    <div class="article-summary-box-inner">
                                        <span>A central roadblock to analyzing quantum algorithms on quantum states is the
lack of a comparable input model for classical algorithms. Inspired by recent
work of the author [E. Tang, STOC&#x27;19], we introduce such a model, where we
assume we can efficiently perform $\ell^2$-norm samples of input data, a
natural analogue to quantum algorithms that assume efficient state preparation
of classical data. Though this model produces less practical algorithms than
the (stronger) standard model of classical computation, it captures versions of
many of the features and nuances of quantum linear algebra algorithms. With
this model, we describe classical analogues to Lloyd, Mohseni, and Rebentrost&#x27;s
quantum algorithms for principal component analysis [Nat. Phys. 10, 631 (2014)]
and nearest-centroid clustering [arXiv:1307.0411]. Since they are only
polynomially slower, these algorithms suggest that the exponential speedups of
their quantum counterparts are simply an artifact of state preparation
assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Machine Learning Tool to Determine State of Mind and Emotion. (arXiv:2108.03444v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jamisola_R/0/1/0/all/0/1">Rodrigo S. Jamisola Jr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03444">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the possibility of creating a machine learning tool
that automatically determines the state of mind and emotion of an individual
through a questionnaire, without the aid of a human expert. The state of mind
and emotion is defined in this work as pertaining to preference, feelings, or
opinion that is not based on logic or reason. It is the case when a person
gives out an answer to start by saying, &quot;I feel...&quot;. The tool is designed to
mimic the expertise of a psychologist and is built without any formal knowledge
of psychology. The idea is to build the expertise by purely computational
methods through thousands of questions collected from users. It is aimed
towards possibly diagnosing substance addiction, alcoholism, sexual attraction,
HIV status, degree of commitment, activity inclination, etc. First, the paper
presents the related literature and classifies them according to data gathering
methods. Another classification is created according to preference, emotion,
grouping, and rules to achieve a deeper interpretation and better understanding
of the state of mind and emotion. Second, the proposed tool is developed using
an online addiction questionnaire with 10 questions and 292 respondents. In
addition, an initial investigation on the dimension of addiction is presented
through the built machine learning model. Machine learning methods, namely,
artificial neural network (ANN) and support vector machine (SVM), are used to
determine a true or false or degree of state of a respondent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Oblique Random Forests: Towards Closing the Gap on Convolutional Deep Networks. (arXiv:1909.11799v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perry_R/0/1/0/all/0/1">Ronan Perry</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Adam Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_C/0/1/0/all/0/1">Chester Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1">Tyler M. Tomita</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1">Ronak Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Arroyo_J/0/1/0/all/0/1">Jesus Arroyo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patsolic_J/0/1/0/all/0/1">Jesse Patsolic</a>, <a href="http://arxiv.org/find/cs/1/au:+Falk_B/0/1/0/all/0/1">Benjamin Falk</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11799">
                                    <div class="article-summary-box-inner">
                                        <span>Decision forests (Forests), in particular random forests and gradient
boosting trees, have demonstrated state-of-the-art accuracy compared to other
methods in many supervised learning scenarios. In particular, Forests dominate
other methods in tabular data, that is, when the feature space is unstructured,
so that the signal is invariant to a permutation of the feature indices.
However, in structured data lying on a manifold (such as images, text, and
speech) deep networks (Networks), specifically convolutional deep networks
(ConvNets), tend to outperform Forests. We conjecture that at least part of the
reason for this is that the input to Networks is not simply the feature
magnitudes, but also their indices. In contrast, naive Forest implementations
fail to explicitly consider feature indices. A recently proposed Forest
approach demonstrates that Forests, for each node, implicitly sample a random
matrix from some specific distribution. These Forests, like some classes of
Networks, learn by partitioning the feature space into convex polytopes
corresponding to linear functions. We build on that approach and show that one
can choose distributions in a manifold-aware fashion to incorporate feature
locality. We demonstrate the empirical performance on data whose features live
on three different manifolds: a torus, images, and time-series. Moreover, we
demonstrate its strength in multivariate simulated settings and also show
superiority in predicting surgical outcome in epilepsy patients and predicting
movement direction from raw stereotactic EEG data from non-motor brain regions.
In all simulations and real data, Manifold Oblique Random Forest (MORF)
algorithm outperforms approaches that ignore feature space structure and
challenges the performance of ConvNets. Moreover, MORF runs fast and maintains
interpretability and theoretical justification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Nature and Types of Anomalies: A Review of Deviations in Data. (arXiv:2007.15634v4 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foorthuis_R/0/1/0/all/0/1">Ralph Foorthuis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15634">
                                    <div class="article-summary-box-inner">
                                        <span>Anomalies are occurrences in a dataset that are in some way unusual and do
not fit the general patterns. The concept of the anomaly is typically
ill-defined and perceived as vague and domain-dependent. Moreover, despite some
250 years of publications on the topic, no comprehensive and concrete overviews
of the different types of anomalies have hitherto been published. By means of
an extensive literature review this study therefore offers the first
theoretically principled and domain-independent typology of data anomalies and
presents a full overview of anomaly types and subtypes. To concretely define
the concept of the anomaly and its different manifestations, the typology
employs five dimensions: data type, cardinality of relationship, anomaly level,
data structure, and data distribution. These fundamental and data-centric
dimensions naturally yield 3 broad groups, 9 basic types, and 63 subtypes of
anomalies. The typology facilitates the evaluation of the functional
capabilities of anomaly detection algorithms, contributes to explainable data
science, and provides insights into relevant topics such as local versus global
anomalies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Representation Learning for Rapid Intraoperative Diagnosis of Skull Base Tumors Imaged Using Stimulated Raman Histology. (arXiv:2108.03555v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Cheng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1">Abhishek Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzey_J/0/1/0/all/0/1">Joseph Linzey</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rushikesh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sung Jik Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1">Sudharsan Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alber_D/0/1/0/all/0/1">Daniel Alber</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondepudi_A/0/1/0/all/0/1">Akhil Kondepudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Urias_E/0/1/0/all/0/1">Esteban Urias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandian_B/0/1/0/all/0/1">Balaji Pandian</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Holou_W/0/1/0/all/0/1">Wajd Al-Holou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sullivan_S/0/1/0/all/0/1">Steve Sullivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1">B. Gregory Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Heth_J/0/1/0/all/0/1">Jason Heth</a>, <a href="http://arxiv.org/find/cs/1/au:+Freudiger_C/0/1/0/all/0/1">Chris Freudiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Khalsa_S/0/1/0/all/0/1">Siri Khalsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacione_D/0/1/0/all/0/1">Donato Pacione</a>, <a href="http://arxiv.org/find/cs/1/au:+Golfinos_J/0/1/0/all/0/1">John G. Golfinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Camelo_Piragua_S/0/1/0/all/0/1">Sandra Camelo-Piragua</a>, <a href="http://arxiv.org/find/cs/1/au:+Orringer_D/0/1/0/all/0/1">Daniel A. Orringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hollon_T/0/1/0/all/0/1">Todd Hollon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03555">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Accurate diagnosis of skull base tumors is essential for
providing personalized surgical treatment strategies. Intraoperative diagnosis
can be challenging due to tumor diversity and lack of intraoperative pathology
resources.

Objective: To develop an independent and parallel intraoperative pathology
workflow that can provide rapid and accurate skull base tumor diagnoses using
label-free optical imaging and artificial intelligence (AI).

Method: We used a fiber laser-based, label-free, non-consumptive,
high-resolution microscopy method ($&lt;$ 60 sec per 1 $\times$ 1 mm$^\text{2}$),
called stimulated Raman histology (SRH), to image a consecutive, multicenter
cohort of skull base tumor patients. SRH images were then used to train a
convolutional neural network (CNN) model using three representation learning
strategies: cross-entropy, self-supervised contrastive learning, and supervised
contrastive learning. Our trained CNN models were tested on a held-out,
multicenter SRH dataset.

Results: SRH was able to image the diagnostic features of both benign and
malignant skull base tumors. Of the three representation learning strategies,
supervised contrastive learning most effectively learned the distinctive and
diagnostic SRH image features for each of the skull base tumor types. In our
multicenter testing set, cross-entropy achieved an overall diagnostic accuracy
of 91.5%, self-supervised contrastive learning 83.9%, and supervised
contrastive learning 96.6%. Our trained model was able to identify tumor-normal
margins and detect regions of microscopic tumor infiltration in whole-slide SRH
images.

Conclusion: SRH with AI models trained using contrastive representation
learning can provide rapid and accurate intraoperative diagnosis of skull base
tumors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a method to anticipate dark matter signals with deep learning at the LHC. (arXiv:2105.12018v2 [hep-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ph/1/au:+Arganda_E/0/1/0/all/0/1">Ernesto Arganda</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Medina_A/0/1/0/all/0/1">Anibal D. Medina</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Perez_A/0/1/0/all/0/1">Andres D. Perez</a>, <a href="http://arxiv.org/find/hep-ph/1/au:+Szynkman_A/0/1/0/all/0/1">Alejandro Szynkman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12018">
                                    <div class="article-summary-box-inner">
                                        <span>We study several simplified dark matter (DM) models and their signatures at
the LHC using neural networks. We focus on the usual monojet plus missing
transverse energy channel, but to train the algorithms we organize the data in
2D histograms instead of event-by-event arrays. This results in a large
performance boost to distinguish between standard model (SM) only and SM plus
new physics signals. We use the kinematic monojet features as input data which
allow us to describe families of models with a single data sample. We found
that the neural network performance does not depend on the simulated number of
background events if they are presented as a function of $S/\sqrt{B}$, where
$S$ and $B$ are the number of signal and background events per histogram,
respectively. This provides flexibility to the method, since testing a
particular model in that case only requires knowing the new physics monojet
cross section. Furthermore, we also discuss the network performance under
incorrect assumptions about the true DM nature. Finally, we propose multimodel
classifiers to search and identify new signals in a more general way, for the
next LHC run.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Look at the Evaluation Setup of the M5 Forecasting Competition. (arXiv:2108.03588v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hewamalage_H/0/1/0/all/0/1">Hansika Hewamalage</a>, <a href="http://arxiv.org/find/cs/1/au:+Montero_Manso_P/0/1/0/all/0/1">Pablo Montero-Manso</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1">Christoph Bergmeir</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyndman_R/0/1/0/all/0/1">Rob J Hyndman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03588">
                                    <div class="article-summary-box-inner">
                                        <span>Forecast evaluation plays a key role in how empirical evidence shapes the
development of the discipline. Domain experts are interested in error measures
relevant for their decision making needs. Such measures may produce unreliable
results. Although reliability properties of several metrics have already been
discussed, it has hardly been quantified in an objective way. We propose a
measure named Rank Stability, which evaluates how much the rankings of an
experiment differ in between similar datasets, when the models and errors are
constant. We use this to study the evaluation setup of the M5. We find that the
evaluation setup of the M5 is less reliable than other measures. The main
drivers of instability are hierarchical aggregation and scaling.
Price-weighting reduces the stability of all tested error measures. Scale
normalization of the M5 error measure results in less stability than other
scale-free errors. Hierarchical levels taken separately are less stable with
more aggregation, and their combination is even less stable than individual
levels. We also show positive tradeoffs of retaining aggregation importance
without affecting stability. Aggregation and stability can be linked to the
influence of much debated magic numbers. Many of our findings can be applied to
general hierarchical forecast benchmarking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MARViN -- Multiple Arithmetic Resolutions Vacillating in Neural Networks. (arXiv:2107.13490v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1">Lorenz Kummer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidak_K/0/1/0/all/0/1">Kevin Sidak</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichmann_T/0/1/0/all/0/1">Tabea Reichmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1">Wilfried Gansterer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13490">
                                    <div class="article-summary-box-inner">
                                        <span>Quantization is a technique for reducing deep neural networks (DNNs) training
and inference times, which is crucial for training in resource constrained
environments or time critical inference applications. State-of-the-art (SOTA)
quantization approaches focus on post-training quantization, i.e. quantization
of pre-trained DNNs for speeding up inference. Very little work on quantized
training exists, which neither al-lows dynamic intra-epoch precision switches
nor em-ploys an information theory based switching heuristic. Usually, existing
approaches require full precision refinement afterwards and enforce a global
word length across the whole DNN. This leads to suboptimal quantization
mappings and resource usage. Recognizing these limits, we introduce MARViN, a
new quantized training strategy using information theory-based intra-epoch
precision switching, which decides on a per-layer basis which precision should
be used in order to minimize quantization-induced information loss. Note that
any quantization must leave enough precision such that future learning steps do
not suffer from vanishing gradients. We achieve an average speedup of 1.86
compared to a float32 basis while limiting mean accuracy degradation on
AlexNet/ResNet to only -0.075%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Reinforcement Learning in Broad and Non-Parametric Environments. (arXiv:2108.03718v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bing_Z/0/1/0/all/0/1">Zhenshan Bing</a>, <a href="http://arxiv.org/find/cs/1/au:+Knak_L/0/1/0/all/0/1">Lukas Knak</a>, <a href="http://arxiv.org/find/cs/1/au:+Robin_F/0/1/0/all/0/1">Fabrice Oliver Robin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1">Alois Knoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03718">
                                    <div class="article-summary-box-inner">
                                        <span>Recent state-of-the-art artificial agents lack the ability to adapt rapidly
to new tasks, as they are trained exclusively for specific objectives and
require massive amounts of interaction to learn new skills. Meta-reinforcement
learning (meta-RL) addresses this challenge by leveraging knowledge learned
from training tasks to perform well in previously unseen tasks. However,
current meta-RL approaches limit themselves to narrow parametric task
distributions, ignoring qualitative differences between tasks that occur in the
real world. In this paper, we introduce TIGR, a Task-Inference-based meta-RL
algorithm using Gaussian mixture models (GMM) and gated Recurrent units,
designed for tasks in non-parametric environments. We employ a generative model
involving a GMM to capture the multi-modality of the tasks. We decouple the
policy training from the task-inference learning and efficiently train the
inference mechanism on the basis of an unsupervised reconstruction objective.
We provide a benchmark with qualitatively distinct tasks based on the
half-cheetah environment and demonstrate the superior performance of TIGR
compared to state-of-the-art meta-RL approaches in terms of sample efficiency
(3-10 times faster), asymptotic performance, and applicability in
non-parametric environments with zero-shot adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble neuroevolution based approach for multivariate time series anomaly detection. (arXiv:2108.03585v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faber_K/0/1/0/all/0/1">Kamil Faber</a>, <a href="http://arxiv.org/find/cs/1/au:+Zurek_D/0/1/0/all/0/1">Dominik &#x17b;urek</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietron_M/0/1/0/all/0/1">Marcin Pietro&#x144;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietak_K/0/1/0/all/0/1">Kamil Pi&#x119;tak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03585">
                                    <div class="article-summary-box-inner">
                                        <span>Multivariate time series anomaly detection is a very common problem in the
field of failure prevention. Fast prevention means lower repair costs and
losses. The amount of sensors in novel industry systems makes the anomaly
detection process quite difficult for humans. Algorithms which automates the
process of detecting anomalies are crucial in modern failure-prevention
systems. Therefore, many machine and deep learning models have been designed to
address this problem. Mostly, they are autoencoder-based architectures with
some generative adversarial elements. In this work, a framework is shown which
incorporates neuroevolution methods to boost the anomaly-detection scores of
new and already known models. The presented approach adapts evolution
strategies for evolving ensemble model, in which every single model works on a
subgroup of data sensors. The next goal of neuroevolution is to optimise
architecture and hyperparameters like window size, the number of layers, layer
depths, etc. The proposed framework shows that it is possible to boost most of
the anomaly detection deep learning models in a reasonable time and a fully
automated mode. The tests were run on SWAT and WADI datasets. To our knowledge,
this is the first approach in which an ensemble deep learning anomaly detection
model is built in a fully automatic way using a neuroevolution strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor Relational Algebra for Machine Learning System Design. (arXiv:2009.00524v3 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Binhang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jankov_D/0/1/0/all/0/1">Dimitrije Jankov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Jia Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yuxin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bourgeois_D/0/1/0/all/0/1">Daniel Bourgeois</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Chris Jermaine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00524">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the question: what is the abstraction that should be implemented
by the computational engine of a machine learning system? Current machine
learning systems typically push whole tensors through a series of compute
kernels such as matrix multiplications or activation functions, where each
kernel runs on an AI accelerator (ASIC) such as a GPU. This implementation
abstraction provides little built-in support for ML systems to scale past a
single machine, or for handling large models with matrices or tensors that do
not easily fit into the RAM of an ASIC. In this paper, we present an
alternative implementation abstraction called the tensor relational algebra
(TRA). The TRA is a set-based algebra based on the relational algebra.
Expressions in the TRA operate over binary tensor relations, where keys are
multi-dimensional arrays and values are tensors. The TRA is easily executed
with high efficiency in a parallel or distributed environment, and amenable to
automatic optimization. Our empirical study shows that the optimized TRA-based
back-end can significantly outperform alternatives for running ML workflows in
distributed clusters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DCAP: Deep Cross Attentional Product Network for User Response Prediction. (arXiv:2105.08649v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_F/0/1/0/all/0/1">Fangtian Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhumin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pless_R/0/1/0/all/0/1">Robert Pless</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08649">
                                    <div class="article-summary-box-inner">
                                        <span>User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network&#x27;s benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HetEmotionNet: Two-Stream Heterogeneous Graph Recurrent Neural Network for Multi-modal Emotion Recognition. (arXiv:2108.03354v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Ziyu Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Youfang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhiyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiangheng Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Caijie Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03354">
                                    <div class="article-summary-box-inner">
                                        <span>The research on human emotion under multimedia stimulation based on
physiological signals is an emerging field, and important progress has been
achieved for emotion recognition based on multi-modal signals. However, it is
challenging to make full use of the complementarity among
spatial-spectral-temporal domain features for emotion recognition, as well as
model the heterogeneity and correlation among multi-modal signals. In this
paper, we propose a novel two-stream heterogeneous graph recurrent neural
network, named HetEmotionNet, fusing multi-modal physiological signals for
emotion recognition. Specifically, HetEmotionNet consists of the
spatial-temporal stream and the spatial-spectral stream, which can fuse
spatial-spectral-temporal domain features in a unified framework. Each stream
is composed of the graph transformer network for modeling the heterogeneity,
the graph convolutional network for modeling the correlation, and the gated
recurrent unit for capturing the temporal domain or spectral domain dependency.
Extensive experiments on two real-world datasets demonstrate that our proposed
model achieves better performance than state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-pronged Strategy: Lightweight Augmented Graph Network Hashing for Scalable Image Retrieval. (arXiv:2108.03914v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hui Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhiyong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03914">
                                    <div class="article-summary-box-inner">
                                        <span>Hashing learns compact binary codes to store and retrieve massive data
efficiently. Particularly, unsupervised deep hashing is supported by powerful
deep neural networks and has the desirable advantage of label independence. It
is a promising technique for scalable image retrieval. However, deep models
introduce a large number of parameters, which is hard to optimize due to the
lack of explicit semantic labels and brings considerable training cost. As a
result, the retrieval accuracy and training efficiency of existing unsupervised
deep hashing are still limited. To tackle the problems, in this paper, we
propose a simple and efficient \emph{Lightweight Augmented Graph Network
Hashing} (LAGNH) method with a two-pronged strategy. For one thing, we extract
the inner structure of the image as the auxiliary semantics to enhance the
semantic supervision of the unsupervised hash learning process. For another, we
design a lightweight network structure with the assistance of the auxiliary
semantics, which greatly reduces the number of network parameters that needs to
be optimized and thus greatly accelerates the training process. Specifically,
we design a cross-modal attention module based on the auxiliary semantic
information to adaptively mitigate the adverse effects in the deep image
features. Besides, the hash codes are learned by multi-layer message passing
within an adversarial regularized graph convolutional network. Simultaneously,
the semantic representation capability of hash codes is further enhanced by
reconstructing the similarity graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Deep Feature Calibration for Cross-Modal Joint Embedding Learning. (arXiv:2108.00705v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zhongwei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Luo Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00705">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a two-phase deep feature calibration framework for
efficient learning of semantics enhanced text-image cross-modal joint
embedding, which clearly separates the deep feature calibration in data
preprocessing from training the joint embedding model. We use the Recipe1M
dataset for the technical description and empirical validation. In
preprocessing, we perform deep feature calibration by combining deep feature
engineering with semantic context features derived from raw text-image input
data. We leverage LSTM to identify key terms, NLP methods to produce ranking
scores for key terms before generating the key term feature. We leverage
wideResNet50 to extract and encode the image category semantics to help
semantic alignment of the learned recipe and image embeddings in the joint
latent space. In joint embedding learning, we perform deep feature calibration
by optimizing the batch-hard triplet loss function with soft-margin and double
negative sampling, also utilizing the category-based alignment loss and
discriminator-based alignment loss. Extensive experiments demonstrate that our
SEJE approach with the deep feature calibration significantly outperforms the
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Action Localization Using Gated Recurrent Units. (arXiv:2108.03375v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khojasteh_H/0/1/0/all/0/1">Hassan Keshvari Khojasteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadzade_H/0/1/0/all/0/1">Hoda Mohammadzade</a>, <a href="http://arxiv.org/find/cs/1/au:+Behroozi_H/0/1/0/all/0/1">Hamid Behroozi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03375">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal Action Localization (TAL) task in which the aim is to predict the
start and end of each action and its class label has many applications in the
real world. But due to its complexity, researchers have not reached great
results compared to the action recognition task. The complexity is related to
predicting precise start and end times for different actions in any video. In
this paper, we propose a new network based on Gated Recurrent Unit (GRU) and
two novel post-processing ideas for TAL task. Specifically, we propose a new
design for the output layer of the GRU resulting in the so-called GRU-Splitted
model. Moreover, linear interpolation is used to generate the action proposals
with precise start and end times. Finally, to rank the generated proposals
appropriately, we use a Learn to Rank (LTR) approach. We evaluated the
performance of the proposed method on Thumos14 dataset. Results show the
superiority of the performance of the proposed method compared to
state-of-the-art. Especially in the mean Average Precision (mAP) metric at
Intersection over Union (IoU) 0.7, we get 27.52% which is 5.12% better than
that of state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cough Detection Using Selected Informative Features from Audio Signals. (arXiv:2108.03538v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinru Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Menghan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.03538">
                                    <div class="article-summary-box-inner">
                                        <span>Cough is a common symptom of respiratory and lung diseases. Cough detection
is important to prevent, assess and control epidemic, such as COVID-19. This
paper proposes a model to detect cough events from cough audio signals. The
models are trained by the dataset combined ESC-50 dataset with self-recorded
cough recordings. The test dataset contains inpatient cough recordings
collected from inpatients of the respiratory disease department in Ruijin
Hospital. We totally build 15 cough detection models based on different feature
numbers selected by Random Frog, Uninformative Variable Elimination (UVE), and
Variable influence on projection (VIP) algorithms respectively. The optimal
model is based on 20 features selected from Mel Frequency Cepstral Coefficients
(MFCC) features by UVE algorithm and classified with Support Vector Machine
(SVM) linear two-class classifier. The best cough detection model realizes the
accuracy, recall, precision and F1-score with 94.9%, 97.1%, 93.1% and 0.95
respectively. Its excellent performance with fewer dimensionality of the
feature vector shows the potential of being applied to mobile devices, such as
smartphones, thus making cough detection remote and non-contact.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-08-16T01:57:42.823Z">2021-08-16T01:57:42.823Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>